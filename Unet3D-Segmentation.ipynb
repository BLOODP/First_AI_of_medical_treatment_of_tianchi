{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import skimage, os\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "def load_itk(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    ct_scan = sitk.GetArratFromImage(itkimage)\n",
    "    spacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    origin = np.array(list(reversed(itkimage.GetOriin())))\n",
    "    return ct_scan,origin,spacing\n",
    "\n",
    "def world_2_voxel(world_coordinates,origin,spacing):\n",
    "    streched_voxel_coordinates = np.absolute(world_coordinates - origin)\n",
    "    voxel_coordinates= streched_voxel_coordinates / spacing\n",
    "    return voxel_coordinates\n",
    "\n",
    "def voxel_2_world(voxel_coordinates,origin,spacing):\n",
    "    stretched_voxel_coordinates = voxel_coordinates * spacing\n",
    "    world_coordinates = stretched_voxel_coordinates + origin\n",
    "    return world_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _weight_variable(name,shape,stddev):\n",
    "    print('shape :',shape,stddev)\n",
    "#     return tf.get_variable(name,shape,tf.float32,tf.truncated_normal_initializer(stddev=stddev))\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev),name=name)\n",
    "\n",
    "def _bias_variable(name,shape):\n",
    "#     return tf.get_variable(name,shape,tf.float32,tf.constant_initializer(0.1,dtype=tf.float32))\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "\n",
    "def create_3d_unet(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2, summaries=True):\n",
    "    nx = tf.shape(x)[1]\n",
    "    ny = tf.shape(x)[2]\n",
    "    nz = tf.shape(x)[3]\n",
    "    x_image = tf.reshape(x, tf.stack([-1,nx,ny,nz,channels]))\n",
    "    prev_layer = x_image\n",
    "    in_filters = channels\n",
    "    \n",
    "    output_pixels = []\n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "#     with tf.variable_scope('conv1',reuse=True) as scope:\n",
    "    out_filters = 48\n",
    "    stddev = np.sqrt(2 / (3**2 * out_filters))\n",
    "\n",
    "    conv1_w1 = _weight_variable('conv1_weights1',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv1 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv1_w1,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv1_b1 = _bias_variable('conv1_bias1',[out_filters]) \n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_b1))\n",
    "    weights.append(conv1_w1)\n",
    "    biases.append(conv1_b1)\n",
    "    axis = list(range(len(conv1.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv1,axis)\n",
    "    normed = tf.nn.batch_normalization(conv1,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    conv1_w2 = _weight_variable('conv1_weights2',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv1 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv1_w2,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv1_b2 = _bias_variable('conv1_bias2',[out_filters])\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_b2))\n",
    "    mean,variance = tf.nn.moments(conv1,axis)\n",
    "    normed = tf.nn.batch_normalization(conv1,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "    weights.append(conv1_w2)\n",
    "    biases.append(conv1_b2)\n",
    "\n",
    "    conv1_w3 = _weight_variable('conv1_weights3',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv1 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv1_w3,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv1_b3 = _bias_variable('conv1_bias3',[out_filters])\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_b3))\n",
    "    mean,variance = tf.nn.moments(conv1,axis)\n",
    "    #   offset = 0.01 scale = 1\n",
    "    normed = tf.nn.batch_normalization(conv1,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "    weights.append(conv1_w3)\n",
    "    biases.append(conv1_b3)\n",
    "    output_pixels.append(conv1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    down_pool = tf.nn.max_pool3d(prev_layer,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],padding='VALID')\n",
    "    prev_layer = down_pool\n",
    "    in_filters = out_filters\n",
    "\n",
    "    \n",
    "    \n",
    "#     with tf.variable_scope('cnov2',reuse=True) as scope:\n",
    "    stddev = np.sqrt(2 / (3**2 * out_filters))\n",
    "    conv2_w1 = _weight_variable('conv2_weights1',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv2 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv2_w1,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv2_b1 = _bias_variable('conv2_bias1',[out_filters]) \n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_b1))\n",
    "    weights.append(conv2_w1)\n",
    "    biases.append(conv2_b1)\n",
    "    axis = list(range(len(conv2.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv2,axis)\n",
    "    normed = tf.nn.batch_normalization(conv2,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    stddev = np.sqrt(2 / (3**2 * out_filters))\n",
    "    conv2_w2 = _weight_variable('conv2_weights2',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv2 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv2_w2,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv2_b2 = _bias_variable('conv2_bias2',[out_filters]) \n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_b2))\n",
    "    weights.append(conv2_w2)\n",
    "    biases.append(conv2_b2)\n",
    "    axis = list(range(len(conv2.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv2,axis)\n",
    "    normed = tf.nn.batch_normalization(conv2,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    stddev = np.sqrt(2 / (3**2 * out_filters))\n",
    "    conv2_w3 = _weight_variable('conv2_weights3',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv2 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv2_w3,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv2_b3 = _bias_variable('conv2_bias3',[out_filters]) \n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_b3))\n",
    "    weights.append(conv2_w3)\n",
    "    biases.append(conv2_b3)\n",
    "    axis = list(range(len(conv2.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv2,axis)\n",
    "    normed = tf.nn.batch_normalization(conv2,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    stddev = np.sqrt(2 / (3**2 * out_filters))\n",
    "    conv2_w4 = _weight_variable('conv2_weights4',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv2 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv2_w4,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv2_b4 = _bias_variable('conv2_bias4',[out_filters]) \n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_b4))\n",
    "    weights.append(conv2_w4)\n",
    "    biases.append(conv2_b4)\n",
    "    axis = list(range(len(conv2.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv2,axis)\n",
    "    normed = tf.nn.batch_normalization(conv2,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "    output_pixels.append(conv2)\n",
    "        \n",
    "        \n",
    "#     with tf.variable_scope('upscale',reuse=True) as scope:\n",
    "    x_shape = tf.shape(prev_layer)\n",
    "    output_shape = tf.stack([x_shape[0], x_shape[1]*2, x_shape[2]*2,x_shape[3]*2, x_shape[4]])\n",
    "    stddev = np.sqrt(2 / (2**2 * out_filters))\n",
    "    kernel = _weight_variable('kernel',[2,2,2,out_filters,in_filters],stddev)\n",
    "    upscale = tf.nn.conv3d_transpose(prev_layer,kernel,output_shape,[1,2,2,2,1],padding='VALID')\n",
    "    weights.append(kernel)\n",
    "    prev_layer = upscale\n",
    "    output_pixels.append(upscale)\n",
    "    \n",
    "    x1_shape = tf.shape(conv1)\n",
    "    x2_shape = tf.shape(upscale)\n",
    "    \n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2,(x1_shape[3] - x2_shape[3]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2],x2_shape[3], -1]\n",
    "    x1_crop = tf.slice(conv1, offsets, size)\n",
    "    prev_layer = tf.concat([x1_crop, upscale], 4)\n",
    "    in_filters = out_filters*2\n",
    "    \n",
    "#     with tf.variable_scope('conv3',reuse=True) as scope:\n",
    "    out_filters = 96\n",
    "    stddev = np.sqrt(2 / (3**2 * out_filters))\n",
    "\n",
    "    conv3_w1 = _weight_variable('conv3_weights1',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv3 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv3_w1,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv3_b1 = _bias_variable('conv3_bias1',[out_filters]) \n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(conv3,conv3_b1))\n",
    "    weights.append(conv3_w1)\n",
    "    biases.append(conv3_b1)\n",
    "#         prev_layer = conv3\n",
    "    axis = list(range(len(conv3.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv3,axis)\n",
    "    normed = tf.nn.batch_normalization(conv3,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    conv3_w2 = _weight_variable('conv3_weights2',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv3 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv3_w2,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv3_b2 = _bias_variable('conv3_bias2',[out_filters]) \n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(conv3,conv3_b2))\n",
    "    weights.append(conv3_w2)\n",
    "    biases.append(conv3_b2)\n",
    "#         prev_layer = conv3\n",
    "    axis = list(range(len(conv3.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv3,axis)\n",
    "    normed = tf.nn.batch_normalization(conv3,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    conv3_w3 = _weight_variable('conv3_weights3',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv3 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv3_w3,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv3_b3 = _bias_variable('conv3_bias3',[out_filters]) \n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(conv3,conv3_b3))\n",
    "    weights.append(conv3_w3)\n",
    "    biases.append(conv3_b3)\n",
    "#         prev_layer = conv3\n",
    "    axis = list(range(len(conv3.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv3,axis)\n",
    "    normed = tf.nn.batch_normalization(conv3,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    conv3_w4 = _weight_variable('conv3_weights4',[3,3,3,in_filters,out_filters],stddev)\n",
    "    conv3 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv3_w4,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv3_b4 = _bias_variable('conv3_bias4',[out_filters]) \n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(conv3,conv3_b4))\n",
    "    weights.append(conv3_w4)\n",
    "    biases.append(conv3_b4)\n",
    "#         prev_layer = conv3\n",
    "    axis = list(range(len(conv3.get_shape()) - 1))\n",
    "    mean,variance = tf.nn.moments(conv3,axis)\n",
    "    normed = tf.nn.batch_normalization(conv3,mean=mean,variance=variance,offset=None,scale=None,variance_epsilon=0.001)\n",
    "    prev_layer = normed\n",
    "    in_filters = out_filters\n",
    "\n",
    "    conv3_w5 = _weight_variable('conv3_weights5',[3,3,3,in_filters,2],stddev)\n",
    "    conv3 = tf.nn.dropout(tf.nn.conv3d(prev_layer,conv3_w5,[1,1,1,1,1],padding='VALID'),keep_prob)\n",
    "    conv3_b5 = _bias_variable('conv3_bias5',[2]) \n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(conv3,conv3_b5))\n",
    "    weights.append(conv3_w5)\n",
    "    biases.append(conv3_b5)\n",
    "    prev_layer = conv3\n",
    "    in_filters = out_filters\n",
    "    output_pixels.append(conv3)\n",
    "    \n",
    "    \n",
    "    return prev_layer,weights,biases,output_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 ] LKDS-00001 time: 0.875215\n",
      "[ 2 ] LKDS-00003 time: 1.577871\n",
      "[ 3 ] LKDS-00004 time: 2.232676\n",
      "[ 4 ] LKDS-00005 time: 0.565741\n",
      "[ 5 ] LKDS-00007 time: 1.088456\n",
      "[ 6 ] LKDS-00011 time: 0.766372\n",
      "[ 7 ] LKDS-00013 time: 0.866413\n",
      "[ 8 ] LKDS-00015 time: 1.075990\n",
      "[ 9 ] LKDS-00016 time: 1.478942\n",
      "[ 10 ] LKDS-00019 time: 0.789790\n",
      "[ 11 ] LKDS-00020 time: 3.327226\n",
      "[ 12 ] LKDS-00021 time: 0.810491\n",
      "[ 13 ] LKDS-00023 time: 1.074623\n",
      "[ 14 ] LKDS-00025 time: 0.999910\n",
      "[ 15 ] LKDS-00026 time: 0.936111\n",
      "[ 16 ] LKDS-00028 time: 0.721319\n",
      "[ 17 ] LKDS-00029 time: 0.669736\n",
      "[ 18 ] LKDS-00030 time: 1.145899\n",
      "[ 19 ] LKDS-00035 time: 1.270299\n",
      "[ 20 ] LKDS-00036 time: 0.684417\n",
      "[ 21 ] LKDS-00038 time: 0.662636\n",
      "[ 22 ] LKDS-00039 time: 1.257677\n",
      "[ 23 ] LKDS-00040 time: 1.986893\n",
      "[ 24 ] LKDS-00041 time: 1.582417\n",
      "[ 25 ] LKDS-00042 time: 15.910706\n",
      "[ 26 ] LKDS-00043 time: 1.408535\n",
      "[ 27 ] LKDS-00044 time: 0.917874\n",
      "[ 28 ] LKDS-00047 time: 1.112220\n",
      "[ 29 ] LKDS-00050 time: 1.344406\n",
      "[ 30 ] LKDS-00051 time: 0.956711\n",
      "[ 31 ] LKDS-00052 time: 2.261116\n",
      "[ 32 ] LKDS-00053 time: 0.815697\n",
      "[ 33 ] LKDS-00054 time: 2.055949\n",
      "[ 34 ] LKDS-00058 time: 1.357333\n",
      "[ 35 ] LKDS-00061 time: 0.843862\n",
      "[ 36 ] LKDS-00064 time: 1.485775\n",
      "[ 37 ] LKDS-00065 time: 1.287998\n",
      "[ 38 ] LKDS-00066 time: 1.117044\n",
      "[ 39 ] LKDS-00068 time: 1.030125\n",
      "[ 40 ] LKDS-00073 time: 0.685903\n",
      "[ 41 ] LKDS-00074 time: 0.711670\n",
      "[ 42 ] LKDS-00075 time: 1.504179\n",
      "[ 43 ] LKDS-00076 time: 0.672612\n",
      "[ 44 ] LKDS-00077 time: 1.138607\n",
      "[ 45 ] LKDS-00078 time: 2.260956\n",
      "[ 46 ] LKDS-00079 time: 1.184384\n",
      "[ 47 ] LKDS-00081 time: 1.801173\n",
      "[ 48 ] LKDS-00083 time: 1.663521\n",
      "[ 49 ] LKDS-00084 time: 16.333961\n",
      "[ 50 ] LKDS-00085 time: 1.479574\n",
      "[ 51 ] LKDS-00088 time: 0.868578\n",
      "[ 52 ] LKDS-00089 time: 1.026662\n",
      "[ 53 ] LKDS-00091 time: 0.809873\n",
      "[ 54 ] LKDS-00092 time: 0.828014\n",
      "[ 55 ] LKDS-00093 time: 0.897847\n",
      "[ 56 ] LKDS-00095 time: 1.339010\n",
      "[ 57 ] LKDS-00096 time: 1.321535\n",
      "[ 58 ] LKDS-00099 time: 1.208764\n",
      "[ 59 ] LKDS-00100 time: 0.842154\n",
      "[ 60 ] LKDS-00101 time: 0.852342\n",
      "[ 61 ] LKDS-00102 time: 0.624314\n",
      "[ 62 ] LKDS-00104 time: 1.021548\n",
      "[ 63 ] LKDS-00105 time: 0.930553\n",
      "[ 64 ] LKDS-00107 time: 0.966377\n",
      "[ 65 ] LKDS-00108 time: 1.532020\n",
      "[ 66 ] LKDS-00109 time: 0.621232\n",
      "[ 67 ] LKDS-00110 time: 0.902323\n",
      "[ 68 ] LKDS-00111 time: 1.315854\n",
      "[ 69 ] LKDS-00112 time: 1.174451\n",
      "[ 70 ] LKDS-00116 time: 0.385473\n",
      "[ 71 ] LKDS-00117 time: 1.052141\n",
      "[ 72 ] LKDS-00118 time: 1.146771\n",
      "[ 73 ] LKDS-00119 time: 0.660705\n",
      "[ 74 ] LKDS-00120 time: 0.990170\n",
      "[ 75 ] LKDS-00122 time: 1.520739\n",
      "[ 76 ] LKDS-00126 time: 1.955742\n",
      "[ 77 ] LKDS-00127 time: 16.754627\n",
      "[ 78 ] LKDS-00129 time: 1.650011\n",
      "[ 79 ] LKDS-00133 time: 1.674445\n",
      "[ 80 ] LKDS-00134 time: 1.673936\n",
      "[ 81 ] LKDS-00135 time: 1.546070\n",
      "[ 82 ] LKDS-00136 time: 0.851656\n",
      "[ 83 ] LKDS-00137 time: 1.388612\n",
      "[ 84 ] LKDS-00140 time: 1.252801\n",
      "[ 85 ] LKDS-00142 time: 1.320113\n",
      "[ 86 ] LKDS-00144 time: 0.846323\n",
      "[ 87 ] LKDS-00034 time: 0.775076\n",
      "[ 88 ] LKDS-00062 time: 0.901895\n",
      "[ 89 ] LKDS-00090 time: 0.883045\n",
      "[ 90 ] LKDS-00114 time: 1.440432\n",
      "[ 91 ] LKDS-00147 time: 0.787865\n",
      "[ 92 ] LKDS-00181 time: 0.660148\n",
      "[ 93 ] LKDS-00212 time: 1.189493\n",
      "[ 94 ] LKDS-00240 time: 1.149515\n",
      "[ 95 ] LKDS-00273 time: 0.774845\n",
      "[ 96 ] LKDS-00297 time: 0.705574\n",
      "[ 97 ] LKDS-00334 time: 1.226350\n",
      "[ 98 ] LKDS-00371 time: 1.040835\n",
      "[ 99 ] LKDS-00407 time: 1.020939\n",
      "[ 100 ] LKDS-00443 time: 0.904045\n",
      "[ 101 ] LKDS-00472 time: 1.931131\n",
      "[ 102 ] LKDS-00497 time: 1.598787\n",
      "[ 103 ] LKDS-00530 time: 17.055324\n",
      "[ 104 ] LKDS-00565 time: 1.117446\n",
      "[ 105 ] LKDS-00598 time: 1.700995\n",
      "[ 106 ] LKDS-00630 time: 1.373004\n",
      "[ 107 ] LKDS-00666 time: 0.950438\n",
      "[ 108 ] LKDS-00697 time: 0.729907\n",
      "[ 109 ] LKDS-00725 time: 1.367261\n",
      "[ 110 ] LKDS-00759 time: 1.062328\n",
      "[ 111 ] LKDS-00788 time: 0.881794\n",
      "[ 112 ] LKDS-00816 time: 1.470288\n",
      "[ 113 ] LKDS-00837 time: 1.441478\n",
      "[ 114 ] LKDS-00866 time: 1.324835\n",
      "[ 115 ] LKDS-00892 time: 1.531348\n",
      "[ 116 ] LKDS-00921 time: 1.495484\n",
      "[ 117 ] LKDS-00951 time: 0.871753\n",
      "[ 118 ] LKDS-00149 time: 0.865533\n",
      "[ 119 ] LKDS-00150 time: 0.863249\n",
      "[ 120 ] LKDS-00151 time: 0.712023\n",
      "[ 121 ] LKDS-00152 time: 0.779983\n",
      "[ 122 ] LKDS-00154 time: 0.947944\n",
      "[ 123 ] LKDS-00156 time: 0.819209\n",
      "[ 124 ] LKDS-00160 time: 2.522298\n",
      "[ 125 ] LKDS-00162 time: 17.554182\n",
      "[ 126 ] LKDS-00165 time: 0.683549\n",
      "[ 127 ] LKDS-00168 time: 1.382424\n",
      "[ 128 ] LKDS-00169 time: 3.699507\n",
      "[ 129 ] LKDS-00171 time: 1.358429\n",
      "[ 130 ] LKDS-00173 time: 0.942623\n",
      "[ 131 ] LKDS-00175 time: 0.749921\n",
      "[ 132 ] LKDS-00176 time: 0.478305\n",
      "[ 133 ] LKDS-00178 time: 1.224830\n",
      "[ 134 ] LKDS-00180 time: 1.184607\n",
      "[ 135 ] LKDS-00183 time: 0.954405\n",
      "[ 136 ] LKDS-00184 time: 0.761541\n",
      "[ 137 ] LKDS-00185 time: 1.079284\n",
      "[ 138 ] LKDS-00187 time: 1.241001\n",
      "[ 139 ] LKDS-00188 time: 0.803309\n",
      "[ 140 ] LKDS-00189 time: 1.253870\n",
      "[ 141 ] LKDS-00191 time: 1.123450\n",
      "[ 142 ] LKDS-00192 time: 1.001630\n",
      "[ 143 ] LKDS-00193 time: 2.038347\n",
      "[ 144 ] LKDS-00194 time: 0.865893\n",
      "[ 145 ] LKDS-00195 time: 1.249052\n",
      "[ 146 ] LKDS-00196 time: 0.990148\n",
      "[ 147 ] LKDS-00198 time: 1.025467\n",
      "[ 148 ] LKDS-00200 time: 1.115284\n",
      "[ 149 ] LKDS-00203 time: 0.766846\n",
      "[ 150 ] LKDS-00204 time: 1.142027\n",
      "[ 151 ] LKDS-00207 time: 0.951575\n",
      "[ 152 ] LKDS-00213 time: 0.814723\n",
      "[ 153 ] LKDS-00214 time: 0.709323\n",
      "[ 154 ] LKDS-00216 time: 0.952171\n",
      "[ 155 ] LKDS-00217 time: 0.982833\n",
      "[ 156 ] LKDS-00218 time: 0.898282\n",
      "[ 157 ] LKDS-00219 time: 0.876329\n",
      "[ 158 ] LKDS-00220 time: 1.303533\n",
      "[ 159 ] LKDS-00223 time: 1.892356\n",
      "[ 160 ] LKDS-00225 time: 1.586220\n",
      "[ 161 ] LKDS-00227 time: 0.939057\n",
      "[ 162 ] LKDS-00229 time: 17.068702\n",
      "[ 163 ] LKDS-00230 time: 0.749619\n",
      "[ 164 ] LKDS-00232 time: 2.375857\n",
      "[ 165 ] LKDS-00235 time: 1.381622\n",
      "[ 166 ] LKDS-00236 time: 0.715548\n",
      "[ 167 ] LKDS-00237 time: 0.970807\n",
      "[ 168 ] LKDS-00238 time: 1.315262\n",
      "[ 169 ] LKDS-00242 time: 1.089332\n",
      "[ 170 ] LKDS-00244 time: 1.021359\n",
      "[ 171 ] LKDS-00246 time: 0.683787\n",
      "[ 172 ] LKDS-00247 time: 0.860956\n",
      "[ 173 ] LKDS-00249 time: 1.410656\n",
      "[ 174 ] LKDS-00253 time: 0.813808\n",
      "[ 175 ] LKDS-00254 time: 1.620782\n",
      "[ 176 ] LKDS-00256 time: 1.375177\n",
      "[ 177 ] LKDS-00257 time: 1.141471\n",
      "[ 178 ] LKDS-00260 time: 1.135571\n",
      "[ 179 ] LKDS-00261 time: 0.696860\n",
      "[ 180 ] LKDS-00263 time: 0.654716\n",
      "[ 181 ] LKDS-00264 time: 0.775555\n",
      "[ 182 ] LKDS-00267 time: 0.908768\n",
      "[ 183 ] LKDS-00269 time: 0.643942\n",
      "[ 184 ] LKDS-00270 time: 0.718325\n",
      "[ 185 ] LKDS-00272 time: 0.591011\n",
      "[ 186 ] LKDS-00275 time: 1.324584\n",
      "[ 187 ] LKDS-00277 time: 0.799777\n",
      "[ 188 ] LKDS-00278 time: 1.274479\n",
      "[ 189 ] LKDS-00279 time: 1.244101\n",
      "[ 190 ] LKDS-00280 time: 1.425028\n",
      "[ 191 ] LKDS-00281 time: 16.426283\n",
      "[ 192 ] LKDS-00283 time: 1.905677\n",
      "[ 193 ] LKDS-00284 time: 0.918702\n",
      "[ 194 ] LKDS-00286 time: 0.974136\n",
      "[ 195 ] LKDS-00287 time: 4.869468\n",
      "[ 196 ] LKDS-00289 time: 2.029245\n",
      "[ 197 ] LKDS-00290 time: 2.527712\n",
      "[ 198 ] LKDS-00291 time: 0.755366\n",
      "[ 199 ] LKDS-00292 time: 1.155222\n",
      "[ 200 ] LKDS-00293 time: 2.541910\n",
      "[ 201 ] LKDS-00294 time: 1.102943\n",
      "[ 202 ] LKDS-00295 time: 0.742445\n",
      "[ 203 ] LKDS-00296 time: 1.236097\n",
      "[ 204 ] LKDS-00299 time: 1.422737\n",
      "[ 205 ] LKDS-00301 time: 1.341416\n",
      "[ 206 ] LKDS-00302 time: 0.675644\n",
      "[ 207 ] LKDS-00303 time: 1.029450\n",
      "[ 208 ] LKDS-00304 time: 1.226809\n",
      "[ 209 ] LKDS-00306 time: 1.392829\n",
      "[ 210 ] LKDS-00307 time: 16.105658\n",
      "[ 211 ] LKDS-00312 time: 1.691514\n",
      "[ 212 ] LKDS-00314 time: 1.007529\n",
      "[ 213 ] LKDS-00315 time: 0.848238\n",
      "[ 214 ] LKDS-00319 time: 0.865218\n",
      "[ 215 ] LKDS-00320 time: 0.537488\n",
      "[ 216 ] LKDS-00321 time: 1.584533\n",
      "[ 217 ] LKDS-00323 time: 0.773429\n",
      "[ 218 ] LKDS-00325 time: 0.807096\n",
      "[ 219 ] LKDS-00326 time: 1.101500\n",
      "[ 220 ] LKDS-00331 time: 0.711025\n",
      "[ 221 ] LKDS-00333 time: 0.718842\n",
      "[ 222 ] LKDS-00335 time: 1.070157\n",
      "[ 223 ] LKDS-00336 time: 1.046028\n",
      "[ 224 ] LKDS-00337 time: 2.384765\n",
      "[ 225 ] LKDS-00339 time: 1.271455\n",
      "[ 226 ] LKDS-00342 time: 1.491510\n",
      "[ 227 ] LKDS-00345 time: 1.064082\n",
      "[ 228 ] LKDS-00348 time: 2.481902\n",
      "[ 229 ] LKDS-00349 time: 1.129396\n",
      "[ 230 ] LKDS-00350 time: 1.516480\n",
      "[ 231 ] LKDS-00356 time: 15.560360\n",
      "[ 232 ] LKDS-00357 time: 1.234688\n",
      "[ 233 ] LKDS-00358 time: 1.534007\n",
      "[ 234 ] LKDS-00359 time: 0.990146\n",
      "[ 235 ] LKDS-00360 time: 1.226819\n",
      "[ 236 ] LKDS-00363 time: 1.399342\n",
      "[ 237 ] LKDS-00364 time: 0.983368\n",
      "[ 238 ] LKDS-00368 time: 0.907516\n",
      "[ 239 ] LKDS-00369 time: 1.152979\n",
      "[ 240 ] LKDS-00374 time: 0.848997\n",
      "[ 241 ] LKDS-00375 time: 1.107901\n",
      "[ 242 ] LKDS-00378 time: 0.955014\n",
      "[ 243 ] LKDS-00379 time: 0.979050\n",
      "[ 244 ] LKDS-00381 time: 0.828024\n",
      "[ 245 ] LKDS-00388 time: 0.787061\n",
      "[ 246 ] LKDS-00389 time: 0.945751\n",
      "[ 247 ] LKDS-00390 time: 0.967355\n",
      "[ 248 ] LKDS-00392 time: 1.134875\n",
      "[ 249 ] LKDS-00393 time: 0.999467\n",
      "[ 250 ] LKDS-00394 time: 0.964444\n",
      "[ 251 ] LKDS-00395 time: 1.065465\n",
      "[ 252 ] LKDS-00396 time: 0.660386\n",
      "[ 253 ] LKDS-00398 time: 14.641833\n",
      "[ 254 ] LKDS-00402 time: 0.981692\n",
      "[ 255 ] LKDS-00403 time: 0.730658\n",
      "[ 256 ] LKDS-00405 time: 1.526501\n",
      "[ 257 ] LKDS-00406 time: 1.385265\n",
      "[ 258 ] LKDS-00408 time: 1.497420\n",
      "[ 259 ] LKDS-00412 time: 1.463763\n",
      "[ 260 ] LKDS-00413 time: 1.459376\n",
      "[ 261 ] LKDS-00416 time: 0.816175\n",
      "[ 262 ] LKDS-00418 time: 0.815297\n",
      "[ 263 ] LKDS-00420 time: 1.046685\n",
      "[ 264 ] LKDS-00421 time: 0.984550\n",
      "[ 265 ] LKDS-00423 time: 1.046784\n",
      "[ 266 ] LKDS-00424 time: 0.583690\n",
      "[ 267 ] LKDS-00426 time: 0.855757\n",
      "[ 268 ] LKDS-00427 time: 1.243183\n",
      "[ 269 ] LKDS-00428 time: 0.796665\n",
      "[ 270 ] LKDS-00429 time: 1.226166\n",
      "[ 271 ] LKDS-00431 time: 1.072597\n",
      "[ 272 ] LKDS-00434 time: 2.918101\n",
      "[ 273 ] LKDS-00436 time: 1.072933\n",
      "[ 274 ] LKDS-00440 time: 1.569922\n",
      "[ 275 ] LKDS-00442 time: 1.182338\n",
      "[ 276 ] LKDS-00445 time: 0.713322\n",
      "[ 277 ] LKDS-00447 time: 0.787307\n",
      "[ 278 ] LKDS-00448 time: 1.107629\n",
      "[ 279 ] LKDS-00450 time: 2.070287\n",
      "[ 280 ] LKDS-00451 time: 1.361904\n",
      "[ 281 ] LKDS-00454 time: 1.180225\n",
      "[ 282 ] LKDS-00456 time: 1.736928\n",
      "[ 283 ] LKDS-00457 time: 16.205371\n",
      "[ 284 ] LKDS-00459 time: 1.757533\n",
      "[ 285 ] LKDS-00460 time: 1.145633\n",
      "[ 286 ] LKDS-00461 time: 1.298517\n",
      "[ 287 ] LKDS-00463 time: 0.937399\n",
      "[ 288 ] LKDS-00465 time: 0.654778\n",
      "[ 289 ] LKDS-00466 time: 0.802615\n",
      "[ 290 ] LKDS-00467 time: 0.747781\n",
      "[ 291 ] LKDS-00469 time: 0.823910\n",
      "[ 292 ] LKDS-00470 time: 0.711343\n",
      "[ 293 ] LKDS-00471 time: 0.934843\n",
      "[ 294 ] LKDS-00473 time: 1.361465\n",
      "[ 295 ] LKDS-00474 time: 0.907523\n",
      "[ 296 ] LKDS-00475 time: 0.890541\n",
      "[ 297 ] LKDS-00476 time: 1.797760\n",
      "[ 298 ] LKDS-00477 time: 0.735875\n",
      "[ 299 ] LKDS-00478 time: 1.037658\n",
      "[ 300 ] LKDS-00480 time: 1.438258\n",
      "[ 301 ] LKDS-00481 time: 0.970944\n",
      "[ 302 ] LKDS-00482 time: 1.337747\n",
      "[ 303 ] LKDS-00485 time: 1.164664\n",
      "[ 304 ] LKDS-00486 time: 1.163281\n",
      "[ 305 ] LKDS-00487 time: 1.992124\n",
      "[ 306 ] LKDS-00488 time: 15.629359\n",
      "[ 307 ] LKDS-00491 time: 0.728792\n",
      "[ 308 ] LKDS-00492 time: 0.929099\n",
      "[ 309 ] LKDS-00493 time: 1.054346\n",
      "[ 310 ] LKDS-00494 time: 0.685635\n",
      "[ 311 ] LKDS-00496 time: 0.823910\n",
      "[ 312 ] LKDS-00499 time: 0.665097\n",
      "[ 313 ] LKDS-00503 time: 0.788268\n",
      "[ 314 ] LKDS-00506 time: 1.144887\n",
      "[ 315 ] LKDS-00507 time: 0.715532\n",
      "[ 316 ] LKDS-00509 time: 2.241872\n",
      "[ 317 ] LKDS-00511 time: 0.955195\n",
      "[ 318 ] LKDS-00512 time: 1.683033\n",
      "[ 319 ] LKDS-00513 time: 0.989456\n",
      "[ 320 ] LKDS-00514 time: 1.137105\n",
      "[ 321 ] LKDS-00515 time: 1.199930\n",
      "[ 322 ] LKDS-00517 time: 1.072509\n",
      "[ 323 ] LKDS-00519 time: 1.397096\n",
      "[ 324 ] LKDS-00521 time: 0.729576\n",
      "[ 325 ] LKDS-00525 time: 0.757588\n",
      "[ 326 ] LKDS-00527 time: 1.195139\n",
      "[ 327 ] LKDS-00528 time: 0.955601\n",
      "[ 328 ] LKDS-00529 time: 0.907417\n",
      "[ 329 ] LKDS-00531 time: 1.282048\n",
      "[ 330 ] LKDS-00533 time: 2.003757\n",
      "[ 331 ] LKDS-00534 time: 15.544176\n",
      "[ 332 ] LKDS-00537 time: 1.051515\n",
      "[ 333 ] LKDS-00540 time: 1.041388\n",
      "[ 334 ] LKDS-00541 time: 3.311947\n",
      "[ 335 ] LKDS-00544 time: 0.938118\n",
      "[ 336 ] LKDS-00545 time: 2.560990\n",
      "[ 337 ] LKDS-00546 time: 1.341553\n",
      "[ 338 ] LKDS-00549 time: 1.081984\n",
      "[ 339 ] LKDS-00550 time: 0.878812\n",
      "[ 340 ] LKDS-00553 time: 1.757456\n",
      "[ 341 ] LKDS-00555 time: 1.025788\n",
      "[ 342 ] LKDS-00556 time: 1.317095\n",
      "[ 343 ] LKDS-00558 time: 1.192282\n",
      "[ 344 ] LKDS-00562 time: 1.755843\n",
      "[ 345 ] LKDS-00563 time: 1.230055\n",
      "[ 346 ] LKDS-00566 time: 1.060782\n",
      "[ 347 ] LKDS-00567 time: 0.978773\n",
      "[ 348 ] LKDS-00571 time: 1.448272\n",
      "[ 349 ] LKDS-00572 time: 0.823345\n",
      "[ 350 ] LKDS-00573 time: 1.119049\n",
      "[ 351 ] LKDS-00574 time: 1.289721\n",
      "[ 352 ] LKDS-00575 time: 1.349719\n",
      "[ 353 ] LKDS-00578 time: 1.348412\n",
      "[ 354 ] LKDS-00579 time: 16.476730\n",
      "[ 355 ] LKDS-00582 time: 0.658280\n",
      "[ 356 ] LKDS-00585 time: 1.042081\n",
      "[ 357 ] LKDS-00586 time: 0.946153\n",
      "[ 358 ] LKDS-00587 time: 1.540784\n",
      "[ 359 ] LKDS-00589 time: 1.036930\n",
      "[ 360 ] LKDS-00592 time: 0.810504\n",
      "[ 361 ] LKDS-00593 time: 0.753981\n",
      "[ 362 ] LKDS-00595 time: 0.847533\n",
      "[ 363 ] LKDS-00596 time: 1.214302\n",
      "[ 364 ] LKDS-00600 time: 1.322299\n",
      "[ 365 ] LKDS-00601 time: 1.604929\n",
      "[ 366 ] LKDS-00603 time: 1.023657\n",
      "[ 367 ] LKDS-00605 time: 0.854342\n",
      "[ 368 ] LKDS-00608 time: 1.812015\n",
      "[ 369 ] LKDS-00609 time: 0.887927\n",
      "[ 370 ] LKDS-00611 time: 0.920003\n",
      "[ 371 ] LKDS-00612 time: 0.885463\n",
      "[ 372 ] LKDS-00614 time: 1.124093\n",
      "[ 373 ] LKDS-00615 time: 1.202621\n",
      "[ 374 ] LKDS-00619 time: 0.785970\n",
      "[ 375 ] LKDS-00620 time: 1.269926\n",
      "[ 376 ] LKDS-00622 time: 0.746713\n",
      "[ 377 ] LKDS-00623 time: 1.245993\n",
      "[ 378 ] LKDS-00624 time: 16.244891\n",
      "[ 379 ] LKDS-00625 time: 1.103830\n",
      "[ 380 ] LKDS-00628 time: 1.316929\n",
      "[ 381 ] LKDS-00629 time: 0.665699\n",
      "[ 382 ] LKDS-00632 time: 1.344287\n",
      "[ 383 ] LKDS-00634 time: 1.560330\n",
      "[ 384 ] LKDS-00638 time: 0.922538\n",
      "[ 385 ] LKDS-00639 time: 0.973671\n",
      "[ 386 ] LKDS-00640 time: 1.060554\n",
      "[ 387 ] LKDS-00641 time: 0.788801\n",
      "[ 388 ] LKDS-00643 time: 1.498483\n",
      "[ 389 ] LKDS-00646 time: 0.596212\n",
      "[ 390 ] LKDS-00647 time: 0.885310\n",
      "[ 391 ] LKDS-00648 time: 1.577583\n",
      "[ 392 ] LKDS-00649 time: 1.453805\n",
      "[ 393 ] LKDS-00650 time: 1.188290\n",
      "[ 394 ] LKDS-00651 time: 1.781907\n",
      "[ 395 ] LKDS-00653 time: 0.802652\n",
      "[ 396 ] LKDS-00658 time: 0.718236\n",
      "[ 397 ] LKDS-00660 time: 1.003256\n",
      "[ 398 ] LKDS-00661 time: 0.821318\n",
      "[ 399 ] LKDS-00663 time: 1.050321\n",
      "[ 400 ] LKDS-00667 time: 1.045848\n",
      "[ 401 ] LKDS-00668 time: 1.115878\n",
      "[ 402 ] LKDS-00670 time: 16.515176\n",
      "[ 403 ] LKDS-00671 time: 1.078859\n",
      "[ 404 ] LKDS-00673 time: 0.820779\n",
      "[ 405 ] LKDS-00674 time: 1.318048\n",
      "[ 406 ] LKDS-00675 time: 1.084395\n",
      "[ 407 ] LKDS-00676 time: 1.124914\n",
      "[ 408 ] LKDS-00677 time: 1.416146\n",
      "[ 409 ] LKDS-00678 time: 1.953383\n",
      "[ 410 ] LKDS-00681 time: 1.090170\n",
      "[ 411 ] LKDS-00682 time: 0.734719\n",
      "[ 412 ] LKDS-00683 time: 1.468872\n",
      "[ 413 ] LKDS-00684 time: 0.892711\n",
      "[ 414 ] LKDS-00691 time: 0.906845\n",
      "[ 415 ] LKDS-00692 time: 2.489549\n",
      "[ 416 ] LKDS-00694 time: 1.893430\n",
      "[ 417 ] LKDS-00696 time: 1.207952\n",
      "[ 418 ] LKDS-00698 time: 1.231600\n",
      "[ 419 ] LKDS-00699 time: 2.273467\n",
      "[ 420 ] LKDS-00700 time: 16.673084\n",
      "[ 421 ] LKDS-00701 time: 0.725545\n",
      "[ 422 ] LKDS-00702 time: 1.067557\n",
      "[ 423 ] LKDS-00703 time: 1.324575\n",
      "[ 424 ] LKDS-00706 time: 0.770907\n",
      "[ 425 ] LKDS-00707 time: 1.021313\n",
      "[ 426 ] LKDS-00708 time: 0.763052\n",
      "[ 427 ] LKDS-00709 time: 1.192492\n",
      "[ 428 ] LKDS-00710 time: 0.913670\n",
      "[ 429 ] LKDS-00711 time: 1.032176\n",
      "[ 430 ] LKDS-00714 time: 1.647406\n",
      "[ 431 ] LKDS-00716 time: 0.681601\n",
      "[ 432 ] LKDS-00717 time: 1.101298\n",
      "[ 433 ] LKDS-00718 time: 1.055519\n",
      "[ 434 ] LKDS-00722 time: 1.093955\n",
      "[ 435 ] LKDS-00723 time: 1.070566\n",
      "[ 436 ] LKDS-00727 time: 1.646876\n",
      "[ 437 ] LKDS-00728 time: 1.068762\n",
      "[ 438 ] LKDS-00730 time: 4.886172\n",
      "[ 439 ] LKDS-00731 time: 1.875292\n",
      "[ 440 ] LKDS-00732 time: 1.977258\n",
      "[ 441 ] LKDS-00733 time: 16.694467\n",
      "[ 442 ] LKDS-00734 time: 0.901628\n",
      "[ 443 ] LKDS-00739 time: 0.961797\n",
      "[ 444 ] LKDS-00740 time: 4.012036\n",
      "[ 445 ] LKDS-00742 time: 0.627396\n",
      "[ 446 ] LKDS-00744 time: 1.178587\n",
      "[ 447 ] LKDS-00745 time: 1.894327\n",
      "[ 448 ] LKDS-00746 time: 1.296618\n",
      "[ 449 ] LKDS-00750 time: 0.775615\n",
      "[ 450 ] LKDS-00752 time: 0.811951\n",
      "[ 451 ] LKDS-00755 time: 0.991610\n",
      "[ 452 ] LKDS-00756 time: 1.383457\n",
      "[ 453 ] LKDS-00757 time: 0.905118\n",
      "[ 454 ] LKDS-00760 time: 0.828613\n",
      "[ 455 ] LKDS-00762 time: 1.401514\n",
      "[ 456 ] LKDS-00763 time: 0.626344\n",
      "[ 457 ] LKDS-00764 time: 0.903143\n",
      "[ 458 ] LKDS-00767 time: 1.009116\n",
      "[ 459 ] LKDS-00768 time: 1.013463\n",
      "[ 460 ] LKDS-00771 time: 0.880059\n",
      "[ 461 ] LKDS-00772 time: 2.649808\n",
      "[ 462 ] LKDS-00773 time: 1.330252\n",
      "[ 463 ] LKDS-00775 time: 1.470856\n",
      "[ 464 ] LKDS-00776 time: 2.543447\n",
      "[ 465 ] LKDS-00777 time: 16.288526\n",
      "[ 466 ] LKDS-00778 time: 0.966122\n",
      "[ 467 ] LKDS-00780 time: 0.924731\n",
      "[ 468 ] LKDS-00781 time: 1.137548\n",
      "[ 469 ] LKDS-00782 time: 0.668470\n",
      "[ 470 ] LKDS-00783 time: 0.357476\n",
      "[ 471 ] LKDS-00784 time: 0.872703\n",
      "[ 472 ] LKDS-00789 time: 0.698925\n",
      "[ 473 ] LKDS-00790 time: 0.835069\n",
      "[ 474 ] LKDS-00795 time: 0.809014\n",
      "[ 475 ] LKDS-00796 time: 1.477901\n",
      "[ 476 ] LKDS-00797 time: 1.443775\n",
      "[ 477 ] LKDS-00798 time: 1.151075\n",
      "[ 478 ] LKDS-00801 time: 0.743536\n",
      "[ 479 ] LKDS-00803 time: 0.785276\n",
      "[ 480 ] LKDS-00804 time: 1.138879\n",
      "[ 481 ] LKDS-00805 time: 0.951980\n",
      "[ 482 ] LKDS-00807 time: 1.629379\n",
      "[ 483 ] LKDS-00808 time: 1.143184\n",
      "[ 484 ] LKDS-00809 time: 0.843969\n",
      "[ 485 ] LKDS-00811 time: 0.868935\n",
      "[ 486 ] LKDS-00813 time: 0.855090\n",
      "[ 487 ] LKDS-00814 time: 0.812694\n",
      "[ 488 ] LKDS-00815 time: 0.770430\n",
      "[ 489 ] LKDS-00817 time: 1.009048\n",
      "[ 490 ] LKDS-00819 time: 1.681773\n",
      "[ 491 ] LKDS-00820 time: 1.688321\n",
      "[ 492 ] LKDS-00821 time: 0.718902\n",
      "[ 493 ] LKDS-00823 time: 1.146756\n",
      "[ 494 ] LKDS-00824 time: 1.766558\n",
      "[ 495 ] LKDS-00825 time: 15.693239\n",
      "[ 496 ] LKDS-00826 time: 1.232881\n",
      "[ 497 ] LKDS-00827 time: 1.166651\n",
      "[ 498 ] LKDS-00829 time: 0.768770\n",
      "[ 499 ] LKDS-00830 time: 0.997115\n",
      "[ 500 ] LKDS-00831 time: 0.927458\n",
      "[ 501 ] LKDS-00832 time: 0.787463\n",
      "[ 502 ] LKDS-00833 time: 1.047500\n",
      "[ 503 ] LKDS-00834 time: 1.276307\n",
      "[ 504 ] LKDS-00835 time: 1.716031\n",
      "[ 505 ] LKDS-00836 time: 0.922162\n",
      "[ 506 ] LKDS-00838 time: 1.053748\n",
      "[ 507 ] LKDS-00839 time: 1.512420\n",
      "[ 508 ] LKDS-00841 time: 1.043933\n",
      "[ 509 ] LKDS-00843 time: 0.758115\n",
      "[ 510 ] LKDS-00844 time: 0.936646\n",
      "[ 511 ] LKDS-00845 time: 1.384255\n",
      "[ 512 ] LKDS-00846 time: 1.665399\n",
      "[ 513 ] LKDS-00847 time: 1.452533\n",
      "[ 514 ] LKDS-00848 time: 0.812571\n",
      "[ 515 ] LKDS-00852 time: 1.763570\n",
      "[ 516 ] LKDS-00855 time: 3.832355\n",
      "[ 517 ] LKDS-00856 time: 3.134748\n",
      "[ 518 ] LKDS-00857 time: 16.715674\n",
      "[ 519 ] LKDS-00859 time: 1.596743\n",
      "[ 520 ] LKDS-00862 time: 2.173776\n",
      "[ 521 ] LKDS-00863 time: 1.435267\n",
      "[ 522 ] LKDS-00865 time: 1.669703\n",
      "[ 523 ] LKDS-00867 time: 0.862695\n",
      "[ 524 ] LKDS-00868 time: 0.993324\n",
      "[ 525 ] LKDS-00870 time: 1.074653\n",
      "[ 526 ] LKDS-00873 time: 0.896258\n",
      "[ 527 ] LKDS-00875 time: 0.620638\n",
      "[ 528 ] LKDS-00876 time: 0.541039\n",
      "[ 529 ] LKDS-00878 time: 1.564861\n",
      "[ 530 ] LKDS-00879 time: 1.675154\n",
      "[ 531 ] LKDS-00880 time: 1.212250\n",
      "[ 532 ] LKDS-00882 time: 0.844074\n",
      "[ 533 ] LKDS-00884 time: 1.003461\n",
      "[ 534 ] LKDS-00885 time: 1.547511\n",
      "[ 535 ] LKDS-00886 time: 1.053545\n",
      "[ 536 ] LKDS-00887 time: 1.937483\n",
      "[ 537 ] LKDS-00888 time: 0.997848\n",
      "[ 538 ] LKDS-00890 time: 15.089961\n",
      "[ 539 ] LKDS-00891 time: 0.878427\n",
      "[ 540 ] LKDS-00893 time: 1.745254\n",
      "[ 541 ] LKDS-00894 time: 0.408924\n",
      "[ 542 ] LKDS-00896 time: 0.841626\n",
      "[ 543 ] LKDS-00897 time: 0.688597\n",
      "[ 544 ] LKDS-00898 time: 0.913495\n",
      "[ 545 ] LKDS-00899 time: 0.770525\n",
      "[ 546 ] LKDS-00900 time: 1.352693\n",
      "[ 547 ] LKDS-00901 time: 1.428934\n",
      "[ 548 ] LKDS-00904 time: 1.159960\n",
      "[ 549 ] LKDS-00906 time: 0.756578\n",
      "[ 550 ] LKDS-00911 time: 1.095648\n",
      "[ 551 ] LKDS-00912 time: 2.037621\n",
      "[ 552 ] LKDS-00914 time: 1.273104\n",
      "[ 553 ] LKDS-00915 time: 1.577744\n",
      "[ 554 ] LKDS-00917 time: 1.339188\n",
      "[ 555 ] LKDS-00918 time: 1.234778\n",
      "[ 556 ] LKDS-00919 time: 15.242035\n",
      "[ 557 ] LKDS-00923 time: 1.081570\n",
      "[ 558 ] LKDS-00924 time: 0.885289\n",
      "[ 559 ] LKDS-00930 time: 0.753854\n",
      "[ 560 ] LKDS-00931 time: 1.763049\n",
      "[ 561 ] LKDS-00933 time: 1.043926\n",
      "[ 562 ] LKDS-00935 time: 0.453815\n",
      "[ 563 ] LKDS-00936 time: 0.832094\n",
      "[ 564 ] LKDS-00937 time: 1.214369\n",
      "[ 565 ] LKDS-00939 time: 0.627124\n",
      "[ 566 ] LKDS-00941 time: 0.900137\n",
      "[ 567 ] LKDS-00942 time: 1.042265\n",
      "[ 568 ] LKDS-00944 time: 0.845697\n",
      "[ 569 ] LKDS-00945 time: 0.936453\n",
      "[ 570 ] LKDS-00946 time: 0.934875\n",
      "[ 571 ] LKDS-00948 time: 1.667054\n",
      "[ 572 ] LKDS-00949 time: 1.058384\n",
      "[ 573 ] LKDS-00950 time: 0.979925\n",
      "[ 574 ] LKDS-00953 time: 0.910300\n",
      "[ 575 ] LKDS-00954 time: 1.333066\n",
      "[ 576 ] LKDS-00956 time: 1.020444\n",
      "[ 577 ] LKDS-00957 time: 1.033439\n",
      "[ 578 ] LKDS-00961 time: 0.891594\n",
      "[ 579 ] LKDS-00962 time: 0.699406\n",
      "[ 580 ] LKDS-00964 time: 2.443749\n",
      "[ 581 ] LKDS-00968 time: 17.059694\n",
      "[ 582 ] LKDS-00969 time: 1.096461\n",
      "[ 583 ] LKDS-00970 time: 0.735249\n",
      "[ 584 ] LKDS-00973 time: 1.362941\n",
      "[ 585 ] LKDS-00976 time: 3.724190\n",
      "[ 586 ] LKDS-00979 time: 0.756808\n",
      "[ 587 ] LKDS-00981 time: 0.912623\n",
      "[ 588 ] LKDS-00982 time: 0.896261\n",
      "[ 589 ] LKDS-00983 time: 0.850212\n",
      "[ 590 ] LKDS-00984 time: 0.814289\n",
      "[ 591 ] LKDS-00985 time: 0.784085\n",
      "[ 592 ] LKDS-00989 time: 0.712294\n",
      "[ 593 ] LKDS-00990 time: 1.040970\n",
      "[ 594 ] LKDS-00991 time: 1.828821\n",
      "[ 595 ] LKDS-00994 time: 0.719437\n",
      "[ 596 ] LKDS-00995 time: 1.174367\n",
      "[ 597 ] LKDS-00996 time: 1.590569\n",
      "[ 598 ] LKDS-00997 time: 0.896933\n",
      "[ 599 ] LKDS-00998 time: 0.627946\n",
      "[ 600 ] LKDS-01000 time: 1.051437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#从原始数据集中切割模型训练所用的数据\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def seq(start, stop, step=1):\n",
    "#     n = int(round((stop - start)/float(step)))\n",
    "#     if n > 1:\n",
    "#         return([start + step*i for i in range(n+1)])\n",
    "#     else:\n",
    "#         return []\n",
    "    return np.arange(int(start/step)-2,int(stop/step)+2)\n",
    "\n",
    "    \n",
    "df = pd.read_csv('../csv/train/annotations.csv')\n",
    "traindata_files = glob.glob('../nodule_cubes/train_data/npy/*.npy')\n",
    "f = open('../nodule_cubes/train_data/pkl/origion.pkl','rb')\n",
    "origins = pickle.load(f)\n",
    "f.close()\n",
    "f = open('../nodule_cubes/train_data/pkl/old_spacing.pkl','rb')\n",
    "old_spacings = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('../nodule_cubes/train_data/pkl/new_spacing.pkl','rb')\n",
    "new_spacings = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# trans = [[0,0,0],[-8,0,0],[0,-8,0],[0,0,-8],[8,0,0],[0,8,0],[0,0,8]]\n",
    "ind = 0\n",
    "for traindata_file in traindata_files[:]:\n",
    "    ind += 1\n",
    "    t1 = time.time()\n",
    "    ct_id = os.path.basename(traindata_file)[:-4]\n",
    "    train_data = np.load(traindata_file)\n",
    "    image_mask = np.zeros_like(train_data)\n",
    "    mask3d = train_data > -700\n",
    "    label_weight = np.zeros((train_data.shape[0],train_data.shape[1],train_data.shape[2],2))\n",
    "    label_weight[:,:,:,0] = 1\n",
    "    origin = origins[ct_id]\n",
    "    spacing = new_spacings[ct_id]\n",
    "    \n",
    "    patient = df[df['seriesuid']==ct_id]\n",
    "    if patient.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    for i in range(patient.shape[0]):\n",
    "        data = np.zeros((64,64,64))\n",
    "        label = np.zeros((32,32,32,2))\n",
    "        \n",
    "        col = patient.iloc[i]\n",
    "        radius = np.ceil(col['diameter_mm']/spacing.min())/2\n",
    "        coordZ = col['coordZ']\n",
    "        coordY = col['coordY']\n",
    "        coordX = col['coordX']\n",
    "        cz,cy,cx = world_2_voxel(np.array([coordZ,coordY,coordX]),origin,spacing)\n",
    "#         try:\n",
    "#             data[:,:,:] = train_data[int(cz)-32:int(cz)+32,int(cy)-32:int(cy)+32,int(cx)-32:int(cx)+32]\n",
    "#         except ValueError as e:\n",
    "#             print(\"=========  ValueError :\",cz,cy,cx)\n",
    "#             continue\n",
    "        label_weight[int(cz),int(cy),int(cx),1] = 4.0\n",
    "        noduleRange = seq(-radius, radius, spacing[0])\n",
    "        for tx in noduleRange:\n",
    "            for ty in noduleRange:\n",
    "                for tz in noduleRange:\n",
    "                    tmp_coords = np.array([int(cz)+tz,int(cy)+ty,int(cx)+tx])\n",
    "                    dist = np.linalg.norm(np.array([int(cz),int(cy),int(cx)])-tmp_coords)\n",
    "                    if (dist < radius+1) and (mask3d[np.int0(tmp_coords[0]),np.int0(tmp_coords[1]),np.int0(tmp_coords[2])] ==1):\n",
    "#                         image_mask[np.int0(tmp_coords[0]),np.int0(tmp_coords[1]),np.int0(tmp_coords[2])] = int(1)\n",
    "#                         if mask3d[np.int0(tmp_coords[0]),np.int0(tmp_coords[1]),np.int0(tmp_coords[2])] ==1:\n",
    "#                         weight = 4.0 - np.log2((dist+1)**2)\n",
    "                        weight = 4.0 - np.log((dist+1))\n",
    "                        label_weight[np.int0(tmp_coords[0]),np.int0(tmp_coords[1]),np.int0(tmp_coords[2]),1] = weight\n",
    "                        label_weight[np.int0(tmp_coords[0]),np.int0(tmp_coords[1]),np.int0(tmp_coords[2]),0] = 0\n",
    "#         label = np.zeros((64,64,64,2))\n",
    "#         label[:,:,:,1] = image_mask[int(cz)-32:int(cz)+32,int(cy)-32:int(cy)+32,int(cx)-32:int(cx)+32]\n",
    "#         label[:,:,:,0] = 1 - image_mask[int(cz)-32:int(cz)+32,int(cy)-32:int(cy)+32,int(cx)-32:int(cx)+32]\n",
    "#         np.save('../unet_3d_valdata/'+ct_id+\"_data_\"+str(i)+\".npy\",data)\n",
    "#         np.save('../unet_3d_valdata/'+ct_id+'_label_'+str(i)+\".npy\",label)\n",
    "#         label = np.zeros((64,64,64,2))\n",
    "#         label[:,:,:,:] = label_weight[int(cz)-32:int(cz)+32,int(cy)-32:int(cy)+32,int(cx)-32:int(cx)+32,:]\n",
    "#         np.save('../unet_3d_valdata/'+ct_id+'_label_weighted'+str(i)+\".npy\",label)\n",
    "        \n",
    "        # 数据增广，包括固定平移以及随机平移\n",
    "        trans = [[0,0,0],[-8,0,0],[0,-8,0],[0,0,-8],[8,0,0],[0,8,0],[0,0,8]]\n",
    "        for _ in range(10):\n",
    "            trans.append([np.random.randint(-10,10),np.random.randint(-10,10),np.random.randint(-10,10)])\n",
    "    \n",
    "        for trans_z,trans_y,trans_x in trans:\n",
    "            try:\n",
    "                data[:,:,:] = train_data[int(cz)+trans_z-32:int(cz)+trans_z+32,int(cy)+trans_y-32:int(cy)+trans_y+32,int(cx)+trans_x-32:int(cx)+trans_x+32]\n",
    "                label[:,:,:,:] = label_weight[int(cz)+trans_z-16:int(cz)+trans_z+16,int(cy)+trans_y-16:int(cy)+trans_y+16,int(cx)+trans_x-16:int(cx)+trans_x+16,:]\n",
    "                if np.sum(label) < 15:\n",
    "                    continue\n",
    "                np.save('../unet_3d_traindata/'+ct_id+\"_data_\"+str(i)+\"_\"+str(trans_z)+\"_\"+str(trans_y)+\"_\"+str(trans_x)+\".npy\",data)\n",
    "                np.save('../unet_3d_traindata/'+ct_id+\"_label_\"+str(i)+\"_\"+str(trans_z)+\"_\"+str(trans_y)+\"_\"+str(trans_x)+\".npy\",label)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"[ %d ] %s time: %f\" % (ind,ct_id,(t2-t1)))\n",
    "                                           \n",
    "        \n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : [3, 3, 3, 1, 48] 0.068041381744\n",
      "shape : [3, 3, 3, 48, 48] 0.068041381744\n",
      "shape : [3, 3, 3, 48, 48] 0.068041381744\n",
      "shape : [3, 3, 3, 48, 48] 0.068041381744\n",
      "shape : [3, 3, 3, 48, 48] 0.068041381744\n",
      "shape : [3, 3, 3, 48, 48] 0.068041381744\n",
      "shape : [3, 3, 3, 48, 48] 0.068041381744\n",
      "shape : [2, 2, 2, 48, 48] 0.102062072616\n",
      "shape : [3, 3, 3, 96, 96] 0.0481125224325\n",
      "shape : [3, 3, 3, 96, 96] 0.0481125224325\n",
      "shape : [3, 3, 3, 96, 96] 0.0481125224325\n",
      "shape : [3, 3, 3, 96, 96] 0.0481125224325\n",
      "shape : [3, 3, 3, 96, 2] 0.0481125224325\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(y_,output_map):\n",
    "    return -tf.reduce_mean(y_*tf.log(tf.clip_by_value(output_map,1e-10,1.0)), name=\"cross_entropy\")\n",
    "#     return tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=output_map)\n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    sum_exp = tf.reduce_sum(exponential_map, 4, keep_dims=True)\n",
    "    tensor_sum_exp = tf.tile(sum_exp, tf.stack([1, 1, 1,1, tf.shape(output_map)[4]]))\n",
    "    return tf.div(exponential_map,tensor_sum_exp)\n",
    "\n",
    "def crop_to_shape(data, shape):\n",
    "    offset0 = (data.shape[1] - shape[0])//2\n",
    "    offset1 = (data.shape[2] - shape[1])//2\n",
    "    offset2 = (data.shape[3] - shape[2])//2\n",
    "    return data[:,offset0:(-offset0), offset1:(-offset1),offset2:(-offset2),:]\n",
    "\n",
    "input_x = tf.placeholder(\"float32\",[None,None,None,None])\n",
    "input_y = tf.placeholder(\"float32\",[None,None,None,None,2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "nx = tf.shape(input_y)[1]\n",
    "ny = tf.shape(input_y)[2]\n",
    "nz = tf.shape(input_y)[3]\n",
    "unet_label = tf.reshape(input_y, tf.stack([-1,nx,ny,nz,2]))\n",
    "\n",
    "logits,weights,biases,output_pixels = create_3d_unet(input_x,keep_prob,1,2)\n",
    "logits_shape = tf.shape(logits)\n",
    "\n",
    "predictor = pixel_wise_softmax(logits)\n",
    "cost = tf.reduce_mean(cross_entropy(tf.reshape(unet_label, [-1, 2]),tf.reshape(predictor,[-1,2])))\n",
    "gradients_node = tf.gradients(cost, weights)\n",
    "correct_pred = tf.equal(tf.argmax(predictor, 4), tf.argmax(unet_label, 4))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "# global_step = tf.Variable(0)\n",
    "# learning_rate_node = tf.train.exponential_decay(learning_rate=0.1, \n",
    "#                                                         global_step=global_step, \n",
    "#                                                         decay_steps=100,  \n",
    "#                                                         decay_rate=0.90, \n",
    "#                                                         staircase=True)\n",
    "# optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate_node,momentum=0.99).minimize(cost,global_step=global_step)\n",
    "    \n",
    "    \n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0)\n",
    "learning_rate_node = tf.train.exponential_decay(learning_rate=0.01, \n",
    "                                                        global_step=global_step, \n",
    "                                                        decay_steps=100,  \n",
    "                                                        decay_rate=0.95, \n",
    "                                                        staircase=True)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate_node,momentum=0.9,use_nesterov=True).minimize(cost,global_step=global_step)\n",
    "\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001,decay=0.9,momentum=0.66).minimize(cost,global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./unet3d_models_7/ecpho_8/unet3d_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.597832 ,val acc : 0.650787\n",
      "0.597832 0.650787\n",
      "[ ecpho : 0  iter :1 ]train loss : 0.605351 ,train acc: 0.646454 ,val loss : 0.596176 ,val acc : 0.654388\n",
      "[ ecpho : 0  iter :2 ]train loss : 0.658462 ,train acc: 0.621246 ,val loss : 0.599714 ,val acc : 0.651825\n",
      "[ ecpho : 0  iter :3 ]train loss : 0.593126 ,train acc: 0.651398 ,val loss : 0.593506 ,val acc : 0.653351\n",
      "[ ecpho : 0  iter :4 ]train loss : 0.631005 ,train acc: 0.644623 ,val loss : 0.589591 ,val acc : 0.655548\n",
      "[ ecpho : 0  iter :5 ]train loss : 0.583740 ,train acc: 0.652069 ,val loss : 0.582530 ,val acc : 0.656555\n",
      "[ ecpho : 0  iter :6 ]train loss : 0.579801 ,train acc: 0.650238 ,val loss : 0.579180 ,val acc : 0.656494\n",
      "[ ecpho : 0  iter :7 ]train loss : 0.601668 ,train acc: 0.650909 ,val loss : 0.573023 ,val acc : 0.661194\n",
      "[ ecpho : 0  iter :8 ]train loss : 0.628190 ,train acc: 0.615784 ,val loss : 0.564185 ,val acc : 0.664673\n",
      "[ ecpho : 0  iter :9 ]train loss : 0.626660 ,train acc: 0.637177 ,val loss : 0.567205 ,val acc : 0.659729\n",
      "[ ecpho : 0  iter :10 ]train loss : 0.600820 ,train acc: 0.647827 ,val loss : 0.564396 ,val acc : 0.657532\n",
      "[ ecpho : 0  iter :11 ]train loss : 0.546740 ,train acc: 0.666962 ,val loss : 0.557260 ,val acc : 0.662903\n",
      "[ ecpho : 0  iter :12 ]train loss : 0.549824 ,train acc: 0.667206 ,val loss : 0.539531 ,val acc : 0.669037\n",
      "[ ecpho : 0  iter :13 ]train loss : 0.560709 ,train acc: 0.665039 ,val loss : 0.542548 ,val acc : 0.786804\n",
      "[ ecpho : 0  iter :14 ]train loss : 0.538696 ,train acc: 0.792877 ,val loss : 0.543370 ,val acc : 0.787964\n",
      "[ ecpho : 0  iter :15 ]train loss : 0.547798 ,train acc: 0.786621 ,val loss : 0.533070 ,val acc : 0.789429\n",
      "[ ecpho : 0  iter :16 ]train loss : 0.527466 ,train acc: 0.792297 ,val loss : 0.534654 ,val acc : 0.787445\n",
      "[ ecpho : 0  iter :17 ]train loss : 0.520638 ,train acc: 0.792999 ,val loss : 0.516791 ,val acc : 0.794312\n",
      "[ ecpho : 0  iter :18 ]train loss : 0.740197 ,train acc: 0.506165 ,val loss : 0.516061 ,val acc : 0.793060\n",
      "[ ecpho : 0  iter :19 ]train loss : 0.536680 ,train acc: 0.786407 ,val loss : 0.508521 ,val acc : 0.795319\n",
      "[ ecpho : 0  iter :20 ]train loss : 0.513247 ,train acc: 0.795624 ,val loss : 0.515049 ,val acc : 0.792755\n",
      "[ ecpho : 0  iter :21 ]train loss : 0.513858 ,train acc: 0.793579 ,val loss : 0.506693 ,val acc : 0.794464\n",
      "[ ecpho : 0  iter :22 ]train loss : 0.515963 ,train acc: 0.790649 ,val loss : 0.498481 ,val acc : 0.796570\n",
      "[ ecpho : 0  iter :23 ]train loss : 0.482122 ,train acc: 0.803589 ,val loss : 0.495785 ,val acc : 0.796906\n",
      "[ ecpho : 0  iter :24 ]train loss : 0.498809 ,train acc: 0.795593 ,val loss : 0.490671 ,val acc : 0.797791\n",
      "[ ecpho : 0  iter :25 ]train loss : 0.506378 ,train acc: 0.791290 ,val loss : 0.490203 ,val acc : 0.798279\n",
      "[ ecpho : 0  iter :26 ]train loss : 0.629169 ,train acc: 0.666748 ,val loss : 0.487621 ,val acc : 0.799561\n",
      "[ ecpho : 0  iter :27 ]train loss : 0.593340 ,train acc: 0.683258 ,val loss : 0.478578 ,val acc : 0.799927\n",
      "[ ecpho : 0  iter :28 ]train loss : 0.468670 ,train acc: 0.805847 ,val loss : 0.467126 ,val acc : 0.802155\n",
      "[ ecpho : 0  iter :29 ]train loss : 0.480269 ,train acc: 0.795898 ,val loss : 0.467599 ,val acc : 0.801758\n",
      "[ ecpho : 0  iter :30 ]train loss : 0.457706 ,train acc: 0.809570 ,val loss : 0.469202 ,val acc : 0.803650\n",
      "[ ecpho : 0  iter :31 ]train loss : 0.460752 ,train acc: 0.811340 ,val loss : 0.457365 ,val acc : 0.808777\n",
      "[ ecpho : 0  iter :32 ]train loss : 0.451468 ,train acc: 0.807404 ,val loss : 0.456381 ,val acc : 0.805786\n",
      "[ ecpho : 0  iter :33 ]train loss : 0.446890 ,train acc: 0.810699 ,val loss : 0.448916 ,val acc : 0.811218\n",
      "[ ecpho : 0  iter :34 ]train loss : 0.441081 ,train acc: 0.816498 ,val loss : 0.445346 ,val acc : 0.807770\n",
      "[ ecpho : 0  iter :35 ]train loss : 0.434524 ,train acc: 0.812439 ,val loss : 0.435201 ,val acc : 0.813446\n",
      "[ ecpho : 0  iter :36 ]train loss : 0.452109 ,train acc: 0.802490 ,val loss : 0.432296 ,val acc : 0.814056\n",
      "[ ecpho : 0  iter :37 ]train loss : 0.435935 ,train acc: 0.813538 ,val loss : 0.427671 ,val acc : 0.815430\n",
      "[ ecpho : 0  iter :38 ]train loss : 0.422806 ,train acc: 0.808258 ,val loss : 0.430077 ,val acc : 0.814148\n",
      "[ ecpho : 0  iter :39 ]train loss : 0.492831 ,train acc: 0.738312 ,val loss : 0.423662 ,val acc : 0.817352\n",
      "[ ecpho : 0  iter :40 ]train loss : 0.468164 ,train acc: 0.785248 ,val loss : 0.417103 ,val acc : 0.818237\n",
      "[ ecpho : 0  iter :41 ]train loss : 0.408109 ,train acc: 0.821533 ,val loss : 0.417349 ,val acc : 0.817841\n",
      "[ ecpho : 0  iter :42 ]train loss : 0.405245 ,train acc: 0.819916 ,val loss : 0.405769 ,val acc : 0.820496\n",
      "[ ecpho : 0  iter :43 ]train loss : 0.448951 ,train acc: 0.793518 ,val loss : 0.405987 ,val acc : 0.821655\n",
      "[ ecpho : 0  iter :44 ]train loss : 0.398805 ,train acc: 0.826721 ,val loss : 0.403052 ,val acc : 0.820892\n",
      "[ ecpho : 0  iter :45 ]train loss : 0.400414 ,train acc: 0.823669 ,val loss : 0.400616 ,val acc : 0.820679\n",
      "[ ecpho : 0  iter :46 ]train loss : 0.620779 ,train acc: 0.471924 ,val loss : 0.395484 ,val acc : 0.824005\n",
      "[ ecpho : 0  iter :47 ]train loss : 0.384006 ,train acc: 0.822845 ,val loss : 0.391276 ,val acc : 0.826904\n",
      "[ ecpho : 0  iter :48 ]train loss : 0.388554 ,train acc: 0.825226 ,val loss : 0.383174 ,val acc : 0.830292\n",
      "[ ecpho : 0  iter :49 ]train loss : 0.382696 ,train acc: 0.828430 ,val loss : 0.388542 ,val acc : 0.826935\n",
      "[ ecpho : 0  iter :50 ]train loss : 0.373957 ,train acc: 0.821991 ,val loss : 0.374208 ,val acc : 0.831696\n",
      "[ ecpho : 0  iter :51 ]train loss : 0.356740 ,train acc: 0.839905 ,val loss : 0.372017 ,val acc : 0.833130\n",
      "[ ecpho : 0  iter :52 ]train loss : 0.362345 ,train acc: 0.843964 ,val loss : 0.370331 ,val acc : 0.832062\n",
      "[ ecpho : 0  iter :53 ]train loss : 0.370437 ,train acc: 0.826721 ,val loss : 0.364724 ,val acc : 0.834320\n",
      "[ ecpho : 0  iter :54 ]train loss : 0.368662 ,train acc: 0.803802 ,val loss : 0.359116 ,val acc : 0.838715\n",
      "[ ecpho : 0  iter :55 ]train loss : 0.357217 ,train acc: 0.836548 ,val loss : 0.356381 ,val acc : 0.839050\n",
      "[ ecpho : 0  iter :56 ]train loss : 0.376191 ,train acc: 0.800262 ,val loss : 0.350447 ,val acc : 0.842285\n",
      "[ ecpho : 0  iter :57 ]train loss : 0.434759 ,train acc: 0.703156 ,val loss : 0.344023 ,val acc : 0.843811\n",
      "[ ecpho : 0  iter :58 ]train loss : 0.334644 ,train acc: 0.842926 ,val loss : 0.347378 ,val acc : 0.841858\n",
      "[ ecpho : 0  iter :59 ]train loss : 0.345460 ,train acc: 0.836517 ,val loss : 0.340264 ,val acc : 0.844269\n",
      "[ ecpho : 0  iter :60 ]train loss : 0.308845 ,train acc: 0.857269 ,val loss : 0.333906 ,val acc : 0.845703\n",
      "[ ecpho : 0  iter :61 ]train loss : 0.358999 ,train acc: 0.818970 ,val loss : 0.331359 ,val acc : 0.849670\n",
      "[ ecpho : 0  iter :62 ]train loss : 0.339925 ,train acc: 0.830261 ,val loss : 0.326372 ,val acc : 0.852051\n",
      "[ ecpho : 0  iter :63 ]train loss : 0.443844 ,train acc: 0.666290 ,val loss : 0.317899 ,val acc : 0.855652\n",
      "[ ecpho : 0  iter :64 ]train loss : 0.479868 ,train acc: 0.715424 ,val loss : 0.316793 ,val acc : 0.854828\n",
      "[ ecpho : 0  iter :65 ]train loss : 0.333496 ,train acc: 0.848236 ,val loss : 0.312394 ,val acc : 0.859161\n",
      "[ ecpho : 0  iter :66 ]train loss : 0.278801 ,train acc: 0.872986 ,val loss : 0.310968 ,val acc : 0.857025\n",
      "[ ecpho : 0  iter :67 ]train loss : 0.294116 ,train acc: 0.860443 ,val loss : 0.307036 ,val acc : 0.861145\n",
      "[ ecpho : 0  iter :68 ]train loss : 0.269544 ,train acc: 0.877350 ,val loss : 0.298884 ,val acc : 0.862152\n",
      "[ ecpho : 0  iter :69 ]train loss : 0.280394 ,train acc: 0.871582 ,val loss : 0.297518 ,val acc : 0.864929\n",
      "[ ecpho : 0  iter :70 ]train loss : 0.294122 ,train acc: 0.865570 ,val loss : 0.294149 ,val acc : 0.862427\n",
      "[ ecpho : 0  iter :71 ]train loss : 0.264010 ,train acc: 0.873871 ,val loss : 0.292724 ,val acc : 0.866028\n",
      "[ ecpho : 0  iter :72 ]train loss : 0.264723 ,train acc: 0.869049 ,val loss : 0.286111 ,val acc : 0.867401\n",
      "[ ecpho : 0  iter :73 ]train loss : 0.242541 ,train acc: 0.876007 ,val loss : 0.284573 ,val acc : 0.869843\n",
      "[ ecpho : 0  iter :74 ]train loss : 0.510223 ,train acc: 0.610718 ,val loss : 0.290797 ,val acc : 0.866852\n",
      "[ ecpho : 0  iter :75 ]train loss : 0.258870 ,train acc: 0.863800 ,val loss : 0.281994 ,val acc : 0.870331\n",
      "[ ecpho : 0  iter :76 ]train loss : 0.257418 ,train acc: 0.876068 ,val loss : 0.280619 ,val acc : 0.872650\n",
      "[ ecpho : 0  iter :77 ]train loss : 0.235127 ,train acc: 0.884247 ,val loss : 0.280101 ,val acc : 0.874207\n",
      "[ ecpho : 0  iter :78 ]train loss : 0.252854 ,train acc: 0.874481 ,val loss : 0.274986 ,val acc : 0.871613\n",
      "[ ecpho : 0  iter :79 ]train loss : 0.232836 ,train acc: 0.886536 ,val loss : 0.267586 ,val acc : 0.878632\n",
      "[ ecpho : 0  iter :80 ]train loss : 0.257858 ,train acc: 0.880035 ,val loss : 0.268645 ,val acc : 0.877350\n",
      "[ ecpho : 0  iter :81 ]train loss : 0.227795 ,train acc: 0.886353 ,val loss : 0.272373 ,val acc : 0.876129\n",
      "[ ecpho : 0  iter :82 ]train loss : 0.405778 ,train acc: 0.666016 ,val loss : 0.264294 ,val acc : 0.879669\n",
      "[ ecpho : 0  iter :83 ]train loss : 0.236029 ,train acc: 0.889954 ,val loss : 0.261742 ,val acc : 0.883850\n",
      "[ ecpho : 0  iter :84 ]train loss : 0.226255 ,train acc: 0.894928 ,val loss : 0.265981 ,val acc : 0.881409\n",
      "[ ecpho : 0  iter :85 ]train loss : 0.200395 ,train acc: 0.909729 ,val loss : 0.263468 ,val acc : 0.882202\n",
      "[ ecpho : 0  iter :86 ]train loss : 0.226833 ,train acc: 0.893738 ,val loss : 0.259681 ,val acc : 0.884613\n",
      "[ ecpho : 0  iter :87 ]train loss : 0.220605 ,train acc: 0.900970 ,val loss : 0.259110 ,val acc : 0.885437\n",
      "[ ecpho : 0  iter :88 ]train loss : 0.252611 ,train acc: 0.882965 ,val loss : 0.252986 ,val acc : 0.887024\n",
      "[ ecpho : 0  iter :89 ]train loss : 0.281875 ,train acc: 0.807739 ,val loss : 0.254997 ,val acc : 0.888519\n",
      "[ ecpho : 0  iter :90 ]train loss : 0.407199 ,train acc: 0.793427 ,val loss : 0.252461 ,val acc : 0.889740\n",
      "[ ecpho : 0  iter :91 ]train loss : 0.208769 ,train acc: 0.904938 ,val loss : 0.250513 ,val acc : 0.891174\n",
      "[ ecpho : 0  iter :92 ]train loss : 0.237130 ,train acc: 0.860565 ,val loss : 0.246550 ,val acc : 0.890808\n",
      "[ ecpho : 0  iter :93 ]train loss : 0.368098 ,train acc: 0.741943 ,val loss : 0.249616 ,val acc : 0.891479\n",
      "[ ecpho : 0  iter :94 ]train loss : 0.210472 ,train acc: 0.905518 ,val loss : 0.248148 ,val acc : 0.892700\n",
      "[ ecpho : 0  iter :95 ]train loss : 0.559216 ,train acc: 0.660187 ,val loss : 0.247900 ,val acc : 0.895599\n",
      "[ ecpho : 0  iter :96 ]train loss : 0.227757 ,train acc: 0.898102 ,val loss : 0.245154 ,val acc : 0.894867\n",
      "[ ecpho : 0  iter :97 ]train loss : 0.198638 ,train acc: 0.908478 ,val loss : 0.240796 ,val acc : 0.897247\n",
      "[ ecpho : 0  iter :98 ]train loss : 0.220207 ,train acc: 0.907990 ,val loss : 0.236807 ,val acc : 0.897583\n",
      "[ ecpho : 0  iter :99 ]train loss : 0.194545 ,train acc: 0.914948 ,val loss : 0.237304 ,val acc : 0.899963\n",
      "[ ecpho : 0  iter :100 ]train loss : 0.244614 ,train acc: 0.884735 ,val loss : 0.238923 ,val acc : 0.897308\n",
      "[ ecpho : 0  iter :101 ]train loss : 0.211287 ,train acc: 0.905945 ,val loss : 0.238889 ,val acc : 0.896851\n",
      "[ ecpho : 0  iter :102 ]train loss : 0.421836 ,train acc: 0.660614 ,val loss : 0.236428 ,val acc : 0.901642\n",
      "[ ecpho : 0  iter :103 ]train loss : 0.522132 ,train acc: 0.706512 ,val loss : 0.234667 ,val acc : 0.901611\n",
      "[ ecpho : 0  iter :104 ]train loss : 0.389166 ,train acc: 0.661469 ,val loss : 0.226153 ,val acc : 0.904175\n",
      "[ ecpho : 0  iter :105 ]train loss : 0.183762 ,train acc: 0.921539 ,val loss : 0.236505 ,val acc : 0.902954\n",
      "[ ecpho : 0  iter :106 ]train loss : 0.271551 ,train acc: 0.901123 ,val loss : 0.232402 ,val acc : 0.905823\n",
      "[ ecpho : 0  iter :107 ]train loss : 0.240969 ,train acc: 0.884491 ,val loss : 0.233265 ,val acc : 0.903595\n",
      "[ ecpho : 0  iter :108 ]train loss : 0.209391 ,train acc: 0.912720 ,val loss : 0.227698 ,val acc : 0.904846\n",
      "[ ecpho : 0  iter :109 ]train loss : 0.327943 ,train acc: 0.855316 ,val loss : 0.226749 ,val acc : 0.904358\n",
      "[ ecpho : 0  iter :110 ]train loss : 0.162826 ,train acc: 0.937836 ,val loss : 0.224670 ,val acc : 0.907959\n",
      "[ ecpho : 0  iter :111 ]train loss : 0.286039 ,train acc: 0.820007 ,val loss : 0.225472 ,val acc : 0.907196\n",
      "[ ecpho : 0  iter :112 ]train loss : 0.196786 ,train acc: 0.914825 ,val loss : 0.230972 ,val acc : 0.909424\n",
      "[ ecpho : 0  iter :113 ]train loss : 0.688963 ,train acc: 0.473083 ,val loss : 0.225521 ,val acc : 0.909058\n",
      "[ ecpho : 0  iter :114 ]train loss : 0.188961 ,train acc: 0.915955 ,val loss : 0.223537 ,val acc : 0.907257\n",
      "[ ecpho : 0  iter :115 ]train loss : 0.186866 ,train acc: 0.917236 ,val loss : 0.221023 ,val acc : 0.909790\n",
      "[ ecpho : 0  iter :116 ]train loss : 0.290429 ,train acc: 0.760437 ,val loss : 0.223362 ,val acc : 0.909393\n",
      "[ ecpho : 0  iter :117 ]train loss : 0.206599 ,train acc: 0.901672 ,val loss : 0.215377 ,val acc : 0.915619\n",
      "[ ecpho : 0  iter :118 ]train loss : 0.199676 ,train acc: 0.903076 ,val loss : 0.221914 ,val acc : 0.915070\n",
      "[ ecpho : 0  iter :119 ]train loss : 0.184275 ,train acc: 0.927185 ,val loss : 0.219775 ,val acc : 0.914825\n",
      "[ ecpho : 0  iter :120 ]train loss : 0.181424 ,train acc: 0.925934 ,val loss : 0.219741 ,val acc : 0.912384\n",
      "[ ecpho : 0  iter :121 ]train loss : 0.500659 ,train acc: 0.607635 ,val loss : 0.218622 ,val acc : 0.914490\n",
      "[ ecpho : 0  iter :122 ]train loss : 0.187042 ,train acc: 0.925201 ,val loss : 0.218566 ,val acc : 0.915100\n",
      "[ ecpho : 0  iter :123 ]train loss : 0.189988 ,train acc: 0.931946 ,val loss : 0.214467 ,val acc : 0.918823\n",
      "[ ecpho : 0  iter :124 ]train loss : 0.168607 ,train acc: 0.941864 ,val loss : 0.218389 ,val acc : 0.920074\n",
      "[ ecpho : 0  iter :125 ]train loss : 0.196692 ,train acc: 0.932159 ,val loss : 0.214452 ,val acc : 0.919647\n",
      "[ ecpho : 0  iter :126 ]train loss : 0.173265 ,train acc: 0.935089 ,val loss : 0.209816 ,val acc : 0.918732\n",
      "[ ecpho : 0  iter :127 ]train loss : 0.700008 ,train acc: 0.394379 ,val loss : 0.210488 ,val acc : 0.922424\n",
      "[ ecpho : 0  iter :128 ]train loss : 0.186040 ,train acc: 0.938782 ,val loss : 0.208846 ,val acc : 0.922363\n",
      "[ ecpho : 0  iter :129 ]train loss : 0.440176 ,train acc: 0.645355 ,val loss : 0.211022 ,val acc : 0.920837\n",
      "[ ecpho : 0  iter :130 ]train loss : 0.386137 ,train acc: 0.699463 ,val loss : 0.212717 ,val acc : 0.920807\n",
      "[ ecpho : 0  iter :131 ]train loss : 0.196089 ,train acc: 0.914551 ,val loss : 0.211093 ,val acc : 0.922089\n",
      "[ ecpho : 0  iter :132 ]train loss : 0.182009 ,train acc: 0.940002 ,val loss : 0.207437 ,val acc : 0.923218\n",
      "[ ecpho : 0  iter :133 ]train loss : 0.362190 ,train acc: 0.812744 ,val loss : 0.213070 ,val acc : 0.923401\n",
      "[ ecpho : 0  iter :134 ]train loss : 0.420352 ,train acc: 0.688354 ,val loss : 0.212539 ,val acc : 0.922577\n",
      "[ ecpho : 0  iter :135 ]train loss : 0.216871 ,train acc: 0.929108 ,val loss : 0.209873 ,val acc : 0.923889\n",
      "[ ecpho : 0  iter :136 ]train loss : 0.194695 ,train acc: 0.911865 ,val loss : 0.209968 ,val acc : 0.925537\n",
      "[ ecpho : 0  iter :137 ]train loss : 0.178801 ,train acc: 0.934998 ,val loss : 0.204398 ,val acc : 0.925110\n",
      "[ ecpho : 0  iter :138 ]train loss : 0.151699 ,train acc: 0.950012 ,val loss : 0.207664 ,val acc : 0.925751\n",
      "[ ecpho : 0  iter :139 ]train loss : 0.165884 ,train acc: 0.939545 ,val loss : 0.203745 ,val acc : 0.925842\n",
      "[ ecpho : 0  iter :140 ]train loss : 0.184993 ,train acc: 0.927490 ,val loss : 0.205057 ,val acc : 0.926117\n",
      "[ ecpho : 0  iter :141 ]train loss : 0.494337 ,train acc: 0.562592 ,val loss : 0.203536 ,val acc : 0.926910\n",
      "[ ecpho : 0  iter :142 ]train loss : 0.162719 ,train acc: 0.941040 ,val loss : 0.203644 ,val acc : 0.928558\n",
      "[ ecpho : 0  iter :143 ]train loss : 0.167326 ,train acc: 0.938385 ,val loss : 0.208677 ,val acc : 0.929718\n",
      "[ ecpho : 0  iter :144 ]train loss : 0.166956 ,train acc: 0.936432 ,val loss : 0.204574 ,val acc : 0.930511\n",
      "[ ecpho : 0  iter :145 ]train loss : 0.173554 ,train acc: 0.933472 ,val loss : 0.202964 ,val acc : 0.932739\n",
      "[ ecpho : 0  iter :146 ]train loss : 0.166598 ,train acc: 0.939117 ,val loss : 0.202068 ,val acc : 0.931824\n",
      "[ ecpho : 0  iter :147 ]train loss : 0.161085 ,train acc: 0.945557 ,val loss : 0.201721 ,val acc : 0.933350\n",
      "[ ecpho : 0  iter :148 ]train loss : 0.972716 ,train acc: 0.267334 ,val loss : 0.200537 ,val acc : 0.936859\n",
      "[ ecpho : 0  iter :149 ]train loss : 0.199502 ,train acc: 0.906738 ,val loss : 0.195699 ,val acc : 0.936371\n",
      "[ ecpho : 0  iter :150 ]train loss : 0.186490 ,train acc: 0.937378 ,val loss : 0.197774 ,val acc : 0.935242\n",
      "[ ecpho : 0  iter :151 ]train loss : 0.662617 ,train acc: 0.455841 ,val loss : 0.196344 ,val acc : 0.937500\n",
      "[ ecpho : 0  iter :152 ]train loss : 0.289790 ,train acc: 0.876404 ,val loss : 0.202885 ,val acc : 0.936218\n",
      "[ ecpho : 0  iter :153 ]train loss : 0.198006 ,train acc: 0.911835 ,val loss : 0.201073 ,val acc : 0.936584\n",
      "[ ecpho : 0  iter :154 ]train loss : 0.291189 ,train acc: 0.885956 ,val loss : 0.198704 ,val acc : 0.936371\n",
      "[ ecpho : 0  iter :155 ]train loss : 0.179622 ,train acc: 0.946747 ,val loss : 0.196308 ,val acc : 0.936523\n",
      "[ ecpho : 0  iter :156 ]train loss : 0.173313 ,train acc: 0.937897 ,val loss : 0.191054 ,val acc : 0.936554\n",
      "[ ecpho : 0  iter :157 ]train loss : 0.189276 ,train acc: 0.938263 ,val loss : 0.196393 ,val acc : 0.939087\n",
      "[ ecpho : 0  iter :158 ]train loss : 0.167133 ,train acc: 0.947723 ,val loss : 0.191987 ,val acc : 0.937988\n",
      "[ ecpho : 0  iter :159 ]train loss : 0.187315 ,train acc: 0.935486 ,val loss : 0.189107 ,val acc : 0.938293\n",
      "[ ecpho : 0  iter :160 ]train loss : 0.198678 ,train acc: 0.913361 ,val loss : 0.189385 ,val acc : 0.939728\n",
      "[ ecpho : 0  iter :161 ]train loss : 0.979384 ,train acc: 0.181000 ,val loss : 0.189413 ,val acc : 0.940918\n",
      "[ ecpho : 0  iter :162 ]train loss : 0.246458 ,train acc: 0.913361 ,val loss : 0.191976 ,val acc : 0.940613\n",
      "[ ecpho : 0  iter :163 ]train loss : 0.178598 ,train acc: 0.932434 ,val loss : 0.189075 ,val acc : 0.940399\n",
      "[ ecpho : 0  iter :164 ]train loss : 0.218018 ,train acc: 0.922852 ,val loss : 0.188513 ,val acc : 0.939972\n",
      "[ ecpho : 0  iter :165 ]train loss : 0.154061 ,train acc: 0.957153 ,val loss : 0.188743 ,val acc : 0.940857\n",
      "[ ecpho : 0  iter :166 ]train loss : 0.157916 ,train acc: 0.950348 ,val loss : 0.186754 ,val acc : 0.941864\n",
      "[ ecpho : 0  iter :167 ]train loss : 0.379751 ,train acc: 0.706696 ,val loss : 0.186711 ,val acc : 0.942993\n",
      "[ ecpho : 0  iter :168 ]train loss : 0.186195 ,train acc: 0.923279 ,val loss : 0.183481 ,val acc : 0.943787\n",
      "[ ecpho : 0  iter :169 ]train loss : 0.350876 ,train acc: 0.815613 ,val loss : 0.185136 ,val acc : 0.944183\n",
      "[ ecpho : 0  iter :170 ]train loss : 0.694572 ,train acc: 0.464813 ,val loss : 0.185950 ,val acc : 0.945984\n",
      "[ ecpho : 0  iter :171 ]train loss : 0.165629 ,train acc: 0.947906 ,val loss : 0.188640 ,val acc : 0.945221\n",
      "[ ecpho : 0  iter :172 ]train loss : 0.418093 ,train acc: 0.785675 ,val loss : 0.187301 ,val acc : 0.946930\n",
      "[ ecpho : 0  iter :173 ]train loss : 0.564351 ,train acc: 0.544281 ,val loss : 0.184805 ,val acc : 0.944214\n",
      "[ ecpho : 0  iter :174 ]train loss : 0.206901 ,train acc: 0.933838 ,val loss : 0.188504 ,val acc : 0.942200\n",
      "[ ecpho : 0  iter :175 ]train loss : 0.165176 ,train acc: 0.949982 ,val loss : 0.190724 ,val acc : 0.941589\n",
      "[ ecpho : 0  iter :176 ]train loss : 0.266290 ,train acc: 0.827118 ,val loss : 0.187874 ,val acc : 0.943390\n",
      "[ ecpho : 0  iter :177 ]train loss : 0.178999 ,train acc: 0.942169 ,val loss : 0.186823 ,val acc : 0.944977\n",
      "[ ecpho : 0  iter :178 ]train loss : 0.201365 ,train acc: 0.933136 ,val loss : 0.189411 ,val acc : 0.944885\n",
      "[ ecpho : 0  iter :179 ]train loss : 0.209576 ,train acc: 0.896332 ,val loss : 0.185056 ,val acc : 0.945648\n",
      "[ ecpho : 0  iter :180 ]train loss : 0.154610 ,train acc: 0.955872 ,val loss : 0.185577 ,val acc : 0.945404\n",
      "[ ecpho : 0  iter :181 ]train loss : 0.243262 ,train acc: 0.911255 ,val loss : 0.185188 ,val acc : 0.948242\n",
      "[ ecpho : 0  iter :182 ]train loss : 0.188439 ,train acc: 0.941406 ,val loss : 0.183562 ,val acc : 0.950836\n",
      "[ ecpho : 0  iter :183 ]train loss : 0.160443 ,train acc: 0.956543 ,val loss : 0.182052 ,val acc : 0.949799\n",
      "[ ecpho : 0  iter :184 ]train loss : 0.147515 ,train acc: 0.963013 ,val loss : 0.181811 ,val acc : 0.953247\n",
      "[ ecpho : 0  iter :185 ]train loss : 0.652293 ,train acc: 0.409760 ,val loss : 0.181367 ,val acc : 0.953491\n",
      "[ ecpho : 0  iter :186 ]train loss : 0.173801 ,train acc: 0.937195 ,val loss : 0.178722 ,val acc : 0.950806\n",
      "[ ecpho : 0  iter :187 ]train loss : 0.191058 ,train acc: 0.954956 ,val loss : 0.178715 ,val acc : 0.952911\n",
      "[ ecpho : 0  iter :188 ]train loss : 0.163798 ,train acc: 0.961884 ,val loss : 0.183737 ,val acc : 0.951599\n",
      "[ ecpho : 0  iter :189 ]train loss : 0.147566 ,train acc: 0.966522 ,val loss : 0.181456 ,val acc : 0.953766\n",
      "[ ecpho : 0  iter :190 ]train loss : 0.192920 ,train acc: 0.945679 ,val loss : 0.179112 ,val acc : 0.954834\n",
      "[ ecpho : 0  iter :191 ]train loss : 0.224063 ,train acc: 0.887482 ,val loss : 0.180826 ,val acc : 0.954102\n",
      "[ ecpho : 0  iter :192 ]train loss : 0.146098 ,train acc: 0.969421 ,val loss : 0.178385 ,val acc : 0.955566\n",
      "[ ecpho : 0  iter :193 ]train loss : 0.175822 ,train acc: 0.937897 ,val loss : 0.177187 ,val acc : 0.956055\n",
      "[ ecpho : 0  iter :194 ]train loss : 0.381763 ,train acc: 0.800262 ,val loss : 0.179616 ,val acc : 0.957184\n",
      "[ ecpho : 0  iter :195 ]train loss : 0.134628 ,train acc: 0.971100 ,val loss : 0.178454 ,val acc : 0.957092\n",
      "[ ecpho : 0  iter :196 ]train loss : 0.146749 ,train acc: 0.965027 ,val loss : 0.175255 ,val acc : 0.958984\n",
      "[ ecpho : 0  iter :197 ]train loss : 0.148913 ,train acc: 0.966919 ,val loss : 0.175958 ,val acc : 0.956635\n",
      "[ ecpho : 0  iter :198 ]train loss : 0.139727 ,train acc: 0.973450 ,val loss : 0.175277 ,val acc : 0.959595\n",
      "[ ecpho : 0  iter :199 ]train loss : 0.368823 ,train acc: 0.702301 ,val loss : 0.174732 ,val acc : 0.957336\n",
      "[ ecpho : 0  iter :200 ]train loss : 0.233942 ,train acc: 0.897980 ,val loss : 0.173295 ,val acc : 0.957458\n",
      "[ ecpho : 0  iter :201 ]train loss : 0.131529 ,train acc: 0.974365 ,val loss : 0.176802 ,val acc : 0.959686\n",
      "[ ecpho : 0  iter :202 ]train loss : 0.139942 ,train acc: 0.972656 ,val loss : 0.180554 ,val acc : 0.958984\n",
      "[ ecpho : 0  iter :203 ]train loss : 0.187477 ,train acc: 0.947693 ,val loss : 0.177226 ,val acc : 0.960358\n",
      "[ ecpho : 0  iter :204 ]train loss : 0.161833 ,train acc: 0.950409 ,val loss : 0.172518 ,val acc : 0.959839\n",
      "[ ecpho : 0  iter :205 ]train loss : 0.136310 ,train acc: 0.972656 ,val loss : 0.176223 ,val acc : 0.959900\n",
      "[ ecpho : 0  iter :206 ]train loss : 0.300217 ,train acc: 0.830261 ,val loss : 0.176279 ,val acc : 0.962799\n",
      "[ ecpho : 0  iter :207 ]train loss : 0.224689 ,train acc: 0.879059 ,val loss : 0.175205 ,val acc : 0.961853\n",
      "[ ecpho : 0  iter :208 ]train loss : 0.167557 ,train acc: 0.964447 ,val loss : 0.176760 ,val acc : 0.962860\n",
      "[ ecpho : 0  iter :209 ]train loss : 0.146946 ,train acc: 0.964966 ,val loss : 0.173683 ,val acc : 0.962250\n",
      "[ ecpho : 0  iter :210 ]train loss : 0.127026 ,train acc: 0.978607 ,val loss : 0.171370 ,val acc : 0.963715\n",
      "[ ecpho : 0  iter :211 ]train loss : 0.132498 ,train acc: 0.973938 ,val loss : 0.168963 ,val acc : 0.964233\n",
      "[ ecpho : 0  iter :212 ]train loss : 0.321789 ,train acc: 0.770081 ,val loss : 0.171659 ,val acc : 0.965240\n",
      "[ ecpho : 0  iter :213 ]train loss : 0.126222 ,train acc: 0.979401 ,val loss : 0.173003 ,val acc : 0.964996\n",
      "[ ecpho : 0  iter :214 ]train loss : 0.132692 ,train acc: 0.976685 ,val loss : 0.174878 ,val acc : 0.965851\n",
      "[ ecpho : 0  iter :215 ]train loss : 0.137662 ,train acc: 0.970825 ,val loss : 0.168763 ,val acc : 0.966400\n",
      "[ ecpho : 0  iter :216 ]train loss : 0.138910 ,train acc: 0.971252 ,val loss : 0.171456 ,val acc : 0.968445\n",
      "[ ecpho : 0  iter :217 ]train loss : 0.193531 ,train acc: 0.960480 ,val loss : 0.172435 ,val acc : 0.967590\n",
      "[ ecpho : 0  iter :218 ]train loss : 0.132261 ,train acc: 0.970367 ,val loss : 0.168078 ,val acc : 0.967743\n",
      "[ ecpho : 0  iter :219 ]train loss : 0.127244 ,train acc: 0.979004 ,val loss : 0.170908 ,val acc : 0.969299\n",
      "[ ecpho : 0  iter :220 ]train loss : 0.127569 ,train acc: 0.972748 ,val loss : 0.166784 ,val acc : 0.970703\n",
      "[ ecpho : 0  iter :221 ]train loss : 0.110598 ,train acc: 0.985474 ,val loss : 0.170228 ,val acc : 0.969757\n",
      "[ ecpho : 0  iter :222 ]train loss : 0.134092 ,train acc: 0.976105 ,val loss : 0.168153 ,val acc : 0.972290\n",
      "[ ecpho : 0  iter :223 ]train loss : 0.114673 ,train acc: 0.985168 ,val loss : 0.171521 ,val acc : 0.970673\n",
      "[ ecpho : 0  iter :224 ]train loss : 0.387450 ,train acc: 0.682220 ,val loss : 0.170819 ,val acc : 0.970428\n",
      "[ ecpho : 0  iter :225 ]train loss : 0.138022 ,train acc: 0.975586 ,val loss : 0.169288 ,val acc : 0.971619\n",
      "[ ecpho : 0  iter :226 ]train loss : 0.176110 ,train acc: 0.961029 ,val loss : 0.173028 ,val acc : 0.970825\n",
      "[ ecpho : 0  iter :227 ]train loss : 0.274089 ,train acc: 0.924652 ,val loss : 0.170230 ,val acc : 0.969208\n",
      "[ ecpho : 0  iter :228 ]train loss : 0.226095 ,train acc: 0.884033 ,val loss : 0.167125 ,val acc : 0.970398\n",
      "[ ecpho : 0  iter :229 ]train loss : 0.163938 ,train acc: 0.947083 ,val loss : 0.165429 ,val acc : 0.969879\n",
      "[ ecpho : 0  iter :230 ]train loss : 0.166094 ,train acc: 0.964722 ,val loss : 0.166137 ,val acc : 0.969604\n",
      "[ ecpho : 0  iter :231 ]train loss : 0.129839 ,train acc: 0.976929 ,val loss : 0.164582 ,val acc : 0.967407\n",
      "[ ecpho : 0  iter :232 ]train loss : 0.126709 ,train acc: 0.978546 ,val loss : 0.173353 ,val acc : 0.969299\n",
      "[ ecpho : 0  iter :233 ]train loss : 0.146007 ,train acc: 0.975830 ,val loss : 0.166439 ,val acc : 0.970093\n",
      "[ ecpho : 0  iter :234 ]train loss : 0.190096 ,train acc: 0.920837 ,val loss : 0.163966 ,val acc : 0.970367\n",
      "[ ecpho : 0  iter :235 ]train loss : 0.132623 ,train acc: 0.978760 ,val loss : 0.167383 ,val acc : 0.969849\n",
      "[ ecpho : 0  iter :236 ]train loss : 0.122275 ,train acc: 0.982880 ,val loss : 0.168234 ,val acc : 0.972443\n",
      "[ ecpho : 0  iter :237 ]train loss : 0.154755 ,train acc: 0.953613 ,val loss : 0.162037 ,val acc : 0.972900\n",
      "[ ecpho : 0  iter :238 ]train loss : 0.144314 ,train acc: 0.966431 ,val loss : 0.168848 ,val acc : 0.973785\n",
      "[ ecpho : 0  iter :239 ]train loss : 0.127273 ,train acc: 0.983429 ,val loss : 0.165179 ,val acc : 0.975342\n",
      "[ ecpho : 0  iter :240 ]train loss : 0.212422 ,train acc: 0.949097 ,val loss : 0.165758 ,val acc : 0.975128\n",
      "[ ecpho : 0  iter :241 ]train loss : 0.204589 ,train acc: 0.890839 ,val loss : 0.164983 ,val acc : 0.975128\n",
      "[ ecpho : 0  iter :242 ]train loss : 0.150696 ,train acc: 0.959015 ,val loss : 0.163164 ,val acc : 0.975403\n",
      "[ ecpho : 0  iter :243 ]train loss : 0.150436 ,train acc: 0.965515 ,val loss : 0.167137 ,val acc : 0.974365\n",
      "[ ecpho : 0  iter :244 ]train loss : 0.100545 ,train acc: 0.989777 ,val loss : 0.163130 ,val acc : 0.976318\n",
      "[ ecpho : 0  iter :245 ]train loss : 0.135800 ,train acc: 0.977173 ,val loss : 0.167786 ,val acc : 0.975494\n",
      "[ ecpho : 0  iter :246 ]train loss : 0.128092 ,train acc: 0.978638 ,val loss : 0.159928 ,val acc : 0.977234\n",
      "[ ecpho : 0  iter :247 ]train loss : 0.107932 ,train acc: 0.990326 ,val loss : 0.163502 ,val acc : 0.977478\n",
      "[ ecpho : 0  iter :248 ]train loss : 0.120693 ,train acc: 0.985565 ,val loss : 0.164491 ,val acc : 0.976410\n",
      "[ ecpho : 0  iter :249 ]train loss : 0.113789 ,train acc: 0.988861 ,val loss : 0.164047 ,val acc : 0.978394\n",
      "[ ecpho : 0  iter :250 ]train loss : 0.107765 ,train acc: 0.989563 ,val loss : 0.156583 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :251 ]train loss : 0.132754 ,train acc: 0.970184 ,val loss : 0.163437 ,val acc : 0.979156\n",
      "[ ecpho : 0  iter :252 ]train loss : 0.111590 ,train acc: 0.990112 ,val loss : 0.162467 ,val acc : 0.978760\n",
      "[ ecpho : 0  iter :253 ]train loss : 0.172125 ,train acc: 0.941650 ,val loss : 0.158973 ,val acc : 0.979919\n",
      "[ ecpho : 0  iter :254 ]train loss : 1.152862 ,train acc: 0.203583 ,val loss : 0.160983 ,val acc : 0.978027\n",
      "[ ecpho : 0  iter :255 ]train loss : 0.179531 ,train acc: 0.931946 ,val loss : 0.162689 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :256 ]train loss : 0.183027 ,train acc: 0.926758 ,val loss : 0.159891 ,val acc : 0.978333\n",
      "[ ecpho : 0  iter :257 ]train loss : 0.099108 ,train acc: 0.991791 ,val loss : 0.157293 ,val acc : 0.977325\n",
      "[ ecpho : 0  iter :258 ]train loss : 0.141229 ,train acc: 0.980682 ,val loss : 0.158955 ,val acc : 0.977173\n",
      "[ ecpho : 0  iter :259 ]train loss : 0.817225 ,train acc: 0.473389 ,val loss : 0.160305 ,val acc : 0.978271\n",
      "[ ecpho : 0  iter :260 ]train loss : 0.124126 ,train acc: 0.983307 ,val loss : 0.160580 ,val acc : 0.976013\n",
      "[ ecpho : 0  iter :261 ]train loss : 0.107751 ,train acc: 0.988129 ,val loss : 0.154478 ,val acc : 0.978088\n",
      "[ ecpho : 0  iter :262 ]train loss : 0.116749 ,train acc: 0.986481 ,val loss : 0.156495 ,val acc : 0.977570\n",
      "[ ecpho : 0  iter :263 ]train loss : 0.125708 ,train acc: 0.978638 ,val loss : 0.156484 ,val acc : 0.977936\n",
      "[ ecpho : 0  iter :264 ]train loss : 0.145417 ,train acc: 0.981079 ,val loss : 0.156201 ,val acc : 0.977783\n",
      "[ ecpho : 0  iter :265 ]train loss : 0.160821 ,train acc: 0.956207 ,val loss : 0.155980 ,val acc : 0.977417\n",
      "[ ecpho : 0  iter :266 ]train loss : 0.112487 ,train acc: 0.985046 ,val loss : 0.155285 ,val acc : 0.976990\n",
      "[ ecpho : 0  iter :267 ]train loss : 0.096171 ,train acc: 0.995178 ,val loss : 0.156040 ,val acc : 0.979065\n",
      "[ ecpho : 0  iter :268 ]train loss : 0.123724 ,train acc: 0.986755 ,val loss : 0.153531 ,val acc : 0.978729\n",
      "[ ecpho : 0  iter :269 ]train loss : 0.128549 ,train acc: 0.972870 ,val loss : 0.154312 ,val acc : 0.979004\n",
      "[ ecpho : 0  iter :270 ]train loss : 0.154107 ,train acc: 0.957306 ,val loss : 0.152659 ,val acc : 0.978790\n",
      "[ ecpho : 0  iter :271 ]train loss : 0.194126 ,train acc: 0.937500 ,val loss : 0.152379 ,val acc : 0.980347\n",
      "[ ecpho : 0  iter :272 ]train loss : 0.289217 ,train acc: 0.816132 ,val loss : 0.153990 ,val acc : 0.979584\n",
      "[ ecpho : 0  iter :273 ]train loss : 0.122791 ,train acc: 0.985565 ,val loss : 0.151551 ,val acc : 0.978333\n",
      "[ ecpho : 0  iter :274 ]train loss : 0.117332 ,train acc: 0.981140 ,val loss : 0.154034 ,val acc : 0.977722\n",
      "[ ecpho : 0  iter :275 ]train loss : 0.209602 ,train acc: 0.950562 ,val loss : 0.158110 ,val acc : 0.977264\n",
      "[ ecpho : 0  iter :276 ]train loss : 0.127477 ,train acc: 0.976471 ,val loss : 0.153838 ,val acc : 0.977234\n",
      "[ ecpho : 0  iter :277 ]train loss : 0.141702 ,train acc: 0.960938 ,val loss : 0.153562 ,val acc : 0.976257\n",
      "[ ecpho : 0  iter :278 ]train loss : 0.161322 ,train acc: 0.969116 ,val loss : 0.150882 ,val acc : 0.977936\n",
      "[ ecpho : 0  iter :279 ]train loss : 0.127859 ,train acc: 0.984650 ,val loss : 0.151338 ,val acc : 0.977631\n",
      "[ ecpho : 0  iter :280 ]train loss : 0.157019 ,train acc: 0.963379 ,val loss : 0.151295 ,val acc : 0.978241\n",
      "[ ecpho : 0  iter :281 ]train loss : 0.156765 ,train acc: 0.967834 ,val loss : 0.152245 ,val acc : 0.980347\n",
      "[ ecpho : 0  iter :282 ]train loss : 0.970713 ,train acc: 0.295471 ,val loss : 0.152566 ,val acc : 0.978241\n",
      "[ ecpho : 0  iter :283 ]train loss : 0.105060 ,train acc: 0.988586 ,val loss : 0.148282 ,val acc : 0.980530\n",
      "[ ecpho : 0  iter :284 ]train loss : 0.126347 ,train acc: 0.982727 ,val loss : 0.149778 ,val acc : 0.980011\n",
      "[ ecpho : 0  iter :285 ]train loss : 0.110610 ,train acc: 0.986298 ,val loss : 0.149108 ,val acc : 0.980530\n",
      "[ ecpho : 0  iter :286 ]train loss : 0.368484 ,train acc: 0.882599 ,val loss : 0.147176 ,val acc : 0.980499\n",
      "[ ecpho : 0  iter :287 ]train loss : 0.200051 ,train acc: 0.908417 ,val loss : 0.149921 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :288 ]train loss : 0.256395 ,train acc: 0.828064 ,val loss : 0.145459 ,val acc : 0.981018\n",
      "[ ecpho : 0  iter :289 ]train loss : 0.148858 ,train acc: 0.964172 ,val loss : 0.147556 ,val acc : 0.980530\n",
      "[ ecpho : 0  iter :290 ]train loss : 0.096887 ,train acc: 0.993134 ,val loss : 0.151155 ,val acc : 0.978485\n",
      "[ ecpho : 0  iter :291 ]train loss : 0.109382 ,train acc: 0.980591 ,val loss : 0.147499 ,val acc : 0.978668\n",
      "[ ecpho : 0  iter :292 ]train loss : 0.646863 ,train acc: 0.449432 ,val loss : 0.149222 ,val acc : 0.978485\n",
      "[ ecpho : 0  iter :293 ]train loss : 0.123391 ,train acc: 0.985291 ,val loss : 0.149220 ,val acc : 0.976593\n",
      "[ ecpho : 0  iter :294 ]train loss : 0.151521 ,train acc: 0.947815 ,val loss : 0.144412 ,val acc : 0.976288\n",
      "[ ecpho : 0  iter :295 ]train loss : 0.117597 ,train acc: 0.985779 ,val loss : 0.149358 ,val acc : 0.975250\n",
      "[ ecpho : 0  iter :296 ]train loss : 0.106180 ,train acc: 0.988007 ,val loss : 0.146607 ,val acc : 0.975647\n",
      "[ ecpho : 0  iter :297 ]train loss : 0.138639 ,train acc: 0.979980 ,val loss : 0.150037 ,val acc : 0.977753\n",
      "[ ecpho : 0  iter :298 ]train loss : 0.131867 ,train acc: 0.979675 ,val loss : 0.145577 ,val acc : 0.978455\n",
      "[ ecpho : 0  iter :299 ]train loss : 0.132372 ,train acc: 0.983856 ,val loss : 0.151879 ,val acc : 0.978577\n",
      "[ ecpho : 0  iter :300 ]train loss : 0.096011 ,train acc: 0.991852 ,val loss : 0.148822 ,val acc : 0.981171\n",
      "[ ecpho : 0  iter :301 ]train loss : 0.319136 ,train acc: 0.782806 ,val loss : 0.146567 ,val acc : 0.981476\n",
      "[ ecpho : 0  iter :302 ]train loss : 0.142007 ,train acc: 0.976501 ,val loss : 0.148259 ,val acc : 0.982513\n",
      "[ ecpho : 0  iter :303 ]train loss : 0.366501 ,train acc: 0.767700 ,val loss : 0.144559 ,val acc : 0.981842\n",
      "[ ecpho : 0  iter :304 ]train loss : 0.604977 ,train acc: 0.457733 ,val loss : 0.148258 ,val acc : 0.981842\n",
      "[ ecpho : 0  iter :305 ]train loss : 0.343806 ,train acc: 0.754974 ,val loss : 0.146680 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :306 ]train loss : 0.181894 ,train acc: 0.935883 ,val loss : 0.147348 ,val acc : 0.978943\n",
      "[ ecpho : 0  iter :307 ]train loss : 0.374540 ,train acc: 0.804230 ,val loss : 0.148463 ,val acc : 0.976868\n",
      "[ ecpho : 0  iter :308 ]train loss : 0.151430 ,train acc: 0.962524 ,val loss : 0.146636 ,val acc : 0.976105\n",
      "[ ecpho : 0  iter :309 ]train loss : 0.110876 ,train acc: 0.984802 ,val loss : 0.149778 ,val acc : 0.974304\n",
      "[ ecpho : 0  iter :310 ]train loss : 0.283720 ,train acc: 0.883148 ,val loss : 0.148845 ,val acc : 0.974457\n",
      "[ ecpho : 0  iter :311 ]train loss : 0.113520 ,train acc: 0.983978 ,val loss : 0.144668 ,val acc : 0.976837\n",
      "[ ecpho : 0  iter :312 ]train loss : 0.092907 ,train acc: 0.992615 ,val loss : 0.150445 ,val acc : 0.976807\n",
      "[ ecpho : 0  iter :313 ]train loss : 0.134045 ,train acc: 0.970459 ,val loss : 0.150225 ,val acc : 0.978577\n",
      "[ ecpho : 0  iter :314 ]train loss : 0.339194 ,train acc: 0.820465 ,val loss : 0.146601 ,val acc : 0.978821\n",
      "[ ecpho : 0  iter :315 ]train loss : 0.118631 ,train acc: 0.983856 ,val loss : 0.147916 ,val acc : 0.980316\n",
      "[ ecpho : 0  iter :316 ]train loss : 0.087812 ,train acc: 0.993561 ,val loss : 0.150092 ,val acc : 0.981171\n",
      "[ ecpho : 0  iter :317 ]train loss : 0.173154 ,train acc: 0.949615 ,val loss : 0.146884 ,val acc : 0.981842\n",
      "[ ecpho : 0  iter :318 ]train loss : 0.140104 ,train acc: 0.969482 ,val loss : 0.149611 ,val acc : 0.983978\n",
      "[ ecpho : 0  iter :319 ]train loss : 0.186586 ,train acc: 0.927460 ,val loss : 0.147522 ,val acc : 0.982758\n",
      "[ ecpho : 0  iter :320 ]train loss : 0.144253 ,train acc: 0.983337 ,val loss : 0.149244 ,val acc : 0.984283\n",
      "[ ecpho : 0  iter :321 ]train loss : 0.151885 ,train acc: 0.981781 ,val loss : 0.149900 ,val acc : 0.983826\n",
      "[ ecpho : 0  iter :322 ]train loss : 0.102119 ,train acc: 0.990387 ,val loss : 0.148858 ,val acc : 0.983612\n",
      "[ ecpho : 0  iter :323 ]train loss : 0.095722 ,train acc: 0.993683 ,val loss : 0.145071 ,val acc : 0.984131\n",
      "[ ecpho : 0  iter :324 ]train loss : 0.639236 ,train acc: 0.687958 ,val loss : 0.144653 ,val acc : 0.983826\n",
      "[ ecpho : 0  iter :325 ]train loss : 0.113681 ,train acc: 0.988068 ,val loss : 0.147532 ,val acc : 0.983612\n",
      "[ ecpho : 0  iter :326 ]train loss : 0.096114 ,train acc: 0.991974 ,val loss : 0.144868 ,val acc : 0.984985\n",
      "[ ecpho : 0  iter :327 ]train loss : 0.120639 ,train acc: 0.990753 ,val loss : 0.146452 ,val acc : 0.983276\n",
      "[ ecpho : 0  iter :328 ]train loss : 0.100926 ,train acc: 0.990540 ,val loss : 0.145045 ,val acc : 0.984955\n",
      "[ ecpho : 0  iter :329 ]train loss : 0.366141 ,train acc: 0.807281 ,val loss : 0.143671 ,val acc : 0.985229\n",
      "[ ecpho : 0  iter :330 ]train loss : 0.181738 ,train acc: 0.928802 ,val loss : 0.145968 ,val acc : 0.983063\n",
      "[ ecpho : 0  iter :331 ]train loss : 0.141352 ,train acc: 0.987366 ,val loss : 0.145277 ,val acc : 0.984406\n",
      "[ ecpho : 0  iter :332 ]train loss : 0.207464 ,train acc: 0.922577 ,val loss : 0.146973 ,val acc : 0.982697\n",
      "[ ecpho : 0  iter :333 ]train loss : 0.126422 ,train acc: 0.974640 ,val loss : 0.147525 ,val acc : 0.982330\n",
      "[ ecpho : 0  iter :334 ]train loss : 0.117850 ,train acc: 0.987061 ,val loss : 0.146435 ,val acc : 0.982574\n",
      "[ ecpho : 0  iter :335 ]train loss : 0.138586 ,train acc: 0.980957 ,val loss : 0.145448 ,val acc : 0.982025\n",
      "[ ecpho : 0  iter :336 ]train loss : 0.886044 ,train acc: 0.392487 ,val loss : 0.146119 ,val acc : 0.981903\n",
      "[ ecpho : 0  iter :337 ]train loss : 0.443566 ,train acc: 0.672058 ,val loss : 0.143392 ,val acc : 0.981262\n",
      "[ ecpho : 0  iter :338 ]train loss : 0.130807 ,train acc: 0.972168 ,val loss : 0.147100 ,val acc : 0.978973\n",
      "[ ecpho : 0  iter :339 ]train loss : 0.115750 ,train acc: 0.984711 ,val loss : 0.143445 ,val acc : 0.979919\n",
      "[ ecpho : 0  iter :340 ]train loss : 0.154429 ,train acc: 0.947968 ,val loss : 0.147278 ,val acc : 0.978638\n",
      "[ ecpho : 0  iter :341 ]train loss : 0.127389 ,train acc: 0.975464 ,val loss : 0.142691 ,val acc : 0.978729\n",
      "[ ecpho : 0  iter :342 ]train loss : 0.168393 ,train acc: 0.952972 ,val loss : 0.143883 ,val acc : 0.980133\n",
      "[ ecpho : 0  iter :343 ]train loss : 0.796984 ,train acc: 0.361938 ,val loss : 0.145530 ,val acc : 0.978851\n",
      "[ ecpho : 0  iter :344 ]train loss : 0.103423 ,train acc: 0.988953 ,val loss : 0.145830 ,val acc : 0.977325\n",
      "[ ecpho : 0  iter :345 ]train loss : 0.421270 ,train acc: 0.649780 ,val loss : 0.145697 ,val acc : 0.976990\n",
      "[ ecpho : 0  iter :346 ]train loss : 0.275357 ,train acc: 0.878662 ,val loss : 0.147850 ,val acc : 0.974121\n",
      "[ ecpho : 0  iter :347 ]train loss : 0.121863 ,train acc: 0.975433 ,val loss : 0.146569 ,val acc : 0.974945\n",
      "[ ecpho : 0  iter :348 ]train loss : 0.140724 ,train acc: 0.971710 ,val loss : 0.147929 ,val acc : 0.975037\n",
      "[ ecpho : 0  iter :349 ]train loss : 0.139278 ,train acc: 0.976349 ,val loss : 0.148456 ,val acc : 0.975342\n",
      "[ ecpho : 0  iter :350 ]train loss : 0.132201 ,train acc: 0.973206 ,val loss : 0.145383 ,val acc : 0.977661\n",
      "[ ecpho : 0  iter :351 ]train loss : 0.113363 ,train acc: 0.985931 ,val loss : 0.146203 ,val acc : 0.978729\n",
      "[ ecpho : 0  iter :352 ]train loss : 0.152647 ,train acc: 0.971558 ,val loss : 0.147203 ,val acc : 0.981445\n",
      "[ ecpho : 0  iter :353 ]train loss : 0.099199 ,train acc: 0.988007 ,val loss : 0.144133 ,val acc : 0.983459\n",
      "[ ecpho : 0  iter :354 ]train loss : 0.125243 ,train acc: 0.982452 ,val loss : 0.143904 ,val acc : 0.984436\n",
      "[ ecpho : 0  iter :355 ]train loss : 0.117328 ,train acc: 0.991577 ,val loss : 0.149473 ,val acc : 0.986115\n",
      "[ ecpho : 0  iter :356 ]train loss : 0.123972 ,train acc: 0.991364 ,val loss : 0.145500 ,val acc : 0.986694\n",
      "[ ecpho : 0  iter :357 ]train loss : 0.154250 ,train acc: 0.978912 ,val loss : 0.144868 ,val acc : 0.987122\n",
      "[ ecpho : 0  iter :358 ]train loss : 0.118475 ,train acc: 0.992706 ,val loss : 0.143455 ,val acc : 0.987183\n",
      "[ ecpho : 0  iter :359 ]train loss : 0.184035 ,train acc: 0.940094 ,val loss : 0.144260 ,val acc : 0.985443\n",
      "[ ecpho : 0  iter :360 ]train loss : 0.132225 ,train acc: 0.990631 ,val loss : 0.143950 ,val acc : 0.986725\n",
      "[ ecpho : 0  iter :361 ]train loss : 0.119098 ,train acc: 0.980347 ,val loss : 0.145463 ,val acc : 0.986237\n",
      "[ ecpho : 0  iter :362 ]train loss : 0.091432 ,train acc: 0.995148 ,val loss : 0.143179 ,val acc : 0.985321\n",
      "[ ecpho : 0  iter :363 ]train loss : 0.182487 ,train acc: 0.936279 ,val loss : 0.143231 ,val acc : 0.985535\n",
      "[ ecpho : 0  iter :364 ]train loss : 0.122374 ,train acc: 0.990631 ,val loss : 0.143770 ,val acc : 0.984497\n",
      "[ ecpho : 0  iter :365 ]train loss : 0.366079 ,train acc: 0.773132 ,val loss : 0.140177 ,val acc : 0.982971\n",
      "[ ecpho : 0  iter :366 ]train loss : 0.097985 ,train acc: 0.991241 ,val loss : 0.144567 ,val acc : 0.982819\n",
      "[ ecpho : 0  iter :367 ]train loss : 0.304880 ,train acc: 0.793732 ,val loss : 0.145677 ,val acc : 0.980133\n",
      "[ ecpho : 0  iter :368 ]train loss : 0.134192 ,train acc: 0.971313 ,val loss : 0.146212 ,val acc : 0.980652\n",
      "[ ecpho : 0  iter :369 ]train loss : 0.124466 ,train acc: 0.972687 ,val loss : 0.143879 ,val acc : 0.979736\n",
      "[ ecpho : 0  iter :370 ]train loss : 0.223785 ,train acc: 0.876160 ,val loss : 0.146590 ,val acc : 0.977844\n",
      "[ ecpho : 0  iter :371 ]train loss : 0.189897 ,train acc: 0.914490 ,val loss : 0.143517 ,val acc : 0.975616\n",
      "[ ecpho : 0  iter :372 ]train loss : 0.420030 ,train acc: 0.725037 ,val loss : 0.146297 ,val acc : 0.976257\n",
      "[ ecpho : 0  iter :373 ]train loss : 0.108754 ,train acc: 0.985168 ,val loss : 0.145966 ,val acc : 0.973419\n",
      "[ ecpho : 0  iter :374 ]train loss : 0.108461 ,train acc: 0.982727 ,val loss : 0.145396 ,val acc : 0.973328\n",
      "[ ecpho : 0  iter :375 ]train loss : 0.107438 ,train acc: 0.982147 ,val loss : 0.150876 ,val acc : 0.974152\n",
      "[ ecpho : 0  iter :376 ]train loss : 0.122973 ,train acc: 0.977692 ,val loss : 0.144877 ,val acc : 0.975800\n",
      "[ ecpho : 0  iter :377 ]train loss : 0.145787 ,train acc: 0.957123 ,val loss : 0.145868 ,val acc : 0.978943\n",
      "[ ecpho : 0  iter :378 ]train loss : 0.253076 ,train acc: 0.877045 ,val loss : 0.148019 ,val acc : 0.981445\n",
      "[ ecpho : 0  iter :379 ]train loss : 0.120089 ,train acc: 0.974854 ,val loss : 0.142890 ,val acc : 0.983704\n",
      "[ ecpho : 0  iter :380 ]train loss : 0.099136 ,train acc: 0.983917 ,val loss : 0.142853 ,val acc : 0.984528\n",
      "[ ecpho : 0  iter :381 ]train loss : 0.279307 ,train acc: 0.858643 ,val loss : 0.142379 ,val acc : 0.985718\n",
      "[ ecpho : 0  iter :382 ]train loss : 0.174652 ,train acc: 0.939148 ,val loss : 0.143076 ,val acc : 0.986481\n",
      "[ ecpho : 0  iter :383 ]train loss : 0.140150 ,train acc: 0.982910 ,val loss : 0.146500 ,val acc : 0.987183\n",
      "[ ecpho : 0  iter :384 ]train loss : 0.113447 ,train acc: 0.984222 ,val loss : 0.142660 ,val acc : 0.987671\n",
      "[ ecpho : 0  iter :385 ]train loss : 0.112408 ,train acc: 0.989655 ,val loss : 0.147657 ,val acc : 0.987793\n",
      "[ ecpho : 0  iter :386 ]train loss : 0.122638 ,train acc: 0.977478 ,val loss : 0.143894 ,val acc : 0.987885\n",
      "[ ecpho : 0  iter :387 ]train loss : 0.147385 ,train acc: 0.986847 ,val loss : 0.148974 ,val acc : 0.987091\n",
      "[ ecpho : 0  iter :388 ]train loss : 0.092616 ,train acc: 0.997131 ,val loss : 0.147035 ,val acc : 0.987549\n",
      "[ ecpho : 0  iter :389 ]train loss : 0.110835 ,train acc: 0.988312 ,val loss : 0.145439 ,val acc : 0.987335\n",
      "[ ecpho : 0  iter :390 ]train loss : 0.330981 ,train acc: 0.822205 ,val loss : 0.142637 ,val acc : 0.987152\n",
      "[ ecpho : 0  iter :391 ]train loss : 0.464481 ,train acc: 0.668030 ,val loss : 0.147935 ,val acc : 0.986145\n",
      "[ ecpho : 0  iter :392 ]train loss : 0.107898 ,train acc: 0.988861 ,val loss : 0.142903 ,val acc : 0.984863\n",
      "[ ecpho : 0  iter :393 ]train loss : 0.118282 ,train acc: 0.983368 ,val loss : 0.144759 ,val acc : 0.985260\n",
      "[ ecpho : 0  iter :394 ]train loss : 0.106609 ,train acc: 0.989716 ,val loss : 0.143963 ,val acc : 0.984528\n",
      "[ ecpho : 0  iter :395 ]train loss : 0.118665 ,train acc: 0.976868 ,val loss : 0.144767 ,val acc : 0.984314\n",
      "[ ecpho : 0  iter :396 ]train loss : 0.644839 ,train acc: 0.561340 ,val loss : 0.148734 ,val acc : 0.982910\n",
      "[ ecpho : 0  iter :397 ]train loss : 0.112155 ,train acc: 0.990173 ,val loss : 0.143074 ,val acc : 0.982452\n",
      "[ ecpho : 0  iter :398 ]train loss : 0.168928 ,train acc: 0.947754 ,val loss : 0.141953 ,val acc : 0.983246\n",
      "[ ecpho : 0  iter :399 ]train loss : 0.108352 ,train acc: 0.986267 ,val loss : 0.144920 ,val acc : 0.982513\n",
      "[ ecpho : 0  iter :400 ]train loss : 0.098888 ,train acc: 0.991608 ,val loss : 0.139145 ,val acc : 0.983246\n",
      "[ ecpho : 0  iter :401 ]train loss : 0.164683 ,train acc: 0.940247 ,val loss : 0.144167 ,val acc : 0.983765\n",
      "[ ecpho : 0  iter :402 ]train loss : 0.203439 ,train acc: 0.898865 ,val loss : 0.148402 ,val acc : 0.983002\n",
      "[ ecpho : 0  iter :403 ]train loss : 0.095995 ,train acc: 0.991913 ,val loss : 0.141865 ,val acc : 0.984070\n",
      "[ ecpho : 0  iter :404 ]train loss : 0.108147 ,train acc: 0.991089 ,val loss : 0.146484 ,val acc : 0.983521\n",
      "[ ecpho : 0  iter :405 ]train loss : 0.093128 ,train acc: 0.993256 ,val loss : 0.142797 ,val acc : 0.984650\n",
      "[ ecpho : 0  iter :406 ]train loss : 0.115590 ,train acc: 0.979279 ,val loss : 0.141553 ,val acc : 0.985382\n",
      "[ ecpho : 0  iter :407 ]train loss : 0.096732 ,train acc: 0.995239 ,val loss : 0.141686 ,val acc : 0.986115\n",
      "[ ecpho : 0  iter :408 ]train loss : 0.529036 ,train acc: 0.605103 ,val loss : 0.143947 ,val acc : 0.985626\n",
      "[ ecpho : 0  iter :409 ]train loss : 0.251005 ,train acc: 0.833862 ,val loss : 0.144958 ,val acc : 0.985992\n",
      "[ ecpho : 0  iter :410 ]train loss : 0.167838 ,train acc: 0.938232 ,val loss : 0.145344 ,val acc : 0.984497\n",
      "[ ecpho : 0  iter :411 ]train loss : 0.105717 ,train acc: 0.989929 ,val loss : 0.144243 ,val acc : 0.984924\n",
      "[ ecpho : 0  iter :412 ]train loss : 0.242421 ,train acc: 0.883789 ,val loss : 0.141981 ,val acc : 0.985107\n",
      "[ ecpho : 0  iter :413 ]train loss : 0.125045 ,train acc: 0.966431 ,val loss : 0.147045 ,val acc : 0.984100\n",
      "[ ecpho : 0  iter :414 ]train loss : 0.114917 ,train acc: 0.985809 ,val loss : 0.140929 ,val acc : 0.984894\n",
      "[ ecpho : 0  iter :415 ]train loss : 0.108672 ,train acc: 0.992371 ,val loss : 0.144287 ,val acc : 0.984436\n",
      "[ ecpho : 0  iter :416 ]train loss : 0.266808 ,train acc: 0.826996 ,val loss : 0.147209 ,val acc : 0.984222\n",
      "[ ecpho : 0  iter :417 ]train loss : 0.113444 ,train acc: 0.990234 ,val loss : 0.145571 ,val acc : 0.984833\n",
      "[ ecpho : 0  iter :418 ]train loss : 0.500221 ,train acc: 0.614471 ,val loss : 0.145284 ,val acc : 0.983459\n",
      "[ ecpho : 0  iter :419 ]train loss : 0.085602 ,train acc: 0.993805 ,val loss : 0.144243 ,val acc : 0.982880\n",
      "[ ecpho : 0  iter :420 ]train loss : 0.110890 ,train acc: 0.976440 ,val loss : 0.146507 ,val acc : 0.982910\n",
      "[ ecpho : 0  iter :421 ]train loss : 0.110063 ,train acc: 0.988159 ,val loss : 0.139701 ,val acc : 0.982330\n",
      "[ ecpho : 0  iter :422 ]train loss : 0.218168 ,train acc: 0.874237 ,val loss : 0.144016 ,val acc : 0.981873\n",
      "[ ecpho : 0  iter :423 ]train loss : 0.141832 ,train acc: 0.978241 ,val loss : 0.146600 ,val acc : 0.981689\n",
      "[ ecpho : 0  iter :424 ]train loss : 0.132592 ,train acc: 0.971924 ,val loss : 0.148584 ,val acc : 0.982880\n",
      "[ ecpho : 0  iter :425 ]train loss : 0.126329 ,train acc: 0.964630 ,val loss : 0.147278 ,val acc : 0.982605\n",
      "[ ecpho : 0  iter :426 ]train loss : 0.100206 ,train acc: 0.988129 ,val loss : 0.145633 ,val acc : 0.983215\n",
      "[ ecpho : 0  iter :427 ]train loss : 0.130947 ,train acc: 0.965149 ,val loss : 0.144336 ,val acc : 0.984100\n",
      "[ ecpho : 0  iter :428 ]train loss : 0.165837 ,train acc: 0.938477 ,val loss : 0.149994 ,val acc : 0.983917\n",
      "[ ecpho : 0  iter :429 ]train loss : 0.116088 ,train acc: 0.985413 ,val loss : 0.143312 ,val acc : 0.984558\n",
      "[ ecpho : 0  iter :430 ]train loss : 0.127488 ,train acc: 0.977325 ,val loss : 0.142371 ,val acc : 0.985168\n",
      "[ ecpho : 0  iter :431 ]train loss : 0.125154 ,train acc: 0.980652 ,val loss : 0.145032 ,val acc : 0.986389\n",
      "[ ecpho : 0  iter :432 ]train loss : 0.098836 ,train acc: 0.988617 ,val loss : 0.145608 ,val acc : 0.986633\n",
      "[ ecpho : 0  iter :433 ]train loss : 0.111055 ,train acc: 0.987335 ,val loss : 0.142062 ,val acc : 0.987823\n",
      "[ ecpho : 0  iter :434 ]train loss : 0.421225 ,train acc: 0.767151 ,val loss : 0.149774 ,val acc : 0.987427\n",
      "[ ecpho : 0  iter :435 ]train loss : 0.107647 ,train acc: 0.990784 ,val loss : 0.144169 ,val acc : 0.987427\n",
      "[ ecpho : 0  iter :436 ]train loss : 0.108617 ,train acc: 0.990936 ,val loss : 0.147267 ,val acc : 0.987549\n",
      "[ ecpho : 0  iter :437 ]train loss : 0.099724 ,train acc: 0.988403 ,val loss : 0.147009 ,val acc : 0.988159\n",
      "[ ecpho : 0  iter :438 ]train loss : 0.135720 ,train acc: 0.972443 ,val loss : 0.144978 ,val acc : 0.988251\n",
      "[ ecpho : 0  iter :439 ]train loss : 0.179520 ,train acc: 0.932098 ,val loss : 0.147086 ,val acc : 0.988037\n",
      "[ ecpho : 0  iter :440 ]train loss : 1.001114 ,train acc: 0.337097 ,val loss : 0.139735 ,val acc : 0.987915\n",
      "[ ecpho : 0  iter :441 ]train loss : 0.109895 ,train acc: 0.985291 ,val loss : 0.148466 ,val acc : 0.988617\n",
      "[ ecpho : 0  iter :442 ]train loss : 0.083983 ,train acc: 0.994751 ,val loss : 0.144550 ,val acc : 0.989319\n",
      "[ ecpho : 0  iter :443 ]train loss : 0.086758 ,train acc: 0.995270 ,val loss : 0.142599 ,val acc : 0.989136\n",
      "[ ecpho : 0  iter :444 ]train loss : 0.102053 ,train acc: 0.994904 ,val loss : 0.142653 ,val acc : 0.989166\n",
      "[ ecpho : 0  iter :445 ]train loss : 0.091471 ,train acc: 0.995361 ,val loss : 0.143385 ,val acc : 0.989166\n",
      "[ ecpho : 0  iter :446 ]train loss : 0.102343 ,train acc: 0.988129 ,val loss : 0.142577 ,val acc : 0.989197\n",
      "[ ecpho : 0  iter :447 ]train loss : 0.193058 ,train acc: 0.969116 ,val loss : 0.141884 ,val acc : 0.988647\n",
      "[ ecpho : 0  iter :448 ]train loss : 0.590719 ,train acc: 0.660217 ,val loss : 0.138403 ,val acc : 0.988983\n",
      "[ ecpho : 0  iter :449 ]train loss : 0.087431 ,train acc: 0.997040 ,val loss : 0.141107 ,val acc : 0.988831\n",
      "[ ecpho : 0  iter :450 ]train loss : 0.115490 ,train acc: 0.985291 ,val loss : 0.141999 ,val acc : 0.988464\n",
      "[ ecpho : 0  iter :451 ]train loss : 0.128152 ,train acc: 0.992310 ,val loss : 0.138734 ,val acc : 0.988159\n",
      "[ ecpho : 0  iter :452 ]train loss : 0.121986 ,train acc: 0.992523 ,val loss : 0.141201 ,val acc : 0.987457\n",
      "[ ecpho : 0  iter :453 ]train loss : 0.160648 ,train acc: 0.976074 ,val loss : 0.140082 ,val acc : 0.987457\n",
      "[ ecpho : 0  iter :454 ]train loss : 0.328149 ,train acc: 0.861969 ,val loss : 0.138931 ,val acc : 0.987671\n",
      "[ ecpho : 0  iter :455 ]train loss : 0.099667 ,train acc: 0.994690 ,val loss : 0.140963 ,val acc : 0.987274\n",
      "[ ecpho : 0  iter :456 ]train loss : 0.207989 ,train acc: 0.943695 ,val loss : 0.140487 ,val acc : 0.987640\n",
      "[ ecpho : 0  iter :457 ]train loss : 0.193659 ,train acc: 0.928802 ,val loss : 0.138243 ,val acc : 0.987396\n",
      "[ ecpho : 0  iter :458 ]train loss : 0.189578 ,train acc: 0.971863 ,val loss : 0.136454 ,val acc : 0.987671\n",
      "[ ecpho : 0  iter :459 ]train loss : 0.113217 ,train acc: 0.988434 ,val loss : 0.137797 ,val acc : 0.987732\n",
      "[ ecpho : 0  iter :460 ]train loss : 0.113724 ,train acc: 0.991272 ,val loss : 0.140504 ,val acc : 0.987915\n",
      "[ ecpho : 0  iter :461 ]train loss : 0.683328 ,train acc: 0.424866 ,val loss : 0.137529 ,val acc : 0.987457\n",
      "[ ecpho : 0  iter :462 ]train loss : 0.185112 ,train acc: 0.918488 ,val loss : 0.133802 ,val acc : 0.987030\n",
      "[ ecpho : 0  iter :463 ]train loss : 0.085136 ,train acc: 0.995270 ,val loss : 0.137326 ,val acc : 0.986633\n",
      "[ ecpho : 0  iter :464 ]train loss : 0.235747 ,train acc: 0.943817 ,val loss : 0.135547 ,val acc : 0.987366\n",
      "[ ecpho : 0  iter :465 ]train loss : 0.105581 ,train acc: 0.988831 ,val loss : 0.136549 ,val acc : 0.987091\n",
      "[ ecpho : 0  iter :466 ]train loss : 0.170506 ,train acc: 0.982269 ,val loss : 0.136681 ,val acc : 0.986816\n",
      "[ ecpho : 0  iter :467 ]train loss : 0.087262 ,train acc: 0.996613 ,val loss : 0.135152 ,val acc : 0.987366\n",
      "[ ecpho : 0  iter :468 ]train loss : 1.125161 ,train acc: 0.240173 ,val loss : 0.137108 ,val acc : 0.988190\n",
      "[ ecpho : 0  iter :469 ]train loss : 0.136150 ,train acc: 0.979095 ,val loss : 0.134439 ,val acc : 0.987518\n",
      "[ ecpho : 0  iter :470 ]train loss : 0.126477 ,train acc: 0.976044 ,val loss : 0.135594 ,val acc : 0.987732\n",
      "[ ecpho : 0  iter :471 ]train loss : 0.105607 ,train acc: 0.983948 ,val loss : 0.135545 ,val acc : 0.987823\n",
      "[ ecpho : 0  iter :472 ]train loss : 0.097101 ,train acc: 0.989868 ,val loss : 0.136431 ,val acc : 0.988037\n",
      "[ ecpho : 0  iter :473 ]train loss : 0.099499 ,train acc: 0.991394 ,val loss : 0.135988 ,val acc : 0.988251\n",
      "[ ecpho : 0  iter :474 ]train loss : 0.152692 ,train acc: 0.980286 ,val loss : 0.135693 ,val acc : 0.988403\n",
      "[ ecpho : 0  iter :475 ]train loss : 0.204226 ,train acc: 0.899567 ,val loss : 0.129784 ,val acc : 0.989288\n",
      "[ ecpho : 0  iter :476 ]train loss : 0.189790 ,train acc: 0.916473 ,val loss : 0.136086 ,val acc : 0.988220\n",
      "[ ecpho : 0  iter :477 ]train loss : 0.179334 ,train acc: 0.925049 ,val loss : 0.134038 ,val acc : 0.988892\n",
      "[ ecpho : 0  iter :478 ]train loss : 0.092272 ,train acc: 0.996948 ,val loss : 0.135824 ,val acc : 0.988922\n",
      "[ ecpho : 0  iter :479 ]train loss : 0.212861 ,train acc: 0.896301 ,val loss : 0.138163 ,val acc : 0.988098\n",
      "[ ecpho : 0  iter :480 ]train loss : 0.100276 ,train acc: 0.986694 ,val loss : 0.134124 ,val acc : 0.988251\n",
      "[ ecpho : 0  iter :481 ]train loss : 0.446050 ,train acc: 0.665039 ,val loss : 0.136489 ,val acc : 0.987976\n",
      "[ ecpho : 0  iter :482 ]train loss : 0.130911 ,train acc: 0.972412 ,val loss : 0.133431 ,val acc : 0.987396\n",
      "[ ecpho : 0  iter :483 ]train loss : 0.171990 ,train acc: 0.937012 ,val loss : 0.132542 ,val acc : 0.986298\n",
      "[ ecpho : 0  iter :484 ]train loss : 0.156631 ,train acc: 0.943909 ,val loss : 0.135745 ,val acc : 0.986633\n",
      "[ ecpho : 0  iter :485 ]train loss : 1.088288 ,train acc: 0.254822 ,val loss : 0.133311 ,val acc : 0.986572\n",
      "[ ecpho : 0  iter :486 ]train loss : 0.261337 ,train acc: 0.829742 ,val loss : 0.140083 ,val acc : 0.984283\n",
      "[ ecpho : 0  iter :487 ]train loss : 0.118458 ,train acc: 0.981720 ,val loss : 0.139914 ,val acc : 0.982300\n",
      "[ ecpho : 0  iter :488 ]train loss : 0.112863 ,train acc: 0.985931 ,val loss : 0.137117 ,val acc : 0.983032\n",
      "[ ecpho : 0  iter :489 ]train loss : 0.131238 ,train acc: 0.974792 ,val loss : 0.135710 ,val acc : 0.983734\n",
      "[ ecpho : 0  iter :490 ]train loss : 0.099082 ,train acc: 0.989075 ,val loss : 0.137350 ,val acc : 0.982971\n",
      "[ ecpho : 0  iter :491 ]train loss : 0.098630 ,train acc: 0.988464 ,val loss : 0.132573 ,val acc : 0.984009\n",
      "[ ecpho : 0  iter :492 ]train loss : 0.079412 ,train acc: 0.996216 ,val loss : 0.135431 ,val acc : 0.985016\n",
      "[ ecpho : 0  iter :493 ]train loss : 0.100257 ,train acc: 0.987946 ,val loss : 0.136368 ,val acc : 0.986084\n",
      "[ ecpho : 0  iter :494 ]train loss : 0.140627 ,train acc: 0.983612 ,val loss : 0.135877 ,val acc : 0.986359\n",
      "[ ecpho : 0  iter :495 ]train loss : 0.260317 ,train acc: 0.882507 ,val loss : 0.133906 ,val acc : 0.987488\n",
      "[ ecpho : 0  iter :496 ]train loss : 0.258517 ,train acc: 0.841888 ,val loss : 0.135224 ,val acc : 0.989014\n",
      "[ ecpho : 0  iter :497 ]train loss : 0.107861 ,train acc: 0.982269 ,val loss : 0.139255 ,val acc : 0.989838\n",
      "[ ecpho : 0  iter :498 ]train loss : 0.118833 ,train acc: 0.990723 ,val loss : 0.132109 ,val acc : 0.989197\n",
      "[ ecpho : 0  iter :499 ]train loss : 0.315878 ,train acc: 0.848785 ,val loss : 0.134567 ,val acc : 0.989075\n",
      "[ ecpho : 0  iter :500 ]train loss : 0.110698 ,train acc: 0.987671 ,val loss : 0.134131 ,val acc : 0.989532\n",
      "[ ecpho : 0  iter :501 ]train loss : 0.148222 ,train acc: 0.983246 ,val loss : 0.133056 ,val acc : 0.989349\n",
      "[ ecpho : 0  iter :502 ]train loss : 0.109493 ,train acc: 0.993866 ,val loss : 0.133974 ,val acc : 0.989197\n",
      "[ ecpho : 0  iter :503 ]train loss : 0.121382 ,train acc: 0.982391 ,val loss : 0.133478 ,val acc : 0.989655\n",
      "[ ecpho : 0  iter :504 ]train loss : 0.257321 ,train acc: 0.855865 ,val loss : 0.134149 ,val acc : 0.989655\n",
      "[ ecpho : 0  iter :505 ]train loss : 0.234767 ,train acc: 0.865967 ,val loss : 0.132948 ,val acc : 0.989014\n",
      "[ ecpho : 0  iter :506 ]train loss : 0.115514 ,train acc: 0.979828 ,val loss : 0.132989 ,val acc : 0.988953\n",
      "[ ecpho : 0  iter :507 ]train loss : 0.105928 ,train acc: 0.992889 ,val loss : 0.134259 ,val acc : 0.988312\n",
      "[ ecpho : 0  iter :508 ]train loss : 0.156098 ,train acc: 0.956451 ,val loss : 0.131114 ,val acc : 0.987915\n",
      "[ ecpho : 0  iter :509 ]train loss : 0.103992 ,train acc: 0.992950 ,val loss : 0.131514 ,val acc : 0.988770\n",
      "[ ecpho : 0  iter :510 ]train loss : 0.097341 ,train acc: 0.996124 ,val loss : 0.134844 ,val acc : 0.988068\n",
      "[ ecpho : 0  iter :511 ]train loss : 0.137413 ,train acc: 0.960236 ,val loss : 0.134936 ,val acc : 0.988342\n",
      "[ ecpho : 0  iter :512 ]train loss : 0.101745 ,train acc: 0.989502 ,val loss : 0.129234 ,val acc : 0.988800\n",
      "[ ecpho : 0  iter :513 ]train loss : 0.191501 ,train acc: 0.902069 ,val loss : 0.135838 ,val acc : 0.988342\n",
      "[ ecpho : 0  iter :514 ]train loss : 0.107794 ,train acc: 0.981445 ,val loss : 0.132623 ,val acc : 0.987976\n",
      "[ ecpho : 0  iter :515 ]train loss : 1.268484 ,train acc: 0.159698 ,val loss : 0.136771 ,val acc : 0.987061\n",
      "[ ecpho : 0  iter :516 ]train loss : 0.080486 ,train acc: 0.994812 ,val loss : 0.132046 ,val acc : 0.987244\n",
      "[ ecpho : 0  iter :517 ]train loss : 0.237653 ,train acc: 0.875946 ,val loss : 0.135639 ,val acc : 0.988434\n",
      "[ ecpho : 0  iter :518 ]train loss : 0.125214 ,train acc: 0.986481 ,val loss : 0.130473 ,val acc : 0.987885\n",
      "[ ecpho : 0  iter :519 ]train loss : 0.095500 ,train acc: 0.987854 ,val loss : 0.132529 ,val acc : 0.986969\n",
      "[ ecpho : 0  iter :520 ]train loss : 0.162166 ,train acc: 0.950806 ,val loss : 0.134016 ,val acc : 0.987701\n",
      "[ ecpho : 0  iter :521 ]train loss : 0.127567 ,train acc: 0.989594 ,val loss : 0.130217 ,val acc : 0.988098\n",
      "[ ecpho : 0  iter :522 ]train loss : 0.138879 ,train acc: 0.974609 ,val loss : 0.130243 ,val acc : 0.988678\n",
      "[ ecpho : 0  iter :523 ]train loss : 0.245571 ,train acc: 0.888977 ,val loss : 0.133451 ,val acc : 0.987732\n",
      "[ ecpho : 0  iter :524 ]train loss : 0.106233 ,train acc: 0.982727 ,val loss : 0.132792 ,val acc : 0.988220\n",
      "[ ecpho : 0  iter :525 ]train loss : 0.376368 ,train acc: 0.713104 ,val loss : 0.132601 ,val acc : 0.989136\n",
      "[ ecpho : 0  iter :526 ]train loss : 0.156361 ,train acc: 0.974854 ,val loss : 0.130314 ,val acc : 0.988831\n",
      "[ ecpho : 0  iter :527 ]train loss : 0.104317 ,train acc: 0.986420 ,val loss : 0.133817 ,val acc : 0.988373\n",
      "[ ecpho : 0  iter :528 ]train loss : 0.160128 ,train acc: 0.955017 ,val loss : 0.129937 ,val acc : 0.988739\n",
      "[ ecpho : 0  iter :529 ]train loss : 0.194593 ,train acc: 0.953735 ,val loss : 0.137161 ,val acc : 0.988464\n",
      "[ ecpho : 0  iter :530 ]train loss : 0.089797 ,train acc: 0.994873 ,val loss : 0.131878 ,val acc : 0.987976\n",
      "[ ecpho : 0  iter :531 ]train loss : 0.191095 ,train acc: 0.924835 ,val loss : 0.131782 ,val acc : 0.988678\n",
      "[ ecpho : 0  iter :532 ]train loss : 0.114425 ,train acc: 0.974335 ,val loss : 0.132340 ,val acc : 0.988037\n",
      "[ ecpho : 0  iter :533 ]train loss : 0.098983 ,train acc: 0.987305 ,val loss : 0.132869 ,val acc : 0.988678\n",
      "[ ecpho : 0  iter :534 ]train loss : 0.078623 ,train acc: 0.994324 ,val loss : 0.133170 ,val acc : 0.989624\n",
      "[ ecpho : 0  iter :535 ]train loss : 0.556306 ,train acc: 0.616821 ,val loss : 0.130975 ,val acc : 0.988892\n",
      "[ ecpho : 0  iter :536 ]train loss : 0.110080 ,train acc: 0.993347 ,val loss : 0.130865 ,val acc : 0.988342\n",
      "[ ecpho : 0  iter :537 ]train loss : 0.091863 ,train acc: 0.994873 ,val loss : 0.129936 ,val acc : 0.988556\n",
      "[ ecpho : 0  iter :538 ]train loss : 0.102226 ,train acc: 0.991394 ,val loss : 0.133197 ,val acc : 0.988708\n",
      "[ ecpho : 0  iter :539 ]train loss : 0.111893 ,train acc: 0.988556 ,val loss : 0.131366 ,val acc : 0.988251\n",
      "[ ecpho : 0  iter :540 ]train loss : 0.091269 ,train acc: 0.995911 ,val loss : 0.134897 ,val acc : 0.989044\n",
      "[ ecpho : 0  iter :541 ]train loss : 0.117526 ,train acc: 0.992493 ,val loss : 0.132301 ,val acc : 0.989197\n",
      "[ ecpho : 0  iter :542 ]train loss : 0.109637 ,train acc: 0.989960 ,val loss : 0.132540 ,val acc : 0.989380\n",
      "[ ecpho : 0  iter :543 ]train loss : 0.117493 ,train acc: 0.984467 ,val loss : 0.133502 ,val acc : 0.989319\n",
      "[ ecpho : 0  iter :544 ]train loss : 0.105840 ,train acc: 0.995667 ,val loss : 0.131484 ,val acc : 0.989746\n",
      "[ ecpho : 0  iter :545 ]train loss : 0.122183 ,train acc: 0.982239 ,val loss : 0.132371 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :546 ]train loss : 0.090597 ,train acc: 0.996552 ,val loss : 0.131530 ,val acc : 0.990509\n",
      "[ ecpho : 0  iter :547 ]train loss : 0.097551 ,train acc: 0.995361 ,val loss : 0.133571 ,val acc : 0.990021\n",
      "[ ecpho : 0  iter :548 ]train loss : 0.120988 ,train acc: 0.991394 ,val loss : 0.131253 ,val acc : 0.989380\n",
      "[ ecpho : 0  iter :549 ]train loss : 0.102579 ,train acc: 0.992767 ,val loss : 0.131925 ,val acc : 0.989532\n",
      "[ ecpho : 0  iter :550 ]train loss : 0.110304 ,train acc: 0.988953 ,val loss : 0.132176 ,val acc : 0.989746\n",
      "[ ecpho : 0  iter :551 ]train loss : 0.115503 ,train acc: 0.990692 ,val loss : 0.133617 ,val acc : 0.989746\n",
      "[ ecpho : 0  iter :552 ]train loss : 0.112684 ,train acc: 0.979004 ,val loss : 0.132415 ,val acc : 0.989563\n",
      "[ ecpho : 0  iter :553 ]train loss : 0.115846 ,train acc: 0.991791 ,val loss : 0.129857 ,val acc : 0.989655\n",
      "[ ecpho : 0  iter :554 ]train loss : 0.128831 ,train acc: 0.967804 ,val loss : 0.130883 ,val acc : 0.989716\n",
      "[ ecpho : 0  iter :555 ]train loss : 0.112535 ,train acc: 0.986694 ,val loss : 0.132217 ,val acc : 0.989319\n",
      "[ ecpho : 0  iter :556 ]train loss : 0.281353 ,train acc: 0.838409 ,val loss : 0.134532 ,val acc : 0.989655\n",
      "[ ecpho : 0  iter :557 ]train loss : 0.136787 ,train acc: 0.963867 ,val loss : 0.130825 ,val acc : 0.989319\n",
      "[ ecpho : 0  iter :558 ]train loss : 0.203619 ,train acc: 0.901672 ,val loss : 0.131183 ,val acc : 0.989502\n",
      "[ ecpho : 0  iter :559 ]train loss : 0.087240 ,train acc: 0.993927 ,val loss : 0.133630 ,val acc : 0.988922\n",
      "[ ecpho : 0  iter :560 ]train loss : 0.091417 ,train acc: 0.996155 ,val loss : 0.133257 ,val acc : 0.989136\n",
      "[ ecpho : 0  iter :561 ]train loss : 0.101623 ,train acc: 0.996155 ,val loss : 0.132451 ,val acc : 0.989136\n",
      "[ ecpho : 0  iter :562 ]train loss : 0.132410 ,train acc: 0.987366 ,val loss : 0.131854 ,val acc : 0.988556\n",
      "[ ecpho : 0  iter :563 ]train loss : 0.101047 ,train acc: 0.992767 ,val loss : 0.130371 ,val acc : 0.988922\n",
      "[ ecpho : 0  iter :564 ]train loss : 0.069340 ,train acc: 0.998596 ,val loss : 0.133132 ,val acc : 0.989288\n",
      "[ ecpho : 0  iter :565 ]train loss : 0.080555 ,train acc: 0.993958 ,val loss : 0.132143 ,val acc : 0.989563\n",
      "[ ecpho : 0  iter :566 ]train loss : 0.187122 ,train acc: 0.917084 ,val loss : 0.134167 ,val acc : 0.988800\n",
      "[ ecpho : 0  iter :567 ]train loss : 0.095848 ,train acc: 0.985687 ,val loss : 0.133675 ,val acc : 0.989716\n",
      "[ ecpho : 0  iter :568 ]train loss : 0.123662 ,train acc: 0.982117 ,val loss : 0.133283 ,val acc : 0.989594\n",
      "[ ecpho : 0  iter :569 ]train loss : 0.101546 ,train acc: 0.991425 ,val loss : 0.132103 ,val acc : 0.989777\n",
      "[ ecpho : 0  iter :570 ]train loss : 0.106453 ,train acc: 0.996033 ,val loss : 0.132953 ,val acc : 0.989563\n",
      "[ ecpho : 0  iter :571 ]train loss : 0.119326 ,train acc: 0.967133 ,val loss : 0.132677 ,val acc : 0.989471\n",
      "[ ecpho : 0  iter :572 ]train loss : 0.158364 ,train acc: 0.976959 ,val loss : 0.134660 ,val acc : 0.990540\n",
      "[ ecpho : 0  iter :573 ]train loss : 0.375381 ,train acc: 0.725098 ,val loss : 0.131671 ,val acc : 0.990417\n",
      "[ ecpho : 0  iter :574 ]train loss : 0.145136 ,train acc: 0.960327 ,val loss : 0.133634 ,val acc : 0.990417\n",
      "[ ecpho : 0  iter :575 ]train loss : 0.125328 ,train acc: 0.990662 ,val loss : 0.134722 ,val acc : 0.989410\n",
      "[ ecpho : 0  iter :576 ]train loss : 0.960459 ,train acc: 0.347412 ,val loss : 0.129938 ,val acc : 0.990479\n",
      "[ ecpho : 0  iter :577 ]train loss : 0.139111 ,train acc: 0.984009 ,val loss : 0.129810 ,val acc : 0.990204\n",
      "[ ecpho : 0  iter :578 ]train loss : 0.134448 ,train acc: 0.967438 ,val loss : 0.135314 ,val acc : 0.989655\n",
      "[ ecpho : 0  iter :579 ]train loss : 0.211398 ,train acc: 0.940918 ,val loss : 0.135024 ,val acc : 0.990051\n",
      "[ ecpho : 0  iter :580 ]train loss : 0.120243 ,train acc: 0.993713 ,val loss : 0.129182 ,val acc : 0.990143\n",
      "[ ecpho : 0  iter :581 ]train loss : 0.089721 ,train acc: 0.996765 ,val loss : 0.132439 ,val acc : 0.990479\n",
      "[ ecpho : 0  iter :582 ]train loss : 0.097195 ,train acc: 0.991608 ,val loss : 0.129436 ,val acc : 0.990356\n",
      "[ ecpho : 0  iter :583 ]train loss : 0.667252 ,train acc: 0.507294 ,val loss : 0.128887 ,val acc : 0.989502\n",
      "[ ecpho : 0  iter :584 ]train loss : 0.103354 ,train acc: 0.996521 ,val loss : 0.128166 ,val acc : 0.989441\n",
      "[ ecpho : 0  iter :585 ]train loss : 0.102892 ,train acc: 0.996185 ,val loss : 0.129429 ,val acc : 0.989716\n",
      "[ ecpho : 0  iter :586 ]train loss : 0.108442 ,train acc: 0.995392 ,val loss : 0.127562 ,val acc : 0.989624\n",
      "[ ecpho : 0  iter :587 ]train loss : 0.130292 ,train acc: 0.970673 ,val loss : 0.128217 ,val acc : 0.989044\n",
      "[ ecpho : 0  iter :588 ]train loss : 0.102161 ,train acc: 0.996094 ,val loss : 0.130544 ,val acc : 0.989746\n",
      "[ ecpho : 0  iter :589 ]train loss : 0.101114 ,train acc: 0.988678 ,val loss : 0.126975 ,val acc : 0.990112\n",
      "[ ecpho : 0  iter :590 ]train loss : 0.095387 ,train acc: 0.990997 ,val loss : 0.126959 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :591 ]train loss : 0.220304 ,train acc: 0.944244 ,val loss : 0.126575 ,val acc : 0.990845\n",
      "[ ecpho : 0  iter :592 ]train loss : 0.125603 ,train acc: 0.980499 ,val loss : 0.125285 ,val acc : 0.989716\n",
      "[ ecpho : 0  iter :593 ]train loss : 0.101309 ,train acc: 0.993774 ,val loss : 0.130040 ,val acc : 0.990021\n",
      "[ ecpho : 0  iter :594 ]train loss : 0.106431 ,train acc: 0.992920 ,val loss : 0.130445 ,val acc : 0.990601\n",
      "[ ecpho : 0  iter :595 ]train loss : 0.108277 ,train acc: 0.991394 ,val loss : 0.129226 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :596 ]train loss : 0.088443 ,train acc: 0.997131 ,val loss : 0.127606 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :597 ]train loss : 0.094404 ,train acc: 0.991882 ,val loss : 0.125141 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :598 ]train loss : 0.103898 ,train acc: 0.985443 ,val loss : 0.125464 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :599 ]train loss : 0.122704 ,train acc: 0.972809 ,val loss : 0.125434 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :600 ]train loss : 0.131202 ,train acc: 0.980103 ,val loss : 0.130411 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :601 ]train loss : 0.126343 ,train acc: 0.986694 ,val loss : 0.128072 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :602 ]train loss : 0.383296 ,train acc: 0.747223 ,val loss : 0.126664 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :603 ]train loss : 0.109724 ,train acc: 0.985168 ,val loss : 0.124290 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :604 ]train loss : 0.081827 ,train acc: 0.997559 ,val loss : 0.125030 ,val acc : 0.991180\n",
      "[ ecpho : 0  iter :605 ]train loss : 0.099413 ,train acc: 0.992462 ,val loss : 0.125286 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :606 ]train loss : 0.117134 ,train acc: 0.969788 ,val loss : 0.126661 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :607 ]train loss : 0.086692 ,train acc: 0.997925 ,val loss : 0.127582 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :608 ]train loss : 0.106008 ,train acc: 0.987457 ,val loss : 0.124962 ,val acc : 0.991272\n",
      "[ ecpho : 0  iter :609 ]train loss : 0.288679 ,train acc: 0.848938 ,val loss : 0.130492 ,val acc : 0.990540\n",
      "[ ecpho : 0  iter :610 ]train loss : 0.138128 ,train acc: 0.963013 ,val loss : 0.126826 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :611 ]train loss : 0.119732 ,train acc: 0.992432 ,val loss : 0.125063 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :612 ]train loss : 0.096657 ,train acc: 0.995819 ,val loss : 0.125586 ,val acc : 0.990540\n",
      "[ ecpho : 0  iter :613 ]train loss : 0.149511 ,train acc: 0.953979 ,val loss : 0.125143 ,val acc : 0.990570\n",
      "[ ecpho : 0  iter :614 ]train loss : 0.097467 ,train acc: 0.993134 ,val loss : 0.126687 ,val acc : 0.989960\n",
      "[ ecpho : 0  iter :615 ]train loss : 0.087629 ,train acc: 0.996094 ,val loss : 0.127279 ,val acc : 0.990234\n",
      "[ ecpho : 0  iter :616 ]train loss : 0.102263 ,train acc: 0.995209 ,val loss : 0.123249 ,val acc : 0.990662\n",
      "[ ecpho : 0  iter :617 ]train loss : 0.080520 ,train acc: 0.996521 ,val loss : 0.127919 ,val acc : 0.990112\n",
      "[ ecpho : 0  iter :618 ]train loss : 0.108910 ,train acc: 0.995148 ,val loss : 0.127739 ,val acc : 0.989777\n",
      "[ ecpho : 0  iter :619 ]train loss : 0.089135 ,train acc: 0.993286 ,val loss : 0.127810 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :620 ]train loss : 0.135392 ,train acc: 0.980499 ,val loss : 0.128017 ,val acc : 0.990479\n",
      "[ ecpho : 0  iter :621 ]train loss : 0.112001 ,train acc: 0.995087 ,val loss : 0.124032 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :622 ]train loss : 0.108825 ,train acc: 0.987976 ,val loss : 0.128714 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :623 ]train loss : 0.102377 ,train acc: 0.990265 ,val loss : 0.126661 ,val acc : 0.990753\n",
      "[ ecpho : 0  iter :624 ]train loss : 0.094815 ,train acc: 0.997406 ,val loss : 0.126756 ,val acc : 0.990967\n",
      "[ ecpho : 0  iter :625 ]train loss : 0.102547 ,train acc: 0.990692 ,val loss : 0.127108 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :626 ]train loss : 0.118277 ,train acc: 0.995850 ,val loss : 0.125858 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :627 ]train loss : 0.102986 ,train acc: 0.996460 ,val loss : 0.126689 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :628 ]train loss : 0.090804 ,train acc: 0.989868 ,val loss : 0.126222 ,val acc : 0.990601\n",
      "[ ecpho : 0  iter :629 ]train loss : 0.251249 ,train acc: 0.868561 ,val loss : 0.123285 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :630 ]train loss : 0.476559 ,train acc: 0.614838 ,val loss : 0.123932 ,val acc : 0.990601\n",
      "[ ecpho : 0  iter :631 ]train loss : 0.381184 ,train acc: 0.723694 ,val loss : 0.125686 ,val acc : 0.990906\n",
      "[ ecpho : 0  iter :632 ]train loss : 0.074334 ,train acc: 0.998260 ,val loss : 0.126655 ,val acc : 0.990356\n",
      "[ ecpho : 0  iter :633 ]train loss : 0.116169 ,train acc: 0.975494 ,val loss : 0.127592 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :634 ]train loss : 0.102359 ,train acc: 0.993073 ,val loss : 0.126574 ,val acc : 0.989899\n",
      "[ ecpho : 0  iter :635 ]train loss : 0.408170 ,train acc: 0.750183 ,val loss : 0.123295 ,val acc : 0.990082\n",
      "[ ecpho : 0  iter :636 ]train loss : 0.156005 ,train acc: 0.967072 ,val loss : 0.126306 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :637 ]train loss : 0.241602 ,train acc: 0.909668 ,val loss : 0.128625 ,val acc : 0.989105\n",
      "[ ecpho : 0  iter :638 ]train loss : 0.117620 ,train acc: 0.978455 ,val loss : 0.125826 ,val acc : 0.989166\n",
      "[ ecpho : 0  iter :639 ]train loss : 0.255570 ,train acc: 0.893158 ,val loss : 0.128098 ,val acc : 0.988831\n",
      "[ ecpho : 0  iter :640 ]train loss : 0.122736 ,train acc: 0.991180 ,val loss : 0.128872 ,val acc : 0.989105\n",
      "[ ecpho : 0  iter :641 ]train loss : 0.169118 ,train acc: 0.978729 ,val loss : 0.128826 ,val acc : 0.989594\n",
      "[ ecpho : 0  iter :642 ]train loss : 0.102495 ,train acc: 0.987579 ,val loss : 0.125516 ,val acc : 0.989502\n",
      "[ ecpho : 0  iter :643 ]train loss : 0.256834 ,train acc: 0.908752 ,val loss : 0.129475 ,val acc : 0.989532\n",
      "[ ecpho : 0  iter :644 ]train loss : 0.105575 ,train acc: 0.988586 ,val loss : 0.128279 ,val acc : 0.989960\n",
      "[ ecpho : 0  iter :645 ]train loss : 0.286885 ,train acc: 0.866913 ,val loss : 0.124327 ,val acc : 0.989655\n",
      "[ ecpho : 0  iter :646 ]train loss : 0.120147 ,train acc: 0.969391 ,val loss : 0.125870 ,val acc : 0.989990\n",
      "[ ecpho : 0  iter :647 ]train loss : 0.112020 ,train acc: 0.994110 ,val loss : 0.127122 ,val acc : 0.990173\n",
      "[ ecpho : 0  iter :648 ]train loss : 0.251373 ,train acc: 0.859589 ,val loss : 0.131717 ,val acc : 0.989838\n",
      "[ ecpho : 0  iter :649 ]train loss : 0.100123 ,train acc: 0.992249 ,val loss : 0.129282 ,val acc : 0.990082\n",
      "[ ecpho : 0  iter :650 ]train loss : 0.417358 ,train acc: 0.794830 ,val loss : 0.123677 ,val acc : 0.990662\n",
      "[ ecpho : 0  iter :651 ]train loss : 0.125181 ,train acc: 0.989929 ,val loss : 0.127498 ,val acc : 0.990601\n",
      "[ ecpho : 0  iter :652 ]train loss : 0.127033 ,train acc: 0.987366 ,val loss : 0.122901 ,val acc : 0.990356\n",
      "[ ecpho : 0  iter :653 ]train loss : 0.086094 ,train acc: 0.997528 ,val loss : 0.125357 ,val acc : 0.990662\n",
      "[ ecpho : 0  iter :654 ]train loss : 0.082427 ,train acc: 0.996918 ,val loss : 0.126806 ,val acc : 0.990479\n",
      "[ ecpho : 0  iter :655 ]train loss : 0.087307 ,train acc: 0.998322 ,val loss : 0.126151 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :656 ]train loss : 0.136680 ,train acc: 0.958740 ,val loss : 0.125072 ,val acc : 0.990967\n",
      "[ ecpho : 0  iter :657 ]train loss : 0.103688 ,train acc: 0.982758 ,val loss : 0.122415 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :658 ]train loss : 0.119161 ,train acc: 0.976837 ,val loss : 0.125058 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :659 ]train loss : 0.110299 ,train acc: 0.996826 ,val loss : 0.125144 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :660 ]train loss : 0.379114 ,train acc: 0.731659 ,val loss : 0.130421 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :661 ]train loss : 0.109931 ,train acc: 0.981201 ,val loss : 0.126951 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :662 ]train loss : 0.154660 ,train acc: 0.971497 ,val loss : 0.125520 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :663 ]train loss : 0.159471 ,train acc: 0.981842 ,val loss : 0.125128 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :664 ]train loss : 0.130680 ,train acc: 0.983643 ,val loss : 0.124800 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :665 ]train loss : 0.068236 ,train acc: 0.997803 ,val loss : 0.126140 ,val acc : 0.990723\n",
      "[ ecpho : 0  iter :666 ]train loss : 0.170650 ,train acc: 0.964752 ,val loss : 0.124783 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :667 ]train loss : 0.726378 ,train acc: 0.478577 ,val loss : 0.123589 ,val acc : 0.990967\n",
      "[ ecpho : 0  iter :668 ]train loss : 0.103838 ,train acc: 0.982452 ,val loss : 0.125200 ,val acc : 0.990570\n",
      "[ ecpho : 0  iter :669 ]train loss : 0.419547 ,train acc: 0.733276 ,val loss : 0.121973 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :670 ]train loss : 0.092056 ,train acc: 0.991669 ,val loss : 0.128568 ,val acc : 0.989929\n",
      "[ ecpho : 0  iter :671 ]train loss : 0.170853 ,train acc: 0.928009 ,val loss : 0.126327 ,val acc : 0.989807\n",
      "[ ecpho : 0  iter :672 ]train loss : 0.412929 ,train acc: 0.715973 ,val loss : 0.122486 ,val acc : 0.990417\n",
      "[ ecpho : 0  iter :673 ]train loss : 0.298176 ,train acc: 0.827820 ,val loss : 0.123546 ,val acc : 0.988800\n",
      "[ ecpho : 0  iter :674 ]train loss : 0.088181 ,train acc: 0.992096 ,val loss : 0.124869 ,val acc : 0.988403\n",
      "[ ecpho : 0  iter :675 ]train loss : 0.829324 ,train acc: 0.402771 ,val loss : 0.126914 ,val acc : 0.988831\n",
      "[ ecpho : 0  iter :676 ]train loss : 0.175034 ,train acc: 0.933533 ,val loss : 0.127748 ,val acc : 0.987762\n",
      "[ ecpho : 0  iter :677 ]train loss : 0.097336 ,train acc: 0.992462 ,val loss : 0.127575 ,val acc : 0.987030\n",
      "[ ecpho : 0  iter :678 ]train loss : 0.100700 ,train acc: 0.989166 ,val loss : 0.126805 ,val acc : 0.987183\n",
      "[ ecpho : 0  iter :679 ]train loss : 0.122303 ,train acc: 0.972900 ,val loss : 0.125291 ,val acc : 0.987701\n",
      "[ ecpho : 0  iter :680 ]train loss : 0.101894 ,train acc: 0.990662 ,val loss : 0.126657 ,val acc : 0.988190\n",
      "[ ecpho : 0  iter :681 ]train loss : 0.080986 ,train acc: 0.995117 ,val loss : 0.126053 ,val acc : 0.988220\n",
      "[ ecpho : 0  iter :682 ]train loss : 1.165773 ,train acc: 0.200226 ,val loss : 0.126745 ,val acc : 0.988770\n",
      "[ ecpho : 0  iter :683 ]train loss : 0.149891 ,train acc: 0.955963 ,val loss : 0.129366 ,val acc : 0.988678\n",
      "[ ecpho : 0  iter :684 ]train loss : 0.090229 ,train acc: 0.995605 ,val loss : 0.127498 ,val acc : 0.988556\n",
      "[ ecpho : 0  iter :685 ]train loss : 0.081046 ,train acc: 0.996552 ,val loss : 0.125821 ,val acc : 0.989441\n",
      "[ ecpho : 0  iter :686 ]train loss : 0.123210 ,train acc: 0.990387 ,val loss : 0.130653 ,val acc : 0.988525\n",
      "[ ecpho : 0  iter :687 ]train loss : 0.098649 ,train acc: 0.985596 ,val loss : 0.129211 ,val acc : 0.989807\n",
      "[ ecpho : 0  iter :688 ]train loss : 0.457887 ,train acc: 0.731506 ,val loss : 0.131986 ,val acc : 0.989441\n",
      "[ ecpho : 0  iter :689 ]train loss : 0.090115 ,train acc: 0.993164 ,val loss : 0.132353 ,val acc : 0.990723\n",
      "[ ecpho : 0  iter :690 ]train loss : 0.121076 ,train acc: 0.981689 ,val loss : 0.128227 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :691 ]train loss : 0.124026 ,train acc: 0.984283 ,val loss : 0.128064 ,val acc : 0.990173\n",
      "[ ecpho : 0  iter :692 ]train loss : 0.098865 ,train acc: 0.984161 ,val loss : 0.130628 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :693 ]train loss : 0.093294 ,train acc: 0.993164 ,val loss : 0.127973 ,val acc : 0.991394\n",
      "[ ecpho : 0  iter :694 ]train loss : 0.129154 ,train acc: 0.972626 ,val loss : 0.127602 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :695 ]train loss : 0.122665 ,train acc: 0.985565 ,val loss : 0.125581 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :696 ]train loss : 0.460927 ,train acc: 0.660278 ,val loss : 0.128331 ,val acc : 0.991302\n",
      "[ ecpho : 0  iter :697 ]train loss : 0.073733 ,train acc: 0.997711 ,val loss : 0.129126 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :698 ]train loss : 1.378748 ,train acc: 0.024017 ,val loss : 0.129224 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :699 ]train loss : 0.174911 ,train acc: 0.967102 ,val loss : 0.131589 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :700 ]train loss : 0.123922 ,train acc: 0.973755 ,val loss : 0.128558 ,val acc : 0.990692\n",
      "[ ecpho : 0  iter :701 ]train loss : 0.102768 ,train acc: 0.991791 ,val loss : 0.129851 ,val acc : 0.990540\n",
      "[ ecpho : 0  iter :702 ]train loss : 0.143990 ,train acc: 0.977356 ,val loss : 0.131515 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :703 ]train loss : 0.170978 ,train acc: 0.957184 ,val loss : 0.128746 ,val acc : 0.990906\n",
      "[ ecpho : 0  iter :704 ]train loss : 0.153606 ,train acc: 0.980377 ,val loss : 0.129737 ,val acc : 0.990753\n",
      "[ ecpho : 0  iter :705 ]train loss : 0.103567 ,train acc: 0.980927 ,val loss : 0.127040 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :706 ]train loss : 0.083506 ,train acc: 0.996155 ,val loss : 0.131563 ,val acc : 0.990326\n",
      "[ ecpho : 0  iter :707 ]train loss : 0.124749 ,train acc: 0.976715 ,val loss : 0.130213 ,val acc : 0.990509\n",
      "[ ecpho : 0  iter :708 ]train loss : 0.113472 ,train acc: 0.973175 ,val loss : 0.128225 ,val acc : 0.990234\n",
      "[ ecpho : 0  iter :709 ]train loss : 0.109303 ,train acc: 0.993134 ,val loss : 0.129725 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :710 ]train loss : 0.096289 ,train acc: 0.995026 ,val loss : 0.126047 ,val acc : 0.990540\n",
      "[ ecpho : 0  iter :711 ]train loss : 0.169837 ,train acc: 0.925079 ,val loss : 0.130211 ,val acc : 0.990509\n",
      "[ ecpho : 0  iter :712 ]train loss : 0.621484 ,train acc: 0.725372 ,val loss : 0.130430 ,val acc : 0.990723\n",
      "[ ecpho : 0  iter :713 ]train loss : 0.133113 ,train acc: 0.968933 ,val loss : 0.129669 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :714 ]train loss : 0.112486 ,train acc: 0.974579 ,val loss : 0.130786 ,val acc : 0.990204\n",
      "[ ecpho : 0  iter :715 ]train loss : 0.129492 ,train acc: 0.985962 ,val loss : 0.126109 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :716 ]train loss : 0.104291 ,train acc: 0.986633 ,val loss : 0.128797 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :717 ]train loss : 0.110039 ,train acc: 0.989105 ,val loss : 0.124754 ,val acc : 0.990631\n",
      "[ ecpho : 0  iter :718 ]train loss : 0.111623 ,train acc: 0.990997 ,val loss : 0.130931 ,val acc : 0.990692\n",
      "[ ecpho : 0  iter :719 ]train loss : 0.110607 ,train acc: 0.991150 ,val loss : 0.127944 ,val acc : 0.990753\n",
      "[ ecpho : 0  iter :720 ]train loss : 0.094076 ,train acc: 0.994659 ,val loss : 0.129052 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :721 ]train loss : 0.133260 ,train acc: 0.987030 ,val loss : 0.129250 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :722 ]train loss : 0.103662 ,train acc: 0.981354 ,val loss : 0.128184 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :723 ]train loss : 0.090018 ,train acc: 0.996094 ,val loss : 0.127290 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :724 ]train loss : 0.097750 ,train acc: 0.997345 ,val loss : 0.126502 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :725 ]train loss : 0.131842 ,train acc: 0.983582 ,val loss : 0.124672 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :726 ]train loss : 0.090161 ,train acc: 0.989716 ,val loss : 0.124482 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :727 ]train loss : 0.099264 ,train acc: 0.982483 ,val loss : 0.127505 ,val acc : 0.991638\n",
      "[ ecpho : 0  iter :728 ]train loss : 0.388522 ,train acc: 0.742096 ,val loss : 0.125553 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :729 ]train loss : 0.106751 ,train acc: 0.996368 ,val loss : 0.127719 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :730 ]train loss : 0.105541 ,train acc: 0.980560 ,val loss : 0.126653 ,val acc : 0.990631\n",
      "[ ecpho : 0  iter :731 ]train loss : 0.133873 ,train acc: 0.986237 ,val loss : 0.125327 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :732 ]train loss : 0.112112 ,train acc: 0.996185 ,val loss : 0.124146 ,val acc : 0.990845\n",
      "[ ecpho : 0  iter :733 ]train loss : 0.100813 ,train acc: 0.993378 ,val loss : 0.127627 ,val acc : 0.990845\n",
      "[ ecpho : 0  iter :734 ]train loss : 0.107328 ,train acc: 0.985138 ,val loss : 0.128678 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :735 ]train loss : 0.116627 ,train acc: 0.970581 ,val loss : 0.129066 ,val acc : 0.990906\n",
      "[ ecpho : 0  iter :736 ]train loss : 0.108688 ,train acc: 0.986542 ,val loss : 0.126260 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :737 ]train loss : 0.119206 ,train acc: 0.969757 ,val loss : 0.122635 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :738 ]train loss : 0.097785 ,train acc: 0.993164 ,val loss : 0.128910 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :739 ]train loss : 0.106902 ,train acc: 0.985962 ,val loss : 0.129587 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :740 ]train loss : 0.080059 ,train acc: 0.994019 ,val loss : 0.124602 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :741 ]train loss : 0.090349 ,train acc: 0.996277 ,val loss : 0.128923 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :742 ]train loss : 0.079480 ,train acc: 0.997284 ,val loss : 0.124859 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :743 ]train loss : 0.187465 ,train acc: 0.920288 ,val loss : 0.124397 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :744 ]train loss : 0.096202 ,train acc: 0.996826 ,val loss : 0.125234 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :745 ]train loss : 0.210553 ,train acc: 0.947205 ,val loss : 0.127628 ,val acc : 0.991425\n",
      "[ ecpho : 0  iter :746 ]train loss : 0.122023 ,train acc: 0.967285 ,val loss : 0.124550 ,val acc : 0.991364\n",
      "[ ecpho : 0  iter :747 ]train loss : 0.173605 ,train acc: 0.924072 ,val loss : 0.123324 ,val acc : 0.991760\n",
      "[ ecpho : 0  iter :748 ]train loss : 0.661518 ,train acc: 0.605103 ,val loss : 0.126440 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :749 ]train loss : 0.110698 ,train acc: 0.984192 ,val loss : 0.126526 ,val acc : 0.991638\n",
      "[ ecpho : 0  iter :750 ]train loss : 0.086894 ,train acc: 0.995148 ,val loss : 0.128027 ,val acc : 0.990845\n",
      "[ ecpho : 0  iter :751 ]train loss : 0.106664 ,train acc: 0.976685 ,val loss : 0.123309 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :752 ]train loss : 0.112589 ,train acc: 0.993927 ,val loss : 0.124445 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :753 ]train loss : 0.189524 ,train acc: 0.905975 ,val loss : 0.125094 ,val acc : 0.990692\n",
      "[ ecpho : 0  iter :754 ]train loss : 0.104685 ,train acc: 0.996735 ,val loss : 0.123916 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :755 ]train loss : 0.100121 ,train acc: 0.991638 ,val loss : 0.124983 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :756 ]train loss : 0.092793 ,train acc: 0.995972 ,val loss : 0.124995 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :757 ]train loss : 0.104989 ,train acc: 0.982147 ,val loss : 0.124824 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :758 ]train loss : 0.086509 ,train acc: 0.994751 ,val loss : 0.125804 ,val acc : 0.991302\n",
      "[ ecpho : 0  iter :759 ]train loss : 0.144669 ,train acc: 0.970428 ,val loss : 0.122908 ,val acc : 0.990692\n",
      "[ ecpho : 0  iter :760 ]train loss : 0.093710 ,train acc: 0.990814 ,val loss : 0.124616 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :761 ]train loss : 0.122581 ,train acc: 0.977173 ,val loss : 0.123400 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :762 ]train loss : 0.231029 ,train acc: 0.926392 ,val loss : 0.122373 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :763 ]train loss : 0.086250 ,train acc: 0.993256 ,val loss : 0.126199 ,val acc : 0.991150\n",
      "[ ecpho : 0  iter :764 ]train loss : 0.121000 ,train acc: 0.980133 ,val loss : 0.124907 ,val acc : 0.991913\n",
      "[ ecpho : 0  iter :765 ]train loss : 0.127456 ,train acc: 0.974792 ,val loss : 0.124389 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :766 ]train loss : 0.151699 ,train acc: 0.975403 ,val loss : 0.121252 ,val acc : 0.991943\n",
      "[ ecpho : 0  iter :767 ]train loss : 0.149479 ,train acc: 0.963654 ,val loss : 0.126819 ,val acc : 0.992004\n",
      "[ ecpho : 0  iter :768 ]train loss : 0.324174 ,train acc: 0.919312 ,val loss : 0.122429 ,val acc : 0.991730\n",
      "[ ecpho : 0  iter :769 ]train loss : 0.103398 ,train acc: 0.983307 ,val loss : 0.120446 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :770 ]train loss : 0.076003 ,train acc: 0.997925 ,val loss : 0.118322 ,val acc : 0.992157\n",
      "[ ecpho : 0  iter :771 ]train loss : 0.141065 ,train acc: 0.967102 ,val loss : 0.122377 ,val acc : 0.991882\n",
      "[ ecpho : 0  iter :772 ]train loss : 0.083282 ,train acc: 0.996979 ,val loss : 0.120679 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :773 ]train loss : 0.071119 ,train acc: 0.998413 ,val loss : 0.120187 ,val acc : 0.992004\n",
      "[ ecpho : 0  iter :774 ]train loss : 0.086774 ,train acc: 0.990234 ,val loss : 0.123171 ,val acc : 0.991974\n",
      "[ ecpho : 0  iter :775 ]train loss : 0.075405 ,train acc: 0.996246 ,val loss : 0.120510 ,val acc : 0.991913\n",
      "[ ecpho : 0  iter :776 ]train loss : 0.099812 ,train acc: 0.988647 ,val loss : 0.122951 ,val acc : 0.992096\n",
      "[ ecpho : 0  iter :777 ]train loss : 0.094415 ,train acc: 0.994385 ,val loss : 0.122161 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :778 ]train loss : 0.085204 ,train acc: 0.994110 ,val loss : 0.118762 ,val acc : 0.992126\n",
      "[ ecpho : 0  iter :779 ]train loss : 0.087728 ,train acc: 0.998169 ,val loss : 0.120512 ,val acc : 0.991638\n",
      "[ ecpho : 0  iter :780 ]train loss : 0.089801 ,train acc: 0.993530 ,val loss : 0.120463 ,val acc : 0.992401\n",
      "[ ecpho : 0  iter :781 ]train loss : 0.107226 ,train acc: 0.989777 ,val loss : 0.120226 ,val acc : 0.992004\n",
      "[ ecpho : 0  iter :782 ]train loss : 0.139237 ,train acc: 0.957214 ,val loss : 0.119200 ,val acc : 0.992126\n",
      "[ ecpho : 0  iter :783 ]train loss : 0.113389 ,train acc: 0.995605 ,val loss : 0.121367 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :784 ]train loss : 0.112242 ,train acc: 0.992798 ,val loss : 0.119978 ,val acc : 0.992401\n",
      "[ ecpho : 0  iter :785 ]train loss : 0.248755 ,train acc: 0.925446 ,val loss : 0.124305 ,val acc : 0.992096\n",
      "[ ecpho : 0  iter :786 ]train loss : 0.484496 ,train acc: 0.637878 ,val loss : 0.118059 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :787 ]train loss : 0.073515 ,train acc: 0.998779 ,val loss : 0.121462 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :788 ]train loss : 0.097071 ,train acc: 0.991852 ,val loss : 0.119804 ,val acc : 0.990723\n",
      "[ ecpho : 0  iter :789 ]train loss : 0.084503 ,train acc: 0.994507 ,val loss : 0.121693 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :790 ]train loss : 0.092640 ,train acc: 0.994171 ,val loss : 0.123813 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :791 ]train loss : 0.123425 ,train acc: 0.971252 ,val loss : 0.122567 ,val acc : 0.991302\n",
      "[ ecpho : 0  iter :792 ]train loss : 0.087659 ,train acc: 0.997681 ,val loss : 0.123196 ,val acc : 0.990570\n",
      "[ ecpho : 0  iter :793 ]train loss : 0.133792 ,train acc: 0.989868 ,val loss : 0.122735 ,val acc : 0.991180\n",
      "[ ecpho : 0  iter :794 ]train loss : 0.112091 ,train acc: 0.988037 ,val loss : 0.121705 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :795 ]train loss : 0.158876 ,train acc: 0.940063 ,val loss : 0.122255 ,val acc : 0.990753\n",
      "[ ecpho : 0  iter :796 ]train loss : 0.218569 ,train acc: 0.876129 ,val loss : 0.119268 ,val acc : 0.991394\n",
      "[ ecpho : 0  iter :797 ]train loss : 0.118526 ,train acc: 0.992279 ,val loss : 0.121080 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :798 ]train loss : 0.079785 ,train acc: 0.997589 ,val loss : 0.119741 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :799 ]train loss : 0.074376 ,train acc: 0.997192 ,val loss : 0.119930 ,val acc : 0.991730\n",
      "[ ecpho : 0  iter :800 ]train loss : 0.072895 ,train acc: 0.998260 ,val loss : 0.120649 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :801 ]train loss : 0.250158 ,train acc: 0.913147 ,val loss : 0.118760 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :802 ]train loss : 0.460796 ,train acc: 0.692902 ,val loss : 0.121573 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :803 ]train loss : 0.296846 ,train acc: 0.848816 ,val loss : 0.123038 ,val acc : 0.991272\n",
      "[ ecpho : 0  iter :804 ]train loss : 0.099979 ,train acc: 0.992218 ,val loss : 0.119437 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :805 ]train loss : 0.127701 ,train acc: 0.975372 ,val loss : 0.122622 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :806 ]train loss : 0.172689 ,train acc: 0.960846 ,val loss : 0.119472 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :807 ]train loss : 0.069648 ,train acc: 0.997833 ,val loss : 0.121922 ,val acc : 0.991150\n",
      "[ ecpho : 0  iter :808 ]train loss : 0.097208 ,train acc: 0.995636 ,val loss : 0.121703 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :809 ]train loss : 0.291349 ,train acc: 0.801300 ,val loss : 0.122618 ,val acc : 0.990723\n",
      "[ ecpho : 0  iter :810 ]train loss : 0.127625 ,train acc: 0.986542 ,val loss : 0.119059 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :811 ]train loss : 0.075491 ,train acc: 0.997406 ,val loss : 0.123151 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :812 ]train loss : 0.095056 ,train acc: 0.992798 ,val loss : 0.124353 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :813 ]train loss : 0.506693 ,train acc: 0.610748 ,val loss : 0.122407 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :814 ]train loss : 0.095122 ,train acc: 0.992767 ,val loss : 0.125493 ,val acc : 0.991730\n",
      "[ ecpho : 0  iter :815 ]train loss : 0.106996 ,train acc: 0.991577 ,val loss : 0.121397 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :816 ]train loss : 0.122573 ,train acc: 0.986542 ,val loss : 0.122220 ,val acc : 0.990967\n",
      "[ ecpho : 0  iter :817 ]train loss : 0.073120 ,train acc: 0.997040 ,val loss : 0.122676 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :818 ]train loss : 0.137141 ,train acc: 0.964264 ,val loss : 0.121683 ,val acc : 0.990997\n",
      "[ ecpho : 0  iter :819 ]train loss : 0.091909 ,train acc: 0.986328 ,val loss : 0.120228 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :820 ]train loss : 0.066742 ,train acc: 0.998352 ,val loss : 0.126112 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :821 ]train loss : 0.084934 ,train acc: 0.990051 ,val loss : 0.120014 ,val acc : 0.992065\n",
      "[ ecpho : 0  iter :822 ]train loss : 0.087038 ,train acc: 0.995056 ,val loss : 0.121237 ,val acc : 0.992218\n",
      "[ ecpho : 0  iter :823 ]train loss : 0.081213 ,train acc: 0.994507 ,val loss : 0.121141 ,val acc : 0.991821\n",
      "[ ecpho : 0  iter :824 ]train loss : 0.132078 ,train acc: 0.973145 ,val loss : 0.123143 ,val acc : 0.991699\n",
      "[ ecpho : 0  iter :825 ]train loss : 0.079019 ,train acc: 0.998932 ,val loss : 0.121951 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :826 ]train loss : 0.162580 ,train acc: 0.930634 ,val loss : 0.123799 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :827 ]train loss : 0.093349 ,train acc: 0.986115 ,val loss : 0.121277 ,val acc : 0.991913\n",
      "[ ecpho : 0  iter :828 ]train loss : 0.087219 ,train acc: 0.995239 ,val loss : 0.123496 ,val acc : 0.992004\n",
      "[ ecpho : 0  iter :829 ]train loss : 0.106315 ,train acc: 0.983612 ,val loss : 0.123186 ,val acc : 0.991577\n",
      "[ ecpho : 0  iter :830 ]train loss : 0.160664 ,train acc: 0.961517 ,val loss : 0.118641 ,val acc : 0.992523\n",
      "[ ecpho : 0  iter :831 ]train loss : 0.121367 ,train acc: 0.991516 ,val loss : 0.122644 ,val acc : 0.992493\n",
      "[ ecpho : 0  iter :832 ]train loss : 0.094446 ,train acc: 0.992249 ,val loss : 0.121873 ,val acc : 0.992218\n",
      "[ ecpho : 0  iter :833 ]train loss : 0.084999 ,train acc: 0.996979 ,val loss : 0.123490 ,val acc : 0.992493\n",
      "[ ecpho : 0  iter :834 ]train loss : 0.113939 ,train acc: 0.996094 ,val loss : 0.120816 ,val acc : 0.992584\n",
      "[ ecpho : 0  iter :835 ]train loss : 0.115528 ,train acc: 0.985291 ,val loss : 0.123964 ,val acc : 0.992981\n",
      "[ ecpho : 0  iter :836 ]train loss : 0.084019 ,train acc: 0.997284 ,val loss : 0.125314 ,val acc : 0.992065\n",
      "[ ecpho : 0  iter :837 ]train loss : 0.090006 ,train acc: 0.997131 ,val loss : 0.121627 ,val acc : 0.992523\n",
      "[ ecpho : 0  iter :838 ]train loss : 0.124904 ,train acc: 0.966644 ,val loss : 0.123425 ,val acc : 0.992493\n",
      "[ ecpho : 0  iter :839 ]train loss : 0.134017 ,train acc: 0.958282 ,val loss : 0.119303 ,val acc : 0.992126\n",
      "[ ecpho : 0  iter :840 ]train loss : 0.095482 ,train acc: 0.995667 ,val loss : 0.119942 ,val acc : 0.992279\n",
      "[ ecpho : 0  iter :841 ]train loss : 0.167876 ,train acc: 0.961761 ,val loss : 0.122320 ,val acc : 0.992249\n",
      "[ ecpho : 0  iter :842 ]train loss : 0.125986 ,train acc: 0.991516 ,val loss : 0.117922 ,val acc : 0.991974\n",
      "[ ecpho : 0  iter :843 ]train loss : 0.414060 ,train acc: 0.760223 ,val loss : 0.117890 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :844 ]train loss : 0.094083 ,train acc: 0.990692 ,val loss : 0.116929 ,val acc : 0.991943\n",
      "[ ecpho : 0  iter :845 ]train loss : 0.090051 ,train acc: 0.990601 ,val loss : 0.120990 ,val acc : 0.991760\n",
      "[ ecpho : 0  iter :846 ]train loss : 0.072515 ,train acc: 0.997528 ,val loss : 0.121685 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :847 ]train loss : 0.262025 ,train acc: 0.868683 ,val loss : 0.122041 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :848 ]train loss : 0.313542 ,train acc: 0.915619 ,val loss : 0.115411 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :849 ]train loss : 0.084295 ,train acc: 0.998718 ,val loss : 0.122148 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :850 ]train loss : 0.105771 ,train acc: 0.982574 ,val loss : 0.120834 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :851 ]train loss : 0.324637 ,train acc: 0.791107 ,val loss : 0.118627 ,val acc : 0.991821\n",
      "[ ecpho : 0  iter :852 ]train loss : 0.586100 ,train acc: 0.622620 ,val loss : 0.118558 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :853 ]train loss : 0.073649 ,train acc: 0.997803 ,val loss : 0.118984 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :854 ]train loss : 0.244826 ,train acc: 0.859436 ,val loss : 0.121859 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :855 ]train loss : 0.093353 ,train acc: 0.991577 ,val loss : 0.117523 ,val acc : 0.990753\n",
      "[ ecpho : 0  iter :856 ]train loss : 0.066365 ,train acc: 0.997528 ,val loss : 0.120625 ,val acc : 0.990417\n",
      "[ ecpho : 0  iter :857 ]train loss : 0.095216 ,train acc: 0.984375 ,val loss : 0.120398 ,val acc : 0.990936\n",
      "[ ecpho : 0  iter :858 ]train loss : 0.248616 ,train acc: 0.909607 ,val loss : 0.119872 ,val acc : 0.990967\n",
      "[ ecpho : 0  iter :859 ]train loss : 0.085201 ,train acc: 0.991425 ,val loss : 0.118501 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :860 ]train loss : 0.125801 ,train acc: 0.986359 ,val loss : 0.121503 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :861 ]train loss : 0.084101 ,train acc: 0.996704 ,val loss : 0.120302 ,val acc : 0.991302\n",
      "[ ecpho : 0  iter :862 ]train loss : 0.231659 ,train acc: 0.874054 ,val loss : 0.120927 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :863 ]train loss : 0.137067 ,train acc: 0.986755 ,val loss : 0.119228 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :864 ]train loss : 0.169076 ,train acc: 0.932861 ,val loss : 0.119194 ,val acc : 0.991394\n",
      "[ ecpho : 0  iter :865 ]train loss : 0.105710 ,train acc: 0.989502 ,val loss : 0.121929 ,val acc : 0.990753\n",
      "[ ecpho : 0  iter :866 ]train loss : 0.145891 ,train acc: 0.951874 ,val loss : 0.120297 ,val acc : 0.990723\n",
      "[ ecpho : 0  iter :867 ]train loss : 0.076520 ,train acc: 0.991638 ,val loss : 0.119613 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :868 ]train loss : 0.242574 ,train acc: 0.859192 ,val loss : 0.120409 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :869 ]train loss : 0.106465 ,train acc: 0.990173 ,val loss : 0.122097 ,val acc : 0.990509\n",
      "[ ecpho : 0  iter :870 ]train loss : 0.108458 ,train acc: 0.991302 ,val loss : 0.120098 ,val acc : 0.991364\n",
      "[ ecpho : 0  iter :871 ]train loss : 0.077783 ,train acc: 0.998108 ,val loss : 0.118426 ,val acc : 0.990662\n",
      "[ ecpho : 0  iter :872 ]train loss : 0.087525 ,train acc: 0.994873 ,val loss : 0.123606 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :873 ]train loss : 0.091776 ,train acc: 0.992554 ,val loss : 0.118418 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :874 ]train loss : 0.110129 ,train acc: 0.975800 ,val loss : 0.119358 ,val acc : 0.990967\n",
      "[ ecpho : 0  iter :875 ]train loss : 0.331462 ,train acc: 0.792633 ,val loss : 0.120765 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :876 ]train loss : 0.076909 ,train acc: 0.997803 ,val loss : 0.119050 ,val acc : 0.991638\n",
      "[ ecpho : 0  iter :877 ]train loss : 0.089373 ,train acc: 0.994904 ,val loss : 0.118756 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :878 ]train loss : 0.099093 ,train acc: 0.982941 ,val loss : 0.120757 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :879 ]train loss : 0.634072 ,train acc: 0.552887 ,val loss : 0.121390 ,val acc : 0.991486\n",
      "[ ecpho : 0  iter :880 ]train loss : 0.166450 ,train acc: 0.973267 ,val loss : 0.119416 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :881 ]train loss : 1.178761 ,train acc: 0.206207 ,val loss : 0.118404 ,val acc : 0.991638\n",
      "[ ecpho : 0  iter :882 ]train loss : 0.070643 ,train acc: 0.994904 ,val loss : 0.119819 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :883 ]train loss : 0.117403 ,train acc: 0.984619 ,val loss : 0.121516 ,val acc : 0.991760\n",
      "[ ecpho : 0  iter :884 ]train loss : 0.074786 ,train acc: 0.997040 ,val loss : 0.123474 ,val acc : 0.990814\n",
      "[ ecpho : 0  iter :885 ]train loss : 0.242950 ,train acc: 0.933868 ,val loss : 0.121010 ,val acc : 0.991791\n",
      "[ ecpho : 0  iter :886 ]train loss : 0.098127 ,train acc: 0.992096 ,val loss : 0.121244 ,val acc : 0.991608\n",
      "[ ecpho : 0  iter :887 ]train loss : 0.278574 ,train acc: 0.877533 ,val loss : 0.117138 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :888 ]train loss : 0.109728 ,train acc: 0.980316 ,val loss : 0.121429 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :889 ]train loss : 0.220197 ,train acc: 0.951813 ,val loss : 0.120744 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :890 ]train loss : 0.159837 ,train acc: 0.984680 ,val loss : 0.116776 ,val acc : 0.991608\n",
      "[ ecpho : 0  iter :891 ]train loss : 0.102452 ,train acc: 0.993561 ,val loss : 0.120723 ,val acc : 0.992004\n",
      "[ ecpho : 0  iter :892 ]train loss : 0.139191 ,train acc: 0.955627 ,val loss : 0.120704 ,val acc : 0.991882\n",
      "[ ecpho : 0  iter :893 ]train loss : 0.082893 ,train acc: 0.992401 ,val loss : 0.119453 ,val acc : 0.991974\n",
      "[ ecpho : 0  iter :894 ]train loss : 0.072674 ,train acc: 0.998169 ,val loss : 0.116178 ,val acc : 0.991882\n",
      "[ ecpho : 0  iter :895 ]train loss : 0.084847 ,train acc: 0.992004 ,val loss : 0.117581 ,val acc : 0.992340\n",
      "[ ecpho : 0  iter :896 ]train loss : 0.116499 ,train acc: 0.990448 ,val loss : 0.118545 ,val acc : 0.992065\n",
      "[ ecpho : 0  iter :897 ]train loss : 0.125332 ,train acc: 0.973236 ,val loss : 0.120157 ,val acc : 0.992004\n",
      "[ ecpho : 0  iter :898 ]train loss : 0.115400 ,train acc: 0.979340 ,val loss : 0.119812 ,val acc : 0.992462\n",
      "[ ecpho : 0  iter :899 ]train loss : 0.094798 ,train acc: 0.985748 ,val loss : 0.117253 ,val acc : 0.992493\n",
      "[ ecpho : 0  iter :900 ]train loss : 0.094488 ,train acc: 0.989410 ,val loss : 0.116520 ,val acc : 0.992126\n",
      "[ ecpho : 0  iter :901 ]train loss : 0.121987 ,train acc: 0.986877 ,val loss : 0.121382 ,val acc : 0.992218\n",
      "[ ecpho : 0  iter :902 ]train loss : 0.123215 ,train acc: 0.971649 ,val loss : 0.118939 ,val acc : 0.991943\n",
      "[ ecpho : 0  iter :903 ]train loss : 0.422748 ,train acc: 0.704407 ,val loss : 0.117062 ,val acc : 0.992065\n",
      "[ ecpho : 0  iter :904 ]train loss : 0.174561 ,train acc: 0.917938 ,val loss : 0.118747 ,val acc : 0.991852\n",
      "[ ecpho : 0  iter :905 ]train loss : 0.085926 ,train acc: 0.995941 ,val loss : 0.118249 ,val acc : 0.992035\n",
      "[ ecpho : 0  iter :906 ]train loss : 0.084318 ,train acc: 0.997314 ,val loss : 0.117641 ,val acc : 0.992096\n",
      "[ ecpho : 0  iter :907 ]train loss : 0.643344 ,train acc: 0.568085 ,val loss : 0.115896 ,val acc : 0.992126\n",
      "[ ecpho : 0  iter :908 ]train loss : 0.131272 ,train acc: 0.965302 ,val loss : 0.116267 ,val acc : 0.992249\n",
      "[ ecpho : 0  iter :909 ]train loss : 0.229464 ,train acc: 0.919952 ,val loss : 0.121172 ,val acc : 0.992035\n",
      "[ ecpho : 0  iter :910 ]train loss : 0.106819 ,train acc: 0.995453 ,val loss : 0.116974 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :911 ]train loss : 0.223460 ,train acc: 0.912689 ,val loss : 0.119668 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :912 ]train loss : 0.200503 ,train acc: 0.917725 ,val loss : 0.117975 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :913 ]train loss : 0.076346 ,train acc: 0.998077 ,val loss : 0.119335 ,val acc : 0.991211\n",
      "[ ecpho : 0  iter :914 ]train loss : 0.067752 ,train acc: 0.998169 ,val loss : 0.122907 ,val acc : 0.991272\n",
      "[ ecpho : 0  iter :915 ]train loss : 1.017972 ,train acc: 0.422699 ,val loss : 0.118247 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :916 ]train loss : 0.189143 ,train acc: 0.933350 ,val loss : 0.122015 ,val acc : 0.991455\n",
      "[ ecpho : 0  iter :917 ]train loss : 0.109156 ,train acc: 0.978394 ,val loss : 0.120695 ,val acc : 0.991058\n",
      "[ ecpho : 0  iter :918 ]train loss : 0.138506 ,train acc: 0.955933 ,val loss : 0.122963 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :919 ]train loss : 0.087784 ,train acc: 0.990265 ,val loss : 0.121414 ,val acc : 0.990906\n",
      "[ ecpho : 0  iter :920 ]train loss : 0.350637 ,train acc: 0.774994 ,val loss : 0.120248 ,val acc : 0.990875\n",
      "[ ecpho : 0  iter :921 ]train loss : 0.094408 ,train acc: 0.987762 ,val loss : 0.121536 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :922 ]train loss : 0.183506 ,train acc: 0.971802 ,val loss : 0.122897 ,val acc : 0.990784\n",
      "[ ecpho : 0  iter :923 ]train loss : 0.082231 ,train acc: 0.996399 ,val loss : 0.120432 ,val acc : 0.990387\n",
      "[ ecpho : 0  iter :924 ]train loss : 0.160051 ,train acc: 0.940430 ,val loss : 0.118811 ,val acc : 0.991150\n",
      "[ ecpho : 0  iter :925 ]train loss : 0.095229 ,train acc: 0.993439 ,val loss : 0.116483 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :926 ]train loss : 0.069339 ,train acc: 0.997986 ,val loss : 0.119648 ,val acc : 0.991364\n",
      "[ ecpho : 0  iter :927 ]train loss : 0.326226 ,train acc: 0.785431 ,val loss : 0.121162 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :928 ]train loss : 0.076522 ,train acc: 0.997284 ,val loss : 0.119568 ,val acc : 0.991089\n",
      "[ ecpho : 0  iter :929 ]train loss : 0.122461 ,train acc: 0.983551 ,val loss : 0.122201 ,val acc : 0.991333\n",
      "[ ecpho : 0  iter :930 ]train loss : 0.093238 ,train acc: 0.987427 ,val loss : 0.121776 ,val acc : 0.991028\n",
      "[ ecpho : 0  iter :931 ]train loss : 0.081461 ,train acc: 0.993469 ,val loss : 0.120039 ,val acc : 0.991638\n",
      "[ ecpho : 0  iter :932 ]train loss : 0.215050 ,train acc: 0.902527 ,val loss : 0.120415 ,val acc : 0.990845\n",
      "[ ecpho : 0  iter :933 ]train loss : 0.102067 ,train acc: 0.996765 ,val loss : 0.119556 ,val acc : 0.991119\n",
      "[ ecpho : 0  iter :934 ]train loss : 0.174722 ,train acc: 0.919220 ,val loss : 0.121215 ,val acc : 0.991547\n",
      "[ ecpho : 0  iter :935 ]train loss : 0.110375 ,train acc: 0.995331 ,val loss : 0.122415 ,val acc : 0.991241\n",
      "[ ecpho : 0  iter :936 ]train loss : 0.088804 ,train acc: 0.993317 ,val loss : 0.118220 ,val acc : 0.991943\n",
      "[ ecpho : 0  iter :937 ]train loss : 0.093027 ,train acc: 0.988434 ,val loss : 0.120509 ,val acc : 0.991669\n",
      "[ ecpho : 0  iter :938 ]train loss : 0.138285 ,train acc: 0.987762 ,val loss : 0.120498 ,val acc : 0.991516\n",
      "[ ecpho : 0  iter :939 ]train loss : 0.153539 ,train acc: 0.949341 ,val loss : 0.121704 ,val acc : 0.992279\n",
      "[ ecpho : 0  iter :940 ]train loss : 0.179651 ,train acc: 0.971375 ,val loss : 0.120441 ,val acc : 0.991974\n",
      "=============================================\n",
      "[ 0 ] average train loss : 0.209102 train acc : 0.912171\n",
      "[ ecpho : 1  iter :1 ]train loss : 0.085788 ,train acc: 0.991364 ,val loss : 0.121791 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :2 ]train loss : 0.230601 ,train acc: 0.893951 ,val loss : 0.117159 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :3 ]train loss : 0.087282 ,train acc: 0.993378 ,val loss : 0.122114 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :4 ]train loss : 0.114764 ,train acc: 0.974121 ,val loss : 0.122292 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :5 ]train loss : 0.105092 ,train acc: 0.994629 ,val loss : 0.117171 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :6 ]train loss : 0.100890 ,train acc: 0.993622 ,val loss : 0.120281 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :7 ]train loss : 0.097383 ,train acc: 0.977875 ,val loss : 0.119939 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :8 ]train loss : 0.378352 ,train acc: 0.859283 ,val loss : 0.117446 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :9 ]train loss : 0.171407 ,train acc: 0.926208 ,val loss : 0.115027 ,val acc : 0.992828\n",
      "[ ecpho : 1  iter :10 ]train loss : 0.159849 ,train acc: 0.952545 ,val loss : 0.119479 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :11 ]train loss : 0.081406 ,train acc: 0.998993 ,val loss : 0.119376 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :12 ]train loss : 0.098124 ,train acc: 0.994110 ,val loss : 0.119394 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :13 ]train loss : 0.099367 ,train acc: 0.985596 ,val loss : 0.116004 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :14 ]train loss : 0.109914 ,train acc: 0.996185 ,val loss : 0.115266 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :15 ]train loss : 0.090433 ,train acc: 0.983704 ,val loss : 0.116512 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :16 ]train loss : 0.095167 ,train acc: 0.993805 ,val loss : 0.118648 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :17 ]train loss : 0.092185 ,train acc: 0.996796 ,val loss : 0.117547 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :18 ]train loss : 0.732618 ,train acc: 0.505737 ,val loss : 0.117652 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :19 ]train loss : 0.105989 ,train acc: 0.980804 ,val loss : 0.120867 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :20 ]train loss : 0.105564 ,train acc: 0.992035 ,val loss : 0.115966 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :21 ]train loss : 0.120740 ,train acc: 0.985626 ,val loss : 0.119286 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :22 ]train loss : 0.123623 ,train acc: 0.973633 ,val loss : 0.117915 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :23 ]train loss : 0.063664 ,train acc: 0.999023 ,val loss : 0.116780 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :24 ]train loss : 0.118144 ,train acc: 0.991333 ,val loss : 0.116429 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :25 ]train loss : 0.114232 ,train acc: 0.976074 ,val loss : 0.116756 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :26 ]train loss : 0.418300 ,train acc: 0.779419 ,val loss : 0.119126 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :27 ]train loss : 0.348495 ,train acc: 0.770721 ,val loss : 0.119653 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :28 ]train loss : 0.091513 ,train acc: 0.994537 ,val loss : 0.118994 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :29 ]train loss : 0.104409 ,train acc: 0.982483 ,val loss : 0.120012 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :30 ]train loss : 0.086200 ,train acc: 0.994659 ,val loss : 0.117068 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :31 ]train loss : 0.091042 ,train acc: 0.991669 ,val loss : 0.118897 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :32 ]train loss : 0.088529 ,train acc: 0.988922 ,val loss : 0.118437 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :33 ]train loss : 0.070015 ,train acc: 0.997498 ,val loss : 0.120003 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :34 ]train loss : 0.093305 ,train acc: 0.993622 ,val loss : 0.123459 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :35 ]train loss : 0.079521 ,train acc: 0.996887 ,val loss : 0.121902 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :36 ]train loss : 0.116244 ,train acc: 0.969696 ,val loss : 0.116079 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :37 ]train loss : 0.110883 ,train acc: 0.994110 ,val loss : 0.119107 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :38 ]train loss : 0.120876 ,train acc: 0.964142 ,val loss : 0.122165 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :39 ]train loss : 0.256639 ,train acc: 0.854279 ,val loss : 0.117177 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :40 ]train loss : 0.251665 ,train acc: 0.939423 ,val loss : 0.119177 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :41 ]train loss : 0.085846 ,train acc: 0.994598 ,val loss : 0.117838 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :42 ]train loss : 0.087698 ,train acc: 0.993835 ,val loss : 0.117766 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :43 ]train loss : 0.205706 ,train acc: 0.954254 ,val loss : 0.120053 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :44 ]train loss : 0.088650 ,train acc: 0.989594 ,val loss : 0.116054 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :45 ]train loss : 0.111053 ,train acc: 0.984985 ,val loss : 0.119184 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :46 ]train loss : 0.779332 ,train acc: 0.428619 ,val loss : 0.118823 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :47 ]train loss : 0.099488 ,train acc: 0.977661 ,val loss : 0.114888 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :48 ]train loss : 0.118588 ,train acc: 0.985565 ,val loss : 0.116214 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :49 ]train loss : 0.109545 ,train acc: 0.991974 ,val loss : 0.116137 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :50 ]train loss : 0.108835 ,train acc: 0.974182 ,val loss : 0.114918 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :51 ]train loss : 0.088478 ,train acc: 0.995758 ,val loss : 0.113620 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :52 ]train loss : 0.120794 ,train acc: 0.991241 ,val loss : 0.115134 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :53 ]train loss : 0.111914 ,train acc: 0.974396 ,val loss : 0.115719 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :54 ]train loss : 0.178309 ,train acc: 0.920837 ,val loss : 0.118610 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :55 ]train loss : 0.119014 ,train acc: 0.992096 ,val loss : 0.115631 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :56 ]train loss : 0.196505 ,train acc: 0.916504 ,val loss : 0.116265 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :57 ]train loss : 0.362298 ,train acc: 0.771698 ,val loss : 0.114878 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :58 ]train loss : 0.086860 ,train acc: 0.991760 ,val loss : 0.115930 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :59 ]train loss : 0.137072 ,train acc: 0.966980 ,val loss : 0.118618 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :60 ]train loss : 0.072315 ,train acc: 0.998962 ,val loss : 0.115476 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :61 ]train loss : 0.152846 ,train acc: 0.950867 ,val loss : 0.115451 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :62 ]train loss : 0.134380 ,train acc: 0.955780 ,val loss : 0.111643 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :63 ]train loss : 0.431724 ,train acc: 0.710602 ,val loss : 0.116323 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :64 ]train loss : 0.411836 ,train acc: 0.782745 ,val loss : 0.118321 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :65 ]train loss : 0.155369 ,train acc: 0.979828 ,val loss : 0.117976 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :66 ]train loss : 0.085577 ,train acc: 0.997162 ,val loss : 0.117926 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :67 ]train loss : 0.117427 ,train acc: 0.979797 ,val loss : 0.118051 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :68 ]train loss : 0.083264 ,train acc: 0.996887 ,val loss : 0.116539 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :69 ]train loss : 0.095776 ,train acc: 0.996338 ,val loss : 0.117316 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :70 ]train loss : 0.126144 ,train acc: 0.984253 ,val loss : 0.117355 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :71 ]train loss : 0.086427 ,train acc: 0.990997 ,val loss : 0.119828 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :72 ]train loss : 0.094026 ,train acc: 0.985687 ,val loss : 0.119931 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :73 ]train loss : 0.074319 ,train acc: 0.993683 ,val loss : 0.118243 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :74 ]train loss : 0.562505 ,train acc: 0.643219 ,val loss : 0.115530 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :75 ]train loss : 0.111516 ,train acc: 0.972778 ,val loss : 0.117669 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :76 ]train loss : 0.072427 ,train acc: 0.997803 ,val loss : 0.115966 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :77 ]train loss : 0.087490 ,train acc: 0.991974 ,val loss : 0.115667 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :78 ]train loss : 0.076523 ,train acc: 0.993500 ,val loss : 0.113869 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :79 ]train loss : 0.066772 ,train acc: 0.996124 ,val loss : 0.116821 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :80 ]train loss : 0.110601 ,train acc: 0.992737 ,val loss : 0.119179 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :81 ]train loss : 0.098514 ,train acc: 0.981995 ,val loss : 0.116881 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :82 ]train loss : 0.452776 ,train acc: 0.716339 ,val loss : 0.117585 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :83 ]train loss : 0.090477 ,train acc: 0.991791 ,val loss : 0.114755 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :84 ]train loss : 0.084096 ,train acc: 0.998779 ,val loss : 0.115745 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :85 ]train loss : 0.073412 ,train acc: 0.996002 ,val loss : 0.114488 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :86 ]train loss : 0.075554 ,train acc: 0.997467 ,val loss : 0.113972 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :87 ]train loss : 0.096941 ,train acc: 0.987457 ,val loss : 0.116558 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :88 ]train loss : 0.117981 ,train acc: 0.987000 ,val loss : 0.113706 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :89 ]train loss : 0.226594 ,train acc: 0.880432 ,val loss : 0.115104 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :90 ]train loss : 0.342242 ,train acc: 0.866150 ,val loss : 0.119341 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :91 ]train loss : 0.082525 ,train acc: 0.996704 ,val loss : 0.115298 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :92 ]train loss : 0.165409 ,train acc: 0.929779 ,val loss : 0.117132 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :93 ]train loss : 0.381924 ,train acc: 0.782867 ,val loss : 0.113766 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :94 ]train loss : 0.088484 ,train acc: 0.996368 ,val loss : 0.111026 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :95 ]train loss : 0.629759 ,train acc: 0.690704 ,val loss : 0.117452 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :96 ]train loss : 0.124122 ,train acc: 0.973907 ,val loss : 0.116742 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :97 ]train loss : 0.098748 ,train acc: 0.979523 ,val loss : 0.118080 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :98 ]train loss : 0.096160 ,train acc: 0.994507 ,val loss : 0.116223 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :99 ]train loss : 0.070443 ,train acc: 0.997498 ,val loss : 0.116761 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :100 ]train loss : 0.141520 ,train acc: 0.974030 ,val loss : 0.113238 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :101 ]train loss : 0.099252 ,train acc: 0.993103 ,val loss : 0.117379 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :102 ]train loss : 0.489134 ,train acc: 0.690918 ,val loss : 0.116210 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :103 ]train loss : 0.513210 ,train acc: 0.753174 ,val loss : 0.116894 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :104 ]train loss : 0.459041 ,train acc: 0.684662 ,val loss : 0.115822 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :105 ]train loss : 0.085981 ,train acc: 0.990875 ,val loss : 0.117350 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :106 ]train loss : 0.159289 ,train acc: 0.976715 ,val loss : 0.116208 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :107 ]train loss : 0.158432 ,train acc: 0.960724 ,val loss : 0.116655 ,val acc : 0.991150\n",
      "[ ecpho : 1  iter :108 ]train loss : 0.106926 ,train acc: 0.992676 ,val loss : 0.115486 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :109 ]train loss : 0.237323 ,train acc: 0.915466 ,val loss : 0.115383 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :110 ]train loss : 0.069297 ,train acc: 0.997925 ,val loss : 0.115027 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :111 ]train loss : 0.258745 ,train acc: 0.865967 ,val loss : 0.115339 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :112 ]train loss : 0.103403 ,train acc: 0.983307 ,val loss : 0.114042 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :113 ]train loss : 0.830743 ,train acc: 0.464264 ,val loss : 0.117036 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :114 ]train loss : 0.086458 ,train acc: 0.989319 ,val loss : 0.114848 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :115 ]train loss : 0.079447 ,train acc: 0.992523 ,val loss : 0.112935 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :116 ]train loss : 0.310223 ,train acc: 0.790894 ,val loss : 0.116017 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :117 ]train loss : 0.121338 ,train acc: 0.968048 ,val loss : 0.115107 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :118 ]train loss : 0.123941 ,train acc: 0.961456 ,val loss : 0.116573 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :119 ]train loss : 0.093470 ,train acc: 0.991455 ,val loss : 0.117127 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :120 ]train loss : 0.073304 ,train acc: 0.997833 ,val loss : 0.117291 ,val acc : 0.991058\n",
      "[ ecpho : 1  iter :121 ]train loss : 0.602531 ,train acc: 0.606873 ,val loss : 0.116417 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :122 ]train loss : 0.087412 ,train acc: 0.991669 ,val loss : 0.115092 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :123 ]train loss : 0.092071 ,train acc: 0.996521 ,val loss : 0.114616 ,val acc : 0.990936\n",
      "[ ecpho : 1  iter :124 ]train loss : 0.080530 ,train acc: 0.994720 ,val loss : 0.116039 ,val acc : 0.990082\n",
      "[ ecpho : 1  iter :125 ]train loss : 0.105060 ,train acc: 0.990509 ,val loss : 0.116614 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :126 ]train loss : 0.075081 ,train acc: 0.997681 ,val loss : 0.116698 ,val acc : 0.990875\n",
      "[ ecpho : 1  iter :127 ]train loss : 0.909135 ,train acc: 0.355957 ,val loss : 0.117044 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :128 ]train loss : 0.101071 ,train acc: 0.989563 ,val loss : 0.117306 ,val acc : 0.990936\n",
      "[ ecpho : 1  iter :129 ]train loss : 0.517970 ,train acc: 0.659424 ,val loss : 0.116678 ,val acc : 0.990082\n",
      "[ ecpho : 1  iter :130 ]train loss : 0.418554 ,train acc: 0.713623 ,val loss : 0.117044 ,val acc : 0.991058\n",
      "[ ecpho : 1  iter :131 ]train loss : 0.113106 ,train acc: 0.974609 ,val loss : 0.117229 ,val acc : 0.989685\n",
      "[ ecpho : 1  iter :132 ]train loss : 0.094662 ,train acc: 0.992462 ,val loss : 0.121675 ,val acc : 0.990082\n",
      "[ ecpho : 1  iter :133 ]train loss : 0.323431 ,train acc: 0.848724 ,val loss : 0.118596 ,val acc : 0.990082\n",
      "[ ecpho : 1  iter :134 ]train loss : 0.476512 ,train acc: 0.703888 ,val loss : 0.119502 ,val acc : 0.989563\n",
      "[ ecpho : 1  iter :135 ]train loss : 0.135150 ,train acc: 0.982452 ,val loss : 0.122163 ,val acc : 0.989166\n",
      "[ ecpho : 1  iter :136 ]train loss : 0.133662 ,train acc: 0.958191 ,val loss : 0.118114 ,val acc : 0.988922\n",
      "[ ecpho : 1  iter :137 ]train loss : 0.105952 ,train acc: 0.982147 ,val loss : 0.118221 ,val acc : 0.989197\n",
      "[ ecpho : 1  iter :138 ]train loss : 0.074730 ,train acc: 0.995667 ,val loss : 0.118078 ,val acc : 0.989136\n",
      "[ ecpho : 1  iter :139 ]train loss : 0.072792 ,train acc: 0.997742 ,val loss : 0.118248 ,val acc : 0.989685\n",
      "[ ecpho : 1  iter :140 ]train loss : 0.088266 ,train acc: 0.995392 ,val loss : 0.116333 ,val acc : 0.989349\n",
      "[ ecpho : 1  iter :141 ]train loss : 0.591129 ,train acc: 0.555054 ,val loss : 0.117590 ,val acc : 0.989288\n",
      "[ ecpho : 1  iter :142 ]train loss : 0.092315 ,train acc: 0.981628 ,val loss : 0.120515 ,val acc : 0.989166\n",
      "[ ecpho : 1  iter :143 ]train loss : 0.107910 ,train acc: 0.977173 ,val loss : 0.119424 ,val acc : 0.989410\n",
      "[ ecpho : 1  iter :144 ]train loss : 0.105601 ,train acc: 0.973785 ,val loss : 0.117250 ,val acc : 0.989410\n",
      "[ ecpho : 1  iter :145 ]train loss : 0.083755 ,train acc: 0.990631 ,val loss : 0.120385 ,val acc : 0.989227\n",
      "[ ecpho : 1  iter :146 ]train loss : 0.085146 ,train acc: 0.991058 ,val loss : 0.117741 ,val acc : 0.989258\n",
      "[ ecpho : 1  iter :147 ]train loss : 0.081815 ,train acc: 0.992432 ,val loss : 0.121389 ,val acc : 0.989227\n",
      "[ ecpho : 1  iter :148 ]train loss : 1.148703 ,train acc: 0.224915 ,val loss : 0.121523 ,val acc : 0.988770\n",
      "[ ecpho : 1  iter :149 ]train loss : 0.149799 ,train acc: 0.948883 ,val loss : 0.119195 ,val acc : 0.989197\n",
      "[ ecpho : 1  iter :150 ]train loss : 0.125067 ,train acc: 0.974854 ,val loss : 0.121489 ,val acc : 0.988068\n",
      "[ ecpho : 1  iter :151 ]train loss : 0.806846 ,train acc: 0.432434 ,val loss : 0.122997 ,val acc : 0.987885\n",
      "[ ecpho : 1  iter :152 ]train loss : 0.241377 ,train acc: 0.921143 ,val loss : 0.117197 ,val acc : 0.987122\n",
      "[ ecpho : 1  iter :153 ]train loss : 0.137931 ,train acc: 0.952637 ,val loss : 0.122876 ,val acc : 0.986908\n",
      "[ ecpho : 1  iter :154 ]train loss : 0.212540 ,train acc: 0.939331 ,val loss : 0.121491 ,val acc : 0.987305\n",
      "[ ecpho : 1  iter :155 ]train loss : 0.107541 ,train acc: 0.984650 ,val loss : 0.120048 ,val acc : 0.987640\n",
      "[ ecpho : 1  iter :156 ]train loss : 0.095349 ,train acc: 0.986053 ,val loss : 0.117173 ,val acc : 0.987762\n",
      "[ ecpho : 1  iter :157 ]train loss : 0.108619 ,train acc: 0.991913 ,val loss : 0.117039 ,val acc : 0.988373\n",
      "[ ecpho : 1  iter :158 ]train loss : 0.088453 ,train acc: 0.993805 ,val loss : 0.117514 ,val acc : 0.988159\n",
      "[ ecpho : 1  iter :159 ]train loss : 0.121285 ,train acc: 0.982635 ,val loss : 0.117615 ,val acc : 0.988861\n",
      "[ ecpho : 1  iter :160 ]train loss : 0.134844 ,train acc: 0.960297 ,val loss : 0.115342 ,val acc : 0.989410\n",
      "[ ecpho : 1  iter :161 ]train loss : 1.207809 ,train acc: 0.128418 ,val loss : 0.117955 ,val acc : 0.988770\n",
      "[ ecpho : 1  iter :162 ]train loss : 0.171905 ,train acc: 0.946075 ,val loss : 0.117727 ,val acc : 0.989441\n",
      "[ ecpho : 1  iter :163 ]train loss : 0.125458 ,train acc: 0.964783 ,val loss : 0.116298 ,val acc : 0.989349\n",
      "[ ecpho : 1  iter :164 ]train loss : 0.146726 ,train acc: 0.973511 ,val loss : 0.116568 ,val acc : 0.989105\n",
      "[ ecpho : 1  iter :165 ]train loss : 0.086898 ,train acc: 0.993469 ,val loss : 0.121844 ,val acc : 0.989502\n",
      "[ ecpho : 1  iter :166 ]train loss : 0.095594 ,train acc: 0.986328 ,val loss : 0.115543 ,val acc : 0.989838\n",
      "[ ecpho : 1  iter :167 ]train loss : 0.417758 ,train acc: 0.727509 ,val loss : 0.118791 ,val acc : 0.990112\n",
      "[ ecpho : 1  iter :168 ]train loss : 0.133260 ,train acc: 0.957458 ,val loss : 0.117925 ,val acc : 0.989166\n",
      "[ ecpho : 1  iter :169 ]train loss : 0.322956 ,train acc: 0.840515 ,val loss : 0.116587 ,val acc : 0.990082\n",
      "[ ecpho : 1  iter :170 ]train loss : 0.832734 ,train acc: 0.444519 ,val loss : 0.118266 ,val acc : 0.989319\n",
      "[ ecpho : 1  iter :171 ]train loss : 0.093916 ,train acc: 0.988647 ,val loss : 0.116713 ,val acc : 0.988800\n",
      "[ ecpho : 1  iter :172 ]train loss : 0.408662 ,train acc: 0.798950 ,val loss : 0.120070 ,val acc : 0.989166\n",
      "[ ecpho : 1  iter :173 ]train loss : 0.682858 ,train acc: 0.530151 ,val loss : 0.118466 ,val acc : 0.988800\n",
      "[ ecpho : 1  iter :174 ]train loss : 0.130370 ,train acc: 0.982666 ,val loss : 0.118696 ,val acc : 0.988464\n",
      "[ ecpho : 1  iter :175 ]train loss : 0.083531 ,train acc: 0.995300 ,val loss : 0.120107 ,val acc : 0.988220\n",
      "[ ecpho : 1  iter :176 ]train loss : 0.263444 ,train acc: 0.837128 ,val loss : 0.119768 ,val acc : 0.988373\n",
      "[ ecpho : 1  iter :177 ]train loss : 0.112594 ,train acc: 0.984985 ,val loss : 0.120686 ,val acc : 0.987457\n",
      "[ ecpho : 1  iter :178 ]train loss : 0.111578 ,train acc: 0.988464 ,val loss : 0.118646 ,val acc : 0.988312\n",
      "[ ecpho : 1  iter :179 ]train loss : 0.181625 ,train acc: 0.919708 ,val loss : 0.119400 ,val acc : 0.987640\n",
      "[ ecpho : 1  iter :180 ]train loss : 0.092214 ,train acc: 0.986969 ,val loss : 0.119166 ,val acc : 0.987854\n",
      "[ ecpho : 1  iter :181 ]train loss : 0.190721 ,train acc: 0.949219 ,val loss : 0.120478 ,val acc : 0.987396\n",
      "[ ecpho : 1  iter :182 ]train loss : 0.129745 ,train acc: 0.977966 ,val loss : 0.119746 ,val acc : 0.987396\n",
      "[ ecpho : 1  iter :183 ]train loss : 0.096259 ,train acc: 0.988708 ,val loss : 0.121425 ,val acc : 0.988037\n",
      "[ ecpho : 1  iter :184 ]train loss : 0.096350 ,train acc: 0.986511 ,val loss : 0.118202 ,val acc : 0.988373\n",
      "[ ecpho : 1  iter :185 ]train loss : 0.805688 ,train acc: 0.388824 ,val loss : 0.118341 ,val acc : 0.987488\n",
      "[ ecpho : 1  iter :186 ]train loss : 0.131746 ,train acc: 0.959412 ,val loss : 0.118834 ,val acc : 0.987946\n",
      "[ ecpho : 1  iter :187 ]train loss : 0.129726 ,train acc: 0.978363 ,val loss : 0.121864 ,val acc : 0.987671\n",
      "[ ecpho : 1  iter :188 ]train loss : 0.104029 ,train acc: 0.992249 ,val loss : 0.121751 ,val acc : 0.987640\n",
      "[ ecpho : 1  iter :189 ]train loss : 0.083233 ,train acc: 0.994110 ,val loss : 0.119597 ,val acc : 0.988037\n",
      "[ ecpho : 1  iter :190 ]train loss : 0.122424 ,train acc: 0.988617 ,val loss : 0.122121 ,val acc : 0.988678\n",
      "[ ecpho : 1  iter :191 ]train loss : 0.193899 ,train acc: 0.910583 ,val loss : 0.121239 ,val acc : 0.989014\n",
      "[ ecpho : 1  iter :192 ]train loss : 0.089130 ,train acc: 0.993286 ,val loss : 0.118534 ,val acc : 0.989166\n",
      "[ ecpho : 1  iter :193 ]train loss : 0.143276 ,train acc: 0.951630 ,val loss : 0.118780 ,val acc : 0.989441\n",
      "[ ecpho : 1  iter :194 ]train loss : 0.369202 ,train acc: 0.812988 ,val loss : 0.119001 ,val acc : 0.990021\n",
      "[ ecpho : 1  iter :195 ]train loss : 0.083788 ,train acc: 0.989563 ,val loss : 0.121865 ,val acc : 0.990601\n",
      "[ ecpho : 1  iter :196 ]train loss : 0.084556 ,train acc: 0.994110 ,val loss : 0.119426 ,val acc : 0.990295\n",
      "[ ecpho : 1  iter :197 ]train loss : 0.093640 ,train acc: 0.990936 ,val loss : 0.119507 ,val acc : 0.990234\n",
      "[ ecpho : 1  iter :198 ]train loss : 0.084913 ,train acc: 0.993286 ,val loss : 0.118401 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :199 ]train loss : 0.418936 ,train acc: 0.700317 ,val loss : 0.121095 ,val acc : 0.990814\n",
      "[ ecpho : 1  iter :200 ]train loss : 0.202743 ,train acc: 0.917053 ,val loss : 0.121887 ,val acc : 0.990845\n",
      "[ ecpho : 1  iter :201 ]train loss : 0.079456 ,train acc: 0.992584 ,val loss : 0.118207 ,val acc : 0.990204\n",
      "[ ecpho : 1  iter :202 ]train loss : 0.086130 ,train acc: 0.997223 ,val loss : 0.120999 ,val acc : 0.990540\n",
      "[ ecpho : 1  iter :203 ]train loss : 0.137814 ,train acc: 0.976288 ,val loss : 0.116771 ,val acc : 0.990540\n",
      "[ ecpho : 1  iter :204 ]train loss : 0.116100 ,train acc: 0.974182 ,val loss : 0.117405 ,val acc : 0.991058\n",
      "[ ecpho : 1  iter :205 ]train loss : 0.089227 ,train acc: 0.992828 ,val loss : 0.121656 ,val acc : 0.991150\n",
      "[ ecpho : 1  iter :206 ]train loss : 0.298502 ,train acc: 0.839233 ,val loss : 0.116735 ,val acc : 0.990967\n",
      "[ ecpho : 1  iter :207 ]train loss : 0.217035 ,train acc: 0.889771 ,val loss : 0.119889 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :208 ]train loss : 0.112420 ,train acc: 0.991486 ,val loss : 0.119892 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :209 ]train loss : 0.102027 ,train acc: 0.982147 ,val loss : 0.116873 ,val acc : 0.991119\n",
      "[ ecpho : 1  iter :210 ]train loss : 0.074296 ,train acc: 0.997101 ,val loss : 0.119558 ,val acc : 0.991150\n",
      "[ ecpho : 1  iter :211 ]train loss : 0.091905 ,train acc: 0.985168 ,val loss : 0.119420 ,val acc : 0.991211\n",
      "[ ecpho : 1  iter :212 ]train loss : 0.335966 ,train acc: 0.773376 ,val loss : 0.117558 ,val acc : 0.991241\n",
      "[ ecpho : 1  iter :213 ]train loss : 0.081173 ,train acc: 0.994202 ,val loss : 0.116625 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :214 ]train loss : 0.087944 ,train acc: 0.988251 ,val loss : 0.119645 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :215 ]train loss : 0.094480 ,train acc: 0.984406 ,val loss : 0.119290 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :216 ]train loss : 0.095435 ,train acc: 0.988647 ,val loss : 0.119263 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :217 ]train loss : 0.144983 ,train acc: 0.975159 ,val loss : 0.121173 ,val acc : 0.991241\n",
      "[ ecpho : 1  iter :218 ]train loss : 0.095661 ,train acc: 0.982544 ,val loss : 0.118099 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :219 ]train loss : 0.084293 ,train acc: 0.991058 ,val loss : 0.118583 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :220 ]train loss : 0.092930 ,train acc: 0.980865 ,val loss : 0.121079 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :221 ]train loss : 0.070136 ,train acc: 0.993561 ,val loss : 0.120576 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :222 ]train loss : 0.082959 ,train acc: 0.996216 ,val loss : 0.118165 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :223 ]train loss : 0.075971 ,train acc: 0.994690 ,val loss : 0.120219 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :224 ]train loss : 0.432480 ,train acc: 0.681427 ,val loss : 0.117950 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :225 ]train loss : 0.089641 ,train acc: 0.993378 ,val loss : 0.120521 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :226 ]train loss : 0.133681 ,train acc: 0.978912 ,val loss : 0.119160 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :227 ]train loss : 0.233568 ,train acc: 0.947876 ,val loss : 0.120664 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :228 ]train loss : 0.213021 ,train acc: 0.895294 ,val loss : 0.119736 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :229 ]train loss : 0.129132 ,train acc: 0.962555 ,val loss : 0.119276 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :230 ]train loss : 0.117792 ,train acc: 0.975128 ,val loss : 0.116805 ,val acc : 0.990784\n",
      "[ ecpho : 1  iter :231 ]train loss : 0.090516 ,train acc: 0.991394 ,val loss : 0.116310 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :232 ]train loss : 0.090012 ,train acc: 0.991028 ,val loss : 0.118443 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :233 ]train loss : 0.098230 ,train acc: 0.994720 ,val loss : 0.119399 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :234 ]train loss : 0.171969 ,train acc: 0.931335 ,val loss : 0.117619 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :235 ]train loss : 0.085999 ,train acc: 0.996887 ,val loss : 0.117938 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :236 ]train loss : 0.082714 ,train acc: 0.996704 ,val loss : 0.116332 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :237 ]train loss : 0.126401 ,train acc: 0.964447 ,val loss : 0.119142 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :238 ]train loss : 0.114465 ,train acc: 0.979004 ,val loss : 0.120374 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :239 ]train loss : 0.087433 ,train acc: 0.994843 ,val loss : 0.117306 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :240 ]train loss : 0.166829 ,train acc: 0.960693 ,val loss : 0.120882 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :241 ]train loss : 0.201041 ,train acc: 0.893707 ,val loss : 0.119153 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :242 ]train loss : 0.111590 ,train acc: 0.973480 ,val loss : 0.119184 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :243 ]train loss : 0.117487 ,train acc: 0.974030 ,val loss : 0.119679 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :244 ]train loss : 0.065801 ,train acc: 0.998260 ,val loss : 0.121240 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :245 ]train loss : 0.091040 ,train acc: 0.995056 ,val loss : 0.115196 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :246 ]train loss : 0.098462 ,train acc: 0.986420 ,val loss : 0.119280 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :247 ]train loss : 0.074888 ,train acc: 0.998596 ,val loss : 0.118572 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :248 ]train loss : 0.079996 ,train acc: 0.997467 ,val loss : 0.120768 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :249 ]train loss : 0.074676 ,train acc: 0.999237 ,val loss : 0.122102 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :250 ]train loss : 0.071804 ,train acc: 0.997498 ,val loss : 0.119189 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :251 ]train loss : 0.101502 ,train acc: 0.977661 ,val loss : 0.117309 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :252 ]train loss : 0.080538 ,train acc: 0.997528 ,val loss : 0.117315 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :253 ]train loss : 0.144127 ,train acc: 0.950989 ,val loss : 0.115841 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :254 ]train loss : 1.231260 ,train acc: 0.183655 ,val loss : 0.119246 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :255 ]train loss : 0.158432 ,train acc: 0.939301 ,val loss : 0.119930 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :256 ]train loss : 0.166615 ,train acc: 0.933289 ,val loss : 0.118609 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :257 ]train loss : 0.067990 ,train acc: 0.997498 ,val loss : 0.120495 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :258 ]train loss : 0.102897 ,train acc: 0.996765 ,val loss : 0.119492 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :259 ]train loss : 0.872519 ,train acc: 0.464600 ,val loss : 0.117268 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :260 ]train loss : 0.086381 ,train acc: 0.993774 ,val loss : 0.119937 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :261 ]train loss : 0.077580 ,train acc: 0.995850 ,val loss : 0.118041 ,val acc : 0.993011\n",
      "[ ecpho : 1  iter :262 ]train loss : 0.072652 ,train acc: 0.999268 ,val loss : 0.119312 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :263 ]train loss : 0.086962 ,train acc: 0.986816 ,val loss : 0.117491 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :264 ]train loss : 0.107663 ,train acc: 0.996613 ,val loss : 0.118123 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :265 ]train loss : 0.133905 ,train acc: 0.967743 ,val loss : 0.119584 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :266 ]train loss : 0.082804 ,train acc: 0.993774 ,val loss : 0.116404 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :267 ]train loss : 0.061713 ,train acc: 0.999634 ,val loss : 0.119880 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :268 ]train loss : 0.093288 ,train acc: 0.998077 ,val loss : 0.117005 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :269 ]train loss : 0.101611 ,train acc: 0.980927 ,val loss : 0.118493 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :270 ]train loss : 0.127041 ,train acc: 0.967316 ,val loss : 0.117761 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :271 ]train loss : 0.174959 ,train acc: 0.951141 ,val loss : 0.119298 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :272 ]train loss : 0.299358 ,train acc: 0.817352 ,val loss : 0.116646 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :273 ]train loss : 0.080138 ,train acc: 0.998810 ,val loss : 0.118167 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :274 ]train loss : 0.085533 ,train acc: 0.985992 ,val loss : 0.114634 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :275 ]train loss : 0.181957 ,train acc: 0.960785 ,val loss : 0.118274 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :276 ]train loss : 0.096278 ,train acc: 0.983490 ,val loss : 0.118366 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :277 ]train loss : 0.117031 ,train acc: 0.968567 ,val loss : 0.117286 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :278 ]train loss : 0.125292 ,train acc: 0.986084 ,val loss : 0.116825 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :279 ]train loss : 0.095139 ,train acc: 0.997040 ,val loss : 0.118731 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :280 ]train loss : 0.131709 ,train acc: 0.972931 ,val loss : 0.117618 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :281 ]train loss : 0.124908 ,train acc: 0.977325 ,val loss : 0.119330 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :282 ]train loss : 1.036673 ,train acc: 0.282227 ,val loss : 0.115888 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :283 ]train loss : 0.077820 ,train acc: 0.994446 ,val loss : 0.116226 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :284 ]train loss : 0.091710 ,train acc: 0.991211 ,val loss : 0.117302 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :285 ]train loss : 0.079992 ,train acc: 0.992371 ,val loss : 0.117261 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :286 ]train loss : 0.325620 ,train acc: 0.890594 ,val loss : 0.115469 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :287 ]train loss : 0.193825 ,train acc: 0.912506 ,val loss : 0.116788 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :288 ]train loss : 0.268510 ,train acc: 0.828613 ,val loss : 0.116756 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :289 ]train loss : 0.121286 ,train acc: 0.973358 ,val loss : 0.117679 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :290 ]train loss : 0.065808 ,train acc: 0.998077 ,val loss : 0.114032 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :291 ]train loss : 0.083493 ,train acc: 0.984161 ,val loss : 0.116301 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :292 ]train loss : 0.746230 ,train acc: 0.437164 ,val loss : 0.112923 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :293 ]train loss : 0.094058 ,train acc: 0.997528 ,val loss : 0.116558 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :294 ]train loss : 0.132942 ,train acc: 0.952911 ,val loss : 0.119291 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :295 ]train loss : 0.082380 ,train acc: 0.997803 ,val loss : 0.117476 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :296 ]train loss : 0.074914 ,train acc: 0.997345 ,val loss : 0.117939 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :297 ]train loss : 0.108515 ,train acc: 0.992981 ,val loss : 0.120784 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :298 ]train loss : 0.101158 ,train acc: 0.992676 ,val loss : 0.114649 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :299 ]train loss : 0.101130 ,train acc: 0.997131 ,val loss : 0.115860 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :300 ]train loss : 0.068439 ,train acc: 0.998138 ,val loss : 0.116884 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :301 ]train loss : 0.337667 ,train acc: 0.783417 ,val loss : 0.118138 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :302 ]train loss : 0.117607 ,train acc: 0.982819 ,val loss : 0.117239 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :303 ]train loss : 0.388907 ,train acc: 0.767059 ,val loss : 0.116452 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :304 ]train loss : 0.690727 ,train acc: 0.445953 ,val loss : 0.116071 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :305 ]train loss : 0.373571 ,train acc: 0.752869 ,val loss : 0.117365 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :306 ]train loss : 0.167459 ,train acc: 0.943939 ,val loss : 0.117120 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :307 ]train loss : 0.369055 ,train acc: 0.808014 ,val loss : 0.118594 ,val acc : 0.990753\n",
      "[ ecpho : 1  iter :308 ]train loss : 0.129740 ,train acc: 0.971741 ,val loss : 0.118588 ,val acc : 0.990326\n",
      "[ ecpho : 1  iter :309 ]train loss : 0.084122 ,train acc: 0.996918 ,val loss : 0.119831 ,val acc : 0.990326\n",
      "[ ecpho : 1  iter :310 ]train loss : 0.276335 ,train acc: 0.892151 ,val loss : 0.119656 ,val acc : 0.990082\n",
      "[ ecpho : 1  iter :311 ]train loss : 0.083641 ,train acc: 0.992432 ,val loss : 0.118648 ,val acc : 0.990448\n",
      "[ ecpho : 1  iter :312 ]train loss : 0.065734 ,train acc: 0.998657 ,val loss : 0.119168 ,val acc : 0.990570\n",
      "[ ecpho : 1  iter :313 ]train loss : 0.107524 ,train acc: 0.977295 ,val loss : 0.119081 ,val acc : 0.989563\n",
      "[ ecpho : 1  iter :314 ]train loss : 0.340287 ,train acc: 0.824982 ,val loss : 0.117092 ,val acc : 0.990051\n",
      "[ ecpho : 1  iter :315 ]train loss : 0.094009 ,train acc: 0.988983 ,val loss : 0.119305 ,val acc : 0.990356\n",
      "[ ecpho : 1  iter :316 ]train loss : 0.062779 ,train acc: 0.997711 ,val loss : 0.118905 ,val acc : 0.990601\n",
      "[ ecpho : 1  iter :317 ]train loss : 0.151921 ,train acc: 0.957428 ,val loss : 0.119957 ,val acc : 0.990295\n",
      "[ ecpho : 1  iter :318 ]train loss : 0.114513 ,train acc: 0.974792 ,val loss : 0.117879 ,val acc : 0.989960\n",
      "[ ecpho : 1  iter :319 ]train loss : 0.166962 ,train acc: 0.933044 ,val loss : 0.119652 ,val acc : 0.990417\n",
      "[ ecpho : 1  iter :320 ]train loss : 0.106849 ,train acc: 0.995087 ,val loss : 0.120215 ,val acc : 0.990814\n",
      "[ ecpho : 1  iter :321 ]train loss : 0.116881 ,train acc: 0.991364 ,val loss : 0.117395 ,val acc : 0.990234\n",
      "[ ecpho : 1  iter :322 ]train loss : 0.079397 ,train acc: 0.993011 ,val loss : 0.120299 ,val acc : 0.991028\n",
      "[ ecpho : 1  iter :323 ]train loss : 0.072587 ,train acc: 0.996552 ,val loss : 0.119893 ,val acc : 0.990417\n",
      "[ ecpho : 1  iter :324 ]train loss : 0.639454 ,train acc: 0.688019 ,val loss : 0.119801 ,val acc : 0.990601\n",
      "[ ecpho : 1  iter :325 ]train loss : 0.087738 ,train acc: 0.990417 ,val loss : 0.120629 ,val acc : 0.990875\n",
      "[ ecpho : 1  iter :326 ]train loss : 0.074540 ,train acc: 0.994171 ,val loss : 0.119462 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :327 ]train loss : 0.092195 ,train acc: 0.995850 ,val loss : 0.120676 ,val acc : 0.990906\n",
      "[ ecpho : 1  iter :328 ]train loss : 0.079798 ,train acc: 0.993866 ,val loss : 0.121420 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :329 ]train loss : 0.361972 ,train acc: 0.808350 ,val loss : 0.116009 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :330 ]train loss : 0.167321 ,train acc: 0.932678 ,val loss : 0.116154 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :331 ]train loss : 0.115291 ,train acc: 0.992432 ,val loss : 0.118207 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :332 ]train loss : 0.195058 ,train acc: 0.929596 ,val loss : 0.115746 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :333 ]train loss : 0.105494 ,train acc: 0.978912 ,val loss : 0.115270 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :334 ]train loss : 0.088000 ,train acc: 0.993713 ,val loss : 0.118049 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :335 ]train loss : 0.114359 ,train acc: 0.989746 ,val loss : 0.117548 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :336 ]train loss : 0.958881 ,train acc: 0.383392 ,val loss : 0.117781 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :337 ]train loss : 0.474853 ,train acc: 0.669037 ,val loss : 0.115611 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :338 ]train loss : 0.110202 ,train acc: 0.978668 ,val loss : 0.118199 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :339 ]train loss : 0.086057 ,train acc: 0.992035 ,val loss : 0.116820 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :340 ]train loss : 0.141216 ,train acc: 0.951904 ,val loss : 0.118988 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :341 ]train loss : 0.104419 ,train acc: 0.984436 ,val loss : 0.117869 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :342 ]train loss : 0.142311 ,train acc: 0.961578 ,val loss : 0.117291 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :343 ]train loss : 0.885544 ,train acc: 0.348450 ,val loss : 0.120245 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :344 ]train loss : 0.072856 ,train acc: 0.995239 ,val loss : 0.114812 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :345 ]train loss : 0.469865 ,train acc: 0.638824 ,val loss : 0.118969 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :346 ]train loss : 0.271331 ,train acc: 0.886963 ,val loss : 0.116714 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :347 ]train loss : 0.096509 ,train acc: 0.985321 ,val loss : 0.117755 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :348 ]train loss : 0.112942 ,train acc: 0.983459 ,val loss : 0.119538 ,val acc : 0.991119\n",
      "[ ecpho : 1  iter :349 ]train loss : 0.109104 ,train acc: 0.994568 ,val loss : 0.118753 ,val acc : 0.990753\n",
      "[ ecpho : 1  iter :350 ]train loss : 0.105565 ,train acc: 0.984436 ,val loss : 0.118590 ,val acc : 0.990723\n",
      "[ ecpho : 1  iter :351 ]train loss : 0.089468 ,train acc: 0.997498 ,val loss : 0.118259 ,val acc : 0.991272\n",
      "[ ecpho : 1  iter :352 ]train loss : 0.122191 ,train acc: 0.982727 ,val loss : 0.121034 ,val acc : 0.990662\n",
      "[ ecpho : 1  iter :353 ]train loss : 0.079726 ,train acc: 0.991852 ,val loss : 0.119248 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :354 ]train loss : 0.099103 ,train acc: 0.987640 ,val loss : 0.118165 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :355 ]train loss : 0.086041 ,train acc: 0.997681 ,val loss : 0.117750 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :356 ]train loss : 0.103473 ,train acc: 0.996277 ,val loss : 0.120203 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :357 ]train loss : 0.129547 ,train acc: 0.983124 ,val loss : 0.120985 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :358 ]train loss : 0.095600 ,train acc: 0.994324 ,val loss : 0.120631 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :359 ]train loss : 0.170062 ,train acc: 0.944946 ,val loss : 0.119007 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :360 ]train loss : 0.106442 ,train acc: 0.995880 ,val loss : 0.119158 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :361 ]train loss : 0.098945 ,train acc: 0.982758 ,val loss : 0.118503 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :362 ]train loss : 0.066144 ,train acc: 0.997681 ,val loss : 0.119168 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :363 ]train loss : 0.168898 ,train acc: 0.939484 ,val loss : 0.119845 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :364 ]train loss : 0.100609 ,train acc: 0.996735 ,val loss : 0.116030 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :365 ]train loss : 0.385993 ,train acc: 0.773834 ,val loss : 0.120783 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :366 ]train loss : 0.077275 ,train acc: 0.995453 ,val loss : 0.117929 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :367 ]train loss : 0.321464 ,train acc: 0.793457 ,val loss : 0.120298 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :368 ]train loss : 0.114587 ,train acc: 0.978149 ,val loss : 0.120977 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :369 ]train loss : 0.105233 ,train acc: 0.977997 ,val loss : 0.118783 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :370 ]train loss : 0.227767 ,train acc: 0.878052 ,val loss : 0.118271 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :371 ]train loss : 0.178939 ,train acc: 0.919037 ,val loss : 0.121314 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :372 ]train loss : 0.441032 ,train acc: 0.725250 ,val loss : 0.118634 ,val acc : 0.991272\n",
      "[ ecpho : 1  iter :373 ]train loss : 0.085208 ,train acc: 0.992310 ,val loss : 0.118783 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :374 ]train loss : 0.083989 ,train acc: 0.998077 ,val loss : 0.120553 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :375 ]train loss : 0.085628 ,train acc: 0.989777 ,val loss : 0.122858 ,val acc : 0.990692\n",
      "[ ecpho : 1  iter :376 ]train loss : 0.098760 ,train acc: 0.996613 ,val loss : 0.120336 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :377 ]train loss : 0.131304 ,train acc: 0.963898 ,val loss : 0.120872 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :378 ]train loss : 0.251073 ,train acc: 0.885529 ,val loss : 0.117207 ,val acc : 0.990753\n",
      "[ ecpho : 1  iter :379 ]train loss : 0.100752 ,train acc: 0.978668 ,val loss : 0.121423 ,val acc : 0.991272\n",
      "[ ecpho : 1  iter :380 ]train loss : 0.082881 ,train acc: 0.986542 ,val loss : 0.116661 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :381 ]train loss : 0.273778 ,train acc: 0.860138 ,val loss : 0.119939 ,val acc : 0.990631\n",
      "[ ecpho : 1  iter :382 ]train loss : 0.157489 ,train acc: 0.944000 ,val loss : 0.120274 ,val acc : 0.990570\n",
      "[ ecpho : 1  iter :383 ]train loss : 0.119103 ,train acc: 0.986786 ,val loss : 0.122513 ,val acc : 0.990417\n",
      "[ ecpho : 1  iter :384 ]train loss : 0.092065 ,train acc: 0.985840 ,val loss : 0.118556 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :385 ]train loss : 0.094584 ,train acc: 0.992706 ,val loss : 0.120747 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :386 ]train loss : 0.105576 ,train acc: 0.978241 ,val loss : 0.118389 ,val acc : 0.991150\n",
      "[ ecpho : 1  iter :387 ]train loss : 0.127336 ,train acc: 0.989807 ,val loss : 0.121416 ,val acc : 0.990906\n",
      "[ ecpho : 1  iter :388 ]train loss : 0.073518 ,train acc: 0.998413 ,val loss : 0.117533 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :389 ]train loss : 0.094027 ,train acc: 0.990387 ,val loss : 0.119985 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :390 ]train loss : 0.334956 ,train acc: 0.823639 ,val loss : 0.120772 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :391 ]train loss : 0.480367 ,train acc: 0.667664 ,val loss : 0.119867 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :392 ]train loss : 0.083734 ,train acc: 0.992126 ,val loss : 0.118131 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :393 ]train loss : 0.096444 ,train acc: 0.985138 ,val loss : 0.120316 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :394 ]train loss : 0.081503 ,train acc: 0.994080 ,val loss : 0.119163 ,val acc : 0.991089\n",
      "[ ecpho : 1  iter :395 ]train loss : 0.106069 ,train acc: 0.979462 ,val loss : 0.123188 ,val acc : 0.990967\n",
      "[ ecpho : 1  iter :396 ]train loss : 0.683380 ,train acc: 0.557953 ,val loss : 0.118553 ,val acc : 0.990723\n",
      "[ ecpho : 1  iter :397 ]train loss : 0.084827 ,train acc: 0.997833 ,val loss : 0.120668 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :398 ]train loss : 0.157362 ,train acc: 0.954132 ,val loss : 0.121034 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :399 ]train loss : 0.086600 ,train acc: 0.989563 ,val loss : 0.121103 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :400 ]train loss : 0.080521 ,train acc: 0.996948 ,val loss : 0.119395 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :401 ]train loss : 0.153085 ,train acc: 0.944092 ,val loss : 0.118728 ,val acc : 0.991241\n",
      "[ ecpho : 1  iter :402 ]train loss : 0.200122 ,train acc: 0.901489 ,val loss : 0.121814 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :403 ]train loss : 0.076007 ,train acc: 0.997650 ,val loss : 0.120239 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :404 ]train loss : 0.083326 ,train acc: 0.997375 ,val loss : 0.123345 ,val acc : 0.990875\n",
      "[ ecpho : 1  iter :405 ]train loss : 0.074085 ,train acc: 0.997406 ,val loss : 0.121668 ,val acc : 0.990906\n",
      "[ ecpho : 1  iter :406 ]train loss : 0.097145 ,train acc: 0.982452 ,val loss : 0.119380 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :407 ]train loss : 0.075188 ,train acc: 0.998840 ,val loss : 0.126554 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :408 ]train loss : 0.570428 ,train acc: 0.602112 ,val loss : 0.127097 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :409 ]train loss : 0.260508 ,train acc: 0.832703 ,val loss : 0.120389 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :410 ]train loss : 0.157354 ,train acc: 0.941040 ,val loss : 0.125445 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :411 ]train loss : 0.090275 ,train acc: 0.993225 ,val loss : 0.119906 ,val acc : 0.991028\n",
      "[ ecpho : 1  iter :412 ]train loss : 0.242814 ,train acc: 0.888245 ,val loss : 0.121315 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :413 ]train loss : 0.114299 ,train acc: 0.968384 ,val loss : 0.125184 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :414 ]train loss : 0.092375 ,train acc: 0.989532 ,val loss : 0.122251 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :415 ]train loss : 0.083035 ,train acc: 0.997253 ,val loss : 0.119780 ,val acc : 0.991119\n",
      "[ ecpho : 1  iter :416 ]train loss : 0.277675 ,train acc: 0.827332 ,val loss : 0.124616 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :417 ]train loss : 0.096461 ,train acc: 0.996460 ,val loss : 0.123583 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :418 ]train loss : 0.537808 ,train acc: 0.610291 ,val loss : 0.121599 ,val acc : 0.990723\n",
      "[ ecpho : 1  iter :419 ]train loss : 0.066613 ,train acc: 0.998169 ,val loss : 0.120487 ,val acc : 0.990387\n",
      "[ ecpho : 1  iter :420 ]train loss : 0.095946 ,train acc: 0.979156 ,val loss : 0.125385 ,val acc : 0.990814\n",
      "[ ecpho : 1  iter :421 ]train loss : 0.092243 ,train acc: 0.993835 ,val loss : 0.124598 ,val acc : 0.990784\n",
      "[ ecpho : 1  iter :422 ]train loss : 0.221984 ,train acc: 0.874634 ,val loss : 0.125814 ,val acc : 0.990936\n",
      "[ ecpho : 1  iter :423 ]train loss : 0.123882 ,train acc: 0.982819 ,val loss : 0.125054 ,val acc : 0.990509\n",
      "[ ecpho : 1  iter :424 ]train loss : 0.114426 ,train acc: 0.976807 ,val loss : 0.123796 ,val acc : 0.990784\n",
      "[ ecpho : 1  iter :425 ]train loss : 0.113835 ,train acc: 0.966827 ,val loss : 0.127514 ,val acc : 0.990112\n",
      "[ ecpho : 1  iter :426 ]train loss : 0.078351 ,train acc: 0.992126 ,val loss : 0.128355 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :427 ]train loss : 0.120975 ,train acc: 0.968292 ,val loss : 0.125960 ,val acc : 0.990509\n",
      "[ ecpho : 1  iter :428 ]train loss : 0.153650 ,train acc: 0.941864 ,val loss : 0.125665 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :429 ]train loss : 0.096580 ,train acc: 0.991180 ,val loss : 0.123918 ,val acc : 0.990540\n",
      "[ ecpho : 1  iter :430 ]train loss : 0.111785 ,train acc: 0.981506 ,val loss : 0.124158 ,val acc : 0.991241\n",
      "[ ecpho : 1  iter :431 ]train loss : 0.110856 ,train acc: 0.983734 ,val loss : 0.126043 ,val acc : 0.990601\n",
      "[ ecpho : 1  iter :432 ]train loss : 0.081814 ,train acc: 0.990509 ,val loss : 0.123403 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :433 ]train loss : 0.090259 ,train acc: 0.989624 ,val loss : 0.126129 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :434 ]train loss : 0.430160 ,train acc: 0.767120 ,val loss : 0.124915 ,val acc : 0.991241\n",
      "[ ecpho : 1  iter :435 ]train loss : 0.085530 ,train acc: 0.993591 ,val loss : 0.125215 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :436 ]train loss : 0.083525 ,train acc: 0.994049 ,val loss : 0.123721 ,val acc : 0.991241\n",
      "[ ecpho : 1  iter :437 ]train loss : 0.086371 ,train acc: 0.989655 ,val loss : 0.125962 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :438 ]train loss : 0.120059 ,train acc: 0.974823 ,val loss : 0.123340 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :439 ]train loss : 0.172544 ,train acc: 0.934723 ,val loss : 0.125617 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :440 ]train loss : 1.012683 ,train acc: 0.335510 ,val loss : 0.126747 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :441 ]train loss : 0.095036 ,train acc: 0.986420 ,val loss : 0.124163 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :442 ]train loss : 0.067955 ,train acc: 0.994995 ,val loss : 0.123961 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :443 ]train loss : 0.071610 ,train acc: 0.996124 ,val loss : 0.127237 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :444 ]train loss : 0.080342 ,train acc: 0.997192 ,val loss : 0.126414 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :445 ]train loss : 0.072638 ,train acc: 0.996857 ,val loss : 0.122926 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :446 ]train loss : 0.083717 ,train acc: 0.989441 ,val loss : 0.124533 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :447 ]train loss : 0.167780 ,train acc: 0.973419 ,val loss : 0.121412 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :448 ]train loss : 0.606628 ,train acc: 0.661072 ,val loss : 0.119178 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :449 ]train loss : 0.067021 ,train acc: 0.998291 ,val loss : 0.123037 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :450 ]train loss : 0.096658 ,train acc: 0.987488 ,val loss : 0.122479 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :451 ]train loss : 0.102331 ,train acc: 0.997620 ,val loss : 0.125194 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :452 ]train loss : 0.103409 ,train acc: 0.996307 ,val loss : 0.119729 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :453 ]train loss : 0.138907 ,train acc: 0.980957 ,val loss : 0.121881 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :454 ]train loss : 0.315025 ,train acc: 0.863770 ,val loss : 0.122586 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :455 ]train loss : 0.080963 ,train acc: 0.997589 ,val loss : 0.119031 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :456 ]train loss : 0.197933 ,train acc: 0.949188 ,val loss : 0.119979 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :457 ]train loss : 0.185877 ,train acc: 0.930511 ,val loss : 0.120153 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :458 ]train loss : 0.166846 ,train acc: 0.976562 ,val loss : 0.118901 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :459 ]train loss : 0.099305 ,train acc: 0.992950 ,val loss : 0.120414 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :460 ]train loss : 0.092941 ,train acc: 0.994751 ,val loss : 0.116643 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :461 ]train loss : 0.731546 ,train acc: 0.419312 ,val loss : 0.118372 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :462 ]train loss : 0.179638 ,train acc: 0.920013 ,val loss : 0.116891 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :463 ]train loss : 0.070246 ,train acc: 0.997589 ,val loss : 0.115960 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :464 ]train loss : 0.205695 ,train acc: 0.948334 ,val loss : 0.116241 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :465 ]train loss : 0.085224 ,train acc: 0.992371 ,val loss : 0.115476 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :466 ]train loss : 0.145860 ,train acc: 0.987183 ,val loss : 0.118875 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :467 ]train loss : 0.073926 ,train acc: 0.998383 ,val loss : 0.116291 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :468 ]train loss : 1.139219 ,train acc: 0.234985 ,val loss : 0.120086 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :469 ]train loss : 0.121243 ,train acc: 0.983521 ,val loss : 0.116670 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :470 ]train loss : 0.110246 ,train acc: 0.979065 ,val loss : 0.116405 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :471 ]train loss : 0.090470 ,train acc: 0.985168 ,val loss : 0.115254 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :472 ]train loss : 0.084993 ,train acc: 0.991608 ,val loss : 0.115749 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :473 ]train loss : 0.082105 ,train acc: 0.993805 ,val loss : 0.115171 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :474 ]train loss : 0.127257 ,train acc: 0.984863 ,val loss : 0.117257 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :475 ]train loss : 0.205640 ,train acc: 0.899689 ,val loss : 0.116985 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :476 ]train loss : 0.183954 ,train acc: 0.917542 ,val loss : 0.120596 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :477 ]train loss : 0.174726 ,train acc: 0.925781 ,val loss : 0.114723 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :478 ]train loss : 0.072434 ,train acc: 0.998260 ,val loss : 0.117826 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :479 ]train loss : 0.212070 ,train acc: 0.897675 ,val loss : 0.118008 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :480 ]train loss : 0.085170 ,train acc: 0.987793 ,val loss : 0.116935 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :481 ]train loss : 0.475537 ,train acc: 0.663757 ,val loss : 0.115943 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :482 ]train loss : 0.116145 ,train acc: 0.975403 ,val loss : 0.120963 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :483 ]train loss : 0.166339 ,train acc: 0.939209 ,val loss : 0.121080 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :484 ]train loss : 0.147758 ,train acc: 0.945862 ,val loss : 0.115159 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :485 ]train loss : 1.118330 ,train acc: 0.249512 ,val loss : 0.117549 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :486 ]train loss : 0.269203 ,train acc: 0.828339 ,val loss : 0.117759 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :487 ]train loss : 0.101034 ,train acc: 0.986664 ,val loss : 0.116824 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :488 ]train loss : 0.094399 ,train acc: 0.993500 ,val loss : 0.115718 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :489 ]train loss : 0.110505 ,train acc: 0.980774 ,val loss : 0.116939 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :490 ]train loss : 0.079460 ,train acc: 0.993042 ,val loss : 0.118243 ,val acc : 0.990845\n",
      "[ ecpho : 1  iter :491 ]train loss : 0.083928 ,train acc: 0.993225 ,val loss : 0.119427 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :492 ]train loss : 0.060936 ,train acc: 0.999329 ,val loss : 0.112232 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :493 ]train loss : 0.084972 ,train acc: 0.990662 ,val loss : 0.115621 ,val acc : 0.991821\n",
      "[ ecpho : 1  iter :494 ]train loss : 0.119921 ,train acc: 0.990265 ,val loss : 0.116039 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :495 ]train loss : 0.249526 ,train acc: 0.883911 ,val loss : 0.119981 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :496 ]train loss : 0.265819 ,train acc: 0.841766 ,val loss : 0.117481 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :497 ]train loss : 0.088811 ,train acc: 0.983490 ,val loss : 0.119945 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :498 ]train loss : 0.106057 ,train acc: 0.993744 ,val loss : 0.119514 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :499 ]train loss : 0.311398 ,train acc: 0.850464 ,val loss : 0.115080 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :500 ]train loss : 0.090780 ,train acc: 0.988983 ,val loss : 0.117909 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :501 ]train loss : 0.127442 ,train acc: 0.985596 ,val loss : 0.117473 ,val acc : 0.991333\n",
      "[ ecpho : 1  iter :502 ]train loss : 0.087226 ,train acc: 0.997101 ,val loss : 0.118116 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :503 ]train loss : 0.107035 ,train acc: 0.982910 ,val loss : 0.115383 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :504 ]train loss : 0.262329 ,train acc: 0.855896 ,val loss : 0.115271 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :505 ]train loss : 0.238493 ,train acc: 0.866333 ,val loss : 0.115987 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :506 ]train loss : 0.101094 ,train acc: 0.981232 ,val loss : 0.115869 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :507 ]train loss : 0.089114 ,train acc: 0.994995 ,val loss : 0.117306 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :508 ]train loss : 0.145422 ,train acc: 0.957428 ,val loss : 0.117424 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :509 ]train loss : 0.084527 ,train acc: 0.994934 ,val loss : 0.116634 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :510 ]train loss : 0.075220 ,train acc: 0.998352 ,val loss : 0.118110 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :511 ]train loss : 0.125003 ,train acc: 0.962097 ,val loss : 0.116247 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :512 ]train loss : 0.082553 ,train acc: 0.991364 ,val loss : 0.118178 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :513 ]train loss : 0.191546 ,train acc: 0.902710 ,val loss : 0.116464 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :514 ]train loss : 0.095437 ,train acc: 0.983154 ,val loss : 0.117182 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :515 ]train loss : 1.289636 ,train acc: 0.155457 ,val loss : 0.113776 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :516 ]train loss : 0.064789 ,train acc: 0.996643 ,val loss : 0.117029 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :517 ]train loss : 0.234430 ,train acc: 0.876709 ,val loss : 0.115340 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :518 ]train loss : 0.108728 ,train acc: 0.991058 ,val loss : 0.118505 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :519 ]train loss : 0.081988 ,train acc: 0.989746 ,val loss : 0.115951 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :520 ]train loss : 0.154020 ,train acc: 0.953644 ,val loss : 0.116963 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :521 ]train loss : 0.110879 ,train acc: 0.993073 ,val loss : 0.115964 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :522 ]train loss : 0.128414 ,train acc: 0.978516 ,val loss : 0.116283 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :523 ]train loss : 0.245872 ,train acc: 0.890533 ,val loss : 0.119504 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :524 ]train loss : 0.091945 ,train acc: 0.984253 ,val loss : 0.114621 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :525 ]train loss : 0.397133 ,train acc: 0.711884 ,val loss : 0.117045 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :526 ]train loss : 0.146843 ,train acc: 0.977020 ,val loss : 0.117620 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :527 ]train loss : 0.088419 ,train acc: 0.988251 ,val loss : 0.116020 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :528 ]train loss : 0.148598 ,train acc: 0.958160 ,val loss : 0.113754 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :529 ]train loss : 0.176331 ,train acc: 0.957031 ,val loss : 0.116576 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :530 ]train loss : 0.070992 ,train acc: 0.996399 ,val loss : 0.115958 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :531 ]train loss : 0.182466 ,train acc: 0.927612 ,val loss : 0.118944 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :532 ]train loss : 0.101917 ,train acc: 0.975311 ,val loss : 0.119539 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :533 ]train loss : 0.083776 ,train acc: 0.988312 ,val loss : 0.118494 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :534 ]train loss : 0.065061 ,train acc: 0.995453 ,val loss : 0.116347 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :535 ]train loss : 0.589457 ,train acc: 0.615509 ,val loss : 0.114280 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :536 ]train loss : 0.095712 ,train acc: 0.996826 ,val loss : 0.120322 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :537 ]train loss : 0.077624 ,train acc: 0.997406 ,val loss : 0.119944 ,val acc : 0.991425\n",
      "[ ecpho : 1  iter :538 ]train loss : 0.088056 ,train acc: 0.994049 ,val loss : 0.114746 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :539 ]train loss : 0.098898 ,train acc: 0.990662 ,val loss : 0.118832 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :540 ]train loss : 0.075061 ,train acc: 0.997528 ,val loss : 0.115928 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :541 ]train loss : 0.101805 ,train acc: 0.994934 ,val loss : 0.116565 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :542 ]train loss : 0.090895 ,train acc: 0.991699 ,val loss : 0.118800 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :543 ]train loss : 0.105387 ,train acc: 0.985687 ,val loss : 0.117076 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :544 ]train loss : 0.092556 ,train acc: 0.998474 ,val loss : 0.119129 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :545 ]train loss : 0.112675 ,train acc: 0.983429 ,val loss : 0.116054 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :546 ]train loss : 0.077686 ,train acc: 0.997437 ,val loss : 0.116308 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :547 ]train loss : 0.087102 ,train acc: 0.996185 ,val loss : 0.117724 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :548 ]train loss : 0.106128 ,train acc: 0.993591 ,val loss : 0.118597 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :549 ]train loss : 0.085965 ,train acc: 0.994568 ,val loss : 0.116463 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :550 ]train loss : 0.093710 ,train acc: 0.990479 ,val loss : 0.117910 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :551 ]train loss : 0.100334 ,train acc: 0.991821 ,val loss : 0.116823 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :552 ]train loss : 0.099689 ,train acc: 0.979980 ,val loss : 0.115861 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :553 ]train loss : 0.103124 ,train acc: 0.993561 ,val loss : 0.114075 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :554 ]train loss : 0.120352 ,train acc: 0.968567 ,val loss : 0.116282 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :555 ]train loss : 0.096765 ,train acc: 0.987946 ,val loss : 0.117896 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :556 ]train loss : 0.285429 ,train acc: 0.838867 ,val loss : 0.116310 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :557 ]train loss : 0.130111 ,train acc: 0.964661 ,val loss : 0.115690 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :558 ]train loss : 0.202085 ,train acc: 0.902740 ,val loss : 0.115399 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :559 ]train loss : 0.074691 ,train acc: 0.995056 ,val loss : 0.117269 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :560 ]train loss : 0.074134 ,train acc: 0.998016 ,val loss : 0.116652 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :561 ]train loss : 0.083632 ,train acc: 0.998871 ,val loss : 0.117779 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :562 ]train loss : 0.117621 ,train acc: 0.991821 ,val loss : 0.115964 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :563 ]train loss : 0.085110 ,train acc: 0.994873 ,val loss : 0.115316 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :564 ]train loss : 0.058284 ,train acc: 0.999390 ,val loss : 0.116066 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :565 ]train loss : 0.069008 ,train acc: 0.994812 ,val loss : 0.117696 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :566 ]train loss : 0.181002 ,train acc: 0.917908 ,val loss : 0.117350 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :567 ]train loss : 0.082968 ,train acc: 0.987061 ,val loss : 0.116066 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :568 ]train loss : 0.107842 ,train acc: 0.983398 ,val loss : 0.118453 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :569 ]train loss : 0.090002 ,train acc: 0.993408 ,val loss : 0.116713 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :570 ]train loss : 0.093990 ,train acc: 0.998169 ,val loss : 0.116284 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :571 ]train loss : 0.110683 ,train acc: 0.968231 ,val loss : 0.115493 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :572 ]train loss : 0.145924 ,train acc: 0.979645 ,val loss : 0.118854 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :573 ]train loss : 0.383827 ,train acc: 0.724792 ,val loss : 0.117190 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :574 ]train loss : 0.133710 ,train acc: 0.962006 ,val loss : 0.116383 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :575 ]train loss : 0.110773 ,train acc: 0.993073 ,val loss : 0.115620 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :576 ]train loss : 0.958095 ,train acc: 0.345398 ,val loss : 0.114543 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :577 ]train loss : 0.125680 ,train acc: 0.985809 ,val loss : 0.115900 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :578 ]train loss : 0.126785 ,train acc: 0.968628 ,val loss : 0.117075 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :579 ]train loss : 0.193319 ,train acc: 0.943176 ,val loss : 0.116906 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :580 ]train loss : 0.108169 ,train acc: 0.996368 ,val loss : 0.114016 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :581 ]train loss : 0.078661 ,train acc: 0.997559 ,val loss : 0.113961 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :582 ]train loss : 0.084767 ,train acc: 0.992767 ,val loss : 0.115207 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :583 ]train loss : 0.708592 ,train acc: 0.505005 ,val loss : 0.112598 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :584 ]train loss : 0.088515 ,train acc: 0.998383 ,val loss : 0.116514 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :585 ]train loss : 0.091271 ,train acc: 0.998138 ,val loss : 0.114277 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :586 ]train loss : 0.092123 ,train acc: 0.997284 ,val loss : 0.114772 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :587 ]train loss : 0.119957 ,train acc: 0.972198 ,val loss : 0.114075 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :588 ]train loss : 0.092612 ,train acc: 0.998352 ,val loss : 0.117782 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :589 ]train loss : 0.091089 ,train acc: 0.989929 ,val loss : 0.114403 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :590 ]train loss : 0.081269 ,train acc: 0.992249 ,val loss : 0.113031 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :591 ]train loss : 0.196309 ,train acc: 0.946442 ,val loss : 0.114150 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :592 ]train loss : 0.112499 ,train acc: 0.980988 ,val loss : 0.113442 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :593 ]train loss : 0.088047 ,train acc: 0.994843 ,val loss : 0.112893 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :594 ]train loss : 0.090224 ,train acc: 0.994568 ,val loss : 0.112641 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :595 ]train loss : 0.098547 ,train acc: 0.992645 ,val loss : 0.114677 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :596 ]train loss : 0.078426 ,train acc: 0.997620 ,val loss : 0.112248 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :597 ]train loss : 0.081023 ,train acc: 0.992767 ,val loss : 0.117547 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :598 ]train loss : 0.091385 ,train acc: 0.986115 ,val loss : 0.109864 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :599 ]train loss : 0.111597 ,train acc: 0.973267 ,val loss : 0.113315 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :600 ]train loss : 0.117052 ,train acc: 0.980377 ,val loss : 0.111602 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :601 ]train loss : 0.112279 ,train acc: 0.987000 ,val loss : 0.113112 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :602 ]train loss : 0.395913 ,train acc: 0.747559 ,val loss : 0.112255 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :603 ]train loss : 0.094095 ,train acc: 0.985901 ,val loss : 0.112931 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :604 ]train loss : 0.067161 ,train acc: 0.998230 ,val loss : 0.111012 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :605 ]train loss : 0.088586 ,train acc: 0.993256 ,val loss : 0.112805 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :606 ]train loss : 0.111415 ,train acc: 0.970001 ,val loss : 0.113658 ,val acc : 0.993042\n",
      "[ ecpho : 1  iter :607 ]train loss : 0.071591 ,train acc: 0.998901 ,val loss : 0.112373 ,val acc : 0.992889\n",
      "[ ecpho : 1  iter :608 ]train loss : 0.096617 ,train acc: 0.987976 ,val loss : 0.112664 ,val acc : 0.993073\n",
      "[ ecpho : 1  iter :609 ]train loss : 0.290899 ,train acc: 0.849274 ,val loss : 0.112848 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :610 ]train loss : 0.126093 ,train acc: 0.964355 ,val loss : 0.112777 ,val acc : 0.992981\n",
      "[ ecpho : 1  iter :611 ]train loss : 0.105183 ,train acc: 0.994202 ,val loss : 0.111335 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :612 ]train loss : 0.082311 ,train acc: 0.997650 ,val loss : 0.112986 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :613 ]train loss : 0.139923 ,train acc: 0.955139 ,val loss : 0.113107 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :614 ]train loss : 0.087042 ,train acc: 0.994568 ,val loss : 0.113554 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :615 ]train loss : 0.077234 ,train acc: 0.998138 ,val loss : 0.112087 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :616 ]train loss : 0.090745 ,train acc: 0.997162 ,val loss : 0.115158 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :617 ]train loss : 0.070211 ,train acc: 0.997223 ,val loss : 0.114875 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :618 ]train loss : 0.097336 ,train acc: 0.998138 ,val loss : 0.116981 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :619 ]train loss : 0.078957 ,train acc: 0.994263 ,val loss : 0.113713 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :620 ]train loss : 0.123863 ,train acc: 0.982635 ,val loss : 0.113999 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :621 ]train loss : 0.098954 ,train acc: 0.997101 ,val loss : 0.112782 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :622 ]train loss : 0.095683 ,train acc: 0.989105 ,val loss : 0.112026 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :623 ]train loss : 0.087017 ,train acc: 0.990936 ,val loss : 0.110751 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :624 ]train loss : 0.079984 ,train acc: 0.998810 ,val loss : 0.111676 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :625 ]train loss : 0.090306 ,train acc: 0.992065 ,val loss : 0.112427 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :626 ]train loss : 0.105678 ,train acc: 0.998016 ,val loss : 0.115337 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :627 ]train loss : 0.091489 ,train acc: 0.997284 ,val loss : 0.110014 ,val acc : 0.993103\n",
      "[ ecpho : 1  iter :628 ]train loss : 0.080969 ,train acc: 0.990448 ,val loss : 0.111687 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :629 ]train loss : 0.246789 ,train acc: 0.869080 ,val loss : 0.113604 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :630 ]train loss : 0.506170 ,train acc: 0.614197 ,val loss : 0.111006 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :631 ]train loss : 0.399717 ,train acc: 0.723480 ,val loss : 0.112455 ,val acc : 0.993103\n",
      "[ ecpho : 1  iter :632 ]train loss : 0.065611 ,train acc: 0.998718 ,val loss : 0.114858 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :633 ]train loss : 0.108919 ,train acc: 0.976135 ,val loss : 0.111475 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :634 ]train loss : 0.092663 ,train acc: 0.993896 ,val loss : 0.110784 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :635 ]train loss : 0.422696 ,train acc: 0.750061 ,val loss : 0.115270 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :636 ]train loss : 0.148214 ,train acc: 0.968536 ,val loss : 0.112562 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :637 ]train loss : 0.237033 ,train acc: 0.911865 ,val loss : 0.112674 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :638 ]train loss : 0.112149 ,train acc: 0.980042 ,val loss : 0.114584 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :639 ]train loss : 0.245495 ,train acc: 0.895020 ,val loss : 0.111960 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :640 ]train loss : 0.112424 ,train acc: 0.993683 ,val loss : 0.115116 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :641 ]train loss : 0.140088 ,train acc: 0.981689 ,val loss : 0.112605 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :642 ]train loss : 0.089350 ,train acc: 0.988892 ,val loss : 0.114641 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :643 ]train loss : 0.254515 ,train acc: 0.910767 ,val loss : 0.113961 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :644 ]train loss : 0.093802 ,train acc: 0.989594 ,val loss : 0.113592 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :645 ]train loss : 0.294092 ,train acc: 0.867767 ,val loss : 0.113948 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :646 ]train loss : 0.111420 ,train acc: 0.969910 ,val loss : 0.111916 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :647 ]train loss : 0.098562 ,train acc: 0.996124 ,val loss : 0.113830 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :648 ]train loss : 0.253522 ,train acc: 0.860138 ,val loss : 0.114218 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :649 ]train loss : 0.086161 ,train acc: 0.993347 ,val loss : 0.116927 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :650 ]train loss : 0.398050 ,train acc: 0.795044 ,val loss : 0.112858 ,val acc : 0.991608\n",
      "[ ecpho : 1  iter :651 ]train loss : 0.111750 ,train acc: 0.991455 ,val loss : 0.113792 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :652 ]train loss : 0.117502 ,train acc: 0.989410 ,val loss : 0.111996 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :653 ]train loss : 0.077959 ,train acc: 0.998810 ,val loss : 0.112784 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :654 ]train loss : 0.072844 ,train acc: 0.997559 ,val loss : 0.112899 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :655 ]train loss : 0.075505 ,train acc: 0.998810 ,val loss : 0.112560 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :656 ]train loss : 0.126898 ,train acc: 0.959076 ,val loss : 0.112381 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :657 ]train loss : 0.096809 ,train acc: 0.983063 ,val loss : 0.111824 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :658 ]train loss : 0.107405 ,train acc: 0.977539 ,val loss : 0.114326 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :659 ]train loss : 0.100927 ,train acc: 0.997192 ,val loss : 0.111438 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :660 ]train loss : 0.391384 ,train acc: 0.731140 ,val loss : 0.112193 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :661 ]train loss : 0.101597 ,train acc: 0.982117 ,val loss : 0.112966 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :662 ]train loss : 0.146559 ,train acc: 0.973053 ,val loss : 0.110875 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :663 ]train loss : 0.149624 ,train acc: 0.983521 ,val loss : 0.116273 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :664 ]train loss : 0.120247 ,train acc: 0.984039 ,val loss : 0.112510 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :665 ]train loss : 0.059713 ,train acc: 0.997864 ,val loss : 0.113047 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :666 ]train loss : 0.163157 ,train acc: 0.966339 ,val loss : 0.110817 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :667 ]train loss : 0.747854 ,train acc: 0.477051 ,val loss : 0.111747 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :668 ]train loss : 0.094036 ,train acc: 0.983459 ,val loss : 0.112118 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :669 ]train loss : 0.413485 ,train acc: 0.733124 ,val loss : 0.112295 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :670 ]train loss : 0.083057 ,train acc: 0.992645 ,val loss : 0.111421 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :671 ]train loss : 0.169195 ,train acc: 0.928680 ,val loss : 0.114475 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :672 ]train loss : 0.417529 ,train acc: 0.715576 ,val loss : 0.113789 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :673 ]train loss : 0.303953 ,train acc: 0.827423 ,val loss : 0.112394 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :674 ]train loss : 0.076180 ,train acc: 0.993164 ,val loss : 0.110821 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :675 ]train loss : 0.863057 ,train acc: 0.400421 ,val loss : 0.116914 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :676 ]train loss : 0.169365 ,train acc: 0.934601 ,val loss : 0.115076 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :677 ]train loss : 0.086073 ,train acc: 0.995392 ,val loss : 0.116361 ,val acc : 0.991547\n",
      "[ ecpho : 1  iter :678 ]train loss : 0.090774 ,train acc: 0.994019 ,val loss : 0.114577 ,val acc : 0.991211\n",
      "[ ecpho : 1  iter :679 ]train loss : 0.113428 ,train acc: 0.975616 ,val loss : 0.117323 ,val acc : 0.990784\n",
      "[ ecpho : 1  iter :680 ]train loss : 0.090395 ,train acc: 0.993591 ,val loss : 0.114205 ,val acc : 0.991089\n",
      "[ ecpho : 1  iter :681 ]train loss : 0.074595 ,train acc: 0.996765 ,val loss : 0.112812 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :682 ]train loss : 1.189955 ,train acc: 0.197723 ,val loss : 0.114465 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :683 ]train loss : 0.143133 ,train acc: 0.957642 ,val loss : 0.119752 ,val acc : 0.990601\n",
      "[ ecpho : 1  iter :684 ]train loss : 0.076290 ,train acc: 0.997253 ,val loss : 0.117610 ,val acc : 0.990845\n",
      "[ ecpho : 1  iter :685 ]train loss : 0.074234 ,train acc: 0.997559 ,val loss : 0.117255 ,val acc : 0.990753\n",
      "[ ecpho : 1  iter :686 ]train loss : 0.110484 ,train acc: 0.992706 ,val loss : 0.114571 ,val acc : 0.990967\n",
      "[ ecpho : 1  iter :687 ]train loss : 0.090581 ,train acc: 0.986237 ,val loss : 0.117211 ,val acc : 0.991150\n",
      "[ ecpho : 1  iter :688 ]train loss : 0.443173 ,train acc: 0.731659 ,val loss : 0.116203 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :689 ]train loss : 0.081678 ,train acc: 0.993469 ,val loss : 0.116194 ,val acc : 0.991364\n",
      "[ ecpho : 1  iter :690 ]train loss : 0.106770 ,train acc: 0.982574 ,val loss : 0.121640 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :691 ]train loss : 0.114206 ,train acc: 0.985870 ,val loss : 0.116636 ,val acc : 0.991211\n",
      "[ ecpho : 1  iter :692 ]train loss : 0.091884 ,train acc: 0.984131 ,val loss : 0.116078 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :693 ]train loss : 0.080348 ,train acc: 0.993835 ,val loss : 0.118304 ,val acc : 0.991211\n",
      "[ ecpho : 1  iter :694 ]train loss : 0.120367 ,train acc: 0.972961 ,val loss : 0.115318 ,val acc : 0.991211\n",
      "[ ecpho : 1  iter :695 ]train loss : 0.115055 ,train acc: 0.985321 ,val loss : 0.117526 ,val acc : 0.990814\n",
      "[ ecpho : 1  iter :696 ]train loss : 0.483169 ,train acc: 0.659912 ,val loss : 0.113692 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :697 ]train loss : 0.062550 ,train acc: 0.997925 ,val loss : 0.117208 ,val acc : 0.991272\n",
      "[ ecpho : 1  iter :698 ]train loss : 1.418829 ,train acc: 0.021606 ,val loss : 0.117348 ,val acc : 0.991302\n",
      "[ ecpho : 1  iter :699 ]train loss : 0.155557 ,train acc: 0.967224 ,val loss : 0.120642 ,val acc : 0.991486\n",
      "[ ecpho : 1  iter :700 ]train loss : 0.114134 ,train acc: 0.974426 ,val loss : 0.119018 ,val acc : 0.990723\n",
      "[ ecpho : 1  iter :701 ]train loss : 0.093540 ,train acc: 0.992096 ,val loss : 0.120050 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :702 ]train loss : 0.136383 ,train acc: 0.977386 ,val loss : 0.117877 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :703 ]train loss : 0.166764 ,train acc: 0.957794 ,val loss : 0.119663 ,val acc : 0.991089\n",
      "[ ecpho : 1  iter :704 ]train loss : 0.141602 ,train acc: 0.980835 ,val loss : 0.119597 ,val acc : 0.990875\n",
      "[ ecpho : 1  iter :705 ]train loss : 0.094980 ,train acc: 0.981293 ,val loss : 0.124837 ,val acc : 0.990997\n",
      "[ ecpho : 1  iter :706 ]train loss : 0.071742 ,train acc: 0.996857 ,val loss : 0.119148 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :707 ]train loss : 0.117751 ,train acc: 0.977081 ,val loss : 0.119200 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :708 ]train loss : 0.104602 ,train acc: 0.973572 ,val loss : 0.120386 ,val acc : 0.991699\n",
      "[ ecpho : 1  iter :709 ]train loss : 0.101157 ,train acc: 0.994385 ,val loss : 0.119237 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :710 ]train loss : 0.087568 ,train acc: 0.995636 ,val loss : 0.120858 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :711 ]train loss : 0.168064 ,train acc: 0.925598 ,val loss : 0.121279 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :712 ]train loss : 0.604508 ,train acc: 0.725250 ,val loss : 0.119062 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :713 ]train loss : 0.125140 ,train acc: 0.969818 ,val loss : 0.119306 ,val acc : 0.991394\n",
      "[ ecpho : 1  iter :714 ]train loss : 0.103765 ,train acc: 0.975220 ,val loss : 0.120717 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :715 ]train loss : 0.118669 ,train acc: 0.987396 ,val loss : 0.121325 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :716 ]train loss : 0.093010 ,train acc: 0.987976 ,val loss : 0.117050 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :717 ]train loss : 0.099617 ,train acc: 0.989990 ,val loss : 0.117328 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :718 ]train loss : 0.101989 ,train acc: 0.991760 ,val loss : 0.116891 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :719 ]train loss : 0.102768 ,train acc: 0.991333 ,val loss : 0.117302 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :720 ]train loss : 0.081203 ,train acc: 0.995178 ,val loss : 0.115055 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :721 ]train loss : 0.122217 ,train acc: 0.988373 ,val loss : 0.114655 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :722 ]train loss : 0.093147 ,train acc: 0.981689 ,val loss : 0.117559 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :723 ]train loss : 0.076294 ,train acc: 0.996582 ,val loss : 0.118041 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :724 ]train loss : 0.086985 ,train acc: 0.998322 ,val loss : 0.119438 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :725 ]train loss : 0.124276 ,train acc: 0.985321 ,val loss : 0.114754 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :726 ]train loss : 0.084854 ,train acc: 0.989990 ,val loss : 0.117989 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :727 ]train loss : 0.089795 ,train acc: 0.983124 ,val loss : 0.113910 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :728 ]train loss : 0.394923 ,train acc: 0.741608 ,val loss : 0.117448 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :729 ]train loss : 0.095255 ,train acc: 0.998383 ,val loss : 0.114000 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :730 ]train loss : 0.098875 ,train acc: 0.981567 ,val loss : 0.113695 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :731 ]train loss : 0.119391 ,train acc: 0.987488 ,val loss : 0.117621 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :732 ]train loss : 0.100927 ,train acc: 0.998108 ,val loss : 0.114121 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :733 ]train loss : 0.093293 ,train acc: 0.994690 ,val loss : 0.114175 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :734 ]train loss : 0.096782 ,train acc: 0.985992 ,val loss : 0.113566 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :735 ]train loss : 0.111194 ,train acc: 0.970673 ,val loss : 0.116211 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :736 ]train loss : 0.097487 ,train acc: 0.987885 ,val loss : 0.112380 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :737 ]train loss : 0.108596 ,train acc: 0.970459 ,val loss : 0.116135 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :738 ]train loss : 0.086494 ,train acc: 0.993622 ,val loss : 0.115479 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :739 ]train loss : 0.099810 ,train acc: 0.986267 ,val loss : 0.114773 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :740 ]train loss : 0.072360 ,train acc: 0.994659 ,val loss : 0.113253 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :741 ]train loss : 0.083841 ,train acc: 0.996735 ,val loss : 0.114002 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :742 ]train loss : 0.067395 ,train acc: 0.997742 ,val loss : 0.114171 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :743 ]train loss : 0.184715 ,train acc: 0.920593 ,val loss : 0.112779 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :744 ]train loss : 0.086485 ,train acc: 0.997192 ,val loss : 0.115718 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :745 ]train loss : 0.201889 ,train acc: 0.948334 ,val loss : 0.109338 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :746 ]train loss : 0.114375 ,train acc: 0.967468 ,val loss : 0.112173 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :747 ]train loss : 0.169855 ,train acc: 0.924286 ,val loss : 0.112183 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :748 ]train loss : 0.645311 ,train acc: 0.604675 ,val loss : 0.112744 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :749 ]train loss : 0.106316 ,train acc: 0.984406 ,val loss : 0.112647 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :750 ]train loss : 0.076667 ,train acc: 0.995789 ,val loss : 0.112796 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :751 ]train loss : 0.099302 ,train acc: 0.977081 ,val loss : 0.115428 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :752 ]train loss : 0.104236 ,train acc: 0.995209 ,val loss : 0.113509 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :753 ]train loss : 0.190178 ,train acc: 0.905640 ,val loss : 0.114939 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :754 ]train loss : 0.094534 ,train acc: 0.998444 ,val loss : 0.111120 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :755 ]train loss : 0.089864 ,train acc: 0.992310 ,val loss : 0.110693 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :756 ]train loss : 0.086336 ,train acc: 0.997131 ,val loss : 0.114604 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :757 ]train loss : 0.096806 ,train acc: 0.982147 ,val loss : 0.113890 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :758 ]train loss : 0.076616 ,train acc: 0.995392 ,val loss : 0.111852 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :759 ]train loss : 0.137517 ,train acc: 0.970886 ,val loss : 0.114061 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :760 ]train loss : 0.083206 ,train acc: 0.991364 ,val loss : 0.111897 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :761 ]train loss : 0.112698 ,train acc: 0.977448 ,val loss : 0.110945 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :762 ]train loss : 0.211349 ,train acc: 0.926910 ,val loss : 0.110831 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :763 ]train loss : 0.082990 ,train acc: 0.993408 ,val loss : 0.112013 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :764 ]train loss : 0.115443 ,train acc: 0.980804 ,val loss : 0.111142 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :765 ]train loss : 0.118508 ,train acc: 0.975006 ,val loss : 0.110594 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :766 ]train loss : 0.139147 ,train acc: 0.976318 ,val loss : 0.110223 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :767 ]train loss : 0.144953 ,train acc: 0.964172 ,val loss : 0.110321 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :768 ]train loss : 0.296823 ,train acc: 0.920013 ,val loss : 0.109898 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :769 ]train loss : 0.098448 ,train acc: 0.983459 ,val loss : 0.112112 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :770 ]train loss : 0.065591 ,train acc: 0.998138 ,val loss : 0.110623 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :771 ]train loss : 0.135010 ,train acc: 0.966980 ,val loss : 0.112349 ,val acc : 0.992889\n",
      "[ ecpho : 1  iter :772 ]train loss : 0.072248 ,train acc: 0.997467 ,val loss : 0.110214 ,val acc : 0.992920\n",
      "[ ecpho : 1  iter :773 ]train loss : 0.062831 ,train acc: 0.998688 ,val loss : 0.109940 ,val acc : 0.992920\n",
      "[ ecpho : 1  iter :774 ]train loss : 0.080987 ,train acc: 0.990448 ,val loss : 0.110410 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :775 ]train loss : 0.065636 ,train acc: 0.996460 ,val loss : 0.110266 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :776 ]train loss : 0.087691 ,train acc: 0.989197 ,val loss : 0.112774 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :777 ]train loss : 0.084677 ,train acc: 0.994629 ,val loss : 0.112930 ,val acc : 0.992981\n",
      "[ ecpho : 1  iter :778 ]train loss : 0.077786 ,train acc: 0.994598 ,val loss : 0.110908 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :779 ]train loss : 0.079701 ,train acc: 0.998901 ,val loss : 0.110441 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :780 ]train loss : 0.080499 ,train acc: 0.993652 ,val loss : 0.108831 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :781 ]train loss : 0.098275 ,train acc: 0.990936 ,val loss : 0.108232 ,val acc : 0.992828\n",
      "[ ecpho : 1  iter :782 ]train loss : 0.134452 ,train acc: 0.957520 ,val loss : 0.110832 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :783 ]train loss : 0.098923 ,train acc: 0.996857 ,val loss : 0.109929 ,val acc : 0.992950\n",
      "[ ecpho : 1  iter :784 ]train loss : 0.103458 ,train acc: 0.993591 ,val loss : 0.111642 ,val acc : 0.992889\n",
      "[ ecpho : 1  iter :785 ]train loss : 0.231909 ,train acc: 0.926056 ,val loss : 0.107420 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :786 ]train loss : 0.503150 ,train acc: 0.636902 ,val loss : 0.109767 ,val acc : 0.992828\n",
      "[ ecpho : 1  iter :787 ]train loss : 0.066226 ,train acc: 0.999359 ,val loss : 0.110800 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :788 ]train loss : 0.088568 ,train acc: 0.992828 ,val loss : 0.109922 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :789 ]train loss : 0.077136 ,train acc: 0.994995 ,val loss : 0.110204 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :790 ]train loss : 0.082814 ,train acc: 0.995117 ,val loss : 0.112083 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :791 ]train loss : 0.111956 ,train acc: 0.971649 ,val loss : 0.113377 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :792 ]train loss : 0.077655 ,train acc: 0.998505 ,val loss : 0.108704 ,val acc : 0.993011\n",
      "[ ecpho : 1  iter :793 ]train loss : 0.120741 ,train acc: 0.991943 ,val loss : 0.109981 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :794 ]train loss : 0.103369 ,train acc: 0.988861 ,val loss : 0.112356 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :795 ]train loss : 0.155847 ,train acc: 0.940460 ,val loss : 0.110710 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :796 ]train loss : 0.219428 ,train acc: 0.875977 ,val loss : 0.109390 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :797 ]train loss : 0.109137 ,train acc: 0.993408 ,val loss : 0.113022 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :798 ]train loss : 0.068919 ,train acc: 0.998322 ,val loss : 0.111038 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :799 ]train loss : 0.065229 ,train acc: 0.998077 ,val loss : 0.111078 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :800 ]train loss : 0.065013 ,train acc: 0.999298 ,val loss : 0.108383 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :801 ]train loss : 0.243693 ,train acc: 0.913391 ,val loss : 0.110843 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :802 ]train loss : 0.465888 ,train acc: 0.692352 ,val loss : 0.111302 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :803 ]train loss : 0.294782 ,train acc: 0.848846 ,val loss : 0.108461 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :804 ]train loss : 0.091868 ,train acc: 0.993408 ,val loss : 0.111126 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :805 ]train loss : 0.121167 ,train acc: 0.976196 ,val loss : 0.110763 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :806 ]train loss : 0.167291 ,train acc: 0.962128 ,val loss : 0.110265 ,val acc : 0.992340\n",
      "[ ecpho : 1  iter :807 ]train loss : 0.062377 ,train acc: 0.997986 ,val loss : 0.111114 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :808 ]train loss : 0.087436 ,train acc: 0.996765 ,val loss : 0.109907 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :809 ]train loss : 0.292264 ,train acc: 0.800934 ,val loss : 0.114671 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :810 ]train loss : 0.118281 ,train acc: 0.987427 ,val loss : 0.112508 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :811 ]train loss : 0.070145 ,train acc: 0.998260 ,val loss : 0.112796 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :812 ]train loss : 0.085258 ,train acc: 0.993622 ,val loss : 0.111989 ,val acc : 0.992096\n",
      "[ ecpho : 1  iter :813 ]train loss : 0.523800 ,train acc: 0.609619 ,val loss : 0.112910 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :814 ]train loss : 0.088477 ,train acc: 0.993866 ,val loss : 0.111377 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :815 ]train loss : 0.100591 ,train acc: 0.992340 ,val loss : 0.111743 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :816 ]train loss : 0.114075 ,train acc: 0.987457 ,val loss : 0.114112 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :817 ]train loss : 0.068661 ,train acc: 0.997467 ,val loss : 0.113492 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :818 ]train loss : 0.130106 ,train acc: 0.964874 ,val loss : 0.113291 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :819 ]train loss : 0.082474 ,train acc: 0.986572 ,val loss : 0.112466 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :820 ]train loss : 0.058615 ,train acc: 0.998505 ,val loss : 0.111677 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :821 ]train loss : 0.078223 ,train acc: 0.990112 ,val loss : 0.113436 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :822 ]train loss : 0.078653 ,train acc: 0.995087 ,val loss : 0.111445 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :823 ]train loss : 0.074957 ,train acc: 0.994537 ,val loss : 0.113494 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :824 ]train loss : 0.125014 ,train acc: 0.973145 ,val loss : 0.109594 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :825 ]train loss : 0.067861 ,train acc: 0.999237 ,val loss : 0.115202 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :826 ]train loss : 0.158396 ,train acc: 0.931274 ,val loss : 0.113383 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :827 ]train loss : 0.084868 ,train acc: 0.986389 ,val loss : 0.111147 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :828 ]train loss : 0.078547 ,train acc: 0.995361 ,val loss : 0.112942 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :829 ]train loss : 0.096181 ,train acc: 0.983459 ,val loss : 0.112965 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :830 ]train loss : 0.157430 ,train acc: 0.961731 ,val loss : 0.112621 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :831 ]train loss : 0.107700 ,train acc: 0.991547 ,val loss : 0.112363 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :832 ]train loss : 0.089031 ,train acc: 0.991943 ,val loss : 0.111307 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :833 ]train loss : 0.076303 ,train acc: 0.997467 ,val loss : 0.112583 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :834 ]train loss : 0.104003 ,train acc: 0.996918 ,val loss : 0.110556 ,val acc : 0.993011\n",
      "[ ecpho : 1  iter :835 ]train loss : 0.108337 ,train acc: 0.985229 ,val loss : 0.111733 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :836 ]train loss : 0.075283 ,train acc: 0.997498 ,val loss : 0.111990 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :837 ]train loss : 0.082587 ,train acc: 0.997681 ,val loss : 0.111763 ,val acc : 0.992889\n",
      "[ ecpho : 1  iter :838 ]train loss : 0.118136 ,train acc: 0.966766 ,val loss : 0.112854 ,val acc : 0.992981\n",
      "[ ecpho : 1  iter :839 ]train loss : 0.128436 ,train acc: 0.958557 ,val loss : 0.111386 ,val acc : 0.992645\n",
      "[ ecpho : 1  iter :840 ]train loss : 0.084983 ,train acc: 0.995544 ,val loss : 0.110653 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :841 ]train loss : 0.156092 ,train acc: 0.962494 ,val loss : 0.112801 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :842 ]train loss : 0.113596 ,train acc: 0.991943 ,val loss : 0.108712 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :843 ]train loss : 0.419140 ,train acc: 0.760315 ,val loss : 0.111853 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :844 ]train loss : 0.084960 ,train acc: 0.991028 ,val loss : 0.109953 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :845 ]train loss : 0.083889 ,train acc: 0.990753 ,val loss : 0.112382 ,val acc : 0.993073\n",
      "[ ecpho : 1  iter :846 ]train loss : 0.066600 ,train acc: 0.997681 ,val loss : 0.110788 ,val acc : 0.992920\n",
      "[ ecpho : 1  iter :847 ]train loss : 0.264115 ,train acc: 0.869324 ,val loss : 0.113685 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :848 ]train loss : 0.288190 ,train acc: 0.916534 ,val loss : 0.106781 ,val acc : 0.993561\n",
      "[ ecpho : 1  iter :849 ]train loss : 0.077714 ,train acc: 0.999115 ,val loss : 0.108668 ,val acc : 0.993042\n",
      "[ ecpho : 1  iter :850 ]train loss : 0.098878 ,train acc: 0.983337 ,val loss : 0.110725 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :851 ]train loss : 0.329387 ,train acc: 0.791077 ,val loss : 0.108017 ,val acc : 0.992920\n",
      "[ ecpho : 1  iter :852 ]train loss : 0.596420 ,train acc: 0.622284 ,val loss : 0.111628 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :853 ]train loss : 0.065667 ,train acc: 0.998016 ,val loss : 0.110708 ,val acc : 0.992798\n",
      "[ ecpho : 1  iter :854 ]train loss : 0.239220 ,train acc: 0.859802 ,val loss : 0.111413 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :855 ]train loss : 0.083980 ,train acc: 0.992310 ,val loss : 0.111703 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :856 ]train loss : 0.059734 ,train acc: 0.998108 ,val loss : 0.106675 ,val acc : 0.992584\n",
      "[ ecpho : 1  iter :857 ]train loss : 0.088987 ,train acc: 0.984955 ,val loss : 0.113660 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :858 ]train loss : 0.241953 ,train acc: 0.910095 ,val loss : 0.111756 ,val acc : 0.993042\n",
      "[ ecpho : 1  iter :859 ]train loss : 0.076755 ,train acc: 0.991882 ,val loss : 0.110517 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :860 ]train loss : 0.114506 ,train acc: 0.988220 ,val loss : 0.112726 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :861 ]train loss : 0.072699 ,train acc: 0.997711 ,val loss : 0.110147 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :862 ]train loss : 0.230967 ,train acc: 0.873688 ,val loss : 0.112585 ,val acc : 0.992981\n",
      "[ ecpho : 1  iter :863 ]train loss : 0.126435 ,train acc: 0.988373 ,val loss : 0.111599 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :864 ]train loss : 0.167050 ,train acc: 0.933502 ,val loss : 0.110498 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :865 ]train loss : 0.097896 ,train acc: 0.991089 ,val loss : 0.108747 ,val acc : 0.992310\n",
      "[ ecpho : 1  iter :866 ]train loss : 0.140902 ,train acc: 0.952332 ,val loss : 0.111127 ,val acc : 0.993103\n",
      "[ ecpho : 1  iter :867 ]train loss : 0.073295 ,train acc: 0.992126 ,val loss : 0.111652 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :868 ]train loss : 0.239666 ,train acc: 0.859070 ,val loss : 0.108891 ,val acc : 0.992920\n",
      "[ ecpho : 1  iter :869 ]train loss : 0.098423 ,train acc: 0.991760 ,val loss : 0.111597 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :870 ]train loss : 0.101224 ,train acc: 0.992645 ,val loss : 0.109321 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :871 ]train loss : 0.066734 ,train acc: 0.999329 ,val loss : 0.111434 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :872 ]train loss : 0.081322 ,train acc: 0.995911 ,val loss : 0.111998 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :873 ]train loss : 0.082630 ,train acc: 0.993286 ,val loss : 0.110261 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :874 ]train loss : 0.101822 ,train acc: 0.976501 ,val loss : 0.115529 ,val acc : 0.992859\n",
      "[ ecpho : 1  iter :875 ]train loss : 0.333724 ,train acc: 0.792389 ,val loss : 0.109086 ,val acc : 0.993011\n",
      "[ ecpho : 1  iter :876 ]train loss : 0.071590 ,train acc: 0.998566 ,val loss : 0.111519 ,val acc : 0.992706\n",
      "[ ecpho : 1  iter :877 ]train loss : 0.079466 ,train acc: 0.995605 ,val loss : 0.112184 ,val acc : 0.992981\n",
      "[ ecpho : 1  iter :878 ]train loss : 0.091942 ,train acc: 0.982910 ,val loss : 0.112855 ,val acc : 0.992889\n",
      "[ ecpho : 1  iter :879 ]train loss : 0.630364 ,train acc: 0.552124 ,val loss : 0.112254 ,val acc : 0.992737\n",
      "[ ecpho : 1  iter :880 ]train loss : 0.164278 ,train acc: 0.973785 ,val loss : 0.113988 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :881 ]train loss : 1.174916 ,train acc: 0.205231 ,val loss : 0.113622 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :882 ]train loss : 0.065436 ,train acc: 0.995544 ,val loss : 0.113936 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :883 ]train loss : 0.110593 ,train acc: 0.986145 ,val loss : 0.110237 ,val acc : 0.992554\n",
      "[ ecpho : 1  iter :884 ]train loss : 0.069935 ,train acc: 0.997986 ,val loss : 0.110456 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :885 ]train loss : 0.226055 ,train acc: 0.934143 ,val loss : 0.110375 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :886 ]train loss : 0.093398 ,train acc: 0.992981 ,val loss : 0.109776 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :887 ]train loss : 0.275295 ,train acc: 0.877747 ,val loss : 0.113447 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :888 ]train loss : 0.102754 ,train acc: 0.981201 ,val loss : 0.110828 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :889 ]train loss : 0.205761 ,train acc: 0.952179 ,val loss : 0.113110 ,val acc : 0.992432\n",
      "[ ecpho : 1  iter :890 ]train loss : 0.145822 ,train acc: 0.985870 ,val loss : 0.111563 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :891 ]train loss : 0.096583 ,train acc: 0.994507 ,val loss : 0.112032 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :892 ]train loss : 0.133095 ,train acc: 0.955933 ,val loss : 0.110652 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :893 ]train loss : 0.074985 ,train acc: 0.992737 ,val loss : 0.110765 ,val acc : 0.992676\n",
      "[ ecpho : 1  iter :894 ]train loss : 0.064536 ,train acc: 0.998596 ,val loss : 0.112101 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :895 ]train loss : 0.076572 ,train acc: 0.992249 ,val loss : 0.110678 ,val acc : 0.992950\n",
      "[ ecpho : 1  iter :896 ]train loss : 0.106115 ,train acc: 0.990845 ,val loss : 0.114596 ,val acc : 0.992493\n",
      "[ ecpho : 1  iter :897 ]train loss : 0.116470 ,train acc: 0.973602 ,val loss : 0.112486 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :898 ]train loss : 0.107114 ,train acc: 0.979340 ,val loss : 0.109506 ,val acc : 0.992401\n",
      "[ ecpho : 1  iter :899 ]train loss : 0.086781 ,train acc: 0.985931 ,val loss : 0.112270 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :900 ]train loss : 0.087391 ,train acc: 0.989349 ,val loss : 0.112206 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :901 ]train loss : 0.112068 ,train acc: 0.987152 ,val loss : 0.110040 ,val acc : 0.992371\n",
      "[ ecpho : 1  iter :902 ]train loss : 0.118636 ,train acc: 0.971344 ,val loss : 0.108557 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :903 ]train loss : 0.418865 ,train acc: 0.704376 ,val loss : 0.110242 ,val acc : 0.992950\n",
      "[ ecpho : 1  iter :904 ]train loss : 0.171370 ,train acc: 0.918213 ,val loss : 0.107059 ,val acc : 0.992615\n",
      "[ ecpho : 1  iter :905 ]train loss : 0.075920 ,train acc: 0.996552 ,val loss : 0.109206 ,val acc : 0.992767\n",
      "[ ecpho : 1  iter :906 ]train loss : 0.075426 ,train acc: 0.997559 ,val loss : 0.108324 ,val acc : 0.992462\n",
      "[ ecpho : 1  iter :907 ]train loss : 0.640975 ,train acc: 0.567871 ,val loss : 0.111491 ,val acc : 0.992523\n",
      "[ ecpho : 1  iter :908 ]train loss : 0.124008 ,train acc: 0.966034 ,val loss : 0.110768 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :909 ]train loss : 0.223902 ,train acc: 0.920441 ,val loss : 0.110850 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :910 ]train loss : 0.096554 ,train acc: 0.996857 ,val loss : 0.110468 ,val acc : 0.992004\n",
      "[ ecpho : 1  iter :911 ]train loss : 0.220162 ,train acc: 0.913208 ,val loss : 0.109575 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :912 ]train loss : 0.195911 ,train acc: 0.918427 ,val loss : 0.112690 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :913 ]train loss : 0.067944 ,train acc: 0.998627 ,val loss : 0.111125 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :914 ]train loss : 0.060432 ,train acc: 0.998169 ,val loss : 0.109761 ,val acc : 0.992249\n",
      "[ ecpho : 1  iter :915 ]train loss : 1.012602 ,train acc: 0.423096 ,val loss : 0.111686 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :916 ]train loss : 0.181960 ,train acc: 0.933533 ,val loss : 0.113885 ,val acc : 0.992188\n",
      "[ ecpho : 1  iter :917 ]train loss : 0.104147 ,train acc: 0.978241 ,val loss : 0.114500 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :918 ]train loss : 0.132808 ,train acc: 0.956299 ,val loss : 0.111049 ,val acc : 0.991882\n",
      "[ ecpho : 1  iter :919 ]train loss : 0.078864 ,train acc: 0.990662 ,val loss : 0.112617 ,val acc : 0.991974\n",
      "[ ecpho : 1  iter :920 ]train loss : 0.349427 ,train acc: 0.774872 ,val loss : 0.114192 ,val acc : 0.992126\n",
      "[ ecpho : 1  iter :921 ]train loss : 0.087220 ,train acc: 0.988373 ,val loss : 0.110857 ,val acc : 0.991669\n",
      "[ ecpho : 1  iter :922 ]train loss : 0.163502 ,train acc: 0.972076 ,val loss : 0.113844 ,val acc : 0.991455\n",
      "[ ecpho : 1  iter :923 ]train loss : 0.074393 ,train acc: 0.997131 ,val loss : 0.110641 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :924 ]train loss : 0.153813 ,train acc: 0.941010 ,val loss : 0.110815 ,val acc : 0.991180\n",
      "[ ecpho : 1  iter :925 ]train loss : 0.090148 ,train acc: 0.993774 ,val loss : 0.112070 ,val acc : 0.991913\n",
      "[ ecpho : 1  iter :926 ]train loss : 0.066481 ,train acc: 0.997864 ,val loss : 0.110082 ,val acc : 0.991577\n",
      "[ ecpho : 1  iter :927 ]train loss : 0.331488 ,train acc: 0.785095 ,val loss : 0.110501 ,val acc : 0.992218\n",
      "[ ecpho : 1  iter :928 ]train loss : 0.068119 ,train acc: 0.997528 ,val loss : 0.111897 ,val acc : 0.991638\n",
      "[ ecpho : 1  iter :929 ]train loss : 0.117540 ,train acc: 0.983582 ,val loss : 0.110890 ,val acc : 0.991791\n",
      "[ ecpho : 1  iter :930 ]train loss : 0.085989 ,train acc: 0.987396 ,val loss : 0.114190 ,val acc : 0.991760\n",
      "[ ecpho : 1  iter :931 ]train loss : 0.075019 ,train acc: 0.993622 ,val loss : 0.113225 ,val acc : 0.991730\n",
      "[ ecpho : 1  iter :932 ]train loss : 0.213636 ,train acc: 0.902710 ,val loss : 0.113521 ,val acc : 0.992157\n",
      "[ ecpho : 1  iter :933 ]train loss : 0.093446 ,train acc: 0.997894 ,val loss : 0.109621 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :934 ]train loss : 0.172185 ,train acc: 0.919128 ,val loss : 0.107506 ,val acc : 0.991516\n",
      "[ ecpho : 1  iter :935 ]train loss : 0.098124 ,train acc: 0.996246 ,val loss : 0.113178 ,val acc : 0.992065\n",
      "[ ecpho : 1  iter :936 ]train loss : 0.083315 ,train acc: 0.993713 ,val loss : 0.115779 ,val acc : 0.991943\n",
      "[ ecpho : 1  iter :937 ]train loss : 0.084762 ,train acc: 0.988495 ,val loss : 0.110058 ,val acc : 0.991852\n",
      "[ ecpho : 1  iter :938 ]train loss : 0.126045 ,train acc: 0.987213 ,val loss : 0.110520 ,val acc : 0.992035\n",
      "[ ecpho : 1  iter :939 ]train loss : 0.148829 ,train acc: 0.949097 ,val loss : 0.113235 ,val acc : 0.992279\n",
      "[ ecpho : 1  iter :940 ]train loss : 0.166699 ,train acc: 0.972443 ,val loss : 0.108412 ,val acc : 0.992371\n",
      "=============================================\n",
      "[ 1 ] average train loss : 0.169663 train acc : 0.934444\n",
      "[ ecpho : 2  iter :1 ]train loss : 0.079990 ,train acc: 0.991486 ,val loss : 0.114029 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :2 ]train loss : 0.227713 ,train acc: 0.894196 ,val loss : 0.110135 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :3 ]train loss : 0.079093 ,train acc: 0.993530 ,val loss : 0.109258 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :4 ]train loss : 0.106134 ,train acc: 0.974152 ,val loss : 0.111522 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :5 ]train loss : 0.096289 ,train acc: 0.994415 ,val loss : 0.109895 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :6 ]train loss : 0.094179 ,train acc: 0.993256 ,val loss : 0.111944 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :7 ]train loss : 0.093280 ,train acc: 0.977783 ,val loss : 0.109441 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :8 ]train loss : 0.368180 ,train acc: 0.859406 ,val loss : 0.112868 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :9 ]train loss : 0.169030 ,train acc: 0.926361 ,val loss : 0.110346 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :10 ]train loss : 0.154030 ,train acc: 0.952484 ,val loss : 0.110624 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :11 ]train loss : 0.074109 ,train acc: 0.998810 ,val loss : 0.110115 ,val acc : 0.992950\n",
      "[ ecpho : 2  iter :12 ]train loss : 0.093732 ,train acc: 0.994049 ,val loss : 0.112199 ,val acc : 0.993073\n",
      "[ ecpho : 2  iter :13 ]train loss : 0.092053 ,train acc: 0.985901 ,val loss : 0.109193 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :14 ]train loss : 0.100488 ,train acc: 0.996765 ,val loss : 0.110122 ,val acc : 0.993073\n",
      "[ ecpho : 2  iter :15 ]train loss : 0.085032 ,train acc: 0.983521 ,val loss : 0.110305 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :16 ]train loss : 0.092379 ,train acc: 0.994049 ,val loss : 0.107518 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :17 ]train loss : 0.086452 ,train acc: 0.996765 ,val loss : 0.108828 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :18 ]train loss : 0.759262 ,train acc: 0.505859 ,val loss : 0.108708 ,val acc : 0.992950\n",
      "[ ecpho : 2  iter :19 ]train loss : 0.097298 ,train acc: 0.981293 ,val loss : 0.109555 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :20 ]train loss : 0.096985 ,train acc: 0.992859 ,val loss : 0.109418 ,val acc : 0.993134\n",
      "[ ecpho : 2  iter :21 ]train loss : 0.112164 ,train acc: 0.986206 ,val loss : 0.111102 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :22 ]train loss : 0.118489 ,train acc: 0.973724 ,val loss : 0.110884 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :23 ]train loss : 0.058991 ,train acc: 0.999207 ,val loss : 0.109675 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :24 ]train loss : 0.109501 ,train acc: 0.991760 ,val loss : 0.109398 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :25 ]train loss : 0.107207 ,train acc: 0.976379 ,val loss : 0.110397 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :26 ]train loss : 0.425557 ,train acc: 0.779785 ,val loss : 0.106237 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :27 ]train loss : 0.354170 ,train acc: 0.770630 ,val loss : 0.110681 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :28 ]train loss : 0.084467 ,train acc: 0.995148 ,val loss : 0.110863 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :29 ]train loss : 0.099471 ,train acc: 0.982574 ,val loss : 0.111309 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :30 ]train loss : 0.078819 ,train acc: 0.995270 ,val loss : 0.109907 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :31 ]train loss : 0.084083 ,train acc: 0.992218 ,val loss : 0.109217 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :32 ]train loss : 0.080602 ,train acc: 0.989166 ,val loss : 0.109857 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :33 ]train loss : 0.061784 ,train acc: 0.997955 ,val loss : 0.110546 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :34 ]train loss : 0.086368 ,train acc: 0.994110 ,val loss : 0.110714 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :35 ]train loss : 0.071500 ,train acc: 0.997650 ,val loss : 0.109571 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :36 ]train loss : 0.112919 ,train acc: 0.969727 ,val loss : 0.110166 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :37 ]train loss : 0.103563 ,train acc: 0.994568 ,val loss : 0.110185 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :38 ]train loss : 0.114482 ,train acc: 0.964233 ,val loss : 0.110482 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :39 ]train loss : 0.252287 ,train acc: 0.854462 ,val loss : 0.110444 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :40 ]train loss : 0.231825 ,train acc: 0.939728 ,val loss : 0.113127 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :41 ]train loss : 0.079323 ,train acc: 0.994659 ,val loss : 0.109788 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :42 ]train loss : 0.080190 ,train acc: 0.994415 ,val loss : 0.109704 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :43 ]train loss : 0.188035 ,train acc: 0.954224 ,val loss : 0.110006 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :44 ]train loss : 0.086420 ,train acc: 0.989746 ,val loss : 0.108641 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :45 ]train loss : 0.102061 ,train acc: 0.985107 ,val loss : 0.110297 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :46 ]train loss : 0.783163 ,train acc: 0.428711 ,val loss : 0.110256 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :47 ]train loss : 0.095669 ,train acc: 0.977661 ,val loss : 0.106656 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :48 ]train loss : 0.113452 ,train acc: 0.985596 ,val loss : 0.109075 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :49 ]train loss : 0.103707 ,train acc: 0.992645 ,val loss : 0.111572 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :50 ]train loss : 0.105311 ,train acc: 0.974640 ,val loss : 0.111412 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :51 ]train loss : 0.082074 ,train acc: 0.995972 ,val loss : 0.107582 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :52 ]train loss : 0.114640 ,train acc: 0.991302 ,val loss : 0.108543 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :53 ]train loss : 0.108431 ,train acc: 0.974701 ,val loss : 0.107765 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :54 ]train loss : 0.174368 ,train acc: 0.921356 ,val loss : 0.107511 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :55 ]train loss : 0.113538 ,train acc: 0.992249 ,val loss : 0.110659 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :56 ]train loss : 0.190599 ,train acc: 0.916473 ,val loss : 0.106678 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :57 ]train loss : 0.363336 ,train acc: 0.772247 ,val loss : 0.110406 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :58 ]train loss : 0.078830 ,train acc: 0.992371 ,val loss : 0.110348 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :59 ]train loss : 0.131839 ,train acc: 0.967896 ,val loss : 0.108414 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :60 ]train loss : 0.068063 ,train acc: 0.999084 ,val loss : 0.108139 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :61 ]train loss : 0.146634 ,train acc: 0.951080 ,val loss : 0.108175 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :62 ]train loss : 0.130163 ,train acc: 0.956299 ,val loss : 0.107817 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :63 ]train loss : 0.437534 ,train acc: 0.710571 ,val loss : 0.107711 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :64 ]train loss : 0.400205 ,train acc: 0.782928 ,val loss : 0.108801 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :65 ]train loss : 0.142447 ,train acc: 0.981079 ,val loss : 0.108828 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :66 ]train loss : 0.080250 ,train acc: 0.997467 ,val loss : 0.109075 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :67 ]train loss : 0.112768 ,train acc: 0.980530 ,val loss : 0.108600 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :68 ]train loss : 0.078390 ,train acc: 0.996918 ,val loss : 0.112503 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :69 ]train loss : 0.090842 ,train acc: 0.996399 ,val loss : 0.109062 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :70 ]train loss : 0.119496 ,train acc: 0.985107 ,val loss : 0.108589 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :71 ]train loss : 0.081442 ,train acc: 0.991180 ,val loss : 0.110015 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :72 ]train loss : 0.087572 ,train acc: 0.985718 ,val loss : 0.108447 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :73 ]train loss : 0.071599 ,train acc: 0.994141 ,val loss : 0.110083 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :74 ]train loss : 0.546871 ,train acc: 0.642670 ,val loss : 0.107539 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :75 ]train loss : 0.109013 ,train acc: 0.972626 ,val loss : 0.109411 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :76 ]train loss : 0.065260 ,train acc: 0.997803 ,val loss : 0.111362 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :77 ]train loss : 0.081471 ,train acc: 0.992096 ,val loss : 0.108980 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :78 ]train loss : 0.067384 ,train acc: 0.993713 ,val loss : 0.110875 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :79 ]train loss : 0.061923 ,train acc: 0.996185 ,val loss : 0.111964 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :80 ]train loss : 0.102066 ,train acc: 0.992737 ,val loss : 0.108197 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :81 ]train loss : 0.095826 ,train acc: 0.981995 ,val loss : 0.107551 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :82 ]train loss : 0.453472 ,train acc: 0.716400 ,val loss : 0.110293 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :83 ]train loss : 0.082946 ,train acc: 0.992249 ,val loss : 0.107702 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :84 ]train loss : 0.081410 ,train acc: 0.998779 ,val loss : 0.109170 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :85 ]train loss : 0.069636 ,train acc: 0.995911 ,val loss : 0.108258 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :86 ]train loss : 0.069818 ,train acc: 0.997772 ,val loss : 0.106613 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :87 ]train loss : 0.094472 ,train acc: 0.987732 ,val loss : 0.104227 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :88 ]train loss : 0.113313 ,train acc: 0.986938 ,val loss : 0.107447 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :89 ]train loss : 0.224878 ,train acc: 0.880432 ,val loss : 0.106972 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :90 ]train loss : 0.330342 ,train acc: 0.866272 ,val loss : 0.110069 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :91 ]train loss : 0.078301 ,train acc: 0.997375 ,val loss : 0.109737 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :92 ]train loss : 0.160443 ,train acc: 0.929535 ,val loss : 0.108847 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :93 ]train loss : 0.376471 ,train acc: 0.783295 ,val loss : 0.108220 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :94 ]train loss : 0.083334 ,train acc: 0.996765 ,val loss : 0.107713 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :95 ]train loss : 0.611186 ,train acc: 0.690857 ,val loss : 0.109020 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :96 ]train loss : 0.119932 ,train acc: 0.973907 ,val loss : 0.109969 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :97 ]train loss : 0.095409 ,train acc: 0.979553 ,val loss : 0.109877 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :98 ]train loss : 0.090493 ,train acc: 0.994873 ,val loss : 0.106550 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :99 ]train loss : 0.064649 ,train acc: 0.997681 ,val loss : 0.107682 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :100 ]train loss : 0.134753 ,train acc: 0.974548 ,val loss : 0.109167 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :101 ]train loss : 0.093973 ,train acc: 0.993927 ,val loss : 0.109392 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :102 ]train loss : 0.492787 ,train acc: 0.690735 ,val loss : 0.108134 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :103 ]train loss : 0.505790 ,train acc: 0.753326 ,val loss : 0.110113 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :104 ]train loss : 0.463313 ,train acc: 0.684937 ,val loss : 0.109440 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :105 ]train loss : 0.082603 ,train acc: 0.991089 ,val loss : 0.108456 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :106 ]train loss : 0.139154 ,train acc: 0.977448 ,val loss : 0.112775 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :107 ]train loss : 0.154086 ,train acc: 0.961212 ,val loss : 0.108352 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :108 ]train loss : 0.099491 ,train acc: 0.993347 ,val loss : 0.110118 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :109 ]train loss : 0.221506 ,train acc: 0.915985 ,val loss : 0.107978 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :110 ]train loss : 0.065914 ,train acc: 0.998260 ,val loss : 0.108307 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :111 ]train loss : 0.257399 ,train acc: 0.866150 ,val loss : 0.109885 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :112 ]train loss : 0.098169 ,train acc: 0.983459 ,val loss : 0.109440 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :113 ]train loss : 0.821107 ,train acc: 0.464539 ,val loss : 0.109395 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :114 ]train loss : 0.081219 ,train acc: 0.989532 ,val loss : 0.108026 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :115 ]train loss : 0.073796 ,train acc: 0.993042 ,val loss : 0.108450 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :116 ]train loss : 0.311690 ,train acc: 0.791016 ,val loss : 0.109703 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :117 ]train loss : 0.116864 ,train acc: 0.968201 ,val loss : 0.108871 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :118 ]train loss : 0.116618 ,train acc: 0.961273 ,val loss : 0.110957 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :119 ]train loss : 0.086729 ,train acc: 0.991943 ,val loss : 0.110719 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :120 ]train loss : 0.066520 ,train acc: 0.998077 ,val loss : 0.108419 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :121 ]train loss : 0.605090 ,train acc: 0.606842 ,val loss : 0.111266 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :122 ]train loss : 0.081862 ,train acc: 0.991547 ,val loss : 0.111944 ,val acc : 0.991608\n",
      "[ ecpho : 2  iter :123 ]train loss : 0.087776 ,train acc: 0.996948 ,val loss : 0.112208 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :124 ]train loss : 0.075897 ,train acc: 0.994781 ,val loss : 0.112196 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :125 ]train loss : 0.100096 ,train acc: 0.991333 ,val loss : 0.111102 ,val acc : 0.991119\n",
      "[ ecpho : 2  iter :126 ]train loss : 0.067249 ,train acc: 0.998047 ,val loss : 0.108990 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :127 ]train loss : 0.918670 ,train acc: 0.355011 ,val loss : 0.109709 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :128 ]train loss : 0.097569 ,train acc: 0.989685 ,val loss : 0.108994 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :129 ]train loss : 0.523131 ,train acc: 0.659485 ,val loss : 0.110771 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :130 ]train loss : 0.417717 ,train acc: 0.713165 ,val loss : 0.110684 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :131 ]train loss : 0.107456 ,train acc: 0.975281 ,val loss : 0.111921 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :132 ]train loss : 0.091004 ,train acc: 0.992920 ,val loss : 0.116979 ,val acc : 0.990814\n",
      "[ ecpho : 2  iter :133 ]train loss : 0.312032 ,train acc: 0.849518 ,val loss : 0.112966 ,val acc : 0.990570\n",
      "[ ecpho : 2  iter :134 ]train loss : 0.478719 ,train acc: 0.703644 ,val loss : 0.114497 ,val acc : 0.990417\n",
      "[ ecpho : 2  iter :135 ]train loss : 0.124890 ,train acc: 0.982635 ,val loss : 0.111750 ,val acc : 0.990417\n",
      "[ ecpho : 2  iter :136 ]train loss : 0.129214 ,train acc: 0.958405 ,val loss : 0.115353 ,val acc : 0.990753\n",
      "[ ecpho : 2  iter :137 ]train loss : 0.100801 ,train acc: 0.983307 ,val loss : 0.112552 ,val acc : 0.990448\n",
      "[ ecpho : 2  iter :138 ]train loss : 0.071312 ,train acc: 0.996460 ,val loss : 0.113192 ,val acc : 0.990631\n",
      "[ ecpho : 2  iter :139 ]train loss : 0.064257 ,train acc: 0.998566 ,val loss : 0.111704 ,val acc : 0.990387\n",
      "[ ecpho : 2  iter :140 ]train loss : 0.079588 ,train acc: 0.996063 ,val loss : 0.111982 ,val acc : 0.990448\n",
      "[ ecpho : 2  iter :141 ]train loss : 0.588381 ,train acc: 0.554321 ,val loss : 0.111957 ,val acc : 0.990082\n",
      "[ ecpho : 2  iter :142 ]train loss : 0.085664 ,train acc: 0.982147 ,val loss : 0.111581 ,val acc : 0.990387\n",
      "[ ecpho : 2  iter :143 ]train loss : 0.101566 ,train acc: 0.977417 ,val loss : 0.113075 ,val acc : 0.989807\n",
      "[ ecpho : 2  iter :144 ]train loss : 0.100852 ,train acc: 0.974243 ,val loss : 0.111504 ,val acc : 0.990295\n",
      "[ ecpho : 2  iter :145 ]train loss : 0.076246 ,train acc: 0.991364 ,val loss : 0.113917 ,val acc : 0.990356\n",
      "[ ecpho : 2  iter :146 ]train loss : 0.078012 ,train acc: 0.991028 ,val loss : 0.112621 ,val acc : 0.990509\n",
      "[ ecpho : 2  iter :147 ]train loss : 0.076444 ,train acc: 0.992981 ,val loss : 0.109718 ,val acc : 0.989929\n",
      "[ ecpho : 2  iter :148 ]train loss : 1.135837 ,train acc: 0.223694 ,val loss : 0.110855 ,val acc : 0.990051\n",
      "[ ecpho : 2  iter :149 ]train loss : 0.146077 ,train acc: 0.949097 ,val loss : 0.112292 ,val acc : 0.990295\n",
      "[ ecpho : 2  iter :150 ]train loss : 0.119998 ,train acc: 0.975891 ,val loss : 0.112903 ,val acc : 0.990051\n",
      "[ ecpho : 2  iter :151 ]train loss : 0.812654 ,train acc: 0.429718 ,val loss : 0.112442 ,val acc : 0.990021\n",
      "[ ecpho : 2  iter :152 ]train loss : 0.232661 ,train acc: 0.922028 ,val loss : 0.112408 ,val acc : 0.989563\n",
      "[ ecpho : 2  iter :153 ]train loss : 0.132592 ,train acc: 0.953491 ,val loss : 0.111903 ,val acc : 0.989624\n",
      "[ ecpho : 2  iter :154 ]train loss : 0.209975 ,train acc: 0.941223 ,val loss : 0.115044 ,val acc : 0.989563\n",
      "[ ecpho : 2  iter :155 ]train loss : 0.101409 ,train acc: 0.986664 ,val loss : 0.115834 ,val acc : 0.989197\n",
      "[ ecpho : 2  iter :156 ]train loss : 0.086233 ,train acc: 0.987701 ,val loss : 0.115236 ,val acc : 0.989380\n",
      "[ ecpho : 2  iter :157 ]train loss : 0.099002 ,train acc: 0.994446 ,val loss : 0.117874 ,val acc : 0.988892\n",
      "[ ecpho : 2  iter :158 ]train loss : 0.081849 ,train acc: 0.994843 ,val loss : 0.112612 ,val acc : 0.989105\n",
      "[ ecpho : 2  iter :159 ]train loss : 0.116288 ,train acc: 0.982910 ,val loss : 0.111098 ,val acc : 0.990448\n",
      "[ ecpho : 2  iter :160 ]train loss : 0.127601 ,train acc: 0.961273 ,val loss : 0.112296 ,val acc : 0.990173\n",
      "[ ecpho : 2  iter :161 ]train loss : 1.220298 ,train acc: 0.127472 ,val loss : 0.110742 ,val acc : 0.990326\n",
      "[ ecpho : 2  iter :162 ]train loss : 0.167647 ,train acc: 0.946503 ,val loss : 0.108824 ,val acc : 0.989990\n",
      "[ ecpho : 2  iter :163 ]train loss : 0.117190 ,train acc: 0.965302 ,val loss : 0.114451 ,val acc : 0.990204\n",
      "[ ecpho : 2  iter :164 ]train loss : 0.140327 ,train acc: 0.974060 ,val loss : 0.113231 ,val acc : 0.990356\n",
      "[ ecpho : 2  iter :165 ]train loss : 0.080483 ,train acc: 0.994720 ,val loss : 0.111369 ,val acc : 0.990295\n",
      "[ ecpho : 2  iter :166 ]train loss : 0.091559 ,train acc: 0.986328 ,val loss : 0.108614 ,val acc : 0.990265\n",
      "[ ecpho : 2  iter :167 ]train loss : 0.420301 ,train acc: 0.727051 ,val loss : 0.113531 ,val acc : 0.990051\n",
      "[ ecpho : 2  iter :168 ]train loss : 0.131684 ,train acc: 0.958008 ,val loss : 0.111083 ,val acc : 0.990417\n",
      "[ ecpho : 2  iter :169 ]train loss : 0.316997 ,train acc: 0.841095 ,val loss : 0.110522 ,val acc : 0.990265\n",
      "[ ecpho : 2  iter :170 ]train loss : 0.842098 ,train acc: 0.444122 ,val loss : 0.110842 ,val acc : 0.990479\n",
      "[ ecpho : 2  iter :171 ]train loss : 0.086302 ,train acc: 0.988953 ,val loss : 0.110307 ,val acc : 0.989838\n",
      "[ ecpho : 2  iter :172 ]train loss : 0.395246 ,train acc: 0.799530 ,val loss : 0.110202 ,val acc : 0.989471\n",
      "[ ecpho : 2  iter :173 ]train loss : 0.696244 ,train acc: 0.530884 ,val loss : 0.112510 ,val acc : 0.989349\n",
      "[ ecpho : 2  iter :174 ]train loss : 0.123085 ,train acc: 0.983948 ,val loss : 0.114264 ,val acc : 0.989441\n",
      "[ ecpho : 2  iter :175 ]train loss : 0.075409 ,train acc: 0.995667 ,val loss : 0.111692 ,val acc : 0.989502\n",
      "[ ecpho : 2  iter :176 ]train loss : 0.268400 ,train acc: 0.837341 ,val loss : 0.114019 ,val acc : 0.988464\n",
      "[ ecpho : 2  iter :177 ]train loss : 0.106450 ,train acc: 0.984680 ,val loss : 0.112636 ,val acc : 0.988586\n",
      "[ ecpho : 2  iter :178 ]train loss : 0.103010 ,train acc: 0.990356 ,val loss : 0.111705 ,val acc : 0.988403\n",
      "[ ecpho : 2  iter :179 ]train loss : 0.178826 ,train acc: 0.919800 ,val loss : 0.112761 ,val acc : 0.987274\n",
      "[ ecpho : 2  iter :180 ]train loss : 0.083422 ,train acc: 0.987701 ,val loss : 0.114807 ,val acc : 0.987885\n",
      "[ ecpho : 2  iter :181 ]train loss : 0.190642 ,train acc: 0.950104 ,val loss : 0.114012 ,val acc : 0.987457\n",
      "[ ecpho : 2  iter :182 ]train loss : 0.125021 ,train acc: 0.978363 ,val loss : 0.114679 ,val acc : 0.988068\n",
      "[ ecpho : 2  iter :183 ]train loss : 0.089135 ,train acc: 0.989655 ,val loss : 0.113810 ,val acc : 0.988251\n",
      "[ ecpho : 2  iter :184 ]train loss : 0.092712 ,train acc: 0.987213 ,val loss : 0.111914 ,val acc : 0.987762\n",
      "[ ecpho : 2  iter :185 ]train loss : 0.817920 ,train acc: 0.387604 ,val loss : 0.112170 ,val acc : 0.987274\n",
      "[ ecpho : 2  iter :186 ]train loss : 0.127381 ,train acc: 0.959015 ,val loss : 0.112829 ,val acc : 0.987671\n",
      "[ ecpho : 2  iter :187 ]train loss : 0.119113 ,train acc: 0.977570 ,val loss : 0.113317 ,val acc : 0.987915\n",
      "[ ecpho : 2  iter :188 ]train loss : 0.098954 ,train acc: 0.991577 ,val loss : 0.114506 ,val acc : 0.987518\n",
      "[ ecpho : 2  iter :189 ]train loss : 0.074890 ,train acc: 0.994843 ,val loss : 0.112328 ,val acc : 0.988586\n",
      "[ ecpho : 2  iter :190 ]train loss : 0.116084 ,train acc: 0.988312 ,val loss : 0.113956 ,val acc : 0.989136\n",
      "[ ecpho : 2  iter :191 ]train loss : 0.186693 ,train acc: 0.911133 ,val loss : 0.112481 ,val acc : 0.988434\n",
      "[ ecpho : 2  iter :192 ]train loss : 0.082030 ,train acc: 0.992981 ,val loss : 0.115256 ,val acc : 0.989014\n",
      "[ ecpho : 2  iter :193 ]train loss : 0.139527 ,train acc: 0.951263 ,val loss : 0.113932 ,val acc : 0.989105\n",
      "[ ecpho : 2  iter :194 ]train loss : 0.358809 ,train acc: 0.812775 ,val loss : 0.112906 ,val acc : 0.989166\n",
      "[ ecpho : 2  iter :195 ]train loss : 0.077962 ,train acc: 0.989471 ,val loss : 0.115163 ,val acc : 0.989349\n",
      "[ ecpho : 2  iter :196 ]train loss : 0.076819 ,train acc: 0.993652 ,val loss : 0.112881 ,val acc : 0.989380\n",
      "[ ecpho : 2  iter :197 ]train loss : 0.086103 ,train acc: 0.990082 ,val loss : 0.110417 ,val acc : 0.989685\n",
      "[ ecpho : 2  iter :198 ]train loss : 0.080044 ,train acc: 0.992157 ,val loss : 0.113291 ,val acc : 0.989227\n",
      "[ ecpho : 2  iter :199 ]train loss : 0.427914 ,train acc: 0.701294 ,val loss : 0.113324 ,val acc : 0.989777\n",
      "[ ecpho : 2  iter :200 ]train loss : 0.198201 ,train acc: 0.916351 ,val loss : 0.110805 ,val acc : 0.990143\n",
      "[ ecpho : 2  iter :201 ]train loss : 0.071761 ,train acc: 0.992340 ,val loss : 0.111046 ,val acc : 0.990631\n",
      "[ ecpho : 2  iter :202 ]train loss : 0.080864 ,train acc: 0.996429 ,val loss : 0.114239 ,val acc : 0.989777\n",
      "[ ecpho : 2  iter :203 ]train loss : 0.130889 ,train acc: 0.975311 ,val loss : 0.112738 ,val acc : 0.990448\n",
      "[ ecpho : 2  iter :204 ]train loss : 0.110549 ,train acc: 0.973694 ,val loss : 0.111592 ,val acc : 0.990204\n",
      "[ ecpho : 2  iter :205 ]train loss : 0.083468 ,train acc: 0.992432 ,val loss : 0.111746 ,val acc : 0.989960\n",
      "[ ecpho : 2  iter :206 ]train loss : 0.296814 ,train acc: 0.838989 ,val loss : 0.110832 ,val acc : 0.990601\n",
      "[ ecpho : 2  iter :207 ]train loss : 0.215744 ,train acc: 0.889587 ,val loss : 0.110831 ,val acc : 0.990814\n",
      "[ ecpho : 2  iter :208 ]train loss : 0.104917 ,train acc: 0.990295 ,val loss : 0.112115 ,val acc : 0.990326\n",
      "[ ecpho : 2  iter :209 ]train loss : 0.094040 ,train acc: 0.982117 ,val loss : 0.113318 ,val acc : 0.990448\n",
      "[ ecpho : 2  iter :210 ]train loss : 0.067301 ,train acc: 0.997345 ,val loss : 0.113623 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :211 ]train loss : 0.086639 ,train acc: 0.984802 ,val loss : 0.113672 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :212 ]train loss : 0.337245 ,train acc: 0.773834 ,val loss : 0.111514 ,val acc : 0.990540\n",
      "[ ecpho : 2  iter :213 ]train loss : 0.076748 ,train acc: 0.993774 ,val loss : 0.110001 ,val acc : 0.990753\n",
      "[ ecpho : 2  iter :214 ]train loss : 0.084397 ,train acc: 0.987701 ,val loss : 0.116153 ,val acc : 0.990875\n",
      "[ ecpho : 2  iter :215 ]train loss : 0.088719 ,train acc: 0.984344 ,val loss : 0.112147 ,val acc : 0.991425\n",
      "[ ecpho : 2  iter :216 ]train loss : 0.088933 ,train acc: 0.988190 ,val loss : 0.114352 ,val acc : 0.990997\n",
      "[ ecpho : 2  iter :217 ]train loss : 0.134282 ,train acc: 0.974518 ,val loss : 0.112865 ,val acc : 0.990387\n",
      "[ ecpho : 2  iter :218 ]train loss : 0.090943 ,train acc: 0.982941 ,val loss : 0.111295 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :219 ]train loss : 0.077893 ,train acc: 0.991119 ,val loss : 0.113527 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :220 ]train loss : 0.090607 ,train acc: 0.980682 ,val loss : 0.110841 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :221 ]train loss : 0.065393 ,train acc: 0.993713 ,val loss : 0.114964 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :222 ]train loss : 0.076112 ,train acc: 0.995850 ,val loss : 0.109569 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :223 ]train loss : 0.071365 ,train acc: 0.994507 ,val loss : 0.112006 ,val acc : 0.991425\n",
      "[ ecpho : 2  iter :224 ]train loss : 0.445083 ,train acc: 0.682312 ,val loss : 0.112852 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :225 ]train loss : 0.082155 ,train acc: 0.993042 ,val loss : 0.113940 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :226 ]train loss : 0.126518 ,train acc: 0.978638 ,val loss : 0.111341 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :227 ]train loss : 0.221159 ,train acc: 0.947357 ,val loss : 0.110479 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :228 ]train loss : 0.210394 ,train acc: 0.894928 ,val loss : 0.113566 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :229 ]train loss : 0.124772 ,train acc: 0.962860 ,val loss : 0.110722 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :230 ]train loss : 0.109998 ,train acc: 0.974792 ,val loss : 0.110085 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :231 ]train loss : 0.084799 ,train acc: 0.991211 ,val loss : 0.111850 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :232 ]train loss : 0.084836 ,train acc: 0.990967 ,val loss : 0.113392 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :233 ]train loss : 0.092940 ,train acc: 0.994995 ,val loss : 0.109993 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :234 ]train loss : 0.167383 ,train acc: 0.931549 ,val loss : 0.112113 ,val acc : 0.990997\n",
      "[ ecpho : 2  iter :235 ]train loss : 0.077607 ,train acc: 0.996765 ,val loss : 0.110852 ,val acc : 0.991577\n",
      "[ ecpho : 2  iter :236 ]train loss : 0.075049 ,train acc: 0.996979 ,val loss : 0.113864 ,val acc : 0.991333\n",
      "[ ecpho : 2  iter :237 ]train loss : 0.121636 ,train acc: 0.964569 ,val loss : 0.111308 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :238 ]train loss : 0.109142 ,train acc: 0.978638 ,val loss : 0.109911 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :239 ]train loss : 0.083254 ,train acc: 0.994629 ,val loss : 0.112105 ,val acc : 0.991028\n",
      "[ ecpho : 2  iter :240 ]train loss : 0.162326 ,train acc: 0.960144 ,val loss : 0.112946 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :241 ]train loss : 0.199825 ,train acc: 0.893921 ,val loss : 0.111783 ,val acc : 0.991119\n",
      "[ ecpho : 2  iter :242 ]train loss : 0.106098 ,train acc: 0.973663 ,val loss : 0.113622 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :243 ]train loss : 0.115055 ,train acc: 0.973724 ,val loss : 0.112897 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :244 ]train loss : 0.061660 ,train acc: 0.998322 ,val loss : 0.110926 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :245 ]train loss : 0.085606 ,train acc: 0.995270 ,val loss : 0.111353 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :246 ]train loss : 0.095710 ,train acc: 0.985657 ,val loss : 0.112256 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :247 ]train loss : 0.070197 ,train acc: 0.998810 ,val loss : 0.112221 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :248 ]train loss : 0.073180 ,train acc: 0.997681 ,val loss : 0.112397 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :249 ]train loss : 0.066458 ,train acc: 0.999390 ,val loss : 0.111546 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :250 ]train loss : 0.065538 ,train acc: 0.997681 ,val loss : 0.113041 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :251 ]train loss : 0.097762 ,train acc: 0.977814 ,val loss : 0.111217 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :252 ]train loss : 0.075418 ,train acc: 0.997314 ,val loss : 0.108869 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :253 ]train loss : 0.141188 ,train acc: 0.950897 ,val loss : 0.113764 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :254 ]train loss : 1.216076 ,train acc: 0.183502 ,val loss : 0.113079 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :255 ]train loss : 0.155655 ,train acc: 0.939178 ,val loss : 0.111922 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :256 ]train loss : 0.163131 ,train acc: 0.933716 ,val loss : 0.110545 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :257 ]train loss : 0.065575 ,train acc: 0.997314 ,val loss : 0.111577 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :258 ]train loss : 0.094139 ,train acc: 0.996765 ,val loss : 0.114408 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :259 ]train loss : 0.879383 ,train acc: 0.464417 ,val loss : 0.112534 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :260 ]train loss : 0.079413 ,train acc: 0.993744 ,val loss : 0.108005 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :261 ]train loss : 0.073165 ,train acc: 0.996033 ,val loss : 0.115407 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :262 ]train loss : 0.066045 ,train acc: 0.999237 ,val loss : 0.111330 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :263 ]train loss : 0.082874 ,train acc: 0.986969 ,val loss : 0.112398 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :264 ]train loss : 0.102681 ,train acc: 0.996033 ,val loss : 0.112585 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :265 ]train loss : 0.130387 ,train acc: 0.967926 ,val loss : 0.113368 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :266 ]train loss : 0.078239 ,train acc: 0.993744 ,val loss : 0.112621 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :267 ]train loss : 0.056265 ,train acc: 0.999725 ,val loss : 0.109608 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :268 ]train loss : 0.087207 ,train acc: 0.998077 ,val loss : 0.112744 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :269 ]train loss : 0.098625 ,train acc: 0.980499 ,val loss : 0.112397 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :270 ]train loss : 0.119757 ,train acc: 0.967163 ,val loss : 0.109862 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :271 ]train loss : 0.169795 ,train acc: 0.951324 ,val loss : 0.112252 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :272 ]train loss : 0.296582 ,train acc: 0.817139 ,val loss : 0.113309 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :273 ]train loss : 0.072614 ,train acc: 0.999023 ,val loss : 0.111806 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :274 ]train loss : 0.081190 ,train acc: 0.986237 ,val loss : 0.111836 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :275 ]train loss : 0.174208 ,train acc: 0.961243 ,val loss : 0.114206 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :276 ]train loss : 0.091211 ,train acc: 0.983765 ,val loss : 0.111762 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :277 ]train loss : 0.111619 ,train acc: 0.968964 ,val loss : 0.111669 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :278 ]train loss : 0.119881 ,train acc: 0.986786 ,val loss : 0.113745 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :279 ]train loss : 0.090110 ,train acc: 0.997314 ,val loss : 0.111606 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :280 ]train loss : 0.127693 ,train acc: 0.973633 ,val loss : 0.111908 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :281 ]train loss : 0.121937 ,train acc: 0.978119 ,val loss : 0.115878 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :282 ]train loss : 1.021894 ,train acc: 0.281586 ,val loss : 0.111652 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :283 ]train loss : 0.071450 ,train acc: 0.994629 ,val loss : 0.111818 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :284 ]train loss : 0.080905 ,train acc: 0.991577 ,val loss : 0.110213 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :285 ]train loss : 0.074882 ,train acc: 0.992554 ,val loss : 0.111124 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :286 ]train loss : 0.299797 ,train acc: 0.891266 ,val loss : 0.109621 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :287 ]train loss : 0.190944 ,train acc: 0.912384 ,val loss : 0.110517 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :288 ]train loss : 0.271035 ,train acc: 0.828430 ,val loss : 0.107901 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :289 ]train loss : 0.116088 ,train acc: 0.973480 ,val loss : 0.111542 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :290 ]train loss : 0.061368 ,train acc: 0.998230 ,val loss : 0.111713 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :291 ]train loss : 0.079399 ,train acc: 0.984344 ,val loss : 0.111537 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :292 ]train loss : 0.762764 ,train acc: 0.437073 ,val loss : 0.111797 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :293 ]train loss : 0.089763 ,train acc: 0.997986 ,val loss : 0.111440 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :294 ]train loss : 0.129643 ,train acc: 0.953217 ,val loss : 0.110762 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :295 ]train loss : 0.074785 ,train acc: 0.997864 ,val loss : 0.111128 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :296 ]train loss : 0.068343 ,train acc: 0.997711 ,val loss : 0.108417 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :297 ]train loss : 0.102131 ,train acc: 0.993164 ,val loss : 0.113151 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :298 ]train loss : 0.096690 ,train acc: 0.993744 ,val loss : 0.109645 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :299 ]train loss : 0.093617 ,train acc: 0.998169 ,val loss : 0.109903 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :300 ]train loss : 0.062773 ,train acc: 0.998596 ,val loss : 0.110971 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :301 ]train loss : 0.338264 ,train acc: 0.783600 ,val loss : 0.111790 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :302 ]train loss : 0.116402 ,train acc: 0.982605 ,val loss : 0.111953 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :303 ]train loss : 0.397896 ,train acc: 0.767212 ,val loss : 0.112339 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :304 ]train loss : 0.701383 ,train acc: 0.445435 ,val loss : 0.113788 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :305 ]train loss : 0.373452 ,train acc: 0.753113 ,val loss : 0.113475 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :306 ]train loss : 0.162081 ,train acc: 0.945038 ,val loss : 0.112198 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :307 ]train loss : 0.365862 ,train acc: 0.808228 ,val loss : 0.112252 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :308 ]train loss : 0.123900 ,train acc: 0.972198 ,val loss : 0.112926 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :309 ]train loss : 0.079432 ,train acc: 0.997650 ,val loss : 0.117282 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :310 ]train loss : 0.279955 ,train acc: 0.892914 ,val loss : 0.111220 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :311 ]train loss : 0.077827 ,train acc: 0.992462 ,val loss : 0.112457 ,val acc : 0.990967\n",
      "[ ecpho : 2  iter :312 ]train loss : 0.057805 ,train acc: 0.999420 ,val loss : 0.116152 ,val acc : 0.990753\n",
      "[ ecpho : 2  iter :313 ]train loss : 0.100793 ,train acc: 0.977905 ,val loss : 0.114504 ,val acc : 0.990906\n",
      "[ ecpho : 2  iter :314 ]train loss : 0.346842 ,train acc: 0.826447 ,val loss : 0.112583 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :315 ]train loss : 0.089663 ,train acc: 0.990204 ,val loss : 0.112350 ,val acc : 0.990906\n",
      "[ ecpho : 2  iter :316 ]train loss : 0.058626 ,train acc: 0.997925 ,val loss : 0.115181 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :317 ]train loss : 0.145257 ,train acc: 0.957794 ,val loss : 0.116344 ,val acc : 0.990509\n",
      "[ ecpho : 2  iter :318 ]train loss : 0.107728 ,train acc: 0.975159 ,val loss : 0.116068 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :319 ]train loss : 0.163509 ,train acc: 0.933136 ,val loss : 0.114529 ,val acc : 0.990997\n",
      "[ ecpho : 2  iter :320 ]train loss : 0.099718 ,train acc: 0.995361 ,val loss : 0.112596 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :321 ]train loss : 0.108956 ,train acc: 0.991791 ,val loss : 0.115851 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :322 ]train loss : 0.073283 ,train acc: 0.993652 ,val loss : 0.116389 ,val acc : 0.990906\n",
      "[ ecpho : 2  iter :323 ]train loss : 0.068298 ,train acc: 0.996979 ,val loss : 0.114748 ,val acc : 0.990845\n",
      "[ ecpho : 2  iter :324 ]train loss : 0.639604 ,train acc: 0.688110 ,val loss : 0.114490 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :325 ]train loss : 0.083553 ,train acc: 0.990570 ,val loss : 0.110719 ,val acc : 0.991119\n",
      "[ ecpho : 2  iter :326 ]train loss : 0.069561 ,train acc: 0.994019 ,val loss : 0.113844 ,val acc : 0.991028\n",
      "[ ecpho : 2  iter :327 ]train loss : 0.086955 ,train acc: 0.995789 ,val loss : 0.111098 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :328 ]train loss : 0.076628 ,train acc: 0.994019 ,val loss : 0.112700 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :329 ]train loss : 0.364847 ,train acc: 0.808594 ,val loss : 0.112117 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :330 ]train loss : 0.162939 ,train acc: 0.932617 ,val loss : 0.113277 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :331 ]train loss : 0.107598 ,train acc: 0.992798 ,val loss : 0.113640 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :332 ]train loss : 0.192140 ,train acc: 0.929962 ,val loss : 0.112037 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :333 ]train loss : 0.100491 ,train acc: 0.979095 ,val loss : 0.113617 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :334 ]train loss : 0.083387 ,train acc: 0.993561 ,val loss : 0.113742 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :335 ]train loss : 0.110979 ,train acc: 0.989563 ,val loss : 0.114416 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :336 ]train loss : 0.954837 ,train acc: 0.383698 ,val loss : 0.111547 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :337 ]train loss : 0.483996 ,train acc: 0.668823 ,val loss : 0.112232 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :338 ]train loss : 0.105393 ,train acc: 0.978485 ,val loss : 0.113757 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :339 ]train loss : 0.078030 ,train acc: 0.992126 ,val loss : 0.113177 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :340 ]train loss : 0.137900 ,train acc: 0.951904 ,val loss : 0.111925 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :341 ]train loss : 0.100803 ,train acc: 0.984467 ,val loss : 0.111003 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :342 ]train loss : 0.142422 ,train acc: 0.961853 ,val loss : 0.116203 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :343 ]train loss : 0.900711 ,train acc: 0.349060 ,val loss : 0.113745 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :344 ]train loss : 0.067589 ,train acc: 0.994995 ,val loss : 0.113386 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :345 ]train loss : 0.474904 ,train acc: 0.639740 ,val loss : 0.113342 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :346 ]train loss : 0.271969 ,train acc: 0.887512 ,val loss : 0.111935 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :347 ]train loss : 0.091869 ,train acc: 0.985443 ,val loss : 0.113145 ,val acc : 0.991577\n",
      "[ ecpho : 2  iter :348 ]train loss : 0.108053 ,train acc: 0.983154 ,val loss : 0.112474 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :349 ]train loss : 0.102894 ,train acc: 0.994751 ,val loss : 0.115621 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :350 ]train loss : 0.098410 ,train acc: 0.984192 ,val loss : 0.113551 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :351 ]train loss : 0.084810 ,train acc: 0.996826 ,val loss : 0.113703 ,val acc : 0.991089\n",
      "[ ecpho : 2  iter :352 ]train loss : 0.117977 ,train acc: 0.983032 ,val loss : 0.113985 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :353 ]train loss : 0.075237 ,train acc: 0.992493 ,val loss : 0.113271 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :354 ]train loss : 0.092821 ,train acc: 0.988586 ,val loss : 0.113786 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :355 ]train loss : 0.077906 ,train acc: 0.997833 ,val loss : 0.113372 ,val acc : 0.990875\n",
      "[ ecpho : 2  iter :356 ]train loss : 0.099178 ,train acc: 0.995575 ,val loss : 0.113931 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :357 ]train loss : 0.125362 ,train acc: 0.983917 ,val loss : 0.112211 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :358 ]train loss : 0.091321 ,train acc: 0.994843 ,val loss : 0.113706 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :359 ]train loss : 0.164652 ,train acc: 0.944885 ,val loss : 0.112879 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :360 ]train loss : 0.099821 ,train acc: 0.995667 ,val loss : 0.113285 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :361 ]train loss : 0.093587 ,train acc: 0.982697 ,val loss : 0.111906 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :362 ]train loss : 0.061679 ,train acc: 0.997833 ,val loss : 0.115209 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :363 ]train loss : 0.169022 ,train acc: 0.939728 ,val loss : 0.112356 ,val acc : 0.991608\n",
      "[ ecpho : 2  iter :364 ]train loss : 0.096646 ,train acc: 0.996643 ,val loss : 0.112377 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :365 ]train loss : 0.388436 ,train acc: 0.773621 ,val loss : 0.114545 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :366 ]train loss : 0.072306 ,train acc: 0.995514 ,val loss : 0.113301 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :367 ]train loss : 0.324035 ,train acc: 0.793488 ,val loss : 0.115287 ,val acc : 0.991394\n",
      "[ ecpho : 2  iter :368 ]train loss : 0.109062 ,train acc: 0.978058 ,val loss : 0.112685 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :369 ]train loss : 0.099614 ,train acc: 0.978027 ,val loss : 0.112449 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :370 ]train loss : 0.224718 ,train acc: 0.878143 ,val loss : 0.113126 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :371 ]train loss : 0.175836 ,train acc: 0.919006 ,val loss : 0.114570 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :372 ]train loss : 0.447461 ,train acc: 0.725769 ,val loss : 0.112535 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :373 ]train loss : 0.078762 ,train acc: 0.992798 ,val loss : 0.112476 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :374 ]train loss : 0.077771 ,train acc: 0.998657 ,val loss : 0.115283 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :375 ]train loss : 0.079805 ,train acc: 0.989716 ,val loss : 0.113812 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :376 ]train loss : 0.093544 ,train acc: 0.996857 ,val loss : 0.116099 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :377 ]train loss : 0.130048 ,train acc: 0.963867 ,val loss : 0.114805 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :378 ]train loss : 0.245383 ,train acc: 0.885773 ,val loss : 0.115208 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :379 ]train loss : 0.094929 ,train acc: 0.978943 ,val loss : 0.112357 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :380 ]train loss : 0.079597 ,train acc: 0.986755 ,val loss : 0.113439 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :381 ]train loss : 0.270645 ,train acc: 0.860535 ,val loss : 0.114008 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :382 ]train loss : 0.151490 ,train acc: 0.943848 ,val loss : 0.113133 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :383 ]train loss : 0.113537 ,train acc: 0.986786 ,val loss : 0.113749 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :384 ]train loss : 0.088265 ,train acc: 0.986389 ,val loss : 0.116204 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :385 ]train loss : 0.089330 ,train acc: 0.992584 ,val loss : 0.113358 ,val acc : 0.991394\n",
      "[ ecpho : 2  iter :386 ]train loss : 0.101782 ,train acc: 0.978455 ,val loss : 0.113193 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :387 ]train loss : 0.123602 ,train acc: 0.989929 ,val loss : 0.114474 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :388 ]train loss : 0.068918 ,train acc: 0.998596 ,val loss : 0.114293 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :389 ]train loss : 0.088762 ,train acc: 0.990204 ,val loss : 0.112484 ,val acc : 0.991577\n",
      "[ ecpho : 2  iter :390 ]train loss : 0.339877 ,train acc: 0.823242 ,val loss : 0.114207 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :391 ]train loss : 0.482191 ,train acc: 0.667572 ,val loss : 0.113389 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :392 ]train loss : 0.077715 ,train acc: 0.992065 ,val loss : 0.114987 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :393 ]train loss : 0.092861 ,train acc: 0.985352 ,val loss : 0.114337 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :394 ]train loss : 0.076803 ,train acc: 0.994537 ,val loss : 0.115643 ,val acc : 0.990662\n",
      "[ ecpho : 2  iter :395 ]train loss : 0.103330 ,train acc: 0.979645 ,val loss : 0.114933 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :396 ]train loss : 0.686915 ,train acc: 0.557800 ,val loss : 0.114043 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :397 ]train loss : 0.077579 ,train acc: 0.998230 ,val loss : 0.114771 ,val acc : 0.991272\n",
      "[ ecpho : 2  iter :398 ]train loss : 0.153463 ,train acc: 0.954407 ,val loss : 0.111406 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :399 ]train loss : 0.080853 ,train acc: 0.989349 ,val loss : 0.115596 ,val acc : 0.991272\n",
      "[ ecpho : 2  iter :400 ]train loss : 0.076816 ,train acc: 0.996704 ,val loss : 0.115837 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :401 ]train loss : 0.151789 ,train acc: 0.943878 ,val loss : 0.114772 ,val acc : 0.991486\n",
      "[ ecpho : 2  iter :402 ]train loss : 0.195983 ,train acc: 0.901489 ,val loss : 0.114237 ,val acc : 0.991028\n",
      "[ ecpho : 2  iter :403 ]train loss : 0.071415 ,train acc: 0.997162 ,val loss : 0.113408 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :404 ]train loss : 0.076604 ,train acc: 0.997498 ,val loss : 0.113955 ,val acc : 0.991241\n",
      "[ ecpho : 2  iter :405 ]train loss : 0.072702 ,train acc: 0.997833 ,val loss : 0.115974 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :406 ]train loss : 0.091047 ,train acc: 0.982666 ,val loss : 0.112756 ,val acc : 0.991241\n",
      "[ ecpho : 2  iter :407 ]train loss : 0.070218 ,train acc: 0.998413 ,val loss : 0.114502 ,val acc : 0.991089\n",
      "[ ecpho : 2  iter :408 ]train loss : 0.585640 ,train acc: 0.602753 ,val loss : 0.115128 ,val acc : 0.991608\n",
      "[ ecpho : 2  iter :409 ]train loss : 0.267073 ,train acc: 0.832764 ,val loss : 0.114872 ,val acc : 0.991608\n",
      "[ ecpho : 2  iter :410 ]train loss : 0.154690 ,train acc: 0.941010 ,val loss : 0.117079 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :411 ]train loss : 0.089033 ,train acc: 0.993011 ,val loss : 0.116304 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :412 ]train loss : 0.244621 ,train acc: 0.888336 ,val loss : 0.115358 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :413 ]train loss : 0.109885 ,train acc: 0.968231 ,val loss : 0.116075 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :414 ]train loss : 0.086368 ,train acc: 0.989502 ,val loss : 0.115702 ,val acc : 0.990784\n",
      "[ ecpho : 2  iter :415 ]train loss : 0.076840 ,train acc: 0.997589 ,val loss : 0.116021 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :416 ]train loss : 0.279543 ,train acc: 0.826813 ,val loss : 0.115220 ,val acc : 0.990936\n",
      "[ ecpho : 2  iter :417 ]train loss : 0.091396 ,train acc: 0.996033 ,val loss : 0.118060 ,val acc : 0.991119\n",
      "[ ecpho : 2  iter :418 ]train loss : 0.540127 ,train acc: 0.610077 ,val loss : 0.117408 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :419 ]train loss : 0.063542 ,train acc: 0.998016 ,val loss : 0.115538 ,val acc : 0.990356\n",
      "[ ecpho : 2  iter :420 ]train loss : 0.094027 ,train acc: 0.979431 ,val loss : 0.117149 ,val acc : 0.990601\n",
      "[ ecpho : 2  iter :421 ]train loss : 0.087763 ,train acc: 0.993561 ,val loss : 0.117564 ,val acc : 0.990753\n",
      "[ ecpho : 2  iter :422 ]train loss : 0.217805 ,train acc: 0.874756 ,val loss : 0.116099 ,val acc : 0.990540\n",
      "[ ecpho : 2  iter :423 ]train loss : 0.113822 ,train acc: 0.982422 ,val loss : 0.116313 ,val acc : 0.990723\n",
      "[ ecpho : 2  iter :424 ]train loss : 0.111669 ,train acc: 0.976898 ,val loss : 0.119270 ,val acc : 0.990509\n",
      "[ ecpho : 2  iter :425 ]train loss : 0.112138 ,train acc: 0.967194 ,val loss : 0.117328 ,val acc : 0.990570\n",
      "[ ecpho : 2  iter :426 ]train loss : 0.072185 ,train acc: 0.992065 ,val loss : 0.116816 ,val acc : 0.990723\n",
      "[ ecpho : 2  iter :427 ]train loss : 0.116341 ,train acc: 0.968750 ,val loss : 0.114296 ,val acc : 0.991089\n",
      "[ ecpho : 2  iter :428 ]train loss : 0.150723 ,train acc: 0.941345 ,val loss : 0.118375 ,val acc : 0.990570\n",
      "[ ecpho : 2  iter :429 ]train loss : 0.091419 ,train acc: 0.990875 ,val loss : 0.119327 ,val acc : 0.990326\n",
      "[ ecpho : 2  iter :430 ]train loss : 0.109695 ,train acc: 0.981354 ,val loss : 0.120019 ,val acc : 0.990784\n",
      "[ ecpho : 2  iter :431 ]train loss : 0.108122 ,train acc: 0.983765 ,val loss : 0.117001 ,val acc : 0.990509\n",
      "[ ecpho : 2  iter :432 ]train loss : 0.077018 ,train acc: 0.990417 ,val loss : 0.117355 ,val acc : 0.990753\n",
      "[ ecpho : 2  iter :433 ]train loss : 0.085628 ,train acc: 0.989441 ,val loss : 0.116791 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :434 ]train loss : 0.423714 ,train acc: 0.767395 ,val loss : 0.115129 ,val acc : 0.991272\n",
      "[ ecpho : 2  iter :435 ]train loss : 0.078849 ,train acc: 0.993805 ,val loss : 0.117873 ,val acc : 0.990417\n",
      "[ ecpho : 2  iter :436 ]train loss : 0.077006 ,train acc: 0.994324 ,val loss : 0.116804 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :437 ]train loss : 0.083111 ,train acc: 0.988922 ,val loss : 0.113898 ,val acc : 0.990814\n",
      "[ ecpho : 2  iter :438 ]train loss : 0.119733 ,train acc: 0.974243 ,val loss : 0.115990 ,val acc : 0.990845\n",
      "[ ecpho : 2  iter :439 ]train loss : 0.169248 ,train acc: 0.934296 ,val loss : 0.117498 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :440 ]train loss : 0.992257 ,train acc: 0.335480 ,val loss : 0.114746 ,val acc : 0.991333\n",
      "[ ecpho : 2  iter :441 ]train loss : 0.090825 ,train acc: 0.986176 ,val loss : 0.119188 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :442 ]train loss : 0.066965 ,train acc: 0.995117 ,val loss : 0.116613 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :443 ]train loss : 0.069104 ,train acc: 0.996307 ,val loss : 0.114449 ,val acc : 0.991333\n",
      "[ ecpho : 2  iter :444 ]train loss : 0.072865 ,train acc: 0.997162 ,val loss : 0.117974 ,val acc : 0.991180\n",
      "[ ecpho : 2  iter :445 ]train loss : 0.068810 ,train acc: 0.996582 ,val loss : 0.114758 ,val acc : 0.990875\n",
      "[ ecpho : 2  iter :446 ]train loss : 0.078247 ,train acc: 0.989319 ,val loss : 0.115449 ,val acc : 0.991364\n",
      "[ ecpho : 2  iter :447 ]train loss : 0.154883 ,train acc: 0.973145 ,val loss : 0.114739 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :448 ]train loss : 0.615384 ,train acc: 0.660095 ,val loss : 0.115235 ,val acc : 0.991272\n",
      "[ ecpho : 2  iter :449 ]train loss : 0.061343 ,train acc: 0.998077 ,val loss : 0.114938 ,val acc : 0.991241\n",
      "[ ecpho : 2  iter :450 ]train loss : 0.089798 ,train acc: 0.987335 ,val loss : 0.116299 ,val acc : 0.991455\n",
      "[ ecpho : 2  iter :451 ]train loss : 0.094035 ,train acc: 0.997528 ,val loss : 0.119386 ,val acc : 0.991028\n",
      "[ ecpho : 2  iter :452 ]train loss : 0.096218 ,train acc: 0.995728 ,val loss : 0.117988 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :453 ]train loss : 0.132561 ,train acc: 0.980164 ,val loss : 0.113770 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :454 ]train loss : 0.306628 ,train acc: 0.863708 ,val loss : 0.114976 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :455 ]train loss : 0.074942 ,train acc: 0.997070 ,val loss : 0.113422 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :456 ]train loss : 0.195900 ,train acc: 0.947571 ,val loss : 0.117246 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :457 ]train loss : 0.180525 ,train acc: 0.930573 ,val loss : 0.114691 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :458 ]train loss : 0.156098 ,train acc: 0.976624 ,val loss : 0.112014 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :459 ]train loss : 0.094531 ,train acc: 0.992798 ,val loss : 0.112605 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :460 ]train loss : 0.092391 ,train acc: 0.994598 ,val loss : 0.113243 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :461 ]train loss : 0.739155 ,train acc: 0.419006 ,val loss : 0.112352 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :462 ]train loss : 0.177295 ,train acc: 0.920135 ,val loss : 0.114321 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :463 ]train loss : 0.066790 ,train acc: 0.997925 ,val loss : 0.110761 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :464 ]train loss : 0.193622 ,train acc: 0.948547 ,val loss : 0.114393 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :465 ]train loss : 0.080820 ,train acc: 0.992279 ,val loss : 0.111176 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :466 ]train loss : 0.140017 ,train acc: 0.987518 ,val loss : 0.113029 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :467 ]train loss : 0.068998 ,train acc: 0.999115 ,val loss : 0.112330 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :468 ]train loss : 1.126138 ,train acc: 0.234344 ,val loss : 0.111218 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :469 ]train loss : 0.114474 ,train acc: 0.983948 ,val loss : 0.116822 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :470 ]train loss : 0.105212 ,train acc: 0.979095 ,val loss : 0.110543 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :471 ]train loss : 0.084131 ,train acc: 0.985413 ,val loss : 0.112613 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :472 ]train loss : 0.079723 ,train acc: 0.991547 ,val loss : 0.109914 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :473 ]train loss : 0.076232 ,train acc: 0.994049 ,val loss : 0.112536 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :474 ]train loss : 0.122101 ,train acc: 0.985809 ,val loss : 0.113482 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :475 ]train loss : 0.205053 ,train acc: 0.899994 ,val loss : 0.112806 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :476 ]train loss : 0.184157 ,train acc: 0.917603 ,val loss : 0.114448 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :477 ]train loss : 0.172976 ,train acc: 0.926086 ,val loss : 0.111062 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :478 ]train loss : 0.067685 ,train acc: 0.998718 ,val loss : 0.109905 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :479 ]train loss : 0.207037 ,train acc: 0.897919 ,val loss : 0.110972 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :480 ]train loss : 0.083088 ,train acc: 0.987976 ,val loss : 0.114566 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :481 ]train loss : 0.483066 ,train acc: 0.663605 ,val loss : 0.110190 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :482 ]train loss : 0.112490 ,train acc: 0.975464 ,val loss : 0.112610 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :483 ]train loss : 0.163929 ,train acc: 0.939392 ,val loss : 0.112732 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :484 ]train loss : 0.143807 ,train acc: 0.945831 ,val loss : 0.113361 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :485 ]train loss : 1.101928 ,train acc: 0.248749 ,val loss : 0.112626 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :486 ]train loss : 0.271562 ,train acc: 0.828461 ,val loss : 0.112316 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :487 ]train loss : 0.092906 ,train acc: 0.987427 ,val loss : 0.113125 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :488 ]train loss : 0.090604 ,train acc: 0.994263 ,val loss : 0.112269 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :489 ]train loss : 0.106713 ,train acc: 0.981140 ,val loss : 0.112332 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :490 ]train loss : 0.074186 ,train acc: 0.993439 ,val loss : 0.114642 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :491 ]train loss : 0.079314 ,train acc: 0.994110 ,val loss : 0.112940 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :492 ]train loss : 0.057522 ,train acc: 0.999542 ,val loss : 0.111568 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :493 ]train loss : 0.080163 ,train acc: 0.991119 ,val loss : 0.112259 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :494 ]train loss : 0.115804 ,train acc: 0.990601 ,val loss : 0.114203 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :495 ]train loss : 0.243926 ,train acc: 0.884064 ,val loss : 0.115189 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :496 ]train loss : 0.265809 ,train acc: 0.841675 ,val loss : 0.113905 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :497 ]train loss : 0.083796 ,train acc: 0.983368 ,val loss : 0.113814 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :498 ]train loss : 0.099419 ,train acc: 0.994659 ,val loss : 0.110916 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :499 ]train loss : 0.313866 ,train acc: 0.850433 ,val loss : 0.112743 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :500 ]train loss : 0.085761 ,train acc: 0.989410 ,val loss : 0.114456 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :501 ]train loss : 0.121463 ,train acc: 0.986450 ,val loss : 0.113237 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :502 ]train loss : 0.081714 ,train acc: 0.997437 ,val loss : 0.112061 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :503 ]train loss : 0.100641 ,train acc: 0.983582 ,val loss : 0.111455 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :504 ]train loss : 0.262708 ,train acc: 0.856171 ,val loss : 0.111467 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :505 ]train loss : 0.239290 ,train acc: 0.866364 ,val loss : 0.114136 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :506 ]train loss : 0.097058 ,train acc: 0.981354 ,val loss : 0.112543 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :507 ]train loss : 0.086500 ,train acc: 0.995270 ,val loss : 0.110310 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :508 ]train loss : 0.143646 ,train acc: 0.958252 ,val loss : 0.110352 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :509 ]train loss : 0.078551 ,train acc: 0.994965 ,val loss : 0.112795 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :510 ]train loss : 0.069859 ,train acc: 0.998505 ,val loss : 0.112891 ,val acc : 0.991577\n",
      "[ ecpho : 2  iter :511 ]train loss : 0.122751 ,train acc: 0.962006 ,val loss : 0.111490 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :512 ]train loss : 0.078773 ,train acc: 0.991089 ,val loss : 0.110867 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :513 ]train loss : 0.191318 ,train acc: 0.902679 ,val loss : 0.113205 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :514 ]train loss : 0.092880 ,train acc: 0.983154 ,val loss : 0.109142 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :515 ]train loss : 1.279437 ,train acc: 0.155273 ,val loss : 0.111708 ,val acc : 0.991608\n",
      "[ ecpho : 2  iter :516 ]train loss : 0.062524 ,train acc: 0.996613 ,val loss : 0.112527 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :517 ]train loss : 0.234544 ,train acc: 0.876831 ,val loss : 0.111783 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :518 ]train loss : 0.106608 ,train acc: 0.991180 ,val loss : 0.114313 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :519 ]train loss : 0.077420 ,train acc: 0.989899 ,val loss : 0.112875 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :520 ]train loss : 0.149740 ,train acc: 0.953888 ,val loss : 0.111616 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :521 ]train loss : 0.101674 ,train acc: 0.993256 ,val loss : 0.110369 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :522 ]train loss : 0.121893 ,train acc: 0.978790 ,val loss : 0.112489 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :523 ]train loss : 0.245621 ,train acc: 0.890228 ,val loss : 0.110199 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :524 ]train loss : 0.086999 ,train acc: 0.984436 ,val loss : 0.113289 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :525 ]train loss : 0.401906 ,train acc: 0.711823 ,val loss : 0.111876 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :526 ]train loss : 0.140073 ,train acc: 0.976868 ,val loss : 0.115476 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :527 ]train loss : 0.084060 ,train acc: 0.988586 ,val loss : 0.112444 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :528 ]train loss : 0.139124 ,train acc: 0.958160 ,val loss : 0.111420 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :529 ]train loss : 0.172267 ,train acc: 0.957001 ,val loss : 0.112125 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :530 ]train loss : 0.066659 ,train acc: 0.996246 ,val loss : 0.111412 ,val acc : 0.991577\n",
      "[ ecpho : 2  iter :531 ]train loss : 0.181949 ,train acc: 0.927094 ,val loss : 0.114321 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :532 ]train loss : 0.100196 ,train acc: 0.975189 ,val loss : 0.109748 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :533 ]train loss : 0.080077 ,train acc: 0.988159 ,val loss : 0.110682 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :534 ]train loss : 0.061493 ,train acc: 0.995575 ,val loss : 0.112839 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :535 ]train loss : 0.596239 ,train acc: 0.614777 ,val loss : 0.111982 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :536 ]train loss : 0.090369 ,train acc: 0.996826 ,val loss : 0.112512 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :537 ]train loss : 0.073242 ,train acc: 0.997681 ,val loss : 0.111297 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :538 ]train loss : 0.084701 ,train acc: 0.993958 ,val loss : 0.112315 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :539 ]train loss : 0.095143 ,train acc: 0.990509 ,val loss : 0.110172 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :540 ]train loss : 0.070001 ,train acc: 0.997437 ,val loss : 0.112717 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :541 ]train loss : 0.098093 ,train acc: 0.994781 ,val loss : 0.114126 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :542 ]train loss : 0.084768 ,train acc: 0.992035 ,val loss : 0.111319 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :543 ]train loss : 0.100114 ,train acc: 0.985870 ,val loss : 0.112900 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :544 ]train loss : 0.087790 ,train acc: 0.998291 ,val loss : 0.113514 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :545 ]train loss : 0.108590 ,train acc: 0.983612 ,val loss : 0.109702 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :546 ]train loss : 0.075192 ,train acc: 0.997314 ,val loss : 0.113132 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :547 ]train loss : 0.084527 ,train acc: 0.996094 ,val loss : 0.113458 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :548 ]train loss : 0.102504 ,train acc: 0.993408 ,val loss : 0.111200 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :549 ]train loss : 0.081208 ,train acc: 0.994171 ,val loss : 0.109934 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :550 ]train loss : 0.089502 ,train acc: 0.990204 ,val loss : 0.111094 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :551 ]train loss : 0.095697 ,train acc: 0.991821 ,val loss : 0.110487 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :552 ]train loss : 0.095383 ,train acc: 0.979736 ,val loss : 0.109754 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :553 ]train loss : 0.097186 ,train acc: 0.993744 ,val loss : 0.109442 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :554 ]train loss : 0.116868 ,train acc: 0.968750 ,val loss : 0.111011 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :555 ]train loss : 0.092460 ,train acc: 0.987976 ,val loss : 0.111240 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :556 ]train loss : 0.282665 ,train acc: 0.839172 ,val loss : 0.112244 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :557 ]train loss : 0.126678 ,train acc: 0.964417 ,val loss : 0.111999 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :558 ]train loss : 0.198980 ,train acc: 0.902863 ,val loss : 0.112806 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :559 ]train loss : 0.070127 ,train acc: 0.995178 ,val loss : 0.110428 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :560 ]train loss : 0.068529 ,train acc: 0.998138 ,val loss : 0.111886 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :561 ]train loss : 0.079190 ,train acc: 0.998749 ,val loss : 0.112844 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :562 ]train loss : 0.112879 ,train acc: 0.991760 ,val loss : 0.111586 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :563 ]train loss : 0.079874 ,train acc: 0.995148 ,val loss : 0.111360 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :564 ]train loss : 0.055291 ,train acc: 0.999542 ,val loss : 0.110930 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :565 ]train loss : 0.066974 ,train acc: 0.994781 ,val loss : 0.111423 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :566 ]train loss : 0.179210 ,train acc: 0.917786 ,val loss : 0.110981 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :567 ]train loss : 0.080621 ,train acc: 0.987152 ,val loss : 0.110458 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :568 ]train loss : 0.101111 ,train acc: 0.983337 ,val loss : 0.114884 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :569 ]train loss : 0.087711 ,train acc: 0.993622 ,val loss : 0.112272 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :570 ]train loss : 0.088886 ,train acc: 0.998352 ,val loss : 0.110808 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :571 ]train loss : 0.109607 ,train acc: 0.968536 ,val loss : 0.111483 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :572 ]train loss : 0.139331 ,train acc: 0.979156 ,val loss : 0.111098 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :573 ]train loss : 0.389366 ,train acc: 0.724304 ,val loss : 0.112133 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :574 ]train loss : 0.132856 ,train acc: 0.961853 ,val loss : 0.113295 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :575 ]train loss : 0.106848 ,train acc: 0.993164 ,val loss : 0.111631 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :576 ]train loss : 0.941402 ,train acc: 0.345032 ,val loss : 0.112564 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :577 ]train loss : 0.122161 ,train acc: 0.986267 ,val loss : 0.111934 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :578 ]train loss : 0.122486 ,train acc: 0.968536 ,val loss : 0.111728 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :579 ]train loss : 0.194535 ,train acc: 0.943329 ,val loss : 0.109656 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :580 ]train loss : 0.105236 ,train acc: 0.996704 ,val loss : 0.112772 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :581 ]train loss : 0.076614 ,train acc: 0.997162 ,val loss : 0.111738 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :582 ]train loss : 0.083888 ,train acc: 0.992462 ,val loss : 0.109537 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :583 ]train loss : 0.712043 ,train acc: 0.505066 ,val loss : 0.111167 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :584 ]train loss : 0.085196 ,train acc: 0.998657 ,val loss : 0.112362 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :585 ]train loss : 0.087480 ,train acc: 0.998138 ,val loss : 0.108886 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :586 ]train loss : 0.089155 ,train acc: 0.997253 ,val loss : 0.109610 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :587 ]train loss : 0.113504 ,train acc: 0.971924 ,val loss : 0.111492 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :588 ]train loss : 0.089197 ,train acc: 0.997925 ,val loss : 0.110702 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :589 ]train loss : 0.089770 ,train acc: 0.990173 ,val loss : 0.111385 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :590 ]train loss : 0.078570 ,train acc: 0.992432 ,val loss : 0.112186 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :591 ]train loss : 0.192524 ,train acc: 0.946838 ,val loss : 0.108794 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :592 ]train loss : 0.107225 ,train acc: 0.981354 ,val loss : 0.109909 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :593 ]train loss : 0.083487 ,train acc: 0.995117 ,val loss : 0.110879 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :594 ]train loss : 0.085719 ,train acc: 0.994629 ,val loss : 0.108300 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :595 ]train loss : 0.094079 ,train acc: 0.992645 ,val loss : 0.109821 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :596 ]train loss : 0.075784 ,train acc: 0.997681 ,val loss : 0.109764 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :597 ]train loss : 0.076382 ,train acc: 0.992950 ,val loss : 0.108905 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :598 ]train loss : 0.086829 ,train acc: 0.986237 ,val loss : 0.109052 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :599 ]train loss : 0.109837 ,train acc: 0.973022 ,val loss : 0.109846 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :600 ]train loss : 0.113595 ,train acc: 0.980560 ,val loss : 0.110665 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :601 ]train loss : 0.107682 ,train acc: 0.987091 ,val loss : 0.107904 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :602 ]train loss : 0.395200 ,train acc: 0.747772 ,val loss : 0.108750 ,val acc : 0.993103\n",
      "[ ecpho : 2  iter :603 ]train loss : 0.089082 ,train acc: 0.986053 ,val loss : 0.109787 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :604 ]train loss : 0.063990 ,train acc: 0.998291 ,val loss : 0.107245 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :605 ]train loss : 0.087057 ,train acc: 0.993042 ,val loss : 0.106401 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :606 ]train loss : 0.107552 ,train acc: 0.970093 ,val loss : 0.109323 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :607 ]train loss : 0.067666 ,train acc: 0.998932 ,val loss : 0.109719 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :608 ]train loss : 0.093761 ,train acc: 0.987579 ,val loss : 0.109803 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :609 ]train loss : 0.287833 ,train acc: 0.848938 ,val loss : 0.108870 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :610 ]train loss : 0.121055 ,train acc: 0.964203 ,val loss : 0.111040 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :611 ]train loss : 0.101191 ,train acc: 0.994171 ,val loss : 0.109926 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :612 ]train loss : 0.077389 ,train acc: 0.997589 ,val loss : 0.109902 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :613 ]train loss : 0.138028 ,train acc: 0.954865 ,val loss : 0.109683 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :614 ]train loss : 0.083685 ,train acc: 0.994659 ,val loss : 0.110022 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :615 ]train loss : 0.071921 ,train acc: 0.997955 ,val loss : 0.109296 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :616 ]train loss : 0.087262 ,train acc: 0.996490 ,val loss : 0.107389 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :617 ]train loss : 0.067117 ,train acc: 0.997162 ,val loss : 0.108954 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :618 ]train loss : 0.092988 ,train acc: 0.997986 ,val loss : 0.108116 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :619 ]train loss : 0.077184 ,train acc: 0.993866 ,val loss : 0.110030 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :620 ]train loss : 0.119991 ,train acc: 0.982147 ,val loss : 0.108538 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :621 ]train loss : 0.093949 ,train acc: 0.997559 ,val loss : 0.108353 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :622 ]train loss : 0.092541 ,train acc: 0.989166 ,val loss : 0.108713 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :623 ]train loss : 0.084484 ,train acc: 0.990601 ,val loss : 0.109719 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :624 ]train loss : 0.076137 ,train acc: 0.998962 ,val loss : 0.107238 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :625 ]train loss : 0.087081 ,train acc: 0.992035 ,val loss : 0.106987 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :626 ]train loss : 0.101487 ,train acc: 0.998047 ,val loss : 0.107982 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :627 ]train loss : 0.086625 ,train acc: 0.997620 ,val loss : 0.109159 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :628 ]train loss : 0.078997 ,train acc: 0.990234 ,val loss : 0.108828 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :629 ]train loss : 0.246002 ,train acc: 0.869019 ,val loss : 0.106621 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :630 ]train loss : 0.510063 ,train acc: 0.613678 ,val loss : 0.105870 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :631 ]train loss : 0.402995 ,train acc: 0.722839 ,val loss : 0.106723 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :632 ]train loss : 0.062027 ,train acc: 0.998688 ,val loss : 0.108020 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :633 ]train loss : 0.106214 ,train acc: 0.976349 ,val loss : 0.106699 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :634 ]train loss : 0.085611 ,train acc: 0.993744 ,val loss : 0.109853 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :635 ]train loss : 0.425650 ,train acc: 0.749176 ,val loss : 0.107028 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :636 ]train loss : 0.143664 ,train acc: 0.968536 ,val loss : 0.108742 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :637 ]train loss : 0.226098 ,train acc: 0.912628 ,val loss : 0.108564 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :638 ]train loss : 0.109586 ,train acc: 0.980011 ,val loss : 0.109425 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :639 ]train loss : 0.244790 ,train acc: 0.894958 ,val loss : 0.111493 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :640 ]train loss : 0.105578 ,train acc: 0.993988 ,val loss : 0.110655 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :641 ]train loss : 0.132189 ,train acc: 0.982269 ,val loss : 0.108896 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :642 ]train loss : 0.084439 ,train acc: 0.989014 ,val loss : 0.112373 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :643 ]train loss : 0.254588 ,train acc: 0.910706 ,val loss : 0.112079 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :644 ]train loss : 0.090110 ,train acc: 0.989532 ,val loss : 0.109180 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :645 ]train loss : 0.290148 ,train acc: 0.868042 ,val loss : 0.108068 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :646 ]train loss : 0.109065 ,train acc: 0.970306 ,val loss : 0.109122 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :647 ]train loss : 0.094387 ,train acc: 0.996674 ,val loss : 0.109396 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :648 ]train loss : 0.253498 ,train acc: 0.860321 ,val loss : 0.108486 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :649 ]train loss : 0.081615 ,train acc: 0.994263 ,val loss : 0.109905 ,val acc : 0.991577\n",
      "[ ecpho : 2  iter :650 ]train loss : 0.387085 ,train acc: 0.796021 ,val loss : 0.110618 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :651 ]train loss : 0.106266 ,train acc: 0.992767 ,val loss : 0.108448 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :652 ]train loss : 0.111856 ,train acc: 0.989044 ,val loss : 0.109934 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :653 ]train loss : 0.075607 ,train acc: 0.998413 ,val loss : 0.108500 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :654 ]train loss : 0.070195 ,train acc: 0.997650 ,val loss : 0.110515 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :655 ]train loss : 0.071304 ,train acc: 0.999054 ,val loss : 0.108394 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :656 ]train loss : 0.123537 ,train acc: 0.959015 ,val loss : 0.109826 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :657 ]train loss : 0.093521 ,train acc: 0.983215 ,val loss : 0.109968 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :658 ]train loss : 0.103364 ,train acc: 0.977478 ,val loss : 0.110137 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :659 ]train loss : 0.097583 ,train acc: 0.997314 ,val loss : 0.108068 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :660 ]train loss : 0.390702 ,train acc: 0.731018 ,val loss : 0.110242 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :661 ]train loss : 0.096259 ,train acc: 0.981598 ,val loss : 0.109729 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :662 ]train loss : 0.143148 ,train acc: 0.973267 ,val loss : 0.107426 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :663 ]train loss : 0.143881 ,train acc: 0.983612 ,val loss : 0.110516 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :664 ]train loss : 0.118807 ,train acc: 0.984314 ,val loss : 0.109963 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :665 ]train loss : 0.058628 ,train acc: 0.998016 ,val loss : 0.107611 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :666 ]train loss : 0.159148 ,train acc: 0.966187 ,val loss : 0.107777 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :667 ]train loss : 0.747480 ,train acc: 0.477173 ,val loss : 0.108110 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :668 ]train loss : 0.091712 ,train acc: 0.983459 ,val loss : 0.107883 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :669 ]train loss : 0.413062 ,train acc: 0.733398 ,val loss : 0.108513 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :670 ]train loss : 0.078504 ,train acc: 0.992554 ,val loss : 0.110151 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :671 ]train loss : 0.166613 ,train acc: 0.928589 ,val loss : 0.108700 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :672 ]train loss : 0.417769 ,train acc: 0.715881 ,val loss : 0.110583 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :673 ]train loss : 0.308472 ,train acc: 0.827759 ,val loss : 0.108031 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :674 ]train loss : 0.072315 ,train acc: 0.992859 ,val loss : 0.109904 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :675 ]train loss : 0.871005 ,train acc: 0.399811 ,val loss : 0.112309 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :676 ]train loss : 0.166711 ,train acc: 0.934875 ,val loss : 0.109754 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :677 ]train loss : 0.081343 ,train acc: 0.995697 ,val loss : 0.110417 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :678 ]train loss : 0.087523 ,train acc: 0.993622 ,val loss : 0.111152 ,val acc : 0.991394\n",
      "[ ecpho : 2  iter :679 ]train loss : 0.112799 ,train acc: 0.975006 ,val loss : 0.111796 ,val acc : 0.991272\n",
      "[ ecpho : 2  iter :680 ]train loss : 0.088367 ,train acc: 0.993439 ,val loss : 0.109304 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :681 ]train loss : 0.070763 ,train acc: 0.996643 ,val loss : 0.112340 ,val acc : 0.991058\n",
      "[ ecpho : 2  iter :682 ]train loss : 1.184878 ,train acc: 0.197205 ,val loss : 0.115634 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :683 ]train loss : 0.137891 ,train acc: 0.957520 ,val loss : 0.110774 ,val acc : 0.990814\n",
      "[ ecpho : 2  iter :684 ]train loss : 0.071717 ,train acc: 0.997131 ,val loss : 0.111584 ,val acc : 0.991150\n",
      "[ ecpho : 2  iter :685 ]train loss : 0.072671 ,train acc: 0.997406 ,val loss : 0.112795 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :686 ]train loss : 0.106786 ,train acc: 0.992645 ,val loss : 0.111402 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :687 ]train loss : 0.087405 ,train acc: 0.986115 ,val loss : 0.113151 ,val acc : 0.991669\n",
      "[ ecpho : 2  iter :688 ]train loss : 0.441966 ,train acc: 0.732056 ,val loss : 0.110799 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :689 ]train loss : 0.076904 ,train acc: 0.993561 ,val loss : 0.111506 ,val acc : 0.991394\n",
      "[ ecpho : 2  iter :690 ]train loss : 0.102483 ,train acc: 0.982635 ,val loss : 0.114396 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :691 ]train loss : 0.106222 ,train acc: 0.986237 ,val loss : 0.109488 ,val acc : 0.991333\n",
      "[ ecpho : 2  iter :692 ]train loss : 0.087441 ,train acc: 0.984467 ,val loss : 0.115911 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :693 ]train loss : 0.076638 ,train acc: 0.993744 ,val loss : 0.112359 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :694 ]train loss : 0.116434 ,train acc: 0.972961 ,val loss : 0.112286 ,val acc : 0.991302\n",
      "[ ecpho : 2  iter :695 ]train loss : 0.113117 ,train acc: 0.985504 ,val loss : 0.108961 ,val acc : 0.991699\n",
      "[ ecpho : 2  iter :696 ]train loss : 0.489092 ,train acc: 0.659760 ,val loss : 0.114601 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :697 ]train loss : 0.060336 ,train acc: 0.997894 ,val loss : 0.112010 ,val acc : 0.991394\n",
      "[ ecpho : 2  iter :698 ]train loss : 1.421614 ,train acc: 0.020905 ,val loss : 0.113086 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :699 ]train loss : 0.146827 ,train acc: 0.967499 ,val loss : 0.111708 ,val acc : 0.991760\n",
      "[ ecpho : 2  iter :700 ]train loss : 0.109179 ,train acc: 0.974274 ,val loss : 0.114585 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :701 ]train loss : 0.088460 ,train acc: 0.992065 ,val loss : 0.110007 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :702 ]train loss : 0.131710 ,train acc: 0.977234 ,val loss : 0.112038 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :703 ]train loss : 0.165745 ,train acc: 0.957825 ,val loss : 0.114201 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :704 ]train loss : 0.138065 ,train acc: 0.981995 ,val loss : 0.111151 ,val acc : 0.991547\n",
      "[ ecpho : 2  iter :705 ]train loss : 0.091453 ,train acc: 0.981506 ,val loss : 0.116305 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :706 ]train loss : 0.066855 ,train acc: 0.997009 ,val loss : 0.113416 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :707 ]train loss : 0.113678 ,train acc: 0.977722 ,val loss : 0.114400 ,val acc : 0.991425\n",
      "[ ecpho : 2  iter :708 ]train loss : 0.100112 ,train acc: 0.973633 ,val loss : 0.114607 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :709 ]train loss : 0.098319 ,train acc: 0.994049 ,val loss : 0.114801 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :710 ]train loss : 0.084235 ,train acc: 0.995544 ,val loss : 0.116345 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :711 ]train loss : 0.164612 ,train acc: 0.925537 ,val loss : 0.114709 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :712 ]train loss : 0.586722 ,train acc: 0.725555 ,val loss : 0.111672 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :713 ]train loss : 0.120850 ,train acc: 0.970245 ,val loss : 0.112984 ,val acc : 0.992035\n",
      "[ ecpho : 2  iter :714 ]train loss : 0.101661 ,train acc: 0.975159 ,val loss : 0.111179 ,val acc : 0.991608\n",
      "[ ecpho : 2  iter :715 ]train loss : 0.113313 ,train acc: 0.987518 ,val loss : 0.111911 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :716 ]train loss : 0.090383 ,train acc: 0.987701 ,val loss : 0.114237 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :717 ]train loss : 0.094867 ,train acc: 0.989960 ,val loss : 0.110877 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :718 ]train loss : 0.097826 ,train acc: 0.991669 ,val loss : 0.111744 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :719 ]train loss : 0.099172 ,train acc: 0.991638 ,val loss : 0.111975 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :720 ]train loss : 0.075975 ,train acc: 0.995087 ,val loss : 0.114674 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :721 ]train loss : 0.113269 ,train acc: 0.988525 ,val loss : 0.113722 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :722 ]train loss : 0.089012 ,train acc: 0.981781 ,val loss : 0.109549 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :723 ]train loss : 0.072049 ,train acc: 0.996307 ,val loss : 0.113733 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :724 ]train loss : 0.081918 ,train acc: 0.998505 ,val loss : 0.111748 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :725 ]train loss : 0.120387 ,train acc: 0.985138 ,val loss : 0.109119 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :726 ]train loss : 0.079246 ,train acc: 0.990143 ,val loss : 0.112711 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :727 ]train loss : 0.087561 ,train acc: 0.983093 ,val loss : 0.112806 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :728 ]train loss : 0.400035 ,train acc: 0.742035 ,val loss : 0.112826 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :729 ]train loss : 0.090570 ,train acc: 0.998230 ,val loss : 0.112919 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :730 ]train loss : 0.096907 ,train acc: 0.981812 ,val loss : 0.111543 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :731 ]train loss : 0.113679 ,train acc: 0.987396 ,val loss : 0.111751 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :732 ]train loss : 0.095937 ,train acc: 0.997406 ,val loss : 0.109048 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :733 ]train loss : 0.088250 ,train acc: 0.994720 ,val loss : 0.112329 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :734 ]train loss : 0.092419 ,train acc: 0.986359 ,val loss : 0.112773 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :735 ]train loss : 0.107734 ,train acc: 0.970703 ,val loss : 0.113633 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :736 ]train loss : 0.094748 ,train acc: 0.987610 ,val loss : 0.108977 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :737 ]train loss : 0.107425 ,train acc: 0.970734 ,val loss : 0.108288 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :738 ]train loss : 0.082568 ,train acc: 0.993683 ,val loss : 0.109552 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :739 ]train loss : 0.096883 ,train acc: 0.985992 ,val loss : 0.108484 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :740 ]train loss : 0.070311 ,train acc: 0.994415 ,val loss : 0.108451 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :741 ]train loss : 0.078953 ,train acc: 0.997192 ,val loss : 0.109496 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :742 ]train loss : 0.065126 ,train acc: 0.997711 ,val loss : 0.109985 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :743 ]train loss : 0.181769 ,train acc: 0.920502 ,val loss : 0.108957 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :744 ]train loss : 0.083316 ,train acc: 0.997131 ,val loss : 0.114142 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :745 ]train loss : 0.193474 ,train acc: 0.948181 ,val loss : 0.110012 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :746 ]train loss : 0.112079 ,train acc: 0.968018 ,val loss : 0.111886 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :747 ]train loss : 0.169003 ,train acc: 0.924255 ,val loss : 0.110276 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :748 ]train loss : 0.644120 ,train acc: 0.604858 ,val loss : 0.111598 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :749 ]train loss : 0.102606 ,train acc: 0.984222 ,val loss : 0.110276 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :750 ]train loss : 0.073030 ,train acc: 0.995911 ,val loss : 0.106081 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :751 ]train loss : 0.097297 ,train acc: 0.977020 ,val loss : 0.111504 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :752 ]train loss : 0.101064 ,train acc: 0.995544 ,val loss : 0.110418 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :753 ]train loss : 0.189758 ,train acc: 0.905823 ,val loss : 0.112342 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :754 ]train loss : 0.090687 ,train acc: 0.997986 ,val loss : 0.108166 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :755 ]train loss : 0.085283 ,train acc: 0.992462 ,val loss : 0.107977 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :756 ]train loss : 0.084021 ,train acc: 0.997192 ,val loss : 0.108498 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :757 ]train loss : 0.092963 ,train acc: 0.982117 ,val loss : 0.108681 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :758 ]train loss : 0.071318 ,train acc: 0.995453 ,val loss : 0.108431 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :759 ]train loss : 0.133712 ,train acc: 0.970734 ,val loss : 0.109831 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :760 ]train loss : 0.077562 ,train acc: 0.991577 ,val loss : 0.109973 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :761 ]train loss : 0.106762 ,train acc: 0.977539 ,val loss : 0.112887 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :762 ]train loss : 0.213231 ,train acc: 0.926422 ,val loss : 0.111589 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :763 ]train loss : 0.080892 ,train acc: 0.993378 ,val loss : 0.109613 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :764 ]train loss : 0.113849 ,train acc: 0.980927 ,val loss : 0.107273 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :765 ]train loss : 0.115208 ,train acc: 0.975342 ,val loss : 0.107646 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :766 ]train loss : 0.133293 ,train acc: 0.976044 ,val loss : 0.108665 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :767 ]train loss : 0.143284 ,train acc: 0.964111 ,val loss : 0.109722 ,val acc : 0.993073\n",
      "[ ecpho : 2  iter :768 ]train loss : 0.285676 ,train acc: 0.919647 ,val loss : 0.109152 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :769 ]train loss : 0.095497 ,train acc: 0.983429 ,val loss : 0.107757 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :770 ]train loss : 0.063117 ,train acc: 0.998077 ,val loss : 0.108349 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :771 ]train loss : 0.132798 ,train acc: 0.967010 ,val loss : 0.109381 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :772 ]train loss : 0.070180 ,train acc: 0.997528 ,val loss : 0.108113 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :773 ]train loss : 0.059385 ,train acc: 0.998779 ,val loss : 0.107970 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :774 ]train loss : 0.079238 ,train acc: 0.990417 ,val loss : 0.108569 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :775 ]train loss : 0.063043 ,train acc: 0.996552 ,val loss : 0.108179 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :776 ]train loss : 0.084949 ,train acc: 0.989166 ,val loss : 0.109583 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :777 ]train loss : 0.081146 ,train acc: 0.994385 ,val loss : 0.106649 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :778 ]train loss : 0.074971 ,train acc: 0.994537 ,val loss : 0.109637 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :779 ]train loss : 0.077807 ,train acc: 0.998871 ,val loss : 0.103708 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :780 ]train loss : 0.079457 ,train acc: 0.993500 ,val loss : 0.107833 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :781 ]train loss : 0.096635 ,train acc: 0.990784 ,val loss : 0.106551 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :782 ]train loss : 0.132299 ,train acc: 0.957458 ,val loss : 0.108660 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :783 ]train loss : 0.093484 ,train acc: 0.996857 ,val loss : 0.107686 ,val acc : 0.993103\n",
      "[ ecpho : 2  iter :784 ]train loss : 0.097865 ,train acc: 0.993927 ,val loss : 0.105537 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :785 ]train loss : 0.226950 ,train acc: 0.925995 ,val loss : 0.106586 ,val acc : 0.992950\n",
      "[ ecpho : 2  iter :786 ]train loss : 0.504025 ,train acc: 0.637207 ,val loss : 0.105787 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :787 ]train loss : 0.064302 ,train acc: 0.999268 ,val loss : 0.105442 ,val acc : 0.993011\n",
      "[ ecpho : 2  iter :788 ]train loss : 0.084355 ,train acc: 0.992676 ,val loss : 0.106106 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :789 ]train loss : 0.076508 ,train acc: 0.995056 ,val loss : 0.106127 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :790 ]train loss : 0.079452 ,train acc: 0.995026 ,val loss : 0.107623 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :791 ]train loss : 0.110252 ,train acc: 0.971741 ,val loss : 0.107270 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :792 ]train loss : 0.074484 ,train acc: 0.998718 ,val loss : 0.107668 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :793 ]train loss : 0.111121 ,train acc: 0.992188 ,val loss : 0.106635 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :794 ]train loss : 0.102823 ,train acc: 0.988892 ,val loss : 0.110354 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :795 ]train loss : 0.153865 ,train acc: 0.940247 ,val loss : 0.107116 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :796 ]train loss : 0.217809 ,train acc: 0.875946 ,val loss : 0.107681 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :797 ]train loss : 0.105879 ,train acc: 0.993347 ,val loss : 0.107154 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :798 ]train loss : 0.065751 ,train acc: 0.998383 ,val loss : 0.105889 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :799 ]train loss : 0.062952 ,train acc: 0.997742 ,val loss : 0.106767 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :800 ]train loss : 0.064576 ,train acc: 0.999237 ,val loss : 0.108067 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :801 ]train loss : 0.241287 ,train acc: 0.913971 ,val loss : 0.106062 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :802 ]train loss : 0.463885 ,train acc: 0.692657 ,val loss : 0.108811 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :803 ]train loss : 0.298039 ,train acc: 0.849365 ,val loss : 0.106720 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :804 ]train loss : 0.089587 ,train acc: 0.993835 ,val loss : 0.107042 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :805 ]train loss : 0.119676 ,train acc: 0.976288 ,val loss : 0.107223 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :806 ]train loss : 0.154684 ,train acc: 0.962372 ,val loss : 0.107602 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :807 ]train loss : 0.061101 ,train acc: 0.997986 ,val loss : 0.107080 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :808 ]train loss : 0.084802 ,train acc: 0.997223 ,val loss : 0.105525 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :809 ]train loss : 0.291215 ,train acc: 0.801086 ,val loss : 0.105335 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :810 ]train loss : 0.117391 ,train acc: 0.987854 ,val loss : 0.106595 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :811 ]train loss : 0.069533 ,train acc: 0.998260 ,val loss : 0.107648 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :812 ]train loss : 0.082035 ,train acc: 0.993561 ,val loss : 0.108983 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :813 ]train loss : 0.529559 ,train acc: 0.609894 ,val loss : 0.106750 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :814 ]train loss : 0.085484 ,train acc: 0.993713 ,val loss : 0.106573 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :815 ]train loss : 0.098295 ,train acc: 0.992767 ,val loss : 0.105641 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :816 ]train loss : 0.110539 ,train acc: 0.987579 ,val loss : 0.108067 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :817 ]train loss : 0.065030 ,train acc: 0.997620 ,val loss : 0.106734 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :818 ]train loss : 0.125126 ,train acc: 0.964569 ,val loss : 0.108914 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :819 ]train loss : 0.080221 ,train acc: 0.986298 ,val loss : 0.109346 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :820 ]train loss : 0.057980 ,train acc: 0.998474 ,val loss : 0.107690 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :821 ]train loss : 0.076519 ,train acc: 0.990051 ,val loss : 0.105125 ,val acc : 0.992065\n",
      "[ ecpho : 2  iter :822 ]train loss : 0.076907 ,train acc: 0.995300 ,val loss : 0.107392 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :823 ]train loss : 0.075240 ,train acc: 0.994263 ,val loss : 0.107548 ,val acc : 0.991852\n",
      "[ ecpho : 2  iter :824 ]train loss : 0.123596 ,train acc: 0.972717 ,val loss : 0.111254 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :825 ]train loss : 0.066735 ,train acc: 0.999023 ,val loss : 0.107988 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :826 ]train loss : 0.158390 ,train acc: 0.931183 ,val loss : 0.109013 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :827 ]train loss : 0.083189 ,train acc: 0.986176 ,val loss : 0.106868 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :828 ]train loss : 0.075766 ,train acc: 0.995209 ,val loss : 0.108980 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :829 ]train loss : 0.092482 ,train acc: 0.983826 ,val loss : 0.108961 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :830 ]train loss : 0.155755 ,train acc: 0.961304 ,val loss : 0.107161 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :831 ]train loss : 0.104233 ,train acc: 0.991516 ,val loss : 0.111003 ,val acc : 0.992279\n",
      "[ ecpho : 2  iter :832 ]train loss : 0.088424 ,train acc: 0.991669 ,val loss : 0.106595 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :833 ]train loss : 0.072892 ,train acc: 0.997253 ,val loss : 0.108860 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :834 ]train loss : 0.100214 ,train acc: 0.996185 ,val loss : 0.109969 ,val acc : 0.992340\n",
      "[ ecpho : 2  iter :835 ]train loss : 0.105021 ,train acc: 0.985474 ,val loss : 0.108473 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :836 ]train loss : 0.072762 ,train acc: 0.997375 ,val loss : 0.106862 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :837 ]train loss : 0.080388 ,train acc: 0.997192 ,val loss : 0.108817 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :838 ]train loss : 0.116014 ,train acc: 0.966736 ,val loss : 0.109680 ,val acc : 0.993195\n",
      "[ ecpho : 2  iter :839 ]train loss : 0.126246 ,train acc: 0.958405 ,val loss : 0.107561 ,val acc : 0.992249\n",
      "[ ecpho : 2  iter :840 ]train loss : 0.082587 ,train acc: 0.995575 ,val loss : 0.106688 ,val acc : 0.993011\n",
      "[ ecpho : 2  iter :841 ]train loss : 0.151156 ,train acc: 0.962311 ,val loss : 0.107717 ,val acc : 0.993134\n",
      "[ ecpho : 2  iter :842 ]train loss : 0.105657 ,train acc: 0.992310 ,val loss : 0.105706 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :843 ]train loss : 0.418993 ,train acc: 0.760376 ,val loss : 0.106108 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :844 ]train loss : 0.081691 ,train acc: 0.991089 ,val loss : 0.106827 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :845 ]train loss : 0.081607 ,train acc: 0.990356 ,val loss : 0.105726 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :846 ]train loss : 0.065454 ,train acc: 0.997559 ,val loss : 0.106310 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :847 ]train loss : 0.259076 ,train acc: 0.868958 ,val loss : 0.108106 ,val acc : 0.992798\n",
      "[ ecpho : 2  iter :848 ]train loss : 0.277995 ,train acc: 0.916656 ,val loss : 0.108150 ,val acc : 0.993011\n",
      "[ ecpho : 2  iter :849 ]train loss : 0.077363 ,train acc: 0.998474 ,val loss : 0.108099 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :850 ]train loss : 0.097094 ,train acc: 0.983032 ,val loss : 0.106414 ,val acc : 0.993011\n",
      "[ ecpho : 2  iter :851 ]train loss : 0.325151 ,train acc: 0.791199 ,val loss : 0.106414 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :852 ]train loss : 0.585915 ,train acc: 0.622437 ,val loss : 0.110866 ,val acc : 0.993011\n",
      "[ ecpho : 2  iter :853 ]train loss : 0.062915 ,train acc: 0.998016 ,val loss : 0.107735 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :854 ]train loss : 0.233996 ,train acc: 0.859619 ,val loss : 0.105751 ,val acc : 0.992920\n",
      "[ ecpho : 2  iter :855 ]train loss : 0.081956 ,train acc: 0.992279 ,val loss : 0.105194 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :856 ]train loss : 0.057888 ,train acc: 0.998169 ,val loss : 0.109359 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :857 ]train loss : 0.088736 ,train acc: 0.984802 ,val loss : 0.108547 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :858 ]train loss : 0.236101 ,train acc: 0.909943 ,val loss : 0.107841 ,val acc : 0.992950\n",
      "[ ecpho : 2  iter :859 ]train loss : 0.074115 ,train acc: 0.991943 ,val loss : 0.109490 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :860 ]train loss : 0.110545 ,train acc: 0.988159 ,val loss : 0.105164 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :861 ]train loss : 0.070903 ,train acc: 0.997650 ,val loss : 0.106897 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :862 ]train loss : 0.230753 ,train acc: 0.873566 ,val loss : 0.107898 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :863 ]train loss : 0.124541 ,train acc: 0.988800 ,val loss : 0.107301 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :864 ]train loss : 0.166338 ,train acc: 0.933289 ,val loss : 0.107951 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :865 ]train loss : 0.096897 ,train acc: 0.990723 ,val loss : 0.108622 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :866 ]train loss : 0.138879 ,train acc: 0.951935 ,val loss : 0.107306 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :867 ]train loss : 0.070421 ,train acc: 0.992126 ,val loss : 0.110325 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :868 ]train loss : 0.239014 ,train acc: 0.858856 ,val loss : 0.106320 ,val acc : 0.992859\n",
      "[ ecpho : 2  iter :869 ]train loss : 0.096552 ,train acc: 0.991821 ,val loss : 0.107746 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :870 ]train loss : 0.100793 ,train acc: 0.992401 ,val loss : 0.108268 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :871 ]train loss : 0.065128 ,train acc: 0.999359 ,val loss : 0.107247 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :872 ]train loss : 0.080420 ,train acc: 0.995728 ,val loss : 0.108071 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :873 ]train loss : 0.079236 ,train acc: 0.993439 ,val loss : 0.107292 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :874 ]train loss : 0.101571 ,train acc: 0.976074 ,val loss : 0.109004 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :875 ]train loss : 0.331372 ,train acc: 0.792267 ,val loss : 0.105717 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :876 ]train loss : 0.070172 ,train acc: 0.998291 ,val loss : 0.107573 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :877 ]train loss : 0.076015 ,train acc: 0.995636 ,val loss : 0.106582 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :878 ]train loss : 0.090632 ,train acc: 0.982544 ,val loss : 0.106058 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :879 ]train loss : 0.626635 ,train acc: 0.552246 ,val loss : 0.107294 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :880 ]train loss : 0.158523 ,train acc: 0.973297 ,val loss : 0.106227 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :881 ]train loss : 1.177132 ,train acc: 0.204254 ,val loss : 0.107452 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :882 ]train loss : 0.066006 ,train acc: 0.995453 ,val loss : 0.106816 ,val acc : 0.992828\n",
      "[ ecpho : 2  iter :883 ]train loss : 0.111837 ,train acc: 0.985931 ,val loss : 0.107382 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :884 ]train loss : 0.067520 ,train acc: 0.998138 ,val loss : 0.106903 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :885 ]train loss : 0.213554 ,train acc: 0.934265 ,val loss : 0.107980 ,val acc : 0.992889\n",
      "[ ecpho : 2  iter :886 ]train loss : 0.089549 ,train acc: 0.992950 ,val loss : 0.108668 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :887 ]train loss : 0.264157 ,train acc: 0.878143 ,val loss : 0.110449 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :888 ]train loss : 0.098502 ,train acc: 0.981140 ,val loss : 0.108313 ,val acc : 0.992676\n",
      "[ ecpho : 2  iter :889 ]train loss : 0.199247 ,train acc: 0.952454 ,val loss : 0.112110 ,val acc : 0.992432\n",
      "[ ecpho : 2  iter :890 ]train loss : 0.138377 ,train acc: 0.985962 ,val loss : 0.105720 ,val acc : 0.992706\n",
      "[ ecpho : 2  iter :891 ]train loss : 0.093156 ,train acc: 0.994873 ,val loss : 0.105369 ,val acc : 0.992462\n",
      "[ ecpho : 2  iter :892 ]train loss : 0.128174 ,train acc: 0.956390 ,val loss : 0.108124 ,val acc : 0.992981\n",
      "[ ecpho : 2  iter :893 ]train loss : 0.073145 ,train acc: 0.992584 ,val loss : 0.109981 ,val acc : 0.992493\n",
      "[ ecpho : 2  iter :894 ]train loss : 0.061679 ,train acc: 0.998749 ,val loss : 0.107188 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :895 ]train loss : 0.073752 ,train acc: 0.992157 ,val loss : 0.108959 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :896 ]train loss : 0.104872 ,train acc: 0.991089 ,val loss : 0.108787 ,val acc : 0.992401\n",
      "[ ecpho : 2  iter :897 ]train loss : 0.116176 ,train acc: 0.973267 ,val loss : 0.107376 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :898 ]train loss : 0.101964 ,train acc: 0.979340 ,val loss : 0.108823 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :899 ]train loss : 0.084862 ,train acc: 0.985718 ,val loss : 0.106959 ,val acc : 0.992645\n",
      "[ ecpho : 2  iter :900 ]train loss : 0.084043 ,train acc: 0.989624 ,val loss : 0.107456 ,val acc : 0.992737\n",
      "[ ecpho : 2  iter :901 ]train loss : 0.110358 ,train acc: 0.987091 ,val loss : 0.106898 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :902 ]train loss : 0.116374 ,train acc: 0.971436 ,val loss : 0.106843 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :903 ]train loss : 0.419280 ,train acc: 0.704315 ,val loss : 0.107785 ,val acc : 0.992554\n",
      "[ ecpho : 2  iter :904 ]train loss : 0.171485 ,train acc: 0.918335 ,val loss : 0.107037 ,val acc : 0.992523\n",
      "[ ecpho : 2  iter :905 ]train loss : 0.072963 ,train acc: 0.996613 ,val loss : 0.106312 ,val acc : 0.992767\n",
      "[ ecpho : 2  iter :906 ]train loss : 0.072004 ,train acc: 0.997467 ,val loss : 0.107430 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :907 ]train loss : 0.640164 ,train acc: 0.567993 ,val loss : 0.106528 ,val acc : 0.992615\n",
      "[ ecpho : 2  iter :908 ]train loss : 0.119247 ,train acc: 0.965759 ,val loss : 0.109678 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :909 ]train loss : 0.222154 ,train acc: 0.920380 ,val loss : 0.110665 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :910 ]train loss : 0.092932 ,train acc: 0.996368 ,val loss : 0.105966 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :911 ]train loss : 0.220218 ,train acc: 0.912964 ,val loss : 0.111373 ,val acc : 0.992584\n",
      "[ ecpho : 2  iter :912 ]train loss : 0.190143 ,train acc: 0.918396 ,val loss : 0.109824 ,val acc : 0.992371\n",
      "[ ecpho : 2  iter :913 ]train loss : 0.065501 ,train acc: 0.998535 ,val loss : 0.107996 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :914 ]train loss : 0.058013 ,train acc: 0.998352 ,val loss : 0.108818 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :915 ]train loss : 0.999894 ,train acc: 0.423309 ,val loss : 0.108871 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :916 ]train loss : 0.181121 ,train acc: 0.933777 ,val loss : 0.108183 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :917 ]train loss : 0.100983 ,train acc: 0.978882 ,val loss : 0.108126 ,val acc : 0.992218\n",
      "[ ecpho : 2  iter :918 ]train loss : 0.131019 ,train acc: 0.956726 ,val loss : 0.107457 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :919 ]train loss : 0.075506 ,train acc: 0.990417 ,val loss : 0.109416 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :920 ]train loss : 0.351965 ,train acc: 0.774780 ,val loss : 0.111472 ,val acc : 0.992310\n",
      "[ ecpho : 2  iter :921 ]train loss : 0.085088 ,train acc: 0.988281 ,val loss : 0.110809 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :922 ]train loss : 0.156640 ,train acc: 0.971893 ,val loss : 0.108010 ,val acc : 0.992188\n",
      "[ ecpho : 2  iter :923 ]train loss : 0.071449 ,train acc: 0.997070 ,val loss : 0.110409 ,val acc : 0.992096\n",
      "[ ecpho : 2  iter :924 ]train loss : 0.149820 ,train acc: 0.941040 ,val loss : 0.106707 ,val acc : 0.992157\n",
      "[ ecpho : 2  iter :925 ]train loss : 0.086455 ,train acc: 0.993866 ,val loss : 0.109679 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :926 ]train loss : 0.064609 ,train acc: 0.998291 ,val loss : 0.105104 ,val acc : 0.992126\n",
      "[ ecpho : 2  iter :927 ]train loss : 0.328974 ,train acc: 0.785156 ,val loss : 0.110709 ,val acc : 0.991638\n",
      "[ ecpho : 2  iter :928 ]train loss : 0.064267 ,train acc: 0.997589 ,val loss : 0.109603 ,val acc : 0.991730\n",
      "[ ecpho : 2  iter :929 ]train loss : 0.116740 ,train acc: 0.984222 ,val loss : 0.110469 ,val acc : 0.992004\n",
      "[ ecpho : 2  iter :930 ]train loss : 0.084403 ,train acc: 0.987488 ,val loss : 0.110247 ,val acc : 0.991882\n",
      "[ ecpho : 2  iter :931 ]train loss : 0.071387 ,train acc: 0.993774 ,val loss : 0.110205 ,val acc : 0.991211\n",
      "[ ecpho : 2  iter :932 ]train loss : 0.212888 ,train acc: 0.902924 ,val loss : 0.108704 ,val acc : 0.991791\n",
      "[ ecpho : 2  iter :933 ]train loss : 0.088905 ,train acc: 0.997894 ,val loss : 0.109386 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :934 ]train loss : 0.169132 ,train acc: 0.919586 ,val loss : 0.111645 ,val acc : 0.991943\n",
      "[ ecpho : 2  iter :935 ]train loss : 0.093801 ,train acc: 0.996155 ,val loss : 0.108897 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :936 ]train loss : 0.080826 ,train acc: 0.993713 ,val loss : 0.107639 ,val acc : 0.991516\n",
      "[ ecpho : 2  iter :937 ]train loss : 0.085573 ,train acc: 0.988464 ,val loss : 0.110456 ,val acc : 0.991913\n",
      "[ ecpho : 2  iter :938 ]train loss : 0.122670 ,train acc: 0.987885 ,val loss : 0.109351 ,val acc : 0.991974\n",
      "[ ecpho : 2  iter :939 ]train loss : 0.146426 ,train acc: 0.949249 ,val loss : 0.110501 ,val acc : 0.991821\n",
      "[ ecpho : 2  iter :940 ]train loss : 0.160452 ,train acc: 0.972198 ,val loss : 0.108277 ,val acc : 0.992218\n",
      "=============================================\n",
      "[ 2 ] average train loss : 0.165826 train acc : 0.934524\n",
      "[ ecpho : 3  iter :1 ]train loss : 0.077750 ,train acc: 0.991608 ,val loss : 0.108454 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :2 ]train loss : 0.230154 ,train acc: 0.894226 ,val loss : 0.107497 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :3 ]train loss : 0.076324 ,train acc: 0.993896 ,val loss : 0.107886 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :4 ]train loss : 0.104222 ,train acc: 0.974396 ,val loss : 0.108363 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :5 ]train loss : 0.093546 ,train acc: 0.994659 ,val loss : 0.106467 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :6 ]train loss : 0.094768 ,train acc: 0.993103 ,val loss : 0.105843 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :7 ]train loss : 0.093350 ,train acc: 0.977814 ,val loss : 0.107587 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :8 ]train loss : 0.352393 ,train acc: 0.859192 ,val loss : 0.110036 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :9 ]train loss : 0.165880 ,train acc: 0.926361 ,val loss : 0.106286 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :10 ]train loss : 0.150311 ,train acc: 0.952240 ,val loss : 0.108827 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :11 ]train loss : 0.071100 ,train acc: 0.998596 ,val loss : 0.109803 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :12 ]train loss : 0.091948 ,train acc: 0.993958 ,val loss : 0.107208 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :13 ]train loss : 0.088713 ,train acc: 0.985504 ,val loss : 0.109273 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :14 ]train loss : 0.098853 ,train acc: 0.996674 ,val loss : 0.105292 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :15 ]train loss : 0.084833 ,train acc: 0.983459 ,val loss : 0.106377 ,val acc : 0.993042\n",
      "[ ecpho : 3  iter :16 ]train loss : 0.090380 ,train acc: 0.993805 ,val loss : 0.107411 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :17 ]train loss : 0.086342 ,train acc: 0.996826 ,val loss : 0.105780 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :18 ]train loss : 0.762617 ,train acc: 0.505524 ,val loss : 0.106178 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :19 ]train loss : 0.096768 ,train acc: 0.980896 ,val loss : 0.108258 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :20 ]train loss : 0.095669 ,train acc: 0.992310 ,val loss : 0.110206 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :21 ]train loss : 0.112069 ,train acc: 0.985809 ,val loss : 0.109901 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :22 ]train loss : 0.119031 ,train acc: 0.973572 ,val loss : 0.107248 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :23 ]train loss : 0.058077 ,train acc: 0.999207 ,val loss : 0.106552 ,val acc : 0.992828\n",
      "[ ecpho : 3  iter :24 ]train loss : 0.105983 ,train acc: 0.991699 ,val loss : 0.107460 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :25 ]train loss : 0.104675 ,train acc: 0.976379 ,val loss : 0.107485 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :26 ]train loss : 0.421371 ,train acc: 0.779480 ,val loss : 0.106655 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :27 ]train loss : 0.352193 ,train acc: 0.770294 ,val loss : 0.106978 ,val acc : 0.992767\n",
      "[ ecpho : 3  iter :28 ]train loss : 0.083751 ,train acc: 0.994934 ,val loss : 0.108222 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :29 ]train loss : 0.099994 ,train acc: 0.982727 ,val loss : 0.108293 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :30 ]train loss : 0.073857 ,train acc: 0.995239 ,val loss : 0.108762 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :31 ]train loss : 0.079235 ,train acc: 0.992126 ,val loss : 0.107034 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :32 ]train loss : 0.079023 ,train acc: 0.989136 ,val loss : 0.106983 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :33 ]train loss : 0.059263 ,train acc: 0.997925 ,val loss : 0.107273 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :34 ]train loss : 0.084613 ,train acc: 0.994446 ,val loss : 0.107235 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :35 ]train loss : 0.068844 ,train acc: 0.997437 ,val loss : 0.108739 ,val acc : 0.992981\n",
      "[ ecpho : 3  iter :36 ]train loss : 0.112171 ,train acc: 0.969696 ,val loss : 0.109079 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :37 ]train loss : 0.100210 ,train acc: 0.994476 ,val loss : 0.106222 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :38 ]train loss : 0.112910 ,train acc: 0.964203 ,val loss : 0.105802 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :39 ]train loss : 0.255925 ,train acc: 0.854584 ,val loss : 0.107698 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :40 ]train loss : 0.220994 ,train acc: 0.939301 ,val loss : 0.108455 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :41 ]train loss : 0.077264 ,train acc: 0.994598 ,val loss : 0.105358 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :42 ]train loss : 0.076904 ,train acc: 0.994171 ,val loss : 0.106198 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :43 ]train loss : 0.187161 ,train acc: 0.954803 ,val loss : 0.107984 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :44 ]train loss : 0.085300 ,train acc: 0.989502 ,val loss : 0.107591 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :45 ]train loss : 0.101302 ,train acc: 0.985321 ,val loss : 0.108482 ,val acc : 0.992798\n",
      "[ ecpho : 3  iter :46 ]train loss : 0.772759 ,train acc: 0.428772 ,val loss : 0.109495 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :47 ]train loss : 0.092472 ,train acc: 0.977692 ,val loss : 0.106303 ,val acc : 0.992767\n",
      "[ ecpho : 3  iter :48 ]train loss : 0.110471 ,train acc: 0.985687 ,val loss : 0.107964 ,val acc : 0.992828\n",
      "[ ecpho : 3  iter :49 ]train loss : 0.102209 ,train acc: 0.992340 ,val loss : 0.106370 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :50 ]train loss : 0.101352 ,train acc: 0.974640 ,val loss : 0.105522 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :51 ]train loss : 0.080226 ,train acc: 0.995636 ,val loss : 0.108298 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :52 ]train loss : 0.109209 ,train acc: 0.991180 ,val loss : 0.109379 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :53 ]train loss : 0.105081 ,train acc: 0.974762 ,val loss : 0.105793 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :54 ]train loss : 0.169524 ,train acc: 0.921234 ,val loss : 0.107761 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :55 ]train loss : 0.114351 ,train acc: 0.992218 ,val loss : 0.105538 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :56 ]train loss : 0.190272 ,train acc: 0.916199 ,val loss : 0.107498 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :57 ]train loss : 0.358914 ,train acc: 0.771942 ,val loss : 0.103213 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :58 ]train loss : 0.075022 ,train acc: 0.992249 ,val loss : 0.107904 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :59 ]train loss : 0.128661 ,train acc: 0.967712 ,val loss : 0.107373 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :60 ]train loss : 0.066942 ,train acc: 0.999115 ,val loss : 0.109261 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :61 ]train loss : 0.145505 ,train acc: 0.951019 ,val loss : 0.105751 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :62 ]train loss : 0.124922 ,train acc: 0.955780 ,val loss : 0.105353 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :63 ]train loss : 0.431503 ,train acc: 0.710602 ,val loss : 0.107459 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :64 ]train loss : 0.395316 ,train acc: 0.782776 ,val loss : 0.105555 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :65 ]train loss : 0.140946 ,train acc: 0.980988 ,val loss : 0.109462 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :66 ]train loss : 0.078316 ,train acc: 0.997864 ,val loss : 0.105826 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :67 ]train loss : 0.110903 ,train acc: 0.980499 ,val loss : 0.106510 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :68 ]train loss : 0.078624 ,train acc: 0.996948 ,val loss : 0.108091 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :69 ]train loss : 0.088711 ,train acc: 0.996582 ,val loss : 0.107552 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :70 ]train loss : 0.115465 ,train acc: 0.985077 ,val loss : 0.107258 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :71 ]train loss : 0.080361 ,train acc: 0.991089 ,val loss : 0.108127 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :72 ]train loss : 0.087370 ,train acc: 0.985901 ,val loss : 0.104932 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :73 ]train loss : 0.069133 ,train acc: 0.994019 ,val loss : 0.105834 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :74 ]train loss : 0.540764 ,train acc: 0.643005 ,val loss : 0.104396 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :75 ]train loss : 0.105175 ,train acc: 0.972412 ,val loss : 0.106436 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :76 ]train loss : 0.064131 ,train acc: 0.997864 ,val loss : 0.106164 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :77 ]train loss : 0.079547 ,train acc: 0.992035 ,val loss : 0.106529 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :78 ]train loss : 0.067026 ,train acc: 0.993622 ,val loss : 0.108184 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :79 ]train loss : 0.061500 ,train acc: 0.996124 ,val loss : 0.104608 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :80 ]train loss : 0.100747 ,train acc: 0.992889 ,val loss : 0.104839 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :81 ]train loss : 0.096514 ,train acc: 0.982025 ,val loss : 0.107099 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :82 ]train loss : 0.457573 ,train acc: 0.716461 ,val loss : 0.105310 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :83 ]train loss : 0.082056 ,train acc: 0.991943 ,val loss : 0.107546 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :84 ]train loss : 0.079046 ,train acc: 0.998749 ,val loss : 0.106353 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :85 ]train loss : 0.068720 ,train acc: 0.995392 ,val loss : 0.104326 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :86 ]train loss : 0.068355 ,train acc: 0.997528 ,val loss : 0.106035 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :87 ]train loss : 0.092850 ,train acc: 0.987366 ,val loss : 0.108564 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :88 ]train loss : 0.111310 ,train acc: 0.987000 ,val loss : 0.106310 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :89 ]train loss : 0.220910 ,train acc: 0.880737 ,val loss : 0.107627 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :90 ]train loss : 0.320022 ,train acc: 0.866333 ,val loss : 0.107186 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :91 ]train loss : 0.077245 ,train acc: 0.997040 ,val loss : 0.106151 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :92 ]train loss : 0.158306 ,train acc: 0.929626 ,val loss : 0.104334 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :93 ]train loss : 0.365967 ,train acc: 0.782959 ,val loss : 0.109508 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :94 ]train loss : 0.081484 ,train acc: 0.996643 ,val loss : 0.105471 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :95 ]train loss : 0.597321 ,train acc: 0.690765 ,val loss : 0.105457 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :96 ]train loss : 0.116221 ,train acc: 0.974121 ,val loss : 0.107265 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :97 ]train loss : 0.094741 ,train acc: 0.979523 ,val loss : 0.108739 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :98 ]train loss : 0.088930 ,train acc: 0.994629 ,val loss : 0.105740 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :99 ]train loss : 0.062814 ,train acc: 0.997772 ,val loss : 0.107545 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :100 ]train loss : 0.135967 ,train acc: 0.974182 ,val loss : 0.107966 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :101 ]train loss : 0.093034 ,train acc: 0.994263 ,val loss : 0.106171 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :102 ]train loss : 0.490520 ,train acc: 0.691101 ,val loss : 0.106106 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :103 ]train loss : 0.505717 ,train acc: 0.753571 ,val loss : 0.106103 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :104 ]train loss : 0.459945 ,train acc: 0.684448 ,val loss : 0.107394 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :105 ]train loss : 0.080919 ,train acc: 0.991211 ,val loss : 0.109685 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :106 ]train loss : 0.134340 ,train acc: 0.977386 ,val loss : 0.105848 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :107 ]train loss : 0.150320 ,train acc: 0.961304 ,val loss : 0.109935 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :108 ]train loss : 0.098933 ,train acc: 0.992950 ,val loss : 0.107070 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :109 ]train loss : 0.217746 ,train acc: 0.915436 ,val loss : 0.108429 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :110 ]train loss : 0.065275 ,train acc: 0.998016 ,val loss : 0.107978 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :111 ]train loss : 0.256088 ,train acc: 0.866211 ,val loss : 0.106044 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :112 ]train loss : 0.096878 ,train acc: 0.983063 ,val loss : 0.108195 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :113 ]train loss : 0.804632 ,train acc: 0.464813 ,val loss : 0.109633 ,val acc : 0.991272\n",
      "[ ecpho : 3  iter :114 ]train loss : 0.078792 ,train acc: 0.989410 ,val loss : 0.105946 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :115 ]train loss : 0.071091 ,train acc: 0.993103 ,val loss : 0.106672 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :116 ]train loss : 0.314587 ,train acc: 0.790375 ,val loss : 0.107166 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :117 ]train loss : 0.114525 ,train acc: 0.968353 ,val loss : 0.109808 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :118 ]train loss : 0.114943 ,train acc: 0.960693 ,val loss : 0.107998 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :119 ]train loss : 0.088403 ,train acc: 0.991455 ,val loss : 0.110382 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :120 ]train loss : 0.063312 ,train acc: 0.997955 ,val loss : 0.106299 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :121 ]train loss : 0.597179 ,train acc: 0.606720 ,val loss : 0.111218 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :122 ]train loss : 0.079190 ,train acc: 0.991669 ,val loss : 0.108562 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :123 ]train loss : 0.085146 ,train acc: 0.996765 ,val loss : 0.109062 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :124 ]train loss : 0.074798 ,train acc: 0.994812 ,val loss : 0.108419 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :125 ]train loss : 0.097341 ,train acc: 0.991577 ,val loss : 0.108977 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :126 ]train loss : 0.064204 ,train acc: 0.998352 ,val loss : 0.106406 ,val acc : 0.991394\n",
      "[ ecpho : 3  iter :127 ]train loss : 0.909915 ,train acc: 0.354950 ,val loss : 0.105376 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :128 ]train loss : 0.095133 ,train acc: 0.989838 ,val loss : 0.109216 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :129 ]train loss : 0.523356 ,train acc: 0.658783 ,val loss : 0.108198 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :130 ]train loss : 0.418788 ,train acc: 0.712982 ,val loss : 0.110467 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :131 ]train loss : 0.102063 ,train acc: 0.975769 ,val loss : 0.109861 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :132 ]train loss : 0.087545 ,train acc: 0.992920 ,val loss : 0.108462 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :133 ]train loss : 0.303268 ,train acc: 0.849854 ,val loss : 0.108967 ,val acc : 0.990936\n",
      "[ ecpho : 3  iter :134 ]train loss : 0.475420 ,train acc: 0.703461 ,val loss : 0.110912 ,val acc : 0.990936\n",
      "[ ecpho : 3  iter :135 ]train loss : 0.121571 ,train acc: 0.982758 ,val loss : 0.112028 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :136 ]train loss : 0.129167 ,train acc: 0.958893 ,val loss : 0.111310 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :137 ]train loss : 0.100184 ,train acc: 0.983887 ,val loss : 0.109529 ,val acc : 0.991394\n",
      "[ ecpho : 3  iter :138 ]train loss : 0.068634 ,train acc: 0.996826 ,val loss : 0.111301 ,val acc : 0.990326\n",
      "[ ecpho : 3  iter :139 ]train loss : 0.062236 ,train acc: 0.998718 ,val loss : 0.109235 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :140 ]train loss : 0.076335 ,train acc: 0.996429 ,val loss : 0.110717 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :141 ]train loss : 0.592023 ,train acc: 0.554413 ,val loss : 0.110742 ,val acc : 0.990601\n",
      "[ ecpho : 3  iter :142 ]train loss : 0.082900 ,train acc: 0.982330 ,val loss : 0.108864 ,val acc : 0.991028\n",
      "[ ecpho : 3  iter :143 ]train loss : 0.100462 ,train acc: 0.977356 ,val loss : 0.110083 ,val acc : 0.990692\n",
      "[ ecpho : 3  iter :144 ]train loss : 0.101613 ,train acc: 0.974121 ,val loss : 0.111663 ,val acc : 0.990082\n",
      "[ ecpho : 3  iter :145 ]train loss : 0.072236 ,train acc: 0.991394 ,val loss : 0.110331 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :146 ]train loss : 0.074754 ,train acc: 0.991608 ,val loss : 0.107603 ,val acc : 0.991058\n",
      "[ ecpho : 3  iter :147 ]train loss : 0.073415 ,train acc: 0.993011 ,val loss : 0.111156 ,val acc : 0.990204\n",
      "[ ecpho : 3  iter :148 ]train loss : 1.114216 ,train acc: 0.222412 ,val loss : 0.109810 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :149 ]train loss : 0.142909 ,train acc: 0.948730 ,val loss : 0.112034 ,val acc : 0.990173\n",
      "[ ecpho : 3  iter :150 ]train loss : 0.116841 ,train acc: 0.976196 ,val loss : 0.107481 ,val acc : 0.990723\n",
      "[ ecpho : 3  iter :151 ]train loss : 0.808415 ,train acc: 0.429779 ,val loss : 0.108111 ,val acc : 0.991028\n",
      "[ ecpho : 3  iter :152 ]train loss : 0.230527 ,train acc: 0.922760 ,val loss : 0.110567 ,val acc : 0.989716\n",
      "[ ecpho : 3  iter :153 ]train loss : 0.132762 ,train acc: 0.954224 ,val loss : 0.109091 ,val acc : 0.990387\n",
      "[ ecpho : 3  iter :154 ]train loss : 0.203044 ,train acc: 0.941803 ,val loss : 0.110561 ,val acc : 0.990326\n",
      "[ ecpho : 3  iter :155 ]train loss : 0.100578 ,train acc: 0.987274 ,val loss : 0.112094 ,val acc : 0.989380\n",
      "[ ecpho : 3  iter :156 ]train loss : 0.084962 ,train acc: 0.987854 ,val loss : 0.109646 ,val acc : 0.990509\n",
      "[ ecpho : 3  iter :157 ]train loss : 0.095744 ,train acc: 0.995148 ,val loss : 0.107832 ,val acc : 0.990967\n",
      "[ ecpho : 3  iter :158 ]train loss : 0.078467 ,train acc: 0.996155 ,val loss : 0.109588 ,val acc : 0.990387\n",
      "[ ecpho : 3  iter :159 ]train loss : 0.114924 ,train acc: 0.983734 ,val loss : 0.110029 ,val acc : 0.990570\n",
      "[ ecpho : 3  iter :160 ]train loss : 0.126676 ,train acc: 0.961670 ,val loss : 0.109914 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :161 ]train loss : 1.200088 ,train acc: 0.126984 ,val loss : 0.108355 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :162 ]train loss : 0.160867 ,train acc: 0.947113 ,val loss : 0.112064 ,val acc : 0.990967\n",
      "[ ecpho : 3  iter :163 ]train loss : 0.116561 ,train acc: 0.965698 ,val loss : 0.108486 ,val acc : 0.990662\n",
      "[ ecpho : 3  iter :164 ]train loss : 0.136646 ,train acc: 0.974823 ,val loss : 0.109325 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :165 ]train loss : 0.079438 ,train acc: 0.994720 ,val loss : 0.108555 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :166 ]train loss : 0.088362 ,train acc: 0.986328 ,val loss : 0.107473 ,val acc : 0.990265\n",
      "[ ecpho : 3  iter :167 ]train loss : 0.420009 ,train acc: 0.726624 ,val loss : 0.106217 ,val acc : 0.990723\n",
      "[ ecpho : 3  iter :168 ]train loss : 0.129772 ,train acc: 0.957855 ,val loss : 0.109240 ,val acc : 0.990662\n",
      "[ ecpho : 3  iter :169 ]train loss : 0.307930 ,train acc: 0.841431 ,val loss : 0.107136 ,val acc : 0.990631\n",
      "[ ecpho : 3  iter :170 ]train loss : 0.834810 ,train acc: 0.444153 ,val loss : 0.110958 ,val acc : 0.990387\n",
      "[ ecpho : 3  iter :171 ]train loss : 0.083636 ,train acc: 0.988831 ,val loss : 0.110538 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :172 ]train loss : 0.401342 ,train acc: 0.799683 ,val loss : 0.109358 ,val acc : 0.990265\n",
      "[ ecpho : 3  iter :173 ]train loss : 0.689015 ,train acc: 0.529816 ,val loss : 0.108908 ,val acc : 0.990326\n",
      "[ ecpho : 3  iter :174 ]train loss : 0.122862 ,train acc: 0.985138 ,val loss : 0.108989 ,val acc : 0.990143\n",
      "[ ecpho : 3  iter :175 ]train loss : 0.072120 ,train acc: 0.996674 ,val loss : 0.108301 ,val acc : 0.990784\n",
      "[ ecpho : 3  iter :176 ]train loss : 0.264257 ,train acc: 0.836365 ,val loss : 0.109069 ,val acc : 0.989807\n",
      "[ ecpho : 3  iter :177 ]train loss : 0.102500 ,train acc: 0.985596 ,val loss : 0.111598 ,val acc : 0.990631\n",
      "[ ecpho : 3  iter :178 ]train loss : 0.100399 ,train acc: 0.990936 ,val loss : 0.109615 ,val acc : 0.990021\n",
      "[ ecpho : 3  iter :179 ]train loss : 0.174929 ,train acc: 0.919403 ,val loss : 0.110079 ,val acc : 0.990204\n",
      "[ ecpho : 3  iter :180 ]train loss : 0.081982 ,train acc: 0.987946 ,val loss : 0.111024 ,val acc : 0.989624\n",
      "[ ecpho : 3  iter :181 ]train loss : 0.183880 ,train acc: 0.951538 ,val loss : 0.108875 ,val acc : 0.990265\n",
      "[ ecpho : 3  iter :182 ]train loss : 0.120498 ,train acc: 0.980133 ,val loss : 0.111524 ,val acc : 0.989685\n",
      "[ ecpho : 3  iter :183 ]train loss : 0.086066 ,train acc: 0.991089 ,val loss : 0.108926 ,val acc : 0.990265\n",
      "[ ecpho : 3  iter :184 ]train loss : 0.088483 ,train acc: 0.989441 ,val loss : 0.111962 ,val acc : 0.989563\n",
      "[ ecpho : 3  iter :185 ]train loss : 0.809097 ,train acc: 0.385834 ,val loss : 0.110477 ,val acc : 0.989899\n",
      "[ ecpho : 3  iter :186 ]train loss : 0.123876 ,train acc: 0.960175 ,val loss : 0.110476 ,val acc : 0.989807\n",
      "[ ecpho : 3  iter :187 ]train loss : 0.115799 ,train acc: 0.980194 ,val loss : 0.111506 ,val acc : 0.990112\n",
      "[ ecpho : 3  iter :188 ]train loss : 0.095760 ,train acc: 0.994049 ,val loss : 0.109137 ,val acc : 0.989899\n",
      "[ ecpho : 3  iter :189 ]train loss : 0.071605 ,train acc: 0.996368 ,val loss : 0.112488 ,val acc : 0.989960\n",
      "[ ecpho : 3  iter :190 ]train loss : 0.111985 ,train acc: 0.989716 ,val loss : 0.111963 ,val acc : 0.989807\n",
      "[ ecpho : 3  iter :191 ]train loss : 0.186718 ,train acc: 0.910492 ,val loss : 0.108668 ,val acc : 0.990784\n",
      "[ ecpho : 3  iter :192 ]train loss : 0.077934 ,train acc: 0.994049 ,val loss : 0.111408 ,val acc : 0.989868\n",
      "[ ecpho : 3  iter :193 ]train loss : 0.139937 ,train acc: 0.951965 ,val loss : 0.111532 ,val acc : 0.990692\n",
      "[ ecpho : 3  iter :194 ]train loss : 0.358417 ,train acc: 0.812897 ,val loss : 0.110848 ,val acc : 0.990204\n",
      "[ ecpho : 3  iter :195 ]train loss : 0.075264 ,train acc: 0.990051 ,val loss : 0.111265 ,val acc : 0.990417\n",
      "[ ecpho : 3  iter :196 ]train loss : 0.074910 ,train acc: 0.993927 ,val loss : 0.111211 ,val acc : 0.990692\n",
      "[ ecpho : 3  iter :197 ]train loss : 0.082432 ,train acc: 0.990906 ,val loss : 0.110099 ,val acc : 0.990417\n",
      "[ ecpho : 3  iter :198 ]train loss : 0.078624 ,train acc: 0.993164 ,val loss : 0.110428 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :199 ]train loss : 0.425007 ,train acc: 0.700745 ,val loss : 0.110106 ,val acc : 0.990021\n",
      "[ ecpho : 3  iter :200 ]train loss : 0.198056 ,train acc: 0.917023 ,val loss : 0.113020 ,val acc : 0.990753\n",
      "[ ecpho : 3  iter :201 ]train loss : 0.070541 ,train acc: 0.992401 ,val loss : 0.110250 ,val acc : 0.990601\n",
      "[ ecpho : 3  iter :202 ]train loss : 0.078224 ,train acc: 0.996918 ,val loss : 0.109191 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :203 ]train loss : 0.130889 ,train acc: 0.975769 ,val loss : 0.108415 ,val acc : 0.990723\n",
      "[ ecpho : 3  iter :204 ]train loss : 0.109337 ,train acc: 0.973785 ,val loss : 0.110754 ,val acc : 0.990814\n",
      "[ ecpho : 3  iter :205 ]train loss : 0.081812 ,train acc: 0.992554 ,val loss : 0.109304 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :206 ]train loss : 0.293689 ,train acc: 0.839325 ,val loss : 0.111924 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :207 ]train loss : 0.215903 ,train acc: 0.889496 ,val loss : 0.112035 ,val acc : 0.991058\n",
      "[ ecpho : 3  iter :208 ]train loss : 0.104470 ,train acc: 0.990448 ,val loss : 0.110134 ,val acc : 0.990417\n",
      "[ ecpho : 3  iter :209 ]train loss : 0.090843 ,train acc: 0.982544 ,val loss : 0.109879 ,val acc : 0.990509\n",
      "[ ecpho : 3  iter :210 ]train loss : 0.063300 ,train acc: 0.997101 ,val loss : 0.108391 ,val acc : 0.990814\n",
      "[ ecpho : 3  iter :211 ]train loss : 0.084489 ,train acc: 0.984894 ,val loss : 0.108663 ,val acc : 0.990570\n",
      "[ ecpho : 3  iter :212 ]train loss : 0.334596 ,train acc: 0.773438 ,val loss : 0.108510 ,val acc : 0.990601\n",
      "[ ecpho : 3  iter :213 ]train loss : 0.075378 ,train acc: 0.993774 ,val loss : 0.108406 ,val acc : 0.990356\n",
      "[ ecpho : 3  iter :214 ]train loss : 0.083665 ,train acc: 0.987701 ,val loss : 0.111884 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :215 ]train loss : 0.085623 ,train acc: 0.984131 ,val loss : 0.109079 ,val acc : 0.990387\n",
      "[ ecpho : 3  iter :216 ]train loss : 0.087855 ,train acc: 0.988129 ,val loss : 0.112369 ,val acc : 0.990204\n",
      "[ ecpho : 3  iter :217 ]train loss : 0.131924 ,train acc: 0.974396 ,val loss : 0.109332 ,val acc : 0.990662\n",
      "[ ecpho : 3  iter :218 ]train loss : 0.088998 ,train acc: 0.982452 ,val loss : 0.109203 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :219 ]train loss : 0.075369 ,train acc: 0.990723 ,val loss : 0.109734 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :220 ]train loss : 0.088381 ,train acc: 0.980743 ,val loss : 0.110107 ,val acc : 0.990784\n",
      "[ ecpho : 3  iter :221 ]train loss : 0.065215 ,train acc: 0.993439 ,val loss : 0.110163 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :222 ]train loss : 0.073344 ,train acc: 0.996063 ,val loss : 0.111121 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :223 ]train loss : 0.068724 ,train acc: 0.994476 ,val loss : 0.108620 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :224 ]train loss : 0.441049 ,train acc: 0.682739 ,val loss : 0.111503 ,val acc : 0.991028\n",
      "[ ecpho : 3  iter :225 ]train loss : 0.079771 ,train acc: 0.992859 ,val loss : 0.110468 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :226 ]train loss : 0.125367 ,train acc: 0.978241 ,val loss : 0.108596 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :227 ]train loss : 0.210071 ,train acc: 0.947418 ,val loss : 0.111276 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :228 ]train loss : 0.206201 ,train acc: 0.895599 ,val loss : 0.111037 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :229 ]train loss : 0.122188 ,train acc: 0.962830 ,val loss : 0.109299 ,val acc : 0.991180\n",
      "[ ecpho : 3  iter :230 ]train loss : 0.106952 ,train acc: 0.974792 ,val loss : 0.111020 ,val acc : 0.990936\n",
      "[ ecpho : 3  iter :231 ]train loss : 0.081824 ,train acc: 0.991028 ,val loss : 0.108048 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :232 ]train loss : 0.083524 ,train acc: 0.990204 ,val loss : 0.108407 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :233 ]train loss : 0.091407 ,train acc: 0.994324 ,val loss : 0.110389 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :234 ]train loss : 0.163351 ,train acc: 0.931274 ,val loss : 0.109233 ,val acc : 0.991180\n",
      "[ ecpho : 3  iter :235 ]train loss : 0.075520 ,train acc: 0.996460 ,val loss : 0.108922 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :236 ]train loss : 0.073785 ,train acc: 0.996582 ,val loss : 0.109649 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :237 ]train loss : 0.118110 ,train acc: 0.963928 ,val loss : 0.110849 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :238 ]train loss : 0.107871 ,train acc: 0.978760 ,val loss : 0.109066 ,val acc : 0.991150\n",
      "[ ecpho : 3  iter :239 ]train loss : 0.083480 ,train acc: 0.994629 ,val loss : 0.109072 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :240 ]train loss : 0.159996 ,train acc: 0.959412 ,val loss : 0.109826 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :241 ]train loss : 0.195690 ,train acc: 0.893616 ,val loss : 0.108385 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :242 ]train loss : 0.105115 ,train acc: 0.973602 ,val loss : 0.110297 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :243 ]train loss : 0.114290 ,train acc: 0.974030 ,val loss : 0.107751 ,val acc : 0.991455\n",
      "[ ecpho : 3  iter :244 ]train loss : 0.059569 ,train acc: 0.998413 ,val loss : 0.110290 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :245 ]train loss : 0.081560 ,train acc: 0.994843 ,val loss : 0.107152 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :246 ]train loss : 0.095695 ,train acc: 0.985901 ,val loss : 0.110674 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :247 ]train loss : 0.068629 ,train acc: 0.998566 ,val loss : 0.108017 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :248 ]train loss : 0.069956 ,train acc: 0.997528 ,val loss : 0.110822 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :249 ]train loss : 0.064544 ,train acc: 0.998810 ,val loss : 0.110127 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :250 ]train loss : 0.064848 ,train acc: 0.997253 ,val loss : 0.107514 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :251 ]train loss : 0.094361 ,train acc: 0.977509 ,val loss : 0.110971 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :252 ]train loss : 0.073678 ,train acc: 0.997528 ,val loss : 0.108238 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :253 ]train loss : 0.140379 ,train acc: 0.950836 ,val loss : 0.108945 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :254 ]train loss : 1.195417 ,train acc: 0.183167 ,val loss : 0.107676 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :255 ]train loss : 0.153827 ,train acc: 0.939423 ,val loss : 0.110339 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :256 ]train loss : 0.160794 ,train acc: 0.933228 ,val loss : 0.111727 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :257 ]train loss : 0.063832 ,train acc: 0.997223 ,val loss : 0.111771 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :258 ]train loss : 0.091331 ,train acc: 0.996765 ,val loss : 0.110208 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :259 ]train loss : 0.867152 ,train acc: 0.464386 ,val loss : 0.108894 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :260 ]train loss : 0.077940 ,train acc: 0.993469 ,val loss : 0.110009 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :261 ]train loss : 0.070222 ,train acc: 0.995789 ,val loss : 0.109869 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :262 ]train loss : 0.063233 ,train acc: 0.999176 ,val loss : 0.108738 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :263 ]train loss : 0.080207 ,train acc: 0.986877 ,val loss : 0.110693 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :264 ]train loss : 0.101697 ,train acc: 0.995697 ,val loss : 0.110210 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :265 ]train loss : 0.128566 ,train acc: 0.967865 ,val loss : 0.110712 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :266 ]train loss : 0.075048 ,train acc: 0.993500 ,val loss : 0.109333 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :267 ]train loss : 0.053397 ,train acc: 0.999695 ,val loss : 0.110817 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :268 ]train loss : 0.087145 ,train acc: 0.997314 ,val loss : 0.110864 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :269 ]train loss : 0.095134 ,train acc: 0.980652 ,val loss : 0.111491 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :270 ]train loss : 0.120695 ,train acc: 0.966858 ,val loss : 0.111212 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :271 ]train loss : 0.167157 ,train acc: 0.951019 ,val loss : 0.107802 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :272 ]train loss : 0.297610 ,train acc: 0.817200 ,val loss : 0.108995 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :273 ]train loss : 0.070198 ,train acc: 0.998871 ,val loss : 0.111054 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :274 ]train loss : 0.079426 ,train acc: 0.986084 ,val loss : 0.109203 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :275 ]train loss : 0.170179 ,train acc: 0.961060 ,val loss : 0.108768 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :276 ]train loss : 0.089299 ,train acc: 0.983795 ,val loss : 0.108976 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :277 ]train loss : 0.110173 ,train acc: 0.968719 ,val loss : 0.108891 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :278 ]train loss : 0.115418 ,train acc: 0.987457 ,val loss : 0.110406 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :279 ]train loss : 0.087181 ,train acc: 0.997223 ,val loss : 0.107106 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :280 ]train loss : 0.126302 ,train acc: 0.973602 ,val loss : 0.106876 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :281 ]train loss : 0.120078 ,train acc: 0.977783 ,val loss : 0.108838 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :282 ]train loss : 1.012748 ,train acc: 0.281281 ,val loss : 0.111179 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :283 ]train loss : 0.070790 ,train acc: 0.994568 ,val loss : 0.105789 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :284 ]train loss : 0.078921 ,train acc: 0.991669 ,val loss : 0.109049 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :285 ]train loss : 0.073533 ,train acc: 0.992584 ,val loss : 0.107600 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :286 ]train loss : 0.299307 ,train acc: 0.890594 ,val loss : 0.109464 ,val acc : 0.992798\n",
      "[ ecpho : 3  iter :287 ]train loss : 0.188420 ,train acc: 0.912323 ,val loss : 0.107153 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :288 ]train loss : 0.268010 ,train acc: 0.828522 ,val loss : 0.108332 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :289 ]train loss : 0.112979 ,train acc: 0.973633 ,val loss : 0.110059 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :290 ]train loss : 0.060026 ,train acc: 0.998260 ,val loss : 0.109284 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :291 ]train loss : 0.078357 ,train acc: 0.984467 ,val loss : 0.107414 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :292 ]train loss : 0.758232 ,train acc: 0.436981 ,val loss : 0.110072 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :293 ]train loss : 0.087555 ,train acc: 0.997864 ,val loss : 0.109210 ,val acc : 0.992889\n",
      "[ ecpho : 3  iter :294 ]train loss : 0.127021 ,train acc: 0.953247 ,val loss : 0.108715 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :295 ]train loss : 0.071525 ,train acc: 0.998383 ,val loss : 0.114163 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :296 ]train loss : 0.067329 ,train acc: 0.997314 ,val loss : 0.109560 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :297 ]train loss : 0.099964 ,train acc: 0.993347 ,val loss : 0.109487 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :298 ]train loss : 0.096459 ,train acc: 0.993530 ,val loss : 0.111851 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :299 ]train loss : 0.091968 ,train acc: 0.998383 ,val loss : 0.108296 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :300 ]train loss : 0.061454 ,train acc: 0.998322 ,val loss : 0.108190 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :301 ]train loss : 0.334269 ,train acc: 0.783234 ,val loss : 0.110183 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :302 ]train loss : 0.112218 ,train acc: 0.982849 ,val loss : 0.107822 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :303 ]train loss : 0.393032 ,train acc: 0.767029 ,val loss : 0.109667 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :304 ]train loss : 0.700308 ,train acc: 0.444885 ,val loss : 0.108298 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :305 ]train loss : 0.374303 ,train acc: 0.753021 ,val loss : 0.111823 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :306 ]train loss : 0.164617 ,train acc: 0.944397 ,val loss : 0.109385 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :307 ]train loss : 0.357261 ,train acc: 0.808380 ,val loss : 0.110470 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :308 ]train loss : 0.121681 ,train acc: 0.972534 ,val loss : 0.109842 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :309 ]train loss : 0.078089 ,train acc: 0.997955 ,val loss : 0.111259 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :310 ]train loss : 0.276080 ,train acc: 0.893463 ,val loss : 0.111564 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :311 ]train loss : 0.074745 ,train acc: 0.993134 ,val loss : 0.113203 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :312 ]train loss : 0.055465 ,train acc: 0.999420 ,val loss : 0.111444 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :313 ]train loss : 0.098454 ,train acc: 0.978302 ,val loss : 0.110521 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :314 ]train loss : 0.349957 ,train acc: 0.826385 ,val loss : 0.110720 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :315 ]train loss : 0.086259 ,train acc: 0.990051 ,val loss : 0.112340 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :316 ]train loss : 0.058082 ,train acc: 0.998169 ,val loss : 0.112909 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :317 ]train loss : 0.146627 ,train acc: 0.958221 ,val loss : 0.112927 ,val acc : 0.991394\n",
      "[ ecpho : 3  iter :318 ]train loss : 0.105333 ,train acc: 0.975952 ,val loss : 0.110569 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :319 ]train loss : 0.162683 ,train acc: 0.933594 ,val loss : 0.112695 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :320 ]train loss : 0.094501 ,train acc: 0.996124 ,val loss : 0.112820 ,val acc : 0.991302\n",
      "[ ecpho : 3  iter :321 ]train loss : 0.106721 ,train acc: 0.992279 ,val loss : 0.110327 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :322 ]train loss : 0.071182 ,train acc: 0.993530 ,val loss : 0.109457 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :323 ]train loss : 0.067275 ,train acc: 0.997101 ,val loss : 0.112947 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :324 ]train loss : 0.621495 ,train acc: 0.688110 ,val loss : 0.111145 ,val acc : 0.990814\n",
      "[ ecpho : 3  iter :325 ]train loss : 0.082640 ,train acc: 0.990509 ,val loss : 0.110146 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :326 ]train loss : 0.067802 ,train acc: 0.994232 ,val loss : 0.113219 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :327 ]train loss : 0.083525 ,train acc: 0.996399 ,val loss : 0.108387 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :328 ]train loss : 0.074151 ,train acc: 0.994141 ,val loss : 0.110438 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :329 ]train loss : 0.360579 ,train acc: 0.808502 ,val loss : 0.113741 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :330 ]train loss : 0.163441 ,train acc: 0.932922 ,val loss : 0.114392 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :331 ]train loss : 0.104972 ,train acc: 0.993195 ,val loss : 0.110781 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :332 ]train loss : 0.192001 ,train acc: 0.929688 ,val loss : 0.109681 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :333 ]train loss : 0.099235 ,train acc: 0.979462 ,val loss : 0.110122 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :334 ]train loss : 0.080561 ,train acc: 0.993591 ,val loss : 0.110940 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :335 ]train loss : 0.108781 ,train acc: 0.990234 ,val loss : 0.112609 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :336 ]train loss : 0.957166 ,train acc: 0.383087 ,val loss : 0.111320 ,val acc : 0.991882\n",
      "[ ecpho : 3  iter :337 ]train loss : 0.478151 ,train acc: 0.669281 ,val loss : 0.109671 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :338 ]train loss : 0.101879 ,train acc: 0.978729 ,val loss : 0.111697 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :339 ]train loss : 0.075468 ,train acc: 0.991791 ,val loss : 0.111623 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :340 ]train loss : 0.135781 ,train acc: 0.951721 ,val loss : 0.112094 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :341 ]train loss : 0.099771 ,train acc: 0.984406 ,val loss : 0.111015 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :342 ]train loss : 0.137850 ,train acc: 0.962097 ,val loss : 0.111210 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :343 ]train loss : 0.896975 ,train acc: 0.348267 ,val loss : 0.109190 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :344 ]train loss : 0.064579 ,train acc: 0.995148 ,val loss : 0.108392 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :345 ]train loss : 0.481133 ,train acc: 0.639282 ,val loss : 0.111888 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :346 ]train loss : 0.272505 ,train acc: 0.887421 ,val loss : 0.110246 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :347 ]train loss : 0.090990 ,train acc: 0.985443 ,val loss : 0.109769 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :348 ]train loss : 0.107348 ,train acc: 0.983704 ,val loss : 0.112350 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :349 ]train loss : 0.102661 ,train acc: 0.995361 ,val loss : 0.109949 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :350 ]train loss : 0.095189 ,train acc: 0.984924 ,val loss : 0.114396 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :351 ]train loss : 0.081512 ,train acc: 0.997833 ,val loss : 0.112338 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :352 ]train loss : 0.115437 ,train acc: 0.983856 ,val loss : 0.111615 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :353 ]train loss : 0.072686 ,train acc: 0.992340 ,val loss : 0.111288 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :354 ]train loss : 0.089242 ,train acc: 0.988617 ,val loss : 0.110836 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :355 ]train loss : 0.073569 ,train acc: 0.998230 ,val loss : 0.110537 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :356 ]train loss : 0.096718 ,train acc: 0.996094 ,val loss : 0.112360 ,val acc : 0.991394\n",
      "[ ecpho : 3  iter :357 ]train loss : 0.123756 ,train acc: 0.984131 ,val loss : 0.112831 ,val acc : 0.991272\n",
      "[ ecpho : 3  iter :358 ]train loss : 0.088918 ,train acc: 0.994507 ,val loss : 0.111324 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :359 ]train loss : 0.161290 ,train acc: 0.944763 ,val loss : 0.112058 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :360 ]train loss : 0.093398 ,train acc: 0.995972 ,val loss : 0.110082 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :361 ]train loss : 0.089180 ,train acc: 0.982788 ,val loss : 0.112351 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :362 ]train loss : 0.059580 ,train acc: 0.997498 ,val loss : 0.113235 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :363 ]train loss : 0.165096 ,train acc: 0.940094 ,val loss : 0.113340 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :364 ]train loss : 0.094346 ,train acc: 0.995880 ,val loss : 0.113459 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :365 ]train loss : 0.387785 ,train acc: 0.773438 ,val loss : 0.110254 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :366 ]train loss : 0.070300 ,train acc: 0.995605 ,val loss : 0.109136 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :367 ]train loss : 0.324961 ,train acc: 0.793762 ,val loss : 0.111501 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :368 ]train loss : 0.108469 ,train acc: 0.977875 ,val loss : 0.109893 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :369 ]train loss : 0.096853 ,train acc: 0.978119 ,val loss : 0.111185 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :370 ]train loss : 0.225538 ,train acc: 0.878174 ,val loss : 0.109185 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :371 ]train loss : 0.175744 ,train acc: 0.919159 ,val loss : 0.109331 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :372 ]train loss : 0.451068 ,train acc: 0.726196 ,val loss : 0.110755 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :373 ]train loss : 0.075516 ,train acc: 0.992340 ,val loss : 0.109045 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :374 ]train loss : 0.075643 ,train acc: 0.998566 ,val loss : 0.110440 ,val acc : 0.991455\n",
      "[ ecpho : 3  iter :375 ]train loss : 0.077302 ,train acc: 0.989807 ,val loss : 0.112044 ,val acc : 0.991302\n",
      "[ ecpho : 3  iter :376 ]train loss : 0.090922 ,train acc: 0.996918 ,val loss : 0.111498 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :377 ]train loss : 0.128603 ,train acc: 0.963684 ,val loss : 0.110741 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :378 ]train loss : 0.246797 ,train acc: 0.885559 ,val loss : 0.110003 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :379 ]train loss : 0.093705 ,train acc: 0.979126 ,val loss : 0.114060 ,val acc : 0.991180\n",
      "[ ecpho : 3  iter :380 ]train loss : 0.078539 ,train acc: 0.986725 ,val loss : 0.111835 ,val acc : 0.991455\n",
      "[ ecpho : 3  iter :381 ]train loss : 0.269594 ,train acc: 0.860168 ,val loss : 0.109681 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :382 ]train loss : 0.151305 ,train acc: 0.944214 ,val loss : 0.112387 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :383 ]train loss : 0.114163 ,train acc: 0.986755 ,val loss : 0.113778 ,val acc : 0.991394\n",
      "[ ecpho : 3  iter :384 ]train loss : 0.085736 ,train acc: 0.985962 ,val loss : 0.111779 ,val acc : 0.990936\n",
      "[ ecpho : 3  iter :385 ]train loss : 0.087331 ,train acc: 0.992920 ,val loss : 0.114405 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :386 ]train loss : 0.099559 ,train acc: 0.978241 ,val loss : 0.113517 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :387 ]train loss : 0.120871 ,train acc: 0.989960 ,val loss : 0.108191 ,val acc : 0.991272\n",
      "[ ecpho : 3  iter :388 ]train loss : 0.066968 ,train acc: 0.998962 ,val loss : 0.110125 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :389 ]train loss : 0.088722 ,train acc: 0.989960 ,val loss : 0.110937 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :390 ]train loss : 0.341690 ,train acc: 0.823822 ,val loss : 0.112053 ,val acc : 0.991058\n",
      "[ ecpho : 3  iter :391 ]train loss : 0.476219 ,train acc: 0.667694 ,val loss : 0.110409 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :392 ]train loss : 0.075247 ,train acc: 0.992004 ,val loss : 0.114255 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :393 ]train loss : 0.091335 ,train acc: 0.985229 ,val loss : 0.110291 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :394 ]train loss : 0.073670 ,train acc: 0.994202 ,val loss : 0.115330 ,val acc : 0.990967\n",
      "[ ecpho : 3  iter :395 ]train loss : 0.102482 ,train acc: 0.979614 ,val loss : 0.111843 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :396 ]train loss : 0.685496 ,train acc: 0.558411 ,val loss : 0.110914 ,val acc : 0.991180\n",
      "[ ecpho : 3  iter :397 ]train loss : 0.073967 ,train acc: 0.997772 ,val loss : 0.109032 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :398 ]train loss : 0.153098 ,train acc: 0.953979 ,val loss : 0.112333 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :399 ]train loss : 0.079584 ,train acc: 0.989227 ,val loss : 0.111246 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :400 ]train loss : 0.075190 ,train acc: 0.997040 ,val loss : 0.113478 ,val acc : 0.991058\n",
      "[ ecpho : 3  iter :401 ]train loss : 0.147824 ,train acc: 0.944122 ,val loss : 0.111517 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :402 ]train loss : 0.196557 ,train acc: 0.901398 ,val loss : 0.109387 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :403 ]train loss : 0.070840 ,train acc: 0.997314 ,val loss : 0.112419 ,val acc : 0.991028\n",
      "[ ecpho : 3  iter :404 ]train loss : 0.073610 ,train acc: 0.997223 ,val loss : 0.114971 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :405 ]train loss : 0.070549 ,train acc: 0.997437 ,val loss : 0.110079 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :406 ]train loss : 0.090082 ,train acc: 0.982727 ,val loss : 0.112812 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :407 ]train loss : 0.067443 ,train acc: 0.998444 ,val loss : 0.113759 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :408 ]train loss : 0.598156 ,train acc: 0.602173 ,val loss : 0.111008 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :409 ]train loss : 0.266048 ,train acc: 0.832642 ,val loss : 0.113630 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :410 ]train loss : 0.152104 ,train acc: 0.941406 ,val loss : 0.112570 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :411 ]train loss : 0.086831 ,train acc: 0.992828 ,val loss : 0.111657 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :412 ]train loss : 0.247826 ,train acc: 0.888214 ,val loss : 0.112091 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :413 ]train loss : 0.107453 ,train acc: 0.968475 ,val loss : 0.113601 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :414 ]train loss : 0.083707 ,train acc: 0.989563 ,val loss : 0.113684 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :415 ]train loss : 0.072695 ,train acc: 0.997223 ,val loss : 0.114566 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :416 ]train loss : 0.279111 ,train acc: 0.827576 ,val loss : 0.113879 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :417 ]train loss : 0.089096 ,train acc: 0.996368 ,val loss : 0.113973 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :418 ]train loss : 0.543031 ,train acc: 0.610168 ,val loss : 0.112262 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :419 ]train loss : 0.061290 ,train acc: 0.998016 ,val loss : 0.114335 ,val acc : 0.990814\n",
      "[ ecpho : 3  iter :420 ]train loss : 0.092785 ,train acc: 0.979340 ,val loss : 0.113016 ,val acc : 0.990662\n",
      "[ ecpho : 3  iter :421 ]train loss : 0.085679 ,train acc: 0.993805 ,val loss : 0.113735 ,val acc : 0.990479\n",
      "[ ecpho : 3  iter :422 ]train loss : 0.218010 ,train acc: 0.874817 ,val loss : 0.116926 ,val acc : 0.990570\n",
      "[ ecpho : 3  iter :423 ]train loss : 0.112766 ,train acc: 0.982666 ,val loss : 0.115181 ,val acc : 0.990601\n",
      "[ ecpho : 3  iter :424 ]train loss : 0.107989 ,train acc: 0.976532 ,val loss : 0.115117 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :425 ]train loss : 0.110361 ,train acc: 0.967255 ,val loss : 0.114078 ,val acc : 0.990417\n",
      "[ ecpho : 3  iter :426 ]train loss : 0.071175 ,train acc: 0.992310 ,val loss : 0.116181 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :427 ]train loss : 0.115407 ,train acc: 0.968323 ,val loss : 0.115159 ,val acc : 0.990906\n",
      "[ ecpho : 3  iter :428 ]train loss : 0.149100 ,train acc: 0.941315 ,val loss : 0.112917 ,val acc : 0.990540\n",
      "[ ecpho : 3  iter :429 ]train loss : 0.089465 ,train acc: 0.990417 ,val loss : 0.112418 ,val acc : 0.990417\n",
      "[ ecpho : 3  iter :430 ]train loss : 0.106004 ,train acc: 0.981171 ,val loss : 0.115469 ,val acc : 0.990662\n",
      "[ ecpho : 3  iter :431 ]train loss : 0.105910 ,train acc: 0.983459 ,val loss : 0.116351 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :432 ]train loss : 0.076573 ,train acc: 0.990204 ,val loss : 0.115678 ,val acc : 0.990631\n",
      "[ ecpho : 3  iter :433 ]train loss : 0.083377 ,train acc: 0.989594 ,val loss : 0.111299 ,val acc : 0.990814\n",
      "[ ecpho : 3  iter :434 ]train loss : 0.421269 ,train acc: 0.767181 ,val loss : 0.115719 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :435 ]train loss : 0.077462 ,train acc: 0.993286 ,val loss : 0.114808 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :436 ]train loss : 0.076249 ,train acc: 0.994293 ,val loss : 0.111274 ,val acc : 0.990875\n",
      "[ ecpho : 3  iter :437 ]train loss : 0.079805 ,train acc: 0.989197 ,val loss : 0.116806 ,val acc : 0.990723\n",
      "[ ecpho : 3  iter :438 ]train loss : 0.116001 ,train acc: 0.973846 ,val loss : 0.111735 ,val acc : 0.991180\n",
      "[ ecpho : 3  iter :439 ]train loss : 0.167688 ,train acc: 0.934052 ,val loss : 0.116500 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :440 ]train loss : 0.977585 ,train acc: 0.335785 ,val loss : 0.113749 ,val acc : 0.991089\n",
      "[ ecpho : 3  iter :441 ]train loss : 0.091697 ,train acc: 0.985748 ,val loss : 0.114815 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :442 ]train loss : 0.066273 ,train acc: 0.994629 ,val loss : 0.113761 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :443 ]train loss : 0.066605 ,train acc: 0.996246 ,val loss : 0.112981 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :444 ]train loss : 0.069633 ,train acc: 0.997253 ,val loss : 0.111478 ,val acc : 0.990845\n",
      "[ ecpho : 3  iter :445 ]train loss : 0.066396 ,train acc: 0.996216 ,val loss : 0.112525 ,val acc : 0.991180\n",
      "[ ecpho : 3  iter :446 ]train loss : 0.076870 ,train acc: 0.989075 ,val loss : 0.111310 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :447 ]train loss : 0.147817 ,train acc: 0.973022 ,val loss : 0.114769 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :448 ]train loss : 0.604282 ,train acc: 0.661072 ,val loss : 0.112068 ,val acc : 0.991211\n",
      "[ ecpho : 3  iter :449 ]train loss : 0.058721 ,train acc: 0.998047 ,val loss : 0.114436 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :450 ]train loss : 0.088885 ,train acc: 0.987396 ,val loss : 0.113304 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :451 ]train loss : 0.089315 ,train acc: 0.997345 ,val loss : 0.111596 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :452 ]train loss : 0.094370 ,train acc: 0.995789 ,val loss : 0.112246 ,val acc : 0.991272\n",
      "[ ecpho : 3  iter :453 ]train loss : 0.128918 ,train acc: 0.980896 ,val loss : 0.115136 ,val acc : 0.991119\n",
      "[ ecpho : 3  iter :454 ]train loss : 0.298079 ,train acc: 0.864014 ,val loss : 0.113224 ,val acc : 0.991150\n",
      "[ ecpho : 3  iter :455 ]train loss : 0.072413 ,train acc: 0.997162 ,val loss : 0.111768 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :456 ]train loss : 0.193456 ,train acc: 0.948303 ,val loss : 0.112538 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :457 ]train loss : 0.178841 ,train acc: 0.930145 ,val loss : 0.111763 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :458 ]train loss : 0.161855 ,train acc: 0.976562 ,val loss : 0.113605 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :459 ]train loss : 0.092155 ,train acc: 0.992676 ,val loss : 0.112722 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :460 ]train loss : 0.088762 ,train acc: 0.994720 ,val loss : 0.110056 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :461 ]train loss : 0.747731 ,train acc: 0.419159 ,val loss : 0.111715 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :462 ]train loss : 0.174092 ,train acc: 0.920197 ,val loss : 0.113739 ,val acc : 0.991455\n",
      "[ ecpho : 3  iter :463 ]train loss : 0.065340 ,train acc: 0.997437 ,val loss : 0.112418 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :464 ]train loss : 0.186985 ,train acc: 0.948486 ,val loss : 0.112856 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :465 ]train loss : 0.078145 ,train acc: 0.991974 ,val loss : 0.109582 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :466 ]train loss : 0.136497 ,train acc: 0.987030 ,val loss : 0.113531 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :467 ]train loss : 0.066696 ,train acc: 0.998627 ,val loss : 0.112258 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :468 ]train loss : 1.121997 ,train acc: 0.234375 ,val loss : 0.112375 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :469 ]train loss : 0.113633 ,train acc: 0.983490 ,val loss : 0.113821 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :470 ]train loss : 0.101519 ,train acc: 0.979126 ,val loss : 0.108912 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :471 ]train loss : 0.082680 ,train acc: 0.985077 ,val loss : 0.110538 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :472 ]train loss : 0.079962 ,train acc: 0.991272 ,val loss : 0.109840 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :473 ]train loss : 0.075328 ,train acc: 0.994019 ,val loss : 0.110656 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :474 ]train loss : 0.117598 ,train acc: 0.985748 ,val loss : 0.110021 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :475 ]train loss : 0.206137 ,train acc: 0.899872 ,val loss : 0.112214 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :476 ]train loss : 0.185339 ,train acc: 0.917297 ,val loss : 0.108262 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :477 ]train loss : 0.171247 ,train acc: 0.926239 ,val loss : 0.109911 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :478 ]train loss : 0.064762 ,train acc: 0.998383 ,val loss : 0.112559 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :479 ]train loss : 0.206183 ,train acc: 0.897675 ,val loss : 0.111161 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :480 ]train loss : 0.081118 ,train acc: 0.987549 ,val loss : 0.112524 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :481 ]train loss : 0.475908 ,train acc: 0.663666 ,val loss : 0.108926 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :482 ]train loss : 0.111218 ,train acc: 0.974945 ,val loss : 0.108141 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :483 ]train loss : 0.164386 ,train acc: 0.939667 ,val loss : 0.111848 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :484 ]train loss : 0.139664 ,train acc: 0.946228 ,val loss : 0.111710 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :485 ]train loss : 1.103749 ,train acc: 0.248871 ,val loss : 0.112006 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :486 ]train loss : 0.272987 ,train acc: 0.828705 ,val loss : 0.109816 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :487 ]train loss : 0.091251 ,train acc: 0.987305 ,val loss : 0.110875 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :488 ]train loss : 0.091226 ,train acc: 0.993774 ,val loss : 0.111356 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :489 ]train loss : 0.108503 ,train acc: 0.981201 ,val loss : 0.110007 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :490 ]train loss : 0.072664 ,train acc: 0.993347 ,val loss : 0.113500 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :491 ]train loss : 0.078421 ,train acc: 0.993622 ,val loss : 0.111362 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :492 ]train loss : 0.055714 ,train acc: 0.999603 ,val loss : 0.112441 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :493 ]train loss : 0.076431 ,train acc: 0.990784 ,val loss : 0.112156 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :494 ]train loss : 0.114211 ,train acc: 0.990509 ,val loss : 0.111586 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :495 ]train loss : 0.242248 ,train acc: 0.884033 ,val loss : 0.109504 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :496 ]train loss : 0.267648 ,train acc: 0.841675 ,val loss : 0.114703 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :497 ]train loss : 0.083488 ,train acc: 0.983276 ,val loss : 0.111232 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :498 ]train loss : 0.097929 ,train acc: 0.994232 ,val loss : 0.110360 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :499 ]train loss : 0.309228 ,train acc: 0.850555 ,val loss : 0.112981 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :500 ]train loss : 0.083325 ,train acc: 0.989319 ,val loss : 0.114227 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :501 ]train loss : 0.119611 ,train acc: 0.986053 ,val loss : 0.110830 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :502 ]train loss : 0.079764 ,train acc: 0.997284 ,val loss : 0.109990 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :503 ]train loss : 0.100422 ,train acc: 0.983124 ,val loss : 0.111398 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :504 ]train loss : 0.259859 ,train acc: 0.856415 ,val loss : 0.111487 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :505 ]train loss : 0.237601 ,train acc: 0.866425 ,val loss : 0.108265 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :506 ]train loss : 0.095886 ,train acc: 0.980957 ,val loss : 0.109919 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :507 ]train loss : 0.085135 ,train acc: 0.995483 ,val loss : 0.111010 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :508 ]train loss : 0.144894 ,train acc: 0.958527 ,val loss : 0.111569 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :509 ]train loss : 0.075910 ,train acc: 0.995392 ,val loss : 0.112516 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :510 ]train loss : 0.067511 ,train acc: 0.998596 ,val loss : 0.111032 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :511 ]train loss : 0.120027 ,train acc: 0.962189 ,val loss : 0.108014 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :512 ]train loss : 0.077511 ,train acc: 0.990875 ,val loss : 0.111543 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :513 ]train loss : 0.190367 ,train acc: 0.902527 ,val loss : 0.111947 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :514 ]train loss : 0.092312 ,train acc: 0.983246 ,val loss : 0.112297 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :515 ]train loss : 1.271390 ,train acc: 0.155273 ,val loss : 0.110679 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :516 ]train loss : 0.060428 ,train acc: 0.996582 ,val loss : 0.110339 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :517 ]train loss : 0.231162 ,train acc: 0.876282 ,val loss : 0.111528 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :518 ]train loss : 0.104678 ,train acc: 0.990479 ,val loss : 0.111883 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :519 ]train loss : 0.074876 ,train acc: 0.989899 ,val loss : 0.112118 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :520 ]train loss : 0.149083 ,train acc: 0.953400 ,val loss : 0.108756 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :521 ]train loss : 0.097899 ,train acc: 0.993530 ,val loss : 0.112015 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :522 ]train loss : 0.120177 ,train acc: 0.978729 ,val loss : 0.110302 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :523 ]train loss : 0.244845 ,train acc: 0.890198 ,val loss : 0.109353 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :524 ]train loss : 0.083956 ,train acc: 0.984650 ,val loss : 0.107385 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :525 ]train loss : 0.405199 ,train acc: 0.712006 ,val loss : 0.111787 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :526 ]train loss : 0.133416 ,train acc: 0.977081 ,val loss : 0.111254 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :527 ]train loss : 0.081008 ,train acc: 0.988525 ,val loss : 0.112002 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :528 ]train loss : 0.136847 ,train acc: 0.958038 ,val loss : 0.110729 ,val acc : 0.991608\n",
      "[ ecpho : 3  iter :529 ]train loss : 0.169294 ,train acc: 0.956879 ,val loss : 0.108214 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :530 ]train loss : 0.064966 ,train acc: 0.996307 ,val loss : 0.108487 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :531 ]train loss : 0.180706 ,train acc: 0.927246 ,val loss : 0.111314 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :532 ]train loss : 0.095803 ,train acc: 0.975311 ,val loss : 0.109592 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :533 ]train loss : 0.078061 ,train acc: 0.988342 ,val loss : 0.109364 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :534 ]train loss : 0.060067 ,train acc: 0.995728 ,val loss : 0.110629 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :535 ]train loss : 0.591038 ,train acc: 0.615204 ,val loss : 0.113056 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :536 ]train loss : 0.088033 ,train acc: 0.996918 ,val loss : 0.109491 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :537 ]train loss : 0.071949 ,train acc: 0.997925 ,val loss : 0.110746 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :538 ]train loss : 0.081931 ,train acc: 0.993774 ,val loss : 0.112867 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :539 ]train loss : 0.092822 ,train acc: 0.990753 ,val loss : 0.113008 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :540 ]train loss : 0.068232 ,train acc: 0.997375 ,val loss : 0.111044 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :541 ]train loss : 0.097819 ,train acc: 0.994629 ,val loss : 0.110945 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :542 ]train loss : 0.082502 ,train acc: 0.991791 ,val loss : 0.108359 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :543 ]train loss : 0.098179 ,train acc: 0.985199 ,val loss : 0.110878 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :544 ]train loss : 0.087093 ,train acc: 0.998322 ,val loss : 0.111107 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :545 ]train loss : 0.108255 ,train acc: 0.983978 ,val loss : 0.110501 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :546 ]train loss : 0.073609 ,train acc: 0.997070 ,val loss : 0.110335 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :547 ]train loss : 0.082616 ,train acc: 0.995911 ,val loss : 0.109570 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :548 ]train loss : 0.101745 ,train acc: 0.993042 ,val loss : 0.111532 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :549 ]train loss : 0.078916 ,train acc: 0.993835 ,val loss : 0.109550 ,val acc : 0.991699\n",
      "[ ecpho : 3  iter :550 ]train loss : 0.085866 ,train acc: 0.990234 ,val loss : 0.109384 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :551 ]train loss : 0.094851 ,train acc: 0.991577 ,val loss : 0.110331 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :552 ]train loss : 0.093659 ,train acc: 0.979706 ,val loss : 0.109412 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :553 ]train loss : 0.098200 ,train acc: 0.993591 ,val loss : 0.105615 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :554 ]train loss : 0.115759 ,train acc: 0.968658 ,val loss : 0.110404 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :555 ]train loss : 0.091848 ,train acc: 0.987732 ,val loss : 0.108319 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :556 ]train loss : 0.283990 ,train acc: 0.839355 ,val loss : 0.108259 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :557 ]train loss : 0.124483 ,train acc: 0.964447 ,val loss : 0.111109 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :558 ]train loss : 0.196728 ,train acc: 0.902679 ,val loss : 0.108632 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :559 ]train loss : 0.069326 ,train acc: 0.995087 ,val loss : 0.110077 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :560 ]train loss : 0.066510 ,train acc: 0.997711 ,val loss : 0.109307 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :561 ]train loss : 0.075180 ,train acc: 0.999054 ,val loss : 0.108065 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :562 ]train loss : 0.108761 ,train acc: 0.991028 ,val loss : 0.107751 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :563 ]train loss : 0.075789 ,train acc: 0.994690 ,val loss : 0.108420 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :564 ]train loss : 0.054751 ,train acc: 0.999542 ,val loss : 0.109681 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :565 ]train loss : 0.065728 ,train acc: 0.994568 ,val loss : 0.107738 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :566 ]train loss : 0.177192 ,train acc: 0.917847 ,val loss : 0.110009 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :567 ]train loss : 0.079785 ,train acc: 0.987213 ,val loss : 0.108217 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :568 ]train loss : 0.100213 ,train acc: 0.983429 ,val loss : 0.109841 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :569 ]train loss : 0.086445 ,train acc: 0.993439 ,val loss : 0.112403 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :570 ]train loss : 0.088161 ,train acc: 0.997925 ,val loss : 0.112474 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :571 ]train loss : 0.107162 ,train acc: 0.968414 ,val loss : 0.109890 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :572 ]train loss : 0.141501 ,train acc: 0.979370 ,val loss : 0.109218 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :573 ]train loss : 0.385406 ,train acc: 0.724304 ,val loss : 0.110005 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :574 ]train loss : 0.131317 ,train acc: 0.962219 ,val loss : 0.109769 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :575 ]train loss : 0.105351 ,train acc: 0.993134 ,val loss : 0.111122 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :576 ]train loss : 0.933275 ,train acc: 0.345093 ,val loss : 0.110488 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :577 ]train loss : 0.118604 ,train acc: 0.985748 ,val loss : 0.110132 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :578 ]train loss : 0.124451 ,train acc: 0.968567 ,val loss : 0.109140 ,val acc : 0.992828\n",
      "[ ecpho : 3  iter :579 ]train loss : 0.188875 ,train acc: 0.942932 ,val loss : 0.107934 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :580 ]train loss : 0.103339 ,train acc: 0.995911 ,val loss : 0.108472 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :581 ]train loss : 0.076490 ,train acc: 0.997528 ,val loss : 0.107765 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :582 ]train loss : 0.081798 ,train acc: 0.992401 ,val loss : 0.108315 ,val acc : 0.992767\n",
      "[ ecpho : 3  iter :583 ]train loss : 0.704509 ,train acc: 0.504364 ,val loss : 0.108470 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :584 ]train loss : 0.082817 ,train acc: 0.998718 ,val loss : 0.108972 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :585 ]train loss : 0.085661 ,train acc: 0.998291 ,val loss : 0.110079 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :586 ]train loss : 0.086546 ,train acc: 0.997467 ,val loss : 0.108039 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :587 ]train loss : 0.111797 ,train acc: 0.972321 ,val loss : 0.111055 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :588 ]train loss : 0.088465 ,train acc: 0.998199 ,val loss : 0.108841 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :589 ]train loss : 0.087880 ,train acc: 0.990265 ,val loss : 0.109782 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :590 ]train loss : 0.078268 ,train acc: 0.992249 ,val loss : 0.109506 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :591 ]train loss : 0.191132 ,train acc: 0.946777 ,val loss : 0.107704 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :592 ]train loss : 0.102887 ,train acc: 0.981354 ,val loss : 0.109093 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :593 ]train loss : 0.083657 ,train acc: 0.994171 ,val loss : 0.109720 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :594 ]train loss : 0.082982 ,train acc: 0.994202 ,val loss : 0.109194 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :595 ]train loss : 0.092570 ,train acc: 0.992249 ,val loss : 0.106442 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :596 ]train loss : 0.074935 ,train acc: 0.997467 ,val loss : 0.108608 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :597 ]train loss : 0.073962 ,train acc: 0.992523 ,val loss : 0.108255 ,val acc : 0.992828\n",
      "[ ecpho : 3  iter :598 ]train loss : 0.083321 ,train acc: 0.986084 ,val loss : 0.108768 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :599 ]train loss : 0.106982 ,train acc: 0.972992 ,val loss : 0.107640 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :600 ]train loss : 0.109315 ,train acc: 0.980408 ,val loss : 0.109073 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :601 ]train loss : 0.104777 ,train acc: 0.986786 ,val loss : 0.108151 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :602 ]train loss : 0.396368 ,train acc: 0.747833 ,val loss : 0.106784 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :603 ]train loss : 0.086751 ,train acc: 0.985962 ,val loss : 0.105462 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :604 ]train loss : 0.061784 ,train acc: 0.998108 ,val loss : 0.107992 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :605 ]train loss : 0.086181 ,train acc: 0.993134 ,val loss : 0.109645 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :606 ]train loss : 0.104609 ,train acc: 0.969879 ,val loss : 0.108171 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :607 ]train loss : 0.065144 ,train acc: 0.998840 ,val loss : 0.106683 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :608 ]train loss : 0.089324 ,train acc: 0.987671 ,val loss : 0.107986 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :609 ]train loss : 0.286769 ,train acc: 0.848969 ,val loss : 0.108773 ,val acc : 0.992828\n",
      "[ ecpho : 3  iter :610 ]train loss : 0.120355 ,train acc: 0.964081 ,val loss : 0.108180 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :611 ]train loss : 0.098812 ,train acc: 0.993866 ,val loss : 0.107284 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :612 ]train loss : 0.076681 ,train acc: 0.997742 ,val loss : 0.106318 ,val acc : 0.992767\n",
      "[ ecpho : 3  iter :613 ]train loss : 0.138283 ,train acc: 0.954590 ,val loss : 0.106590 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :614 ]train loss : 0.083942 ,train acc: 0.994598 ,val loss : 0.109927 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :615 ]train loss : 0.070202 ,train acc: 0.997955 ,val loss : 0.105802 ,val acc : 0.992920\n",
      "[ ecpho : 3  iter :616 ]train loss : 0.086647 ,train acc: 0.997131 ,val loss : 0.107619 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :617 ]train loss : 0.065730 ,train acc: 0.997223 ,val loss : 0.110413 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :618 ]train loss : 0.091339 ,train acc: 0.998352 ,val loss : 0.106426 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :619 ]train loss : 0.077281 ,train acc: 0.994171 ,val loss : 0.109032 ,val acc : 0.992798\n",
      "[ ecpho : 3  iter :620 ]train loss : 0.116363 ,train acc: 0.982391 ,val loss : 0.107254 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :621 ]train loss : 0.093705 ,train acc: 0.996857 ,val loss : 0.108430 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :622 ]train loss : 0.091496 ,train acc: 0.988922 ,val loss : 0.110082 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :623 ]train loss : 0.081784 ,train acc: 0.990875 ,val loss : 0.106566 ,val acc : 0.992828\n",
      "[ ecpho : 3  iter :624 ]train loss : 0.074376 ,train acc: 0.999023 ,val loss : 0.107899 ,val acc : 0.992950\n",
      "[ ecpho : 3  iter :625 ]train loss : 0.084209 ,train acc: 0.991302 ,val loss : 0.107147 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :626 ]train loss : 0.101026 ,train acc: 0.997864 ,val loss : 0.107420 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :627 ]train loss : 0.085955 ,train acc: 0.997223 ,val loss : 0.106724 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :628 ]train loss : 0.077865 ,train acc: 0.990234 ,val loss : 0.105559 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :629 ]train loss : 0.244078 ,train acc: 0.869049 ,val loss : 0.106882 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :630 ]train loss : 0.503315 ,train acc: 0.614563 ,val loss : 0.107804 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :631 ]train loss : 0.395055 ,train acc: 0.723389 ,val loss : 0.105663 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :632 ]train loss : 0.060491 ,train acc: 0.998779 ,val loss : 0.107288 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :633 ]train loss : 0.106776 ,train acc: 0.976135 ,val loss : 0.105475 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :634 ]train loss : 0.085784 ,train acc: 0.993805 ,val loss : 0.108149 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :635 ]train loss : 0.421168 ,train acc: 0.749908 ,val loss : 0.110824 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :636 ]train loss : 0.142565 ,train acc: 0.968842 ,val loss : 0.106512 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :637 ]train loss : 0.224813 ,train acc: 0.912109 ,val loss : 0.108168 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :638 ]train loss : 0.106836 ,train acc: 0.980255 ,val loss : 0.105997 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :639 ]train loss : 0.243490 ,train acc: 0.894836 ,val loss : 0.108161 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :640 ]train loss : 0.103359 ,train acc: 0.993927 ,val loss : 0.108995 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :641 ]train loss : 0.128700 ,train acc: 0.982391 ,val loss : 0.107238 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :642 ]train loss : 0.084508 ,train acc: 0.988525 ,val loss : 0.108056 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :643 ]train loss : 0.250258 ,train acc: 0.910858 ,val loss : 0.109331 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :644 ]train loss : 0.087568 ,train acc: 0.989624 ,val loss : 0.107279 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :645 ]train loss : 0.289825 ,train acc: 0.867889 ,val loss : 0.109270 ,val acc : 0.991882\n",
      "[ ecpho : 3  iter :646 ]train loss : 0.105203 ,train acc: 0.970276 ,val loss : 0.111088 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :647 ]train loss : 0.093020 ,train acc: 0.996307 ,val loss : 0.107955 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :648 ]train loss : 0.251366 ,train acc: 0.859894 ,val loss : 0.109457 ,val acc : 0.991882\n",
      "[ ecpho : 3  iter :649 ]train loss : 0.079242 ,train acc: 0.994324 ,val loss : 0.106916 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :650 ]train loss : 0.376223 ,train acc: 0.795410 ,val loss : 0.109106 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :651 ]train loss : 0.104853 ,train acc: 0.992188 ,val loss : 0.108157 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :652 ]train loss : 0.110858 ,train acc: 0.989532 ,val loss : 0.107614 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :653 ]train loss : 0.073841 ,train acc: 0.998260 ,val loss : 0.108818 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :654 ]train loss : 0.068224 ,train acc: 0.997650 ,val loss : 0.105815 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :655 ]train loss : 0.069839 ,train acc: 0.998718 ,val loss : 0.108129 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :656 ]train loss : 0.124196 ,train acc: 0.959137 ,val loss : 0.109618 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :657 ]train loss : 0.092929 ,train acc: 0.982941 ,val loss : 0.106667 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :658 ]train loss : 0.102694 ,train acc: 0.977386 ,val loss : 0.107719 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :659 ]train loss : 0.096153 ,train acc: 0.997467 ,val loss : 0.107599 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :660 ]train loss : 0.394219 ,train acc: 0.731720 ,val loss : 0.109875 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :661 ]train loss : 0.094735 ,train acc: 0.981812 ,val loss : 0.106497 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :662 ]train loss : 0.140944 ,train acc: 0.972656 ,val loss : 0.106452 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :663 ]train loss : 0.138357 ,train acc: 0.983185 ,val loss : 0.109277 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :664 ]train loss : 0.114522 ,train acc: 0.984222 ,val loss : 0.107799 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :665 ]train loss : 0.057810 ,train acc: 0.998077 ,val loss : 0.106123 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :666 ]train loss : 0.158086 ,train acc: 0.965637 ,val loss : 0.107762 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :667 ]train loss : 0.744293 ,train acc: 0.477142 ,val loss : 0.107345 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :668 ]train loss : 0.091946 ,train acc: 0.983704 ,val loss : 0.108034 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :669 ]train loss : 0.407239 ,train acc: 0.733521 ,val loss : 0.108757 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :670 ]train loss : 0.077814 ,train acc: 0.992340 ,val loss : 0.107776 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :671 ]train loss : 0.165756 ,train acc: 0.928802 ,val loss : 0.108352 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :672 ]train loss : 0.413695 ,train acc: 0.716125 ,val loss : 0.108263 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :673 ]train loss : 0.303410 ,train acc: 0.827576 ,val loss : 0.109302 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :674 ]train loss : 0.072312 ,train acc: 0.993347 ,val loss : 0.110429 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :675 ]train loss : 0.859743 ,train acc: 0.399719 ,val loss : 0.109859 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :676 ]train loss : 0.164253 ,train acc: 0.934479 ,val loss : 0.107802 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :677 ]train loss : 0.078523 ,train acc: 0.995514 ,val loss : 0.110651 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :678 ]train loss : 0.086193 ,train acc: 0.993622 ,val loss : 0.107090 ,val acc : 0.991425\n",
      "[ ecpho : 3  iter :679 ]train loss : 0.108196 ,train acc: 0.975372 ,val loss : 0.111586 ,val acc : 0.991669\n",
      "[ ecpho : 3  iter :680 ]train loss : 0.087582 ,train acc: 0.994049 ,val loss : 0.109024 ,val acc : 0.991455\n",
      "[ ecpho : 3  iter :681 ]train loss : 0.071333 ,train acc: 0.995972 ,val loss : 0.108031 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :682 ]train loss : 1.167246 ,train acc: 0.197083 ,val loss : 0.111304 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :683 ]train loss : 0.138781 ,train acc: 0.957245 ,val loss : 0.110936 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :684 ]train loss : 0.070181 ,train acc: 0.996704 ,val loss : 0.112795 ,val acc : 0.991272\n",
      "[ ecpho : 3  iter :685 ]train loss : 0.071448 ,train acc: 0.997284 ,val loss : 0.109840 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :686 ]train loss : 0.103455 ,train acc: 0.993256 ,val loss : 0.111525 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :687 ]train loss : 0.086330 ,train acc: 0.986145 ,val loss : 0.111163 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :688 ]train loss : 0.433235 ,train acc: 0.732086 ,val loss : 0.110181 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :689 ]train loss : 0.075361 ,train acc: 0.993713 ,val loss : 0.112017 ,val acc : 0.991272\n",
      "[ ecpho : 3  iter :690 ]train loss : 0.102287 ,train acc: 0.982697 ,val loss : 0.108555 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :691 ]train loss : 0.104849 ,train acc: 0.986176 ,val loss : 0.109713 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :692 ]train loss : 0.086681 ,train acc: 0.984161 ,val loss : 0.110905 ,val acc : 0.991333\n",
      "[ ecpho : 3  iter :693 ]train loss : 0.073562 ,train acc: 0.993652 ,val loss : 0.108225 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :694 ]train loss : 0.112042 ,train acc: 0.972839 ,val loss : 0.108955 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :695 ]train loss : 0.111246 ,train acc: 0.984924 ,val loss : 0.110781 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :696 ]train loss : 0.488824 ,train acc: 0.659637 ,val loss : 0.109718 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :697 ]train loss : 0.058718 ,train acc: 0.997528 ,val loss : 0.110424 ,val acc : 0.991577\n",
      "[ ecpho : 3  iter :698 ]train loss : 1.422770 ,train acc: 0.020660 ,val loss : 0.110419 ,val acc : 0.991150\n",
      "[ ecpho : 3  iter :699 ]train loss : 0.142283 ,train acc: 0.967316 ,val loss : 0.111838 ,val acc : 0.991241\n",
      "[ ecpho : 3  iter :700 ]train loss : 0.106495 ,train acc: 0.974274 ,val loss : 0.110644 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :701 ]train loss : 0.086833 ,train acc: 0.991974 ,val loss : 0.111941 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :702 ]train loss : 0.127778 ,train acc: 0.977417 ,val loss : 0.110904 ,val acc : 0.990997\n",
      "[ ecpho : 3  iter :703 ]train loss : 0.162120 ,train acc: 0.957458 ,val loss : 0.109702 ,val acc : 0.990967\n",
      "[ ecpho : 3  iter :704 ]train loss : 0.135889 ,train acc: 0.981781 ,val loss : 0.106966 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :705 ]train loss : 0.090341 ,train acc: 0.981140 ,val loss : 0.108653 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :706 ]train loss : 0.065418 ,train acc: 0.996887 ,val loss : 0.109206 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :707 ]train loss : 0.115356 ,train acc: 0.977753 ,val loss : 0.110983 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :708 ]train loss : 0.097306 ,train acc: 0.973419 ,val loss : 0.111120 ,val acc : 0.991486\n",
      "[ ecpho : 3  iter :709 ]train loss : 0.096858 ,train acc: 0.993622 ,val loss : 0.111106 ,val acc : 0.991547\n",
      "[ ecpho : 3  iter :710 ]train loss : 0.082752 ,train acc: 0.995148 ,val loss : 0.107856 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :711 ]train loss : 0.163952 ,train acc: 0.925140 ,val loss : 0.109656 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :712 ]train loss : 0.559020 ,train acc: 0.725647 ,val loss : 0.110679 ,val acc : 0.991821\n",
      "[ ecpho : 3  iter :713 ]train loss : 0.117979 ,train acc: 0.969147 ,val loss : 0.108747 ,val acc : 0.991913\n",
      "[ ecpho : 3  iter :714 ]train loss : 0.099762 ,train acc: 0.975159 ,val loss : 0.109476 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :715 ]train loss : 0.109534 ,train acc: 0.987305 ,val loss : 0.110685 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :716 ]train loss : 0.088643 ,train acc: 0.987305 ,val loss : 0.107686 ,val acc : 0.991364\n",
      "[ ecpho : 3  iter :717 ]train loss : 0.091380 ,train acc: 0.989563 ,val loss : 0.109765 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :718 ]train loss : 0.094865 ,train acc: 0.991486 ,val loss : 0.110883 ,val acc : 0.991516\n",
      "[ ecpho : 3  iter :719 ]train loss : 0.097127 ,train acc: 0.991699 ,val loss : 0.110102 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :720 ]train loss : 0.073794 ,train acc: 0.994781 ,val loss : 0.110135 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :721 ]train loss : 0.110195 ,train acc: 0.988342 ,val loss : 0.111419 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :722 ]train loss : 0.089277 ,train acc: 0.981537 ,val loss : 0.110854 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :723 ]train loss : 0.069868 ,train acc: 0.996399 ,val loss : 0.110521 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :724 ]train loss : 0.078685 ,train acc: 0.998840 ,val loss : 0.110612 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :725 ]train loss : 0.119427 ,train acc: 0.985291 ,val loss : 0.108793 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :726 ]train loss : 0.080803 ,train acc: 0.989960 ,val loss : 0.111637 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :727 ]train loss : 0.085054 ,train acc: 0.982971 ,val loss : 0.109337 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :728 ]train loss : 0.399908 ,train acc: 0.741913 ,val loss : 0.110612 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :729 ]train loss : 0.088479 ,train acc: 0.998627 ,val loss : 0.112603 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :730 ]train loss : 0.096607 ,train acc: 0.981873 ,val loss : 0.108987 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :731 ]train loss : 0.115561 ,train acc: 0.987366 ,val loss : 0.108009 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :732 ]train loss : 0.094238 ,train acc: 0.997681 ,val loss : 0.109288 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :733 ]train loss : 0.086795 ,train acc: 0.994537 ,val loss : 0.110008 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :734 ]train loss : 0.090975 ,train acc: 0.985840 ,val loss : 0.106910 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :735 ]train loss : 0.105149 ,train acc: 0.970581 ,val loss : 0.107940 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :736 ]train loss : 0.093124 ,train acc: 0.987488 ,val loss : 0.107274 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :737 ]train loss : 0.106333 ,train acc: 0.970673 ,val loss : 0.106689 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :738 ]train loss : 0.079054 ,train acc: 0.993652 ,val loss : 0.107131 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :739 ]train loss : 0.094672 ,train acc: 0.986053 ,val loss : 0.108902 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :740 ]train loss : 0.068437 ,train acc: 0.994659 ,val loss : 0.108921 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :741 ]train loss : 0.078776 ,train acc: 0.996918 ,val loss : 0.107250 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :742 ]train loss : 0.061939 ,train acc: 0.997711 ,val loss : 0.109938 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :743 ]train loss : 0.180245 ,train acc: 0.920288 ,val loss : 0.107353 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :744 ]train loss : 0.082283 ,train acc: 0.996887 ,val loss : 0.108623 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :745 ]train loss : 0.192934 ,train acc: 0.947693 ,val loss : 0.107729 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :746 ]train loss : 0.108657 ,train acc: 0.967651 ,val loss : 0.106828 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :747 ]train loss : 0.166842 ,train acc: 0.924561 ,val loss : 0.106096 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :748 ]train loss : 0.640512 ,train acc: 0.604706 ,val loss : 0.108477 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :749 ]train loss : 0.101080 ,train acc: 0.984406 ,val loss : 0.106490 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :750 ]train loss : 0.071506 ,train acc: 0.995972 ,val loss : 0.108205 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :751 ]train loss : 0.097048 ,train acc: 0.977173 ,val loss : 0.109252 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :752 ]train loss : 0.098195 ,train acc: 0.995148 ,val loss : 0.108457 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :753 ]train loss : 0.184235 ,train acc: 0.905823 ,val loss : 0.106491 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :754 ]train loss : 0.088458 ,train acc: 0.998077 ,val loss : 0.105678 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :755 ]train loss : 0.084827 ,train acc: 0.992188 ,val loss : 0.105501 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :756 ]train loss : 0.081863 ,train acc: 0.997284 ,val loss : 0.105327 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :757 ]train loss : 0.092397 ,train acc: 0.982269 ,val loss : 0.106914 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :758 ]train loss : 0.070102 ,train acc: 0.995300 ,val loss : 0.107673 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :759 ]train loss : 0.131440 ,train acc: 0.970490 ,val loss : 0.107448 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :760 ]train loss : 0.077140 ,train acc: 0.991791 ,val loss : 0.108478 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :761 ]train loss : 0.106375 ,train acc: 0.977386 ,val loss : 0.107140 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :762 ]train loss : 0.201310 ,train acc: 0.926575 ,val loss : 0.109120 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :763 ]train loss : 0.078913 ,train acc: 0.993408 ,val loss : 0.106400 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :764 ]train loss : 0.112503 ,train acc: 0.980652 ,val loss : 0.107578 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :765 ]train loss : 0.115482 ,train acc: 0.974701 ,val loss : 0.107173 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :766 ]train loss : 0.133781 ,train acc: 0.976166 ,val loss : 0.107601 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :767 ]train loss : 0.141729 ,train acc: 0.964355 ,val loss : 0.106351 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :768 ]train loss : 0.279241 ,train acc: 0.919861 ,val loss : 0.106208 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :769 ]train loss : 0.094133 ,train acc: 0.983582 ,val loss : 0.108172 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :770 ]train loss : 0.061522 ,train acc: 0.998077 ,val loss : 0.106853 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :771 ]train loss : 0.131542 ,train acc: 0.967255 ,val loss : 0.107103 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :772 ]train loss : 0.067331 ,train acc: 0.997498 ,val loss : 0.110403 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :773 ]train loss : 0.057901 ,train acc: 0.998627 ,val loss : 0.107542 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :774 ]train loss : 0.078974 ,train acc: 0.990051 ,val loss : 0.109860 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :775 ]train loss : 0.061457 ,train acc: 0.996613 ,val loss : 0.107597 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :776 ]train loss : 0.082852 ,train acc: 0.988953 ,val loss : 0.109951 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :777 ]train loss : 0.079920 ,train acc: 0.994324 ,val loss : 0.106249 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :778 ]train loss : 0.074172 ,train acc: 0.994293 ,val loss : 0.107529 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :779 ]train loss : 0.078471 ,train acc: 0.998688 ,val loss : 0.108238 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :780 ]train loss : 0.076877 ,train acc: 0.993317 ,val loss : 0.106331 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :781 ]train loss : 0.095469 ,train acc: 0.990540 ,val loss : 0.105985 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :782 ]train loss : 0.130645 ,train acc: 0.957123 ,val loss : 0.106019 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :783 ]train loss : 0.090328 ,train acc: 0.996735 ,val loss : 0.108537 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :784 ]train loss : 0.098218 ,train acc: 0.993286 ,val loss : 0.102989 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :785 ]train loss : 0.227553 ,train acc: 0.925903 ,val loss : 0.105374 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :786 ]train loss : 0.498199 ,train acc: 0.637360 ,val loss : 0.104206 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :787 ]train loss : 0.064032 ,train acc: 0.999390 ,val loss : 0.103221 ,val acc : 0.993011\n",
      "[ ecpho : 3  iter :788 ]train loss : 0.082801 ,train acc: 0.992523 ,val loss : 0.105023 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :789 ]train loss : 0.075152 ,train acc: 0.995148 ,val loss : 0.104624 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :790 ]train loss : 0.077112 ,train acc: 0.994904 ,val loss : 0.106453 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :791 ]train loss : 0.108592 ,train acc: 0.971527 ,val loss : 0.106009 ,val acc : 0.992767\n",
      "[ ecpho : 3  iter :792 ]train loss : 0.072820 ,train acc: 0.998230 ,val loss : 0.105470 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :793 ]train loss : 0.109999 ,train acc: 0.992249 ,val loss : 0.105159 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :794 ]train loss : 0.099313 ,train acc: 0.989075 ,val loss : 0.106610 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :795 ]train loss : 0.150961 ,train acc: 0.940094 ,val loss : 0.108098 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :796 ]train loss : 0.220296 ,train acc: 0.876160 ,val loss : 0.105467 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :797 ]train loss : 0.106045 ,train acc: 0.993713 ,val loss : 0.103837 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :798 ]train loss : 0.063101 ,train acc: 0.998322 ,val loss : 0.106598 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :799 ]train loss : 0.062681 ,train acc: 0.997925 ,val loss : 0.106237 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :800 ]train loss : 0.063312 ,train acc: 0.999298 ,val loss : 0.106641 ,val acc : 0.992889\n",
      "[ ecpho : 3  iter :801 ]train loss : 0.234369 ,train acc: 0.913788 ,val loss : 0.106450 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :802 ]train loss : 0.468886 ,train acc: 0.692474 ,val loss : 0.107568 ,val acc : 0.992950\n",
      "[ ecpho : 3  iter :803 ]train loss : 0.298451 ,train acc: 0.849365 ,val loss : 0.105536 ,val acc : 0.992889\n",
      "[ ecpho : 3  iter :804 ]train loss : 0.090152 ,train acc: 0.993286 ,val loss : 0.107554 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :805 ]train loss : 0.118528 ,train acc: 0.976105 ,val loss : 0.104660 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :806 ]train loss : 0.156891 ,train acc: 0.962433 ,val loss : 0.105146 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :807 ]train loss : 0.060758 ,train acc: 0.998016 ,val loss : 0.108886 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :808 ]train loss : 0.084860 ,train acc: 0.997162 ,val loss : 0.103538 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :809 ]train loss : 0.290178 ,train acc: 0.800995 ,val loss : 0.104686 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :810 ]train loss : 0.110867 ,train acc: 0.988464 ,val loss : 0.105213 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :811 ]train loss : 0.068920 ,train acc: 0.998077 ,val loss : 0.107195 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :812 ]train loss : 0.081334 ,train acc: 0.993591 ,val loss : 0.104631 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :813 ]train loss : 0.528713 ,train acc: 0.609375 ,val loss : 0.103799 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :814 ]train loss : 0.085216 ,train acc: 0.994049 ,val loss : 0.106748 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :815 ]train loss : 0.097697 ,train acc: 0.992554 ,val loss : 0.103207 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :816 ]train loss : 0.109313 ,train acc: 0.987488 ,val loss : 0.107610 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :817 ]train loss : 0.065037 ,train acc: 0.997803 ,val loss : 0.106765 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :818 ]train loss : 0.124060 ,train acc: 0.965088 ,val loss : 0.106684 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :819 ]train loss : 0.080501 ,train acc: 0.986664 ,val loss : 0.105545 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :820 ]train loss : 0.057693 ,train acc: 0.998718 ,val loss : 0.108087 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :821 ]train loss : 0.075318 ,train acc: 0.990265 ,val loss : 0.108846 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :822 ]train loss : 0.076627 ,train acc: 0.995270 ,val loss : 0.105269 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :823 ]train loss : 0.075990 ,train acc: 0.994446 ,val loss : 0.106524 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :824 ]train loss : 0.122567 ,train acc: 0.973358 ,val loss : 0.105237 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :825 ]train loss : 0.064221 ,train acc: 0.999207 ,val loss : 0.106269 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :826 ]train loss : 0.156301 ,train acc: 0.931000 ,val loss : 0.106888 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :827 ]train loss : 0.080600 ,train acc: 0.986328 ,val loss : 0.107805 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :828 ]train loss : 0.073853 ,train acc: 0.995056 ,val loss : 0.105978 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :829 ]train loss : 0.092430 ,train acc: 0.983582 ,val loss : 0.105533 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :830 ]train loss : 0.155394 ,train acc: 0.961365 ,val loss : 0.106294 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :831 ]train loss : 0.101660 ,train acc: 0.991333 ,val loss : 0.109958 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :832 ]train loss : 0.087381 ,train acc: 0.991699 ,val loss : 0.104604 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :833 ]train loss : 0.071209 ,train acc: 0.997223 ,val loss : 0.107191 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :834 ]train loss : 0.097700 ,train acc: 0.996033 ,val loss : 0.107803 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :835 ]train loss : 0.104633 ,train acc: 0.985413 ,val loss : 0.106991 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :836 ]train loss : 0.071490 ,train acc: 0.997101 ,val loss : 0.106600 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :837 ]train loss : 0.081425 ,train acc: 0.997375 ,val loss : 0.106936 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :838 ]train loss : 0.117413 ,train acc: 0.966736 ,val loss : 0.107032 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :839 ]train loss : 0.124487 ,train acc: 0.958221 ,val loss : 0.105293 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :840 ]train loss : 0.083472 ,train acc: 0.995392 ,val loss : 0.106137 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :841 ]train loss : 0.146791 ,train acc: 0.962128 ,val loss : 0.106047 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :842 ]train loss : 0.102771 ,train acc: 0.992004 ,val loss : 0.105086 ,val acc : 0.992920\n",
      "[ ecpho : 3  iter :843 ]train loss : 0.417651 ,train acc: 0.760529 ,val loss : 0.105048 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :844 ]train loss : 0.080139 ,train acc: 0.990784 ,val loss : 0.103967 ,val acc : 0.993011\n",
      "[ ecpho : 3  iter :845 ]train loss : 0.080843 ,train acc: 0.990601 ,val loss : 0.104915 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :846 ]train loss : 0.065902 ,train acc: 0.997620 ,val loss : 0.106853 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :847 ]train loss : 0.257931 ,train acc: 0.869019 ,val loss : 0.105934 ,val acc : 0.992889\n",
      "[ ecpho : 3  iter :848 ]train loss : 0.272296 ,train acc: 0.916504 ,val loss : 0.104432 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :849 ]train loss : 0.077273 ,train acc: 0.998474 ,val loss : 0.105171 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :850 ]train loss : 0.097731 ,train acc: 0.983185 ,val loss : 0.105604 ,val acc : 0.992950\n",
      "[ ecpho : 3  iter :851 ]train loss : 0.325400 ,train acc: 0.790955 ,val loss : 0.103600 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :852 ]train loss : 0.571628 ,train acc: 0.622345 ,val loss : 0.104993 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :853 ]train loss : 0.061361 ,train acc: 0.997864 ,val loss : 0.107491 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :854 ]train loss : 0.233107 ,train acc: 0.859863 ,val loss : 0.105378 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :855 ]train loss : 0.082482 ,train acc: 0.992218 ,val loss : 0.104735 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :856 ]train loss : 0.057818 ,train acc: 0.998199 ,val loss : 0.104569 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :857 ]train loss : 0.087229 ,train acc: 0.984833 ,val loss : 0.104900 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :858 ]train loss : 0.233394 ,train acc: 0.910126 ,val loss : 0.107579 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :859 ]train loss : 0.074503 ,train acc: 0.991852 ,val loss : 0.106473 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :860 ]train loss : 0.109988 ,train acc: 0.987854 ,val loss : 0.104311 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :861 ]train loss : 0.067866 ,train acc: 0.997559 ,val loss : 0.106408 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :862 ]train loss : 0.230769 ,train acc: 0.873444 ,val loss : 0.107319 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :863 ]train loss : 0.120303 ,train acc: 0.988342 ,val loss : 0.104988 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :864 ]train loss : 0.164799 ,train acc: 0.933228 ,val loss : 0.106830 ,val acc : 0.992523\n",
      "[ ecpho : 3  iter :865 ]train loss : 0.094497 ,train acc: 0.991089 ,val loss : 0.105939 ,val acc : 0.992798\n",
      "[ ecpho : 3  iter :866 ]train loss : 0.138508 ,train acc: 0.952209 ,val loss : 0.107793 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :867 ]train loss : 0.069973 ,train acc: 0.991943 ,val loss : 0.103561 ,val acc : 0.992889\n",
      "[ ecpho : 3  iter :868 ]train loss : 0.238775 ,train acc: 0.859253 ,val loss : 0.108172 ,val acc : 0.992737\n",
      "[ ecpho : 3  iter :869 ]train loss : 0.096019 ,train acc: 0.991852 ,val loss : 0.105817 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :870 ]train loss : 0.097478 ,train acc: 0.992584 ,val loss : 0.107612 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :871 ]train loss : 0.062767 ,train acc: 0.999176 ,val loss : 0.104769 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :872 ]train loss : 0.079421 ,train acc: 0.995605 ,val loss : 0.107101 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :873 ]train loss : 0.078388 ,train acc: 0.993225 ,val loss : 0.106172 ,val acc : 0.992706\n",
      "[ ecpho : 3  iter :874 ]train loss : 0.101106 ,train acc: 0.976288 ,val loss : 0.106418 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :875 ]train loss : 0.329280 ,train acc: 0.792572 ,val loss : 0.106876 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :876 ]train loss : 0.071538 ,train acc: 0.998413 ,val loss : 0.107964 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :877 ]train loss : 0.074175 ,train acc: 0.995361 ,val loss : 0.105292 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :878 ]train loss : 0.089642 ,train acc: 0.982605 ,val loss : 0.106674 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :879 ]train loss : 0.616475 ,train acc: 0.552948 ,val loss : 0.106588 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :880 ]train loss : 0.151111 ,train acc: 0.973053 ,val loss : 0.108169 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :881 ]train loss : 1.154215 ,train acc: 0.204468 ,val loss : 0.105806 ,val acc : 0.992249\n",
      "[ ecpho : 3  iter :882 ]train loss : 0.064441 ,train acc: 0.995087 ,val loss : 0.107766 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :883 ]train loss : 0.109861 ,train acc: 0.986084 ,val loss : 0.107323 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :884 ]train loss : 0.068376 ,train acc: 0.997528 ,val loss : 0.109970 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :885 ]train loss : 0.214838 ,train acc: 0.933838 ,val loss : 0.106125 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :886 ]train loss : 0.088518 ,train acc: 0.992737 ,val loss : 0.107525 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :887 ]train loss : 0.272123 ,train acc: 0.877472 ,val loss : 0.106855 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :888 ]train loss : 0.098933 ,train acc: 0.980682 ,val loss : 0.108540 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :889 ]train loss : 0.194634 ,train acc: 0.952454 ,val loss : 0.105703 ,val acc : 0.992340\n",
      "[ ecpho : 3  iter :890 ]train loss : 0.130421 ,train acc: 0.985931 ,val loss : 0.106309 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :891 ]train loss : 0.092894 ,train acc: 0.994507 ,val loss : 0.107663 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :892 ]train loss : 0.126676 ,train acc: 0.956299 ,val loss : 0.104737 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :893 ]train loss : 0.072488 ,train acc: 0.992767 ,val loss : 0.106473 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :894 ]train loss : 0.061455 ,train acc: 0.998352 ,val loss : 0.106857 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :895 ]train loss : 0.074120 ,train acc: 0.992188 ,val loss : 0.107864 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :896 ]train loss : 0.103944 ,train acc: 0.990570 ,val loss : 0.108349 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :897 ]train loss : 0.113812 ,train acc: 0.973358 ,val loss : 0.105331 ,val acc : 0.992889\n",
      "[ ecpho : 3  iter :898 ]train loss : 0.102457 ,train acc: 0.979309 ,val loss : 0.105290 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :899 ]train loss : 0.083227 ,train acc: 0.985779 ,val loss : 0.107564 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :900 ]train loss : 0.082876 ,train acc: 0.989349 ,val loss : 0.106915 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :901 ]train loss : 0.107844 ,train acc: 0.986725 ,val loss : 0.108219 ,val acc : 0.992279\n",
      "[ ecpho : 3  iter :902 ]train loss : 0.118697 ,train acc: 0.971497 ,val loss : 0.106620 ,val acc : 0.992310\n",
      "[ ecpho : 3  iter :903 ]train loss : 0.419438 ,train acc: 0.704773 ,val loss : 0.105312 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :904 ]train loss : 0.167647 ,train acc: 0.918243 ,val loss : 0.106486 ,val acc : 0.992615\n",
      "[ ecpho : 3  iter :905 ]train loss : 0.071627 ,train acc: 0.996521 ,val loss : 0.105702 ,val acc : 0.992859\n",
      "[ ecpho : 3  iter :906 ]train loss : 0.070129 ,train acc: 0.997589 ,val loss : 0.106579 ,val acc : 0.992645\n",
      "[ ecpho : 3  iter :907 ]train loss : 0.638550 ,train acc: 0.567749 ,val loss : 0.106199 ,val acc : 0.992401\n",
      "[ ecpho : 3  iter :908 ]train loss : 0.119273 ,train acc: 0.965668 ,val loss : 0.106772 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :909 ]train loss : 0.223388 ,train acc: 0.920288 ,val loss : 0.107477 ,val acc : 0.992493\n",
      "[ ecpho : 3  iter :910 ]train loss : 0.090771 ,train acc: 0.996552 ,val loss : 0.109101 ,val acc : 0.992188\n",
      "[ ecpho : 3  iter :911 ]train loss : 0.215211 ,train acc: 0.912994 ,val loss : 0.108016 ,val acc : 0.992584\n",
      "[ ecpho : 3  iter :912 ]train loss : 0.190385 ,train acc: 0.918457 ,val loss : 0.106190 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :913 ]train loss : 0.064772 ,train acc: 0.998169 ,val loss : 0.107034 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :914 ]train loss : 0.058200 ,train acc: 0.998444 ,val loss : 0.107536 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :915 ]train loss : 0.990868 ,train acc: 0.422943 ,val loss : 0.106284 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :916 ]train loss : 0.182196 ,train acc: 0.933990 ,val loss : 0.108861 ,val acc : 0.992767\n",
      "[ ecpho : 3  iter :917 ]train loss : 0.103359 ,train acc: 0.978668 ,val loss : 0.107112 ,val acc : 0.992462\n",
      "[ ecpho : 3  iter :918 ]train loss : 0.128327 ,train acc: 0.956238 ,val loss : 0.106288 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :919 ]train loss : 0.074059 ,train acc: 0.990570 ,val loss : 0.107887 ,val acc : 0.992676\n",
      "[ ecpho : 3  iter :920 ]train loss : 0.351290 ,train acc: 0.775208 ,val loss : 0.107624 ,val acc : 0.991730\n",
      "[ ecpho : 3  iter :921 ]train loss : 0.082624 ,train acc: 0.988098 ,val loss : 0.104987 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :922 ]train loss : 0.156705 ,train acc: 0.971985 ,val loss : 0.105633 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :923 ]train loss : 0.069292 ,train acc: 0.997009 ,val loss : 0.111004 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :924 ]train loss : 0.150633 ,train acc: 0.941437 ,val loss : 0.106732 ,val acc : 0.991852\n",
      "[ ecpho : 3  iter :925 ]train loss : 0.087161 ,train acc: 0.994202 ,val loss : 0.107887 ,val acc : 0.992218\n",
      "[ ecpho : 3  iter :926 ]train loss : 0.065367 ,train acc: 0.997986 ,val loss : 0.104747 ,val acc : 0.991760\n",
      "[ ecpho : 3  iter :927 ]train loss : 0.328439 ,train acc: 0.785583 ,val loss : 0.104706 ,val acc : 0.992157\n",
      "[ ecpho : 3  iter :928 ]train loss : 0.063104 ,train acc: 0.997437 ,val loss : 0.109024 ,val acc : 0.992554\n",
      "[ ecpho : 3  iter :929 ]train loss : 0.115226 ,train acc: 0.984222 ,val loss : 0.109189 ,val acc : 0.992096\n",
      "[ ecpho : 3  iter :930 ]train loss : 0.083103 ,train acc: 0.987701 ,val loss : 0.108230 ,val acc : 0.991638\n",
      "[ ecpho : 3  iter :931 ]train loss : 0.070342 ,train acc: 0.993988 ,val loss : 0.106456 ,val acc : 0.992126\n",
      "[ ecpho : 3  iter :932 ]train loss : 0.211118 ,train acc: 0.903137 ,val loss : 0.107340 ,val acc : 0.991791\n",
      "[ ecpho : 3  iter :933 ]train loss : 0.086225 ,train acc: 0.997864 ,val loss : 0.105412 ,val acc : 0.992004\n",
      "[ ecpho : 3  iter :934 ]train loss : 0.167996 ,train acc: 0.919342 ,val loss : 0.106565 ,val acc : 0.991943\n",
      "[ ecpho : 3  iter :935 ]train loss : 0.092559 ,train acc: 0.996490 ,val loss : 0.104727 ,val acc : 0.992371\n",
      "[ ecpho : 3  iter :936 ]train loss : 0.079697 ,train acc: 0.993866 ,val loss : 0.106625 ,val acc : 0.991974\n",
      "[ ecpho : 3  iter :937 ]train loss : 0.083382 ,train acc: 0.988556 ,val loss : 0.108546 ,val acc : 0.992065\n",
      "[ ecpho : 3  iter :938 ]train loss : 0.117866 ,train acc: 0.987885 ,val loss : 0.106676 ,val acc : 0.992432\n",
      "[ ecpho : 3  iter :939 ]train loss : 0.145176 ,train acc: 0.949402 ,val loss : 0.109944 ,val acc : 0.992035\n",
      "[ ecpho : 3  iter :940 ]train loss : 0.156405 ,train acc: 0.971802 ,val loss : 0.105367 ,val acc : 0.992279\n",
      "=============================================\n",
      "[ 3 ] average train loss : 0.163690 train acc : 0.934511\n",
      "[ ecpho : 4  iter :1 ]train loss : 0.075924 ,train acc: 0.991638 ,val loss : 0.108547 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :2 ]train loss : 0.228627 ,train acc: 0.893646 ,val loss : 0.106901 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :3 ]train loss : 0.074125 ,train acc: 0.993439 ,val loss : 0.108840 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :4 ]train loss : 0.102389 ,train acc: 0.974091 ,val loss : 0.108713 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :5 ]train loss : 0.093863 ,train acc: 0.994202 ,val loss : 0.107494 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :6 ]train loss : 0.094479 ,train acc: 0.993225 ,val loss : 0.106152 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :7 ]train loss : 0.092976 ,train acc: 0.977722 ,val loss : 0.105928 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :8 ]train loss : 0.350182 ,train acc: 0.859192 ,val loss : 0.105175 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :9 ]train loss : 0.167026 ,train acc: 0.926361 ,val loss : 0.106992 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :10 ]train loss : 0.149092 ,train acc: 0.952179 ,val loss : 0.106525 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :11 ]train loss : 0.070325 ,train acc: 0.998474 ,val loss : 0.106440 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :12 ]train loss : 0.088675 ,train acc: 0.993988 ,val loss : 0.105365 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :13 ]train loss : 0.086277 ,train acc: 0.985687 ,val loss : 0.105477 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :14 ]train loss : 0.095605 ,train acc: 0.996796 ,val loss : 0.105965 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :15 ]train loss : 0.083890 ,train acc: 0.983246 ,val loss : 0.106236 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :16 ]train loss : 0.090516 ,train acc: 0.993469 ,val loss : 0.107723 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :17 ]train loss : 0.085768 ,train acc: 0.996429 ,val loss : 0.105853 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :18 ]train loss : 0.752266 ,train acc: 0.505188 ,val loss : 0.107271 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :19 ]train loss : 0.097924 ,train acc: 0.981232 ,val loss : 0.104594 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :20 ]train loss : 0.094141 ,train acc: 0.992645 ,val loss : 0.106653 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :21 ]train loss : 0.111279 ,train acc: 0.985565 ,val loss : 0.107388 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :22 ]train loss : 0.115474 ,train acc: 0.973511 ,val loss : 0.105744 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :23 ]train loss : 0.056962 ,train acc: 0.999054 ,val loss : 0.106526 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :24 ]train loss : 0.105397 ,train acc: 0.991760 ,val loss : 0.105696 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :25 ]train loss : 0.102435 ,train acc: 0.976532 ,val loss : 0.106223 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :26 ]train loss : 0.417875 ,train acc: 0.779724 ,val loss : 0.106126 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :27 ]train loss : 0.349561 ,train acc: 0.770599 ,val loss : 0.106284 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :28 ]train loss : 0.083360 ,train acc: 0.994843 ,val loss : 0.106273 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :29 ]train loss : 0.098795 ,train acc: 0.982574 ,val loss : 0.107429 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :30 ]train loss : 0.073692 ,train acc: 0.994965 ,val loss : 0.107712 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :31 ]train loss : 0.077920 ,train acc: 0.992401 ,val loss : 0.103818 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :32 ]train loss : 0.077607 ,train acc: 0.989014 ,val loss : 0.108256 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :33 ]train loss : 0.059072 ,train acc: 0.998047 ,val loss : 0.102696 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :34 ]train loss : 0.083582 ,train acc: 0.994385 ,val loss : 0.104556 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :35 ]train loss : 0.067764 ,train acc: 0.997223 ,val loss : 0.107412 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :36 ]train loss : 0.112041 ,train acc: 0.969727 ,val loss : 0.103696 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :37 ]train loss : 0.098858 ,train acc: 0.994171 ,val loss : 0.105916 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :38 ]train loss : 0.112908 ,train acc: 0.964264 ,val loss : 0.108010 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :39 ]train loss : 0.251739 ,train acc: 0.854919 ,val loss : 0.106152 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :40 ]train loss : 0.214099 ,train acc: 0.939606 ,val loss : 0.106668 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :41 ]train loss : 0.075294 ,train acc: 0.994324 ,val loss : 0.106491 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :42 ]train loss : 0.077146 ,train acc: 0.994110 ,val loss : 0.104871 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :43 ]train loss : 0.184394 ,train acc: 0.954926 ,val loss : 0.105709 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :44 ]train loss : 0.085573 ,train acc: 0.989716 ,val loss : 0.106160 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :45 ]train loss : 0.101541 ,train acc: 0.985443 ,val loss : 0.106000 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :46 ]train loss : 0.762050 ,train acc: 0.429535 ,val loss : 0.107200 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :47 ]train loss : 0.093068 ,train acc: 0.977509 ,val loss : 0.105410 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :48 ]train loss : 0.108290 ,train acc: 0.985596 ,val loss : 0.108794 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :49 ]train loss : 0.101261 ,train acc: 0.992493 ,val loss : 0.106648 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :50 ]train loss : 0.101312 ,train acc: 0.974457 ,val loss : 0.110792 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :51 ]train loss : 0.079834 ,train acc: 0.995667 ,val loss : 0.104281 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :52 ]train loss : 0.107744 ,train acc: 0.990814 ,val loss : 0.105702 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :53 ]train loss : 0.102380 ,train acc: 0.974670 ,val loss : 0.106084 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :54 ]train loss : 0.170313 ,train acc: 0.921021 ,val loss : 0.104214 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :55 ]train loss : 0.113358 ,train acc: 0.991669 ,val loss : 0.106697 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :56 ]train loss : 0.191445 ,train acc: 0.916412 ,val loss : 0.105353 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :57 ]train loss : 0.355190 ,train acc: 0.771851 ,val loss : 0.105244 ,val acc : 0.992889\n",
      "[ ecpho : 4  iter :58 ]train loss : 0.075250 ,train acc: 0.992126 ,val loss : 0.104966 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :59 ]train loss : 0.130733 ,train acc: 0.967072 ,val loss : 0.104073 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :60 ]train loss : 0.066586 ,train acc: 0.999023 ,val loss : 0.105208 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :61 ]train loss : 0.143010 ,train acc: 0.951172 ,val loss : 0.105793 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :62 ]train loss : 0.125317 ,train acc: 0.956055 ,val loss : 0.102978 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :63 ]train loss : 0.433037 ,train acc: 0.710541 ,val loss : 0.106745 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :64 ]train loss : 0.387584 ,train acc: 0.782501 ,val loss : 0.106385 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :65 ]train loss : 0.134005 ,train acc: 0.980927 ,val loss : 0.105337 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :66 ]train loss : 0.078015 ,train acc: 0.997650 ,val loss : 0.107995 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :67 ]train loss : 0.110635 ,train acc: 0.980652 ,val loss : 0.105724 ,val acc : 0.992859\n",
      "[ ecpho : 4  iter :68 ]train loss : 0.076561 ,train acc: 0.997437 ,val loss : 0.105154 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :69 ]train loss : 0.087260 ,train acc: 0.996979 ,val loss : 0.105884 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :70 ]train loss : 0.115019 ,train acc: 0.985107 ,val loss : 0.106897 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :71 ]train loss : 0.078912 ,train acc: 0.991211 ,val loss : 0.106947 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :72 ]train loss : 0.084350 ,train acc: 0.985535 ,val loss : 0.105349 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :73 ]train loss : 0.069223 ,train acc: 0.993958 ,val loss : 0.107079 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :74 ]train loss : 0.529724 ,train acc: 0.642883 ,val loss : 0.104383 ,val acc : 0.992767\n",
      "[ ecpho : 4  iter :75 ]train loss : 0.105156 ,train acc: 0.972351 ,val loss : 0.104033 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :76 ]train loss : 0.063616 ,train acc: 0.997955 ,val loss : 0.105162 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :77 ]train loss : 0.079103 ,train acc: 0.992096 ,val loss : 0.106585 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :78 ]train loss : 0.066425 ,train acc: 0.993561 ,val loss : 0.104995 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :79 ]train loss : 0.059952 ,train acc: 0.996185 ,val loss : 0.103938 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :80 ]train loss : 0.100636 ,train acc: 0.993195 ,val loss : 0.103476 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :81 ]train loss : 0.095567 ,train acc: 0.982025 ,val loss : 0.106390 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :82 ]train loss : 0.456871 ,train acc: 0.716278 ,val loss : 0.104161 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :83 ]train loss : 0.080023 ,train acc: 0.992004 ,val loss : 0.106982 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :84 ]train loss : 0.078916 ,train acc: 0.998871 ,val loss : 0.105759 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :85 ]train loss : 0.068461 ,train acc: 0.995544 ,val loss : 0.107675 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :86 ]train loss : 0.067320 ,train acc: 0.997314 ,val loss : 0.106363 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :87 ]train loss : 0.094550 ,train acc: 0.987640 ,val loss : 0.107018 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :88 ]train loss : 0.108749 ,train acc: 0.987091 ,val loss : 0.108602 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :89 ]train loss : 0.224785 ,train acc: 0.880707 ,val loss : 0.104852 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :90 ]train loss : 0.323593 ,train acc: 0.866333 ,val loss : 0.103192 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :91 ]train loss : 0.077838 ,train acc: 0.997192 ,val loss : 0.105784 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :92 ]train loss : 0.157197 ,train acc: 0.929871 ,val loss : 0.105814 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :93 ]train loss : 0.373154 ,train acc: 0.782928 ,val loss : 0.104281 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :94 ]train loss : 0.080375 ,train acc: 0.996399 ,val loss : 0.103551 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :95 ]train loss : 0.594873 ,train acc: 0.690887 ,val loss : 0.105679 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :96 ]train loss : 0.116129 ,train acc: 0.974182 ,val loss : 0.104553 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :97 ]train loss : 0.095372 ,train acc: 0.979553 ,val loss : 0.104949 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :98 ]train loss : 0.088966 ,train acc: 0.994751 ,val loss : 0.106674 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :99 ]train loss : 0.062499 ,train acc: 0.997284 ,val loss : 0.107323 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :100 ]train loss : 0.132064 ,train acc: 0.974640 ,val loss : 0.103755 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :101 ]train loss : 0.091273 ,train acc: 0.993774 ,val loss : 0.105691 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :102 ]train loss : 0.488515 ,train acc: 0.690948 ,val loss : 0.105841 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :103 ]train loss : 0.489265 ,train acc: 0.753845 ,val loss : 0.103558 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :104 ]train loss : 0.462927 ,train acc: 0.684174 ,val loss : 0.104824 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :105 ]train loss : 0.080552 ,train acc: 0.991302 ,val loss : 0.109039 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :106 ]train loss : 0.134234 ,train acc: 0.976868 ,val loss : 0.105392 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :107 ]train loss : 0.148969 ,train acc: 0.960938 ,val loss : 0.105780 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :108 ]train loss : 0.097446 ,train acc: 0.993073 ,val loss : 0.104380 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :109 ]train loss : 0.214241 ,train acc: 0.916046 ,val loss : 0.101773 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :110 ]train loss : 0.065256 ,train acc: 0.998199 ,val loss : 0.104820 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :111 ]train loss : 0.252471 ,train acc: 0.866119 ,val loss : 0.104779 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :112 ]train loss : 0.095375 ,train acc: 0.983490 ,val loss : 0.105509 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :113 ]train loss : 0.798673 ,train acc: 0.464386 ,val loss : 0.105517 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :114 ]train loss : 0.079421 ,train acc: 0.989410 ,val loss : 0.104763 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :115 ]train loss : 0.070807 ,train acc: 0.993011 ,val loss : 0.105430 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :116 ]train loss : 0.314830 ,train acc: 0.791046 ,val loss : 0.106839 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :117 ]train loss : 0.114279 ,train acc: 0.968597 ,val loss : 0.106393 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :118 ]train loss : 0.115990 ,train acc: 0.961182 ,val loss : 0.107400 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :119 ]train loss : 0.085641 ,train acc: 0.992462 ,val loss : 0.106671 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :120 ]train loss : 0.063409 ,train acc: 0.998199 ,val loss : 0.107070 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :121 ]train loss : 0.598342 ,train acc: 0.606689 ,val loss : 0.105844 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :122 ]train loss : 0.077779 ,train acc: 0.991699 ,val loss : 0.107857 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :123 ]train loss : 0.084143 ,train acc: 0.997192 ,val loss : 0.106971 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :124 ]train loss : 0.074257 ,train acc: 0.995026 ,val loss : 0.107590 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :125 ]train loss : 0.097529 ,train acc: 0.990997 ,val loss : 0.108003 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :126 ]train loss : 0.064461 ,train acc: 0.998199 ,val loss : 0.109227 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :127 ]train loss : 0.911986 ,train acc: 0.354736 ,val loss : 0.108093 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :128 ]train loss : 0.092619 ,train acc: 0.989746 ,val loss : 0.106018 ,val acc : 0.991333\n",
      "[ ecpho : 4  iter :129 ]train loss : 0.517385 ,train acc: 0.659363 ,val loss : 0.106439 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :130 ]train loss : 0.417856 ,train acc: 0.713226 ,val loss : 0.107378 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :131 ]train loss : 0.100348 ,train acc: 0.975677 ,val loss : 0.107418 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :132 ]train loss : 0.087118 ,train acc: 0.993317 ,val loss : 0.109954 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :133 ]train loss : 0.301741 ,train acc: 0.849915 ,val loss : 0.107016 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :134 ]train loss : 0.480122 ,train acc: 0.702911 ,val loss : 0.107809 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :135 ]train loss : 0.117323 ,train acc: 0.983063 ,val loss : 0.107464 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :136 ]train loss : 0.126989 ,train acc: 0.958801 ,val loss : 0.108235 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :137 ]train loss : 0.099335 ,train acc: 0.984131 ,val loss : 0.109075 ,val acc : 0.990753\n",
      "[ ecpho : 4  iter :138 ]train loss : 0.068465 ,train acc: 0.997101 ,val loss : 0.107074 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :139 ]train loss : 0.060198 ,train acc: 0.998993 ,val loss : 0.108552 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :140 ]train loss : 0.074753 ,train acc: 0.996399 ,val loss : 0.110767 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :141 ]train loss : 0.592564 ,train acc: 0.554138 ,val loss : 0.107391 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :142 ]train loss : 0.082864 ,train acc: 0.982605 ,val loss : 0.109182 ,val acc : 0.990570\n",
      "[ ecpho : 4  iter :143 ]train loss : 0.098418 ,train acc: 0.977753 ,val loss : 0.108806 ,val acc : 0.990875\n",
      "[ ecpho : 4  iter :144 ]train loss : 0.096917 ,train acc: 0.974640 ,val loss : 0.111545 ,val acc : 0.990845\n",
      "[ ecpho : 4  iter :145 ]train loss : 0.072210 ,train acc: 0.991333 ,val loss : 0.110474 ,val acc : 0.991089\n",
      "[ ecpho : 4  iter :146 ]train loss : 0.074703 ,train acc: 0.991638 ,val loss : 0.109544 ,val acc : 0.991150\n",
      "[ ecpho : 4  iter :147 ]train loss : 0.072976 ,train acc: 0.993347 ,val loss : 0.107995 ,val acc : 0.991241\n",
      "[ ecpho : 4  iter :148 ]train loss : 1.103086 ,train acc: 0.222687 ,val loss : 0.107234 ,val acc : 0.990540\n",
      "[ ecpho : 4  iter :149 ]train loss : 0.142280 ,train acc: 0.949127 ,val loss : 0.107572 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :150 ]train loss : 0.116466 ,train acc: 0.976837 ,val loss : 0.109234 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :151 ]train loss : 0.800162 ,train acc: 0.429871 ,val loss : 0.108584 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :152 ]train loss : 0.229755 ,train acc: 0.923706 ,val loss : 0.110518 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :153 ]train loss : 0.128679 ,train acc: 0.954559 ,val loss : 0.111998 ,val acc : 0.990540\n",
      "[ ecpho : 4  iter :154 ]train loss : 0.197159 ,train acc: 0.941742 ,val loss : 0.108986 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :155 ]train loss : 0.099607 ,train acc: 0.987946 ,val loss : 0.108943 ,val acc : 0.990875\n",
      "[ ecpho : 4  iter :156 ]train loss : 0.083437 ,train acc: 0.988159 ,val loss : 0.113229 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :157 ]train loss : 0.094010 ,train acc: 0.995605 ,val loss : 0.108382 ,val acc : 0.990417\n",
      "[ ecpho : 4  iter :158 ]train loss : 0.077405 ,train acc: 0.996185 ,val loss : 0.108199 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :159 ]train loss : 0.113966 ,train acc: 0.984924 ,val loss : 0.109080 ,val acc : 0.991211\n",
      "[ ecpho : 4  iter :160 ]train loss : 0.124352 ,train acc: 0.962128 ,val loss : 0.106789 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :161 ]train loss : 1.197121 ,train acc: 0.126251 ,val loss : 0.109358 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :162 ]train loss : 0.163051 ,train acc: 0.947327 ,val loss : 0.108705 ,val acc : 0.990936\n",
      "[ ecpho : 4  iter :163 ]train loss : 0.116626 ,train acc: 0.965607 ,val loss : 0.108724 ,val acc : 0.990448\n",
      "[ ecpho : 4  iter :164 ]train loss : 0.140925 ,train acc: 0.975769 ,val loss : 0.109024 ,val acc : 0.991150\n",
      "[ ecpho : 4  iter :165 ]train loss : 0.078501 ,train acc: 0.995148 ,val loss : 0.108287 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :166 ]train loss : 0.086994 ,train acc: 0.986877 ,val loss : 0.110383 ,val acc : 0.991302\n",
      "[ ecpho : 4  iter :167 ]train loss : 0.423053 ,train acc: 0.726929 ,val loss : 0.110299 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :168 ]train loss : 0.127144 ,train acc: 0.958588 ,val loss : 0.107326 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :169 ]train loss : 0.313375 ,train acc: 0.841339 ,val loss : 0.109153 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :170 ]train loss : 0.834553 ,train acc: 0.444000 ,val loss : 0.109376 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :171 ]train loss : 0.084085 ,train acc: 0.989044 ,val loss : 0.111396 ,val acc : 0.990753\n",
      "[ ecpho : 4  iter :172 ]train loss : 0.393301 ,train acc: 0.799438 ,val loss : 0.109443 ,val acc : 0.990631\n",
      "[ ecpho : 4  iter :173 ]train loss : 0.699718 ,train acc: 0.528961 ,val loss : 0.109269 ,val acc : 0.990417\n",
      "[ ecpho : 4  iter :174 ]train loss : 0.121440 ,train acc: 0.984772 ,val loss : 0.107337 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :175 ]train loss : 0.069254 ,train acc: 0.997406 ,val loss : 0.110415 ,val acc : 0.990692\n",
      "[ ecpho : 4  iter :176 ]train loss : 0.259980 ,train acc: 0.836853 ,val loss : 0.110806 ,val acc : 0.990479\n",
      "[ ecpho : 4  iter :177 ]train loss : 0.100850 ,train acc: 0.986633 ,val loss : 0.108035 ,val acc : 0.990509\n",
      "[ ecpho : 4  iter :178 ]train loss : 0.097632 ,train acc: 0.991730 ,val loss : 0.109187 ,val acc : 0.990631\n",
      "[ ecpho : 4  iter :179 ]train loss : 0.174843 ,train acc: 0.919647 ,val loss : 0.109696 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :180 ]train loss : 0.080926 ,train acc: 0.988586 ,val loss : 0.107993 ,val acc : 0.991058\n",
      "[ ecpho : 4  iter :181 ]train loss : 0.184726 ,train acc: 0.952545 ,val loss : 0.108792 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :182 ]train loss : 0.119966 ,train acc: 0.981598 ,val loss : 0.110850 ,val acc : 0.990417\n",
      "[ ecpho : 4  iter :183 ]train loss : 0.082906 ,train acc: 0.991425 ,val loss : 0.111605 ,val acc : 0.990601\n",
      "[ ecpho : 4  iter :184 ]train loss : 0.089622 ,train acc: 0.989807 ,val loss : 0.108560 ,val acc : 0.990540\n",
      "[ ecpho : 4  iter :185 ]train loss : 0.810935 ,train acc: 0.385864 ,val loss : 0.108507 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :186 ]train loss : 0.124084 ,train acc: 0.960297 ,val loss : 0.108195 ,val acc : 0.990723\n",
      "[ ecpho : 4  iter :187 ]train loss : 0.115000 ,train acc: 0.980804 ,val loss : 0.110383 ,val acc : 0.990295\n",
      "[ ecpho : 4  iter :188 ]train loss : 0.094410 ,train acc: 0.994751 ,val loss : 0.107955 ,val acc : 0.990631\n",
      "[ ecpho : 4  iter :189 ]train loss : 0.069571 ,train acc: 0.996552 ,val loss : 0.105976 ,val acc : 0.990509\n",
      "[ ecpho : 4  iter :190 ]train loss : 0.108729 ,train acc: 0.989807 ,val loss : 0.108622 ,val acc : 0.990601\n",
      "[ ecpho : 4  iter :191 ]train loss : 0.185806 ,train acc: 0.910889 ,val loss : 0.110318 ,val acc : 0.990814\n",
      "[ ecpho : 4  iter :192 ]train loss : 0.076616 ,train acc: 0.993927 ,val loss : 0.108647 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :193 ]train loss : 0.136126 ,train acc: 0.952484 ,val loss : 0.109527 ,val acc : 0.990479\n",
      "[ ecpho : 4  iter :194 ]train loss : 0.350062 ,train acc: 0.813507 ,val loss : 0.107668 ,val acc : 0.990692\n",
      "[ ecpho : 4  iter :195 ]train loss : 0.074607 ,train acc: 0.990143 ,val loss : 0.107976 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :196 ]train loss : 0.073467 ,train acc: 0.993835 ,val loss : 0.109364 ,val acc : 0.990417\n",
      "[ ecpho : 4  iter :197 ]train loss : 0.081908 ,train acc: 0.991455 ,val loss : 0.107567 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :198 ]train loss : 0.077889 ,train acc: 0.992310 ,val loss : 0.111198 ,val acc : 0.990540\n",
      "[ ecpho : 4  iter :199 ]train loss : 0.430653 ,train acc: 0.701172 ,val loss : 0.109644 ,val acc : 0.991302\n",
      "[ ecpho : 4  iter :200 ]train loss : 0.198048 ,train acc: 0.917084 ,val loss : 0.108304 ,val acc : 0.990417\n",
      "[ ecpho : 4  iter :201 ]train loss : 0.068596 ,train acc: 0.992615 ,val loss : 0.107652 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :202 ]train loss : 0.076676 ,train acc: 0.997528 ,val loss : 0.108774 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :203 ]train loss : 0.129007 ,train acc: 0.976074 ,val loss : 0.108312 ,val acc : 0.990662\n",
      "[ ecpho : 4  iter :204 ]train loss : 0.108195 ,train acc: 0.973877 ,val loss : 0.108111 ,val acc : 0.990723\n",
      "[ ecpho : 4  iter :205 ]train loss : 0.080978 ,train acc: 0.992615 ,val loss : 0.107836 ,val acc : 0.991150\n",
      "[ ecpho : 4  iter :206 ]train loss : 0.293554 ,train acc: 0.839294 ,val loss : 0.107385 ,val acc : 0.991058\n",
      "[ ecpho : 4  iter :207 ]train loss : 0.217966 ,train acc: 0.888672 ,val loss : 0.110121 ,val acc : 0.990845\n",
      "[ ecpho : 4  iter :208 ]train loss : 0.101420 ,train acc: 0.990784 ,val loss : 0.108753 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :209 ]train loss : 0.089564 ,train acc: 0.981934 ,val loss : 0.110271 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :210 ]train loss : 0.063597 ,train acc: 0.997131 ,val loss : 0.107386 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :211 ]train loss : 0.082846 ,train acc: 0.984772 ,val loss : 0.107616 ,val acc : 0.991089\n",
      "[ ecpho : 4  iter :212 ]train loss : 0.331448 ,train acc: 0.773773 ,val loss : 0.108208 ,val acc : 0.990509\n",
      "[ ecpho : 4  iter :213 ]train loss : 0.074374 ,train acc: 0.993713 ,val loss : 0.107438 ,val acc : 0.991150\n",
      "[ ecpho : 4  iter :214 ]train loss : 0.081456 ,train acc: 0.987762 ,val loss : 0.107638 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :215 ]train loss : 0.084734 ,train acc: 0.984039 ,val loss : 0.107496 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :216 ]train loss : 0.085084 ,train acc: 0.988068 ,val loss : 0.109756 ,val acc : 0.990509\n",
      "[ ecpho : 4  iter :217 ]train loss : 0.131599 ,train acc: 0.974304 ,val loss : 0.112501 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :218 ]train loss : 0.088206 ,train acc: 0.982635 ,val loss : 0.110084 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :219 ]train loss : 0.073745 ,train acc: 0.990662 ,val loss : 0.108551 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :220 ]train loss : 0.087594 ,train acc: 0.980743 ,val loss : 0.108126 ,val acc : 0.991089\n",
      "[ ecpho : 4  iter :221 ]train loss : 0.063525 ,train acc: 0.993530 ,val loss : 0.110020 ,val acc : 0.990540\n",
      "[ ecpho : 4  iter :222 ]train loss : 0.070589 ,train acc: 0.996368 ,val loss : 0.109917 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :223 ]train loss : 0.068083 ,train acc: 0.994354 ,val loss : 0.109346 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :224 ]train loss : 0.445018 ,train acc: 0.682495 ,val loss : 0.108269 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :225 ]train loss : 0.077934 ,train acc: 0.992737 ,val loss : 0.108671 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :226 ]train loss : 0.121165 ,train acc: 0.978271 ,val loss : 0.105156 ,val acc : 0.991333\n",
      "[ ecpho : 4  iter :227 ]train loss : 0.207293 ,train acc: 0.947296 ,val loss : 0.109206 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :228 ]train loss : 0.203454 ,train acc: 0.895111 ,val loss : 0.111083 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :229 ]train loss : 0.120915 ,train acc: 0.962494 ,val loss : 0.108434 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :230 ]train loss : 0.106026 ,train acc: 0.974670 ,val loss : 0.108658 ,val acc : 0.990387\n",
      "[ ecpho : 4  iter :231 ]train loss : 0.080287 ,train acc: 0.990448 ,val loss : 0.109752 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :232 ]train loss : 0.082150 ,train acc: 0.990112 ,val loss : 0.111959 ,val acc : 0.990692\n",
      "[ ecpho : 4  iter :233 ]train loss : 0.091386 ,train acc: 0.994446 ,val loss : 0.109303 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :234 ]train loss : 0.163952 ,train acc: 0.931183 ,val loss : 0.109122 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :235 ]train loss : 0.073576 ,train acc: 0.996643 ,val loss : 0.107281 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :236 ]train loss : 0.071301 ,train acc: 0.996704 ,val loss : 0.107885 ,val acc : 0.991364\n",
      "[ ecpho : 4  iter :237 ]train loss : 0.117698 ,train acc: 0.964600 ,val loss : 0.110712 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :238 ]train loss : 0.107944 ,train acc: 0.978241 ,val loss : 0.106961 ,val acc : 0.991241\n",
      "[ ecpho : 4  iter :239 ]train loss : 0.081118 ,train acc: 0.994507 ,val loss : 0.108251 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :240 ]train loss : 0.159647 ,train acc: 0.960205 ,val loss : 0.110257 ,val acc : 0.990814\n",
      "[ ecpho : 4  iter :241 ]train loss : 0.197205 ,train acc: 0.894073 ,val loss : 0.106914 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :242 ]train loss : 0.104214 ,train acc: 0.973328 ,val loss : 0.109501 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :243 ]train loss : 0.114821 ,train acc: 0.973846 ,val loss : 0.107236 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :244 ]train loss : 0.058928 ,train acc: 0.998413 ,val loss : 0.106176 ,val acc : 0.991302\n",
      "[ ecpho : 4  iter :245 ]train loss : 0.079906 ,train acc: 0.994751 ,val loss : 0.108141 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :246 ]train loss : 0.095222 ,train acc: 0.985382 ,val loss : 0.110665 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :247 ]train loss : 0.068074 ,train acc: 0.998779 ,val loss : 0.108870 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :248 ]train loss : 0.069380 ,train acc: 0.997284 ,val loss : 0.107215 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :249 ]train loss : 0.063667 ,train acc: 0.998810 ,val loss : 0.108567 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :250 ]train loss : 0.063241 ,train acc: 0.997040 ,val loss : 0.110370 ,val acc : 0.991211\n",
      "[ ecpho : 4  iter :251 ]train loss : 0.093666 ,train acc: 0.977844 ,val loss : 0.108298 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :252 ]train loss : 0.073242 ,train acc: 0.997467 ,val loss : 0.108392 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :253 ]train loss : 0.137325 ,train acc: 0.950409 ,val loss : 0.109313 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :254 ]train loss : 1.190837 ,train acc: 0.183105 ,val loss : 0.105818 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :255 ]train loss : 0.153943 ,train acc: 0.938660 ,val loss : 0.108207 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :256 ]train loss : 0.160821 ,train acc: 0.933350 ,val loss : 0.111080 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :257 ]train loss : 0.063473 ,train acc: 0.996918 ,val loss : 0.110926 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :258 ]train loss : 0.091417 ,train acc: 0.996307 ,val loss : 0.106581 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :259 ]train loss : 0.872393 ,train acc: 0.464661 ,val loss : 0.107251 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :260 ]train loss : 0.075688 ,train acc: 0.993286 ,val loss : 0.107795 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :261 ]train loss : 0.071264 ,train acc: 0.995514 ,val loss : 0.106420 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :262 ]train loss : 0.063055 ,train acc: 0.999084 ,val loss : 0.109497 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :263 ]train loss : 0.078311 ,train acc: 0.986572 ,val loss : 0.108601 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :264 ]train loss : 0.100197 ,train acc: 0.995026 ,val loss : 0.110244 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :265 ]train loss : 0.127271 ,train acc: 0.967072 ,val loss : 0.108121 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :266 ]train loss : 0.076361 ,train acc: 0.993500 ,val loss : 0.109339 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :267 ]train loss : 0.053725 ,train acc: 0.999634 ,val loss : 0.110092 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :268 ]train loss : 0.086717 ,train acc: 0.997223 ,val loss : 0.109355 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :269 ]train loss : 0.094585 ,train acc: 0.980164 ,val loss : 0.109895 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :270 ]train loss : 0.121786 ,train acc: 0.966919 ,val loss : 0.111537 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :271 ]train loss : 0.167257 ,train acc: 0.950623 ,val loss : 0.110082 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :272 ]train loss : 0.297880 ,train acc: 0.817444 ,val loss : 0.109219 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :273 ]train loss : 0.069170 ,train acc: 0.998566 ,val loss : 0.106891 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :274 ]train loss : 0.079260 ,train acc: 0.985840 ,val loss : 0.106153 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :275 ]train loss : 0.168971 ,train acc: 0.961060 ,val loss : 0.106763 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :276 ]train loss : 0.089564 ,train acc: 0.983612 ,val loss : 0.108755 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :277 ]train loss : 0.108602 ,train acc: 0.968475 ,val loss : 0.109372 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :278 ]train loss : 0.115854 ,train acc: 0.986481 ,val loss : 0.106496 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :279 ]train loss : 0.087194 ,train acc: 0.996918 ,val loss : 0.111671 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :280 ]train loss : 0.124584 ,train acc: 0.973053 ,val loss : 0.108234 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :281 ]train loss : 0.119252 ,train acc: 0.977203 ,val loss : 0.106213 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :282 ]train loss : 1.000196 ,train acc: 0.281921 ,val loss : 0.104980 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :283 ]train loss : 0.069514 ,train acc: 0.994263 ,val loss : 0.107830 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :284 ]train loss : 0.079994 ,train acc: 0.991516 ,val loss : 0.107491 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :285 ]train loss : 0.072191 ,train acc: 0.992004 ,val loss : 0.107670 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :286 ]train loss : 0.291761 ,train acc: 0.890656 ,val loss : 0.107121 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :287 ]train loss : 0.186835 ,train acc: 0.912079 ,val loss : 0.106298 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :288 ]train loss : 0.266919 ,train acc: 0.828888 ,val loss : 0.107205 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :289 ]train loss : 0.113184 ,train acc: 0.973145 ,val loss : 0.106953 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :290 ]train loss : 0.059285 ,train acc: 0.997955 ,val loss : 0.107352 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :291 ]train loss : 0.076775 ,train acc: 0.984314 ,val loss : 0.108623 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :292 ]train loss : 0.754502 ,train acc: 0.437103 ,val loss : 0.109308 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :293 ]train loss : 0.086003 ,train acc: 0.997437 ,val loss : 0.108583 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :294 ]train loss : 0.125639 ,train acc: 0.953278 ,val loss : 0.107007 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :295 ]train loss : 0.071358 ,train acc: 0.997864 ,val loss : 0.105346 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :296 ]train loss : 0.066486 ,train acc: 0.997314 ,val loss : 0.108206 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :297 ]train loss : 0.098435 ,train acc: 0.992767 ,val loss : 0.109083 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :298 ]train loss : 0.097165 ,train acc: 0.993561 ,val loss : 0.106759 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :299 ]train loss : 0.090465 ,train acc: 0.997711 ,val loss : 0.106523 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :300 ]train loss : 0.060415 ,train acc: 0.998474 ,val loss : 0.107025 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :301 ]train loss : 0.338899 ,train acc: 0.783630 ,val loss : 0.107019 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :302 ]train loss : 0.114367 ,train acc: 0.982208 ,val loss : 0.107598 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :303 ]train loss : 0.396088 ,train acc: 0.766937 ,val loss : 0.109654 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :304 ]train loss : 0.701786 ,train acc: 0.445587 ,val loss : 0.108847 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :305 ]train loss : 0.376631 ,train acc: 0.752930 ,val loss : 0.106514 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :306 ]train loss : 0.163640 ,train acc: 0.944733 ,val loss : 0.108145 ,val acc : 0.991455\n",
      "[ ecpho : 4  iter :307 ]train loss : 0.354191 ,train acc: 0.808197 ,val loss : 0.110361 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :308 ]train loss : 0.121637 ,train acc: 0.972137 ,val loss : 0.109882 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :309 ]train loss : 0.078094 ,train acc: 0.997803 ,val loss : 0.109383 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :310 ]train loss : 0.277677 ,train acc: 0.893311 ,val loss : 0.108801 ,val acc : 0.991455\n",
      "[ ecpho : 4  iter :311 ]train loss : 0.073965 ,train acc: 0.992798 ,val loss : 0.108185 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :312 ]train loss : 0.054797 ,train acc: 0.999237 ,val loss : 0.107601 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :313 ]train loss : 0.096030 ,train acc: 0.977692 ,val loss : 0.109162 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :314 ]train loss : 0.345530 ,train acc: 0.826965 ,val loss : 0.108823 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :315 ]train loss : 0.086981 ,train acc: 0.990234 ,val loss : 0.109688 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :316 ]train loss : 0.056992 ,train acc: 0.998047 ,val loss : 0.108360 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :317 ]train loss : 0.143680 ,train acc: 0.958069 ,val loss : 0.109964 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :318 ]train loss : 0.103729 ,train acc: 0.975311 ,val loss : 0.109165 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :319 ]train loss : 0.159737 ,train acc: 0.933380 ,val loss : 0.108690 ,val acc : 0.991302\n",
      "[ ecpho : 4  iter :320 ]train loss : 0.090249 ,train acc: 0.996460 ,val loss : 0.107915 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :321 ]train loss : 0.100712 ,train acc: 0.992249 ,val loss : 0.109629 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :322 ]train loss : 0.071185 ,train acc: 0.993683 ,val loss : 0.108665 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :323 ]train loss : 0.065814 ,train acc: 0.997131 ,val loss : 0.110701 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :324 ]train loss : 0.611881 ,train acc: 0.687714 ,val loss : 0.110262 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :325 ]train loss : 0.078900 ,train acc: 0.990784 ,val loss : 0.111328 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :326 ]train loss : 0.067299 ,train acc: 0.994354 ,val loss : 0.107442 ,val acc : 0.991364\n",
      "[ ecpho : 4  iter :327 ]train loss : 0.082698 ,train acc: 0.995941 ,val loss : 0.107881 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :328 ]train loss : 0.073918 ,train acc: 0.993958 ,val loss : 0.107747 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :329 ]train loss : 0.358048 ,train acc: 0.808502 ,val loss : 0.108615 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :330 ]train loss : 0.161470 ,train acc: 0.932739 ,val loss : 0.110765 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :331 ]train loss : 0.102683 ,train acc: 0.992676 ,val loss : 0.109915 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :332 ]train loss : 0.191110 ,train acc: 0.930267 ,val loss : 0.110742 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :333 ]train loss : 0.099143 ,train acc: 0.978912 ,val loss : 0.109972 ,val acc : 0.991455\n",
      "[ ecpho : 4  iter :334 ]train loss : 0.078223 ,train acc: 0.993286 ,val loss : 0.106322 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :335 ]train loss : 0.107388 ,train acc: 0.989838 ,val loss : 0.105791 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :336 ]train loss : 0.944325 ,train acc: 0.382721 ,val loss : 0.110594 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :337 ]train loss : 0.484227 ,train acc: 0.669281 ,val loss : 0.108372 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :338 ]train loss : 0.103154 ,train acc: 0.979034 ,val loss : 0.109729 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :339 ]train loss : 0.075140 ,train acc: 0.992218 ,val loss : 0.108190 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :340 ]train loss : 0.133467 ,train acc: 0.951385 ,val loss : 0.108483 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :341 ]train loss : 0.098696 ,train acc: 0.983978 ,val loss : 0.108148 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :342 ]train loss : 0.138189 ,train acc: 0.961639 ,val loss : 0.108464 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :343 ]train loss : 0.897969 ,train acc: 0.348663 ,val loss : 0.106376 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :344 ]train loss : 0.064310 ,train acc: 0.995087 ,val loss : 0.108092 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :345 ]train loss : 0.480219 ,train acc: 0.639404 ,val loss : 0.108421 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :346 ]train loss : 0.268188 ,train acc: 0.886902 ,val loss : 0.107574 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :347 ]train loss : 0.091334 ,train acc: 0.985168 ,val loss : 0.109957 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :348 ]train loss : 0.104593 ,train acc: 0.983582 ,val loss : 0.109491 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :349 ]train loss : 0.100306 ,train acc: 0.994781 ,val loss : 0.108855 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :350 ]train loss : 0.092425 ,train acc: 0.984467 ,val loss : 0.109699 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :351 ]train loss : 0.081590 ,train acc: 0.997284 ,val loss : 0.111228 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :352 ]train loss : 0.115046 ,train acc: 0.983673 ,val loss : 0.109633 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :353 ]train loss : 0.073051 ,train acc: 0.992310 ,val loss : 0.112283 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :354 ]train loss : 0.087835 ,train acc: 0.988312 ,val loss : 0.107042 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :355 ]train loss : 0.072193 ,train acc: 0.998383 ,val loss : 0.109787 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :356 ]train loss : 0.096126 ,train acc: 0.995911 ,val loss : 0.107257 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :357 ]train loss : 0.117627 ,train acc: 0.983917 ,val loss : 0.111497 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :358 ]train loss : 0.086200 ,train acc: 0.994690 ,val loss : 0.109391 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :359 ]train loss : 0.159501 ,train acc: 0.944489 ,val loss : 0.112516 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :360 ]train loss : 0.091771 ,train acc: 0.995636 ,val loss : 0.113173 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :361 ]train loss : 0.089586 ,train acc: 0.982300 ,val loss : 0.108692 ,val acc : 0.991455\n",
      "[ ecpho : 4  iter :362 ]train loss : 0.058374 ,train acc: 0.997620 ,val loss : 0.108281 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :363 ]train loss : 0.164324 ,train acc: 0.939545 ,val loss : 0.109418 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :364 ]train loss : 0.093299 ,train acc: 0.995575 ,val loss : 0.109775 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :365 ]train loss : 0.392531 ,train acc: 0.773590 ,val loss : 0.111885 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :366 ]train loss : 0.068272 ,train acc: 0.995178 ,val loss : 0.107117 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :367 ]train loss : 0.322884 ,train acc: 0.793823 ,val loss : 0.109991 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :368 ]train loss : 0.106689 ,train acc: 0.977997 ,val loss : 0.109913 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :369 ]train loss : 0.097572 ,train acc: 0.977875 ,val loss : 0.109268 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :370 ]train loss : 0.225031 ,train acc: 0.877594 ,val loss : 0.109196 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :371 ]train loss : 0.172225 ,train acc: 0.919220 ,val loss : 0.107897 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :372 ]train loss : 0.452882 ,train acc: 0.726471 ,val loss : 0.111219 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :373 ]train loss : 0.076509 ,train acc: 0.992493 ,val loss : 0.111083 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :374 ]train loss : 0.073947 ,train acc: 0.998444 ,val loss : 0.110972 ,val acc : 0.991089\n",
      "[ ecpho : 4  iter :375 ]train loss : 0.076319 ,train acc: 0.989777 ,val loss : 0.110630 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :376 ]train loss : 0.088600 ,train acc: 0.996979 ,val loss : 0.109919 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :377 ]train loss : 0.126493 ,train acc: 0.963623 ,val loss : 0.108935 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :378 ]train loss : 0.244793 ,train acc: 0.885376 ,val loss : 0.111485 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :379 ]train loss : 0.091956 ,train acc: 0.979004 ,val loss : 0.109648 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :380 ]train loss : 0.078872 ,train acc: 0.986603 ,val loss : 0.110292 ,val acc : 0.991241\n",
      "[ ecpho : 4  iter :381 ]train loss : 0.267939 ,train acc: 0.860870 ,val loss : 0.109835 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :382 ]train loss : 0.147760 ,train acc: 0.943542 ,val loss : 0.109730 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :383 ]train loss : 0.111573 ,train acc: 0.987061 ,val loss : 0.109004 ,val acc : 0.990845\n",
      "[ ecpho : 4  iter :384 ]train loss : 0.085148 ,train acc: 0.985931 ,val loss : 0.110304 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :385 ]train loss : 0.087958 ,train acc: 0.992737 ,val loss : 0.108993 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :386 ]train loss : 0.097529 ,train acc: 0.978424 ,val loss : 0.107663 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :387 ]train loss : 0.119362 ,train acc: 0.989319 ,val loss : 0.110136 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :388 ]train loss : 0.066282 ,train acc: 0.998840 ,val loss : 0.109654 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :389 ]train loss : 0.087434 ,train acc: 0.989990 ,val loss : 0.107626 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :390 ]train loss : 0.341092 ,train acc: 0.823608 ,val loss : 0.109625 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :391 ]train loss : 0.476421 ,train acc: 0.668060 ,val loss : 0.108500 ,val acc : 0.991455\n",
      "[ ecpho : 4  iter :392 ]train loss : 0.074238 ,train acc: 0.991821 ,val loss : 0.109638 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :393 ]train loss : 0.090006 ,train acc: 0.985168 ,val loss : 0.110004 ,val acc : 0.991241\n",
      "[ ecpho : 4  iter :394 ]train loss : 0.072264 ,train acc: 0.994446 ,val loss : 0.109117 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :395 ]train loss : 0.102673 ,train acc: 0.979492 ,val loss : 0.109203 ,val acc : 0.991455\n",
      "[ ecpho : 4  iter :396 ]train loss : 0.688675 ,train acc: 0.557953 ,val loss : 0.111477 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :397 ]train loss : 0.072608 ,train acc: 0.997620 ,val loss : 0.111179 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :398 ]train loss : 0.149458 ,train acc: 0.953674 ,val loss : 0.113902 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :399 ]train loss : 0.078049 ,train acc: 0.989502 ,val loss : 0.109483 ,val acc : 0.991089\n",
      "[ ecpho : 4  iter :400 ]train loss : 0.074368 ,train acc: 0.997101 ,val loss : 0.109734 ,val acc : 0.991058\n",
      "[ ecpho : 4  iter :401 ]train loss : 0.149191 ,train acc: 0.943939 ,val loss : 0.111407 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :402 ]train loss : 0.197254 ,train acc: 0.901398 ,val loss : 0.111425 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :403 ]train loss : 0.070089 ,train acc: 0.997101 ,val loss : 0.108990 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :404 ]train loss : 0.072708 ,train acc: 0.997192 ,val loss : 0.109979 ,val acc : 0.991364\n",
      "[ ecpho : 4  iter :405 ]train loss : 0.069429 ,train acc: 0.997650 ,val loss : 0.112934 ,val acc : 0.991333\n",
      "[ ecpho : 4  iter :406 ]train loss : 0.087133 ,train acc: 0.982819 ,val loss : 0.110595 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :407 ]train loss : 0.066252 ,train acc: 0.998535 ,val loss : 0.111321 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :408 ]train loss : 0.599675 ,train acc: 0.602051 ,val loss : 0.111256 ,val acc : 0.991058\n",
      "[ ecpho : 4  iter :409 ]train loss : 0.267859 ,train acc: 0.832703 ,val loss : 0.110513 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :410 ]train loss : 0.152537 ,train acc: 0.940735 ,val loss : 0.111147 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :411 ]train loss : 0.084929 ,train acc: 0.992462 ,val loss : 0.109070 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :412 ]train loss : 0.246972 ,train acc: 0.888245 ,val loss : 0.109868 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :413 ]train loss : 0.108166 ,train acc: 0.968140 ,val loss : 0.111117 ,val acc : 0.991364\n",
      "[ ecpho : 4  iter :414 ]train loss : 0.083965 ,train acc: 0.989380 ,val loss : 0.108901 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :415 ]train loss : 0.072042 ,train acc: 0.997620 ,val loss : 0.112037 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :416 ]train loss : 0.280762 ,train acc: 0.827240 ,val loss : 0.108068 ,val acc : 0.991150\n",
      "[ ecpho : 4  iter :417 ]train loss : 0.088358 ,train acc: 0.996246 ,val loss : 0.109875 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :418 ]train loss : 0.551834 ,train acc: 0.610016 ,val loss : 0.109819 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :419 ]train loss : 0.060515 ,train acc: 0.997772 ,val loss : 0.114440 ,val acc : 0.990967\n",
      "[ ecpho : 4  iter :420 ]train loss : 0.091183 ,train acc: 0.979431 ,val loss : 0.111388 ,val acc : 0.990631\n",
      "[ ecpho : 4  iter :421 ]train loss : 0.083764 ,train acc: 0.993683 ,val loss : 0.110236 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :422 ]train loss : 0.218258 ,train acc: 0.874725 ,val loss : 0.112105 ,val acc : 0.990356\n",
      "[ ecpho : 4  iter :423 ]train loss : 0.109425 ,train acc: 0.982269 ,val loss : 0.110996 ,val acc : 0.990936\n",
      "[ ecpho : 4  iter :424 ]train loss : 0.106196 ,train acc: 0.977051 ,val loss : 0.111035 ,val acc : 0.990814\n",
      "[ ecpho : 4  iter :425 ]train loss : 0.110760 ,train acc: 0.967163 ,val loss : 0.112553 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :426 ]train loss : 0.069948 ,train acc: 0.992157 ,val loss : 0.111967 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :427 ]train loss : 0.115470 ,train acc: 0.968506 ,val loss : 0.108982 ,val acc : 0.991058\n",
      "[ ecpho : 4  iter :428 ]train loss : 0.147629 ,train acc: 0.941162 ,val loss : 0.110574 ,val acc : 0.990936\n",
      "[ ecpho : 4  iter :429 ]train loss : 0.087416 ,train acc: 0.990906 ,val loss : 0.110820 ,val acc : 0.990631\n",
      "[ ecpho : 4  iter :430 ]train loss : 0.105818 ,train acc: 0.980865 ,val loss : 0.113093 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :431 ]train loss : 0.104422 ,train acc: 0.984131 ,val loss : 0.111290 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :432 ]train loss : 0.076717 ,train acc: 0.990265 ,val loss : 0.109817 ,val acc : 0.991028\n",
      "[ ecpho : 4  iter :433 ]train loss : 0.081371 ,train acc: 0.989655 ,val loss : 0.113348 ,val acc : 0.990479\n",
      "[ ecpho : 4  iter :434 ]train loss : 0.417226 ,train acc: 0.766998 ,val loss : 0.114891 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :435 ]train loss : 0.076243 ,train acc: 0.993378 ,val loss : 0.109420 ,val acc : 0.990845\n",
      "[ ecpho : 4  iter :436 ]train loss : 0.072665 ,train acc: 0.994293 ,val loss : 0.110937 ,val acc : 0.990723\n",
      "[ ecpho : 4  iter :437 ]train loss : 0.081076 ,train acc: 0.988922 ,val loss : 0.111438 ,val acc : 0.990753\n",
      "[ ecpho : 4  iter :438 ]train loss : 0.113555 ,train acc: 0.974365 ,val loss : 0.112646 ,val acc : 0.990601\n",
      "[ ecpho : 4  iter :439 ]train loss : 0.166331 ,train acc: 0.934265 ,val loss : 0.111198 ,val acc : 0.991058\n",
      "[ ecpho : 4  iter :440 ]train loss : 0.968410 ,train acc: 0.335052 ,val loss : 0.113596 ,val acc : 0.990936\n",
      "[ ecpho : 4  iter :441 ]train loss : 0.088938 ,train acc: 0.985840 ,val loss : 0.113940 ,val acc : 0.990631\n",
      "[ ecpho : 4  iter :442 ]train loss : 0.065173 ,train acc: 0.995026 ,val loss : 0.110460 ,val acc : 0.990814\n",
      "[ ecpho : 4  iter :443 ]train loss : 0.066510 ,train acc: 0.996277 ,val loss : 0.111803 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :444 ]train loss : 0.068396 ,train acc: 0.997101 ,val loss : 0.110972 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :445 ]train loss : 0.064737 ,train acc: 0.996490 ,val loss : 0.111373 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :446 ]train loss : 0.075069 ,train acc: 0.989319 ,val loss : 0.111441 ,val acc : 0.991211\n",
      "[ ecpho : 4  iter :447 ]train loss : 0.146578 ,train acc: 0.973053 ,val loss : 0.112760 ,val acc : 0.991211\n",
      "[ ecpho : 4  iter :448 ]train loss : 0.597354 ,train acc: 0.660553 ,val loss : 0.112207 ,val acc : 0.990784\n",
      "[ ecpho : 4  iter :449 ]train loss : 0.058138 ,train acc: 0.998108 ,val loss : 0.112733 ,val acc : 0.991211\n",
      "[ ecpho : 4  iter :450 ]train loss : 0.087994 ,train acc: 0.986877 ,val loss : 0.112066 ,val acc : 0.990906\n",
      "[ ecpho : 4  iter :451 ]train loss : 0.086400 ,train acc: 0.997253 ,val loss : 0.112282 ,val acc : 0.990845\n",
      "[ ecpho : 4  iter :452 ]train loss : 0.092514 ,train acc: 0.995300 ,val loss : 0.112839 ,val acc : 0.990997\n",
      "[ ecpho : 4  iter :453 ]train loss : 0.126798 ,train acc: 0.980316 ,val loss : 0.109880 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :454 ]train loss : 0.301322 ,train acc: 0.863098 ,val loss : 0.109525 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :455 ]train loss : 0.071528 ,train acc: 0.996826 ,val loss : 0.110945 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :456 ]train loss : 0.191973 ,train acc: 0.947510 ,val loss : 0.110151 ,val acc : 0.991119\n",
      "[ ecpho : 4  iter :457 ]train loss : 0.175425 ,train acc: 0.930145 ,val loss : 0.108282 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :458 ]train loss : 0.160073 ,train acc: 0.976196 ,val loss : 0.110609 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :459 ]train loss : 0.091115 ,train acc: 0.991974 ,val loss : 0.110064 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :460 ]train loss : 0.089797 ,train acc: 0.994446 ,val loss : 0.108702 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :461 ]train loss : 0.739861 ,train acc: 0.419373 ,val loss : 0.112458 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :462 ]train loss : 0.172189 ,train acc: 0.920441 ,val loss : 0.110233 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :463 ]train loss : 0.064998 ,train acc: 0.997223 ,val loss : 0.111559 ,val acc : 0.991272\n",
      "[ ecpho : 4  iter :464 ]train loss : 0.187470 ,train acc: 0.947876 ,val loss : 0.111550 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :465 ]train loss : 0.076733 ,train acc: 0.992188 ,val loss : 0.111402 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :466 ]train loss : 0.133686 ,train acc: 0.986084 ,val loss : 0.110417 ,val acc : 0.991302\n",
      "[ ecpho : 4  iter :467 ]train loss : 0.065195 ,train acc: 0.998322 ,val loss : 0.110918 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :468 ]train loss : 1.122649 ,train acc: 0.234589 ,val loss : 0.111670 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :469 ]train loss : 0.111280 ,train acc: 0.983490 ,val loss : 0.107541 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :470 ]train loss : 0.102360 ,train acc: 0.979095 ,val loss : 0.111647 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :471 ]train loss : 0.080873 ,train acc: 0.984955 ,val loss : 0.110611 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :472 ]train loss : 0.078302 ,train acc: 0.991333 ,val loss : 0.112899 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :473 ]train loss : 0.074765 ,train acc: 0.993500 ,val loss : 0.108974 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :474 ]train loss : 0.114507 ,train acc: 0.985748 ,val loss : 0.109530 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :475 ]train loss : 0.206404 ,train acc: 0.899963 ,val loss : 0.112778 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :476 ]train loss : 0.183849 ,train acc: 0.916718 ,val loss : 0.111215 ,val acc : 0.991180\n",
      "[ ecpho : 4  iter :477 ]train loss : 0.170949 ,train acc: 0.926208 ,val loss : 0.109972 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :478 ]train loss : 0.063192 ,train acc: 0.998322 ,val loss : 0.109347 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :479 ]train loss : 0.206339 ,train acc: 0.897980 ,val loss : 0.110532 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :480 ]train loss : 0.079645 ,train acc: 0.987518 ,val loss : 0.109430 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :481 ]train loss : 0.481879 ,train acc: 0.663727 ,val loss : 0.111214 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :482 ]train loss : 0.109641 ,train acc: 0.974884 ,val loss : 0.108778 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :483 ]train loss : 0.163386 ,train acc: 0.939392 ,val loss : 0.111005 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :484 ]train loss : 0.139450 ,train acc: 0.945892 ,val loss : 0.108024 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :485 ]train loss : 1.094551 ,train acc: 0.249420 ,val loss : 0.110654 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :486 ]train loss : 0.273812 ,train acc: 0.828613 ,val loss : 0.107048 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :487 ]train loss : 0.089152 ,train acc: 0.986847 ,val loss : 0.112410 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :488 ]train loss : 0.088802 ,train acc: 0.993622 ,val loss : 0.110825 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :489 ]train loss : 0.105154 ,train acc: 0.981049 ,val loss : 0.109295 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :490 ]train loss : 0.070817 ,train acc: 0.993073 ,val loss : 0.110095 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :491 ]train loss : 0.077298 ,train acc: 0.993835 ,val loss : 0.109392 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :492 ]train loss : 0.055168 ,train acc: 0.999512 ,val loss : 0.110108 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :493 ]train loss : 0.077112 ,train acc: 0.990692 ,val loss : 0.108617 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :494 ]train loss : 0.114642 ,train acc: 0.989532 ,val loss : 0.110958 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :495 ]train loss : 0.237436 ,train acc: 0.883698 ,val loss : 0.110594 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :496 ]train loss : 0.268703 ,train acc: 0.841583 ,val loss : 0.110978 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :497 ]train loss : 0.080498 ,train acc: 0.983429 ,val loss : 0.106980 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :498 ]train loss : 0.094791 ,train acc: 0.994354 ,val loss : 0.109515 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :499 ]train loss : 0.307858 ,train acc: 0.850555 ,val loss : 0.110518 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :500 ]train loss : 0.081489 ,train acc: 0.988922 ,val loss : 0.108267 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :501 ]train loss : 0.118172 ,train acc: 0.985962 ,val loss : 0.111918 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :502 ]train loss : 0.077783 ,train acc: 0.996704 ,val loss : 0.110165 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :503 ]train loss : 0.100405 ,train acc: 0.983337 ,val loss : 0.110160 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :504 ]train loss : 0.262634 ,train acc: 0.856201 ,val loss : 0.109676 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :505 ]train loss : 0.239903 ,train acc: 0.866547 ,val loss : 0.109413 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :506 ]train loss : 0.092395 ,train acc: 0.980927 ,val loss : 0.109903 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :507 ]train loss : 0.083576 ,train acc: 0.995331 ,val loss : 0.110348 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :508 ]train loss : 0.144152 ,train acc: 0.958344 ,val loss : 0.110876 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :509 ]train loss : 0.075839 ,train acc: 0.995087 ,val loss : 0.109101 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :510 ]train loss : 0.065402 ,train acc: 0.998169 ,val loss : 0.108713 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :511 ]train loss : 0.117545 ,train acc: 0.961731 ,val loss : 0.111339 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :512 ]train loss : 0.074930 ,train acc: 0.990997 ,val loss : 0.109196 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :513 ]train loss : 0.187860 ,train acc: 0.902527 ,val loss : 0.108416 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :514 ]train loss : 0.091410 ,train acc: 0.983185 ,val loss : 0.110638 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :515 ]train loss : 1.265741 ,train acc: 0.155151 ,val loss : 0.108243 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :516 ]train loss : 0.059607 ,train acc: 0.996704 ,val loss : 0.107666 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :517 ]train loss : 0.231906 ,train acc: 0.876801 ,val loss : 0.111672 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :518 ]train loss : 0.103704 ,train acc: 0.990753 ,val loss : 0.110394 ,val acc : 0.991547\n",
      "[ ecpho : 4  iter :519 ]train loss : 0.073117 ,train acc: 0.989838 ,val loss : 0.109847 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :520 ]train loss : 0.147688 ,train acc: 0.953583 ,val loss : 0.109595 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :521 ]train loss : 0.100083 ,train acc: 0.992737 ,val loss : 0.108198 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :522 ]train loss : 0.118553 ,train acc: 0.978851 ,val loss : 0.108341 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :523 ]train loss : 0.245791 ,train acc: 0.890137 ,val loss : 0.108119 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :524 ]train loss : 0.083830 ,train acc: 0.984467 ,val loss : 0.110731 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :525 ]train loss : 0.402189 ,train acc: 0.711975 ,val loss : 0.108366 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :526 ]train loss : 0.131242 ,train acc: 0.976593 ,val loss : 0.106981 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :527 ]train loss : 0.079656 ,train acc: 0.988281 ,val loss : 0.108901 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :528 ]train loss : 0.137461 ,train acc: 0.958069 ,val loss : 0.113627 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :529 ]train loss : 0.167330 ,train acc: 0.957306 ,val loss : 0.109634 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :530 ]train loss : 0.063998 ,train acc: 0.996277 ,val loss : 0.106579 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :531 ]train loss : 0.183461 ,train acc: 0.927307 ,val loss : 0.107012 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :532 ]train loss : 0.096525 ,train acc: 0.975159 ,val loss : 0.110527 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :533 ]train loss : 0.076232 ,train acc: 0.988342 ,val loss : 0.110602 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :534 ]train loss : 0.059350 ,train acc: 0.995636 ,val loss : 0.111979 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :535 ]train loss : 0.592430 ,train acc: 0.615051 ,val loss : 0.109759 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :536 ]train loss : 0.087203 ,train acc: 0.997070 ,val loss : 0.109074 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :537 ]train loss : 0.071714 ,train acc: 0.997864 ,val loss : 0.108742 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :538 ]train loss : 0.082317 ,train acc: 0.993805 ,val loss : 0.108327 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :539 ]train loss : 0.092129 ,train acc: 0.990784 ,val loss : 0.108566 ,val acc : 0.991516\n",
      "[ ecpho : 4  iter :540 ]train loss : 0.066351 ,train acc: 0.997192 ,val loss : 0.106800 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :541 ]train loss : 0.096294 ,train acc: 0.994843 ,val loss : 0.108776 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :542 ]train loss : 0.080930 ,train acc: 0.991211 ,val loss : 0.109465 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :543 ]train loss : 0.098813 ,train acc: 0.985596 ,val loss : 0.113900 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :544 ]train loss : 0.085633 ,train acc: 0.998322 ,val loss : 0.108177 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :545 ]train loss : 0.106198 ,train acc: 0.983978 ,val loss : 0.110376 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :546 ]train loss : 0.073178 ,train acc: 0.997101 ,val loss : 0.111688 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :547 ]train loss : 0.082745 ,train acc: 0.995605 ,val loss : 0.112074 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :548 ]train loss : 0.100035 ,train acc: 0.993347 ,val loss : 0.109550 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :549 ]train loss : 0.078128 ,train acc: 0.994080 ,val loss : 0.108712 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :550 ]train loss : 0.084541 ,train acc: 0.990143 ,val loss : 0.110777 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :551 ]train loss : 0.092831 ,train acc: 0.991577 ,val loss : 0.112898 ,val acc : 0.991730\n",
      "[ ecpho : 4  iter :552 ]train loss : 0.093146 ,train acc: 0.979614 ,val loss : 0.108388 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :553 ]train loss : 0.096128 ,train acc: 0.993103 ,val loss : 0.110264 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :554 ]train loss : 0.114594 ,train acc: 0.968658 ,val loss : 0.107545 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :555 ]train loss : 0.087980 ,train acc: 0.988037 ,val loss : 0.108433 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :556 ]train loss : 0.286877 ,train acc: 0.839020 ,val loss : 0.108823 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :557 ]train loss : 0.126180 ,train acc: 0.964111 ,val loss : 0.107335 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :558 ]train loss : 0.195943 ,train acc: 0.902527 ,val loss : 0.109307 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :559 ]train loss : 0.068609 ,train acc: 0.995056 ,val loss : 0.109428 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :560 ]train loss : 0.065074 ,train acc: 0.997986 ,val loss : 0.107194 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :561 ]train loss : 0.073907 ,train acc: 0.998596 ,val loss : 0.108155 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :562 ]train loss : 0.107351 ,train acc: 0.990845 ,val loss : 0.107060 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :563 ]train loss : 0.077914 ,train acc: 0.994812 ,val loss : 0.107508 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :564 ]train loss : 0.053464 ,train acc: 0.999542 ,val loss : 0.106846 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :565 ]train loss : 0.064056 ,train acc: 0.994720 ,val loss : 0.111147 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :566 ]train loss : 0.175144 ,train acc: 0.918304 ,val loss : 0.108267 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :567 ]train loss : 0.076979 ,train acc: 0.987244 ,val loss : 0.111060 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :568 ]train loss : 0.098932 ,train acc: 0.983093 ,val loss : 0.109004 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :569 ]train loss : 0.086404 ,train acc: 0.993225 ,val loss : 0.110635 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :570 ]train loss : 0.088039 ,train acc: 0.997894 ,val loss : 0.109403 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :571 ]train loss : 0.108469 ,train acc: 0.968506 ,val loss : 0.110202 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :572 ]train loss : 0.136325 ,train acc: 0.979248 ,val loss : 0.106535 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :573 ]train loss : 0.385218 ,train acc: 0.724854 ,val loss : 0.107463 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :574 ]train loss : 0.132153 ,train acc: 0.961792 ,val loss : 0.108511 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :575 ]train loss : 0.104117 ,train acc: 0.993011 ,val loss : 0.108437 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :576 ]train loss : 0.931272 ,train acc: 0.345245 ,val loss : 0.106965 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :577 ]train loss : 0.118395 ,train acc: 0.985565 ,val loss : 0.110701 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :578 ]train loss : 0.121316 ,train acc: 0.968231 ,val loss : 0.107953 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :579 ]train loss : 0.190153 ,train acc: 0.942566 ,val loss : 0.108300 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :580 ]train loss : 0.103548 ,train acc: 0.995789 ,val loss : 0.106757 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :581 ]train loss : 0.074759 ,train acc: 0.997589 ,val loss : 0.106471 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :582 ]train loss : 0.081366 ,train acc: 0.992188 ,val loss : 0.106786 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :583 ]train loss : 0.698954 ,train acc: 0.505280 ,val loss : 0.105381 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :584 ]train loss : 0.083609 ,train acc: 0.998383 ,val loss : 0.107313 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :585 ]train loss : 0.085842 ,train acc: 0.998016 ,val loss : 0.108947 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :586 ]train loss : 0.087118 ,train acc: 0.997559 ,val loss : 0.105280 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :587 ]train loss : 0.111655 ,train acc: 0.972504 ,val loss : 0.106248 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :588 ]train loss : 0.087351 ,train acc: 0.998230 ,val loss : 0.109170 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :589 ]train loss : 0.087961 ,train acc: 0.989838 ,val loss : 0.107838 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :590 ]train loss : 0.077361 ,train acc: 0.992279 ,val loss : 0.109368 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :591 ]train loss : 0.193682 ,train acc: 0.946808 ,val loss : 0.107787 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :592 ]train loss : 0.100916 ,train acc: 0.981293 ,val loss : 0.105529 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :593 ]train loss : 0.081330 ,train acc: 0.994659 ,val loss : 0.108674 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :594 ]train loss : 0.081157 ,train acc: 0.994110 ,val loss : 0.109484 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :595 ]train loss : 0.091272 ,train acc: 0.992493 ,val loss : 0.106960 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :596 ]train loss : 0.074489 ,train acc: 0.997406 ,val loss : 0.107152 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :597 ]train loss : 0.074146 ,train acc: 0.992828 ,val loss : 0.109711 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :598 ]train loss : 0.084493 ,train acc: 0.986023 ,val loss : 0.105851 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :599 ]train loss : 0.107909 ,train acc: 0.972931 ,val loss : 0.107184 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :600 ]train loss : 0.107663 ,train acc: 0.980652 ,val loss : 0.108140 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :601 ]train loss : 0.104703 ,train acc: 0.986298 ,val loss : 0.107938 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :602 ]train loss : 0.393588 ,train acc: 0.747620 ,val loss : 0.108063 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :603 ]train loss : 0.085252 ,train acc: 0.985809 ,val loss : 0.105105 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :604 ]train loss : 0.060207 ,train acc: 0.998047 ,val loss : 0.105578 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :605 ]train loss : 0.086576 ,train acc: 0.992828 ,val loss : 0.106445 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :606 ]train loss : 0.106763 ,train acc: 0.969910 ,val loss : 0.104663 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :607 ]train loss : 0.064463 ,train acc: 0.998840 ,val loss : 0.108441 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :608 ]train loss : 0.090381 ,train acc: 0.987366 ,val loss : 0.105167 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :609 ]train loss : 0.284492 ,train acc: 0.848969 ,val loss : 0.105478 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :610 ]train loss : 0.118909 ,train acc: 0.964203 ,val loss : 0.109403 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :611 ]train loss : 0.097877 ,train acc: 0.993713 ,val loss : 0.104595 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :612 ]train loss : 0.076158 ,train acc: 0.997375 ,val loss : 0.107299 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :613 ]train loss : 0.135999 ,train acc: 0.954651 ,val loss : 0.108783 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :614 ]train loss : 0.082208 ,train acc: 0.994934 ,val loss : 0.107127 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :615 ]train loss : 0.070676 ,train acc: 0.997894 ,val loss : 0.110436 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :616 ]train loss : 0.085643 ,train acc: 0.996582 ,val loss : 0.107543 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :617 ]train loss : 0.064851 ,train acc: 0.996643 ,val loss : 0.107539 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :618 ]train loss : 0.089786 ,train acc: 0.998383 ,val loss : 0.107460 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :619 ]train loss : 0.077151 ,train acc: 0.994080 ,val loss : 0.106642 ,val acc : 0.992828\n",
      "[ ecpho : 4  iter :620 ]train loss : 0.118719 ,train acc: 0.981598 ,val loss : 0.106066 ,val acc : 0.992767\n",
      "[ ecpho : 4  iter :621 ]train loss : 0.092389 ,train acc: 0.996735 ,val loss : 0.107416 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :622 ]train loss : 0.093645 ,train acc: 0.988647 ,val loss : 0.106225 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :623 ]train loss : 0.080106 ,train acc: 0.990723 ,val loss : 0.107376 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :624 ]train loss : 0.073271 ,train acc: 0.998688 ,val loss : 0.105839 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :625 ]train loss : 0.084009 ,train acc: 0.991516 ,val loss : 0.105103 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :626 ]train loss : 0.101355 ,train acc: 0.996796 ,val loss : 0.106050 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :627 ]train loss : 0.084062 ,train acc: 0.997345 ,val loss : 0.106247 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :628 ]train loss : 0.075716 ,train acc: 0.990265 ,val loss : 0.108947 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :629 ]train loss : 0.242344 ,train acc: 0.869171 ,val loss : 0.107714 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :630 ]train loss : 0.502905 ,train acc: 0.614349 ,val loss : 0.106348 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :631 ]train loss : 0.395185 ,train acc: 0.723389 ,val loss : 0.108995 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :632 ]train loss : 0.060796 ,train acc: 0.998566 ,val loss : 0.106127 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :633 ]train loss : 0.104285 ,train acc: 0.976105 ,val loss : 0.105003 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :634 ]train loss : 0.084115 ,train acc: 0.993988 ,val loss : 0.107866 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :635 ]train loss : 0.422511 ,train acc: 0.749390 ,val loss : 0.105200 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :636 ]train loss : 0.141462 ,train acc: 0.968628 ,val loss : 0.106589 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :637 ]train loss : 0.225188 ,train acc: 0.912659 ,val loss : 0.104874 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :638 ]train loss : 0.107038 ,train acc: 0.979858 ,val loss : 0.106543 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :639 ]train loss : 0.241316 ,train acc: 0.895325 ,val loss : 0.108108 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :640 ]train loss : 0.101779 ,train acc: 0.994720 ,val loss : 0.105491 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :641 ]train loss : 0.127949 ,train acc: 0.982300 ,val loss : 0.105568 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :642 ]train loss : 0.082603 ,train acc: 0.988617 ,val loss : 0.105034 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :643 ]train loss : 0.248003 ,train acc: 0.911194 ,val loss : 0.105038 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :644 ]train loss : 0.086588 ,train acc: 0.989716 ,val loss : 0.105582 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :645 ]train loss : 0.284784 ,train acc: 0.868042 ,val loss : 0.107741 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :646 ]train loss : 0.105441 ,train acc: 0.970215 ,val loss : 0.105708 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :647 ]train loss : 0.090632 ,train acc: 0.996155 ,val loss : 0.105367 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :648 ]train loss : 0.250801 ,train acc: 0.859894 ,val loss : 0.106336 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :649 ]train loss : 0.078405 ,train acc: 0.994141 ,val loss : 0.107622 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :650 ]train loss : 0.382410 ,train acc: 0.795349 ,val loss : 0.106381 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :651 ]train loss : 0.102088 ,train acc: 0.992432 ,val loss : 0.105861 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :652 ]train loss : 0.108983 ,train acc: 0.989319 ,val loss : 0.106522 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :653 ]train loss : 0.073892 ,train acc: 0.998535 ,val loss : 0.107893 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :654 ]train loss : 0.067815 ,train acc: 0.997864 ,val loss : 0.108205 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :655 ]train loss : 0.068940 ,train acc: 0.998932 ,val loss : 0.103878 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :656 ]train loss : 0.122135 ,train acc: 0.958954 ,val loss : 0.109101 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :657 ]train loss : 0.092952 ,train acc: 0.983093 ,val loss : 0.106616 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :658 ]train loss : 0.101250 ,train acc: 0.977814 ,val loss : 0.103273 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :659 ]train loss : 0.095520 ,train acc: 0.997620 ,val loss : 0.106718 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :660 ]train loss : 0.389637 ,train acc: 0.731537 ,val loss : 0.107982 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :661 ]train loss : 0.092343 ,train acc: 0.981628 ,val loss : 0.106882 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :662 ]train loss : 0.139133 ,train acc: 0.973358 ,val loss : 0.102895 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :663 ]train loss : 0.135651 ,train acc: 0.983215 ,val loss : 0.106382 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :664 ]train loss : 0.112779 ,train acc: 0.984375 ,val loss : 0.109626 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :665 ]train loss : 0.057337 ,train acc: 0.998383 ,val loss : 0.107969 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :666 ]train loss : 0.153232 ,train acc: 0.966187 ,val loss : 0.107336 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :667 ]train loss : 0.747505 ,train acc: 0.477386 ,val loss : 0.106078 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :668 ]train loss : 0.088755 ,train acc: 0.983856 ,val loss : 0.109857 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :669 ]train loss : 0.403916 ,train acc: 0.733276 ,val loss : 0.106774 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :670 ]train loss : 0.077150 ,train acc: 0.992584 ,val loss : 0.106532 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :671 ]train loss : 0.163667 ,train acc: 0.928406 ,val loss : 0.107173 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :672 ]train loss : 0.417689 ,train acc: 0.715576 ,val loss : 0.106028 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :673 ]train loss : 0.299022 ,train acc: 0.827820 ,val loss : 0.106690 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :674 ]train loss : 0.069898 ,train acc: 0.993378 ,val loss : 0.105007 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :675 ]train loss : 0.866651 ,train acc: 0.400269 ,val loss : 0.107016 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :676 ]train loss : 0.165026 ,train acc: 0.934875 ,val loss : 0.107648 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :677 ]train loss : 0.078851 ,train acc: 0.995270 ,val loss : 0.106833 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :678 ]train loss : 0.085450 ,train acc: 0.993896 ,val loss : 0.106892 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :679 ]train loss : 0.108334 ,train acc: 0.975250 ,val loss : 0.106665 ,val acc : 0.991791\n",
      "[ ecpho : 4  iter :680 ]train loss : 0.086803 ,train acc: 0.993805 ,val loss : 0.106613 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :681 ]train loss : 0.070331 ,train acc: 0.996613 ,val loss : 0.107804 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :682 ]train loss : 1.171768 ,train acc: 0.197479 ,val loss : 0.108319 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :683 ]train loss : 0.134159 ,train acc: 0.957672 ,val loss : 0.107819 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :684 ]train loss : 0.068357 ,train acc: 0.997162 ,val loss : 0.106716 ,val acc : 0.991333\n",
      "[ ecpho : 4  iter :685 ]train loss : 0.069551 ,train acc: 0.997559 ,val loss : 0.105918 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :686 ]train loss : 0.101351 ,train acc: 0.993561 ,val loss : 0.109388 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :687 ]train loss : 0.082410 ,train acc: 0.986267 ,val loss : 0.108513 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :688 ]train loss : 0.436118 ,train acc: 0.731873 ,val loss : 0.109010 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :689 ]train loss : 0.074695 ,train acc: 0.993713 ,val loss : 0.108077 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :690 ]train loss : 0.099210 ,train acc: 0.982544 ,val loss : 0.108333 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :691 ]train loss : 0.100188 ,train acc: 0.986053 ,val loss : 0.107851 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :692 ]train loss : 0.086971 ,train acc: 0.984467 ,val loss : 0.106602 ,val acc : 0.991608\n",
      "[ ecpho : 4  iter :693 ]train loss : 0.073534 ,train acc: 0.993652 ,val loss : 0.107109 ,val acc : 0.991669\n",
      "[ ecpho : 4  iter :694 ]train loss : 0.110509 ,train acc: 0.973145 ,val loss : 0.106406 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :695 ]train loss : 0.110901 ,train acc: 0.984863 ,val loss : 0.108382 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :696 ]train loss : 0.492147 ,train acc: 0.659302 ,val loss : 0.110218 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :697 ]train loss : 0.058945 ,train acc: 0.997589 ,val loss : 0.108443 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :698 ]train loss : 1.421282 ,train acc: 0.020325 ,val loss : 0.109373 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :699 ]train loss : 0.141312 ,train acc: 0.967560 ,val loss : 0.108927 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :700 ]train loss : 0.105021 ,train acc: 0.974426 ,val loss : 0.104459 ,val acc : 0.991577\n",
      "[ ecpho : 4  iter :701 ]train loss : 0.085637 ,train acc: 0.992249 ,val loss : 0.106728 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :702 ]train loss : 0.124280 ,train acc: 0.977936 ,val loss : 0.112358 ,val acc : 0.991394\n",
      "[ ecpho : 4  iter :703 ]train loss : 0.160855 ,train acc: 0.957428 ,val loss : 0.109163 ,val acc : 0.991760\n",
      "[ ecpho : 4  iter :704 ]train loss : 0.135625 ,train acc: 0.981750 ,val loss : 0.110609 ,val acc : 0.991425\n",
      "[ ecpho : 4  iter :705 ]train loss : 0.089072 ,train acc: 0.981415 ,val loss : 0.106988 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :706 ]train loss : 0.063462 ,train acc: 0.997284 ,val loss : 0.107050 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :707 ]train loss : 0.111664 ,train acc: 0.977539 ,val loss : 0.104997 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :708 ]train loss : 0.096865 ,train acc: 0.973572 ,val loss : 0.107728 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :709 ]train loss : 0.094572 ,train acc: 0.993958 ,val loss : 0.108720 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :710 ]train loss : 0.082733 ,train acc: 0.995117 ,val loss : 0.109675 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :711 ]train loss : 0.163449 ,train acc: 0.925629 ,val loss : 0.106547 ,val acc : 0.991699\n",
      "[ ecpho : 4  iter :712 ]train loss : 0.550447 ,train acc: 0.726715 ,val loss : 0.108414 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :713 ]train loss : 0.115401 ,train acc: 0.969574 ,val loss : 0.106430 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :714 ]train loss : 0.098861 ,train acc: 0.975433 ,val loss : 0.108478 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :715 ]train loss : 0.107946 ,train acc: 0.987366 ,val loss : 0.108730 ,val acc : 0.991638\n",
      "[ ecpho : 4  iter :716 ]train loss : 0.087667 ,train acc: 0.987396 ,val loss : 0.107419 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :717 ]train loss : 0.090520 ,train acc: 0.989807 ,val loss : 0.110476 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :718 ]train loss : 0.095687 ,train acc: 0.991302 ,val loss : 0.106596 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :719 ]train loss : 0.096901 ,train acc: 0.991669 ,val loss : 0.106942 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :720 ]train loss : 0.072915 ,train acc: 0.994904 ,val loss : 0.108370 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :721 ]train loss : 0.107262 ,train acc: 0.988586 ,val loss : 0.109435 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :722 ]train loss : 0.088421 ,train acc: 0.981781 ,val loss : 0.108175 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :723 ]train loss : 0.068484 ,train acc: 0.996399 ,val loss : 0.109316 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :724 ]train loss : 0.076118 ,train acc: 0.998474 ,val loss : 0.106821 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :725 ]train loss : 0.116979 ,train acc: 0.984894 ,val loss : 0.106594 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :726 ]train loss : 0.079330 ,train acc: 0.989990 ,val loss : 0.106002 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :727 ]train loss : 0.084527 ,train acc: 0.983276 ,val loss : 0.108673 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :728 ]train loss : 0.400340 ,train acc: 0.741974 ,val loss : 0.109392 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :729 ]train loss : 0.086589 ,train acc: 0.998383 ,val loss : 0.106851 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :730 ]train loss : 0.095856 ,train acc: 0.981903 ,val loss : 0.106369 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :731 ]train loss : 0.114871 ,train acc: 0.987244 ,val loss : 0.104969 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :732 ]train loss : 0.092098 ,train acc: 0.998016 ,val loss : 0.105877 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :733 ]train loss : 0.085668 ,train acc: 0.994202 ,val loss : 0.108790 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :734 ]train loss : 0.090985 ,train acc: 0.985992 ,val loss : 0.108244 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :735 ]train loss : 0.105110 ,train acc: 0.970551 ,val loss : 0.105263 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :736 ]train loss : 0.091608 ,train acc: 0.987274 ,val loss : 0.105743 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :737 ]train loss : 0.103915 ,train acc: 0.970612 ,val loss : 0.107758 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :738 ]train loss : 0.077766 ,train acc: 0.993713 ,val loss : 0.104906 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :739 ]train loss : 0.094813 ,train acc: 0.986053 ,val loss : 0.108734 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :740 ]train loss : 0.066875 ,train acc: 0.994720 ,val loss : 0.106623 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :741 ]train loss : 0.078351 ,train acc: 0.996704 ,val loss : 0.106842 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :742 ]train loss : 0.060924 ,train acc: 0.997528 ,val loss : 0.103744 ,val acc : 0.992859\n",
      "[ ecpho : 4  iter :743 ]train loss : 0.181372 ,train acc: 0.920654 ,val loss : 0.109465 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :744 ]train loss : 0.082168 ,train acc: 0.996735 ,val loss : 0.107130 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :745 ]train loss : 0.190649 ,train acc: 0.948029 ,val loss : 0.106935 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :746 ]train loss : 0.110553 ,train acc: 0.967346 ,val loss : 0.107390 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :747 ]train loss : 0.166529 ,train acc: 0.924438 ,val loss : 0.105606 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :748 ]train loss : 0.637816 ,train acc: 0.604645 ,val loss : 0.107879 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :749 ]train loss : 0.098266 ,train acc: 0.984375 ,val loss : 0.107018 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :750 ]train loss : 0.071199 ,train acc: 0.995758 ,val loss : 0.106723 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :751 ]train loss : 0.096542 ,train acc: 0.977081 ,val loss : 0.106305 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :752 ]train loss : 0.097559 ,train acc: 0.995056 ,val loss : 0.107302 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :753 ]train loss : 0.184216 ,train acc: 0.905792 ,val loss : 0.106905 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :754 ]train loss : 0.087337 ,train acc: 0.998169 ,val loss : 0.108403 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :755 ]train loss : 0.082349 ,train acc: 0.992126 ,val loss : 0.108131 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :756 ]train loss : 0.082466 ,train acc: 0.996979 ,val loss : 0.108586 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :757 ]train loss : 0.091788 ,train acc: 0.982056 ,val loss : 0.106265 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :758 ]train loss : 0.069701 ,train acc: 0.995209 ,val loss : 0.105448 ,val acc : 0.992767\n",
      "[ ecpho : 4  iter :759 ]train loss : 0.130170 ,train acc: 0.970490 ,val loss : 0.106192 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :760 ]train loss : 0.075589 ,train acc: 0.991272 ,val loss : 0.105633 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :761 ]train loss : 0.105523 ,train acc: 0.977234 ,val loss : 0.108344 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :762 ]train loss : 0.200220 ,train acc: 0.926605 ,val loss : 0.105618 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :763 ]train loss : 0.078158 ,train acc: 0.993225 ,val loss : 0.105253 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :764 ]train loss : 0.110860 ,train acc: 0.980621 ,val loss : 0.104902 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :765 ]train loss : 0.111935 ,train acc: 0.975250 ,val loss : 0.106063 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :766 ]train loss : 0.128868 ,train acc: 0.976471 ,val loss : 0.104872 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :767 ]train loss : 0.138191 ,train acc: 0.963837 ,val loss : 0.105468 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :768 ]train loss : 0.283813 ,train acc: 0.920258 ,val loss : 0.106302 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :769 ]train loss : 0.093406 ,train acc: 0.983429 ,val loss : 0.104930 ,val acc : 0.992767\n",
      "[ ecpho : 4  iter :770 ]train loss : 0.061462 ,train acc: 0.997864 ,val loss : 0.106129 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :771 ]train loss : 0.131540 ,train acc: 0.967194 ,val loss : 0.106442 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :772 ]train loss : 0.067634 ,train acc: 0.997437 ,val loss : 0.104796 ,val acc : 0.993011\n",
      "[ ecpho : 4  iter :773 ]train loss : 0.057901 ,train acc: 0.998627 ,val loss : 0.106510 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :774 ]train loss : 0.078543 ,train acc: 0.990143 ,val loss : 0.104824 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :775 ]train loss : 0.060815 ,train acc: 0.996490 ,val loss : 0.105947 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :776 ]train loss : 0.081923 ,train acc: 0.988861 ,val loss : 0.106069 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :777 ]train loss : 0.078867 ,train acc: 0.994354 ,val loss : 0.104161 ,val acc : 0.993073\n",
      "[ ecpho : 4  iter :778 ]train loss : 0.074284 ,train acc: 0.994263 ,val loss : 0.104519 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :779 ]train loss : 0.078005 ,train acc: 0.998413 ,val loss : 0.105633 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :780 ]train loss : 0.077012 ,train acc: 0.993256 ,val loss : 0.105265 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :781 ]train loss : 0.095281 ,train acc: 0.990082 ,val loss : 0.106577 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :782 ]train loss : 0.130112 ,train acc: 0.957214 ,val loss : 0.104107 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :783 ]train loss : 0.089531 ,train acc: 0.996765 ,val loss : 0.104281 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :784 ]train loss : 0.095633 ,train acc: 0.993561 ,val loss : 0.103578 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :785 ]train loss : 0.226521 ,train acc: 0.925842 ,val loss : 0.105657 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :786 ]train loss : 0.497760 ,train acc: 0.637482 ,val loss : 0.105478 ,val acc : 0.992920\n",
      "[ ecpho : 4  iter :787 ]train loss : 0.063811 ,train acc: 0.999084 ,val loss : 0.104979 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :788 ]train loss : 0.082356 ,train acc: 0.992615 ,val loss : 0.104982 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :789 ]train loss : 0.076185 ,train acc: 0.995209 ,val loss : 0.105954 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :790 ]train loss : 0.077747 ,train acc: 0.994720 ,val loss : 0.105236 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :791 ]train loss : 0.109004 ,train acc: 0.971863 ,val loss : 0.104572 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :792 ]train loss : 0.072664 ,train acc: 0.998413 ,val loss : 0.100967 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :793 ]train loss : 0.107385 ,train acc: 0.992401 ,val loss : 0.104860 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :794 ]train loss : 0.100178 ,train acc: 0.988586 ,val loss : 0.107306 ,val acc : 0.992889\n",
      "[ ecpho : 4  iter :795 ]train loss : 0.152053 ,train acc: 0.940277 ,val loss : 0.103337 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :796 ]train loss : 0.219869 ,train acc: 0.875916 ,val loss : 0.104212 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :797 ]train loss : 0.104413 ,train acc: 0.993225 ,val loss : 0.103804 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :798 ]train loss : 0.063203 ,train acc: 0.998444 ,val loss : 0.105012 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :799 ]train loss : 0.061449 ,train acc: 0.997772 ,val loss : 0.105435 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :800 ]train loss : 0.062786 ,train acc: 0.999146 ,val loss : 0.105021 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :801 ]train loss : 0.240639 ,train acc: 0.913910 ,val loss : 0.105827 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :802 ]train loss : 0.459912 ,train acc: 0.692841 ,val loss : 0.104373 ,val acc : 0.992920\n",
      "[ ecpho : 4  iter :803 ]train loss : 0.294270 ,train acc: 0.848969 ,val loss : 0.106171 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :804 ]train loss : 0.089648 ,train acc: 0.993530 ,val loss : 0.104736 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :805 ]train loss : 0.120373 ,train acc: 0.976105 ,val loss : 0.104371 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :806 ]train loss : 0.154924 ,train acc: 0.962158 ,val loss : 0.104724 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :807 ]train loss : 0.060678 ,train acc: 0.998138 ,val loss : 0.106371 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :808 ]train loss : 0.083789 ,train acc: 0.996521 ,val loss : 0.106257 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :809 ]train loss : 0.287687 ,train acc: 0.801086 ,val loss : 0.104808 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :810 ]train loss : 0.108967 ,train acc: 0.988007 ,val loss : 0.102831 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :811 ]train loss : 0.067735 ,train acc: 0.998169 ,val loss : 0.103976 ,val acc : 0.992767\n",
      "[ ecpho : 4  iter :812 ]train loss : 0.080383 ,train acc: 0.993439 ,val loss : 0.105834 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :813 ]train loss : 0.528668 ,train acc: 0.609222 ,val loss : 0.106479 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :814 ]train loss : 0.084956 ,train acc: 0.993866 ,val loss : 0.107657 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :815 ]train loss : 0.095154 ,train acc: 0.992554 ,val loss : 0.104275 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :816 ]train loss : 0.108275 ,train acc: 0.987518 ,val loss : 0.104402 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :817 ]train loss : 0.065076 ,train acc: 0.997772 ,val loss : 0.106489 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :818 ]train loss : 0.123483 ,train acc: 0.965088 ,val loss : 0.106601 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :819 ]train loss : 0.080717 ,train acc: 0.986633 ,val loss : 0.103984 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :820 ]train loss : 0.057589 ,train acc: 0.998627 ,val loss : 0.105473 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :821 ]train loss : 0.074409 ,train acc: 0.990051 ,val loss : 0.106605 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :822 ]train loss : 0.075730 ,train acc: 0.995392 ,val loss : 0.104554 ,val acc : 0.992035\n",
      "[ ecpho : 4  iter :823 ]train loss : 0.074459 ,train acc: 0.994202 ,val loss : 0.105660 ,val acc : 0.991821\n",
      "[ ecpho : 4  iter :824 ]train loss : 0.122448 ,train acc: 0.973480 ,val loss : 0.104475 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :825 ]train loss : 0.062975 ,train acc: 0.999298 ,val loss : 0.104722 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :826 ]train loss : 0.156766 ,train acc: 0.931183 ,val loss : 0.105674 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :827 ]train loss : 0.081639 ,train acc: 0.986298 ,val loss : 0.105418 ,val acc : 0.991913\n",
      "[ ecpho : 4  iter :828 ]train loss : 0.073249 ,train acc: 0.995117 ,val loss : 0.105039 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :829 ]train loss : 0.092034 ,train acc: 0.983673 ,val loss : 0.103154 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :830 ]train loss : 0.153223 ,train acc: 0.961578 ,val loss : 0.106135 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :831 ]train loss : 0.101655 ,train acc: 0.991272 ,val loss : 0.107037 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :832 ]train loss : 0.088120 ,train acc: 0.991425 ,val loss : 0.103415 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :833 ]train loss : 0.071229 ,train acc: 0.997162 ,val loss : 0.103556 ,val acc : 0.991852\n",
      "[ ecpho : 4  iter :834 ]train loss : 0.097322 ,train acc: 0.996094 ,val loss : 0.104258 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :835 ]train loss : 0.106105 ,train acc: 0.985748 ,val loss : 0.105372 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :836 ]train loss : 0.070820 ,train acc: 0.996857 ,val loss : 0.106801 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :837 ]train loss : 0.079911 ,train acc: 0.997406 ,val loss : 0.105434 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :838 ]train loss : 0.114871 ,train acc: 0.966827 ,val loss : 0.106556 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :839 ]train loss : 0.124538 ,train acc: 0.958130 ,val loss : 0.105068 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :840 ]train loss : 0.082788 ,train acc: 0.995331 ,val loss : 0.105083 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :841 ]train loss : 0.143866 ,train acc: 0.962280 ,val loss : 0.104354 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :842 ]train loss : 0.098638 ,train acc: 0.991577 ,val loss : 0.107391 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :843 ]train loss : 0.415514 ,train acc: 0.760132 ,val loss : 0.105506 ,val acc : 0.992737\n",
      "[ ecpho : 4  iter :844 ]train loss : 0.079700 ,train acc: 0.990631 ,val loss : 0.106250 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :845 ]train loss : 0.079163 ,train acc: 0.990631 ,val loss : 0.103631 ,val acc : 0.992798\n",
      "[ ecpho : 4  iter :846 ]train loss : 0.064543 ,train acc: 0.997345 ,val loss : 0.104439 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :847 ]train loss : 0.258273 ,train acc: 0.869385 ,val loss : 0.105998 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :848 ]train loss : 0.268799 ,train acc: 0.916687 ,val loss : 0.102968 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :849 ]train loss : 0.076399 ,train acc: 0.998260 ,val loss : 0.106555 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :850 ]train loss : 0.097609 ,train acc: 0.982910 ,val loss : 0.105334 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :851 ]train loss : 0.323382 ,train acc: 0.790985 ,val loss : 0.105916 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :852 ]train loss : 0.575293 ,train acc: 0.622498 ,val loss : 0.103752 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :853 ]train loss : 0.061545 ,train acc: 0.998016 ,val loss : 0.105472 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :854 ]train loss : 0.232794 ,train acc: 0.860016 ,val loss : 0.106605 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :855 ]train loss : 0.081410 ,train acc: 0.991943 ,val loss : 0.105734 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :856 ]train loss : 0.057894 ,train acc: 0.997955 ,val loss : 0.106084 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :857 ]train loss : 0.088429 ,train acc: 0.984558 ,val loss : 0.106868 ,val acc : 0.992676\n",
      "[ ecpho : 4  iter :858 ]train loss : 0.237095 ,train acc: 0.909851 ,val loss : 0.104780 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :859 ]train loss : 0.072954 ,train acc: 0.991730 ,val loss : 0.106651 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :860 ]train loss : 0.108720 ,train acc: 0.988281 ,val loss : 0.104760 ,val acc : 0.992004\n",
      "[ ecpho : 4  iter :861 ]train loss : 0.068221 ,train acc: 0.997650 ,val loss : 0.106218 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :862 ]train loss : 0.230332 ,train acc: 0.873535 ,val loss : 0.105209 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :863 ]train loss : 0.120726 ,train acc: 0.988159 ,val loss : 0.104725 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :864 ]train loss : 0.164022 ,train acc: 0.933105 ,val loss : 0.105476 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :865 ]train loss : 0.093654 ,train acc: 0.991089 ,val loss : 0.105738 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :866 ]train loss : 0.136182 ,train acc: 0.952026 ,val loss : 0.106114 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :867 ]train loss : 0.070952 ,train acc: 0.991943 ,val loss : 0.105566 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :868 ]train loss : 0.238871 ,train acc: 0.859131 ,val loss : 0.105158 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :869 ]train loss : 0.095124 ,train acc: 0.991730 ,val loss : 0.107683 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :870 ]train loss : 0.098121 ,train acc: 0.992706 ,val loss : 0.106458 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :871 ]train loss : 0.062949 ,train acc: 0.999207 ,val loss : 0.103175 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :872 ]train loss : 0.079305 ,train acc: 0.995422 ,val loss : 0.105022 ,val acc : 0.992706\n",
      "[ ecpho : 4  iter :873 ]train loss : 0.078565 ,train acc: 0.993134 ,val loss : 0.105642 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :874 ]train loss : 0.100373 ,train acc: 0.976196 ,val loss : 0.105319 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :875 ]train loss : 0.328370 ,train acc: 0.792542 ,val loss : 0.106200 ,val acc : 0.991943\n",
      "[ ecpho : 4  iter :876 ]train loss : 0.070385 ,train acc: 0.998322 ,val loss : 0.103035 ,val acc : 0.992859\n",
      "[ ecpho : 4  iter :877 ]train loss : 0.073688 ,train acc: 0.995270 ,val loss : 0.107320 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :878 ]train loss : 0.089172 ,train acc: 0.982849 ,val loss : 0.104344 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :879 ]train loss : 0.619900 ,train acc: 0.552368 ,val loss : 0.103399 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :880 ]train loss : 0.151285 ,train acc: 0.973602 ,val loss : 0.105489 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :881 ]train loss : 1.172099 ,train acc: 0.204346 ,val loss : 0.104971 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :882 ]train loss : 0.065013 ,train acc: 0.995392 ,val loss : 0.102968 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :883 ]train loss : 0.108635 ,train acc: 0.985748 ,val loss : 0.106634 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :884 ]train loss : 0.067972 ,train acc: 0.997925 ,val loss : 0.107273 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :885 ]train loss : 0.206912 ,train acc: 0.934662 ,val loss : 0.103382 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :886 ]train loss : 0.087882 ,train acc: 0.992981 ,val loss : 0.105797 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :887 ]train loss : 0.269937 ,train acc: 0.877808 ,val loss : 0.106188 ,val acc : 0.992828\n",
      "[ ecpho : 4  iter :888 ]train loss : 0.098517 ,train acc: 0.981079 ,val loss : 0.106551 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :889 ]train loss : 0.191621 ,train acc: 0.952087 ,val loss : 0.104824 ,val acc : 0.992157\n",
      "[ ecpho : 4  iter :890 ]train loss : 0.124215 ,train acc: 0.986115 ,val loss : 0.102851 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :891 ]train loss : 0.092733 ,train acc: 0.994385 ,val loss : 0.107474 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :892 ]train loss : 0.125428 ,train acc: 0.956055 ,val loss : 0.105242 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :893 ]train loss : 0.071288 ,train acc: 0.992767 ,val loss : 0.104958 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :894 ]train loss : 0.060828 ,train acc: 0.998474 ,val loss : 0.105760 ,val acc : 0.992615\n",
      "[ ecpho : 4  iter :895 ]train loss : 0.071979 ,train acc: 0.992004 ,val loss : 0.104450 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :896 ]train loss : 0.101763 ,train acc: 0.990631 ,val loss : 0.106427 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :897 ]train loss : 0.112312 ,train acc: 0.973145 ,val loss : 0.105515 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :898 ]train loss : 0.101914 ,train acc: 0.979340 ,val loss : 0.104314 ,val acc : 0.992584\n",
      "[ ecpho : 4  iter :899 ]train loss : 0.083119 ,train acc: 0.985779 ,val loss : 0.106903 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :900 ]train loss : 0.082696 ,train acc: 0.989349 ,val loss : 0.107007 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :901 ]train loss : 0.107680 ,train acc: 0.987396 ,val loss : 0.106026 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :902 ]train loss : 0.115190 ,train acc: 0.971252 ,val loss : 0.109216 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :903 ]train loss : 0.421739 ,train acc: 0.704559 ,val loss : 0.105467 ,val acc : 0.992493\n",
      "[ ecpho : 4  iter :904 ]train loss : 0.166700 ,train acc: 0.917969 ,val loss : 0.103473 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :905 ]train loss : 0.070751 ,train acc: 0.996155 ,val loss : 0.105384 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :906 ]train loss : 0.069894 ,train acc: 0.997437 ,val loss : 0.107783 ,val acc : 0.992645\n",
      "[ ecpho : 4  iter :907 ]train loss : 0.633512 ,train acc: 0.567963 ,val loss : 0.105050 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :908 ]train loss : 0.119984 ,train acc: 0.965729 ,val loss : 0.106900 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :909 ]train loss : 0.218526 ,train acc: 0.920380 ,val loss : 0.104446 ,val acc : 0.992523\n",
      "[ ecpho : 4  iter :910 ]train loss : 0.089136 ,train acc: 0.996704 ,val loss : 0.107097 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :911 ]train loss : 0.218152 ,train acc: 0.913330 ,val loss : 0.109074 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :912 ]train loss : 0.189742 ,train acc: 0.918182 ,val loss : 0.103836 ,val acc : 0.992554\n",
      "[ ecpho : 4  iter :913 ]train loss : 0.064533 ,train acc: 0.998596 ,val loss : 0.106628 ,val acc : 0.991486\n",
      "[ ecpho : 4  iter :914 ]train loss : 0.057458 ,train acc: 0.998260 ,val loss : 0.107437 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :915 ]train loss : 0.988640 ,train acc: 0.423035 ,val loss : 0.105459 ,val acc : 0.992340\n",
      "[ ecpho : 4  iter :916 ]train loss : 0.177825 ,train acc: 0.934143 ,val loss : 0.105786 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :917 ]train loss : 0.103125 ,train acc: 0.978790 ,val loss : 0.108454 ,val acc : 0.992279\n",
      "[ ecpho : 4  iter :918 ]train loss : 0.129989 ,train acc: 0.956451 ,val loss : 0.108017 ,val acc : 0.992401\n",
      "[ ecpho : 4  iter :919 ]train loss : 0.075254 ,train acc: 0.990814 ,val loss : 0.104766 ,val acc : 0.992249\n",
      "[ ecpho : 4  iter :920 ]train loss : 0.350995 ,train acc: 0.774567 ,val loss : 0.103606 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :921 ]train loss : 0.083121 ,train acc: 0.988068 ,val loss : 0.106955 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :922 ]train loss : 0.152708 ,train acc: 0.971771 ,val loss : 0.106886 ,val acc : 0.992096\n",
      "[ ecpho : 4  iter :923 ]train loss : 0.068256 ,train acc: 0.997040 ,val loss : 0.106852 ,val acc : 0.992218\n",
      "[ ecpho : 4  iter :924 ]train loss : 0.150986 ,train acc: 0.941223 ,val loss : 0.108317 ,val acc : 0.992065\n",
      "[ ecpho : 4  iter :925 ]train loss : 0.086033 ,train acc: 0.994202 ,val loss : 0.105161 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :926 ]train loss : 0.065181 ,train acc: 0.997864 ,val loss : 0.105262 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :927 ]train loss : 0.329814 ,train acc: 0.785431 ,val loss : 0.104676 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :928 ]train loss : 0.062915 ,train acc: 0.997681 ,val loss : 0.107883 ,val acc : 0.992371\n",
      "[ ecpho : 4  iter :929 ]train loss : 0.113960 ,train acc: 0.983948 ,val loss : 0.105008 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :930 ]train loss : 0.082928 ,train acc: 0.987274 ,val loss : 0.106241 ,val acc : 0.992188\n",
      "[ ecpho : 4  iter :931 ]train loss : 0.069924 ,train acc: 0.993896 ,val loss : 0.106388 ,val acc : 0.992126\n",
      "[ ecpho : 4  iter :932 ]train loss : 0.210774 ,train acc: 0.902771 ,val loss : 0.108013 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :933 ]train loss : 0.085042 ,train acc: 0.997650 ,val loss : 0.104410 ,val acc : 0.992462\n",
      "[ ecpho : 4  iter :934 ]train loss : 0.169194 ,train acc: 0.919373 ,val loss : 0.106688 ,val acc : 0.992432\n",
      "[ ecpho : 4  iter :935 ]train loss : 0.089921 ,train acc: 0.996704 ,val loss : 0.106029 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :936 ]train loss : 0.078869 ,train acc: 0.993866 ,val loss : 0.108084 ,val acc : 0.991882\n",
      "[ ecpho : 4  iter :937 ]train loss : 0.084598 ,train acc: 0.988098 ,val loss : 0.105965 ,val acc : 0.991974\n",
      "[ ecpho : 4  iter :938 ]train loss : 0.115545 ,train acc: 0.988098 ,val loss : 0.104176 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :939 ]train loss : 0.145363 ,train acc: 0.949677 ,val loss : 0.103965 ,val acc : 0.992310\n",
      "[ ecpho : 4  iter :940 ]train loss : 0.153649 ,train acc: 0.972412 ,val loss : 0.106796 ,val acc : 0.991516\n",
      "=============================================\n",
      "[ 4 ] average train loss : 0.162686 train acc : 0.934491\n",
      "[ ecpho : 5  iter :1 ]train loss : 0.075568 ,train acc: 0.991486 ,val loss : 0.105511 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :2 ]train loss : 0.226643 ,train acc: 0.893799 ,val loss : 0.107141 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :3 ]train loss : 0.074491 ,train acc: 0.993439 ,val loss : 0.106241 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :4 ]train loss : 0.103142 ,train acc: 0.974060 ,val loss : 0.106659 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :5 ]train loss : 0.092095 ,train acc: 0.994446 ,val loss : 0.108444 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :6 ]train loss : 0.094262 ,train acc: 0.993103 ,val loss : 0.105207 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :7 ]train loss : 0.093702 ,train acc: 0.977783 ,val loss : 0.105531 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :8 ]train loss : 0.340307 ,train acc: 0.859406 ,val loss : 0.105287 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :9 ]train loss : 0.163705 ,train acc: 0.926392 ,val loss : 0.104977 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :10 ]train loss : 0.149583 ,train acc: 0.952515 ,val loss : 0.103459 ,val acc : 0.992645\n",
      "[ ecpho : 5  iter :11 ]train loss : 0.069141 ,train acc: 0.998962 ,val loss : 0.107453 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :12 ]train loss : 0.087420 ,train acc: 0.993958 ,val loss : 0.105381 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :13 ]train loss : 0.085666 ,train acc: 0.985413 ,val loss : 0.103023 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :14 ]train loss : 0.094634 ,train acc: 0.996826 ,val loss : 0.106036 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :15 ]train loss : 0.083953 ,train acc: 0.983368 ,val loss : 0.106958 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :16 ]train loss : 0.088995 ,train acc: 0.993195 ,val loss : 0.102815 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :17 ]train loss : 0.086558 ,train acc: 0.996338 ,val loss : 0.104578 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :18 ]train loss : 0.750244 ,train acc: 0.504944 ,val loss : 0.105950 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :19 ]train loss : 0.095687 ,train acc: 0.980865 ,val loss : 0.106971 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :20 ]train loss : 0.094863 ,train acc: 0.992340 ,val loss : 0.106578 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :21 ]train loss : 0.109280 ,train acc: 0.985138 ,val loss : 0.105388 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :22 ]train loss : 0.117776 ,train acc: 0.973450 ,val loss : 0.104119 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :23 ]train loss : 0.057580 ,train acc: 0.998871 ,val loss : 0.104366 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :24 ]train loss : 0.105320 ,train acc: 0.991486 ,val loss : 0.105631 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :25 ]train loss : 0.102997 ,train acc: 0.976227 ,val loss : 0.104239 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :26 ]train loss : 0.414394 ,train acc: 0.779297 ,val loss : 0.103919 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :27 ]train loss : 0.348573 ,train acc: 0.770172 ,val loss : 0.104296 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :28 ]train loss : 0.084872 ,train acc: 0.994751 ,val loss : 0.105482 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :29 ]train loss : 0.097514 ,train acc: 0.982788 ,val loss : 0.104346 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :30 ]train loss : 0.073147 ,train acc: 0.995178 ,val loss : 0.104708 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :31 ]train loss : 0.077145 ,train acc: 0.992065 ,val loss : 0.106139 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :32 ]train loss : 0.077427 ,train acc: 0.989197 ,val loss : 0.107134 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :33 ]train loss : 0.058188 ,train acc: 0.998138 ,val loss : 0.105833 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :34 ]train loss : 0.083656 ,train acc: 0.994507 ,val loss : 0.106468 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :35 ]train loss : 0.066811 ,train acc: 0.997162 ,val loss : 0.104836 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :36 ]train loss : 0.113416 ,train acc: 0.969330 ,val loss : 0.106225 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :37 ]train loss : 0.098986 ,train acc: 0.993896 ,val loss : 0.107613 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :38 ]train loss : 0.110909 ,train acc: 0.963989 ,val loss : 0.106230 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :39 ]train loss : 0.252750 ,train acc: 0.854767 ,val loss : 0.106493 ,val acc : 0.992859\n",
      "[ ecpho : 5  iter :40 ]train loss : 0.212822 ,train acc: 0.939819 ,val loss : 0.105882 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :41 ]train loss : 0.075377 ,train acc: 0.994110 ,val loss : 0.105134 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :42 ]train loss : 0.075859 ,train acc: 0.993927 ,val loss : 0.104139 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :43 ]train loss : 0.177854 ,train acc: 0.955322 ,val loss : 0.104459 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :44 ]train loss : 0.084581 ,train acc: 0.989624 ,val loss : 0.104619 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :45 ]train loss : 0.100860 ,train acc: 0.984772 ,val loss : 0.103176 ,val acc : 0.992645\n",
      "[ ecpho : 5  iter :46 ]train loss : 0.760735 ,train acc: 0.428894 ,val loss : 0.105271 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :47 ]train loss : 0.090673 ,train acc: 0.977600 ,val loss : 0.104080 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :48 ]train loss : 0.111161 ,train acc: 0.985626 ,val loss : 0.107446 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :49 ]train loss : 0.098999 ,train acc: 0.992462 ,val loss : 0.105056 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :50 ]train loss : 0.101149 ,train acc: 0.974609 ,val loss : 0.107159 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :51 ]train loss : 0.080383 ,train acc: 0.995361 ,val loss : 0.105188 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :52 ]train loss : 0.107159 ,train acc: 0.990692 ,val loss : 0.106435 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :53 ]train loss : 0.101294 ,train acc: 0.974762 ,val loss : 0.105149 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :54 ]train loss : 0.169975 ,train acc: 0.921051 ,val loss : 0.104173 ,val acc : 0.992889\n",
      "[ ecpho : 5  iter :55 ]train loss : 0.111802 ,train acc: 0.992249 ,val loss : 0.104701 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :56 ]train loss : 0.186588 ,train acc: 0.916565 ,val loss : 0.104423 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :57 ]train loss : 0.355933 ,train acc: 0.771515 ,val loss : 0.105396 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :58 ]train loss : 0.074188 ,train acc: 0.992218 ,val loss : 0.105516 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :59 ]train loss : 0.129063 ,train acc: 0.967499 ,val loss : 0.106133 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :60 ]train loss : 0.065863 ,train acc: 0.998962 ,val loss : 0.106470 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :61 ]train loss : 0.141565 ,train acc: 0.950989 ,val loss : 0.105378 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :62 ]train loss : 0.125350 ,train acc: 0.956024 ,val loss : 0.107705 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :63 ]train loss : 0.433729 ,train acc: 0.710327 ,val loss : 0.106970 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :64 ]train loss : 0.388504 ,train acc: 0.782959 ,val loss : 0.104546 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :65 ]train loss : 0.136283 ,train acc: 0.980530 ,val loss : 0.104365 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :66 ]train loss : 0.078203 ,train acc: 0.997528 ,val loss : 0.105023 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :67 ]train loss : 0.110437 ,train acc: 0.980103 ,val loss : 0.104661 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :68 ]train loss : 0.076512 ,train acc: 0.997253 ,val loss : 0.104900 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :69 ]train loss : 0.087460 ,train acc: 0.996460 ,val loss : 0.106623 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :70 ]train loss : 0.114118 ,train acc: 0.985107 ,val loss : 0.106044 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :71 ]train loss : 0.079530 ,train acc: 0.991180 ,val loss : 0.105692 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :72 ]train loss : 0.083588 ,train acc: 0.985626 ,val loss : 0.106002 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :73 ]train loss : 0.069842 ,train acc: 0.994202 ,val loss : 0.104476 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :74 ]train loss : 0.529033 ,train acc: 0.643524 ,val loss : 0.103609 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :75 ]train loss : 0.104529 ,train acc: 0.972443 ,val loss : 0.103000 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :76 ]train loss : 0.062205 ,train acc: 0.997803 ,val loss : 0.103210 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :77 ]train loss : 0.077298 ,train acc: 0.991852 ,val loss : 0.106727 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :78 ]train loss : 0.065480 ,train acc: 0.993744 ,val loss : 0.103701 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :79 ]train loss : 0.059844 ,train acc: 0.996124 ,val loss : 0.104366 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :80 ]train loss : 0.097580 ,train acc: 0.992737 ,val loss : 0.104061 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :81 ]train loss : 0.094200 ,train acc: 0.981812 ,val loss : 0.105431 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :82 ]train loss : 0.451536 ,train acc: 0.716522 ,val loss : 0.104026 ,val acc : 0.992859\n",
      "[ ecpho : 5  iter :83 ]train loss : 0.080571 ,train acc: 0.991516 ,val loss : 0.104388 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :84 ]train loss : 0.079078 ,train acc: 0.998566 ,val loss : 0.104763 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :85 ]train loss : 0.068581 ,train acc: 0.995483 ,val loss : 0.105986 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :86 ]train loss : 0.067128 ,train acc: 0.997589 ,val loss : 0.104015 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :87 ]train loss : 0.094006 ,train acc: 0.987030 ,val loss : 0.105426 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :88 ]train loss : 0.108928 ,train acc: 0.986877 ,val loss : 0.105062 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :89 ]train loss : 0.219573 ,train acc: 0.880859 ,val loss : 0.102977 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :90 ]train loss : 0.323660 ,train acc: 0.866272 ,val loss : 0.105588 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :91 ]train loss : 0.076811 ,train acc: 0.996857 ,val loss : 0.104419 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :92 ]train loss : 0.158381 ,train acc: 0.929871 ,val loss : 0.103498 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :93 ]train loss : 0.369372 ,train acc: 0.783325 ,val loss : 0.106071 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :94 ]train loss : 0.079076 ,train acc: 0.996735 ,val loss : 0.105649 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :95 ]train loss : 0.589765 ,train acc: 0.690735 ,val loss : 0.104525 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :96 ]train loss : 0.118230 ,train acc: 0.973572 ,val loss : 0.105890 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :97 ]train loss : 0.092572 ,train acc: 0.979858 ,val loss : 0.105934 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :98 ]train loss : 0.088624 ,train acc: 0.994965 ,val loss : 0.106980 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :99 ]train loss : 0.061048 ,train acc: 0.997498 ,val loss : 0.104454 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :100 ]train loss : 0.132506 ,train acc: 0.974335 ,val loss : 0.107245 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :101 ]train loss : 0.090869 ,train acc: 0.994171 ,val loss : 0.105306 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :102 ]train loss : 0.487397 ,train acc: 0.691284 ,val loss : 0.105026 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :103 ]train loss : 0.488911 ,train acc: 0.753448 ,val loss : 0.106466 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :104 ]train loss : 0.459242 ,train acc: 0.684540 ,val loss : 0.104167 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :105 ]train loss : 0.081175 ,train acc: 0.991516 ,val loss : 0.107526 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :106 ]train loss : 0.131556 ,train acc: 0.977234 ,val loss : 0.102760 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :107 ]train loss : 0.149670 ,train acc: 0.961548 ,val loss : 0.104981 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :108 ]train loss : 0.097528 ,train acc: 0.993347 ,val loss : 0.105980 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :109 ]train loss : 0.212579 ,train acc: 0.915741 ,val loss : 0.109632 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :110 ]train loss : 0.065278 ,train acc: 0.997650 ,val loss : 0.104438 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :111 ]train loss : 0.251902 ,train acc: 0.865875 ,val loss : 0.106971 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :112 ]train loss : 0.094763 ,train acc: 0.983521 ,val loss : 0.106305 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :113 ]train loss : 0.793867 ,train acc: 0.464386 ,val loss : 0.106304 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :114 ]train loss : 0.078320 ,train acc: 0.989044 ,val loss : 0.105233 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :115 ]train loss : 0.069632 ,train acc: 0.993011 ,val loss : 0.106643 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :116 ]train loss : 0.312484 ,train acc: 0.790527 ,val loss : 0.105808 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :117 ]train loss : 0.113267 ,train acc: 0.968323 ,val loss : 0.104245 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :118 ]train loss : 0.113632 ,train acc: 0.961060 ,val loss : 0.106432 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :119 ]train loss : 0.086154 ,train acc: 0.991943 ,val loss : 0.104542 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :120 ]train loss : 0.062226 ,train acc: 0.998352 ,val loss : 0.105342 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :121 ]train loss : 0.596058 ,train acc: 0.606537 ,val loss : 0.104572 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :122 ]train loss : 0.077425 ,train acc: 0.991516 ,val loss : 0.108485 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :123 ]train loss : 0.085259 ,train acc: 0.996796 ,val loss : 0.103313 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :124 ]train loss : 0.074015 ,train acc: 0.995087 ,val loss : 0.108234 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :125 ]train loss : 0.095822 ,train acc: 0.991730 ,val loss : 0.103854 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :126 ]train loss : 0.062815 ,train acc: 0.998138 ,val loss : 0.105751 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :127 ]train loss : 0.903906 ,train acc: 0.354309 ,val loss : 0.107045 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :128 ]train loss : 0.094642 ,train acc: 0.990356 ,val loss : 0.103922 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :129 ]train loss : 0.520892 ,train acc: 0.658997 ,val loss : 0.105030 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :130 ]train loss : 0.415796 ,train acc: 0.712769 ,val loss : 0.104497 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :131 ]train loss : 0.100276 ,train acc: 0.975861 ,val loss : 0.107273 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :132 ]train loss : 0.087128 ,train acc: 0.993622 ,val loss : 0.106411 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :133 ]train loss : 0.303596 ,train acc: 0.849762 ,val loss : 0.104999 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :134 ]train loss : 0.474560 ,train acc: 0.703003 ,val loss : 0.107839 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :135 ]train loss : 0.122208 ,train acc: 0.983429 ,val loss : 0.105072 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :136 ]train loss : 0.126710 ,train acc: 0.959229 ,val loss : 0.109778 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :137 ]train loss : 0.099530 ,train acc: 0.984467 ,val loss : 0.108262 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :138 ]train loss : 0.067162 ,train acc: 0.997498 ,val loss : 0.107161 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :139 ]train loss : 0.059545 ,train acc: 0.998810 ,val loss : 0.106112 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :140 ]train loss : 0.072997 ,train acc: 0.996704 ,val loss : 0.107238 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :141 ]train loss : 0.588953 ,train acc: 0.553284 ,val loss : 0.107138 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :142 ]train loss : 0.083965 ,train acc: 0.982544 ,val loss : 0.108018 ,val acc : 0.991241\n",
      "[ ecpho : 5  iter :143 ]train loss : 0.099445 ,train acc: 0.977844 ,val loss : 0.106611 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :144 ]train loss : 0.099037 ,train acc: 0.975037 ,val loss : 0.107212 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :145 ]train loss : 0.071504 ,train acc: 0.991150 ,val loss : 0.107576 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :146 ]train loss : 0.073751 ,train acc: 0.992035 ,val loss : 0.107828 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :147 ]train loss : 0.072289 ,train acc: 0.993164 ,val loss : 0.106222 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :148 ]train loss : 1.095669 ,train acc: 0.221680 ,val loss : 0.109188 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :149 ]train loss : 0.141447 ,train acc: 0.949158 ,val loss : 0.107007 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :150 ]train loss : 0.115689 ,train acc: 0.977051 ,val loss : 0.106856 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :151 ]train loss : 0.801723 ,train acc: 0.428955 ,val loss : 0.107795 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :152 ]train loss : 0.221456 ,train acc: 0.924072 ,val loss : 0.108511 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :153 ]train loss : 0.126662 ,train acc: 0.954590 ,val loss : 0.108285 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :154 ]train loss : 0.199373 ,train acc: 0.942841 ,val loss : 0.107665 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :155 ]train loss : 0.098258 ,train acc: 0.988800 ,val loss : 0.107732 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :156 ]train loss : 0.082735 ,train acc: 0.988464 ,val loss : 0.108695 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :157 ]train loss : 0.090800 ,train acc: 0.996277 ,val loss : 0.108428 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :158 ]train loss : 0.074408 ,train acc: 0.996490 ,val loss : 0.108134 ,val acc : 0.991150\n",
      "[ ecpho : 5  iter :159 ]train loss : 0.113994 ,train acc: 0.985626 ,val loss : 0.107802 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :160 ]train loss : 0.123277 ,train acc: 0.961731 ,val loss : 0.106983 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :161 ]train loss : 1.194247 ,train acc: 0.126099 ,val loss : 0.105833 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :162 ]train loss : 0.164093 ,train acc: 0.947083 ,val loss : 0.104158 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :163 ]train loss : 0.116396 ,train acc: 0.965759 ,val loss : 0.105814 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :164 ]train loss : 0.136147 ,train acc: 0.975098 ,val loss : 0.107996 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :165 ]train loss : 0.078977 ,train acc: 0.996155 ,val loss : 0.106874 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :166 ]train loss : 0.086103 ,train acc: 0.987244 ,val loss : 0.107732 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :167 ]train loss : 0.421421 ,train acc: 0.726654 ,val loss : 0.105351 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :168 ]train loss : 0.125978 ,train acc: 0.958344 ,val loss : 0.105701 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :169 ]train loss : 0.309822 ,train acc: 0.841492 ,val loss : 0.106571 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :170 ]train loss : 0.836959 ,train acc: 0.443329 ,val loss : 0.106532 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :171 ]train loss : 0.082625 ,train acc: 0.989594 ,val loss : 0.106553 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :172 ]train loss : 0.398045 ,train acc: 0.799835 ,val loss : 0.108418 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :173 ]train loss : 0.700990 ,train acc: 0.528961 ,val loss : 0.107239 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :174 ]train loss : 0.119763 ,train acc: 0.986786 ,val loss : 0.107758 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :175 ]train loss : 0.069511 ,train acc: 0.997681 ,val loss : 0.107072 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :176 ]train loss : 0.262975 ,train acc: 0.836670 ,val loss : 0.106552 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :177 ]train loss : 0.099469 ,train acc: 0.986877 ,val loss : 0.107968 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :178 ]train loss : 0.096955 ,train acc: 0.992157 ,val loss : 0.107276 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :179 ]train loss : 0.176717 ,train acc: 0.919769 ,val loss : 0.107004 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :180 ]train loss : 0.081078 ,train acc: 0.989044 ,val loss : 0.108315 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :181 ]train loss : 0.181779 ,train acc: 0.953186 ,val loss : 0.105762 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :182 ]train loss : 0.118460 ,train acc: 0.982178 ,val loss : 0.105307 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :183 ]train loss : 0.082122 ,train acc: 0.992310 ,val loss : 0.105506 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :184 ]train loss : 0.087856 ,train acc: 0.990479 ,val loss : 0.109564 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :185 ]train loss : 0.820975 ,train acc: 0.385101 ,val loss : 0.106332 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :186 ]train loss : 0.124367 ,train acc: 0.960602 ,val loss : 0.108288 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :187 ]train loss : 0.115566 ,train acc: 0.981812 ,val loss : 0.106424 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :188 ]train loss : 0.091177 ,train acc: 0.995789 ,val loss : 0.109688 ,val acc : 0.991150\n",
      "[ ecpho : 5  iter :189 ]train loss : 0.068657 ,train acc: 0.997437 ,val loss : 0.109118 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :190 ]train loss : 0.105995 ,train acc: 0.991119 ,val loss : 0.109044 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :191 ]train loss : 0.185795 ,train acc: 0.910950 ,val loss : 0.108457 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :192 ]train loss : 0.074903 ,train acc: 0.994720 ,val loss : 0.105577 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :193 ]train loss : 0.137690 ,train acc: 0.952911 ,val loss : 0.109481 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :194 ]train loss : 0.355122 ,train acc: 0.813568 ,val loss : 0.107524 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :195 ]train loss : 0.072556 ,train acc: 0.990753 ,val loss : 0.107841 ,val acc : 0.991058\n",
      "[ ecpho : 5  iter :196 ]train loss : 0.072112 ,train acc: 0.994690 ,val loss : 0.105873 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :197 ]train loss : 0.081770 ,train acc: 0.992065 ,val loss : 0.108027 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :198 ]train loss : 0.076436 ,train acc: 0.993408 ,val loss : 0.107515 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :199 ]train loss : 0.434327 ,train acc: 0.700134 ,val loss : 0.107265 ,val acc : 0.991150\n",
      "[ ecpho : 5  iter :200 ]train loss : 0.196414 ,train acc: 0.917877 ,val loss : 0.107823 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :201 ]train loss : 0.068292 ,train acc: 0.992859 ,val loss : 0.106939 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :202 ]train loss : 0.076303 ,train acc: 0.998199 ,val loss : 0.107794 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :203 ]train loss : 0.125663 ,train acc: 0.977020 ,val loss : 0.107894 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :204 ]train loss : 0.105576 ,train acc: 0.974884 ,val loss : 0.106235 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :205 ]train loss : 0.079109 ,train acc: 0.993042 ,val loss : 0.108130 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :206 ]train loss : 0.299029 ,train acc: 0.839935 ,val loss : 0.103509 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :207 ]train loss : 0.215125 ,train acc: 0.889587 ,val loss : 0.106982 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :208 ]train loss : 0.101025 ,train acc: 0.991974 ,val loss : 0.107086 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :209 ]train loss : 0.088963 ,train acc: 0.982666 ,val loss : 0.107645 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :210 ]train loss : 0.062255 ,train acc: 0.997833 ,val loss : 0.108898 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :211 ]train loss : 0.082542 ,train acc: 0.985321 ,val loss : 0.107676 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :212 ]train loss : 0.332368 ,train acc: 0.773743 ,val loss : 0.106562 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :213 ]train loss : 0.074880 ,train acc: 0.994080 ,val loss : 0.106153 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :214 ]train loss : 0.080704 ,train acc: 0.987640 ,val loss : 0.107500 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :215 ]train loss : 0.083057 ,train acc: 0.984406 ,val loss : 0.110082 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :216 ]train loss : 0.084712 ,train acc: 0.988342 ,val loss : 0.105233 ,val acc : 0.990784\n",
      "[ ecpho : 5  iter :217 ]train loss : 0.128912 ,train acc: 0.974640 ,val loss : 0.108899 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :218 ]train loss : 0.087148 ,train acc: 0.982971 ,val loss : 0.108797 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :219 ]train loss : 0.073620 ,train acc: 0.991119 ,val loss : 0.108971 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :220 ]train loss : 0.087521 ,train acc: 0.980774 ,val loss : 0.106350 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :221 ]train loss : 0.063872 ,train acc: 0.993683 ,val loss : 0.106748 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :222 ]train loss : 0.070731 ,train acc: 0.996674 ,val loss : 0.108380 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :223 ]train loss : 0.067544 ,train acc: 0.994690 ,val loss : 0.103699 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :224 ]train loss : 0.449144 ,train acc: 0.681702 ,val loss : 0.107955 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :225 ]train loss : 0.076968 ,train acc: 0.993256 ,val loss : 0.107088 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :226 ]train loss : 0.120259 ,train acc: 0.978516 ,val loss : 0.107315 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :227 ]train loss : 0.199991 ,train acc: 0.947998 ,val loss : 0.109814 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :228 ]train loss : 0.204982 ,train acc: 0.895660 ,val loss : 0.107455 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :229 ]train loss : 0.120382 ,train acc: 0.962433 ,val loss : 0.106658 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :230 ]train loss : 0.104776 ,train acc: 0.974670 ,val loss : 0.107533 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :231 ]train loss : 0.079743 ,train acc: 0.990997 ,val loss : 0.107410 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :232 ]train loss : 0.080542 ,train acc: 0.990814 ,val loss : 0.108592 ,val acc : 0.990967\n",
      "[ ecpho : 5  iter :233 ]train loss : 0.090162 ,train acc: 0.994385 ,val loss : 0.104792 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :234 ]train loss : 0.163766 ,train acc: 0.931213 ,val loss : 0.108219 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :235 ]train loss : 0.072370 ,train acc: 0.996918 ,val loss : 0.106339 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :236 ]train loss : 0.071361 ,train acc: 0.996979 ,val loss : 0.108403 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :237 ]train loss : 0.115336 ,train acc: 0.964539 ,val loss : 0.109670 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :238 ]train loss : 0.105124 ,train acc: 0.978424 ,val loss : 0.109077 ,val acc : 0.991150\n",
      "[ ecpho : 5  iter :239 ]train loss : 0.081134 ,train acc: 0.994720 ,val loss : 0.107161 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :240 ]train loss : 0.157997 ,train acc: 0.959869 ,val loss : 0.105140 ,val acc : 0.991150\n",
      "[ ecpho : 5  iter :241 ]train loss : 0.197548 ,train acc: 0.893860 ,val loss : 0.108708 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :242 ]train loss : 0.102253 ,train acc: 0.973785 ,val loss : 0.106255 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :243 ]train loss : 0.114426 ,train acc: 0.973785 ,val loss : 0.108718 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :244 ]train loss : 0.059038 ,train acc: 0.998260 ,val loss : 0.106393 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :245 ]train loss : 0.078582 ,train acc: 0.995117 ,val loss : 0.105886 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :246 ]train loss : 0.094439 ,train acc: 0.985352 ,val loss : 0.107873 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :247 ]train loss : 0.067240 ,train acc: 0.998810 ,val loss : 0.105583 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :248 ]train loss : 0.068129 ,train acc: 0.997040 ,val loss : 0.104678 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :249 ]train loss : 0.062747 ,train acc: 0.998810 ,val loss : 0.107097 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :250 ]train loss : 0.062465 ,train acc: 0.997253 ,val loss : 0.107082 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :251 ]train loss : 0.092825 ,train acc: 0.977417 ,val loss : 0.108906 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :252 ]train loss : 0.072695 ,train acc: 0.997253 ,val loss : 0.106853 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :253 ]train loss : 0.137602 ,train acc: 0.950684 ,val loss : 0.105206 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :254 ]train loss : 1.194636 ,train acc: 0.182861 ,val loss : 0.111616 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :255 ]train loss : 0.152866 ,train acc: 0.938965 ,val loss : 0.107951 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :256 ]train loss : 0.161232 ,train acc: 0.933258 ,val loss : 0.108914 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :257 ]train loss : 0.063114 ,train acc: 0.997009 ,val loss : 0.105693 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :258 ]train loss : 0.088985 ,train acc: 0.996368 ,val loss : 0.105181 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :259 ]train loss : 0.862856 ,train acc: 0.464935 ,val loss : 0.105209 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :260 ]train loss : 0.074861 ,train acc: 0.993286 ,val loss : 0.107805 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :261 ]train loss : 0.070372 ,train acc: 0.995636 ,val loss : 0.106248 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :262 ]train loss : 0.062623 ,train acc: 0.998932 ,val loss : 0.107193 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :263 ]train loss : 0.079543 ,train acc: 0.986481 ,val loss : 0.107814 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :264 ]train loss : 0.097850 ,train acc: 0.995056 ,val loss : 0.107240 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :265 ]train loss : 0.124261 ,train acc: 0.967133 ,val loss : 0.105936 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :266 ]train loss : 0.074795 ,train acc: 0.993408 ,val loss : 0.107256 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :267 ]train loss : 0.053557 ,train acc: 0.999451 ,val loss : 0.106623 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :268 ]train loss : 0.086536 ,train acc: 0.997437 ,val loss : 0.105980 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :269 ]train loss : 0.095408 ,train acc: 0.980316 ,val loss : 0.107738 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :270 ]train loss : 0.119628 ,train acc: 0.966522 ,val loss : 0.107548 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :271 ]train loss : 0.169178 ,train acc: 0.950256 ,val loss : 0.107275 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :272 ]train loss : 0.299115 ,train acc: 0.817230 ,val loss : 0.105720 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :273 ]train loss : 0.068379 ,train acc: 0.998810 ,val loss : 0.105189 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :274 ]train loss : 0.078974 ,train acc: 0.985687 ,val loss : 0.107520 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :275 ]train loss : 0.166968 ,train acc: 0.960785 ,val loss : 0.109871 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :276 ]train loss : 0.088071 ,train acc: 0.983185 ,val loss : 0.106305 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :277 ]train loss : 0.108239 ,train acc: 0.968475 ,val loss : 0.107661 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :278 ]train loss : 0.116410 ,train acc: 0.986572 ,val loss : 0.107604 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :279 ]train loss : 0.087300 ,train acc: 0.996307 ,val loss : 0.107446 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :280 ]train loss : 0.125394 ,train acc: 0.973633 ,val loss : 0.106954 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :281 ]train loss : 0.117110 ,train acc: 0.977875 ,val loss : 0.107436 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :282 ]train loss : 0.991826 ,train acc: 0.282043 ,val loss : 0.107652 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :283 ]train loss : 0.068429 ,train acc: 0.994690 ,val loss : 0.106467 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :284 ]train loss : 0.078714 ,train acc: 0.991302 ,val loss : 0.106294 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :285 ]train loss : 0.072375 ,train acc: 0.992157 ,val loss : 0.108803 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :286 ]train loss : 0.295773 ,train acc: 0.890564 ,val loss : 0.107546 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :287 ]train loss : 0.189854 ,train acc: 0.912109 ,val loss : 0.106332 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :288 ]train loss : 0.268519 ,train acc: 0.829071 ,val loss : 0.106732 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :289 ]train loss : 0.112327 ,train acc: 0.973389 ,val loss : 0.106642 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :290 ]train loss : 0.059043 ,train acc: 0.997864 ,val loss : 0.108872 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :291 ]train loss : 0.077833 ,train acc: 0.984253 ,val loss : 0.105695 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :292 ]train loss : 0.754132 ,train acc: 0.436707 ,val loss : 0.107293 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :293 ]train loss : 0.086634 ,train acc: 0.997345 ,val loss : 0.106194 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :294 ]train loss : 0.127263 ,train acc: 0.953064 ,val loss : 0.107298 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :295 ]train loss : 0.069856 ,train acc: 0.997833 ,val loss : 0.107421 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :296 ]train loss : 0.066974 ,train acc: 0.997253 ,val loss : 0.108052 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :297 ]train loss : 0.097155 ,train acc: 0.993225 ,val loss : 0.107889 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :298 ]train loss : 0.096613 ,train acc: 0.993164 ,val loss : 0.106768 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :299 ]train loss : 0.090033 ,train acc: 0.997345 ,val loss : 0.107275 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :300 ]train loss : 0.061382 ,train acc: 0.998260 ,val loss : 0.108921 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :301 ]train loss : 0.336774 ,train acc: 0.783539 ,val loss : 0.112113 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :302 ]train loss : 0.110329 ,train acc: 0.982422 ,val loss : 0.108970 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :303 ]train loss : 0.397825 ,train acc: 0.767395 ,val loss : 0.107469 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :304 ]train loss : 0.703555 ,train acc: 0.445007 ,val loss : 0.105883 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :305 ]train loss : 0.369531 ,train acc: 0.752838 ,val loss : 0.105422 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :306 ]train loss : 0.162007 ,train acc: 0.944733 ,val loss : 0.109657 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :307 ]train loss : 0.351530 ,train acc: 0.808136 ,val loss : 0.111240 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :308 ]train loss : 0.121467 ,train acc: 0.972290 ,val loss : 0.110999 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :309 ]train loss : 0.076851 ,train acc: 0.997711 ,val loss : 0.108181 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :310 ]train loss : 0.276213 ,train acc: 0.892883 ,val loss : 0.106250 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :311 ]train loss : 0.072245 ,train acc: 0.993103 ,val loss : 0.106421 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :312 ]train loss : 0.054584 ,train acc: 0.999268 ,val loss : 0.110210 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :313 ]train loss : 0.095878 ,train acc: 0.978363 ,val loss : 0.108096 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :314 ]train loss : 0.339344 ,train acc: 0.826996 ,val loss : 0.107699 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :315 ]train loss : 0.086373 ,train acc: 0.990173 ,val loss : 0.108705 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :316 ]train loss : 0.057509 ,train acc: 0.998291 ,val loss : 0.109652 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :317 ]train loss : 0.142279 ,train acc: 0.958221 ,val loss : 0.108442 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :318 ]train loss : 0.105624 ,train acc: 0.975281 ,val loss : 0.110657 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :319 ]train loss : 0.158002 ,train acc: 0.933136 ,val loss : 0.111623 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :320 ]train loss : 0.088933 ,train acc: 0.996490 ,val loss : 0.108351 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :321 ]train loss : 0.101424 ,train acc: 0.992432 ,val loss : 0.106430 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :322 ]train loss : 0.070853 ,train acc: 0.993561 ,val loss : 0.108192 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :323 ]train loss : 0.065952 ,train acc: 0.997772 ,val loss : 0.108589 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :324 ]train loss : 0.620931 ,train acc: 0.688171 ,val loss : 0.109451 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :325 ]train loss : 0.080770 ,train acc: 0.990875 ,val loss : 0.110302 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :326 ]train loss : 0.066706 ,train acc: 0.994537 ,val loss : 0.108999 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :327 ]train loss : 0.082347 ,train acc: 0.996033 ,val loss : 0.108654 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :328 ]train loss : 0.072752 ,train acc: 0.993988 ,val loss : 0.107353 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :329 ]train loss : 0.355977 ,train acc: 0.808655 ,val loss : 0.106082 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :330 ]train loss : 0.160752 ,train acc: 0.932922 ,val loss : 0.108473 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :331 ]train loss : 0.101261 ,train acc: 0.992706 ,val loss : 0.107576 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :332 ]train loss : 0.191263 ,train acc: 0.929932 ,val loss : 0.109212 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :333 ]train loss : 0.099584 ,train acc: 0.978729 ,val loss : 0.107348 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :334 ]train loss : 0.079280 ,train acc: 0.993256 ,val loss : 0.107524 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :335 ]train loss : 0.105519 ,train acc: 0.989777 ,val loss : 0.109095 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :336 ]train loss : 0.944071 ,train acc: 0.382446 ,val loss : 0.107430 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :337 ]train loss : 0.486204 ,train acc: 0.668976 ,val loss : 0.108465 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :338 ]train loss : 0.100286 ,train acc: 0.978821 ,val loss : 0.106884 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :339 ]train loss : 0.074271 ,train acc: 0.991943 ,val loss : 0.107683 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :340 ]train loss : 0.134003 ,train acc: 0.951660 ,val loss : 0.107589 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :341 ]train loss : 0.099517 ,train acc: 0.984436 ,val loss : 0.106332 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :342 ]train loss : 0.138168 ,train acc: 0.961945 ,val loss : 0.110328 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :343 ]train loss : 0.900906 ,train acc: 0.348480 ,val loss : 0.108885 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :344 ]train loss : 0.061609 ,train acc: 0.995178 ,val loss : 0.105548 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :345 ]train loss : 0.479610 ,train acc: 0.639496 ,val loss : 0.107816 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :346 ]train loss : 0.265826 ,train acc: 0.887207 ,val loss : 0.104202 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :347 ]train loss : 0.088692 ,train acc: 0.985352 ,val loss : 0.110915 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :348 ]train loss : 0.102873 ,train acc: 0.984100 ,val loss : 0.109157 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :349 ]train loss : 0.097653 ,train acc: 0.995239 ,val loss : 0.106900 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :350 ]train loss : 0.093046 ,train acc: 0.984375 ,val loss : 0.108481 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :351 ]train loss : 0.080065 ,train acc: 0.997040 ,val loss : 0.112289 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :352 ]train loss : 0.113338 ,train acc: 0.983398 ,val loss : 0.106940 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :353 ]train loss : 0.072677 ,train acc: 0.992676 ,val loss : 0.110193 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :354 ]train loss : 0.085850 ,train acc: 0.988342 ,val loss : 0.108138 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :355 ]train loss : 0.071094 ,train acc: 0.997955 ,val loss : 0.107668 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :356 ]train loss : 0.094213 ,train acc: 0.996246 ,val loss : 0.108461 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :357 ]train loss : 0.116879 ,train acc: 0.984436 ,val loss : 0.108476 ,val acc : 0.991241\n",
      "[ ecpho : 5  iter :358 ]train loss : 0.085872 ,train acc: 0.994049 ,val loss : 0.110710 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :359 ]train loss : 0.160307 ,train acc: 0.945099 ,val loss : 0.109500 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :360 ]train loss : 0.089648 ,train acc: 0.995941 ,val loss : 0.106804 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :361 ]train loss : 0.088694 ,train acc: 0.982544 ,val loss : 0.108228 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :362 ]train loss : 0.057267 ,train acc: 0.997589 ,val loss : 0.107383 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :363 ]train loss : 0.165020 ,train acc: 0.939941 ,val loss : 0.106927 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :364 ]train loss : 0.093344 ,train acc: 0.996429 ,val loss : 0.106516 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :365 ]train loss : 0.391251 ,train acc: 0.773254 ,val loss : 0.106954 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :366 ]train loss : 0.068500 ,train acc: 0.995300 ,val loss : 0.105509 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :367 ]train loss : 0.326093 ,train acc: 0.793854 ,val loss : 0.107257 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :368 ]train loss : 0.105196 ,train acc: 0.977844 ,val loss : 0.108391 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :369 ]train loss : 0.097151 ,train acc: 0.977661 ,val loss : 0.108637 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :370 ]train loss : 0.222483 ,train acc: 0.877930 ,val loss : 0.108994 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :371 ]train loss : 0.174251 ,train acc: 0.919220 ,val loss : 0.107699 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :372 ]train loss : 0.459445 ,train acc: 0.726196 ,val loss : 0.107232 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :373 ]train loss : 0.073816 ,train acc: 0.991882 ,val loss : 0.107080 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :374 ]train loss : 0.074303 ,train acc: 0.998535 ,val loss : 0.108093 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :375 ]train loss : 0.076506 ,train acc: 0.989838 ,val loss : 0.109588 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :376 ]train loss : 0.088026 ,train acc: 0.996704 ,val loss : 0.107001 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :377 ]train loss : 0.128792 ,train acc: 0.963684 ,val loss : 0.107767 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :378 ]train loss : 0.246786 ,train acc: 0.885529 ,val loss : 0.109090 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :379 ]train loss : 0.094113 ,train acc: 0.978821 ,val loss : 0.107395 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :380 ]train loss : 0.078086 ,train acc: 0.986816 ,val loss : 0.108001 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :381 ]train loss : 0.268228 ,train acc: 0.860077 ,val loss : 0.111486 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :382 ]train loss : 0.148073 ,train acc: 0.944336 ,val loss : 0.106630 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :383 ]train loss : 0.110519 ,train acc: 0.987061 ,val loss : 0.110180 ,val acc : 0.991180\n",
      "[ ecpho : 5  iter :384 ]train loss : 0.083281 ,train acc: 0.986145 ,val loss : 0.106853 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :385 ]train loss : 0.086486 ,train acc: 0.992828 ,val loss : 0.110176 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :386 ]train loss : 0.097941 ,train acc: 0.978271 ,val loss : 0.106902 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :387 ]train loss : 0.116108 ,train acc: 0.990356 ,val loss : 0.107401 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :388 ]train loss : 0.064909 ,train acc: 0.998901 ,val loss : 0.108447 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :389 ]train loss : 0.085798 ,train acc: 0.990051 ,val loss : 0.107867 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :390 ]train loss : 0.345555 ,train acc: 0.823700 ,val loss : 0.108518 ,val acc : 0.991272\n",
      "[ ecpho : 5  iter :391 ]train loss : 0.476171 ,train acc: 0.668030 ,val loss : 0.107417 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :392 ]train loss : 0.072075 ,train acc: 0.991943 ,val loss : 0.109600 ,val acc : 0.990875\n",
      "[ ecpho : 5  iter :393 ]train loss : 0.089221 ,train acc: 0.985413 ,val loss : 0.105862 ,val acc : 0.991333\n",
      "[ ecpho : 5  iter :394 ]train loss : 0.071645 ,train acc: 0.994568 ,val loss : 0.108343 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :395 ]train loss : 0.101190 ,train acc: 0.979523 ,val loss : 0.110519 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :396 ]train loss : 0.693363 ,train acc: 0.557648 ,val loss : 0.107819 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :397 ]train loss : 0.071357 ,train acc: 0.997498 ,val loss : 0.109984 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :398 ]train loss : 0.151927 ,train acc: 0.953033 ,val loss : 0.109149 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :399 ]train loss : 0.076621 ,train acc: 0.989838 ,val loss : 0.108463 ,val acc : 0.991089\n",
      "[ ecpho : 5  iter :400 ]train loss : 0.074965 ,train acc: 0.996582 ,val loss : 0.108607 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :401 ]train loss : 0.148276 ,train acc: 0.944092 ,val loss : 0.108454 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :402 ]train loss : 0.195882 ,train acc: 0.901489 ,val loss : 0.109775 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :403 ]train loss : 0.069295 ,train acc: 0.996643 ,val loss : 0.110041 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :404 ]train loss : 0.071977 ,train acc: 0.996887 ,val loss : 0.109714 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :405 ]train loss : 0.068867 ,train acc: 0.997589 ,val loss : 0.109415 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :406 ]train loss : 0.087495 ,train acc: 0.982483 ,val loss : 0.107367 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :407 ]train loss : 0.066340 ,train acc: 0.998688 ,val loss : 0.108499 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :408 ]train loss : 0.600357 ,train acc: 0.602234 ,val loss : 0.107309 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :409 ]train loss : 0.268719 ,train acc: 0.832397 ,val loss : 0.107823 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :410 ]train loss : 0.151192 ,train acc: 0.941101 ,val loss : 0.108681 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :411 ]train loss : 0.085019 ,train acc: 0.992920 ,val loss : 0.111366 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :412 ]train loss : 0.248496 ,train acc: 0.888031 ,val loss : 0.107853 ,val acc : 0.991180\n",
      "[ ecpho : 5  iter :413 ]train loss : 0.108518 ,train acc: 0.968414 ,val loss : 0.109418 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :414 ]train loss : 0.082795 ,train acc: 0.989563 ,val loss : 0.110605 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :415 ]train loss : 0.070408 ,train acc: 0.997528 ,val loss : 0.110003 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :416 ]train loss : 0.277821 ,train acc: 0.827148 ,val loss : 0.107458 ,val acc : 0.991333\n",
      "[ ecpho : 5  iter :417 ]train loss : 0.087895 ,train acc: 0.996643 ,val loss : 0.108653 ,val acc : 0.991241\n",
      "[ ecpho : 5  iter :418 ]train loss : 0.542710 ,train acc: 0.609863 ,val loss : 0.106802 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :419 ]train loss : 0.060538 ,train acc: 0.998169 ,val loss : 0.106113 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :420 ]train loss : 0.092228 ,train acc: 0.979797 ,val loss : 0.109831 ,val acc : 0.991180\n",
      "[ ecpho : 5  iter :421 ]train loss : 0.083696 ,train acc: 0.994324 ,val loss : 0.108125 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :422 ]train loss : 0.217702 ,train acc: 0.874573 ,val loss : 0.109285 ,val acc : 0.991241\n",
      "[ ecpho : 5  iter :423 ]train loss : 0.108664 ,train acc: 0.982452 ,val loss : 0.109851 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :424 ]train loss : 0.105000 ,train acc: 0.977112 ,val loss : 0.109125 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :425 ]train loss : 0.109798 ,train acc: 0.967438 ,val loss : 0.110326 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :426 ]train loss : 0.069303 ,train acc: 0.991974 ,val loss : 0.107619 ,val acc : 0.990906\n",
      "[ ecpho : 5  iter :427 ]train loss : 0.113655 ,train acc: 0.968567 ,val loss : 0.110143 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :428 ]train loss : 0.145421 ,train acc: 0.941620 ,val loss : 0.108165 ,val acc : 0.991180\n",
      "[ ecpho : 5  iter :429 ]train loss : 0.087308 ,train acc: 0.990631 ,val loss : 0.110339 ,val acc : 0.991089\n",
      "[ ecpho : 5  iter :430 ]train loss : 0.105204 ,train acc: 0.982147 ,val loss : 0.108884 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :431 ]train loss : 0.103601 ,train acc: 0.983948 ,val loss : 0.112595 ,val acc : 0.991119\n",
      "[ ecpho : 5  iter :432 ]train loss : 0.075643 ,train acc: 0.990448 ,val loss : 0.111957 ,val acc : 0.990967\n",
      "[ ecpho : 5  iter :433 ]train loss : 0.080679 ,train acc: 0.989838 ,val loss : 0.110964 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :434 ]train loss : 0.415326 ,train acc: 0.767212 ,val loss : 0.111821 ,val acc : 0.991028\n",
      "[ ecpho : 5  iter :435 ]train loss : 0.075113 ,train acc: 0.992889 ,val loss : 0.110309 ,val acc : 0.990906\n",
      "[ ecpho : 5  iter :436 ]train loss : 0.072039 ,train acc: 0.994324 ,val loss : 0.111416 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :437 ]train loss : 0.080384 ,train acc: 0.988770 ,val loss : 0.109116 ,val acc : 0.991089\n",
      "[ ecpho : 5  iter :438 ]train loss : 0.115301 ,train acc: 0.973999 ,val loss : 0.108707 ,val acc : 0.991028\n",
      "[ ecpho : 5  iter :439 ]train loss : 0.166861 ,train acc: 0.934753 ,val loss : 0.112763 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :440 ]train loss : 0.962858 ,train acc: 0.335022 ,val loss : 0.109399 ,val acc : 0.991089\n",
      "[ ecpho : 5  iter :441 ]train loss : 0.089074 ,train acc: 0.985657 ,val loss : 0.110990 ,val acc : 0.990997\n",
      "[ ecpho : 5  iter :442 ]train loss : 0.066273 ,train acc: 0.995026 ,val loss : 0.109563 ,val acc : 0.991119\n",
      "[ ecpho : 5  iter :443 ]train loss : 0.064889 ,train acc: 0.996216 ,val loss : 0.108044 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :444 ]train loss : 0.068330 ,train acc: 0.996979 ,val loss : 0.109102 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :445 ]train loss : 0.066115 ,train acc: 0.996124 ,val loss : 0.110138 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :446 ]train loss : 0.075501 ,train acc: 0.988861 ,val loss : 0.107919 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :447 ]train loss : 0.142308 ,train acc: 0.973877 ,val loss : 0.109698 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :448 ]train loss : 0.598344 ,train acc: 0.660767 ,val loss : 0.110275 ,val acc : 0.991364\n",
      "[ ecpho : 5  iter :449 ]train loss : 0.057909 ,train acc: 0.997894 ,val loss : 0.108736 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :450 ]train loss : 0.086048 ,train acc: 0.987335 ,val loss : 0.109937 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :451 ]train loss : 0.084586 ,train acc: 0.997772 ,val loss : 0.111326 ,val acc : 0.991272\n",
      "[ ecpho : 5  iter :452 ]train loss : 0.091798 ,train acc: 0.995758 ,val loss : 0.110546 ,val acc : 0.991302\n",
      "[ ecpho : 5  iter :453 ]train loss : 0.126869 ,train acc: 0.980560 ,val loss : 0.109387 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :454 ]train loss : 0.296773 ,train acc: 0.863251 ,val loss : 0.108442 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :455 ]train loss : 0.069552 ,train acc: 0.996979 ,val loss : 0.110693 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :456 ]train loss : 0.193091 ,train acc: 0.947754 ,val loss : 0.109902 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :457 ]train loss : 0.175398 ,train acc: 0.930481 ,val loss : 0.110422 ,val acc : 0.991241\n",
      "[ ecpho : 5  iter :458 ]train loss : 0.153835 ,train acc: 0.976044 ,val loss : 0.108008 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :459 ]train loss : 0.090525 ,train acc: 0.992065 ,val loss : 0.110082 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :460 ]train loss : 0.088154 ,train acc: 0.994476 ,val loss : 0.110438 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :461 ]train loss : 0.737948 ,train acc: 0.419464 ,val loss : 0.110449 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :462 ]train loss : 0.173500 ,train acc: 0.920044 ,val loss : 0.108544 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :463 ]train loss : 0.065096 ,train acc: 0.997345 ,val loss : 0.109748 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :464 ]train loss : 0.187308 ,train acc: 0.947845 ,val loss : 0.108444 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :465 ]train loss : 0.075495 ,train acc: 0.992188 ,val loss : 0.109903 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :466 ]train loss : 0.134835 ,train acc: 0.986725 ,val loss : 0.110121 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :467 ]train loss : 0.064346 ,train acc: 0.998260 ,val loss : 0.109553 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :468 ]train loss : 1.115559 ,train acc: 0.234650 ,val loss : 0.109330 ,val acc : 0.991241\n",
      "[ ecpho : 5  iter :469 ]train loss : 0.111991 ,train acc: 0.982910 ,val loss : 0.107222 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :470 ]train loss : 0.101337 ,train acc: 0.979248 ,val loss : 0.108124 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :471 ]train loss : 0.079717 ,train acc: 0.985260 ,val loss : 0.110052 ,val acc : 0.990784\n",
      "[ ecpho : 5  iter :472 ]train loss : 0.076627 ,train acc: 0.991211 ,val loss : 0.109103 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :473 ]train loss : 0.073952 ,train acc: 0.993683 ,val loss : 0.110127 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :474 ]train loss : 0.115187 ,train acc: 0.986053 ,val loss : 0.106453 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :475 ]train loss : 0.202765 ,train acc: 0.899780 ,val loss : 0.106683 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :476 ]train loss : 0.182419 ,train acc: 0.917114 ,val loss : 0.108267 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :477 ]train loss : 0.170814 ,train acc: 0.925964 ,val loss : 0.109044 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :478 ]train loss : 0.062966 ,train acc: 0.998474 ,val loss : 0.106031 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :479 ]train loss : 0.206695 ,train acc: 0.897736 ,val loss : 0.109178 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :480 ]train loss : 0.079474 ,train acc: 0.987579 ,val loss : 0.109662 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :481 ]train loss : 0.479355 ,train acc: 0.663940 ,val loss : 0.110080 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :482 ]train loss : 0.109642 ,train acc: 0.974945 ,val loss : 0.108545 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :483 ]train loss : 0.163200 ,train acc: 0.939148 ,val loss : 0.110050 ,val acc : 0.991547\n",
      "[ ecpho : 5  iter :484 ]train loss : 0.139618 ,train acc: 0.945984 ,val loss : 0.110070 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :485 ]train loss : 1.095438 ,train acc: 0.249176 ,val loss : 0.108462 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :486 ]train loss : 0.268825 ,train acc: 0.828857 ,val loss : 0.109194 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :487 ]train loss : 0.089991 ,train acc: 0.986908 ,val loss : 0.107305 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :488 ]train loss : 0.088123 ,train acc: 0.993500 ,val loss : 0.110787 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :489 ]train loss : 0.104952 ,train acc: 0.981110 ,val loss : 0.109742 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :490 ]train loss : 0.070496 ,train acc: 0.993225 ,val loss : 0.109785 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :491 ]train loss : 0.077407 ,train acc: 0.993073 ,val loss : 0.109498 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :492 ]train loss : 0.054820 ,train acc: 0.999573 ,val loss : 0.110378 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :493 ]train loss : 0.076678 ,train acc: 0.990662 ,val loss : 0.108462 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :494 ]train loss : 0.113385 ,train acc: 0.989594 ,val loss : 0.107903 ,val acc : 0.991394\n",
      "[ ecpho : 5  iter :495 ]train loss : 0.237630 ,train acc: 0.883850 ,val loss : 0.111210 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :496 ]train loss : 0.268712 ,train acc: 0.841522 ,val loss : 0.109222 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :497 ]train loss : 0.080298 ,train acc: 0.983337 ,val loss : 0.109560 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :498 ]train loss : 0.094563 ,train acc: 0.994110 ,val loss : 0.107479 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :499 ]train loss : 0.307887 ,train acc: 0.850616 ,val loss : 0.109300 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :500 ]train loss : 0.081045 ,train acc: 0.989044 ,val loss : 0.111928 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :501 ]train loss : 0.118622 ,train acc: 0.985718 ,val loss : 0.105566 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :502 ]train loss : 0.075921 ,train acc: 0.996796 ,val loss : 0.109923 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :503 ]train loss : 0.100762 ,train acc: 0.982880 ,val loss : 0.111262 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :504 ]train loss : 0.262892 ,train acc: 0.856201 ,val loss : 0.108510 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :505 ]train loss : 0.239871 ,train acc: 0.866302 ,val loss : 0.109019 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :506 ]train loss : 0.093026 ,train acc: 0.980896 ,val loss : 0.104709 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :507 ]train loss : 0.083270 ,train acc: 0.995209 ,val loss : 0.108226 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :508 ]train loss : 0.141456 ,train acc: 0.957764 ,val loss : 0.109198 ,val acc : 0.991669\n",
      "[ ecpho : 5  iter :509 ]train loss : 0.073803 ,train acc: 0.994904 ,val loss : 0.111707 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :510 ]train loss : 0.064399 ,train acc: 0.998169 ,val loss : 0.110059 ,val acc : 0.991211\n",
      "[ ecpho : 5  iter :511 ]train loss : 0.118775 ,train acc: 0.961914 ,val loss : 0.107672 ,val acc : 0.991577\n",
      "[ ecpho : 5  iter :512 ]train loss : 0.074078 ,train acc: 0.991302 ,val loss : 0.109074 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :513 ]train loss : 0.187487 ,train acc: 0.902252 ,val loss : 0.110106 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :514 ]train loss : 0.090552 ,train acc: 0.983063 ,val loss : 0.108001 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :515 ]train loss : 1.270927 ,train acc: 0.155365 ,val loss : 0.108681 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :516 ]train loss : 0.058976 ,train acc: 0.996704 ,val loss : 0.108260 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :517 ]train loss : 0.230925 ,train acc: 0.877014 ,val loss : 0.109976 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :518 ]train loss : 0.101402 ,train acc: 0.990814 ,val loss : 0.109499 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :519 ]train loss : 0.073462 ,train acc: 0.989807 ,val loss : 0.107442 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :520 ]train loss : 0.146884 ,train acc: 0.953369 ,val loss : 0.108989 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :521 ]train loss : 0.098681 ,train acc: 0.993439 ,val loss : 0.107017 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :522 ]train loss : 0.117758 ,train acc: 0.978485 ,val loss : 0.107185 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :523 ]train loss : 0.240641 ,train acc: 0.890045 ,val loss : 0.106798 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :524 ]train loss : 0.085038 ,train acc: 0.984467 ,val loss : 0.110213 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :525 ]train loss : 0.401143 ,train acc: 0.711914 ,val loss : 0.107163 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :526 ]train loss : 0.134307 ,train acc: 0.976379 ,val loss : 0.109474 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :527 ]train loss : 0.079679 ,train acc: 0.988281 ,val loss : 0.107118 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :528 ]train loss : 0.133043 ,train acc: 0.957977 ,val loss : 0.110917 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :529 ]train loss : 0.165150 ,train acc: 0.957428 ,val loss : 0.108395 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :530 ]train loss : 0.063223 ,train acc: 0.996155 ,val loss : 0.111501 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :531 ]train loss : 0.178919 ,train acc: 0.927795 ,val loss : 0.107318 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :532 ]train loss : 0.096749 ,train acc: 0.975189 ,val loss : 0.108586 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :533 ]train loss : 0.075177 ,train acc: 0.988403 ,val loss : 0.107883 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :534 ]train loss : 0.058020 ,train acc: 0.995667 ,val loss : 0.110230 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :535 ]train loss : 0.586888 ,train acc: 0.615601 ,val loss : 0.109782 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :536 ]train loss : 0.088582 ,train acc: 0.996704 ,val loss : 0.110535 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :537 ]train loss : 0.072167 ,train acc: 0.997284 ,val loss : 0.108327 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :538 ]train loss : 0.080932 ,train acc: 0.993652 ,val loss : 0.110649 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :539 ]train loss : 0.091176 ,train acc: 0.990387 ,val loss : 0.109861 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :540 ]train loss : 0.067630 ,train acc: 0.997040 ,val loss : 0.109324 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :541 ]train loss : 0.095585 ,train acc: 0.994659 ,val loss : 0.105976 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :542 ]train loss : 0.080031 ,train acc: 0.991455 ,val loss : 0.110032 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :543 ]train loss : 0.098458 ,train acc: 0.985840 ,val loss : 0.109568 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :544 ]train loss : 0.085025 ,train acc: 0.998047 ,val loss : 0.109853 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :545 ]train loss : 0.106341 ,train acc: 0.983582 ,val loss : 0.108720 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :546 ]train loss : 0.071485 ,train acc: 0.997253 ,val loss : 0.105672 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :547 ]train loss : 0.081431 ,train acc: 0.995667 ,val loss : 0.107419 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :548 ]train loss : 0.100743 ,train acc: 0.993134 ,val loss : 0.110138 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :549 ]train loss : 0.077973 ,train acc: 0.993713 ,val loss : 0.110398 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :550 ]train loss : 0.083579 ,train acc: 0.989960 ,val loss : 0.109809 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :551 ]train loss : 0.092583 ,train acc: 0.991547 ,val loss : 0.107431 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :552 ]train loss : 0.093350 ,train acc: 0.979218 ,val loss : 0.106834 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :553 ]train loss : 0.096610 ,train acc: 0.993103 ,val loss : 0.111389 ,val acc : 0.991425\n",
      "[ ecpho : 5  iter :554 ]train loss : 0.112873 ,train acc: 0.968658 ,val loss : 0.107927 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :555 ]train loss : 0.087724 ,train acc: 0.987854 ,val loss : 0.111011 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :556 ]train loss : 0.282640 ,train acc: 0.839294 ,val loss : 0.109198 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :557 ]train loss : 0.122614 ,train acc: 0.964142 ,val loss : 0.109143 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :558 ]train loss : 0.200215 ,train acc: 0.902924 ,val loss : 0.109085 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :559 ]train loss : 0.069338 ,train acc: 0.994690 ,val loss : 0.107320 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :560 ]train loss : 0.064366 ,train acc: 0.997894 ,val loss : 0.108458 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :561 ]train loss : 0.073745 ,train acc: 0.998322 ,val loss : 0.108934 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :562 ]train loss : 0.110293 ,train acc: 0.991180 ,val loss : 0.105491 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :563 ]train loss : 0.076551 ,train acc: 0.994568 ,val loss : 0.106756 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :564 ]train loss : 0.052456 ,train acc: 0.999451 ,val loss : 0.109155 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :565 ]train loss : 0.063917 ,train acc: 0.994720 ,val loss : 0.108345 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :566 ]train loss : 0.176516 ,train acc: 0.917816 ,val loss : 0.108027 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :567 ]train loss : 0.076410 ,train acc: 0.987091 ,val loss : 0.108966 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :568 ]train loss : 0.100235 ,train acc: 0.983124 ,val loss : 0.111015 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :569 ]train loss : 0.086004 ,train acc: 0.993103 ,val loss : 0.106139 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :570 ]train loss : 0.087085 ,train acc: 0.997559 ,val loss : 0.109377 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :571 ]train loss : 0.107965 ,train acc: 0.968292 ,val loss : 0.106220 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :572 ]train loss : 0.139034 ,train acc: 0.979218 ,val loss : 0.109854 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :573 ]train loss : 0.385228 ,train acc: 0.724762 ,val loss : 0.107329 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :574 ]train loss : 0.129553 ,train acc: 0.961792 ,val loss : 0.107123 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :575 ]train loss : 0.105249 ,train acc: 0.992249 ,val loss : 0.108556 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :576 ]train loss : 0.927593 ,train acc: 0.345123 ,val loss : 0.109601 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :577 ]train loss : 0.119105 ,train acc: 0.985718 ,val loss : 0.107528 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :578 ]train loss : 0.122192 ,train acc: 0.968567 ,val loss : 0.109576 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :579 ]train loss : 0.188955 ,train acc: 0.942535 ,val loss : 0.109006 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :580 ]train loss : 0.102289 ,train acc: 0.996033 ,val loss : 0.109739 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :581 ]train loss : 0.075038 ,train acc: 0.997284 ,val loss : 0.109091 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :582 ]train loss : 0.080872 ,train acc: 0.991913 ,val loss : 0.106748 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :583 ]train loss : 0.704256 ,train acc: 0.505249 ,val loss : 0.107669 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :584 ]train loss : 0.082497 ,train acc: 0.998108 ,val loss : 0.109536 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :585 ]train loss : 0.084824 ,train acc: 0.998444 ,val loss : 0.108729 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :586 ]train loss : 0.087121 ,train acc: 0.997253 ,val loss : 0.106480 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :587 ]train loss : 0.111451 ,train acc: 0.971954 ,val loss : 0.105688 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :588 ]train loss : 0.088454 ,train acc: 0.997925 ,val loss : 0.109716 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :589 ]train loss : 0.089231 ,train acc: 0.989990 ,val loss : 0.109148 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :590 ]train loss : 0.077032 ,train acc: 0.992432 ,val loss : 0.106123 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :591 ]train loss : 0.192626 ,train acc: 0.946442 ,val loss : 0.109120 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :592 ]train loss : 0.099804 ,train acc: 0.981262 ,val loss : 0.109020 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :593 ]train loss : 0.081921 ,train acc: 0.994476 ,val loss : 0.108252 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :594 ]train loss : 0.080973 ,train acc: 0.994110 ,val loss : 0.108713 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :595 ]train loss : 0.090011 ,train acc: 0.992279 ,val loss : 0.107663 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :596 ]train loss : 0.072682 ,train acc: 0.997406 ,val loss : 0.106472 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :597 ]train loss : 0.072229 ,train acc: 0.992462 ,val loss : 0.109703 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :598 ]train loss : 0.080981 ,train acc: 0.986023 ,val loss : 0.105294 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :599 ]train loss : 0.106305 ,train acc: 0.973114 ,val loss : 0.106874 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :600 ]train loss : 0.107449 ,train acc: 0.980347 ,val loss : 0.106958 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :601 ]train loss : 0.105153 ,train acc: 0.986328 ,val loss : 0.107338 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :602 ]train loss : 0.389047 ,train acc: 0.747742 ,val loss : 0.105760 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :603 ]train loss : 0.086034 ,train acc: 0.985840 ,val loss : 0.106038 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :604 ]train loss : 0.059812 ,train acc: 0.997864 ,val loss : 0.106268 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :605 ]train loss : 0.084254 ,train acc: 0.992920 ,val loss : 0.106287 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :606 ]train loss : 0.103064 ,train acc: 0.970123 ,val loss : 0.107417 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :607 ]train loss : 0.062687 ,train acc: 0.998444 ,val loss : 0.106089 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :608 ]train loss : 0.089037 ,train acc: 0.987396 ,val loss : 0.107278 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :609 ]train loss : 0.281266 ,train acc: 0.848755 ,val loss : 0.106895 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :610 ]train loss : 0.115392 ,train acc: 0.964264 ,val loss : 0.105794 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :611 ]train loss : 0.096785 ,train acc: 0.993683 ,val loss : 0.110273 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :612 ]train loss : 0.075007 ,train acc: 0.997253 ,val loss : 0.106726 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :613 ]train loss : 0.133843 ,train acc: 0.954773 ,val loss : 0.109750 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :614 ]train loss : 0.083098 ,train acc: 0.994843 ,val loss : 0.104759 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :615 ]train loss : 0.070200 ,train acc: 0.997864 ,val loss : 0.106078 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :616 ]train loss : 0.084351 ,train acc: 0.996613 ,val loss : 0.106432 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :617 ]train loss : 0.064892 ,train acc: 0.997101 ,val loss : 0.110290 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :618 ]train loss : 0.089250 ,train acc: 0.998077 ,val loss : 0.109726 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :619 ]train loss : 0.076122 ,train acc: 0.993866 ,val loss : 0.107791 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :620 ]train loss : 0.117868 ,train acc: 0.982025 ,val loss : 0.106216 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :621 ]train loss : 0.092236 ,train acc: 0.996826 ,val loss : 0.110764 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :622 ]train loss : 0.090752 ,train acc: 0.988831 ,val loss : 0.105192 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :623 ]train loss : 0.081075 ,train acc: 0.990448 ,val loss : 0.105094 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :624 ]train loss : 0.073481 ,train acc: 0.998871 ,val loss : 0.107170 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :625 ]train loss : 0.085966 ,train acc: 0.991028 ,val loss : 0.106237 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :626 ]train loss : 0.099957 ,train acc: 0.997070 ,val loss : 0.106384 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :627 ]train loss : 0.086209 ,train acc: 0.997437 ,val loss : 0.106067 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :628 ]train loss : 0.077860 ,train acc: 0.990234 ,val loss : 0.105435 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :629 ]train loss : 0.239532 ,train acc: 0.869141 ,val loss : 0.106682 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :630 ]train loss : 0.502359 ,train acc: 0.614258 ,val loss : 0.106675 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :631 ]train loss : 0.393663 ,train acc: 0.723511 ,val loss : 0.105013 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :632 ]train loss : 0.060563 ,train acc: 0.998596 ,val loss : 0.108157 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :633 ]train loss : 0.105838 ,train acc: 0.976318 ,val loss : 0.106564 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :634 ]train loss : 0.084652 ,train acc: 0.994019 ,val loss : 0.107372 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :635 ]train loss : 0.417306 ,train acc: 0.749420 ,val loss : 0.104233 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :636 ]train loss : 0.139832 ,train acc: 0.968536 ,val loss : 0.106902 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :637 ]train loss : 0.226416 ,train acc: 0.912140 ,val loss : 0.106271 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :638 ]train loss : 0.108198 ,train acc: 0.980194 ,val loss : 0.107107 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :639 ]train loss : 0.242162 ,train acc: 0.894836 ,val loss : 0.105571 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :640 ]train loss : 0.100977 ,train acc: 0.994843 ,val loss : 0.105416 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :641 ]train loss : 0.125319 ,train acc: 0.982483 ,val loss : 0.107539 ,val acc : 0.992645\n",
      "[ ecpho : 5  iter :642 ]train loss : 0.082825 ,train acc: 0.988739 ,val loss : 0.106177 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :643 ]train loss : 0.246633 ,train acc: 0.910706 ,val loss : 0.105546 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :644 ]train loss : 0.086415 ,train acc: 0.989807 ,val loss : 0.107172 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :645 ]train loss : 0.283045 ,train acc: 0.867828 ,val loss : 0.108227 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :646 ]train loss : 0.106094 ,train acc: 0.970062 ,val loss : 0.106834 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :647 ]train loss : 0.091871 ,train acc: 0.996307 ,val loss : 0.106649 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :648 ]train loss : 0.253942 ,train acc: 0.859894 ,val loss : 0.105743 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :649 ]train loss : 0.077590 ,train acc: 0.993988 ,val loss : 0.106886 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :650 ]train loss : 0.375184 ,train acc: 0.795776 ,val loss : 0.106134 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :651 ]train loss : 0.102233 ,train acc: 0.991943 ,val loss : 0.107217 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :652 ]train loss : 0.108008 ,train acc: 0.989136 ,val loss : 0.105741 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :653 ]train loss : 0.073586 ,train acc: 0.998444 ,val loss : 0.105138 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :654 ]train loss : 0.067476 ,train acc: 0.997711 ,val loss : 0.107992 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :655 ]train loss : 0.068729 ,train acc: 0.999573 ,val loss : 0.106659 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :656 ]train loss : 0.121584 ,train acc: 0.959290 ,val loss : 0.108170 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :657 ]train loss : 0.091935 ,train acc: 0.983093 ,val loss : 0.105818 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :658 ]train loss : 0.100096 ,train acc: 0.977448 ,val loss : 0.106407 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :659 ]train loss : 0.096991 ,train acc: 0.997406 ,val loss : 0.107008 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :660 ]train loss : 0.392503 ,train acc: 0.731323 ,val loss : 0.107094 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :661 ]train loss : 0.093407 ,train acc: 0.981567 ,val loss : 0.109069 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :662 ]train loss : 0.141950 ,train acc: 0.973114 ,val loss : 0.103176 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :663 ]train loss : 0.133089 ,train acc: 0.984222 ,val loss : 0.107495 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :664 ]train loss : 0.112655 ,train acc: 0.984070 ,val loss : 0.105729 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :665 ]train loss : 0.057067 ,train acc: 0.998169 ,val loss : 0.107405 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :666 ]train loss : 0.157453 ,train acc: 0.966095 ,val loss : 0.105292 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :667 ]train loss : 0.741363 ,train acc: 0.476685 ,val loss : 0.105021 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :668 ]train loss : 0.089348 ,train acc: 0.983917 ,val loss : 0.104793 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :669 ]train loss : 0.396280 ,train acc: 0.733765 ,val loss : 0.107429 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :670 ]train loss : 0.076216 ,train acc: 0.992493 ,val loss : 0.107005 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :671 ]train loss : 0.164971 ,train acc: 0.928284 ,val loss : 0.106634 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :672 ]train loss : 0.410998 ,train acc: 0.715881 ,val loss : 0.107736 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :673 ]train loss : 0.300354 ,train acc: 0.827637 ,val loss : 0.106417 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :674 ]train loss : 0.070457 ,train acc: 0.992950 ,val loss : 0.107037 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :675 ]train loss : 0.863168 ,train acc: 0.400177 ,val loss : 0.106382 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :676 ]train loss : 0.163104 ,train acc: 0.934570 ,val loss : 0.106493 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :677 ]train loss : 0.077793 ,train acc: 0.995636 ,val loss : 0.106588 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :678 ]train loss : 0.084370 ,train acc: 0.993988 ,val loss : 0.107665 ,val acc : 0.991699\n",
      "[ ecpho : 5  iter :679 ]train loss : 0.108388 ,train acc: 0.975067 ,val loss : 0.107253 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :680 ]train loss : 0.087399 ,train acc: 0.993591 ,val loss : 0.106717 ,val acc : 0.991852\n",
      "[ ecpho : 5  iter :681 ]train loss : 0.070372 ,train acc: 0.996429 ,val loss : 0.108947 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :682 ]train loss : 1.161495 ,train acc: 0.197052 ,val loss : 0.105664 ,val acc : 0.991455\n",
      "[ ecpho : 5  iter :683 ]train loss : 0.133335 ,train acc: 0.957916 ,val loss : 0.107039 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :684 ]train loss : 0.068762 ,train acc: 0.996887 ,val loss : 0.106476 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :685 ]train loss : 0.070555 ,train acc: 0.997864 ,val loss : 0.103629 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :686 ]train loss : 0.099345 ,train acc: 0.993195 ,val loss : 0.107492 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :687 ]train loss : 0.083263 ,train acc: 0.986359 ,val loss : 0.105929 ,val acc : 0.991516\n",
      "[ ecpho : 5  iter :688 ]train loss : 0.436967 ,train acc: 0.732025 ,val loss : 0.106702 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :689 ]train loss : 0.073630 ,train acc: 0.993439 ,val loss : 0.104825 ,val acc : 0.991486\n",
      "[ ecpho : 5  iter :690 ]train loss : 0.098767 ,train acc: 0.982758 ,val loss : 0.107321 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :691 ]train loss : 0.100963 ,train acc: 0.986145 ,val loss : 0.107980 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :692 ]train loss : 0.082914 ,train acc: 0.984222 ,val loss : 0.106591 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :693 ]train loss : 0.072959 ,train acc: 0.993774 ,val loss : 0.108553 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :694 ]train loss : 0.110340 ,train acc: 0.973297 ,val loss : 0.104963 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :695 ]train loss : 0.110318 ,train acc: 0.985474 ,val loss : 0.104484 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :696 ]train loss : 0.490153 ,train acc: 0.659973 ,val loss : 0.108599 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :697 ]train loss : 0.058017 ,train acc: 0.997498 ,val loss : 0.107363 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :698 ]train loss : 1.423917 ,train acc: 0.020233 ,val loss : 0.107778 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :699 ]train loss : 0.141709 ,train acc: 0.967499 ,val loss : 0.106956 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :700 ]train loss : 0.106066 ,train acc: 0.974548 ,val loss : 0.108074 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :701 ]train loss : 0.085800 ,train acc: 0.991699 ,val loss : 0.107344 ,val acc : 0.991638\n",
      "[ ecpho : 5  iter :702 ]train loss : 0.125429 ,train acc: 0.977753 ,val loss : 0.107439 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :703 ]train loss : 0.159759 ,train acc: 0.957947 ,val loss : 0.108179 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :704 ]train loss : 0.134087 ,train acc: 0.982422 ,val loss : 0.106113 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :705 ]train loss : 0.088573 ,train acc: 0.980957 ,val loss : 0.107766 ,val acc : 0.991821\n",
      "[ ecpho : 5  iter :706 ]train loss : 0.064633 ,train acc: 0.996857 ,val loss : 0.110169 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :707 ]train loss : 0.113688 ,train acc: 0.977203 ,val loss : 0.105636 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :708 ]train loss : 0.095008 ,train acc: 0.973328 ,val loss : 0.106996 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :709 ]train loss : 0.096126 ,train acc: 0.994080 ,val loss : 0.111311 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :710 ]train loss : 0.081807 ,train acc: 0.994537 ,val loss : 0.105355 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :711 ]train loss : 0.162718 ,train acc: 0.925507 ,val loss : 0.107932 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :712 ]train loss : 0.555031 ,train acc: 0.725983 ,val loss : 0.105421 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :713 ]train loss : 0.115456 ,train acc: 0.969543 ,val loss : 0.108109 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :714 ]train loss : 0.099977 ,train acc: 0.975433 ,val loss : 0.106654 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :715 ]train loss : 0.107844 ,train acc: 0.987671 ,val loss : 0.109074 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :716 ]train loss : 0.086841 ,train acc: 0.987488 ,val loss : 0.107649 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :717 ]train loss : 0.091178 ,train acc: 0.989563 ,val loss : 0.108221 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :718 ]train loss : 0.094199 ,train acc: 0.991516 ,val loss : 0.107642 ,val acc : 0.991791\n",
      "[ ecpho : 5  iter :719 ]train loss : 0.095257 ,train acc: 0.991791 ,val loss : 0.105001 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :720 ]train loss : 0.071679 ,train acc: 0.994995 ,val loss : 0.109336 ,val acc : 0.991882\n",
      "[ ecpho : 5  iter :721 ]train loss : 0.105852 ,train acc: 0.988739 ,val loss : 0.105826 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :722 ]train loss : 0.087527 ,train acc: 0.981720 ,val loss : 0.104613 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :723 ]train loss : 0.067237 ,train acc: 0.996704 ,val loss : 0.108024 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :724 ]train loss : 0.075692 ,train acc: 0.998688 ,val loss : 0.105654 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :725 ]train loss : 0.117337 ,train acc: 0.984558 ,val loss : 0.105885 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :726 ]train loss : 0.077884 ,train acc: 0.989777 ,val loss : 0.105864 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :727 ]train loss : 0.083603 ,train acc: 0.983093 ,val loss : 0.106666 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :728 ]train loss : 0.399182 ,train acc: 0.742126 ,val loss : 0.109310 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :729 ]train loss : 0.087075 ,train acc: 0.997650 ,val loss : 0.107787 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :730 ]train loss : 0.096012 ,train acc: 0.981750 ,val loss : 0.104735 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :731 ]train loss : 0.111937 ,train acc: 0.987213 ,val loss : 0.106532 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :732 ]train loss : 0.090727 ,train acc: 0.997650 ,val loss : 0.107059 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :733 ]train loss : 0.087601 ,train acc: 0.994080 ,val loss : 0.104046 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :734 ]train loss : 0.089623 ,train acc: 0.985840 ,val loss : 0.102951 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :735 ]train loss : 0.105176 ,train acc: 0.970398 ,val loss : 0.111103 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :736 ]train loss : 0.091150 ,train acc: 0.987244 ,val loss : 0.106893 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :737 ]train loss : 0.103059 ,train acc: 0.970520 ,val loss : 0.106547 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :738 ]train loss : 0.077462 ,train acc: 0.993591 ,val loss : 0.106747 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :739 ]train loss : 0.092569 ,train acc: 0.985931 ,val loss : 0.106545 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :740 ]train loss : 0.066753 ,train acc: 0.994537 ,val loss : 0.106493 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :741 ]train loss : 0.076895 ,train acc: 0.996704 ,val loss : 0.106465 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :742 ]train loss : 0.060821 ,train acc: 0.997559 ,val loss : 0.106103 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :743 ]train loss : 0.179842 ,train acc: 0.920471 ,val loss : 0.106894 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :744 ]train loss : 0.080852 ,train acc: 0.996155 ,val loss : 0.108917 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :745 ]train loss : 0.193160 ,train acc: 0.947357 ,val loss : 0.109162 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :746 ]train loss : 0.108979 ,train acc: 0.967194 ,val loss : 0.105230 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :747 ]train loss : 0.167428 ,train acc: 0.924316 ,val loss : 0.106050 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :748 ]train loss : 0.631447 ,train acc: 0.604675 ,val loss : 0.104777 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :749 ]train loss : 0.099886 ,train acc: 0.984528 ,val loss : 0.106175 ,val acc : 0.991913\n",
      "[ ecpho : 5  iter :750 ]train loss : 0.069554 ,train acc: 0.995575 ,val loss : 0.105917 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :751 ]train loss : 0.095126 ,train acc: 0.977020 ,val loss : 0.106155 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :752 ]train loss : 0.096882 ,train acc: 0.994904 ,val loss : 0.108078 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :753 ]train loss : 0.187561 ,train acc: 0.906036 ,val loss : 0.104379 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :754 ]train loss : 0.088347 ,train acc: 0.998291 ,val loss : 0.108010 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :755 ]train loss : 0.081961 ,train acc: 0.992218 ,val loss : 0.106696 ,val acc : 0.992065\n",
      "[ ecpho : 5  iter :756 ]train loss : 0.081843 ,train acc: 0.996735 ,val loss : 0.108555 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :757 ]train loss : 0.090291 ,train acc: 0.982025 ,val loss : 0.104759 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :758 ]train loss : 0.069129 ,train acc: 0.995178 ,val loss : 0.107845 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :759 ]train loss : 0.130842 ,train acc: 0.970459 ,val loss : 0.106531 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :760 ]train loss : 0.076034 ,train acc: 0.991333 ,val loss : 0.106871 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :761 ]train loss : 0.105678 ,train acc: 0.977112 ,val loss : 0.105844 ,val acc : 0.991730\n",
      "[ ecpho : 5  iter :762 ]train loss : 0.197632 ,train acc: 0.926483 ,val loss : 0.107786 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :763 ]train loss : 0.079445 ,train acc: 0.992920 ,val loss : 0.105716 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :764 ]train loss : 0.113284 ,train acc: 0.980774 ,val loss : 0.106676 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :765 ]train loss : 0.113773 ,train acc: 0.974884 ,val loss : 0.104886 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :766 ]train loss : 0.130327 ,train acc: 0.976135 ,val loss : 0.103889 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :767 ]train loss : 0.137046 ,train acc: 0.963989 ,val loss : 0.106446 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :768 ]train loss : 0.278369 ,train acc: 0.919617 ,val loss : 0.107137 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :769 ]train loss : 0.093821 ,train acc: 0.983276 ,val loss : 0.106404 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :770 ]train loss : 0.061290 ,train acc: 0.997955 ,val loss : 0.105546 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :771 ]train loss : 0.129783 ,train acc: 0.966827 ,val loss : 0.105767 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :772 ]train loss : 0.066506 ,train acc: 0.997253 ,val loss : 0.107432 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :773 ]train loss : 0.057338 ,train acc: 0.998444 ,val loss : 0.106159 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :774 ]train loss : 0.079682 ,train acc: 0.990143 ,val loss : 0.106316 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :775 ]train loss : 0.060505 ,train acc: 0.996521 ,val loss : 0.104651 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :776 ]train loss : 0.081482 ,train acc: 0.988770 ,val loss : 0.107335 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :777 ]train loss : 0.078539 ,train acc: 0.994446 ,val loss : 0.107909 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :778 ]train loss : 0.074438 ,train acc: 0.994324 ,val loss : 0.106123 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :779 ]train loss : 0.078414 ,train acc: 0.998077 ,val loss : 0.105875 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :780 ]train loss : 0.076913 ,train acc: 0.993408 ,val loss : 0.104076 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :781 ]train loss : 0.095028 ,train acc: 0.990326 ,val loss : 0.106439 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :782 ]train loss : 0.131595 ,train acc: 0.957336 ,val loss : 0.104610 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :783 ]train loss : 0.089402 ,train acc: 0.996124 ,val loss : 0.103744 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :784 ]train loss : 0.096859 ,train acc: 0.993164 ,val loss : 0.107144 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :785 ]train loss : 0.221954 ,train acc: 0.925812 ,val loss : 0.107802 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :786 ]train loss : 0.495735 ,train acc: 0.636993 ,val loss : 0.105893 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :787 ]train loss : 0.063917 ,train acc: 0.999176 ,val loss : 0.107684 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :788 ]train loss : 0.082419 ,train acc: 0.992645 ,val loss : 0.104565 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :789 ]train loss : 0.075633 ,train acc: 0.995117 ,val loss : 0.106357 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :790 ]train loss : 0.076287 ,train acc: 0.994812 ,val loss : 0.104827 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :791 ]train loss : 0.106850 ,train acc: 0.971375 ,val loss : 0.104525 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :792 ]train loss : 0.071591 ,train acc: 0.998108 ,val loss : 0.105157 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :793 ]train loss : 0.108854 ,train acc: 0.992218 ,val loss : 0.106950 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :794 ]train loss : 0.101062 ,train acc: 0.988708 ,val loss : 0.104668 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :795 ]train loss : 0.150953 ,train acc: 0.940186 ,val loss : 0.103509 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :796 ]train loss : 0.215840 ,train acc: 0.876007 ,val loss : 0.106498 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :797 ]train loss : 0.104092 ,train acc: 0.992950 ,val loss : 0.104320 ,val acc : 0.992950\n",
      "[ ecpho : 5  iter :798 ]train loss : 0.062965 ,train acc: 0.998108 ,val loss : 0.107789 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :799 ]train loss : 0.062376 ,train acc: 0.997803 ,val loss : 0.107664 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :800 ]train loss : 0.062949 ,train acc: 0.999207 ,val loss : 0.105006 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :801 ]train loss : 0.240375 ,train acc: 0.913513 ,val loss : 0.106460 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :802 ]train loss : 0.460039 ,train acc: 0.692627 ,val loss : 0.106651 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :803 ]train loss : 0.293478 ,train acc: 0.849457 ,val loss : 0.106156 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :804 ]train loss : 0.088895 ,train acc: 0.993347 ,val loss : 0.105505 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :805 ]train loss : 0.119810 ,train acc: 0.976471 ,val loss : 0.104446 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :806 ]train loss : 0.152994 ,train acc: 0.962433 ,val loss : 0.105676 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :807 ]train loss : 0.059360 ,train acc: 0.997894 ,val loss : 0.105011 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :808 ]train loss : 0.083632 ,train acc: 0.996460 ,val loss : 0.106398 ,val acc : 0.992035\n",
      "[ ecpho : 5  iter :809 ]train loss : 0.285941 ,train acc: 0.801147 ,val loss : 0.106535 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :810 ]train loss : 0.107922 ,train acc: 0.988129 ,val loss : 0.104313 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :811 ]train loss : 0.069187 ,train acc: 0.997925 ,val loss : 0.105961 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :812 ]train loss : 0.080501 ,train acc: 0.993500 ,val loss : 0.106450 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :813 ]train loss : 0.520822 ,train acc: 0.609650 ,val loss : 0.104070 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :814 ]train loss : 0.085566 ,train acc: 0.993835 ,val loss : 0.106087 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :815 ]train loss : 0.097041 ,train acc: 0.992462 ,val loss : 0.105654 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :816 ]train loss : 0.107978 ,train acc: 0.987762 ,val loss : 0.107049 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :817 ]train loss : 0.065654 ,train acc: 0.997620 ,val loss : 0.102907 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :818 ]train loss : 0.121049 ,train acc: 0.964966 ,val loss : 0.105376 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :819 ]train loss : 0.080156 ,train acc: 0.986450 ,val loss : 0.106482 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :820 ]train loss : 0.057480 ,train acc: 0.998688 ,val loss : 0.106845 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :821 ]train loss : 0.075343 ,train acc: 0.989960 ,val loss : 0.107886 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :822 ]train loss : 0.075413 ,train acc: 0.995361 ,val loss : 0.105822 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :823 ]train loss : 0.076357 ,train acc: 0.994293 ,val loss : 0.106539 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :824 ]train loss : 0.122726 ,train acc: 0.973297 ,val loss : 0.105866 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :825 ]train loss : 0.063332 ,train acc: 0.999054 ,val loss : 0.106356 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :826 ]train loss : 0.154670 ,train acc: 0.930664 ,val loss : 0.106166 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :827 ]train loss : 0.082501 ,train acc: 0.986298 ,val loss : 0.108870 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :828 ]train loss : 0.072608 ,train acc: 0.995148 ,val loss : 0.108271 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :829 ]train loss : 0.091047 ,train acc: 0.983795 ,val loss : 0.107350 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :830 ]train loss : 0.154448 ,train acc: 0.961884 ,val loss : 0.105176 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :831 ]train loss : 0.101374 ,train acc: 0.991364 ,val loss : 0.105789 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :832 ]train loss : 0.086369 ,train acc: 0.991821 ,val loss : 0.107803 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :833 ]train loss : 0.070583 ,train acc: 0.997284 ,val loss : 0.106178 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :834 ]train loss : 0.096890 ,train acc: 0.995941 ,val loss : 0.105378 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :835 ]train loss : 0.104898 ,train acc: 0.985535 ,val loss : 0.103995 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :836 ]train loss : 0.070981 ,train acc: 0.996704 ,val loss : 0.106941 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :837 ]train loss : 0.080062 ,train acc: 0.997498 ,val loss : 0.104961 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :838 ]train loss : 0.114786 ,train acc: 0.966736 ,val loss : 0.107491 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :839 ]train loss : 0.124257 ,train acc: 0.958008 ,val loss : 0.104720 ,val acc : 0.992859\n",
      "[ ecpho : 5  iter :840 ]train loss : 0.082729 ,train acc: 0.995300 ,val loss : 0.107838 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :841 ]train loss : 0.142814 ,train acc: 0.961914 ,val loss : 0.107433 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :842 ]train loss : 0.099650 ,train acc: 0.991821 ,val loss : 0.104592 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :843 ]train loss : 0.412183 ,train acc: 0.760559 ,val loss : 0.105448 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :844 ]train loss : 0.080143 ,train acc: 0.990601 ,val loss : 0.107014 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :845 ]train loss : 0.079992 ,train acc: 0.990601 ,val loss : 0.104835 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :846 ]train loss : 0.066205 ,train acc: 0.997650 ,val loss : 0.107256 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :847 ]train loss : 0.258632 ,train acc: 0.869141 ,val loss : 0.105322 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :848 ]train loss : 0.266189 ,train acc: 0.916565 ,val loss : 0.104853 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :849 ]train loss : 0.076285 ,train acc: 0.998383 ,val loss : 0.104428 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :850 ]train loss : 0.098303 ,train acc: 0.982483 ,val loss : 0.105450 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :851 ]train loss : 0.321289 ,train acc: 0.791168 ,val loss : 0.104339 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :852 ]train loss : 0.572539 ,train acc: 0.622284 ,val loss : 0.104700 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :853 ]train loss : 0.061297 ,train acc: 0.997650 ,val loss : 0.104444 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :854 ]train loss : 0.232071 ,train acc: 0.859985 ,val loss : 0.105388 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :855 ]train loss : 0.079752 ,train acc: 0.992126 ,val loss : 0.103642 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :856 ]train loss : 0.057788 ,train acc: 0.998047 ,val loss : 0.106167 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :857 ]train loss : 0.089316 ,train acc: 0.984558 ,val loss : 0.104301 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :858 ]train loss : 0.234212 ,train acc: 0.910065 ,val loss : 0.104524 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :859 ]train loss : 0.072602 ,train acc: 0.991608 ,val loss : 0.105270 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :860 ]train loss : 0.107994 ,train acc: 0.988098 ,val loss : 0.104408 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :861 ]train loss : 0.068039 ,train acc: 0.997498 ,val loss : 0.103055 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :862 ]train loss : 0.229492 ,train acc: 0.873718 ,val loss : 0.104397 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :863 ]train loss : 0.121809 ,train acc: 0.988098 ,val loss : 0.103562 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :864 ]train loss : 0.163064 ,train acc: 0.933105 ,val loss : 0.105558 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :865 ]train loss : 0.094738 ,train acc: 0.991028 ,val loss : 0.105162 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :866 ]train loss : 0.137665 ,train acc: 0.952057 ,val loss : 0.106462 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :867 ]train loss : 0.069262 ,train acc: 0.992218 ,val loss : 0.104868 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :868 ]train loss : 0.236334 ,train acc: 0.859100 ,val loss : 0.104112 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :869 ]train loss : 0.094901 ,train acc: 0.991638 ,val loss : 0.104183 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :870 ]train loss : 0.099358 ,train acc: 0.992645 ,val loss : 0.103717 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :871 ]train loss : 0.062566 ,train acc: 0.999146 ,val loss : 0.105033 ,val acc : 0.992767\n",
      "[ ecpho : 5  iter :872 ]train loss : 0.080203 ,train acc: 0.995361 ,val loss : 0.106914 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :873 ]train loss : 0.076919 ,train acc: 0.992950 ,val loss : 0.105757 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :874 ]train loss : 0.099236 ,train acc: 0.976166 ,val loss : 0.102985 ,val acc : 0.992371\n",
      "[ ecpho : 5  iter :875 ]train loss : 0.327320 ,train acc: 0.792480 ,val loss : 0.103798 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :876 ]train loss : 0.071193 ,train acc: 0.998474 ,val loss : 0.106916 ,val acc : 0.992706\n",
      "[ ecpho : 5  iter :877 ]train loss : 0.074644 ,train acc: 0.995514 ,val loss : 0.105186 ,val acc : 0.992737\n",
      "[ ecpho : 5  iter :878 ]train loss : 0.087829 ,train acc: 0.982330 ,val loss : 0.102619 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :879 ]train loss : 0.614453 ,train acc: 0.552765 ,val loss : 0.107431 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :880 ]train loss : 0.149042 ,train acc: 0.973358 ,val loss : 0.103712 ,val acc : 0.992584\n",
      "[ ecpho : 5  iter :881 ]train loss : 1.174098 ,train acc: 0.203949 ,val loss : 0.106148 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :882 ]train loss : 0.065552 ,train acc: 0.995361 ,val loss : 0.105236 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :883 ]train loss : 0.107488 ,train acc: 0.986176 ,val loss : 0.105274 ,val acc : 0.991608\n",
      "[ ecpho : 5  iter :884 ]train loss : 0.067204 ,train acc: 0.997864 ,val loss : 0.105313 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :885 ]train loss : 0.210220 ,train acc: 0.934235 ,val loss : 0.106266 ,val acc : 0.992493\n",
      "[ ecpho : 5  iter :886 ]train loss : 0.089398 ,train acc: 0.992859 ,val loss : 0.103973 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :887 ]train loss : 0.272095 ,train acc: 0.877625 ,val loss : 0.105758 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :888 ]train loss : 0.097985 ,train acc: 0.980713 ,val loss : 0.103840 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :889 ]train loss : 0.191057 ,train acc: 0.952393 ,val loss : 0.102058 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :890 ]train loss : 0.125542 ,train acc: 0.985840 ,val loss : 0.106635 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :891 ]train loss : 0.091289 ,train acc: 0.994324 ,val loss : 0.105162 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :892 ]train loss : 0.124391 ,train acc: 0.956146 ,val loss : 0.102152 ,val acc : 0.992859\n",
      "[ ecpho : 5  iter :893 ]train loss : 0.071408 ,train acc: 0.992615 ,val loss : 0.103223 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :894 ]train loss : 0.060220 ,train acc: 0.998199 ,val loss : 0.104109 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :895 ]train loss : 0.073060 ,train acc: 0.992096 ,val loss : 0.104537 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :896 ]train loss : 0.102896 ,train acc: 0.990967 ,val loss : 0.102728 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :897 ]train loss : 0.113234 ,train acc: 0.973389 ,val loss : 0.103795 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :898 ]train loss : 0.102297 ,train acc: 0.979340 ,val loss : 0.105047 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :899 ]train loss : 0.081642 ,train acc: 0.985687 ,val loss : 0.102699 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :900 ]train loss : 0.083038 ,train acc: 0.989105 ,val loss : 0.105129 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :901 ]train loss : 0.107623 ,train acc: 0.986511 ,val loss : 0.104457 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :902 ]train loss : 0.114751 ,train acc: 0.970978 ,val loss : 0.102810 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :903 ]train loss : 0.417872 ,train acc: 0.704498 ,val loss : 0.104265 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :904 ]train loss : 0.166379 ,train acc: 0.918152 ,val loss : 0.105951 ,val acc : 0.992798\n",
      "[ ecpho : 5  iter :905 ]train loss : 0.069690 ,train acc: 0.996582 ,val loss : 0.105941 ,val acc : 0.992554\n",
      "[ ecpho : 5  iter :906 ]train loss : 0.069333 ,train acc: 0.997528 ,val loss : 0.103912 ,val acc : 0.992615\n",
      "[ ecpho : 5  iter :907 ]train loss : 0.639408 ,train acc: 0.567932 ,val loss : 0.108064 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :908 ]train loss : 0.118095 ,train acc: 0.965668 ,val loss : 0.103723 ,val acc : 0.992523\n",
      "[ ecpho : 5  iter :909 ]train loss : 0.219452 ,train acc: 0.920288 ,val loss : 0.103388 ,val acc : 0.991943\n",
      "[ ecpho : 5  iter :910 ]train loss : 0.087232 ,train acc: 0.997101 ,val loss : 0.105841 ,val acc : 0.992188\n",
      "[ ecpho : 5  iter :911 ]train loss : 0.216810 ,train acc: 0.913025 ,val loss : 0.104280 ,val acc : 0.991760\n",
      "[ ecpho : 5  iter :912 ]train loss : 0.189743 ,train acc: 0.918365 ,val loss : 0.106947 ,val acc : 0.992645\n",
      "[ ecpho : 5  iter :913 ]train loss : 0.064238 ,train acc: 0.998322 ,val loss : 0.103415 ,val acc : 0.992645\n",
      "[ ecpho : 5  iter :914 ]train loss : 0.057483 ,train acc: 0.998383 ,val loss : 0.106671 ,val acc : 0.992279\n",
      "[ ecpho : 5  iter :915 ]train loss : 0.980826 ,train acc: 0.422852 ,val loss : 0.103288 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :916 ]train loss : 0.178500 ,train acc: 0.933624 ,val loss : 0.102577 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :917 ]train loss : 0.101774 ,train acc: 0.979034 ,val loss : 0.105102 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :918 ]train loss : 0.130193 ,train acc: 0.956390 ,val loss : 0.106552 ,val acc : 0.992157\n",
      "[ ecpho : 5  iter :919 ]train loss : 0.074872 ,train acc: 0.990753 ,val loss : 0.103779 ,val acc : 0.992859\n",
      "[ ecpho : 5  iter :920 ]train loss : 0.353124 ,train acc: 0.774567 ,val loss : 0.104198 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :921 ]train loss : 0.082982 ,train acc: 0.988190 ,val loss : 0.103968 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :922 ]train loss : 0.150988 ,train acc: 0.971802 ,val loss : 0.104523 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :923 ]train loss : 0.067971 ,train acc: 0.997314 ,val loss : 0.105026 ,val acc : 0.992340\n",
      "[ ecpho : 5  iter :924 ]train loss : 0.149923 ,train acc: 0.941162 ,val loss : 0.106350 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :925 ]train loss : 0.085313 ,train acc: 0.994263 ,val loss : 0.104906 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :926 ]train loss : 0.065085 ,train acc: 0.998108 ,val loss : 0.106374 ,val acc : 0.992126\n",
      "[ ecpho : 5  iter :927 ]train loss : 0.329022 ,train acc: 0.785248 ,val loss : 0.105456 ,val acc : 0.992676\n",
      "[ ecpho : 5  iter :928 ]train loss : 0.063985 ,train acc: 0.997498 ,val loss : 0.104212 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :929 ]train loss : 0.114890 ,train acc: 0.984467 ,val loss : 0.104823 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :930 ]train loss : 0.082933 ,train acc: 0.987579 ,val loss : 0.108305 ,val acc : 0.992310\n",
      "[ ecpho : 5  iter :931 ]train loss : 0.069350 ,train acc: 0.993927 ,val loss : 0.105550 ,val acc : 0.992249\n",
      "[ ecpho : 5  iter :932 ]train loss : 0.206377 ,train acc: 0.902924 ,val loss : 0.103895 ,val acc : 0.992432\n",
      "[ ecpho : 5  iter :933 ]train loss : 0.083821 ,train acc: 0.998383 ,val loss : 0.106337 ,val acc : 0.992401\n",
      "[ ecpho : 5  iter :934 ]train loss : 0.170507 ,train acc: 0.919312 ,val loss : 0.104429 ,val acc : 0.992462\n",
      "[ ecpho : 5  iter :935 ]train loss : 0.086880 ,train acc: 0.997040 ,val loss : 0.105573 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :936 ]train loss : 0.079281 ,train acc: 0.993774 ,val loss : 0.105388 ,val acc : 0.992096\n",
      "[ ecpho : 5  iter :937 ]train loss : 0.082604 ,train acc: 0.988525 ,val loss : 0.104380 ,val acc : 0.992004\n",
      "[ ecpho : 5  iter :938 ]train loss : 0.114314 ,train acc: 0.987640 ,val loss : 0.103128 ,val acc : 0.992218\n",
      "[ ecpho : 5  iter :939 ]train loss : 0.145060 ,train acc: 0.949127 ,val loss : 0.104341 ,val acc : 0.991974\n",
      "[ ecpho : 5  iter :940 ]train loss : 0.157177 ,train acc: 0.971924 ,val loss : 0.107255 ,val acc : 0.992401\n",
      "=============================================\n",
      "[ 5 ] average train loss : 0.162091 train acc : 0.934505\n",
      "[ ecpho : 6  iter :1 ]train loss : 0.075607 ,train acc: 0.991241 ,val loss : 0.103300 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :2 ]train loss : 0.225522 ,train acc: 0.894165 ,val loss : 0.106614 ,val acc : 0.992889\n",
      "[ ecpho : 6  iter :3 ]train loss : 0.073641 ,train acc: 0.993530 ,val loss : 0.104228 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :4 ]train loss : 0.102944 ,train acc: 0.974304 ,val loss : 0.104230 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :5 ]train loss : 0.091901 ,train acc: 0.994659 ,val loss : 0.103324 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :6 ]train loss : 0.093334 ,train acc: 0.993622 ,val loss : 0.104312 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :7 ]train loss : 0.092787 ,train acc: 0.977692 ,val loss : 0.104948 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :8 ]train loss : 0.336734 ,train acc: 0.859589 ,val loss : 0.104516 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :9 ]train loss : 0.167640 ,train acc: 0.926361 ,val loss : 0.104609 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :10 ]train loss : 0.150322 ,train acc: 0.952515 ,val loss : 0.104209 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :11 ]train loss : 0.068774 ,train acc: 0.998779 ,val loss : 0.104369 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :12 ]train loss : 0.088175 ,train acc: 0.994080 ,val loss : 0.104131 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :13 ]train loss : 0.088099 ,train acc: 0.985504 ,val loss : 0.104636 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :14 ]train loss : 0.093292 ,train acc: 0.997101 ,val loss : 0.105824 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :15 ]train loss : 0.084454 ,train acc: 0.983368 ,val loss : 0.103035 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :16 ]train loss : 0.089631 ,train acc: 0.993591 ,val loss : 0.103478 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :17 ]train loss : 0.085645 ,train acc: 0.996185 ,val loss : 0.105050 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :18 ]train loss : 0.755120 ,train acc: 0.505402 ,val loss : 0.103089 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :19 ]train loss : 0.094339 ,train acc: 0.981018 ,val loss : 0.102089 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :20 ]train loss : 0.096276 ,train acc: 0.992432 ,val loss : 0.106896 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :21 ]train loss : 0.109410 ,train acc: 0.985535 ,val loss : 0.106223 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :22 ]train loss : 0.115608 ,train acc: 0.973114 ,val loss : 0.107144 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :23 ]train loss : 0.057785 ,train acc: 0.999054 ,val loss : 0.103949 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :24 ]train loss : 0.103486 ,train acc: 0.991669 ,val loss : 0.107624 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :25 ]train loss : 0.102183 ,train acc: 0.976257 ,val loss : 0.103288 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :26 ]train loss : 0.411912 ,train acc: 0.779694 ,val loss : 0.106006 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :27 ]train loss : 0.350358 ,train acc: 0.770477 ,val loss : 0.105739 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :28 ]train loss : 0.083616 ,train acc: 0.994781 ,val loss : 0.103916 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :29 ]train loss : 0.100212 ,train acc: 0.982330 ,val loss : 0.105347 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :30 ]train loss : 0.073147 ,train acc: 0.995026 ,val loss : 0.104673 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :31 ]train loss : 0.077662 ,train acc: 0.991882 ,val loss : 0.106028 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :32 ]train loss : 0.075952 ,train acc: 0.988953 ,val loss : 0.103496 ,val acc : 0.992798\n",
      "[ ecpho : 6  iter :33 ]train loss : 0.058295 ,train acc: 0.997864 ,val loss : 0.107116 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :34 ]train loss : 0.083604 ,train acc: 0.994293 ,val loss : 0.104831 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :35 ]train loss : 0.067078 ,train acc: 0.997162 ,val loss : 0.106036 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :36 ]train loss : 0.112406 ,train acc: 0.969360 ,val loss : 0.105595 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :37 ]train loss : 0.097752 ,train acc: 0.994202 ,val loss : 0.105255 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :38 ]train loss : 0.112351 ,train acc: 0.964264 ,val loss : 0.105345 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :39 ]train loss : 0.252569 ,train acc: 0.854553 ,val loss : 0.105583 ,val acc : 0.992798\n",
      "[ ecpho : 6  iter :40 ]train loss : 0.214357 ,train acc: 0.939667 ,val loss : 0.104632 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :41 ]train loss : 0.075744 ,train acc: 0.994507 ,val loss : 0.104904 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :42 ]train loss : 0.074926 ,train acc: 0.993927 ,val loss : 0.106720 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :43 ]train loss : 0.177219 ,train acc: 0.955170 ,val loss : 0.104927 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :44 ]train loss : 0.084851 ,train acc: 0.989838 ,val loss : 0.102850 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :45 ]train loss : 0.099356 ,train acc: 0.984802 ,val loss : 0.105558 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :46 ]train loss : 0.756498 ,train acc: 0.428589 ,val loss : 0.105280 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :47 ]train loss : 0.092518 ,train acc: 0.977753 ,val loss : 0.105634 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :48 ]train loss : 0.107242 ,train acc: 0.985413 ,val loss : 0.104109 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :49 ]train loss : 0.100807 ,train acc: 0.992218 ,val loss : 0.105328 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :50 ]train loss : 0.102301 ,train acc: 0.974396 ,val loss : 0.103516 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :51 ]train loss : 0.080006 ,train acc: 0.995544 ,val loss : 0.106591 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :52 ]train loss : 0.105620 ,train acc: 0.991058 ,val loss : 0.106686 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :53 ]train loss : 0.104431 ,train acc: 0.974670 ,val loss : 0.103697 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :54 ]train loss : 0.171366 ,train acc: 0.921021 ,val loss : 0.104992 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :55 ]train loss : 0.112046 ,train acc: 0.991913 ,val loss : 0.106002 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :56 ]train loss : 0.188019 ,train acc: 0.915924 ,val loss : 0.103260 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :57 ]train loss : 0.357060 ,train acc: 0.771606 ,val loss : 0.104578 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :58 ]train loss : 0.073579 ,train acc: 0.992065 ,val loss : 0.104527 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :59 ]train loss : 0.128594 ,train acc: 0.966949 ,val loss : 0.104893 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :60 ]train loss : 0.065721 ,train acc: 0.998962 ,val loss : 0.105316 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :61 ]train loss : 0.143313 ,train acc: 0.951202 ,val loss : 0.104046 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :62 ]train loss : 0.124508 ,train acc: 0.955933 ,val loss : 0.103274 ,val acc : 0.992737\n",
      "[ ecpho : 6  iter :63 ]train loss : 0.430147 ,train acc: 0.710571 ,val loss : 0.103609 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :64 ]train loss : 0.382470 ,train acc: 0.782745 ,val loss : 0.104410 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :65 ]train loss : 0.134914 ,train acc: 0.980621 ,val loss : 0.105210 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :66 ]train loss : 0.077675 ,train acc: 0.997162 ,val loss : 0.105409 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :67 ]train loss : 0.109886 ,train acc: 0.980835 ,val loss : 0.103674 ,val acc : 0.992737\n",
      "[ ecpho : 6  iter :68 ]train loss : 0.076722 ,train acc: 0.997192 ,val loss : 0.103913 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :69 ]train loss : 0.086555 ,train acc: 0.996307 ,val loss : 0.104034 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :70 ]train loss : 0.114605 ,train acc: 0.984711 ,val loss : 0.107628 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :71 ]train loss : 0.078435 ,train acc: 0.991150 ,val loss : 0.102362 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :72 ]train loss : 0.083829 ,train acc: 0.985413 ,val loss : 0.105628 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :73 ]train loss : 0.070588 ,train acc: 0.994019 ,val loss : 0.104381 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :74 ]train loss : 0.530344 ,train acc: 0.643219 ,val loss : 0.102047 ,val acc : 0.992859\n",
      "[ ecpho : 6  iter :75 ]train loss : 0.105376 ,train acc: 0.972321 ,val loss : 0.102091 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :76 ]train loss : 0.062316 ,train acc: 0.997986 ,val loss : 0.106173 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :77 ]train loss : 0.078270 ,train acc: 0.991882 ,val loss : 0.105814 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :78 ]train loss : 0.065713 ,train acc: 0.993652 ,val loss : 0.104325 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :79 ]train loss : 0.060169 ,train acc: 0.996246 ,val loss : 0.104015 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :80 ]train loss : 0.099166 ,train acc: 0.992676 ,val loss : 0.102776 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :81 ]train loss : 0.096546 ,train acc: 0.981873 ,val loss : 0.104536 ,val acc : 0.992859\n",
      "[ ecpho : 6  iter :82 ]train loss : 0.456220 ,train acc: 0.715881 ,val loss : 0.104866 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :83 ]train loss : 0.079149 ,train acc: 0.991638 ,val loss : 0.104728 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :84 ]train loss : 0.078094 ,train acc: 0.998383 ,val loss : 0.102046 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :85 ]train loss : 0.069087 ,train acc: 0.995514 ,val loss : 0.104772 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :86 ]train loss : 0.066318 ,train acc: 0.997437 ,val loss : 0.104369 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :87 ]train loss : 0.093805 ,train acc: 0.987213 ,val loss : 0.104836 ,val acc : 0.992798\n",
      "[ ecpho : 6  iter :88 ]train loss : 0.110974 ,train acc: 0.987274 ,val loss : 0.102271 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :89 ]train loss : 0.221153 ,train acc: 0.880493 ,val loss : 0.103859 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :90 ]train loss : 0.314435 ,train acc: 0.866669 ,val loss : 0.103216 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :91 ]train loss : 0.077083 ,train acc: 0.997253 ,val loss : 0.104359 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :92 ]train loss : 0.158342 ,train acc: 0.929779 ,val loss : 0.106812 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :93 ]train loss : 0.371403 ,train acc: 0.783295 ,val loss : 0.103538 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :94 ]train loss : 0.079877 ,train acc: 0.996674 ,val loss : 0.105651 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :95 ]train loss : 0.590299 ,train acc: 0.691406 ,val loss : 0.103393 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :96 ]train loss : 0.115613 ,train acc: 0.974060 ,val loss : 0.104666 ,val acc : 0.992798\n",
      "[ ecpho : 6  iter :97 ]train loss : 0.094516 ,train acc: 0.979614 ,val loss : 0.104841 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :98 ]train loss : 0.088758 ,train acc: 0.994598 ,val loss : 0.105451 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :99 ]train loss : 0.061692 ,train acc: 0.997650 ,val loss : 0.103765 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :100 ]train loss : 0.128413 ,train acc: 0.974274 ,val loss : 0.105828 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :101 ]train loss : 0.091166 ,train acc: 0.993866 ,val loss : 0.104216 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :102 ]train loss : 0.486791 ,train acc: 0.690887 ,val loss : 0.104398 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :103 ]train loss : 0.489824 ,train acc: 0.753143 ,val loss : 0.105271 ,val acc : 0.992767\n",
      "[ ecpho : 6  iter :104 ]train loss : 0.459303 ,train acc: 0.684418 ,val loss : 0.102976 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :105 ]train loss : 0.080779 ,train acc: 0.991272 ,val loss : 0.105577 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :106 ]train loss : 0.130923 ,train acc: 0.977539 ,val loss : 0.103737 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :107 ]train loss : 0.149772 ,train acc: 0.961578 ,val loss : 0.105199 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :108 ]train loss : 0.096678 ,train acc: 0.993317 ,val loss : 0.103012 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :109 ]train loss : 0.209219 ,train acc: 0.915863 ,val loss : 0.103472 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :110 ]train loss : 0.065490 ,train acc: 0.998047 ,val loss : 0.103661 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :111 ]train loss : 0.254966 ,train acc: 0.865997 ,val loss : 0.104638 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :112 ]train loss : 0.095545 ,train acc: 0.983368 ,val loss : 0.104562 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :113 ]train loss : 0.785917 ,train acc: 0.464142 ,val loss : 0.106318 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :114 ]train loss : 0.077351 ,train acc: 0.989471 ,val loss : 0.103409 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :115 ]train loss : 0.069996 ,train acc: 0.992767 ,val loss : 0.107105 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :116 ]train loss : 0.313009 ,train acc: 0.791351 ,val loss : 0.102690 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :117 ]train loss : 0.112434 ,train acc: 0.968719 ,val loss : 0.106432 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :118 ]train loss : 0.113614 ,train acc: 0.961395 ,val loss : 0.105033 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :119 ]train loss : 0.085193 ,train acc: 0.992401 ,val loss : 0.104693 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :120 ]train loss : 0.061980 ,train acc: 0.998352 ,val loss : 0.104739 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :121 ]train loss : 0.590981 ,train acc: 0.606262 ,val loss : 0.105583 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :122 ]train loss : 0.077323 ,train acc: 0.991547 ,val loss : 0.107339 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :123 ]train loss : 0.083697 ,train acc: 0.997192 ,val loss : 0.103190 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :124 ]train loss : 0.074982 ,train acc: 0.995422 ,val loss : 0.102820 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :125 ]train loss : 0.095837 ,train acc: 0.991516 ,val loss : 0.105666 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :126 ]train loss : 0.062478 ,train acc: 0.998322 ,val loss : 0.105820 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :127 ]train loss : 0.905755 ,train acc: 0.354095 ,val loss : 0.105811 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :128 ]train loss : 0.095136 ,train acc: 0.990234 ,val loss : 0.101983 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :129 ]train loss : 0.525582 ,train acc: 0.658539 ,val loss : 0.104216 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :130 ]train loss : 0.417615 ,train acc: 0.712708 ,val loss : 0.105088 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :131 ]train loss : 0.100174 ,train acc: 0.975555 ,val loss : 0.105387 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :132 ]train loss : 0.087767 ,train acc: 0.993408 ,val loss : 0.106681 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :133 ]train loss : 0.297177 ,train acc: 0.850708 ,val loss : 0.105861 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :134 ]train loss : 0.475403 ,train acc: 0.702728 ,val loss : 0.105094 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :135 ]train loss : 0.118646 ,train acc: 0.983368 ,val loss : 0.108382 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :136 ]train loss : 0.127497 ,train acc: 0.958984 ,val loss : 0.105588 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :137 ]train loss : 0.098877 ,train acc: 0.984497 ,val loss : 0.106868 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :138 ]train loss : 0.067663 ,train acc: 0.997528 ,val loss : 0.104878 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :139 ]train loss : 0.059188 ,train acc: 0.999298 ,val loss : 0.105798 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :140 ]train loss : 0.072671 ,train acc: 0.996826 ,val loss : 0.107415 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :141 ]train loss : 0.586144 ,train acc: 0.552887 ,val loss : 0.109017 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :142 ]train loss : 0.082670 ,train acc: 0.982666 ,val loss : 0.106785 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :143 ]train loss : 0.098140 ,train acc: 0.977875 ,val loss : 0.106420 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :144 ]train loss : 0.098520 ,train acc: 0.974701 ,val loss : 0.106709 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :145 ]train loss : 0.070463 ,train acc: 0.991547 ,val loss : 0.103819 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :146 ]train loss : 0.073074 ,train acc: 0.991943 ,val loss : 0.104863 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :147 ]train loss : 0.071392 ,train acc: 0.993805 ,val loss : 0.105570 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :148 ]train loss : 1.088746 ,train acc: 0.221649 ,val loss : 0.104912 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :149 ]train loss : 0.140940 ,train acc: 0.949371 ,val loss : 0.105780 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :150 ]train loss : 0.113694 ,train acc: 0.977234 ,val loss : 0.106660 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :151 ]train loss : 0.800710 ,train acc: 0.428650 ,val loss : 0.106621 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :152 ]train loss : 0.225796 ,train acc: 0.924042 ,val loss : 0.105175 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :153 ]train loss : 0.129125 ,train acc: 0.954712 ,val loss : 0.106300 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :154 ]train loss : 0.194056 ,train acc: 0.942566 ,val loss : 0.105748 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :155 ]train loss : 0.096475 ,train acc: 0.988647 ,val loss : 0.107062 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :156 ]train loss : 0.081283 ,train acc: 0.988525 ,val loss : 0.106675 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :157 ]train loss : 0.090767 ,train acc: 0.996552 ,val loss : 0.106094 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :158 ]train loss : 0.074583 ,train acc: 0.996368 ,val loss : 0.107876 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :159 ]train loss : 0.113487 ,train acc: 0.985229 ,val loss : 0.107627 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :160 ]train loss : 0.122378 ,train acc: 0.962219 ,val loss : 0.106904 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :161 ]train loss : 1.190958 ,train acc: 0.125488 ,val loss : 0.103530 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :162 ]train loss : 0.156828 ,train acc: 0.948273 ,val loss : 0.105690 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :163 ]train loss : 0.114910 ,train acc: 0.965759 ,val loss : 0.106851 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :164 ]train loss : 0.133322 ,train acc: 0.976624 ,val loss : 0.107378 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :165 ]train loss : 0.078212 ,train acc: 0.995972 ,val loss : 0.103858 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :166 ]train loss : 0.084880 ,train acc: 0.987335 ,val loss : 0.106473 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :167 ]train loss : 0.431674 ,train acc: 0.725830 ,val loss : 0.106744 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :168 ]train loss : 0.127089 ,train acc: 0.958618 ,val loss : 0.105851 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :169 ]train loss : 0.312042 ,train acc: 0.841248 ,val loss : 0.108107 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :170 ]train loss : 0.829434 ,train acc: 0.443787 ,val loss : 0.106909 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :171 ]train loss : 0.082192 ,train acc: 0.989838 ,val loss : 0.107547 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :172 ]train loss : 0.394597 ,train acc: 0.799744 ,val loss : 0.105908 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :173 ]train loss : 0.693033 ,train acc: 0.528809 ,val loss : 0.109176 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :174 ]train loss : 0.117407 ,train acc: 0.986542 ,val loss : 0.106245 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :175 ]train loss : 0.068309 ,train acc: 0.997833 ,val loss : 0.109134 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :176 ]train loss : 0.264500 ,train acc: 0.836548 ,val loss : 0.109087 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :177 ]train loss : 0.097228 ,train acc: 0.987335 ,val loss : 0.107061 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :178 ]train loss : 0.091937 ,train acc: 0.992371 ,val loss : 0.106526 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :179 ]train loss : 0.175908 ,train acc: 0.920013 ,val loss : 0.104368 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :180 ]train loss : 0.078913 ,train acc: 0.989532 ,val loss : 0.106931 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :181 ]train loss : 0.185862 ,train acc: 0.953522 ,val loss : 0.105201 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :182 ]train loss : 0.117217 ,train acc: 0.982513 ,val loss : 0.109422 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :183 ]train loss : 0.080622 ,train acc: 0.992371 ,val loss : 0.107117 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :184 ]train loss : 0.086462 ,train acc: 0.990295 ,val loss : 0.106086 ,val acc : 0.991241\n",
      "[ ecpho : 6  iter :185 ]train loss : 0.823181 ,train acc: 0.384430 ,val loss : 0.106944 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :186 ]train loss : 0.122187 ,train acc: 0.960571 ,val loss : 0.110499 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :187 ]train loss : 0.114960 ,train acc: 0.982086 ,val loss : 0.106591 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :188 ]train loss : 0.090893 ,train acc: 0.995911 ,val loss : 0.106908 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :189 ]train loss : 0.068172 ,train acc: 0.997437 ,val loss : 0.107983 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :190 ]train loss : 0.105843 ,train acc: 0.991669 ,val loss : 0.105859 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :191 ]train loss : 0.186021 ,train acc: 0.911133 ,val loss : 0.106211 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :192 ]train loss : 0.075368 ,train acc: 0.994598 ,val loss : 0.109136 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :193 ]train loss : 0.136031 ,train acc: 0.952881 ,val loss : 0.106242 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :194 ]train loss : 0.354050 ,train acc: 0.814270 ,val loss : 0.105919 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :195 ]train loss : 0.073459 ,train acc: 0.990601 ,val loss : 0.105949 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :196 ]train loss : 0.072161 ,train acc: 0.994812 ,val loss : 0.104433 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :197 ]train loss : 0.080632 ,train acc: 0.991974 ,val loss : 0.104709 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :198 ]train loss : 0.074655 ,train acc: 0.993378 ,val loss : 0.106940 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :199 ]train loss : 0.430279 ,train acc: 0.700378 ,val loss : 0.107534 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :200 ]train loss : 0.199076 ,train acc: 0.917511 ,val loss : 0.108781 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :201 ]train loss : 0.067332 ,train acc: 0.993073 ,val loss : 0.108296 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :202 ]train loss : 0.074985 ,train acc: 0.998322 ,val loss : 0.105684 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :203 ]train loss : 0.125581 ,train acc: 0.977417 ,val loss : 0.105682 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :204 ]train loss : 0.103029 ,train acc: 0.974762 ,val loss : 0.106145 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :205 ]train loss : 0.080175 ,train acc: 0.993073 ,val loss : 0.104982 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :206 ]train loss : 0.296737 ,train acc: 0.839264 ,val loss : 0.106290 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :207 ]train loss : 0.216520 ,train acc: 0.889282 ,val loss : 0.105732 ,val acc : 0.991241\n",
      "[ ecpho : 6  iter :208 ]train loss : 0.099723 ,train acc: 0.992096 ,val loss : 0.105403 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :209 ]train loss : 0.087278 ,train acc: 0.982422 ,val loss : 0.104328 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :210 ]train loss : 0.060904 ,train acc: 0.997559 ,val loss : 0.106334 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :211 ]train loss : 0.080885 ,train acc: 0.985321 ,val loss : 0.105311 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :212 ]train loss : 0.329732 ,train acc: 0.773621 ,val loss : 0.109106 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :213 ]train loss : 0.075377 ,train acc: 0.994263 ,val loss : 0.108412 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :214 ]train loss : 0.079873 ,train acc: 0.987885 ,val loss : 0.107675 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :215 ]train loss : 0.083342 ,train acc: 0.984436 ,val loss : 0.106470 ,val acc : 0.991241\n",
      "[ ecpho : 6  iter :216 ]train loss : 0.084718 ,train acc: 0.988586 ,val loss : 0.106741 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :217 ]train loss : 0.130048 ,train acc: 0.974152 ,val loss : 0.107740 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :218 ]train loss : 0.088651 ,train acc: 0.982880 ,val loss : 0.106546 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :219 ]train loss : 0.072348 ,train acc: 0.990906 ,val loss : 0.106219 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :220 ]train loss : 0.087954 ,train acc: 0.981110 ,val loss : 0.108284 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :221 ]train loss : 0.062214 ,train acc: 0.993683 ,val loss : 0.106716 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :222 ]train loss : 0.069698 ,train acc: 0.996552 ,val loss : 0.105095 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :223 ]train loss : 0.067828 ,train acc: 0.994385 ,val loss : 0.105770 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :224 ]train loss : 0.446187 ,train acc: 0.681793 ,val loss : 0.103825 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :225 ]train loss : 0.075783 ,train acc: 0.992828 ,val loss : 0.105468 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :226 ]train loss : 0.120276 ,train acc: 0.978760 ,val loss : 0.107946 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :227 ]train loss : 0.205289 ,train acc: 0.947754 ,val loss : 0.104414 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :228 ]train loss : 0.205376 ,train acc: 0.895599 ,val loss : 0.105212 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :229 ]train loss : 0.119949 ,train acc: 0.962891 ,val loss : 0.105963 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :230 ]train loss : 0.104623 ,train acc: 0.975037 ,val loss : 0.106960 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :231 ]train loss : 0.080481 ,train acc: 0.991364 ,val loss : 0.107152 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :232 ]train loss : 0.080755 ,train acc: 0.990601 ,val loss : 0.106758 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :233 ]train loss : 0.089910 ,train acc: 0.994629 ,val loss : 0.106644 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :234 ]train loss : 0.162980 ,train acc: 0.931885 ,val loss : 0.106515 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :235 ]train loss : 0.071513 ,train acc: 0.996918 ,val loss : 0.107070 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :236 ]train loss : 0.070259 ,train acc: 0.996552 ,val loss : 0.108900 ,val acc : 0.991394\n",
      "[ ecpho : 6  iter :237 ]train loss : 0.115715 ,train acc: 0.964478 ,val loss : 0.108489 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :238 ]train loss : 0.105948 ,train acc: 0.979248 ,val loss : 0.107131 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :239 ]train loss : 0.080002 ,train acc: 0.994568 ,val loss : 0.106474 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :240 ]train loss : 0.158158 ,train acc: 0.960144 ,val loss : 0.104974 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :241 ]train loss : 0.199272 ,train acc: 0.893738 ,val loss : 0.105373 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :242 ]train loss : 0.100434 ,train acc: 0.973755 ,val loss : 0.108561 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :243 ]train loss : 0.112132 ,train acc: 0.974304 ,val loss : 0.106297 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :244 ]train loss : 0.058630 ,train acc: 0.998169 ,val loss : 0.107658 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :245 ]train loss : 0.078430 ,train acc: 0.994812 ,val loss : 0.106937 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :246 ]train loss : 0.093826 ,train acc: 0.985535 ,val loss : 0.111126 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :247 ]train loss : 0.068124 ,train acc: 0.998596 ,val loss : 0.107489 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :248 ]train loss : 0.067470 ,train acc: 0.997498 ,val loss : 0.104536 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :249 ]train loss : 0.062163 ,train acc: 0.998901 ,val loss : 0.108517 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :250 ]train loss : 0.062758 ,train acc: 0.997284 ,val loss : 0.106761 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :251 ]train loss : 0.093214 ,train acc: 0.977386 ,val loss : 0.104979 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :252 ]train loss : 0.073239 ,train acc: 0.997589 ,val loss : 0.106960 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :253 ]train loss : 0.137591 ,train acc: 0.951019 ,val loss : 0.105238 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :254 ]train loss : 1.193978 ,train acc: 0.183075 ,val loss : 0.106167 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :255 ]train loss : 0.153775 ,train acc: 0.938873 ,val loss : 0.107382 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :256 ]train loss : 0.162721 ,train acc: 0.933472 ,val loss : 0.105501 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :257 ]train loss : 0.063145 ,train acc: 0.997223 ,val loss : 0.106965 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :258 ]train loss : 0.088332 ,train acc: 0.996277 ,val loss : 0.105688 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :259 ]train loss : 0.861444 ,train acc: 0.464722 ,val loss : 0.104546 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :260 ]train loss : 0.074232 ,train acc: 0.993378 ,val loss : 0.105701 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :261 ]train loss : 0.070676 ,train acc: 0.995697 ,val loss : 0.106370 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :262 ]train loss : 0.060989 ,train acc: 0.999084 ,val loss : 0.107922 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :263 ]train loss : 0.078938 ,train acc: 0.986603 ,val loss : 0.104757 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :264 ]train loss : 0.098150 ,train acc: 0.995880 ,val loss : 0.109886 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :265 ]train loss : 0.127442 ,train acc: 0.966949 ,val loss : 0.106962 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :266 ]train loss : 0.074359 ,train acc: 0.993500 ,val loss : 0.107001 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :267 ]train loss : 0.053512 ,train acc: 0.999359 ,val loss : 0.107972 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :268 ]train loss : 0.085662 ,train acc: 0.997345 ,val loss : 0.106885 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :269 ]train loss : 0.093477 ,train acc: 0.980072 ,val loss : 0.105789 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :270 ]train loss : 0.115841 ,train acc: 0.966736 ,val loss : 0.106996 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :271 ]train loss : 0.165426 ,train acc: 0.951447 ,val loss : 0.107655 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :272 ]train loss : 0.299168 ,train acc: 0.817261 ,val loss : 0.107052 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :273 ]train loss : 0.067554 ,train acc: 0.999023 ,val loss : 0.104058 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :274 ]train loss : 0.078327 ,train acc: 0.985809 ,val loss : 0.107112 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :275 ]train loss : 0.167328 ,train acc: 0.960754 ,val loss : 0.106756 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :276 ]train loss : 0.088239 ,train acc: 0.983582 ,val loss : 0.105701 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :277 ]train loss : 0.109347 ,train acc: 0.968323 ,val loss : 0.106727 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :278 ]train loss : 0.112499 ,train acc: 0.986969 ,val loss : 0.107582 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :279 ]train loss : 0.086629 ,train acc: 0.997162 ,val loss : 0.108534 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :280 ]train loss : 0.121851 ,train acc: 0.973450 ,val loss : 0.106857 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :281 ]train loss : 0.117640 ,train acc: 0.977722 ,val loss : 0.106128 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :282 ]train loss : 0.994999 ,train acc: 0.281952 ,val loss : 0.105570 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :283 ]train loss : 0.069342 ,train acc: 0.994507 ,val loss : 0.106342 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :284 ]train loss : 0.077952 ,train acc: 0.991699 ,val loss : 0.107067 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :285 ]train loss : 0.072092 ,train acc: 0.992249 ,val loss : 0.107764 ,val acc : 0.992737\n",
      "[ ecpho : 6  iter :286 ]train loss : 0.289395 ,train acc: 0.890930 ,val loss : 0.107400 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :287 ]train loss : 0.189258 ,train acc: 0.912262 ,val loss : 0.105280 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :288 ]train loss : 0.264964 ,train acc: 0.828583 ,val loss : 0.107356 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :289 ]train loss : 0.111373 ,train acc: 0.973267 ,val loss : 0.105368 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :290 ]train loss : 0.058569 ,train acc: 0.998077 ,val loss : 0.106977 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :291 ]train loss : 0.078640 ,train acc: 0.984222 ,val loss : 0.106728 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :292 ]train loss : 0.758184 ,train acc: 0.436646 ,val loss : 0.106611 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :293 ]train loss : 0.087151 ,train acc: 0.997589 ,val loss : 0.107542 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :294 ]train loss : 0.126211 ,train acc: 0.953156 ,val loss : 0.106903 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :295 ]train loss : 0.070189 ,train acc: 0.997894 ,val loss : 0.106923 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :296 ]train loss : 0.065744 ,train acc: 0.997040 ,val loss : 0.106957 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :297 ]train loss : 0.097938 ,train acc: 0.992950 ,val loss : 0.105531 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :298 ]train loss : 0.094930 ,train acc: 0.993378 ,val loss : 0.106816 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :299 ]train loss : 0.088885 ,train acc: 0.998444 ,val loss : 0.105060 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :300 ]train loss : 0.059799 ,train acc: 0.998230 ,val loss : 0.105768 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :301 ]train loss : 0.338844 ,train acc: 0.783295 ,val loss : 0.101703 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :302 ]train loss : 0.109063 ,train acc: 0.982483 ,val loss : 0.108457 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :303 ]train loss : 0.391245 ,train acc: 0.766846 ,val loss : 0.105252 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :304 ]train loss : 0.705232 ,train acc: 0.445312 ,val loss : 0.106635 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :305 ]train loss : 0.372110 ,train acc: 0.752319 ,val loss : 0.106775 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :306 ]train loss : 0.164374 ,train acc: 0.944611 ,val loss : 0.105932 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :307 ]train loss : 0.350849 ,train acc: 0.808685 ,val loss : 0.106156 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :308 ]train loss : 0.119270 ,train acc: 0.972076 ,val loss : 0.107713 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :309 ]train loss : 0.076600 ,train acc: 0.997711 ,val loss : 0.109009 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :310 ]train loss : 0.270357 ,train acc: 0.893066 ,val loss : 0.105775 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :311 ]train loss : 0.073008 ,train acc: 0.993073 ,val loss : 0.106712 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :312 ]train loss : 0.055132 ,train acc: 0.999146 ,val loss : 0.108743 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :313 ]train loss : 0.096197 ,train acc: 0.978302 ,val loss : 0.102784 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :314 ]train loss : 0.350470 ,train acc: 0.826630 ,val loss : 0.109670 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :315 ]train loss : 0.086279 ,train acc: 0.990417 ,val loss : 0.107696 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :316 ]train loss : 0.057060 ,train acc: 0.998260 ,val loss : 0.105592 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :317 ]train loss : 0.144094 ,train acc: 0.957733 ,val loss : 0.106250 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :318 ]train loss : 0.100853 ,train acc: 0.975739 ,val loss : 0.107969 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :319 ]train loss : 0.159804 ,train acc: 0.933380 ,val loss : 0.106345 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :320 ]train loss : 0.087794 ,train acc: 0.996643 ,val loss : 0.106983 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :321 ]train loss : 0.099271 ,train acc: 0.992554 ,val loss : 0.108138 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :322 ]train loss : 0.069996 ,train acc: 0.993652 ,val loss : 0.108447 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :323 ]train loss : 0.065227 ,train acc: 0.997192 ,val loss : 0.105352 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :324 ]train loss : 0.622384 ,train acc: 0.688049 ,val loss : 0.108295 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :325 ]train loss : 0.078670 ,train acc: 0.990875 ,val loss : 0.106287 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :326 ]train loss : 0.066965 ,train acc: 0.994476 ,val loss : 0.105820 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :327 ]train loss : 0.080252 ,train acc: 0.996552 ,val loss : 0.105571 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :328 ]train loss : 0.073762 ,train acc: 0.993988 ,val loss : 0.107942 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :329 ]train loss : 0.358124 ,train acc: 0.808685 ,val loss : 0.108795 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :330 ]train loss : 0.159705 ,train acc: 0.932861 ,val loss : 0.105362 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :331 ]train loss : 0.101731 ,train acc: 0.993011 ,val loss : 0.109365 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :332 ]train loss : 0.188293 ,train acc: 0.930389 ,val loss : 0.105829 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :333 ]train loss : 0.098951 ,train acc: 0.978912 ,val loss : 0.108699 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :334 ]train loss : 0.078728 ,train acc: 0.993622 ,val loss : 0.107068 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :335 ]train loss : 0.106033 ,train acc: 0.989960 ,val loss : 0.106719 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :336 ]train loss : 0.932152 ,train acc: 0.382965 ,val loss : 0.107226 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :337 ]train loss : 0.488139 ,train acc: 0.669312 ,val loss : 0.109433 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :338 ]train loss : 0.100365 ,train acc: 0.978729 ,val loss : 0.107574 ,val acc : 0.991425\n",
      "[ ecpho : 6  iter :339 ]train loss : 0.072777 ,train acc: 0.991974 ,val loss : 0.106149 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :340 ]train loss : 0.132385 ,train acc: 0.951874 ,val loss : 0.107857 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :341 ]train loss : 0.096896 ,train acc: 0.984222 ,val loss : 0.103892 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :342 ]train loss : 0.140476 ,train acc: 0.961792 ,val loss : 0.107394 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :343 ]train loss : 0.908980 ,train acc: 0.348633 ,val loss : 0.107018 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :344 ]train loss : 0.062452 ,train acc: 0.995117 ,val loss : 0.106725 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :345 ]train loss : 0.485344 ,train acc: 0.639618 ,val loss : 0.106620 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :346 ]train loss : 0.266220 ,train acc: 0.887238 ,val loss : 0.108742 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :347 ]train loss : 0.088269 ,train acc: 0.985718 ,val loss : 0.106055 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :348 ]train loss : 0.104102 ,train acc: 0.983643 ,val loss : 0.107813 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :349 ]train loss : 0.096041 ,train acc: 0.995392 ,val loss : 0.109956 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :350 ]train loss : 0.090047 ,train acc: 0.984741 ,val loss : 0.107237 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :351 ]train loss : 0.079248 ,train acc: 0.997559 ,val loss : 0.106674 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :352 ]train loss : 0.114360 ,train acc: 0.983429 ,val loss : 0.106604 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :353 ]train loss : 0.071543 ,train acc: 0.992554 ,val loss : 0.103961 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :354 ]train loss : 0.087412 ,train acc: 0.988373 ,val loss : 0.106639 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :355 ]train loss : 0.069862 ,train acc: 0.998260 ,val loss : 0.106650 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :356 ]train loss : 0.093575 ,train acc: 0.995880 ,val loss : 0.106286 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :357 ]train loss : 0.115384 ,train acc: 0.984253 ,val loss : 0.109752 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :358 ]train loss : 0.086134 ,train acc: 0.994537 ,val loss : 0.108689 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :359 ]train loss : 0.160761 ,train acc: 0.944366 ,val loss : 0.108534 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :360 ]train loss : 0.088284 ,train acc: 0.996063 ,val loss : 0.108564 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :361 ]train loss : 0.088740 ,train acc: 0.982452 ,val loss : 0.106478 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :362 ]train loss : 0.056532 ,train acc: 0.997681 ,val loss : 0.108609 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :363 ]train loss : 0.163834 ,train acc: 0.939850 ,val loss : 0.105920 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :364 ]train loss : 0.090818 ,train acc: 0.996246 ,val loss : 0.107307 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :365 ]train loss : 0.391915 ,train acc: 0.773651 ,val loss : 0.109052 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :366 ]train loss : 0.068726 ,train acc: 0.995422 ,val loss : 0.105560 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :367 ]train loss : 0.327357 ,train acc: 0.793457 ,val loss : 0.105901 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :368 ]train loss : 0.105002 ,train acc: 0.977997 ,val loss : 0.105352 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :369 ]train loss : 0.095560 ,train acc: 0.977997 ,val loss : 0.108107 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :370 ]train loss : 0.224075 ,train acc: 0.878326 ,val loss : 0.107664 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :371 ]train loss : 0.175742 ,train acc: 0.919250 ,val loss : 0.108737 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :372 ]train loss : 0.455204 ,train acc: 0.726135 ,val loss : 0.108002 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :373 ]train loss : 0.074561 ,train acc: 0.992249 ,val loss : 0.106080 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :374 ]train loss : 0.073111 ,train acc: 0.998413 ,val loss : 0.107678 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :375 ]train loss : 0.074723 ,train acc: 0.989899 ,val loss : 0.105799 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :376 ]train loss : 0.087826 ,train acc: 0.996796 ,val loss : 0.109835 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :377 ]train loss : 0.124634 ,train acc: 0.963928 ,val loss : 0.106036 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :378 ]train loss : 0.246674 ,train acc: 0.885773 ,val loss : 0.108156 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :379 ]train loss : 0.092923 ,train acc: 0.979126 ,val loss : 0.107417 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :380 ]train loss : 0.078204 ,train acc: 0.986786 ,val loss : 0.107790 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :381 ]train loss : 0.267514 ,train acc: 0.860474 ,val loss : 0.105659 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :382 ]train loss : 0.146393 ,train acc: 0.944092 ,val loss : 0.106856 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :383 ]train loss : 0.108093 ,train acc: 0.987427 ,val loss : 0.108037 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :384 ]train loss : 0.082719 ,train acc: 0.986298 ,val loss : 0.109650 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :385 ]train loss : 0.085490 ,train acc: 0.992554 ,val loss : 0.110624 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :386 ]train loss : 0.097051 ,train acc: 0.978333 ,val loss : 0.107702 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :387 ]train loss : 0.112815 ,train acc: 0.990631 ,val loss : 0.107529 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :388 ]train loss : 0.065695 ,train acc: 0.998993 ,val loss : 0.105705 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :389 ]train loss : 0.087213 ,train acc: 0.990479 ,val loss : 0.104609 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :390 ]train loss : 0.343653 ,train acc: 0.823730 ,val loss : 0.106442 ,val acc : 0.991150\n",
      "[ ecpho : 6  iter :391 ]train loss : 0.476829 ,train acc: 0.667755 ,val loss : 0.105576 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :392 ]train loss : 0.073042 ,train acc: 0.992340 ,val loss : 0.110015 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :393 ]train loss : 0.090591 ,train acc: 0.985565 ,val loss : 0.108836 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :394 ]train loss : 0.072778 ,train acc: 0.994476 ,val loss : 0.109489 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :395 ]train loss : 0.100254 ,train acc: 0.979614 ,val loss : 0.107522 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :396 ]train loss : 0.684766 ,train acc: 0.557770 ,val loss : 0.108345 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :397 ]train loss : 0.070692 ,train acc: 0.997894 ,val loss : 0.107797 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :398 ]train loss : 0.149180 ,train acc: 0.953461 ,val loss : 0.107938 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :399 ]train loss : 0.077595 ,train acc: 0.989380 ,val loss : 0.109336 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :400 ]train loss : 0.073206 ,train acc: 0.997040 ,val loss : 0.108136 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :401 ]train loss : 0.148188 ,train acc: 0.943909 ,val loss : 0.108308 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :402 ]train loss : 0.196884 ,train acc: 0.901367 ,val loss : 0.109734 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :403 ]train loss : 0.068538 ,train acc: 0.997131 ,val loss : 0.110358 ,val acc : 0.991272\n",
      "[ ecpho : 6  iter :404 ]train loss : 0.071309 ,train acc: 0.997467 ,val loss : 0.109587 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :405 ]train loss : 0.069583 ,train acc: 0.997803 ,val loss : 0.107396 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :406 ]train loss : 0.086450 ,train acc: 0.983093 ,val loss : 0.108522 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :407 ]train loss : 0.064734 ,train acc: 0.998291 ,val loss : 0.107972 ,val acc : 0.991302\n",
      "[ ecpho : 6  iter :408 ]train loss : 0.603833 ,train acc: 0.602142 ,val loss : 0.105838 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :409 ]train loss : 0.270587 ,train acc: 0.832703 ,val loss : 0.106023 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :410 ]train loss : 0.151351 ,train acc: 0.941345 ,val loss : 0.109377 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :411 ]train loss : 0.084923 ,train acc: 0.992859 ,val loss : 0.110029 ,val acc : 0.991272\n",
      "[ ecpho : 6  iter :412 ]train loss : 0.249465 ,train acc: 0.888062 ,val loss : 0.107589 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :413 ]train loss : 0.107557 ,train acc: 0.968353 ,val loss : 0.106829 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :414 ]train loss : 0.082003 ,train acc: 0.989532 ,val loss : 0.109958 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :415 ]train loss : 0.069396 ,train acc: 0.997650 ,val loss : 0.109311 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :416 ]train loss : 0.279459 ,train acc: 0.827240 ,val loss : 0.107638 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :417 ]train loss : 0.087454 ,train acc: 0.996490 ,val loss : 0.107478 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :418 ]train loss : 0.542700 ,train acc: 0.609863 ,val loss : 0.110182 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :419 ]train loss : 0.060496 ,train acc: 0.998169 ,val loss : 0.110015 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :420 ]train loss : 0.091661 ,train acc: 0.979584 ,val loss : 0.108832 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :421 ]train loss : 0.083731 ,train acc: 0.994446 ,val loss : 0.108351 ,val acc : 0.991425\n",
      "[ ecpho : 6  iter :422 ]train loss : 0.217907 ,train acc: 0.874817 ,val loss : 0.109810 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :423 ]train loss : 0.107238 ,train acc: 0.982544 ,val loss : 0.106861 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :424 ]train loss : 0.102519 ,train acc: 0.976807 ,val loss : 0.108730 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :425 ]train loss : 0.109302 ,train acc: 0.967407 ,val loss : 0.108151 ,val acc : 0.991394\n",
      "[ ecpho : 6  iter :426 ]train loss : 0.067626 ,train acc: 0.992462 ,val loss : 0.106825 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :427 ]train loss : 0.113386 ,train acc: 0.968567 ,val loss : 0.107767 ,val acc : 0.991150\n",
      "[ ecpho : 6  iter :428 ]train loss : 0.146178 ,train acc: 0.941711 ,val loss : 0.109701 ,val acc : 0.991302\n",
      "[ ecpho : 6  iter :429 ]train loss : 0.086052 ,train acc: 0.990997 ,val loss : 0.107603 ,val acc : 0.991180\n",
      "[ ecpho : 6  iter :430 ]train loss : 0.104531 ,train acc: 0.982056 ,val loss : 0.104909 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :431 ]train loss : 0.104263 ,train acc: 0.983612 ,val loss : 0.109153 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :432 ]train loss : 0.074878 ,train acc: 0.990448 ,val loss : 0.107397 ,val acc : 0.991241\n",
      "[ ecpho : 6  iter :433 ]train loss : 0.079364 ,train acc: 0.989990 ,val loss : 0.109829 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :434 ]train loss : 0.415304 ,train acc: 0.767059 ,val loss : 0.109756 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :435 ]train loss : 0.073282 ,train acc: 0.993744 ,val loss : 0.108039 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :436 ]train loss : 0.072429 ,train acc: 0.994659 ,val loss : 0.109273 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :437 ]train loss : 0.081331 ,train acc: 0.988800 ,val loss : 0.110775 ,val acc : 0.990723\n",
      "[ ecpho : 6  iter :438 ]train loss : 0.114969 ,train acc: 0.974884 ,val loss : 0.109931 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :439 ]train loss : 0.167862 ,train acc: 0.933807 ,val loss : 0.109505 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :440 ]train loss : 0.959529 ,train acc: 0.334259 ,val loss : 0.111489 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :441 ]train loss : 0.089420 ,train acc: 0.986145 ,val loss : 0.108418 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :442 ]train loss : 0.066876 ,train acc: 0.994568 ,val loss : 0.106315 ,val acc : 0.991211\n",
      "[ ecpho : 6  iter :443 ]train loss : 0.065473 ,train acc: 0.996124 ,val loss : 0.105821 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :444 ]train loss : 0.067852 ,train acc: 0.997131 ,val loss : 0.106413 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :445 ]train loss : 0.064737 ,train acc: 0.996185 ,val loss : 0.108832 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :446 ]train loss : 0.073328 ,train acc: 0.989380 ,val loss : 0.111421 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :447 ]train loss : 0.142721 ,train acc: 0.973816 ,val loss : 0.106075 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :448 ]train loss : 0.608981 ,train acc: 0.660370 ,val loss : 0.109851 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :449 ]train loss : 0.057466 ,train acc: 0.998108 ,val loss : 0.108242 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :450 ]train loss : 0.087018 ,train acc: 0.987610 ,val loss : 0.109726 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :451 ]train loss : 0.082417 ,train acc: 0.997681 ,val loss : 0.109145 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :452 ]train loss : 0.090497 ,train acc: 0.995819 ,val loss : 0.109391 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :453 ]train loss : 0.125134 ,train acc: 0.980133 ,val loss : 0.109086 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :454 ]train loss : 0.294117 ,train acc: 0.863678 ,val loss : 0.109064 ,val acc : 0.991150\n",
      "[ ecpho : 6  iter :455 ]train loss : 0.069926 ,train acc: 0.996704 ,val loss : 0.105457 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :456 ]train loss : 0.192054 ,train acc: 0.948059 ,val loss : 0.108291 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :457 ]train loss : 0.175104 ,train acc: 0.930725 ,val loss : 0.106978 ,val acc : 0.991241\n",
      "[ ecpho : 6  iter :458 ]train loss : 0.156298 ,train acc: 0.975922 ,val loss : 0.109149 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :459 ]train loss : 0.090197 ,train acc: 0.991882 ,val loss : 0.109174 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :460 ]train loss : 0.086927 ,train acc: 0.994415 ,val loss : 0.106831 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :461 ]train loss : 0.744518 ,train acc: 0.419037 ,val loss : 0.107396 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :462 ]train loss : 0.175538 ,train acc: 0.919922 ,val loss : 0.109532 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :463 ]train loss : 0.065609 ,train acc: 0.997223 ,val loss : 0.108053 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :464 ]train loss : 0.183101 ,train acc: 0.947723 ,val loss : 0.110859 ,val acc : 0.991516\n",
      "[ ecpho : 6  iter :465 ]train loss : 0.075386 ,train acc: 0.992218 ,val loss : 0.106651 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :466 ]train loss : 0.131277 ,train acc: 0.986145 ,val loss : 0.109234 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :467 ]train loss : 0.065224 ,train acc: 0.998291 ,val loss : 0.107570 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :468 ]train loss : 1.120074 ,train acc: 0.234802 ,val loss : 0.108946 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :469 ]train loss : 0.109836 ,train acc: 0.983093 ,val loss : 0.109978 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :470 ]train loss : 0.100769 ,train acc: 0.978638 ,val loss : 0.107654 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :471 ]train loss : 0.078849 ,train acc: 0.985107 ,val loss : 0.107103 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :472 ]train loss : 0.076467 ,train acc: 0.991089 ,val loss : 0.108619 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :473 ]train loss : 0.073265 ,train acc: 0.993561 ,val loss : 0.106908 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :474 ]train loss : 0.112708 ,train acc: 0.985779 ,val loss : 0.107368 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :475 ]train loss : 0.204078 ,train acc: 0.900146 ,val loss : 0.107720 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :476 ]train loss : 0.184932 ,train acc: 0.917053 ,val loss : 0.108055 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :477 ]train loss : 0.168513 ,train acc: 0.926392 ,val loss : 0.106800 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :478 ]train loss : 0.062292 ,train acc: 0.998260 ,val loss : 0.105310 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :479 ]train loss : 0.205617 ,train acc: 0.897339 ,val loss : 0.104727 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :480 ]train loss : 0.080199 ,train acc: 0.987427 ,val loss : 0.106030 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :481 ]train loss : 0.482753 ,train acc: 0.664062 ,val loss : 0.109118 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :482 ]train loss : 0.109018 ,train acc: 0.975067 ,val loss : 0.107340 ,val acc : 0.991241\n",
      "[ ecpho : 6  iter :483 ]train loss : 0.162631 ,train acc: 0.939301 ,val loss : 0.107305 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :484 ]train loss : 0.139314 ,train acc: 0.946106 ,val loss : 0.110315 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :485 ]train loss : 1.092136 ,train acc: 0.249207 ,val loss : 0.107915 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :486 ]train loss : 0.269566 ,train acc: 0.828644 ,val loss : 0.109928 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :487 ]train loss : 0.087935 ,train acc: 0.986786 ,val loss : 0.105323 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :488 ]train loss : 0.088387 ,train acc: 0.993347 ,val loss : 0.106859 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :489 ]train loss : 0.104792 ,train acc: 0.980896 ,val loss : 0.108209 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :490 ]train loss : 0.070624 ,train acc: 0.993134 ,val loss : 0.107636 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :491 ]train loss : 0.077164 ,train acc: 0.993622 ,val loss : 0.107076 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :492 ]train loss : 0.054563 ,train acc: 0.999268 ,val loss : 0.108498 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :493 ]train loss : 0.075929 ,train acc: 0.991028 ,val loss : 0.108770 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :494 ]train loss : 0.112114 ,train acc: 0.989899 ,val loss : 0.108074 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :495 ]train loss : 0.238394 ,train acc: 0.883514 ,val loss : 0.111933 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :496 ]train loss : 0.268043 ,train acc: 0.841888 ,val loss : 0.109798 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :497 ]train loss : 0.082249 ,train acc: 0.983459 ,val loss : 0.109122 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :498 ]train loss : 0.094820 ,train acc: 0.993835 ,val loss : 0.107235 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :499 ]train loss : 0.308130 ,train acc: 0.850403 ,val loss : 0.107414 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :500 ]train loss : 0.080142 ,train acc: 0.989227 ,val loss : 0.108355 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :501 ]train loss : 0.117139 ,train acc: 0.985596 ,val loss : 0.107703 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :502 ]train loss : 0.076485 ,train acc: 0.997192 ,val loss : 0.106025 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :503 ]train loss : 0.099282 ,train acc: 0.983032 ,val loss : 0.109705 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :504 ]train loss : 0.258608 ,train acc: 0.856506 ,val loss : 0.109954 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :505 ]train loss : 0.238390 ,train acc: 0.866516 ,val loss : 0.108179 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :506 ]train loss : 0.093109 ,train acc: 0.980896 ,val loss : 0.105375 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :507 ]train loss : 0.082486 ,train acc: 0.995087 ,val loss : 0.108928 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :508 ]train loss : 0.141068 ,train acc: 0.957794 ,val loss : 0.108111 ,val acc : 0.991364\n",
      "[ ecpho : 6  iter :509 ]train loss : 0.073497 ,train acc: 0.995026 ,val loss : 0.104712 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :510 ]train loss : 0.064333 ,train acc: 0.998199 ,val loss : 0.107381 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :511 ]train loss : 0.118169 ,train acc: 0.962097 ,val loss : 0.105910 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :512 ]train loss : 0.074761 ,train acc: 0.990814 ,val loss : 0.109877 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :513 ]train loss : 0.188716 ,train acc: 0.902374 ,val loss : 0.107018 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :514 ]train loss : 0.091486 ,train acc: 0.983368 ,val loss : 0.107204 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :515 ]train loss : 1.266649 ,train acc: 0.155029 ,val loss : 0.109492 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :516 ]train loss : 0.058996 ,train acc: 0.996613 ,val loss : 0.106384 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :517 ]train loss : 0.230211 ,train acc: 0.876892 ,val loss : 0.108300 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :518 ]train loss : 0.101103 ,train acc: 0.990234 ,val loss : 0.107261 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :519 ]train loss : 0.072775 ,train acc: 0.989777 ,val loss : 0.107635 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :520 ]train loss : 0.144711 ,train acc: 0.953339 ,val loss : 0.107591 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :521 ]train loss : 0.096994 ,train acc: 0.993042 ,val loss : 0.106383 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :522 ]train loss : 0.118774 ,train acc: 0.978088 ,val loss : 0.106331 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :523 ]train loss : 0.244844 ,train acc: 0.890411 ,val loss : 0.105734 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :524 ]train loss : 0.083112 ,train acc: 0.984314 ,val loss : 0.107173 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :525 ]train loss : 0.405726 ,train acc: 0.711945 ,val loss : 0.106559 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :526 ]train loss : 0.131155 ,train acc: 0.976868 ,val loss : 0.107112 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :527 ]train loss : 0.079422 ,train acc: 0.988525 ,val loss : 0.109261 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :528 ]train loss : 0.134514 ,train acc: 0.958221 ,val loss : 0.110276 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :529 ]train loss : 0.166697 ,train acc: 0.956970 ,val loss : 0.108202 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :530 ]train loss : 0.062632 ,train acc: 0.996155 ,val loss : 0.104954 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :531 ]train loss : 0.177956 ,train acc: 0.927551 ,val loss : 0.107597 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :532 ]train loss : 0.096558 ,train acc: 0.975098 ,val loss : 0.106894 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :533 ]train loss : 0.076233 ,train acc: 0.988373 ,val loss : 0.111024 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :534 ]train loss : 0.058755 ,train acc: 0.995575 ,val loss : 0.105870 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :535 ]train loss : 0.591690 ,train acc: 0.614838 ,val loss : 0.107927 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :536 ]train loss : 0.086850 ,train acc: 0.996735 ,val loss : 0.108538 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :537 ]train loss : 0.071230 ,train acc: 0.997406 ,val loss : 0.111902 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :538 ]train loss : 0.082096 ,train acc: 0.993958 ,val loss : 0.107878 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :539 ]train loss : 0.091446 ,train acc: 0.990723 ,val loss : 0.106044 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :540 ]train loss : 0.065314 ,train acc: 0.996826 ,val loss : 0.108385 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :541 ]train loss : 0.094543 ,train acc: 0.994629 ,val loss : 0.107437 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :542 ]train loss : 0.079244 ,train acc: 0.991486 ,val loss : 0.108057 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :543 ]train loss : 0.098347 ,train acc: 0.985321 ,val loss : 0.109467 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :544 ]train loss : 0.085555 ,train acc: 0.997894 ,val loss : 0.108816 ,val acc : 0.991333\n",
      "[ ecpho : 6  iter :545 ]train loss : 0.108165 ,train acc: 0.983368 ,val loss : 0.107409 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :546 ]train loss : 0.072285 ,train acc: 0.996857 ,val loss : 0.109087 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :547 ]train loss : 0.081995 ,train acc: 0.995392 ,val loss : 0.109931 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :548 ]train loss : 0.099067 ,train acc: 0.993195 ,val loss : 0.106294 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :549 ]train loss : 0.076720 ,train acc: 0.993988 ,val loss : 0.107543 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :550 ]train loss : 0.083913 ,train acc: 0.990082 ,val loss : 0.107268 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :551 ]train loss : 0.092920 ,train acc: 0.991241 ,val loss : 0.108539 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :552 ]train loss : 0.092622 ,train acc: 0.979614 ,val loss : 0.109331 ,val acc : 0.991486\n",
      "[ ecpho : 6  iter :553 ]train loss : 0.094340 ,train acc: 0.993378 ,val loss : 0.111130 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :554 ]train loss : 0.114642 ,train acc: 0.968628 ,val loss : 0.107592 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :555 ]train loss : 0.087273 ,train acc: 0.987671 ,val loss : 0.107491 ,val acc : 0.991638\n",
      "[ ecpho : 6  iter :556 ]train loss : 0.282796 ,train acc: 0.839203 ,val loss : 0.108110 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :557 ]train loss : 0.120912 ,train acc: 0.964264 ,val loss : 0.109614 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :558 ]train loss : 0.195125 ,train acc: 0.902802 ,val loss : 0.107700 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :559 ]train loss : 0.068747 ,train acc: 0.994934 ,val loss : 0.106495 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :560 ]train loss : 0.064594 ,train acc: 0.997620 ,val loss : 0.108226 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :561 ]train loss : 0.074185 ,train acc: 0.998474 ,val loss : 0.108262 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :562 ]train loss : 0.109645 ,train acc: 0.991638 ,val loss : 0.107110 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :563 ]train loss : 0.076257 ,train acc: 0.994812 ,val loss : 0.110397 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :564 ]train loss : 0.052835 ,train acc: 0.999512 ,val loss : 0.106972 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :565 ]train loss : 0.063335 ,train acc: 0.994812 ,val loss : 0.106846 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :566 ]train loss : 0.176190 ,train acc: 0.917877 ,val loss : 0.107879 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :567 ]train loss : 0.076526 ,train acc: 0.986969 ,val loss : 0.107525 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :568 ]train loss : 0.098981 ,train acc: 0.983154 ,val loss : 0.106804 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :569 ]train loss : 0.085676 ,train acc: 0.993378 ,val loss : 0.109704 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :570 ]train loss : 0.086140 ,train acc: 0.997833 ,val loss : 0.107691 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :571 ]train loss : 0.106406 ,train acc: 0.968262 ,val loss : 0.107601 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :572 ]train loss : 0.137796 ,train acc: 0.978821 ,val loss : 0.106329 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :573 ]train loss : 0.389108 ,train acc: 0.724548 ,val loss : 0.106423 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :574 ]train loss : 0.128070 ,train acc: 0.961823 ,val loss : 0.107262 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :575 ]train loss : 0.104991 ,train acc: 0.992676 ,val loss : 0.108645 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :576 ]train loss : 0.926230 ,train acc: 0.345612 ,val loss : 0.107873 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :577 ]train loss : 0.116440 ,train acc: 0.985718 ,val loss : 0.106379 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :578 ]train loss : 0.121802 ,train acc: 0.968323 ,val loss : 0.110008 ,val acc : 0.991547\n",
      "[ ecpho : 6  iter :579 ]train loss : 0.186877 ,train acc: 0.942902 ,val loss : 0.107972 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :580 ]train loss : 0.103797 ,train acc: 0.995605 ,val loss : 0.106666 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :581 ]train loss : 0.074763 ,train acc: 0.997498 ,val loss : 0.106252 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :582 ]train loss : 0.080627 ,train acc: 0.992157 ,val loss : 0.106346 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :583 ]train loss : 0.703274 ,train acc: 0.505432 ,val loss : 0.106922 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :584 ]train loss : 0.082492 ,train acc: 0.998138 ,val loss : 0.104981 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :585 ]train loss : 0.085047 ,train acc: 0.998077 ,val loss : 0.107260 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :586 ]train loss : 0.087512 ,train acc: 0.997375 ,val loss : 0.104504 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :587 ]train loss : 0.111423 ,train acc: 0.971863 ,val loss : 0.105653 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :588 ]train loss : 0.088444 ,train acc: 0.997009 ,val loss : 0.108572 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :589 ]train loss : 0.087979 ,train acc: 0.990143 ,val loss : 0.109836 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :590 ]train loss : 0.077810 ,train acc: 0.992096 ,val loss : 0.107375 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :591 ]train loss : 0.188051 ,train acc: 0.946411 ,val loss : 0.106960 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :592 ]train loss : 0.100617 ,train acc: 0.981232 ,val loss : 0.109283 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :593 ]train loss : 0.082212 ,train acc: 0.994446 ,val loss : 0.107706 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :594 ]train loss : 0.081250 ,train acc: 0.994385 ,val loss : 0.107664 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :595 ]train loss : 0.090479 ,train acc: 0.992157 ,val loss : 0.107865 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :596 ]train loss : 0.075007 ,train acc: 0.997284 ,val loss : 0.103544 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :597 ]train loss : 0.071482 ,train acc: 0.992462 ,val loss : 0.107123 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :598 ]train loss : 0.082803 ,train acc: 0.985931 ,val loss : 0.108582 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :599 ]train loss : 0.105529 ,train acc: 0.973328 ,val loss : 0.106518 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :600 ]train loss : 0.105341 ,train acc: 0.980499 ,val loss : 0.109415 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :601 ]train loss : 0.102732 ,train acc: 0.986115 ,val loss : 0.109646 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :602 ]train loss : 0.392097 ,train acc: 0.747894 ,val loss : 0.108943 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :603 ]train loss : 0.086214 ,train acc: 0.985748 ,val loss : 0.107247 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :604 ]train loss : 0.059440 ,train acc: 0.997894 ,val loss : 0.106270 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :605 ]train loss : 0.084566 ,train acc: 0.992737 ,val loss : 0.104883 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :606 ]train loss : 0.102027 ,train acc: 0.969635 ,val loss : 0.106768 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :607 ]train loss : 0.063808 ,train acc: 0.998596 ,val loss : 0.106289 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :608 ]train loss : 0.086870 ,train acc: 0.987305 ,val loss : 0.106577 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :609 ]train loss : 0.284358 ,train acc: 0.849274 ,val loss : 0.107222 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :610 ]train loss : 0.118141 ,train acc: 0.964233 ,val loss : 0.107770 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :611 ]train loss : 0.098558 ,train acc: 0.993530 ,val loss : 0.107906 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :612 ]train loss : 0.074977 ,train acc: 0.997162 ,val loss : 0.106094 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :613 ]train loss : 0.134230 ,train acc: 0.954895 ,val loss : 0.107594 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :614 ]train loss : 0.083577 ,train acc: 0.994263 ,val loss : 0.108161 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :615 ]train loss : 0.070005 ,train acc: 0.997894 ,val loss : 0.107154 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :616 ]train loss : 0.084572 ,train acc: 0.996643 ,val loss : 0.107111 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :617 ]train loss : 0.064088 ,train acc: 0.996765 ,val loss : 0.106974 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :618 ]train loss : 0.091292 ,train acc: 0.997925 ,val loss : 0.106358 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :619 ]train loss : 0.075336 ,train acc: 0.993866 ,val loss : 0.107654 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :620 ]train loss : 0.117559 ,train acc: 0.982056 ,val loss : 0.107186 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :621 ]train loss : 0.092425 ,train acc: 0.996796 ,val loss : 0.107375 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :622 ]train loss : 0.091722 ,train acc: 0.988647 ,val loss : 0.108341 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :623 ]train loss : 0.080481 ,train acc: 0.990662 ,val loss : 0.106069 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :624 ]train loss : 0.072812 ,train acc: 0.998627 ,val loss : 0.106256 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :625 ]train loss : 0.083362 ,train acc: 0.991241 ,val loss : 0.104768 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :626 ]train loss : 0.101051 ,train acc: 0.997498 ,val loss : 0.108008 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :627 ]train loss : 0.085888 ,train acc: 0.996857 ,val loss : 0.104510 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :628 ]train loss : 0.075776 ,train acc: 0.990204 ,val loss : 0.105453 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :629 ]train loss : 0.237978 ,train acc: 0.868988 ,val loss : 0.105975 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :630 ]train loss : 0.499063 ,train acc: 0.614014 ,val loss : 0.107906 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :631 ]train loss : 0.393091 ,train acc: 0.723236 ,val loss : 0.104698 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :632 ]train loss : 0.060875 ,train acc: 0.998505 ,val loss : 0.104857 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :633 ]train loss : 0.108741 ,train acc: 0.976410 ,val loss : 0.108283 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :634 ]train loss : 0.083550 ,train acc: 0.993835 ,val loss : 0.107030 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :635 ]train loss : 0.415066 ,train acc: 0.750031 ,val loss : 0.109409 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :636 ]train loss : 0.140317 ,train acc: 0.968262 ,val loss : 0.107016 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :637 ]train loss : 0.220062 ,train acc: 0.912079 ,val loss : 0.106608 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :638 ]train loss : 0.107534 ,train acc: 0.980316 ,val loss : 0.106069 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :639 ]train loss : 0.240924 ,train acc: 0.895416 ,val loss : 0.104778 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :640 ]train loss : 0.102766 ,train acc: 0.994293 ,val loss : 0.106810 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :641 ]train loss : 0.124758 ,train acc: 0.982513 ,val loss : 0.107080 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :642 ]train loss : 0.082731 ,train acc: 0.988831 ,val loss : 0.108583 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :643 ]train loss : 0.244209 ,train acc: 0.911346 ,val loss : 0.105624 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :644 ]train loss : 0.086468 ,train acc: 0.989624 ,val loss : 0.105966 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :645 ]train loss : 0.286033 ,train acc: 0.867828 ,val loss : 0.106367 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :646 ]train loss : 0.105875 ,train acc: 0.970215 ,val loss : 0.107986 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :647 ]train loss : 0.091815 ,train acc: 0.996155 ,val loss : 0.109605 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :648 ]train loss : 0.252147 ,train acc: 0.859863 ,val loss : 0.110250 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :649 ]train loss : 0.077724 ,train acc: 0.994080 ,val loss : 0.106543 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :650 ]train loss : 0.376534 ,train acc: 0.795837 ,val loss : 0.105660 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :651 ]train loss : 0.102136 ,train acc: 0.992310 ,val loss : 0.106105 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :652 ]train loss : 0.107544 ,train acc: 0.988861 ,val loss : 0.107994 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :653 ]train loss : 0.073796 ,train acc: 0.998566 ,val loss : 0.106990 ,val acc : 0.991425\n",
      "[ ecpho : 6  iter :654 ]train loss : 0.068330 ,train acc: 0.997833 ,val loss : 0.106630 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :655 ]train loss : 0.068480 ,train acc: 0.998962 ,val loss : 0.108981 ,val acc : 0.992889\n",
      "[ ecpho : 6  iter :656 ]train loss : 0.120416 ,train acc: 0.959167 ,val loss : 0.103303 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :657 ]train loss : 0.091757 ,train acc: 0.983276 ,val loss : 0.105677 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :658 ]train loss : 0.101449 ,train acc: 0.977539 ,val loss : 0.104589 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :659 ]train loss : 0.096343 ,train acc: 0.997711 ,val loss : 0.105536 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :660 ]train loss : 0.390072 ,train acc: 0.731354 ,val loss : 0.107847 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :661 ]train loss : 0.092455 ,train acc: 0.981598 ,val loss : 0.105438 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :662 ]train loss : 0.140791 ,train acc: 0.973114 ,val loss : 0.105630 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :663 ]train loss : 0.137207 ,train acc: 0.983734 ,val loss : 0.106608 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :664 ]train loss : 0.112012 ,train acc: 0.984253 ,val loss : 0.104941 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :665 ]train loss : 0.057355 ,train acc: 0.998260 ,val loss : 0.108254 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :666 ]train loss : 0.160677 ,train acc: 0.965454 ,val loss : 0.107284 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :667 ]train loss : 0.733443 ,train acc: 0.477112 ,val loss : 0.106513 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :668 ]train loss : 0.089931 ,train acc: 0.983307 ,val loss : 0.106157 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :669 ]train loss : 0.394309 ,train acc: 0.733429 ,val loss : 0.106241 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :670 ]train loss : 0.076363 ,train acc: 0.992279 ,val loss : 0.106493 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :671 ]train loss : 0.167469 ,train acc: 0.928436 ,val loss : 0.108877 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :672 ]train loss : 0.407810 ,train acc: 0.716034 ,val loss : 0.104763 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :673 ]train loss : 0.301564 ,train acc: 0.827789 ,val loss : 0.106578 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :674 ]train loss : 0.069840 ,train acc: 0.993195 ,val loss : 0.108220 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :675 ]train loss : 0.868405 ,train acc: 0.399811 ,val loss : 0.106308 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :676 ]train loss : 0.163870 ,train acc: 0.935089 ,val loss : 0.106230 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :677 ]train loss : 0.076983 ,train acc: 0.995575 ,val loss : 0.106634 ,val acc : 0.991455\n",
      "[ ecpho : 6  iter :678 ]train loss : 0.083941 ,train acc: 0.994110 ,val loss : 0.105206 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :679 ]train loss : 0.106191 ,train acc: 0.975922 ,val loss : 0.105327 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :680 ]train loss : 0.087612 ,train acc: 0.993896 ,val loss : 0.106150 ,val acc : 0.991608\n",
      "[ ecpho : 6  iter :681 ]train loss : 0.071349 ,train acc: 0.996368 ,val loss : 0.106467 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :682 ]train loss : 1.170074 ,train acc: 0.197357 ,val loss : 0.108799 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :683 ]train loss : 0.132161 ,train acc: 0.957733 ,val loss : 0.106645 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :684 ]train loss : 0.067488 ,train acc: 0.997620 ,val loss : 0.106096 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :685 ]train loss : 0.069376 ,train acc: 0.997864 ,val loss : 0.106833 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :686 ]train loss : 0.100237 ,train acc: 0.993256 ,val loss : 0.105733 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :687 ]train loss : 0.082732 ,train acc: 0.986420 ,val loss : 0.106813 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :688 ]train loss : 0.438098 ,train acc: 0.732056 ,val loss : 0.104990 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :689 ]train loss : 0.073291 ,train acc: 0.993866 ,val loss : 0.108877 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :690 ]train loss : 0.098345 ,train acc: 0.982330 ,val loss : 0.106661 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :691 ]train loss : 0.100828 ,train acc: 0.986176 ,val loss : 0.106809 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :692 ]train loss : 0.085522 ,train acc: 0.984619 ,val loss : 0.107882 ,val acc : 0.991821\n",
      "[ ecpho : 6  iter :693 ]train loss : 0.071612 ,train acc: 0.993927 ,val loss : 0.106783 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :694 ]train loss : 0.109646 ,train acc: 0.973389 ,val loss : 0.107425 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :695 ]train loss : 0.110167 ,train acc: 0.985504 ,val loss : 0.107653 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :696 ]train loss : 0.491872 ,train acc: 0.659271 ,val loss : 0.106674 ,val acc : 0.991669\n",
      "[ ecpho : 6  iter :697 ]train loss : 0.058216 ,train acc: 0.997894 ,val loss : 0.106391 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :698 ]train loss : 1.419758 ,train acc: 0.020111 ,val loss : 0.107620 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :699 ]train loss : 0.139374 ,train acc: 0.967743 ,val loss : 0.107103 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :700 ]train loss : 0.107407 ,train acc: 0.974609 ,val loss : 0.107930 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :701 ]train loss : 0.085108 ,train acc: 0.992065 ,val loss : 0.106333 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :702 ]train loss : 0.127001 ,train acc: 0.977875 ,val loss : 0.107596 ,val acc : 0.991760\n",
      "[ ecpho : 6  iter :703 ]train loss : 0.162556 ,train acc: 0.957886 ,val loss : 0.107967 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :704 ]train loss : 0.129368 ,train acc: 0.982025 ,val loss : 0.110035 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :705 ]train loss : 0.090066 ,train acc: 0.981415 ,val loss : 0.107839 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :706 ]train loss : 0.063925 ,train acc: 0.997162 ,val loss : 0.105812 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :707 ]train loss : 0.112739 ,train acc: 0.977753 ,val loss : 0.107886 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :708 ]train loss : 0.095667 ,train acc: 0.973541 ,val loss : 0.105553 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :709 ]train loss : 0.094132 ,train acc: 0.994049 ,val loss : 0.107670 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :710 ]train loss : 0.080076 ,train acc: 0.994934 ,val loss : 0.107755 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :711 ]train loss : 0.161423 ,train acc: 0.925507 ,val loss : 0.105490 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :712 ]train loss : 0.550454 ,train acc: 0.726318 ,val loss : 0.106327 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :713 ]train loss : 0.115500 ,train acc: 0.969238 ,val loss : 0.108831 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :714 ]train loss : 0.098591 ,train acc: 0.975433 ,val loss : 0.103677 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :715 ]train loss : 0.106584 ,train acc: 0.987854 ,val loss : 0.107749 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :716 ]train loss : 0.085224 ,train acc: 0.987091 ,val loss : 0.104765 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :717 ]train loss : 0.090668 ,train acc: 0.989563 ,val loss : 0.106263 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :718 ]train loss : 0.093436 ,train acc: 0.991577 ,val loss : 0.104725 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :719 ]train loss : 0.096547 ,train acc: 0.991730 ,val loss : 0.107154 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :720 ]train loss : 0.069812 ,train acc: 0.995056 ,val loss : 0.108488 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :721 ]train loss : 0.103861 ,train acc: 0.988373 ,val loss : 0.108021 ,val acc : 0.991791\n",
      "[ ecpho : 6  iter :722 ]train loss : 0.086306 ,train acc: 0.981873 ,val loss : 0.105773 ,val acc : 0.991699\n",
      "[ ecpho : 6  iter :723 ]train loss : 0.068440 ,train acc: 0.996277 ,val loss : 0.107192 ,val acc : 0.991577\n",
      "[ ecpho : 6  iter :724 ]train loss : 0.074435 ,train acc: 0.998566 ,val loss : 0.108671 ,val acc : 0.991852\n",
      "[ ecpho : 6  iter :725 ]train loss : 0.116226 ,train acc: 0.984985 ,val loss : 0.104422 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :726 ]train loss : 0.079607 ,train acc: 0.989777 ,val loss : 0.105981 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :727 ]train loss : 0.083148 ,train acc: 0.982819 ,val loss : 0.106600 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :728 ]train loss : 0.397841 ,train acc: 0.741943 ,val loss : 0.105691 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :729 ]train loss : 0.086658 ,train acc: 0.997833 ,val loss : 0.107289 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :730 ]train loss : 0.094917 ,train acc: 0.981659 ,val loss : 0.107406 ,val acc : 0.991913\n",
      "[ ecpho : 6  iter :731 ]train loss : 0.112484 ,train acc: 0.987274 ,val loss : 0.104737 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :732 ]train loss : 0.090470 ,train acc: 0.997833 ,val loss : 0.107115 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :733 ]train loss : 0.086079 ,train acc: 0.993988 ,val loss : 0.108017 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :734 ]train loss : 0.089936 ,train acc: 0.985535 ,val loss : 0.106030 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :735 ]train loss : 0.104078 ,train acc: 0.970551 ,val loss : 0.106940 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :736 ]train loss : 0.091295 ,train acc: 0.987091 ,val loss : 0.104591 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :737 ]train loss : 0.104413 ,train acc: 0.970337 ,val loss : 0.104730 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :738 ]train loss : 0.077849 ,train acc: 0.993195 ,val loss : 0.106723 ,val acc : 0.991882\n",
      "[ ecpho : 6  iter :739 ]train loss : 0.093850 ,train acc: 0.985901 ,val loss : 0.105933 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :740 ]train loss : 0.066434 ,train acc: 0.994476 ,val loss : 0.102692 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :741 ]train loss : 0.076459 ,train acc: 0.997040 ,val loss : 0.107188 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :742 ]train loss : 0.059674 ,train acc: 0.997345 ,val loss : 0.105110 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :743 ]train loss : 0.179929 ,train acc: 0.920288 ,val loss : 0.106066 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :744 ]train loss : 0.081496 ,train acc: 0.996185 ,val loss : 0.106963 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :745 ]train loss : 0.190344 ,train acc: 0.947601 ,val loss : 0.109442 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :746 ]train loss : 0.109593 ,train acc: 0.967468 ,val loss : 0.106056 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :747 ]train loss : 0.166860 ,train acc: 0.924316 ,val loss : 0.104517 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :748 ]train loss : 0.637071 ,train acc: 0.605164 ,val loss : 0.105606 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :749 ]train loss : 0.100986 ,train acc: 0.984283 ,val loss : 0.107844 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :750 ]train loss : 0.068811 ,train acc: 0.995758 ,val loss : 0.110043 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :751 ]train loss : 0.095080 ,train acc: 0.977020 ,val loss : 0.106417 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :752 ]train loss : 0.098025 ,train acc: 0.994781 ,val loss : 0.106248 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :753 ]train loss : 0.187901 ,train acc: 0.905762 ,val loss : 0.104773 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :754 ]train loss : 0.087858 ,train acc: 0.997742 ,val loss : 0.106555 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :755 ]train loss : 0.081850 ,train acc: 0.992096 ,val loss : 0.105711 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :756 ]train loss : 0.081634 ,train acc: 0.996918 ,val loss : 0.106946 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :757 ]train loss : 0.091456 ,train acc: 0.982056 ,val loss : 0.106268 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :758 ]train loss : 0.068659 ,train acc: 0.995239 ,val loss : 0.102363 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :759 ]train loss : 0.129433 ,train acc: 0.970184 ,val loss : 0.106874 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :760 ]train loss : 0.074661 ,train acc: 0.991486 ,val loss : 0.107834 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :761 ]train loss : 0.103758 ,train acc: 0.977020 ,val loss : 0.105837 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :762 ]train loss : 0.198799 ,train acc: 0.926880 ,val loss : 0.107272 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :763 ]train loss : 0.079160 ,train acc: 0.992920 ,val loss : 0.104619 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :764 ]train loss : 0.111743 ,train acc: 0.980560 ,val loss : 0.104933 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :765 ]train loss : 0.113094 ,train acc: 0.974884 ,val loss : 0.103894 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :766 ]train loss : 0.132150 ,train acc: 0.975861 ,val loss : 0.105758 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :767 ]train loss : 0.139356 ,train acc: 0.963989 ,val loss : 0.105010 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :768 ]train loss : 0.281082 ,train acc: 0.919434 ,val loss : 0.106191 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :769 ]train loss : 0.095252 ,train acc: 0.983490 ,val loss : 0.106993 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :770 ]train loss : 0.061267 ,train acc: 0.998077 ,val loss : 0.109770 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :771 ]train loss : 0.133410 ,train acc: 0.966705 ,val loss : 0.108089 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :772 ]train loss : 0.067081 ,train acc: 0.996704 ,val loss : 0.106919 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :773 ]train loss : 0.056389 ,train acc: 0.998627 ,val loss : 0.106352 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :774 ]train loss : 0.077504 ,train acc: 0.990204 ,val loss : 0.106191 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :775 ]train loss : 0.060516 ,train acc: 0.996582 ,val loss : 0.105588 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :776 ]train loss : 0.081045 ,train acc: 0.988922 ,val loss : 0.104772 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :777 ]train loss : 0.078170 ,train acc: 0.993927 ,val loss : 0.104525 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :778 ]train loss : 0.074133 ,train acc: 0.994324 ,val loss : 0.106005 ,val acc : 0.992828\n",
      "[ ecpho : 6  iter :779 ]train loss : 0.078497 ,train acc: 0.998077 ,val loss : 0.105156 ,val acc : 0.992828\n",
      "[ ecpho : 6  iter :780 ]train loss : 0.076425 ,train acc: 0.993378 ,val loss : 0.106987 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :781 ]train loss : 0.096184 ,train acc: 0.990143 ,val loss : 0.104170 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :782 ]train loss : 0.129450 ,train acc: 0.957001 ,val loss : 0.106051 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :783 ]train loss : 0.088302 ,train acc: 0.995758 ,val loss : 0.107008 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :784 ]train loss : 0.098739 ,train acc: 0.993195 ,val loss : 0.105072 ,val acc : 0.992950\n",
      "[ ecpho : 6  iter :785 ]train loss : 0.223637 ,train acc: 0.925568 ,val loss : 0.106193 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :786 ]train loss : 0.492672 ,train acc: 0.637482 ,val loss : 0.106083 ,val acc : 0.992859\n",
      "[ ecpho : 6  iter :787 ]train loss : 0.063467 ,train acc: 0.999237 ,val loss : 0.105628 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :788 ]train loss : 0.082073 ,train acc: 0.992615 ,val loss : 0.106125 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :789 ]train loss : 0.075523 ,train acc: 0.995117 ,val loss : 0.104966 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :790 ]train loss : 0.076259 ,train acc: 0.994965 ,val loss : 0.103948 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :791 ]train loss : 0.106148 ,train acc: 0.971832 ,val loss : 0.106462 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :792 ]train loss : 0.071882 ,train acc: 0.998352 ,val loss : 0.104625 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :793 ]train loss : 0.112125 ,train acc: 0.992432 ,val loss : 0.104548 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :794 ]train loss : 0.101051 ,train acc: 0.988586 ,val loss : 0.107426 ,val acc : 0.991730\n",
      "[ ecpho : 6  iter :795 ]train loss : 0.151611 ,train acc: 0.940277 ,val loss : 0.106657 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :796 ]train loss : 0.216922 ,train acc: 0.876221 ,val loss : 0.105469 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :797 ]train loss : 0.106176 ,train acc: 0.992615 ,val loss : 0.103586 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :798 ]train loss : 0.063258 ,train acc: 0.998077 ,val loss : 0.107172 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :799 ]train loss : 0.060861 ,train acc: 0.997955 ,val loss : 0.105770 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :800 ]train loss : 0.063341 ,train acc: 0.998932 ,val loss : 0.107145 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :801 ]train loss : 0.237761 ,train acc: 0.913910 ,val loss : 0.105051 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :802 ]train loss : 0.458541 ,train acc: 0.693054 ,val loss : 0.104302 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :803 ]train loss : 0.294370 ,train acc: 0.848785 ,val loss : 0.106378 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :804 ]train loss : 0.091131 ,train acc: 0.992889 ,val loss : 0.105546 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :805 ]train loss : 0.119182 ,train acc: 0.976196 ,val loss : 0.101525 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :806 ]train loss : 0.152441 ,train acc: 0.962097 ,val loss : 0.106163 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :807 ]train loss : 0.060084 ,train acc: 0.997955 ,val loss : 0.107056 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :808 ]train loss : 0.084463 ,train acc: 0.996796 ,val loss : 0.106535 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :809 ]train loss : 0.286072 ,train acc: 0.801147 ,val loss : 0.104950 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :810 ]train loss : 0.109217 ,train acc: 0.987854 ,val loss : 0.106776 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :811 ]train loss : 0.068062 ,train acc: 0.998138 ,val loss : 0.106508 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :812 ]train loss : 0.080623 ,train acc: 0.993622 ,val loss : 0.106768 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :813 ]train loss : 0.526598 ,train acc: 0.609863 ,val loss : 0.107927 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :814 ]train loss : 0.085147 ,train acc: 0.993469 ,val loss : 0.107994 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :815 ]train loss : 0.096636 ,train acc: 0.992523 ,val loss : 0.103316 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :816 ]train loss : 0.107975 ,train acc: 0.987579 ,val loss : 0.104573 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :817 ]train loss : 0.064653 ,train acc: 0.997589 ,val loss : 0.105668 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :818 ]train loss : 0.122656 ,train acc: 0.964996 ,val loss : 0.105488 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :819 ]train loss : 0.079642 ,train acc: 0.986359 ,val loss : 0.104165 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :820 ]train loss : 0.057633 ,train acc: 0.998688 ,val loss : 0.105704 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :821 ]train loss : 0.074467 ,train acc: 0.990326 ,val loss : 0.106714 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :822 ]train loss : 0.075506 ,train acc: 0.995331 ,val loss : 0.105209 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :823 ]train loss : 0.074611 ,train acc: 0.994629 ,val loss : 0.105586 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :824 ]train loss : 0.122761 ,train acc: 0.973297 ,val loss : 0.105079 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :825 ]train loss : 0.061973 ,train acc: 0.999084 ,val loss : 0.103658 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :826 ]train loss : 0.155907 ,train acc: 0.930939 ,val loss : 0.106245 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :827 ]train loss : 0.081044 ,train acc: 0.986206 ,val loss : 0.105964 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :828 ]train loss : 0.073589 ,train acc: 0.995331 ,val loss : 0.106794 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :829 ]train loss : 0.091346 ,train acc: 0.983856 ,val loss : 0.105300 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :830 ]train loss : 0.156037 ,train acc: 0.961578 ,val loss : 0.106837 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :831 ]train loss : 0.100695 ,train acc: 0.991272 ,val loss : 0.105877 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :832 ]train loss : 0.088245 ,train acc: 0.991211 ,val loss : 0.104631 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :833 ]train loss : 0.070868 ,train acc: 0.996918 ,val loss : 0.105854 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :834 ]train loss : 0.094818 ,train acc: 0.996155 ,val loss : 0.105726 ,val acc : 0.992615\n",
      "[ ecpho : 6  iter :835 ]train loss : 0.105463 ,train acc: 0.985382 ,val loss : 0.104044 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :836 ]train loss : 0.071820 ,train acc: 0.997101 ,val loss : 0.106442 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :837 ]train loss : 0.079435 ,train acc: 0.997406 ,val loss : 0.105985 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :838 ]train loss : 0.114115 ,train acc: 0.966522 ,val loss : 0.107828 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :839 ]train loss : 0.124378 ,train acc: 0.958130 ,val loss : 0.104510 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :840 ]train loss : 0.083125 ,train acc: 0.995117 ,val loss : 0.105587 ,val acc : 0.992798\n",
      "[ ecpho : 6  iter :841 ]train loss : 0.141251 ,train acc: 0.962372 ,val loss : 0.103799 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :842 ]train loss : 0.101130 ,train acc: 0.992157 ,val loss : 0.107113 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :843 ]train loss : 0.412158 ,train acc: 0.760559 ,val loss : 0.105360 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :844 ]train loss : 0.080077 ,train acc: 0.990417 ,val loss : 0.103693 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :845 ]train loss : 0.080861 ,train acc: 0.990021 ,val loss : 0.107048 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :846 ]train loss : 0.064967 ,train acc: 0.997406 ,val loss : 0.106283 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :847 ]train loss : 0.253680 ,train acc: 0.869080 ,val loss : 0.103611 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :848 ]train loss : 0.268110 ,train acc: 0.916473 ,val loss : 0.109536 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :849 ]train loss : 0.077391 ,train acc: 0.998413 ,val loss : 0.106649 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :850 ]train loss : 0.097753 ,train acc: 0.982544 ,val loss : 0.105219 ,val acc : 0.992767\n",
      "[ ecpho : 6  iter :851 ]train loss : 0.323632 ,train acc: 0.790863 ,val loss : 0.103189 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :852 ]train loss : 0.573669 ,train acc: 0.622406 ,val loss : 0.106150 ,val acc : 0.992035\n",
      "[ ecpho : 6  iter :853 ]train loss : 0.060533 ,train acc: 0.997925 ,val loss : 0.105130 ,val acc : 0.992798\n",
      "[ ecpho : 6  iter :854 ]train loss : 0.231760 ,train acc: 0.860016 ,val loss : 0.103172 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :855 ]train loss : 0.080483 ,train acc: 0.991974 ,val loss : 0.105268 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :856 ]train loss : 0.057896 ,train acc: 0.997894 ,val loss : 0.104738 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :857 ]train loss : 0.087211 ,train acc: 0.984589 ,val loss : 0.104503 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :858 ]train loss : 0.231254 ,train acc: 0.909851 ,val loss : 0.103904 ,val acc : 0.992645\n",
      "[ ecpho : 6  iter :859 ]train loss : 0.071391 ,train acc: 0.992065 ,val loss : 0.105782 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :860 ]train loss : 0.106565 ,train acc: 0.988129 ,val loss : 0.105184 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :861 ]train loss : 0.068552 ,train acc: 0.997467 ,val loss : 0.105888 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :862 ]train loss : 0.227733 ,train acc: 0.873718 ,val loss : 0.105558 ,val acc : 0.992737\n",
      "[ ecpho : 6  iter :863 ]train loss : 0.120552 ,train acc: 0.987823 ,val loss : 0.106583 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :864 ]train loss : 0.164202 ,train acc: 0.933380 ,val loss : 0.105073 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :865 ]train loss : 0.093323 ,train acc: 0.990814 ,val loss : 0.105683 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :866 ]train loss : 0.136765 ,train acc: 0.952271 ,val loss : 0.105276 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :867 ]train loss : 0.069173 ,train acc: 0.991943 ,val loss : 0.106029 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :868 ]train loss : 0.241275 ,train acc: 0.859009 ,val loss : 0.104841 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :869 ]train loss : 0.095748 ,train acc: 0.991425 ,val loss : 0.104515 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :870 ]train loss : 0.098729 ,train acc: 0.991913 ,val loss : 0.104634 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :871 ]train loss : 0.062912 ,train acc: 0.998840 ,val loss : 0.104212 ,val acc : 0.992004\n",
      "[ ecpho : 6  iter :872 ]train loss : 0.078851 ,train acc: 0.995514 ,val loss : 0.104864 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :873 ]train loss : 0.077532 ,train acc: 0.992950 ,val loss : 0.105309 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :874 ]train loss : 0.099145 ,train acc: 0.976227 ,val loss : 0.107077 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :875 ]train loss : 0.325141 ,train acc: 0.792450 ,val loss : 0.106398 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :876 ]train loss : 0.070518 ,train acc: 0.998047 ,val loss : 0.102587 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :877 ]train loss : 0.073781 ,train acc: 0.995300 ,val loss : 0.102962 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :878 ]train loss : 0.088264 ,train acc: 0.982727 ,val loss : 0.105116 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :879 ]train loss : 0.613116 ,train acc: 0.552979 ,val loss : 0.105352 ,val acc : 0.992584\n",
      "[ ecpho : 6  iter :880 ]train loss : 0.150741 ,train acc: 0.973358 ,val loss : 0.108047 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :881 ]train loss : 1.164467 ,train acc: 0.204041 ,val loss : 0.106137 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :882 ]train loss : 0.065832 ,train acc: 0.995300 ,val loss : 0.106696 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :883 ]train loss : 0.108406 ,train acc: 0.985992 ,val loss : 0.106659 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :884 ]train loss : 0.067206 ,train acc: 0.998138 ,val loss : 0.103833 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :885 ]train loss : 0.210900 ,train acc: 0.934387 ,val loss : 0.106892 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :886 ]train loss : 0.088051 ,train acc: 0.992767 ,val loss : 0.106071 ,val acc : 0.992554\n",
      "[ ecpho : 6  iter :887 ]train loss : 0.269192 ,train acc: 0.877838 ,val loss : 0.103683 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :888 ]train loss : 0.096131 ,train acc: 0.980682 ,val loss : 0.106261 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :889 ]train loss : 0.189692 ,train acc: 0.951935 ,val loss : 0.106874 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :890 ]train loss : 0.130772 ,train acc: 0.986145 ,val loss : 0.107315 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :891 ]train loss : 0.091853 ,train acc: 0.994843 ,val loss : 0.107406 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :892 ]train loss : 0.125065 ,train acc: 0.956421 ,val loss : 0.107409 ,val acc : 0.992767\n",
      "[ ecpho : 6  iter :893 ]train loss : 0.072339 ,train acc: 0.992737 ,val loss : 0.103566 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :894 ]train loss : 0.060379 ,train acc: 0.998322 ,val loss : 0.106918 ,val acc : 0.991943\n",
      "[ ecpho : 6  iter :895 ]train loss : 0.072559 ,train acc: 0.991943 ,val loss : 0.105341 ,val acc : 0.992126\n",
      "[ ecpho : 6  iter :896 ]train loss : 0.102657 ,train acc: 0.990997 ,val loss : 0.105368 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :897 ]train loss : 0.113263 ,train acc: 0.973267 ,val loss : 0.105324 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :898 ]train loss : 0.100035 ,train acc: 0.979034 ,val loss : 0.106562 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :899 ]train loss : 0.083410 ,train acc: 0.985748 ,val loss : 0.104543 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :900 ]train loss : 0.081122 ,train acc: 0.989380 ,val loss : 0.106291 ,val acc : 0.992310\n",
      "[ ecpho : 6  iter :901 ]train loss : 0.107468 ,train acc: 0.987152 ,val loss : 0.105961 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :902 ]train loss : 0.114780 ,train acc: 0.971130 ,val loss : 0.105945 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :903 ]train loss : 0.420297 ,train acc: 0.704376 ,val loss : 0.106275 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :904 ]train loss : 0.168591 ,train acc: 0.918030 ,val loss : 0.107444 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :905 ]train loss : 0.070881 ,train acc: 0.996338 ,val loss : 0.104357 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :906 ]train loss : 0.070328 ,train acc: 0.997131 ,val loss : 0.103297 ,val acc : 0.992401\n",
      "[ ecpho : 6  iter :907 ]train loss : 0.631733 ,train acc: 0.567474 ,val loss : 0.106656 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :908 ]train loss : 0.120159 ,train acc: 0.965332 ,val loss : 0.105817 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :909 ]train loss : 0.218267 ,train acc: 0.920593 ,val loss : 0.104563 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :910 ]train loss : 0.088807 ,train acc: 0.996552 ,val loss : 0.106803 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :911 ]train loss : 0.218771 ,train acc: 0.913025 ,val loss : 0.104306 ,val acc : 0.992218\n",
      "[ ecpho : 6  iter :912 ]train loss : 0.188433 ,train acc: 0.918396 ,val loss : 0.102991 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :913 ]train loss : 0.064557 ,train acc: 0.998291 ,val loss : 0.107023 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :914 ]train loss : 0.058272 ,train acc: 0.998291 ,val loss : 0.103335 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :915 ]train loss : 0.986858 ,train acc: 0.422913 ,val loss : 0.105275 ,val acc : 0.992493\n",
      "[ ecpho : 6  iter :916 ]train loss : 0.177882 ,train acc: 0.933990 ,val loss : 0.104761 ,val acc : 0.992523\n",
      "[ ecpho : 6  iter :917 ]train loss : 0.103710 ,train acc: 0.978973 ,val loss : 0.105490 ,val acc : 0.992737\n",
      "[ ecpho : 6  iter :918 ]train loss : 0.128995 ,train acc: 0.956390 ,val loss : 0.104136 ,val acc : 0.992065\n",
      "[ ecpho : 6  iter :919 ]train loss : 0.074081 ,train acc: 0.990631 ,val loss : 0.104634 ,val acc : 0.992371\n",
      "[ ecpho : 6  iter :920 ]train loss : 0.350745 ,train acc: 0.774628 ,val loss : 0.106966 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :921 ]train loss : 0.081452 ,train acc: 0.988220 ,val loss : 0.105897 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :922 ]train loss : 0.149898 ,train acc: 0.972107 ,val loss : 0.102962 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :923 ]train loss : 0.068634 ,train acc: 0.997223 ,val loss : 0.105922 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :924 ]train loss : 0.152491 ,train acc: 0.941254 ,val loss : 0.105981 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :925 ]train loss : 0.085753 ,train acc: 0.994415 ,val loss : 0.106045 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :926 ]train loss : 0.065302 ,train acc: 0.997864 ,val loss : 0.104649 ,val acc : 0.992188\n",
      "[ ecpho : 6  iter :927 ]train loss : 0.323344 ,train acc: 0.785278 ,val loss : 0.103903 ,val acc : 0.992157\n",
      "[ ecpho : 6  iter :928 ]train loss : 0.063062 ,train acc: 0.997437 ,val loss : 0.103712 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :929 ]train loss : 0.114287 ,train acc: 0.983795 ,val loss : 0.106729 ,val acc : 0.991974\n",
      "[ ecpho : 6  iter :930 ]train loss : 0.082430 ,train acc: 0.987793 ,val loss : 0.104728 ,val acc : 0.992279\n",
      "[ ecpho : 6  iter :931 ]train loss : 0.068645 ,train acc: 0.994171 ,val loss : 0.105921 ,val acc : 0.992340\n",
      "[ ecpho : 6  iter :932 ]train loss : 0.207636 ,train acc: 0.903015 ,val loss : 0.105460 ,val acc : 0.992432\n",
      "[ ecpho : 6  iter :933 ]train loss : 0.084692 ,train acc: 0.997742 ,val loss : 0.102565 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :934 ]train loss : 0.169899 ,train acc: 0.919281 ,val loss : 0.104672 ,val acc : 0.992462\n",
      "[ ecpho : 6  iter :935 ]train loss : 0.086791 ,train acc: 0.996643 ,val loss : 0.105488 ,val acc : 0.992676\n",
      "[ ecpho : 6  iter :936 ]train loss : 0.079481 ,train acc: 0.993683 ,val loss : 0.107290 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :937 ]train loss : 0.082863 ,train acc: 0.988464 ,val loss : 0.104861 ,val acc : 0.992706\n",
      "[ ecpho : 6  iter :938 ]train loss : 0.111335 ,train acc: 0.988007 ,val loss : 0.104969 ,val acc : 0.992096\n",
      "[ ecpho : 6  iter :939 ]train loss : 0.142434 ,train acc: 0.949341 ,val loss : 0.106125 ,val acc : 0.992249\n",
      "[ ecpho : 6  iter :940 ]train loss : 0.152766 ,train acc: 0.972412 ,val loss : 0.105499 ,val acc : 0.992371\n",
      "=============================================\n",
      "[ 6 ] average train loss : 0.161806 train acc : 0.934525\n",
      "[ ecpho : 7  iter :1 ]train loss : 0.076237 ,train acc: 0.991455 ,val loss : 0.104408 ,val acc : 0.992676\n",
      "[ ecpho : 7  iter :2 ]train loss : 0.222308 ,train acc: 0.894104 ,val loss : 0.109152 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :3 ]train loss : 0.074935 ,train acc: 0.993561 ,val loss : 0.106787 ,val acc : 0.992462\n",
      "[ ecpho : 7  iter :4 ]train loss : 0.102765 ,train acc: 0.974396 ,val loss : 0.104361 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :5 ]train loss : 0.094857 ,train acc: 0.994293 ,val loss : 0.103143 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :6 ]train loss : 0.092967 ,train acc: 0.993225 ,val loss : 0.103354 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :7 ]train loss : 0.093121 ,train acc: 0.977722 ,val loss : 0.106328 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :8 ]train loss : 0.337217 ,train acc: 0.859497 ,val loss : 0.106673 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :9 ]train loss : 0.165462 ,train acc: 0.926483 ,val loss : 0.103081 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :10 ]train loss : 0.147903 ,train acc: 0.952179 ,val loss : 0.105359 ,val acc : 0.992676\n",
      "[ ecpho : 7  iter :11 ]train loss : 0.069148 ,train acc: 0.998535 ,val loss : 0.106279 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :12 ]train loss : 0.090983 ,train acc: 0.993805 ,val loss : 0.105836 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :13 ]train loss : 0.086743 ,train acc: 0.985779 ,val loss : 0.106300 ,val acc : 0.992493\n",
      "[ ecpho : 7  iter :14 ]train loss : 0.092757 ,train acc: 0.996674 ,val loss : 0.105005 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :15 ]train loss : 0.083989 ,train acc: 0.983307 ,val loss : 0.104129 ,val acc : 0.992676\n",
      "[ ecpho : 7  iter :16 ]train loss : 0.089999 ,train acc: 0.993164 ,val loss : 0.106200 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :17 ]train loss : 0.085883 ,train acc: 0.995728 ,val loss : 0.104608 ,val acc : 0.991943\n",
      "[ ecpho : 7  iter :18 ]train loss : 0.744745 ,train acc: 0.504944 ,val loss : 0.106470 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :19 ]train loss : 0.093687 ,train acc: 0.980988 ,val loss : 0.106470 ,val acc : 0.992828\n",
      "[ ecpho : 7  iter :20 ]train loss : 0.096283 ,train acc: 0.992706 ,val loss : 0.105256 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :21 ]train loss : 0.112280 ,train acc: 0.985260 ,val loss : 0.104351 ,val acc : 0.992493\n",
      "[ ecpho : 7  iter :22 ]train loss : 0.117602 ,train acc: 0.973694 ,val loss : 0.102673 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :23 ]train loss : 0.057256 ,train acc: 0.999176 ,val loss : 0.106821 ,val acc : 0.992798\n",
      "[ ecpho : 7  iter :24 ]train loss : 0.103973 ,train acc: 0.991699 ,val loss : 0.105436 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :25 ]train loss : 0.102363 ,train acc: 0.976257 ,val loss : 0.103887 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :26 ]train loss : 0.409592 ,train acc: 0.779602 ,val loss : 0.104789 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :27 ]train loss : 0.348927 ,train acc: 0.770172 ,val loss : 0.103854 ,val acc : 0.992798\n",
      "[ ecpho : 7  iter :28 ]train loss : 0.082824 ,train acc: 0.994751 ,val loss : 0.104317 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :29 ]train loss : 0.097859 ,train acc: 0.982666 ,val loss : 0.106157 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :30 ]train loss : 0.072834 ,train acc: 0.995209 ,val loss : 0.104162 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :31 ]train loss : 0.076859 ,train acc: 0.992096 ,val loss : 0.105099 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :32 ]train loss : 0.076435 ,train acc: 0.989075 ,val loss : 0.105859 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :33 ]train loss : 0.057574 ,train acc: 0.998138 ,val loss : 0.104611 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :34 ]train loss : 0.083010 ,train acc: 0.994263 ,val loss : 0.105315 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :35 ]train loss : 0.066735 ,train acc: 0.997131 ,val loss : 0.105996 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :36 ]train loss : 0.112209 ,train acc: 0.969574 ,val loss : 0.105263 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :37 ]train loss : 0.099643 ,train acc: 0.993805 ,val loss : 0.102961 ,val acc : 0.992462\n",
      "[ ecpho : 7  iter :38 ]train loss : 0.112296 ,train acc: 0.964294 ,val loss : 0.104214 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :39 ]train loss : 0.250256 ,train acc: 0.854767 ,val loss : 0.107728 ,val acc : 0.992432\n",
      "[ ecpho : 7  iter :40 ]train loss : 0.210806 ,train acc: 0.939789 ,val loss : 0.104077 ,val acc : 0.992615\n",
      "[ ecpho : 7  iter :41 ]train loss : 0.076013 ,train acc: 0.994263 ,val loss : 0.105640 ,val acc : 0.992798\n",
      "[ ecpho : 7  iter :42 ]train loss : 0.075926 ,train acc: 0.993835 ,val loss : 0.104241 ,val acc : 0.992462\n",
      "[ ecpho : 7  iter :43 ]train loss : 0.177384 ,train acc: 0.955231 ,val loss : 0.107005 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :44 ]train loss : 0.085117 ,train acc: 0.989594 ,val loss : 0.105279 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :45 ]train loss : 0.099801 ,train acc: 0.985291 ,val loss : 0.105721 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :46 ]train loss : 0.759404 ,train acc: 0.428894 ,val loss : 0.107091 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :47 ]train loss : 0.091974 ,train acc: 0.977570 ,val loss : 0.104814 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :48 ]train loss : 0.109739 ,train acc: 0.985443 ,val loss : 0.105676 ,val acc : 0.992584\n",
      "[ ecpho : 7  iter :49 ]train loss : 0.099506 ,train acc: 0.992188 ,val loss : 0.106021 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :50 ]train loss : 0.100967 ,train acc: 0.974365 ,val loss : 0.104960 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :51 ]train loss : 0.080932 ,train acc: 0.995026 ,val loss : 0.106012 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :52 ]train loss : 0.106225 ,train acc: 0.991058 ,val loss : 0.104911 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :53 ]train loss : 0.104072 ,train acc: 0.974518 ,val loss : 0.104988 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :54 ]train loss : 0.170692 ,train acc: 0.921021 ,val loss : 0.103356 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :55 ]train loss : 0.110618 ,train acc: 0.992249 ,val loss : 0.105867 ,val acc : 0.992706\n",
      "[ ecpho : 7  iter :56 ]train loss : 0.187300 ,train acc: 0.916321 ,val loss : 0.104495 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :57 ]train loss : 0.357232 ,train acc: 0.771667 ,val loss : 0.106070 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :58 ]train loss : 0.073136 ,train acc: 0.992065 ,val loss : 0.105426 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :59 ]train loss : 0.128054 ,train acc: 0.967194 ,val loss : 0.101887 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :60 ]train loss : 0.066045 ,train acc: 0.998962 ,val loss : 0.107675 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :61 ]train loss : 0.144532 ,train acc: 0.951111 ,val loss : 0.107152 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :62 ]train loss : 0.122391 ,train acc: 0.955994 ,val loss : 0.105162 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :63 ]train loss : 0.433195 ,train acc: 0.710358 ,val loss : 0.104550 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :64 ]train loss : 0.383311 ,train acc: 0.782654 ,val loss : 0.104226 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :65 ]train loss : 0.136596 ,train acc: 0.981079 ,val loss : 0.104157 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :66 ]train loss : 0.076978 ,train acc: 0.997559 ,val loss : 0.106664 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :67 ]train loss : 0.109680 ,train acc: 0.980499 ,val loss : 0.105018 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :68 ]train loss : 0.076668 ,train acc: 0.997070 ,val loss : 0.104081 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :69 ]train loss : 0.086711 ,train acc: 0.996552 ,val loss : 0.103216 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :70 ]train loss : 0.113968 ,train acc: 0.984711 ,val loss : 0.105128 ,val acc : 0.992798\n",
      "[ ecpho : 7  iter :71 ]train loss : 0.079871 ,train acc: 0.990997 ,val loss : 0.102854 ,val acc : 0.992767\n",
      "[ ecpho : 7  iter :72 ]train loss : 0.084790 ,train acc: 0.985535 ,val loss : 0.106688 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :73 ]train loss : 0.069674 ,train acc: 0.993927 ,val loss : 0.104058 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :74 ]train loss : 0.526332 ,train acc: 0.643616 ,val loss : 0.104998 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :75 ]train loss : 0.105745 ,train acc: 0.972504 ,val loss : 0.105514 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :76 ]train loss : 0.063254 ,train acc: 0.997864 ,val loss : 0.104940 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :77 ]train loss : 0.079384 ,train acc: 0.991791 ,val loss : 0.103823 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :78 ]train loss : 0.065222 ,train acc: 0.993744 ,val loss : 0.104495 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :79 ]train loss : 0.059492 ,train acc: 0.996246 ,val loss : 0.104658 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :80 ]train loss : 0.098547 ,train acc: 0.993103 ,val loss : 0.103314 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :81 ]train loss : 0.094309 ,train acc: 0.981689 ,val loss : 0.103911 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :82 ]train loss : 0.453733 ,train acc: 0.716553 ,val loss : 0.103178 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :83 ]train loss : 0.080187 ,train acc: 0.991577 ,val loss : 0.102446 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :84 ]train loss : 0.079258 ,train acc: 0.997986 ,val loss : 0.103675 ,val acc : 0.992706\n",
      "[ ecpho : 7  iter :85 ]train loss : 0.068879 ,train acc: 0.995544 ,val loss : 0.103471 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :86 ]train loss : 0.065391 ,train acc: 0.997345 ,val loss : 0.105269 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :87 ]train loss : 0.091706 ,train acc: 0.987061 ,val loss : 0.105985 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :88 ]train loss : 0.110970 ,train acc: 0.986725 ,val loss : 0.103656 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :89 ]train loss : 0.224670 ,train acc: 0.880554 ,val loss : 0.104732 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :90 ]train loss : 0.315539 ,train acc: 0.866333 ,val loss : 0.106164 ,val acc : 0.992615\n",
      "[ ecpho : 7  iter :91 ]train loss : 0.076368 ,train acc: 0.997101 ,val loss : 0.105861 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :92 ]train loss : 0.156465 ,train acc: 0.929871 ,val loss : 0.103614 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :93 ]train loss : 0.367910 ,train acc: 0.782623 ,val loss : 0.104352 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :94 ]train loss : 0.079650 ,train acc: 0.996521 ,val loss : 0.107134 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :95 ]train loss : 0.585496 ,train acc: 0.691528 ,val loss : 0.104782 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :96 ]train loss : 0.117148 ,train acc: 0.973938 ,val loss : 0.103455 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :97 ]train loss : 0.094100 ,train acc: 0.979736 ,val loss : 0.104711 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :98 ]train loss : 0.088381 ,train acc: 0.994659 ,val loss : 0.107156 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :99 ]train loss : 0.061521 ,train acc: 0.997528 ,val loss : 0.105652 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :100 ]train loss : 0.130991 ,train acc: 0.974274 ,val loss : 0.105119 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :101 ]train loss : 0.090483 ,train acc: 0.993927 ,val loss : 0.103040 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :102 ]train loss : 0.482917 ,train acc: 0.690613 ,val loss : 0.104976 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :103 ]train loss : 0.490457 ,train acc: 0.753540 ,val loss : 0.105666 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :104 ]train loss : 0.460903 ,train acc: 0.684570 ,val loss : 0.102844 ,val acc : 0.993011\n",
      "[ ecpho : 7  iter :105 ]train loss : 0.079860 ,train acc: 0.991302 ,val loss : 0.105740 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :106 ]train loss : 0.130194 ,train acc: 0.977203 ,val loss : 0.104585 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :107 ]train loss : 0.148322 ,train acc: 0.961273 ,val loss : 0.104939 ,val acc : 0.992432\n",
      "[ ecpho : 7  iter :108 ]train loss : 0.097482 ,train acc: 0.993408 ,val loss : 0.105489 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :109 ]train loss : 0.210823 ,train acc: 0.915649 ,val loss : 0.103935 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :110 ]train loss : 0.065799 ,train acc: 0.998108 ,val loss : 0.104749 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :111 ]train loss : 0.254445 ,train acc: 0.865845 ,val loss : 0.104604 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :112 ]train loss : 0.096788 ,train acc: 0.983307 ,val loss : 0.103442 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :113 ]train loss : 0.783660 ,train acc: 0.463898 ,val loss : 0.105036 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :114 ]train loss : 0.079248 ,train acc: 0.989319 ,val loss : 0.103635 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :115 ]train loss : 0.070509 ,train acc: 0.993225 ,val loss : 0.105035 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :116 ]train loss : 0.313678 ,train acc: 0.790497 ,val loss : 0.103308 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :117 ]train loss : 0.113554 ,train acc: 0.968262 ,val loss : 0.103695 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :118 ]train loss : 0.116041 ,train acc: 0.961273 ,val loss : 0.105666 ,val acc : 0.992615\n",
      "[ ecpho : 7  iter :119 ]train loss : 0.084319 ,train acc: 0.992371 ,val loss : 0.105188 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :120 ]train loss : 0.061976 ,train acc: 0.998260 ,val loss : 0.103747 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :121 ]train loss : 0.590868 ,train acc: 0.606293 ,val loss : 0.103060 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :122 ]train loss : 0.077423 ,train acc: 0.991821 ,val loss : 0.103700 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :123 ]train loss : 0.084167 ,train acc: 0.997040 ,val loss : 0.106109 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :124 ]train loss : 0.074739 ,train acc: 0.995087 ,val loss : 0.106813 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :125 ]train loss : 0.096118 ,train acc: 0.992035 ,val loss : 0.101606 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :126 ]train loss : 0.062624 ,train acc: 0.998291 ,val loss : 0.104159 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :127 ]train loss : 0.900628 ,train acc: 0.354248 ,val loss : 0.105461 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :128 ]train loss : 0.094866 ,train acc: 0.990479 ,val loss : 0.102552 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :129 ]train loss : 0.523944 ,train acc: 0.658997 ,val loss : 0.106054 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :130 ]train loss : 0.418543 ,train acc: 0.712769 ,val loss : 0.106689 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :131 ]train loss : 0.100853 ,train acc: 0.975464 ,val loss : 0.105907 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :132 ]train loss : 0.087137 ,train acc: 0.993225 ,val loss : 0.106675 ,val acc : 0.991608\n",
      "[ ecpho : 7  iter :133 ]train loss : 0.297913 ,train acc: 0.850098 ,val loss : 0.104921 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :134 ]train loss : 0.479754 ,train acc: 0.703339 ,val loss : 0.104155 ,val acc : 0.991760\n",
      "[ ecpho : 7  iter :135 ]train loss : 0.119347 ,train acc: 0.983612 ,val loss : 0.104582 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :136 ]train loss : 0.126632 ,train acc: 0.958801 ,val loss : 0.107152 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :137 ]train loss : 0.099324 ,train acc: 0.984894 ,val loss : 0.105087 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :138 ]train loss : 0.067644 ,train acc: 0.997192 ,val loss : 0.104376 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :139 ]train loss : 0.059044 ,train acc: 0.999359 ,val loss : 0.105732 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :140 ]train loss : 0.073593 ,train acc: 0.996643 ,val loss : 0.105260 ,val acc : 0.991943\n",
      "[ ecpho : 7  iter :141 ]train loss : 0.591651 ,train acc: 0.552765 ,val loss : 0.103008 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :142 ]train loss : 0.082443 ,train acc: 0.982391 ,val loss : 0.105700 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :143 ]train loss : 0.097544 ,train acc: 0.977753 ,val loss : 0.106574 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :144 ]train loss : 0.098372 ,train acc: 0.974823 ,val loss : 0.102073 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :145 ]train loss : 0.070372 ,train acc: 0.991486 ,val loss : 0.107105 ,val acc : 0.991577\n",
      "[ ecpho : 7  iter :146 ]train loss : 0.072383 ,train acc: 0.992279 ,val loss : 0.105199 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :147 ]train loss : 0.070547 ,train acc: 0.993591 ,val loss : 0.107492 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :148 ]train loss : 1.084049 ,train acc: 0.221588 ,val loss : 0.105378 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :149 ]train loss : 0.140557 ,train acc: 0.949341 ,val loss : 0.108256 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :150 ]train loss : 0.114888 ,train acc: 0.977112 ,val loss : 0.106536 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :151 ]train loss : 0.801791 ,train acc: 0.427917 ,val loss : 0.103715 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :152 ]train loss : 0.224217 ,train acc: 0.924377 ,val loss : 0.107986 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :153 ]train loss : 0.127831 ,train acc: 0.955109 ,val loss : 0.104819 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :154 ]train loss : 0.196010 ,train acc: 0.943024 ,val loss : 0.106476 ,val acc : 0.991943\n",
      "[ ecpho : 7  iter :155 ]train loss : 0.098068 ,train acc: 0.988800 ,val loss : 0.104424 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :156 ]train loss : 0.081214 ,train acc: 0.988922 ,val loss : 0.109957 ,val acc : 0.991913\n",
      "[ ecpho : 7  iter :157 ]train loss : 0.089080 ,train acc: 0.996429 ,val loss : 0.103774 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :158 ]train loss : 0.074879 ,train acc: 0.996887 ,val loss : 0.106285 ,val acc : 0.991608\n",
      "[ ecpho : 7  iter :159 ]train loss : 0.111302 ,train acc: 0.985596 ,val loss : 0.107295 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :160 ]train loss : 0.122629 ,train acc: 0.962097 ,val loss : 0.103806 ,val acc : 0.992432\n",
      "[ ecpho : 7  iter :161 ]train loss : 1.193446 ,train acc: 0.125702 ,val loss : 0.105847 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :162 ]train loss : 0.160857 ,train acc: 0.947601 ,val loss : 0.104701 ,val acc : 0.991486\n",
      "[ ecpho : 7  iter :163 ]train loss : 0.114109 ,train acc: 0.965881 ,val loss : 0.105437 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :164 ]train loss : 0.134314 ,train acc: 0.976227 ,val loss : 0.105233 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :165 ]train loss : 0.077416 ,train acc: 0.996002 ,val loss : 0.107063 ,val acc : 0.991943\n",
      "[ ecpho : 7  iter :166 ]train loss : 0.086569 ,train acc: 0.987274 ,val loss : 0.105442 ,val acc : 0.992523\n",
      "[ ecpho : 7  iter :167 ]train loss : 0.426515 ,train acc: 0.726379 ,val loss : 0.105801 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :168 ]train loss : 0.126106 ,train acc: 0.958832 ,val loss : 0.107857 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :169 ]train loss : 0.313004 ,train acc: 0.841492 ,val loss : 0.106991 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :170 ]train loss : 0.832213 ,train acc: 0.442902 ,val loss : 0.104524 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :171 ]train loss : 0.081105 ,train acc: 0.989532 ,val loss : 0.104312 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :172 ]train loss : 0.399459 ,train acc: 0.799805 ,val loss : 0.106127 ,val acc : 0.991730\n",
      "[ ecpho : 7  iter :173 ]train loss : 0.697879 ,train acc: 0.529327 ,val loss : 0.103189 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :174 ]train loss : 0.117366 ,train acc: 0.986359 ,val loss : 0.108382 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :175 ]train loss : 0.068390 ,train acc: 0.997894 ,val loss : 0.106669 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :176 ]train loss : 0.265329 ,train acc: 0.836365 ,val loss : 0.106578 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :177 ]train loss : 0.097218 ,train acc: 0.986969 ,val loss : 0.108218 ,val acc : 0.991455\n",
      "[ ecpho : 7  iter :178 ]train loss : 0.095031 ,train acc: 0.992188 ,val loss : 0.106965 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :179 ]train loss : 0.175254 ,train acc: 0.920105 ,val loss : 0.105106 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :180 ]train loss : 0.080030 ,train acc: 0.989166 ,val loss : 0.108145 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :181 ]train loss : 0.180925 ,train acc: 0.953613 ,val loss : 0.105667 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :182 ]train loss : 0.116238 ,train acc: 0.982605 ,val loss : 0.104685 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :183 ]train loss : 0.080011 ,train acc: 0.992493 ,val loss : 0.106635 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :184 ]train loss : 0.087020 ,train acc: 0.990814 ,val loss : 0.106516 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :185 ]train loss : 0.820472 ,train acc: 0.384003 ,val loss : 0.106457 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :186 ]train loss : 0.122885 ,train acc: 0.960724 ,val loss : 0.104737 ,val acc : 0.991577\n",
      "[ ecpho : 7  iter :187 ]train loss : 0.112125 ,train acc: 0.982361 ,val loss : 0.106499 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :188 ]train loss : 0.089858 ,train acc: 0.996429 ,val loss : 0.106229 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :189 ]train loss : 0.066794 ,train acc: 0.996948 ,val loss : 0.106415 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :190 ]train loss : 0.105183 ,train acc: 0.991730 ,val loss : 0.107067 ,val acc : 0.991913\n",
      "[ ecpho : 7  iter :191 ]train loss : 0.184713 ,train acc: 0.910797 ,val loss : 0.110269 ,val acc : 0.991608\n",
      "[ ecpho : 7  iter :192 ]train loss : 0.074283 ,train acc: 0.994751 ,val loss : 0.104627 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :193 ]train loss : 0.136293 ,train acc: 0.953339 ,val loss : 0.105788 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :194 ]train loss : 0.353738 ,train acc: 0.813965 ,val loss : 0.106277 ,val acc : 0.991699\n",
      "[ ecpho : 7  iter :195 ]train loss : 0.072259 ,train acc: 0.990845 ,val loss : 0.106057 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :196 ]train loss : 0.071405 ,train acc: 0.994873 ,val loss : 0.103901 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :197 ]train loss : 0.080421 ,train acc: 0.992096 ,val loss : 0.106796 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :198 ]train loss : 0.075873 ,train acc: 0.993805 ,val loss : 0.106430 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :199 ]train loss : 0.434772 ,train acc: 0.700287 ,val loss : 0.105729 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :200 ]train loss : 0.197158 ,train acc: 0.917236 ,val loss : 0.109295 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :201 ]train loss : 0.068233 ,train acc: 0.993225 ,val loss : 0.105476 ,val acc : 0.991638\n",
      "[ ecpho : 7  iter :202 ]train loss : 0.074542 ,train acc: 0.998749 ,val loss : 0.107601 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :203 ]train loss : 0.125126 ,train acc: 0.977692 ,val loss : 0.106237 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :204 ]train loss : 0.103107 ,train acc: 0.974731 ,val loss : 0.107577 ,val acc : 0.991669\n",
      "[ ecpho : 7  iter :205 ]train loss : 0.080407 ,train acc: 0.993317 ,val loss : 0.105093 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :206 ]train loss : 0.295229 ,train acc: 0.839630 ,val loss : 0.104938 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :207 ]train loss : 0.214461 ,train acc: 0.890045 ,val loss : 0.107715 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :208 ]train loss : 0.098504 ,train acc: 0.991913 ,val loss : 0.105132 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :209 ]train loss : 0.087921 ,train acc: 0.982330 ,val loss : 0.105819 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :210 ]train loss : 0.060692 ,train acc: 0.997498 ,val loss : 0.105963 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :211 ]train loss : 0.082559 ,train acc: 0.985321 ,val loss : 0.107763 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :212 ]train loss : 0.333076 ,train acc: 0.773285 ,val loss : 0.106461 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :213 ]train loss : 0.074226 ,train acc: 0.993896 ,val loss : 0.105761 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :214 ]train loss : 0.080915 ,train acc: 0.988068 ,val loss : 0.105877 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :215 ]train loss : 0.083796 ,train acc: 0.984680 ,val loss : 0.103291 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :216 ]train loss : 0.082204 ,train acc: 0.988251 ,val loss : 0.105634 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :217 ]train loss : 0.128479 ,train acc: 0.974762 ,val loss : 0.105755 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :218 ]train loss : 0.087973 ,train acc: 0.983185 ,val loss : 0.108301 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :219 ]train loss : 0.072136 ,train acc: 0.991333 ,val loss : 0.106673 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :220 ]train loss : 0.088290 ,train acc: 0.980896 ,val loss : 0.105071 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :221 ]train loss : 0.062402 ,train acc: 0.993805 ,val loss : 0.108968 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :222 ]train loss : 0.069388 ,train acc: 0.996338 ,val loss : 0.107914 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :223 ]train loss : 0.066689 ,train acc: 0.994843 ,val loss : 0.106381 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :224 ]train loss : 0.452268 ,train acc: 0.681732 ,val loss : 0.103939 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :225 ]train loss : 0.075764 ,train acc: 0.993011 ,val loss : 0.105925 ,val acc : 0.991486\n",
      "[ ecpho : 7  iter :226 ]train loss : 0.120266 ,train acc: 0.979279 ,val loss : 0.108335 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :227 ]train loss : 0.203786 ,train acc: 0.948059 ,val loss : 0.105808 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :228 ]train loss : 0.205059 ,train acc: 0.895447 ,val loss : 0.105274 ,val acc : 0.991760\n",
      "[ ecpho : 7  iter :229 ]train loss : 0.118206 ,train acc: 0.962708 ,val loss : 0.107113 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :230 ]train loss : 0.105307 ,train acc: 0.974915 ,val loss : 0.108883 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :231 ]train loss : 0.078570 ,train acc: 0.991211 ,val loss : 0.107415 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :232 ]train loss : 0.078680 ,train acc: 0.990753 ,val loss : 0.105863 ,val acc : 0.991608\n",
      "[ ecpho : 7  iter :233 ]train loss : 0.088798 ,train acc: 0.995239 ,val loss : 0.109199 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :234 ]train loss : 0.161928 ,train acc: 0.931702 ,val loss : 0.105123 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :235 ]train loss : 0.071350 ,train acc: 0.997101 ,val loss : 0.106459 ,val acc : 0.991760\n",
      "[ ecpho : 7  iter :236 ]train loss : 0.069334 ,train acc: 0.996887 ,val loss : 0.107556 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :237 ]train loss : 0.115083 ,train acc: 0.964050 ,val loss : 0.106949 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :238 ]train loss : 0.106322 ,train acc: 0.978668 ,val loss : 0.105851 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :239 ]train loss : 0.079505 ,train acc: 0.995087 ,val loss : 0.107841 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :240 ]train loss : 0.155129 ,train acc: 0.960266 ,val loss : 0.106277 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :241 ]train loss : 0.195751 ,train acc: 0.893951 ,val loss : 0.105071 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :242 ]train loss : 0.101493 ,train acc: 0.973511 ,val loss : 0.107121 ,val acc : 0.991638\n",
      "[ ecpho : 7  iter :243 ]train loss : 0.112233 ,train acc: 0.974152 ,val loss : 0.107506 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :244 ]train loss : 0.058099 ,train acc: 0.998260 ,val loss : 0.107106 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :245 ]train loss : 0.077083 ,train acc: 0.995148 ,val loss : 0.107228 ,val acc : 0.991638\n",
      "[ ecpho : 7  iter :246 ]train loss : 0.093512 ,train acc: 0.986023 ,val loss : 0.104671 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :247 ]train loss : 0.067291 ,train acc: 0.999115 ,val loss : 0.103942 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :248 ]train loss : 0.066970 ,train acc: 0.997375 ,val loss : 0.104494 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :249 ]train loss : 0.061454 ,train acc: 0.998932 ,val loss : 0.108726 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :250 ]train loss : 0.061009 ,train acc: 0.997314 ,val loss : 0.106620 ,val acc : 0.991730\n",
      "[ ecpho : 7  iter :251 ]train loss : 0.094350 ,train acc: 0.977814 ,val loss : 0.107273 ,val acc : 0.991699\n",
      "[ ecpho : 7  iter :252 ]train loss : 0.072886 ,train acc: 0.997803 ,val loss : 0.106235 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :253 ]train loss : 0.138725 ,train acc: 0.950836 ,val loss : 0.105099 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :254 ]train loss : 1.194424 ,train acc: 0.182892 ,val loss : 0.106642 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :255 ]train loss : 0.151921 ,train acc: 0.938782 ,val loss : 0.104643 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :256 ]train loss : 0.161181 ,train acc: 0.933289 ,val loss : 0.106381 ,val acc : 0.992462\n",
      "[ ecpho : 7  iter :257 ]train loss : 0.062584 ,train acc: 0.997101 ,val loss : 0.105838 ,val acc : 0.991791\n",
      "[ ecpho : 7  iter :258 ]train loss : 0.087662 ,train acc: 0.996033 ,val loss : 0.106315 ,val acc : 0.992035\n",
      "[ ecpho : 7  iter :259 ]train loss : 0.868715 ,train acc: 0.464233 ,val loss : 0.105857 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :260 ]train loss : 0.074189 ,train acc: 0.993195 ,val loss : 0.106459 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :261 ]train loss : 0.070239 ,train acc: 0.995575 ,val loss : 0.107017 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :262 ]train loss : 0.060953 ,train acc: 0.999115 ,val loss : 0.107337 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :263 ]train loss : 0.077594 ,train acc: 0.986359 ,val loss : 0.104829 ,val acc : 0.991882\n",
      "[ ecpho : 7  iter :264 ]train loss : 0.097567 ,train acc: 0.995178 ,val loss : 0.105956 ,val acc : 0.992462\n",
      "[ ecpho : 7  iter :265 ]train loss : 0.126324 ,train acc: 0.966949 ,val loss : 0.103986 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :266 ]train loss : 0.073893 ,train acc: 0.993439 ,val loss : 0.106656 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :267 ]train loss : 0.052818 ,train acc: 0.999542 ,val loss : 0.103617 ,val acc : 0.991943\n",
      "[ ecpho : 7  iter :268 ]train loss : 0.085258 ,train acc: 0.997375 ,val loss : 0.105170 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :269 ]train loss : 0.094200 ,train acc: 0.980347 ,val loss : 0.104641 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :270 ]train loss : 0.117991 ,train acc: 0.966461 ,val loss : 0.106244 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :271 ]train loss : 0.163651 ,train acc: 0.950867 ,val loss : 0.106971 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :272 ]train loss : 0.297177 ,train acc: 0.817535 ,val loss : 0.105775 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :273 ]train loss : 0.067187 ,train acc: 0.998840 ,val loss : 0.109525 ,val acc : 0.991730\n",
      "[ ecpho : 7  iter :274 ]train loss : 0.077915 ,train acc: 0.985840 ,val loss : 0.106989 ,val acc : 0.992432\n",
      "[ ecpho : 7  iter :275 ]train loss : 0.163532 ,train acc: 0.960663 ,val loss : 0.105532 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :276 ]train loss : 0.087723 ,train acc: 0.983185 ,val loss : 0.105193 ,val acc : 0.991974\n",
      "[ ecpho : 7  iter :277 ]train loss : 0.108246 ,train acc: 0.968658 ,val loss : 0.105874 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :278 ]train loss : 0.112715 ,train acc: 0.986938 ,val loss : 0.106127 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :279 ]train loss : 0.085090 ,train acc: 0.997131 ,val loss : 0.105104 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :280 ]train loss : 0.123584 ,train acc: 0.973602 ,val loss : 0.105524 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :281 ]train loss : 0.119539 ,train acc: 0.977722 ,val loss : 0.105765 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :282 ]train loss : 1.000532 ,train acc: 0.281860 ,val loss : 0.105766 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :283 ]train loss : 0.070655 ,train acc: 0.994598 ,val loss : 0.108578 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :284 ]train loss : 0.076931 ,train acc: 0.991547 ,val loss : 0.106314 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :285 ]train loss : 0.070943 ,train acc: 0.992096 ,val loss : 0.105064 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :286 ]train loss : 0.287551 ,train acc: 0.890808 ,val loss : 0.106164 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :287 ]train loss : 0.188799 ,train acc: 0.912140 ,val loss : 0.105995 ,val acc : 0.992493\n",
      "[ ecpho : 7  iter :288 ]train loss : 0.266741 ,train acc: 0.828522 ,val loss : 0.106031 ,val acc : 0.992004\n",
      "[ ecpho : 7  iter :289 ]train loss : 0.109307 ,train acc: 0.973389 ,val loss : 0.107153 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :290 ]train loss : 0.058483 ,train acc: 0.998108 ,val loss : 0.106237 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :291 ]train loss : 0.076762 ,train acc: 0.984253 ,val loss : 0.107055 ,val acc : 0.992249\n",
      "[ ecpho : 7  iter :292 ]train loss : 0.766326 ,train acc: 0.437073 ,val loss : 0.106171 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :293 ]train loss : 0.085087 ,train acc: 0.997406 ,val loss : 0.107135 ,val acc : 0.991638\n",
      "[ ecpho : 7  iter :294 ]train loss : 0.127223 ,train acc: 0.953247 ,val loss : 0.105759 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :295 ]train loss : 0.069856 ,train acc: 0.997559 ,val loss : 0.105988 ,val acc : 0.992157\n",
      "[ ecpho : 7  iter :296 ]train loss : 0.065137 ,train acc: 0.997406 ,val loss : 0.107780 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :297 ]train loss : 0.098429 ,train acc: 0.993073 ,val loss : 0.106456 ,val acc : 0.992371\n",
      "[ ecpho : 7  iter :298 ]train loss : 0.095264 ,train acc: 0.993561 ,val loss : 0.105588 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :299 ]train loss : 0.087360 ,train acc: 0.998138 ,val loss : 0.107146 ,val acc : 0.992310\n",
      "[ ecpho : 7  iter :300 ]train loss : 0.061065 ,train acc: 0.998383 ,val loss : 0.105001 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :301 ]train loss : 0.339892 ,train acc: 0.783325 ,val loss : 0.106059 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :302 ]train loss : 0.109229 ,train acc: 0.982574 ,val loss : 0.104786 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :303 ]train loss : 0.389493 ,train acc: 0.767334 ,val loss : 0.105512 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :304 ]train loss : 0.703890 ,train acc: 0.445618 ,val loss : 0.106929 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :305 ]train loss : 0.373633 ,train acc: 0.753113 ,val loss : 0.105196 ,val acc : 0.992493\n",
      "[ ecpho : 7  iter :306 ]train loss : 0.162841 ,train acc: 0.944946 ,val loss : 0.107845 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :307 ]train loss : 0.354378 ,train acc: 0.808380 ,val loss : 0.107467 ,val acc : 0.992615\n",
      "[ ecpho : 7  iter :308 ]train loss : 0.120114 ,train acc: 0.972046 ,val loss : 0.104133 ,val acc : 0.992218\n",
      "[ ecpho : 7  iter :309 ]train loss : 0.075709 ,train acc: 0.998260 ,val loss : 0.106946 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :310 ]train loss : 0.279451 ,train acc: 0.893311 ,val loss : 0.106849 ,val acc : 0.991821\n",
      "[ ecpho : 7  iter :311 ]train loss : 0.072639 ,train acc: 0.993225 ,val loss : 0.107861 ,val acc : 0.991516\n",
      "[ ecpho : 7  iter :312 ]train loss : 0.054080 ,train acc: 0.999329 ,val loss : 0.106901 ,val acc : 0.991608\n",
      "[ ecpho : 7  iter :313 ]train loss : 0.095045 ,train acc: 0.978363 ,val loss : 0.104047 ,val acc : 0.992188\n",
      "[ ecpho : 7  iter :314 ]train loss : 0.344301 ,train acc: 0.826996 ,val loss : 0.106153 ,val acc : 0.992645\n",
      "[ ecpho : 7  iter :315 ]train loss : 0.085351 ,train acc: 0.990265 ,val loss : 0.105640 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :316 ]train loss : 0.057367 ,train acc: 0.998108 ,val loss : 0.110146 ,val acc : 0.991577\n",
      "[ ecpho : 7  iter :317 ]train loss : 0.142353 ,train acc: 0.958344 ,val loss : 0.105031 ,val acc : 0.992279\n",
      "[ ecpho : 7  iter :318 ]train loss : 0.102996 ,train acc: 0.975769 ,val loss : 0.105994 ,val acc : 0.991486\n",
      "[ ecpho : 7  iter :319 ]train loss : 0.159129 ,train acc: 0.933411 ,val loss : 0.105373 ,val acc : 0.991913\n",
      "[ ecpho : 7  iter :320 ]train loss : 0.086717 ,train acc: 0.996735 ,val loss : 0.107993 ,val acc : 0.991913\n",
      "[ ecpho : 7  iter :321 ]train loss : 0.099758 ,train acc: 0.992462 ,val loss : 0.106450 ,val acc : 0.992096\n",
      "[ ecpho : 7  iter :322 ]train loss : 0.069825 ,train acc: 0.993622 ,val loss : 0.104576 ,val acc : 0.992401\n",
      "[ ecpho : 7  iter :323 ]train loss : 0.064956 ,train acc: 0.997253 ,val loss : 0.106289 ,val acc : 0.991943\n",
      "[ ecpho : 7  iter :324 ]train loss : 0.620336 ,train acc: 0.688080 ,val loss : 0.106580 ,val acc : 0.991699\n",
      "[ ecpho : 7  iter :325 ]train loss : 0.079281 ,train acc: 0.990875 ,val loss : 0.106342 ,val acc : 0.991516\n",
      "[ ecpho : 7  iter :326 ]train loss : 0.066769 ,train acc: 0.994507 ,val loss : 0.105480 ,val acc : 0.991730\n",
      "[ ecpho : 7  iter :327 ]train loss : 0.080291 ,train acc: 0.996185 ,val loss : 0.106181 ,val acc : 0.992554\n",
      "[ ecpho : 7  iter :328 ]train loss : 0.073833 ,train acc: 0.994141 ,val loss : 0.106764 ,val acc : 0.991852\n",
      "[ ecpho : 7  iter :329 ]train loss : 0.358346 ,train acc: 0.808807 ,val loss : 0.107078 ,val acc : 0.991608\n",
      "[ ecpho : 7  iter :330 ]train loss : 0.161292 ,train acc: 0.932861 ,val loss : 0.106842 ,val acc : 0.991913\n",
      "[ ecpho : 7  iter :331 ]train loss : 0.102032 ,train acc: 0.992920 ,val loss : 0.108766 ,val acc : 0.992340\n",
      "[ ecpho : 7  iter :332 ]train loss : 0.190556 ,train acc: 0.929840 ,val loss : 0.105252 ,val acc : 0.991760\n",
      "[ ecpho : 7  iter :333 ]train loss : 0.099121 ,train acc: 0.979309 ,val loss : 0.105189 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :334 ]train loss : 0.078913 ,train acc: 0.993622 ,val loss : 0.108714 ,val acc : 0.992065\n",
      "[ ecpho : 7  iter :335 ]train loss : 0.105195 ,train acc: 0.990295 ,val loss : 0.106916 ,val acc : 0.992126\n",
      "[ ecpho : 7  iter :336 ]train loss : 0.933072 ,train acc: 0.382660 ,val loss : 0.107170 ,val acc : 0.992157\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "data_files = glob.glob('../unet_3d_traindata/*_data_*.npy')\n",
    "\n",
    "np.random.shuffle(data_files)\n",
    "train_datafiles = data_files[:-10]\n",
    "val_datafiles = data_files[-10:]  \n",
    "\n",
    "\n",
    "evaled_weights = []\n",
    "saver = tf.train.Saver()\n",
    "# sess = tf.InteractiveSession()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "val_costs = []\n",
    "val_accs = []\n",
    "for val_datafile in val_datafiles[:20]:\n",
    "    val_data = np.load(val_datafile)\n",
    "    val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "    val_norm[val_norm > 1] = 1\n",
    "    val_norm[val_norm < 0] = 0\n",
    "    val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "    val_label = np.load(val_datafiles[0].replace('_data_','_label_weighted'))\n",
    "    val_label = np.reshape(val_label,[1,64,64,64,2])\n",
    "    \n",
    "    val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                       feed_dict={x:val_norm,y:crop_to_shape(val_label,[32,32,32,2]),keep_prob:0.5})\n",
    "    print('val loss: %f ,val acc : %f' % (val_cost,val_acc))\n",
    "    val_costs.append(val_cost)\n",
    "    val_accs.append(val_acc)\n",
    "print(np.mean(val_cost),np.mean(val_acc))\n",
    "\n",
    "for ecpho in range(20):\n",
    "    iteration = 0\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    for train_datafile in train_datafiles:\n",
    "        iteration += 1\n",
    "        train_data = np.load(train_datafile)\n",
    "        train_norm = (train_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "        train_norm[train_norm > 1] = 1\n",
    "        train_norm[train_norm < 0] = 0\n",
    "        train_norm = np.reshape(train_norm,[1,64,64,64])\n",
    "        train_label = np.load(train_datafile.replace('_data_','_label_weighted'))\n",
    "        train_label = np.reshape(train_label,[1,64,64,64,2])\n",
    "        _,train_cost,train_output_shape,train_acc,ws = sess.run([optimizer,cost,logits_shape,accuracy,weights],\n",
    "                                       feed_dict={x:train_norm,y:crop_to_shape(train_label,[32,32,32,2]),keep_prob:0.5})\n",
    "        evaled_weights.extend(ws)\n",
    "        train_loss.append(train_cost)\n",
    "        train_accs.append(train_acc)\n",
    "        val_costs = []\n",
    "        val_accs = []\n",
    "        for val_datafile in val_datafiles[:10]:\n",
    "            val_data = np.load(val_datafile)\n",
    "            val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            val_norm[val_norm > 1] = 1\n",
    "            val_norm[val_norm < 0] = 0\n",
    "            val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "            val_label = np.load(val_datafiles[0].replace('_data_','_label_weighted'))\n",
    "            val_label = np.reshape(val_label,[1,64,64,64,2])\n",
    "            val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                           feed_dict={x:val_norm,y:crop_to_shape(val_label,[32,32,32,2]),keep_prob:0.5})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accs.append(val_acc)\n",
    "        print('[ ecpho : %d  iter :%d ]train loss : %f ,train acc: %f ,val loss : %f ,val acc : %f' % (ecpho,iteration,train_cost,train_acc,np.mean(val_cost),np.mean(val_acc)))\n",
    "    print(\"=============================================\")\n",
    "    print(\"[ %d ] average train loss : %f train acc : %f\" % (ecpho,np.mean(train_loss),np.mean(train_accs)))\n",
    "    \n",
    "    modelpath = './unet3d_models_3/ecpho_'+str(ecpho)\n",
    "    if not os.path.exists(modelpath):\n",
    "        os.mkdir(modelpath)\n",
    "    saver.save(sess,modelpath+'/unet3d_model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16040\n",
      "165\n",
      "val loss: 0.689933 ,val acc : 0.648895\n",
      "val loss: 0.689363 ,val acc : 0.649109\n",
      "0.689363 0.649109\n",
      "[ ecpho : 0  iter :1 ]train loss : 0.654566 ,train acc: 0.654521 ,val loss : 0.704670 ,val acc : 0.644470\n",
      "[ ecpho : 0  iter :2 ]train loss : 0.635287 ,train acc: 0.656444 ,val loss : 0.706882 ,val acc : 0.639008\n",
      "[ ecpho : 0  iter :3 ]train loss : 0.618558 ,train acc: 0.660981 ,val loss : 0.697151 ,val acc : 0.641724\n",
      "[ ecpho : 0  iter :4 ]train loss : 0.638679 ,train acc: 0.657430 ,val loss : 0.702251 ,val acc : 0.646545\n",
      "[ ecpho : 0  iter :5 ]train loss : 0.610012 ,train acc: 0.658193 ,val loss : 0.695565 ,val acc : 0.646637\n",
      "[ ecpho : 0  iter :6 ]train loss : 0.618261 ,train acc: 0.656739 ,val loss : 0.719544 ,val acc : 0.641602\n",
      "[ ecpho : 0  iter :7 ]train loss : 0.636098 ,train acc: 0.658580 ,val loss : 0.708617 ,val acc : 0.642242\n",
      "[ ecpho : 0  iter :8 ]train loss : 0.784518 ,train acc: 0.643708 ,val loss : 0.705656 ,val acc : 0.643616\n",
      "[ ecpho : 0  iter :9 ]train loss : 0.612606 ,train acc: 0.667074 ,val loss : 0.704450 ,val acc : 0.647308\n",
      "[ ecpho : 0  iter :10 ]train loss : 0.631088 ,train acc: 0.655986 ,val loss : 0.704525 ,val acc : 0.647034\n",
      "[ ecpho : 0  iter :11 ]train loss : 0.701272 ,train acc: 0.645742 ,val loss : 0.702981 ,val acc : 0.640106\n",
      "[ ecpho : 0  iter :12 ]train loss : 0.642827 ,train acc: 0.653524 ,val loss : 0.694165 ,val acc : 0.644257\n",
      "[ ecpho : 0  iter :13 ]train loss : 0.694013 ,train acc: 0.652314 ,val loss : 0.703296 ,val acc : 0.642914\n",
      "[ ecpho : 0  iter :14 ]train loss : 0.616664 ,train acc: 0.660024 ,val loss : 0.701634 ,val acc : 0.644867\n",
      "[ ecpho : 0  iter :15 ]train loss : 0.705348 ,train acc: 0.654002 ,val loss : 0.701849 ,val acc : 0.641083\n",
      "[ ecpho : 0  iter :16 ]train loss : 0.625645 ,train acc: 0.656301 ,val loss : 0.691841 ,val acc : 0.644653\n",
      "[ ecpho : 0  iter :17 ]train loss : 0.625644 ,train acc: 0.652985 ,val loss : 0.683602 ,val acc : 0.648163\n",
      "[ ecpho : 0  iter :18 ]train loss : 0.631544 ,train acc: 0.654623 ,val loss : 0.696872 ,val acc : 0.641785\n",
      "[ ecpho : 0  iter :19 ]train loss : 0.710452 ,train acc: 0.646485 ,val loss : 0.692569 ,val acc : 0.644196\n",
      "[ ecpho : 0  iter :20 ]train loss : 0.674818 ,train acc: 0.645925 ,val loss : 0.696173 ,val acc : 0.645874\n",
      "[ ecpho : 0  iter :21 ]train loss : 0.682505 ,train acc: 0.652598 ,val loss : 0.699370 ,val acc : 0.643005\n",
      "[ ecpho : 0  iter :22 ]train loss : 0.666431 ,train acc: 0.652649 ,val loss : 0.686119 ,val acc : 0.646484\n",
      "[ ecpho : 0  iter :23 ]train loss : 0.633222 ,train acc: 0.658834 ,val loss : 0.687433 ,val acc : 0.641602\n",
      "[ ecpho : 0  iter :24 ]train loss : 0.612133 ,train acc: 0.663829 ,val loss : 0.699227 ,val acc : 0.642670\n",
      "[ ecpho : 0  iter :25 ]train loss : 0.714383 ,train acc: 0.640493 ,val loss : 0.685343 ,val acc : 0.647644\n",
      "[ ecpho : 0  iter :26 ]train loss : 0.727380 ,train acc: 0.646871 ,val loss : 0.680397 ,val acc : 0.647461\n",
      "[ ecpho : 0  iter :27 ]train loss : 0.661053 ,train acc: 0.658702 ,val loss : 0.697098 ,val acc : 0.646210\n",
      "[ ecpho : 0  iter :28 ]train loss : 0.612816 ,train acc: 0.656271 ,val loss : 0.712663 ,val acc : 0.640869\n",
      "[ ecpho : 0  iter :29 ]train loss : 0.614727 ,train acc: 0.663941 ,val loss : 0.695831 ,val acc : 0.643738\n",
      "[ ecpho : 0  iter :30 ]train loss : 0.635890 ,train acc: 0.662924 ,val loss : 0.692371 ,val acc : 0.643799\n",
      "[ ecpho : 0  iter :31 ]train loss : 0.609904 ,train acc: 0.658499 ,val loss : 0.687670 ,val acc : 0.646973\n",
      "[ ecpho : 0  iter :32 ]train loss : 0.613207 ,train acc: 0.662557 ,val loss : 0.690595 ,val acc : 0.645935\n",
      "[ ecpho : 0  iter :33 ]train loss : 0.623051 ,train acc: 0.656637 ,val loss : 0.693283 ,val acc : 0.645752\n",
      "[ ecpho : 0  iter :34 ]train loss : 0.607557 ,train acc: 0.659963 ,val loss : 0.702104 ,val acc : 0.638977\n",
      "[ ecpho : 0  iter :35 ]train loss : 0.689916 ,train acc: 0.651907 ,val loss : 0.693567 ,val acc : 0.642853\n",
      "[ ecpho : 0  iter :36 ]train loss : 0.668982 ,train acc: 0.650513 ,val loss : 0.692676 ,val acc : 0.647858\n",
      "[ ecpho : 0  iter :37 ]train loss : 0.609797 ,train acc: 0.665446 ,val loss : 0.696539 ,val acc : 0.646698\n",
      "[ ecpho : 0  iter :38 ]train loss : 0.744127 ,train acc: 0.632304 ,val loss : 0.686462 ,val acc : 0.647827\n",
      "[ ecpho : 0  iter :39 ]train loss : 0.654509 ,train acc: 0.655091 ,val loss : 0.695535 ,val acc : 0.643494\n",
      "[ ecpho : 0  iter :40 ]train loss : 0.645826 ,train acc: 0.653534 ,val loss : 0.699232 ,val acc : 0.645020\n",
      "[ ecpho : 0  iter :41 ]train loss : 0.619620 ,train acc: 0.666036 ,val loss : 0.679640 ,val acc : 0.645782\n",
      "[ ecpho : 0  iter :42 ]train loss : 0.602079 ,train acc: 0.658366 ,val loss : 0.687956 ,val acc : 0.644928\n",
      "[ ecpho : 0  iter :43 ]train loss : 0.607052 ,train acc: 0.658661 ,val loss : 0.691203 ,val acc : 0.651337\n",
      "[ ecpho : 0  iter :44 ]train loss : 0.616639 ,train acc: 0.659526 ,val loss : 0.699354 ,val acc : 0.644897\n",
      "[ ecpho : 0  iter :45 ]train loss : 0.625181 ,train acc: 0.655823 ,val loss : 0.684885 ,val acc : 0.643646\n",
      "[ ecpho : 0  iter :46 ]train loss : 0.651507 ,train acc: 0.655376 ,val loss : 0.678544 ,val acc : 0.646484\n",
      "[ ecpho : 0  iter :47 ]train loss : 0.743285 ,train acc: 0.640432 ,val loss : 0.676548 ,val acc : 0.646454\n",
      "[ ecpho : 0  iter :48 ]train loss : 0.622393 ,train acc: 0.662344 ,val loss : 0.688973 ,val acc : 0.646149\n",
      "[ ecpho : 0  iter :49 ]train loss : 0.618279 ,train acc: 0.657430 ,val loss : 0.681935 ,val acc : 0.645294\n",
      "[ ecpho : 0  iter :50 ]train loss : 0.660868 ,train acc: 0.655701 ,val loss : 0.696130 ,val acc : 0.646423\n",
      "[ ecpho : 0  iter :51 ]train loss : 0.601066 ,train acc: 0.660197 ,val loss : 0.692064 ,val acc : 0.646667\n",
      "[ ecpho : 0  iter :52 ]train loss : 0.630782 ,train acc: 0.656138 ,val loss : 0.693640 ,val acc : 0.646118\n",
      "[ ecpho : 0  iter :53 ]train loss : 0.650635 ,train acc: 0.649709 ,val loss : 0.681387 ,val acc : 0.643219\n",
      "[ ecpho : 0  iter :54 ]train loss : 0.608809 ,train acc: 0.659190 ,val loss : 0.707320 ,val acc : 0.646759\n",
      "[ ecpho : 0  iter :55 ]train loss : 0.605838 ,train acc: 0.656851 ,val loss : 0.692164 ,val acc : 0.642883\n",
      "[ ecpho : 0  iter :56 ]train loss : 0.593848 ,train acc: 0.663870 ,val loss : 0.683791 ,val acc : 0.644409\n",
      "[ ecpho : 0  iter :57 ]train loss : 0.604523 ,train acc: 0.658926 ,val loss : 0.678008 ,val acc : 0.645691\n",
      "[ ecpho : 0  iter :58 ]train loss : 0.611761 ,train acc: 0.656332 ,val loss : 0.686532 ,val acc : 0.645844\n",
      "[ ecpho : 0  iter :59 ]train loss : 0.620158 ,train acc: 0.657695 ,val loss : 0.679875 ,val acc : 0.647705\n",
      "[ ecpho : 0  iter :60 ]train loss : 0.604455 ,train acc: 0.660350 ,val loss : 0.684725 ,val acc : 0.645264\n",
      "[ ecpho : 0  iter :61 ]train loss : 0.591224 ,train acc: 0.659943 ,val loss : 0.691111 ,val acc : 0.646423\n",
      "[ ecpho : 0  iter :62 ]train loss : 0.590963 ,train acc: 0.662395 ,val loss : 0.671288 ,val acc : 0.650787\n",
      "[ ecpho : 0  iter :63 ]train loss : 0.630933 ,train acc: 0.653809 ,val loss : 0.687759 ,val acc : 0.645752\n",
      "[ ecpho : 0  iter :64 ]train loss : 0.631783 ,train acc: 0.655843 ,val loss : 0.686721 ,val acc : 0.644348\n",
      "[ ecpho : 0  iter :65 ]train loss : 0.630299 ,train acc: 0.661103 ,val loss : 0.681454 ,val acc : 0.644501\n",
      "[ ecpho : 0  iter :66 ]train loss : 0.612340 ,train acc: 0.657888 ,val loss : 0.684368 ,val acc : 0.645935\n",
      "[ ecpho : 0  iter :67 ]train loss : 0.641360 ,train acc: 0.661082 ,val loss : 0.673658 ,val acc : 0.648773\n",
      "[ ecpho : 0  iter :68 ]train loss : 0.606955 ,train acc: 0.658722 ,val loss : 0.687793 ,val acc : 0.642456\n",
      "[ ecpho : 0  iter :69 ]train loss : 0.607619 ,train acc: 0.656688 ,val loss : 0.684692 ,val acc : 0.645782\n",
      "[ ecpho : 0  iter :70 ]train loss : 0.608473 ,train acc: 0.661825 ,val loss : 0.674899 ,val acc : 0.645569\n",
      "[ ecpho : 0  iter :71 ]train loss : 0.583747 ,train acc: 0.665752 ,val loss : 0.689221 ,val acc : 0.645020\n",
      "[ ecpho : 0  iter :72 ]train loss : 0.606246 ,train acc: 0.656698 ,val loss : 0.673480 ,val acc : 0.646027\n",
      "[ ecpho : 0  iter :73 ]train loss : 0.636913 ,train acc: 0.651581 ,val loss : 0.687234 ,val acc : 0.646393\n",
      "[ ecpho : 0  iter :74 ]train loss : 0.654828 ,train acc: 0.650452 ,val loss : 0.685427 ,val acc : 0.641876\n",
      "[ ecpho : 0  iter :75 ]train loss : 0.722106 ,train acc: 0.639710 ,val loss : 0.677751 ,val acc : 0.642212\n",
      "[ ecpho : 0  iter :76 ]train loss : 0.598112 ,train acc: 0.659272 ,val loss : 0.680002 ,val acc : 0.643463\n",
      "[ ecpho : 0  iter :77 ]train loss : 0.613412 ,train acc: 0.659048 ,val loss : 0.679235 ,val acc : 0.648438\n",
      "[ ecpho : 0  iter :78 ]train loss : 0.587353 ,train acc: 0.663758 ,val loss : 0.681527 ,val acc : 0.648499\n",
      "[ ecpho : 0  iter :79 ]train loss : 0.620678 ,train acc: 0.659221 ,val loss : 0.684185 ,val acc : 0.645966\n",
      "[ ecpho : 0  iter :80 ]train loss : 0.617777 ,train acc: 0.657959 ,val loss : 0.677767 ,val acc : 0.650116\n",
      "[ ecpho : 0  iter :81 ]train loss : 0.582742 ,train acc: 0.665579 ,val loss : 0.664999 ,val acc : 0.651886\n",
      "[ ecpho : 0  iter :82 ]train loss : 0.732983 ,train acc: 0.632996 ,val loss : 0.682406 ,val acc : 0.642761\n",
      "[ ecpho : 0  iter :83 ]train loss : 0.618581 ,train acc: 0.660106 ,val loss : 0.682022 ,val acc : 0.646057\n",
      "[ ecpho : 0  iter :84 ]train loss : 0.597665 ,train acc: 0.662354 ,val loss : 0.675592 ,val acc : 0.650116\n",
      "[ ecpho : 0  iter :85 ]train loss : 0.708341 ,train acc: 0.643463 ,val loss : 0.668678 ,val acc : 0.649841\n",
      "[ ecpho : 0  iter :86 ]train loss : 0.660063 ,train acc: 0.649252 ,val loss : 0.672484 ,val acc : 0.647552\n",
      "[ ecpho : 0  iter :87 ]train loss : 0.600018 ,train acc: 0.660340 ,val loss : 0.671491 ,val acc : 0.645966\n",
      "[ ecpho : 0  iter :88 ]train loss : 0.636367 ,train acc: 0.655050 ,val loss : 0.665342 ,val acc : 0.649933\n",
      "[ ecpho : 0  iter :89 ]train loss : 0.708592 ,train acc: 0.636037 ,val loss : 0.668838 ,val acc : 0.650757\n",
      "[ ecpho : 0  iter :90 ]train loss : 0.619593 ,train acc: 0.656840 ,val loss : 0.678384 ,val acc : 0.644684\n",
      "[ ecpho : 0  iter :91 ]train loss : 0.606615 ,train acc: 0.660218 ,val loss : 0.674087 ,val acc : 0.648224\n",
      "[ ecpho : 0  iter :92 ]train loss : 0.643472 ,train acc: 0.654501 ,val loss : 0.672442 ,val acc : 0.647583\n",
      "[ ecpho : 0  iter :93 ]train loss : 0.715576 ,train acc: 0.639161 ,val loss : 0.673874 ,val acc : 0.645538\n",
      "[ ecpho : 0  iter :94 ]train loss : 0.595294 ,train acc: 0.662201 ,val loss : 0.670033 ,val acc : 0.646515\n",
      "[ ecpho : 0  iter :95 ]train loss : 0.618673 ,train acc: 0.656484 ,val loss : 0.662299 ,val acc : 0.651428\n",
      "[ ecpho : 0  iter :96 ]train loss : 0.704446 ,train acc: 0.643667 ,val loss : 0.670547 ,val acc : 0.648376\n",
      "[ ecpho : 0  iter :97 ]train loss : 0.611280 ,train acc: 0.663544 ,val loss : 0.674814 ,val acc : 0.652618\n",
      "[ ecpho : 0  iter :98 ]train loss : 0.650799 ,train acc: 0.649374 ,val loss : 0.682766 ,val acc : 0.648438\n",
      "[ ecpho : 0  iter :99 ]train loss : 0.591524 ,train acc: 0.661683 ,val loss : 0.678635 ,val acc : 0.644806\n",
      "[ ecpho : 0  iter :100 ]train loss : 0.721130 ,train acc: 0.648428 ,val loss : 0.664227 ,val acc : 0.651520\n",
      "[ ecpho : 0  iter :101 ]train loss : 0.757439 ,train acc: 0.630310 ,val loss : 0.671322 ,val acc : 0.648865\n",
      "[ ecpho : 0  iter :102 ]train loss : 0.592220 ,train acc: 0.663646 ,val loss : 0.677817 ,val acc : 0.649994\n",
      "[ ecpho : 0  iter :103 ]train loss : 0.627718 ,train acc: 0.657512 ,val loss : 0.667656 ,val acc : 0.646118\n",
      "[ ecpho : 0  iter :104 ]train loss : 0.643662 ,train acc: 0.656973 ,val loss : 0.677277 ,val acc : 0.649384\n",
      "[ ecpho : 0  iter :105 ]train loss : 0.593059 ,train acc: 0.668224 ,val loss : 0.684062 ,val acc : 0.650482\n",
      "[ ecpho : 0  iter :106 ]train loss : 0.586322 ,train acc: 0.664602 ,val loss : 0.674182 ,val acc : 0.650726\n",
      "[ ecpho : 0  iter :107 ]train loss : 0.594428 ,train acc: 0.662496 ,val loss : 0.678596 ,val acc : 0.645294\n",
      "[ ecpho : 0  iter :108 ]train loss : 0.687682 ,train acc: 0.644064 ,val loss : 0.679310 ,val acc : 0.649353\n",
      "[ ecpho : 0  iter :109 ]train loss : 0.586554 ,train acc: 0.663371 ,val loss : 0.673247 ,val acc : 0.650421\n",
      "[ ecpho : 0  iter :110 ]train loss : 0.572191 ,train acc: 0.667166 ,val loss : 0.671971 ,val acc : 0.652283\n",
      "[ ecpho : 0  iter :111 ]train loss : 0.656881 ,train acc: 0.657542 ,val loss : 0.663561 ,val acc : 0.645660\n",
      "[ ecpho : 0  iter :112 ]train loss : 0.703609 ,train acc: 0.639323 ,val loss : 0.659194 ,val acc : 0.651337\n",
      "[ ecpho : 0  iter :113 ]train loss : 0.576800 ,train acc: 0.669108 ,val loss : 0.670155 ,val acc : 0.652161\n",
      "[ ecpho : 0  iter :114 ]train loss : 0.704256 ,train acc: 0.639455 ,val loss : 0.674446 ,val acc : 0.646149\n",
      "[ ecpho : 0  iter :115 ]train loss : 0.579575 ,train acc: 0.667878 ,val loss : 0.677311 ,val acc : 0.646515\n",
      "[ ecpho : 0  iter :116 ]train loss : 0.591624 ,train acc: 0.662486 ,val loss : 0.661404 ,val acc : 0.652771\n",
      "[ ecpho : 0  iter :117 ]train loss : 0.579440 ,train acc: 0.664256 ,val loss : 0.669284 ,val acc : 0.648773\n",
      "[ ecpho : 0  iter :118 ]train loss : 0.683863 ,train acc: 0.645549 ,val loss : 0.662146 ,val acc : 0.647400\n",
      "[ ecpho : 0  iter :119 ]train loss : 0.575642 ,train acc: 0.665579 ,val loss : 0.658583 ,val acc : 0.648651\n",
      "[ ecpho : 0  iter :120 ]train loss : 0.647013 ,train acc: 0.653453 ,val loss : 0.660996 ,val acc : 0.652008\n",
      "[ ecpho : 0  iter :121 ]train loss : 0.602005 ,train acc: 0.662832 ,val loss : 0.662888 ,val acc : 0.652863\n",
      "[ ecpho : 0  iter :122 ]train loss : 0.579358 ,train acc: 0.663554 ,val loss : 0.662776 ,val acc : 0.653076\n",
      "[ ecpho : 0  iter :123 ]train loss : 0.605018 ,train acc: 0.662700 ,val loss : 0.682890 ,val acc : 0.649902\n",
      "[ ecpho : 0  iter :124 ]train loss : 0.615041 ,train acc: 0.659943 ,val loss : 0.663848 ,val acc : 0.647339\n",
      "[ ecpho : 0  iter :125 ]train loss : 0.692231 ,train acc: 0.645671 ,val loss : 0.665250 ,val acc : 0.652008\n",
      "[ ecpho : 0  iter :126 ]train loss : 0.690363 ,train acc: 0.644949 ,val loss : 0.667669 ,val acc : 0.647675\n",
      "[ ecpho : 0  iter :127 ]train loss : 0.586523 ,train acc: 0.660909 ,val loss : 0.673061 ,val acc : 0.645325\n",
      "[ ecpho : 0  iter :128 ]train loss : 0.571529 ,train acc: 0.664307 ,val loss : 0.655269 ,val acc : 0.653351\n",
      "[ ecpho : 0  iter :129 ]train loss : 0.609598 ,train acc: 0.661133 ,val loss : 0.663418 ,val acc : 0.652802\n",
      "[ ecpho : 0  iter :130 ]train loss : 0.590028 ,train acc: 0.663198 ,val loss : 0.659762 ,val acc : 0.647614\n",
      "[ ecpho : 0  iter :131 ]train loss : 0.609896 ,train acc: 0.664246 ,val loss : 0.663372 ,val acc : 0.652191\n",
      "[ ecpho : 0  iter :132 ]train loss : 0.627996 ,train acc: 0.658499 ,val loss : 0.664854 ,val acc : 0.647339\n",
      "[ ecpho : 0  iter :133 ]train loss : 0.642881 ,train acc: 0.660940 ,val loss : 0.660024 ,val acc : 0.653198\n",
      "[ ecpho : 0  iter :134 ]train loss : 0.593582 ,train acc: 0.664246 ,val loss : 0.657709 ,val acc : 0.649139\n",
      "[ ecpho : 0  iter :135 ]train loss : 0.574867 ,train acc: 0.664002 ,val loss : 0.652661 ,val acc : 0.648865\n",
      "[ ecpho : 0  iter :136 ]train loss : 0.607974 ,train acc: 0.661367 ,val loss : 0.666965 ,val acc : 0.648865\n",
      "[ ecpho : 0  iter :137 ]train loss : 0.609509 ,train acc: 0.662679 ,val loss : 0.653574 ,val acc : 0.649414\n",
      "[ ecpho : 0  iter :138 ]train loss : 0.587692 ,train acc: 0.665507 ,val loss : 0.662839 ,val acc : 0.653137\n",
      "[ ecpho : 0  iter :139 ]train loss : 0.589206 ,train acc: 0.663687 ,val loss : 0.672826 ,val acc : 0.646240\n",
      "[ ecpho : 0  iter :140 ]train loss : 0.668608 ,train acc: 0.651296 ,val loss : 0.658854 ,val acc : 0.650970\n",
      "[ ecpho : 0  iter :141 ]train loss : 0.597768 ,train acc: 0.662283 ,val loss : 0.648198 ,val acc : 0.649445\n",
      "[ ecpho : 0  iter :142 ]train loss : 0.584746 ,train acc: 0.665019 ,val loss : 0.656867 ,val acc : 0.650299\n",
      "[ ecpho : 0  iter :143 ]train loss : 0.598674 ,train acc: 0.663137 ,val loss : 0.664406 ,val acc : 0.647827\n",
      "[ ecpho : 0  iter :144 ]train loss : 0.619561 ,train acc: 0.661072 ,val loss : 0.661483 ,val acc : 0.652222\n",
      "[ ecpho : 0  iter :145 ]train loss : 0.567090 ,train acc: 0.667328 ,val loss : 0.666826 ,val acc : 0.648865\n",
      "[ ecpho : 0  iter :146 ]train loss : 0.573474 ,train acc: 0.668834 ,val loss : 0.663126 ,val acc : 0.650543\n",
      "[ ecpho : 0  iter :147 ]train loss : 0.626903 ,train acc: 0.658122 ,val loss : 0.645611 ,val acc : 0.650238\n",
      "[ ecpho : 0  iter :148 ]train loss : 0.607590 ,train acc: 0.660777 ,val loss : 0.648266 ,val acc : 0.651215\n",
      "[ ecpho : 0  iter :149 ]train loss : 0.600585 ,train acc: 0.663086 ,val loss : 0.661838 ,val acc : 0.655151\n",
      "[ ecpho : 0  iter :150 ]train loss : 0.590048 ,train acc: 0.664276 ,val loss : 0.659103 ,val acc : 0.652527\n",
      "[ ecpho : 0  iter :151 ]train loss : 0.587465 ,train acc: 0.664460 ,val loss : 0.653924 ,val acc : 0.650238\n",
      "[ ecpho : 0  iter :152 ]train loss : 0.561742 ,train acc: 0.671469 ,val loss : 0.664382 ,val acc : 0.651886\n",
      "[ ecpho : 0  iter :153 ]train loss : 0.608523 ,train acc: 0.658854 ,val loss : 0.657607 ,val acc : 0.648224\n",
      "[ ecpho : 0  iter :154 ]train loss : 0.563101 ,train acc: 0.667522 ,val loss : 0.656606 ,val acc : 0.653076\n",
      "[ ecpho : 0  iter :155 ]train loss : 0.582163 ,train acc: 0.666301 ,val loss : 0.661473 ,val acc : 0.651062\n",
      "[ ecpho : 0  iter :156 ]train loss : 0.698926 ,train acc: 0.650208 ,val loss : 0.666955 ,val acc : 0.653687\n",
      "[ ecpho : 0  iter :157 ]train loss : 0.573189 ,train acc: 0.668173 ,val loss : 0.657515 ,val acc : 0.651245\n",
      "[ ecpho : 0  iter :158 ]train loss : 0.657561 ,train acc: 0.652720 ,val loss : 0.667479 ,val acc : 0.648315\n",
      "[ ecpho : 0  iter :159 ]train loss : 0.604318 ,train acc: 0.663158 ,val loss : 0.668678 ,val acc : 0.648682\n",
      "[ ecpho : 0  iter :160 ]train loss : 0.591037 ,train acc: 0.666474 ,val loss : 0.656933 ,val acc : 0.653503\n",
      "[ ecpho : 0  iter :161 ]train loss : 0.643139 ,train acc: 0.653138 ,val loss : 0.657426 ,val acc : 0.651611\n",
      "[ ecpho : 0  iter :162 ]train loss : 0.570830 ,train acc: 0.666535 ,val loss : 0.657363 ,val acc : 0.651917\n",
      "[ ecpho : 0  iter :163 ]train loss : 0.563090 ,train acc: 0.670431 ,val loss : 0.639836 ,val acc : 0.656982\n",
      "[ ecpho : 0  iter :164 ]train loss : 0.577908 ,train acc: 0.667389 ,val loss : 0.651677 ,val acc : 0.654907\n",
      "[ ecpho : 0  iter :165 ]train loss : 0.675317 ,train acc: 0.651398 ,val loss : 0.649604 ,val acc : 0.652649\n",
      "[ ecpho : 0  iter :166 ]train loss : 0.604306 ,train acc: 0.661957 ,val loss : 0.652507 ,val acc : 0.651825\n",
      "[ ecpho : 0  iter :167 ]train loss : 0.598595 ,train acc: 0.663585 ,val loss : 0.650562 ,val acc : 0.650940\n",
      "[ ecpho : 0  iter :168 ]train loss : 0.702469 ,train acc: 0.644104 ,val loss : 0.664921 ,val acc : 0.655365\n",
      "[ ecpho : 0  iter :169 ]train loss : 0.595413 ,train acc: 0.665751 ,val loss : 0.653285 ,val acc : 0.653015\n",
      "[ ecpho : 0  iter :170 ]train loss : 0.597025 ,train acc: 0.665864 ,val loss : 0.652536 ,val acc : 0.651215\n",
      "[ ecpho : 0  iter :171 ]train loss : 0.562842 ,train acc: 0.667176 ,val loss : 0.649173 ,val acc : 0.656189\n",
      "[ ecpho : 0  iter :172 ]train loss : 0.621342 ,train acc: 0.663035 ,val loss : 0.642619 ,val acc : 0.657074\n",
      "[ ecpho : 0  iter :173 ]train loss : 0.622886 ,train acc: 0.660523 ,val loss : 0.652911 ,val acc : 0.650970\n",
      "[ ecpho : 0  iter :174 ]train loss : 0.571673 ,train acc: 0.670899 ,val loss : 0.643965 ,val acc : 0.657288\n",
      "[ ecpho : 0  iter :175 ]train loss : 0.584836 ,train acc: 0.664785 ,val loss : 0.667287 ,val acc : 0.649384\n",
      "[ ecpho : 0  iter :176 ]train loss : 0.562215 ,train acc: 0.669963 ,val loss : 0.650470 ,val acc : 0.652069\n",
      "[ ecpho : 0  iter :177 ]train loss : 0.600349 ,train acc: 0.665813 ,val loss : 0.654372 ,val acc : 0.653717\n",
      "[ ecpho : 0  iter :178 ]train loss : 0.593346 ,train acc: 0.665650 ,val loss : 0.644512 ,val acc : 0.652161\n",
      "[ ecpho : 0  iter :179 ]train loss : 0.672633 ,train acc: 0.652914 ,val loss : 0.649469 ,val acc : 0.651062\n",
      "[ ecpho : 0  iter :180 ]train loss : 0.578554 ,train acc: 0.669037 ,val loss : 0.651715 ,val acc : 0.652557\n",
      "[ ecpho : 0  iter :181 ]train loss : 0.556777 ,train acc: 0.671224 ,val loss : 0.643645 ,val acc : 0.654541\n",
      "[ ecpho : 0  iter :182 ]train loss : 0.625467 ,train acc: 0.658682 ,val loss : 0.646401 ,val acc : 0.652313\n",
      "[ ecpho : 0  iter :183 ]train loss : 0.575818 ,train acc: 0.667532 ,val loss : 0.664821 ,val acc : 0.651428\n",
      "[ ecpho : 0  iter :184 ]train loss : 0.655287 ,train acc: 0.656922 ,val loss : 0.645194 ,val acc : 0.653473\n",
      "[ ecpho : 0  iter :185 ]train loss : 0.584882 ,train acc: 0.666616 ,val loss : 0.642526 ,val acc : 0.655945\n",
      "[ ecpho : 0  iter :186 ]train loss : 0.720401 ,train acc: 0.648560 ,val loss : 0.641419 ,val acc : 0.653870\n",
      "[ ecpho : 0  iter :187 ]train loss : 0.672461 ,train acc: 0.650900 ,val loss : 0.632569 ,val acc : 0.653168\n",
      "[ ecpho : 0  iter :188 ]train loss : 0.597148 ,train acc: 0.667511 ,val loss : 0.646730 ,val acc : 0.655670\n",
      "[ ecpho : 0  iter :189 ]train loss : 0.732880 ,train acc: 0.638509 ,val loss : 0.650323 ,val acc : 0.655823\n",
      "[ ecpho : 0  iter :190 ]train loss : 0.589121 ,train acc: 0.667664 ,val loss : 0.652802 ,val acc : 0.652985\n",
      "[ ecpho : 0  iter :191 ]train loss : 0.562894 ,train acc: 0.671367 ,val loss : 0.646103 ,val acc : 0.657959\n",
      "[ ecpho : 0  iter :192 ]train loss : 0.572180 ,train acc: 0.667043 ,val loss : 0.640948 ,val acc : 0.653625\n",
      "[ ecpho : 0  iter :193 ]train loss : 0.575509 ,train acc: 0.666962 ,val loss : 0.637692 ,val acc : 0.654358\n",
      "[ ecpho : 0  iter :194 ]train loss : 0.620521 ,train acc: 0.663778 ,val loss : 0.636769 ,val acc : 0.657196\n",
      "[ ecpho : 0  iter :195 ]train loss : 0.591311 ,train acc: 0.664287 ,val loss : 0.649416 ,val acc : 0.653015\n",
      "[ ecpho : 0  iter :196 ]train loss : 0.653013 ,train acc: 0.653890 ,val loss : 0.638316 ,val acc : 0.657440\n",
      "[ ecpho : 0  iter :197 ]train loss : 0.591229 ,train acc: 0.667328 ,val loss : 0.644944 ,val acc : 0.651703\n",
      "[ ecpho : 0  iter :198 ]train loss : 0.654577 ,train acc: 0.653687 ,val loss : 0.637915 ,val acc : 0.658875\n",
      "[ ecpho : 0  iter :199 ]train loss : 0.669310 ,train acc: 0.652965 ,val loss : 0.646136 ,val acc : 0.654816\n",
      "[ ecpho : 0  iter :200 ]train loss : 0.645288 ,train acc: 0.658041 ,val loss : 0.649841 ,val acc : 0.654755\n",
      "[ ecpho : 0  iter :201 ]train loss : 0.610750 ,train acc: 0.663585 ,val loss : 0.628832 ,val acc : 0.662537\n",
      "[ ecpho : 0  iter :202 ]train loss : 0.570556 ,train acc: 0.666860 ,val loss : 0.630323 ,val acc : 0.657867\n",
      "[ ecpho : 0  iter :203 ]train loss : 0.565639 ,train acc: 0.670675 ,val loss : 0.639372 ,val acc : 0.655365\n",
      "[ ecpho : 0  iter :204 ]train loss : 0.550559 ,train acc: 0.674378 ,val loss : 0.641404 ,val acc : 0.659027\n",
      "[ ecpho : 0  iter :205 ]train loss : 0.551247 ,train acc: 0.673656 ,val loss : 0.643907 ,val acc : 0.657379\n",
      "[ ecpho : 0  iter :206 ]train loss : 0.610990 ,train acc: 0.662537 ,val loss : 0.641285 ,val acc : 0.652649\n",
      "[ ecpho : 0  iter :207 ]train loss : 0.683227 ,train acc: 0.651988 ,val loss : 0.641524 ,val acc : 0.655792\n",
      "[ ecpho : 0  iter :208 ]train loss : 0.581755 ,train acc: 0.667206 ,val loss : 0.646124 ,val acc : 0.655457\n",
      "[ ecpho : 0  iter :209 ]train loss : 0.560687 ,train acc: 0.675395 ,val loss : 0.646691 ,val acc : 0.767578\n",
      "[ ecpho : 0  iter :210 ]train loss : 0.609951 ,train acc: 0.775940 ,val loss : 0.646732 ,val acc : 0.765411\n",
      "[ ecpho : 0  iter :211 ]train loss : 0.548034 ,train acc: 0.793925 ,val loss : 0.647068 ,val acc : 0.767456\n",
      "[ ecpho : 0  iter :212 ]train loss : 0.607012 ,train acc: 0.772370 ,val loss : 0.637164 ,val acc : 0.764618\n",
      "[ ecpho : 0  iter :213 ]train loss : 0.563832 ,train acc: 0.788839 ,val loss : 0.633079 ,val acc : 0.771515\n",
      "[ ecpho : 0  iter :214 ]train loss : 0.827550 ,train acc: 0.642273 ,val loss : 0.633730 ,val acc : 0.770325\n",
      "[ ecpho : 0  iter :215 ]train loss : 0.642794 ,train acc: 0.764374 ,val loss : 0.648290 ,val acc : 0.771240\n",
      "[ ecpho : 0  iter :216 ]train loss : 0.546514 ,train acc: 0.790925 ,val loss : 0.640029 ,val acc : 0.767120\n",
      "[ ecpho : 0  iter :217 ]train loss : 0.660274 ,train acc: 0.756684 ,val loss : 0.650469 ,val acc : 0.768097\n",
      "[ ecpho : 0  iter :218 ]train loss : 0.647624 ,train acc: 0.763937 ,val loss : 0.632093 ,val acc : 0.767731\n",
      "[ ecpho : 0  iter :219 ]train loss : 0.702633 ,train acc: 0.752147 ,val loss : 0.641044 ,val acc : 0.769806\n",
      "[ ecpho : 0  iter :220 ]train loss : 0.591398 ,train acc: 0.780192 ,val loss : 0.647773 ,val acc : 0.766815\n",
      "[ ecpho : 0  iter :221 ]train loss : 0.554231 ,train acc: 0.791748 ,val loss : 0.636556 ,val acc : 0.766907\n",
      "[ ecpho : 0  iter :222 ]train loss : 0.702120 ,train acc: 0.726400 ,val loss : 0.639146 ,val acc : 0.769531\n",
      "[ ecpho : 0  iter :223 ]train loss : 0.558830 ,train acc: 0.788463 ,val loss : 0.632110 ,val acc : 0.771210\n",
      "[ ecpho : 0  iter :224 ]train loss : 0.551141 ,train acc: 0.790477 ,val loss : 0.649719 ,val acc : 0.764465\n",
      "[ ecpho : 0  iter :225 ]train loss : 0.601990 ,train acc: 0.780905 ,val loss : 0.643422 ,val acc : 0.764801\n",
      "[ ecpho : 0  iter :226 ]train loss : 0.597293 ,train acc: 0.780599 ,val loss : 0.630596 ,val acc : 0.773651\n",
      "[ ecpho : 0  iter :227 ]train loss : 0.568516 ,train acc: 0.786398 ,val loss : 0.643040 ,val acc : 0.768799\n",
      "[ ecpho : 0  iter :228 ]train loss : 0.607988 ,train acc: 0.768962 ,val loss : 0.642281 ,val acc : 0.765656\n",
      "[ ecpho : 0  iter :229 ]train loss : 0.606941 ,train acc: 0.772543 ,val loss : 0.635467 ,val acc : 0.767731\n",
      "[ ecpho : 0  iter :230 ]train loss : 0.725109 ,train acc: 0.734009 ,val loss : 0.635408 ,val acc : 0.770996\n",
      "[ ecpho : 0  iter :231 ]train loss : 0.620893 ,train acc: 0.766327 ,val loss : 0.646168 ,val acc : 0.768829\n",
      "[ ecpho : 0  iter :232 ]train loss : 0.564819 ,train acc: 0.789541 ,val loss : 0.634056 ,val acc : 0.770905\n",
      "[ ecpho : 0  iter :233 ]train loss : 0.568589 ,train acc: 0.785747 ,val loss : 0.629138 ,val acc : 0.768890\n",
      "[ ecpho : 0  iter :234 ]train loss : 0.538575 ,train acc: 0.793905 ,val loss : 0.644416 ,val acc : 0.768311\n",
      "[ ecpho : 0  iter :235 ]train loss : 0.539338 ,train acc: 0.798473 ,val loss : 0.626247 ,val acc : 0.772491\n",
      "[ ecpho : 0  iter :236 ]train loss : 0.606400 ,train acc: 0.769206 ,val loss : 0.632744 ,val acc : 0.767426\n",
      "[ ecpho : 0  iter :237 ]train loss : 0.621539 ,train acc: 0.767456 ,val loss : 0.638434 ,val acc : 0.770233\n",
      "[ ecpho : 0  iter :238 ]train loss : 0.549431 ,train acc: 0.793152 ,val loss : 0.629973 ,val acc : 0.771790\n",
      "[ ecpho : 0  iter :239 ]train loss : 0.647658 ,train acc: 0.758759 ,val loss : 0.638698 ,val acc : 0.769806\n",
      "[ ecpho : 0  iter :240 ]train loss : 0.572963 ,train acc: 0.786092 ,val loss : 0.646587 ,val acc : 0.764923\n",
      "[ ecpho : 0  iter :241 ]train loss : 0.586960 ,train acc: 0.783275 ,val loss : 0.635629 ,val acc : 0.766602\n",
      "[ ecpho : 0  iter :242 ]train loss : 0.566793 ,train acc: 0.787384 ,val loss : 0.624796 ,val acc : 0.770538\n",
      "[ ecpho : 0  iter :243 ]train loss : 0.591348 ,train acc: 0.775798 ,val loss : 0.639517 ,val acc : 0.770081\n",
      "[ ecpho : 0  iter :244 ]train loss : 0.703782 ,train acc: 0.744690 ,val loss : 0.651987 ,val acc : 0.767944\n",
      "[ ecpho : 0  iter :245 ]train loss : 0.621239 ,train acc: 0.771739 ,val loss : 0.629563 ,val acc : 0.766510\n",
      "[ ecpho : 0  iter :246 ]train loss : 0.546256 ,train acc: 0.791779 ,val loss : 0.622838 ,val acc : 0.769073\n",
      "[ ecpho : 0  iter :247 ]train loss : 0.691897 ,train acc: 0.742096 ,val loss : 0.647583 ,val acc : 0.767456\n",
      "[ ecpho : 0  iter :248 ]train loss : 0.668236 ,train acc: 0.750051 ,val loss : 0.622134 ,val acc : 0.772064\n",
      "[ ecpho : 0  iter :249 ]train loss : 0.621102 ,train acc: 0.764557 ,val loss : 0.625956 ,val acc : 0.767365\n",
      "[ ecpho : 0  iter :250 ]train loss : 0.544766 ,train acc: 0.791260 ,val loss : 0.641718 ,val acc : 0.766846\n",
      "[ ecpho : 0  iter :251 ]train loss : 0.625079 ,train acc: 0.770396 ,val loss : 0.634462 ,val acc : 0.766296\n",
      "[ ecpho : 0  iter :252 ]train loss : 0.590878 ,train acc: 0.785370 ,val loss : 0.640390 ,val acc : 0.767120\n",
      "[ ecpho : 0  iter :253 ]train loss : 0.590282 ,train acc: 0.780406 ,val loss : 0.624599 ,val acc : 0.773041\n",
      "[ ecpho : 0  iter :254 ]train loss : 0.597609 ,train acc: 0.779541 ,val loss : 0.629953 ,val acc : 0.769226\n",
      "[ ecpho : 0  iter :255 ]train loss : 0.616407 ,train acc: 0.766704 ,val loss : 0.633193 ,val acc : 0.770905\n",
      "[ ecpho : 0  iter :256 ]train loss : 0.557131 ,train acc: 0.789388 ,val loss : 0.641251 ,val acc : 0.768707\n",
      "[ ecpho : 0  iter :257 ]train loss : 0.637801 ,train acc: 0.768006 ,val loss : 0.631993 ,val acc : 0.770966\n",
      "[ ecpho : 0  iter :258 ]train loss : 0.549909 ,train acc: 0.790192 ,val loss : 0.635036 ,val acc : 0.768433\n",
      "[ ecpho : 0  iter :259 ]train loss : 0.553889 ,train acc: 0.786581 ,val loss : 0.640032 ,val acc : 0.765320\n",
      "[ ecpho : 0  iter :260 ]train loss : 0.574489 ,train acc: 0.784211 ,val loss : 0.620317 ,val acc : 0.770599\n",
      "[ ecpho : 0  iter :261 ]train loss : 0.576525 ,train acc: 0.776408 ,val loss : 0.637424 ,val acc : 0.766937\n",
      "[ ecpho : 0  iter :262 ]train loss : 0.561998 ,train acc: 0.785706 ,val loss : 0.633866 ,val acc : 0.768585\n",
      "[ ecpho : 0  iter :263 ]train loss : 0.542130 ,train acc: 0.791789 ,val loss : 0.632527 ,val acc : 0.769318\n",
      "[ ecpho : 0  iter :264 ]train loss : 0.686742 ,train acc: 0.738587 ,val loss : 0.629772 ,val acc : 0.770996\n",
      "[ ecpho : 0  iter :265 ]train loss : 0.545809 ,train acc: 0.792369 ,val loss : 0.633782 ,val acc : 0.767426\n",
      "[ ecpho : 0  iter :266 ]train loss : 0.534842 ,train acc: 0.797587 ,val loss : 0.632773 ,val acc : 0.768524\n",
      "[ ecpho : 0  iter :267 ]train loss : 0.558452 ,train acc: 0.788351 ,val loss : 0.631184 ,val acc : 0.771027\n",
      "[ ecpho : 0  iter :268 ]train loss : 0.577086 ,train acc: 0.784841 ,val loss : 0.634899 ,val acc : 0.769867\n",
      "[ ecpho : 0  iter :269 ]train loss : 0.596065 ,train acc: 0.778056 ,val loss : 0.636428 ,val acc : 0.773071\n",
      "[ ecpho : 0  iter :270 ]train loss : 0.550182 ,train acc: 0.790019 ,val loss : 0.632129 ,val acc : 0.769928\n",
      "[ ecpho : 0  iter :271 ]train loss : 0.558170 ,train acc: 0.790182 ,val loss : 0.626602 ,val acc : 0.769257\n",
      "[ ecpho : 0  iter :272 ]train loss : 0.535160 ,train acc: 0.795929 ,val loss : 0.635926 ,val acc : 0.769073\n",
      "[ ecpho : 0  iter :273 ]train loss : 0.699147 ,train acc: 0.739716 ,val loss : 0.627540 ,val acc : 0.770477\n",
      "[ ecpho : 0  iter :274 ]train loss : 0.637960 ,train acc: 0.758535 ,val loss : 0.622400 ,val acc : 0.771729\n",
      "[ ecpho : 0  iter :275 ]train loss : 0.774446 ,train acc: 0.657990 ,val loss : 0.624567 ,val acc : 0.769623\n",
      "[ ecpho : 0  iter :276 ]train loss : 0.541858 ,train acc: 0.793579 ,val loss : 0.636175 ,val acc : 0.769409\n",
      "[ ecpho : 0  iter :277 ]train loss : 0.562055 ,train acc: 0.784068 ,val loss : 0.631214 ,val acc : 0.768433\n",
      "[ ecpho : 0  iter :278 ]train loss : 0.624598 ,train acc: 0.767436 ,val loss : 0.633440 ,val acc : 0.767181\n",
      "[ ecpho : 0  iter :279 ]train loss : 0.646179 ,train acc: 0.755921 ,val loss : 0.627921 ,val acc : 0.766571\n",
      "[ ecpho : 0  iter :280 ]train loss : 0.536471 ,train acc: 0.793366 ,val loss : 0.627433 ,val acc : 0.768097\n",
      "[ ecpho : 0  iter :281 ]train loss : 0.695071 ,train acc: 0.734630 ,val loss : 0.626499 ,val acc : 0.768982\n",
      "[ ecpho : 0  iter :282 ]train loss : 0.619291 ,train acc: 0.771353 ,val loss : 0.623357 ,val acc : 0.769379\n",
      "[ ecpho : 0  iter :283 ]train loss : 0.594830 ,train acc: 0.773245 ,val loss : 0.630915 ,val acc : 0.766632\n",
      "[ ecpho : 0  iter :284 ]train loss : 0.641665 ,train acc: 0.757518 ,val loss : 0.624916 ,val acc : 0.769226\n",
      "[ ecpho : 0  iter :285 ]train loss : 0.562626 ,train acc: 0.787791 ,val loss : 0.620791 ,val acc : 0.770447\n",
      "[ ecpho : 0  iter :286 ]train loss : 0.540353 ,train acc: 0.793498 ,val loss : 0.621206 ,val acc : 0.772095\n",
      "[ ecpho : 0  iter :287 ]train loss : 0.546384 ,train acc: 0.792450 ,val loss : 0.622978 ,val acc : 0.771027\n",
      "[ ecpho : 0  iter :288 ]train loss : 0.560723 ,train acc: 0.789653 ,val loss : 0.624086 ,val acc : 0.770844\n",
      "[ ecpho : 0  iter :289 ]train loss : 0.575118 ,train acc: 0.781637 ,val loss : 0.616652 ,val acc : 0.773254\n",
      "[ ecpho : 0  iter :290 ]train loss : 0.529743 ,train acc: 0.792837 ,val loss : 0.629957 ,val acc : 0.768585\n",
      "[ ecpho : 0  iter :291 ]train loss : 0.661485 ,train acc: 0.751587 ,val loss : 0.624760 ,val acc : 0.768524\n",
      "[ ecpho : 0  iter :292 ]train loss : 0.565296 ,train acc: 0.786662 ,val loss : 0.616104 ,val acc : 0.775757\n",
      "[ ecpho : 0  iter :293 ]train loss : 0.566888 ,train acc: 0.786215 ,val loss : 0.623328 ,val acc : 0.768158\n",
      "[ ecpho : 0  iter :294 ]train loss : 0.589951 ,train acc: 0.778239 ,val loss : 0.621100 ,val acc : 0.768951\n",
      "[ ecpho : 0  iter :295 ]train loss : 0.564588 ,train acc: 0.786398 ,val loss : 0.628503 ,val acc : 0.767395\n",
      "[ ecpho : 0  iter :296 ]train loss : 0.598638 ,train acc: 0.773580 ,val loss : 0.628798 ,val acc : 0.767517\n",
      "[ ecpho : 0  iter :297 ]train loss : 0.560110 ,train acc: 0.792532 ,val loss : 0.626717 ,val acc : 0.768372\n",
      "[ ecpho : 0  iter :298 ]train loss : 0.536761 ,train acc: 0.793681 ,val loss : 0.620031 ,val acc : 0.769806\n",
      "[ ecpho : 0  iter :299 ]train loss : 0.563022 ,train acc: 0.787130 ,val loss : 0.621551 ,val acc : 0.769592\n",
      "[ ecpho : 0  iter :300 ]train loss : 0.659223 ,train acc: 0.749624 ,val loss : 0.623122 ,val acc : 0.773224\n",
      "[ ecpho : 0  iter :301 ]train loss : 0.543533 ,train acc: 0.794342 ,val loss : 0.610518 ,val acc : 0.774170\n",
      "[ ecpho : 0  iter :302 ]train loss : 0.566439 ,train acc: 0.786306 ,val loss : 0.624936 ,val acc : 0.768402\n",
      "[ ecpho : 0  iter :303 ]train loss : 0.680117 ,train acc: 0.698639 ,val loss : 0.631757 ,val acc : 0.766571\n",
      "[ ecpho : 0  iter :304 ]train loss : 0.523618 ,train acc: 0.800029 ,val loss : 0.622875 ,val acc : 0.773712\n",
      "[ ecpho : 0  iter :305 ]train loss : 0.576361 ,train acc: 0.778799 ,val loss : 0.615728 ,val acc : 0.773193\n",
      "[ ecpho : 0  iter :306 ]train loss : 0.592784 ,train acc: 0.774150 ,val loss : 0.618064 ,val acc : 0.771545\n",
      "[ ecpho : 0  iter :307 ]train loss : 0.573165 ,train acc: 0.783224 ,val loss : 0.613388 ,val acc : 0.775085\n",
      "[ ecpho : 0  iter :308 ]train loss : 0.711142 ,train acc: 0.728028 ,val loss : 0.626728 ,val acc : 0.770142\n",
      "[ ecpho : 0  iter :309 ]train loss : 0.563564 ,train acc: 0.788463 ,val loss : 0.620899 ,val acc : 0.769531\n",
      "[ ecpho : 0  iter :310 ]train loss : 0.550520 ,train acc: 0.788819 ,val loss : 0.625788 ,val acc : 0.769104\n",
      "[ ecpho : 0  iter :311 ]train loss : 0.578854 ,train acc: 0.779826 ,val loss : 0.625049 ,val acc : 0.770691\n",
      "[ ecpho : 0  iter :312 ]train loss : 0.592546 ,train acc: 0.777263 ,val loss : 0.617392 ,val acc : 0.772522\n",
      "[ ecpho : 0  iter :313 ]train loss : 0.526101 ,train acc: 0.792176 ,val loss : 0.613769 ,val acc : 0.771912\n",
      "[ ecpho : 0  iter :314 ]train loss : 0.528373 ,train acc: 0.795319 ,val loss : 0.616888 ,val acc : 0.770813\n",
      "[ ecpho : 0  iter :315 ]train loss : 0.542905 ,train acc: 0.791738 ,val loss : 0.626052 ,val acc : 0.773865\n",
      "[ ecpho : 0  iter :316 ]train loss : 0.534101 ,train acc: 0.792399 ,val loss : 0.619524 ,val acc : 0.775757\n",
      "[ ecpho : 0  iter :317 ]train loss : 0.548766 ,train acc: 0.790558 ,val loss : 0.621479 ,val acc : 0.769409\n",
      "[ ecpho : 0  iter :318 ]train loss : 0.564944 ,train acc: 0.785726 ,val loss : 0.622428 ,val acc : 0.769012\n",
      "[ ecpho : 0  iter :319 ]train loss : 0.615554 ,train acc: 0.771057 ,val loss : 0.611930 ,val acc : 0.772278\n",
      "[ ecpho : 0  iter :320 ]train loss : 0.594495 ,train acc: 0.778666 ,val loss : 0.621358 ,val acc : 0.770233\n",
      "[ ecpho : 0  iter :321 ]train loss : 0.541276 ,train acc: 0.791972 ,val loss : 0.623382 ,val acc : 0.771973\n",
      "[ ecpho : 0  iter :322 ]train loss : 0.595397 ,train acc: 0.778789 ,val loss : 0.610714 ,val acc : 0.773621\n",
      "[ ecpho : 0  iter :323 ]train loss : 0.520657 ,train acc: 0.794882 ,val loss : 0.615587 ,val acc : 0.773468\n",
      "[ ecpho : 0  iter :324 ]train loss : 0.553100 ,train acc: 0.788249 ,val loss : 0.629661 ,val acc : 0.771149\n",
      "[ ecpho : 0  iter :325 ]train loss : 0.599659 ,train acc: 0.774994 ,val loss : 0.620311 ,val acc : 0.772552\n",
      "[ ecpho : 0  iter :326 ]train loss : 0.531287 ,train acc: 0.796214 ,val loss : 0.619968 ,val acc : 0.770569\n",
      "[ ecpho : 0  iter :327 ]train loss : 0.576305 ,train acc: 0.785991 ,val loss : 0.622314 ,val acc : 0.771851\n",
      "[ ecpho : 0  iter :328 ]train loss : 0.573623 ,train acc: 0.785716 ,val loss : 0.621277 ,val acc : 0.772675\n",
      "[ ecpho : 0  iter :329 ]train loss : 0.573119 ,train acc: 0.786388 ,val loss : 0.623534 ,val acc : 0.770111\n",
      "[ ecpho : 0  iter :330 ]train loss : 0.526921 ,train acc: 0.794597 ,val loss : 0.612659 ,val acc : 0.773712\n",
      "[ ecpho : 0  iter :331 ]train loss : 0.583670 ,train acc: 0.773489 ,val loss : 0.618432 ,val acc : 0.769440\n",
      "[ ecpho : 0  iter :332 ]train loss : 0.551132 ,train acc: 0.791077 ,val loss : 0.620094 ,val acc : 0.769928\n",
      "[ ecpho : 0  iter :333 ]train loss : 0.542614 ,train acc: 0.793539 ,val loss : 0.610625 ,val acc : 0.771362\n",
      "[ ecpho : 0  iter :334 ]train loss : 0.574318 ,train acc: 0.784058 ,val loss : 0.619611 ,val acc : 0.766418\n",
      "[ ecpho : 0  iter :335 ]train loss : 0.593270 ,train acc: 0.778921 ,val loss : 0.621778 ,val acc : 0.772980\n",
      "[ ecpho : 0  iter :336 ]train loss : 0.558235 ,train acc: 0.788127 ,val loss : 0.615624 ,val acc : 0.772369\n",
      "[ ecpho : 0  iter :337 ]train loss : 0.581079 ,train acc: 0.780945 ,val loss : 0.611181 ,val acc : 0.773926\n",
      "[ ecpho : 0  iter :338 ]train loss : 0.525245 ,train acc: 0.795736 ,val loss : 0.619065 ,val acc : 0.768890\n",
      "[ ecpho : 0  iter :339 ]train loss : 0.624947 ,train acc: 0.756114 ,val loss : 0.616691 ,val acc : 0.771942\n",
      "[ ecpho : 0  iter :340 ]train loss : 0.525524 ,train acc: 0.796133 ,val loss : 0.616715 ,val acc : 0.769501\n",
      "[ ecpho : 0  iter :341 ]train loss : 0.537056 ,train acc: 0.792420 ,val loss : 0.613307 ,val acc : 0.771393\n",
      "[ ecpho : 0  iter :342 ]train loss : 0.567750 ,train acc: 0.785869 ,val loss : 0.614867 ,val acc : 0.774628\n",
      "[ ecpho : 0  iter :343 ]train loss : 0.534246 ,train acc: 0.791667 ,val loss : 0.617837 ,val acc : 0.773773\n",
      "[ ecpho : 0  iter :344 ]train loss : 0.589683 ,train acc: 0.781535 ,val loss : 0.616404 ,val acc : 0.774872\n",
      "[ ecpho : 0  iter :345 ]train loss : 0.657189 ,train acc: 0.746928 ,val loss : 0.608311 ,val acc : 0.771545\n",
      "[ ecpho : 0  iter :346 ]train loss : 0.560005 ,train acc: 0.786428 ,val loss : 0.612390 ,val acc : 0.772797\n",
      "[ ecpho : 0  iter :347 ]train loss : 0.564458 ,train acc: 0.777436 ,val loss : 0.605783 ,val acc : 0.772278\n",
      "[ ecpho : 0  iter :348 ]train loss : 0.559607 ,train acc: 0.784638 ,val loss : 0.612021 ,val acc : 0.769073\n",
      "[ ecpho : 0  iter :349 ]train loss : 0.563919 ,train acc: 0.783712 ,val loss : 0.613012 ,val acc : 0.770386\n",
      "[ ecpho : 0  iter :350 ]train loss : 0.529508 ,train acc: 0.793396 ,val loss : 0.608618 ,val acc : 0.772308\n",
      "[ ecpho : 0  iter :351 ]train loss : 0.693834 ,train acc: 0.738617 ,val loss : 0.606811 ,val acc : 0.772186\n",
      "[ ecpho : 0  iter :352 ]train loss : 0.543526 ,train acc: 0.791342 ,val loss : 0.612592 ,val acc : 0.773132\n",
      "[ ecpho : 0  iter :353 ]train loss : 0.560183 ,train acc: 0.784190 ,val loss : 0.607742 ,val acc : 0.769562\n",
      "[ ecpho : 0  iter :354 ]train loss : 0.586197 ,train acc: 0.777537 ,val loss : 0.606042 ,val acc : 0.772858\n",
      "[ ecpho : 0  iter :355 ]train loss : 0.542732 ,train acc: 0.790467 ,val loss : 0.601823 ,val acc : 0.772400\n",
      "[ ecpho : 0  iter :356 ]train loss : 0.550460 ,train acc: 0.789154 ,val loss : 0.614358 ,val acc : 0.771271\n",
      "[ ecpho : 0  iter :357 ]train loss : 0.532521 ,train acc: 0.796316 ,val loss : 0.618867 ,val acc : 0.770355\n",
      "[ ecpho : 0  iter :358 ]train loss : 0.564059 ,train acc: 0.785350 ,val loss : 0.623992 ,val acc : 0.767059\n",
      "[ ecpho : 0  iter :359 ]train loss : 0.519821 ,train acc: 0.797618 ,val loss : 0.613044 ,val acc : 0.774231\n",
      "[ ecpho : 0  iter :360 ]train loss : 0.522108 ,train acc: 0.796713 ,val loss : 0.612303 ,val acc : 0.775116\n",
      "[ ecpho : 0  iter :361 ]train loss : 0.544322 ,train acc: 0.788066 ,val loss : 0.614135 ,val acc : 0.772034\n",
      "[ ecpho : 0  iter :362 ]train loss : 0.528883 ,train acc: 0.793844 ,val loss : 0.605814 ,val acc : 0.776001\n",
      "[ ecpho : 0  iter :363 ]train loss : 0.524527 ,train acc: 0.797292 ,val loss : 0.606792 ,val acc : 0.772369\n",
      "[ ecpho : 0  iter :364 ]train loss : 0.557503 ,train acc: 0.787608 ,val loss : 0.615354 ,val acc : 0.772675\n",
      "[ ecpho : 0  iter :365 ]train loss : 0.523629 ,train acc: 0.795970 ,val loss : 0.616372 ,val acc : 0.771210\n",
      "[ ecpho : 0  iter :366 ]train loss : 0.716691 ,train acc: 0.701783 ,val loss : 0.610119 ,val acc : 0.773590\n",
      "[ ecpho : 0  iter :367 ]train loss : 0.534021 ,train acc: 0.793457 ,val loss : 0.615541 ,val acc : 0.774750\n",
      "[ ecpho : 0  iter :368 ]train loss : 0.512645 ,train acc: 0.797323 ,val loss : 0.605918 ,val acc : 0.770325\n",
      "[ ecpho : 0  iter :369 ]train loss : 0.528391 ,train acc: 0.795105 ,val loss : 0.604792 ,val acc : 0.770142\n",
      "[ ecpho : 0  iter :370 ]train loss : 0.537969 ,train acc: 0.790070 ,val loss : 0.618700 ,val acc : 0.775482\n",
      "[ ecpho : 0  iter :371 ]train loss : 0.601342 ,train acc: 0.773316 ,val loss : 0.599411 ,val acc : 0.774475\n",
      "[ ecpho : 0  iter :372 ]train loss : 0.539452 ,train acc: 0.791148 ,val loss : 0.609159 ,val acc : 0.770844\n",
      "[ ecpho : 0  iter :373 ]train loss : 0.548138 ,train acc: 0.788036 ,val loss : 0.608861 ,val acc : 0.773132\n",
      "[ ecpho : 0  iter :374 ]train loss : 0.543930 ,train acc: 0.790904 ,val loss : 0.611143 ,val acc : 0.771332\n",
      "[ ecpho : 0  iter :375 ]train loss : 0.552666 ,train acc: 0.786428 ,val loss : 0.600729 ,val acc : 0.769806\n",
      "[ ecpho : 0  iter :376 ]train loss : 0.513738 ,train acc: 0.798808 ,val loss : 0.598585 ,val acc : 0.773956\n",
      "[ ecpho : 0  iter :377 ]train loss : 0.572972 ,train acc: 0.779735 ,val loss : 0.605574 ,val acc : 0.772400\n",
      "[ ecpho : 0  iter :378 ]train loss : 0.576657 ,train acc: 0.777975 ,val loss : 0.601984 ,val acc : 0.774750\n",
      "[ ecpho : 0  iter :379 ]train loss : 0.714206 ,train acc: 0.722891 ,val loss : 0.611134 ,val acc : 0.771301\n",
      "[ ecpho : 0  iter :380 ]train loss : 0.514503 ,train acc: 0.796987 ,val loss : 0.612351 ,val acc : 0.773315\n",
      "[ ecpho : 0  iter :381 ]train loss : 0.593499 ,train acc: 0.769196 ,val loss : 0.606725 ,val acc : 0.770721\n",
      "[ ecpho : 0  iter :382 ]train loss : 0.531702 ,train acc: 0.792756 ,val loss : 0.606986 ,val acc : 0.770477\n",
      "[ ecpho : 0  iter :383 ]train loss : 0.547548 ,train acc: 0.790619 ,val loss : 0.602543 ,val acc : 0.776581\n",
      "[ ecpho : 0  iter :384 ]train loss : 0.552310 ,train acc: 0.789989 ,val loss : 0.606774 ,val acc : 0.773621\n",
      "[ ecpho : 0  iter :385 ]train loss : 0.576691 ,train acc: 0.783834 ,val loss : 0.602037 ,val acc : 0.770569\n",
      "[ ecpho : 0  iter :386 ]train loss : 0.541987 ,train acc: 0.788432 ,val loss : 0.610828 ,val acc : 0.770294\n",
      "[ ecpho : 0  iter :387 ]train loss : 0.521462 ,train acc: 0.795126 ,val loss : 0.594209 ,val acc : 0.773102\n",
      "[ ecpho : 0  iter :388 ]train loss : 0.572756 ,train acc: 0.764771 ,val loss : 0.615577 ,val acc : 0.771973\n",
      "[ ecpho : 0  iter :389 ]train loss : 0.536193 ,train acc: 0.793803 ,val loss : 0.599782 ,val acc : 0.771637\n",
      "[ ecpho : 0  iter :390 ]train loss : 0.628091 ,train acc: 0.757904 ,val loss : 0.600703 ,val acc : 0.775238\n",
      "[ ecpho : 0  iter :391 ]train loss : 0.624043 ,train acc: 0.761841 ,val loss : 0.604919 ,val acc : 0.774475\n",
      "[ ecpho : 0  iter :392 ]train loss : 0.498003 ,train acc: 0.804983 ,val loss : 0.602525 ,val acc : 0.776276\n",
      "[ ecpho : 0  iter :393 ]train loss : 0.518565 ,train acc: 0.794180 ,val loss : 0.605207 ,val acc : 0.772003\n",
      "[ ecpho : 0  iter :394 ]train loss : 0.511397 ,train acc: 0.798096 ,val loss : 0.608017 ,val acc : 0.772552\n",
      "[ ecpho : 0  iter :395 ]train loss : 0.540286 ,train acc: 0.791291 ,val loss : 0.602038 ,val acc : 0.772095\n",
      "[ ecpho : 0  iter :396 ]train loss : 0.575485 ,train acc: 0.780508 ,val loss : 0.598400 ,val acc : 0.768677\n",
      "[ ecpho : 0  iter :397 ]train loss : 0.506095 ,train acc: 0.798340 ,val loss : 0.599555 ,val acc : 0.774200\n",
      "[ ecpho : 0  iter :398 ]train loss : 0.521674 ,train acc: 0.795940 ,val loss : 0.606933 ,val acc : 0.772919\n",
      "[ ecpho : 0  iter :399 ]train loss : 0.544026 ,train acc: 0.788910 ,val loss : 0.598342 ,val acc : 0.773529\n",
      "[ ecpho : 0  iter :400 ]train loss : 0.525735 ,train acc: 0.793895 ,val loss : 0.612988 ,val acc : 0.773376\n",
      "[ ecpho : 0  iter :401 ]train loss : 0.623183 ,train acc: 0.762452 ,val loss : 0.604311 ,val acc : 0.776367\n",
      "[ ecpho : 0  iter :402 ]train loss : 0.516589 ,train acc: 0.796265 ,val loss : 0.603819 ,val acc : 0.771301\n",
      "[ ecpho : 0  iter :403 ]train loss : 0.527670 ,train acc: 0.794871 ,val loss : 0.603922 ,val acc : 0.774689\n",
      "[ ecpho : 0  iter :404 ]train loss : 0.517811 ,train acc: 0.796407 ,val loss : 0.606113 ,val acc : 0.774567\n",
      "[ ecpho : 0  iter :405 ]train loss : 0.527167 ,train acc: 0.794098 ,val loss : 0.601218 ,val acc : 0.769897\n",
      "[ ecpho : 0  iter :406 ]train loss : 0.580541 ,train acc: 0.779470 ,val loss : 0.596424 ,val acc : 0.770966\n",
      "[ ecpho : 0  iter :407 ]train loss : 0.527176 ,train acc: 0.792257 ,val loss : 0.611998 ,val acc : 0.771576\n",
      "[ ecpho : 0  iter :408 ]train loss : 0.570101 ,train acc: 0.768911 ,val loss : 0.597880 ,val acc : 0.775696\n",
      "[ ecpho : 0  iter :409 ]train loss : 0.595924 ,train acc: 0.773784 ,val loss : 0.597340 ,val acc : 0.771881\n",
      "[ ecpho : 0  iter :410 ]train loss : 0.551592 ,train acc: 0.785391 ,val loss : 0.600879 ,val acc : 0.775391\n",
      "[ ecpho : 0  iter :411 ]train loss : 0.550781 ,train acc: 0.786306 ,val loss : 0.604887 ,val acc : 0.772064\n",
      "[ ecpho : 0  iter :412 ]train loss : 0.551843 ,train acc: 0.784933 ,val loss : 0.598206 ,val acc : 0.773743\n",
      "[ ecpho : 0  iter :413 ]train loss : 0.538482 ,train acc: 0.789185 ,val loss : 0.602815 ,val acc : 0.774933\n",
      "[ ecpho : 0  iter :414 ]train loss : 0.524446 ,train acc: 0.793935 ,val loss : 0.597749 ,val acc : 0.770966\n",
      "[ ecpho : 0  iter :415 ]train loss : 0.673195 ,train acc: 0.750967 ,val loss : 0.593559 ,val acc : 0.773895\n",
      "[ ecpho : 0  iter :416 ]train loss : 0.516256 ,train acc: 0.794780 ,val loss : 0.596668 ,val acc : 0.774139\n",
      "[ ecpho : 0  iter :417 ]train loss : 0.580146 ,train acc: 0.769816 ,val loss : 0.600424 ,val acc : 0.775116\n",
      "[ ecpho : 0  iter :418 ]train loss : 0.508197 ,train acc: 0.797710 ,val loss : 0.600857 ,val acc : 0.773254\n",
      "[ ecpho : 0  iter :419 ]train loss : 0.530018 ,train acc: 0.792532 ,val loss : 0.600224 ,val acc : 0.775269\n",
      "[ ecpho : 0  iter :420 ]train loss : 0.537109 ,train acc: 0.793254 ,val loss : 0.588818 ,val acc : 0.774353\n",
      "[ ecpho : 0  iter :421 ]train loss : 0.515927 ,train acc: 0.797313 ,val loss : 0.604536 ,val acc : 0.772980\n",
      "[ ecpho : 0  iter :422 ]train loss : 0.533683 ,train acc: 0.793356 ,val loss : 0.596073 ,val acc : 0.773376\n",
      "[ ecpho : 0  iter :423 ]train loss : 0.517665 ,train acc: 0.793305 ,val loss : 0.601689 ,val acc : 0.774231\n",
      "[ ecpho : 0  iter :424 ]train loss : 0.586774 ,train acc: 0.771098 ,val loss : 0.597206 ,val acc : 0.774811\n",
      "[ ecpho : 0  iter :425 ]train loss : 0.601529 ,train acc: 0.767202 ,val loss : 0.597281 ,val acc : 0.774445\n",
      "[ ecpho : 0  iter :426 ]train loss : 0.585296 ,train acc: 0.772187 ,val loss : 0.604044 ,val acc : 0.772583\n",
      "[ ecpho : 0  iter :427 ]train loss : 0.524069 ,train acc: 0.793193 ,val loss : 0.599341 ,val acc : 0.775085\n",
      "[ ecpho : 0  iter :428 ]train loss : 0.496606 ,train acc: 0.799408 ,val loss : 0.596496 ,val acc : 0.775055\n",
      "[ ecpho : 0  iter :429 ]train loss : 0.526949 ,train acc: 0.792959 ,val loss : 0.600830 ,val acc : 0.777679\n",
      "[ ecpho : 0  iter :430 ]train loss : 0.504835 ,train acc: 0.798147 ,val loss : 0.599381 ,val acc : 0.774811\n",
      "[ ecpho : 0  iter :431 ]train loss : 0.570342 ,train acc: 0.766815 ,val loss : 0.597582 ,val acc : 0.774139\n",
      "[ ecpho : 0  iter :432 ]train loss : 0.601514 ,train acc: 0.767324 ,val loss : 0.592327 ,val acc : 0.778320\n",
      "[ ecpho : 0  iter :433 ]train loss : 0.579773 ,train acc: 0.765391 ,val loss : 0.598530 ,val acc : 0.775208\n",
      "[ ecpho : 0  iter :434 ]train loss : 0.513546 ,train acc: 0.797028 ,val loss : 0.593484 ,val acc : 0.774353\n",
      "[ ecpho : 0  iter :435 ]train loss : 0.501130 ,train acc: 0.800832 ,val loss : 0.598560 ,val acc : 0.773132\n",
      "[ ecpho : 0  iter :436 ]train loss : 0.542765 ,train acc: 0.788676 ,val loss : 0.596475 ,val acc : 0.775726\n",
      "[ ecpho : 0  iter :437 ]train loss : 0.522381 ,train acc: 0.794536 ,val loss : 0.586274 ,val acc : 0.776184\n",
      "[ ecpho : 0  iter :438 ]train loss : 0.568345 ,train acc: 0.774598 ,val loss : 0.602017 ,val acc : 0.772583\n",
      "[ ecpho : 0  iter :439 ]train loss : 0.533758 ,train acc: 0.794088 ,val loss : 0.587806 ,val acc : 0.775604\n",
      "[ ecpho : 0  iter :440 ]train loss : 0.604567 ,train acc: 0.762564 ,val loss : 0.599690 ,val acc : 0.778900\n",
      "[ ecpho : 0  iter :441 ]train loss : 0.518373 ,train acc: 0.793864 ,val loss : 0.588446 ,val acc : 0.777283\n",
      "[ ecpho : 0  iter :442 ]train loss : 0.531557 ,train acc: 0.792115 ,val loss : 0.599435 ,val acc : 0.775024\n",
      "[ ecpho : 0  iter :443 ]train loss : 0.565565 ,train acc: 0.780284 ,val loss : 0.595951 ,val acc : 0.775604\n",
      "[ ecpho : 0  iter :444 ]train loss : 0.560355 ,train acc: 0.780060 ,val loss : 0.592034 ,val acc : 0.777252\n",
      "[ ecpho : 0  iter :445 ]train loss : 0.516380 ,train acc: 0.793040 ,val loss : 0.603575 ,val acc : 0.774445\n",
      "[ ecpho : 0  iter :446 ]train loss : 0.571821 ,train acc: 0.777293 ,val loss : 0.593124 ,val acc : 0.778961\n",
      "[ ecpho : 0  iter :447 ]train loss : 0.648135 ,train acc: 0.741801 ,val loss : 0.591166 ,val acc : 0.774506\n",
      "[ ecpho : 0  iter :448 ]train loss : 0.521312 ,train acc: 0.794353 ,val loss : 0.593654 ,val acc : 0.772064\n",
      "[ ecpho : 0  iter :449 ]train loss : 0.503068 ,train acc: 0.800242 ,val loss : 0.597093 ,val acc : 0.771515\n",
      "[ ecpho : 0  iter :450 ]train loss : 0.514552 ,train acc: 0.797943 ,val loss : 0.586577 ,val acc : 0.774323\n",
      "[ ecpho : 0  iter :451 ]train loss : 0.565167 ,train acc: 0.773529 ,val loss : 0.593952 ,val acc : 0.776398\n",
      "[ ecpho : 0  iter :452 ]train loss : 0.531071 ,train acc: 0.787374 ,val loss : 0.596772 ,val acc : 0.774780\n",
      "[ ecpho : 0  iter :453 ]train loss : 0.564583 ,train acc: 0.781657 ,val loss : 0.599285 ,val acc : 0.775146\n",
      "[ ecpho : 0  iter :454 ]train loss : 0.526610 ,train acc: 0.791708 ,val loss : 0.592147 ,val acc : 0.771729\n",
      "[ ecpho : 0  iter :455 ]train loss : 0.516583 ,train acc: 0.794119 ,val loss : 0.572973 ,val acc : 0.776123\n",
      "[ ecpho : 0  iter :456 ]train loss : 0.510834 ,train acc: 0.792817 ,val loss : 0.583780 ,val acc : 0.776550\n",
      "[ ecpho : 0  iter :457 ]train loss : 0.504531 ,train acc: 0.800497 ,val loss : 0.597720 ,val acc : 0.775330\n",
      "[ ecpho : 0  iter :458 ]train loss : 0.609296 ,train acc: 0.758678 ,val loss : 0.598182 ,val acc : 0.777374\n",
      "[ ecpho : 0  iter :459 ]train loss : 0.515145 ,train acc: 0.795085 ,val loss : 0.584252 ,val acc : 0.776733\n",
      "[ ecpho : 0  iter :460 ]train loss : 0.568378 ,train acc: 0.777893 ,val loss : 0.595234 ,val acc : 0.774109\n",
      "[ ecpho : 0  iter :461 ]train loss : 0.529960 ,train acc: 0.791392 ,val loss : 0.590738 ,val acc : 0.774261\n",
      "[ ecpho : 0  iter :462 ]train loss : 0.559044 ,train acc: 0.786184 ,val loss : 0.579641 ,val acc : 0.777954\n",
      "[ ecpho : 0  iter :463 ]train loss : 0.511751 ,train acc: 0.794861 ,val loss : 0.589492 ,val acc : 0.776550\n",
      "[ ecpho : 0  iter :464 ]train loss : 0.572395 ,train acc: 0.758810 ,val loss : 0.595282 ,val acc : 0.774658\n",
      "[ ecpho : 0  iter :465 ]train loss : 0.533704 ,train acc: 0.789368 ,val loss : 0.592375 ,val acc : 0.773773\n",
      "[ ecpho : 0  iter :466 ]train loss : 0.537094 ,train acc: 0.790640 ,val loss : 0.592704 ,val acc : 0.777466\n",
      "[ ecpho : 0  iter :467 ]train loss : 0.492632 ,train acc: 0.803579 ,val loss : 0.591348 ,val acc : 0.775604\n",
      "[ ecpho : 0  iter :468 ]train loss : 0.523347 ,train acc: 0.792491 ,val loss : 0.590896 ,val acc : 0.775024\n",
      "[ ecpho : 0  iter :469 ]train loss : 0.561331 ,train acc: 0.778656 ,val loss : 0.583680 ,val acc : 0.776428\n",
      "[ ecpho : 0  iter :470 ]train loss : 0.548699 ,train acc: 0.781739 ,val loss : 0.582775 ,val acc : 0.775574\n",
      "[ ecpho : 0  iter :471 ]train loss : 0.500648 ,train acc: 0.798289 ,val loss : 0.598778 ,val acc : 0.773224\n",
      "[ ecpho : 0  iter :472 ]train loss : 0.551408 ,train acc: 0.782939 ,val loss : 0.585811 ,val acc : 0.777466\n",
      "[ ecpho : 0  iter :473 ]train loss : 0.546233 ,train acc: 0.782380 ,val loss : 0.582494 ,val acc : 0.776123\n",
      "[ ecpho : 0  iter :474 ]train loss : 0.478983 ,train acc: 0.806468 ,val loss : 0.589906 ,val acc : 0.773163\n",
      "[ ecpho : 0  iter :475 ]train loss : 0.507169 ,train acc: 0.798544 ,val loss : 0.587324 ,val acc : 0.776123\n",
      "[ ecpho : 0  iter :476 ]train loss : 0.481655 ,train acc: 0.804159 ,val loss : 0.584269 ,val acc : 0.776703\n",
      "[ ecpho : 0  iter :477 ]train loss : 0.486329 ,train acc: 0.803365 ,val loss : 0.579874 ,val acc : 0.778412\n",
      "[ ecpho : 0  iter :478 ]train loss : 0.494101 ,train acc: 0.800171 ,val loss : 0.590342 ,val acc : 0.778625\n",
      "[ ecpho : 0  iter :479 ]train loss : 0.485310 ,train acc: 0.803681 ,val loss : 0.581267 ,val acc : 0.776550\n",
      "[ ecpho : 0  iter :480 ]train loss : 0.567746 ,train acc: 0.773997 ,val loss : 0.586668 ,val acc : 0.773773\n",
      "[ ecpho : 0  iter :481 ]train loss : 0.553178 ,train acc: 0.768067 ,val loss : 0.578043 ,val acc : 0.777832\n",
      "[ ecpho : 0  iter :482 ]train loss : 0.533772 ,train acc: 0.791931 ,val loss : 0.587941 ,val acc : 0.779938\n",
      "[ ecpho : 0  iter :483 ]train loss : 0.559017 ,train acc: 0.768270 ,val loss : 0.586735 ,val acc : 0.776703\n",
      "[ ecpho : 0  iter :484 ]train loss : 0.496456 ,train acc: 0.799724 ,val loss : 0.587316 ,val acc : 0.774353\n",
      "[ ecpho : 0  iter :485 ]train loss : 0.499810 ,train acc: 0.801402 ,val loss : 0.585919 ,val acc : 0.774231\n",
      "[ ecpho : 0  iter :486 ]train loss : 0.568191 ,train acc: 0.764059 ,val loss : 0.575252 ,val acc : 0.780914\n",
      "[ ecpho : 0  iter :487 ]train loss : 0.538924 ,train acc: 0.792288 ,val loss : 0.584764 ,val acc : 0.776062\n",
      "[ ecpho : 0  iter :488 ]train loss : 0.490167 ,train acc: 0.805186 ,val loss : 0.583599 ,val acc : 0.775879\n",
      "[ ecpho : 0  iter :489 ]train loss : 0.503840 ,train acc: 0.803996 ,val loss : 0.569341 ,val acc : 0.777191\n",
      "[ ecpho : 0  iter :490 ]train loss : 0.580058 ,train acc: 0.775096 ,val loss : 0.592383 ,val acc : 0.772247\n",
      "[ ecpho : 0  iter :491 ]train loss : 0.502583 ,train acc: 0.799775 ,val loss : 0.586438 ,val acc : 0.777374\n",
      "[ ecpho : 0  iter :492 ]train loss : 0.506919 ,train acc: 0.799001 ,val loss : 0.579393 ,val acc : 0.777374\n",
      "[ ecpho : 0  iter :493 ]train loss : 0.527150 ,train acc: 0.792766 ,val loss : 0.578017 ,val acc : 0.775909\n",
      "[ ecpho : 0  iter :494 ]train loss : 0.518728 ,train acc: 0.794597 ,val loss : 0.586779 ,val acc : 0.776459\n",
      "[ ecpho : 0  iter :495 ]train loss : 0.498299 ,train acc: 0.804098 ,val loss : 0.583392 ,val acc : 0.772308\n",
      "[ ecpho : 0  iter :496 ]train loss : 0.510859 ,train acc: 0.796936 ,val loss : 0.581129 ,val acc : 0.777863\n",
      "[ ecpho : 0  iter :497 ]train loss : 0.493097 ,train acc: 0.801412 ,val loss : 0.571781 ,val acc : 0.778015\n",
      "[ ecpho : 0  iter :498 ]train loss : 0.502884 ,train acc: 0.798564 ,val loss : 0.588426 ,val acc : 0.775024\n",
      "[ ecpho : 0  iter :499 ]train loss : 0.536786 ,train acc: 0.787272 ,val loss : 0.582833 ,val acc : 0.777679\n",
      "[ ecpho : 0  iter :500 ]train loss : 0.483739 ,train acc: 0.806865 ,val loss : 0.589275 ,val acc : 0.776245\n",
      "[ ecpho : 0  iter :501 ]train loss : 0.545693 ,train acc: 0.774028 ,val loss : 0.578842 ,val acc : 0.779785\n",
      "[ ecpho : 0  iter :502 ]train loss : 0.527701 ,train acc: 0.789500 ,val loss : 0.581762 ,val acc : 0.777222\n",
      "[ ecpho : 0  iter :503 ]train loss : 0.491486 ,train acc: 0.800761 ,val loss : 0.574536 ,val acc : 0.779785\n",
      "[ ecpho : 0  iter :504 ]train loss : 0.527939 ,train acc: 0.793630 ,val loss : 0.578629 ,val acc : 0.778198\n",
      "[ ecpho : 0  iter :505 ]train loss : 0.491803 ,train acc: 0.803406 ,val loss : 0.573004 ,val acc : 0.775940\n",
      "[ ecpho : 0  iter :506 ]train loss : 0.493873 ,train acc: 0.800507 ,val loss : 0.579916 ,val acc : 0.774292\n",
      "[ ecpho : 0  iter :507 ]train loss : 0.527472 ,train acc: 0.792878 ,val loss : 0.581516 ,val acc : 0.774780\n",
      "[ ecpho : 0  iter :508 ]train loss : 0.503039 ,train acc: 0.800120 ,val loss : 0.579423 ,val acc : 0.781006\n",
      "[ ecpho : 0  iter :509 ]train loss : 0.543043 ,train acc: 0.788768 ,val loss : 0.578961 ,val acc : 0.776154\n",
      "[ ecpho : 0  iter :510 ]train loss : 0.573846 ,train acc: 0.774811 ,val loss : 0.581599 ,val acc : 0.777740\n",
      "[ ecpho : 0  iter :511 ]train loss : 0.541924 ,train acc: 0.767823 ,val loss : 0.574484 ,val acc : 0.778107\n",
      "[ ecpho : 0  iter :512 ]train loss : 0.560316 ,train acc: 0.771983 ,val loss : 0.579061 ,val acc : 0.780365\n",
      "[ ecpho : 0  iter :513 ]train loss : 0.536545 ,train acc: 0.777904 ,val loss : 0.571209 ,val acc : 0.779846\n",
      "[ ecpho : 0  iter :514 ]train loss : 0.506344 ,train acc: 0.799927 ,val loss : 0.576010 ,val acc : 0.776001\n",
      "[ ecpho : 0  iter :515 ]train loss : 0.493637 ,train acc: 0.802552 ,val loss : 0.578493 ,val acc : 0.774292\n",
      "[ ecpho : 0  iter :516 ]train loss : 0.515884 ,train acc: 0.795065 ,val loss : 0.583059 ,val acc : 0.780457\n",
      "[ ecpho : 0  iter :517 ]train loss : 0.604509 ,train acc: 0.759105 ,val loss : 0.579326 ,val acc : 0.775421\n",
      "[ ecpho : 0  iter :518 ]train loss : 0.510194 ,train acc: 0.794942 ,val loss : 0.581591 ,val acc : 0.779907\n",
      "[ ecpho : 0  iter :519 ]train loss : 0.532777 ,train acc: 0.787903 ,val loss : 0.571782 ,val acc : 0.777863\n",
      "[ ecpho : 0  iter :520 ]train loss : 0.481597 ,train acc: 0.801748 ,val loss : 0.581516 ,val acc : 0.778809\n",
      "[ ecpho : 0  iter :521 ]train loss : 0.491154 ,train acc: 0.801829 ,val loss : 0.574310 ,val acc : 0.779541\n",
      "[ ecpho : 0  iter :522 ]train loss : 0.496189 ,train acc: 0.800354 ,val loss : 0.581650 ,val acc : 0.776886\n",
      "[ ecpho : 0  iter :523 ]train loss : 0.562099 ,train acc: 0.768169 ,val loss : 0.572360 ,val acc : 0.782379\n",
      "[ ecpho : 0  iter :524 ]train loss : 0.489292 ,train acc: 0.804169 ,val loss : 0.577866 ,val acc : 0.776947\n",
      "[ ecpho : 0  iter :525 ]train loss : 0.524814 ,train acc: 0.786764 ,val loss : 0.574675 ,val acc : 0.778656\n",
      "[ ecpho : 0  iter :526 ]train loss : 0.555573 ,train acc: 0.714824 ,val loss : 0.571899 ,val acc : 0.777832\n",
      "[ ecpho : 0  iter :527 ]train loss : 0.473282 ,train acc: 0.808625 ,val loss : 0.573479 ,val acc : 0.779266\n",
      "[ ecpho : 0  iter :528 ]train loss : 0.540426 ,train acc: 0.778850 ,val loss : 0.576598 ,val acc : 0.778534\n",
      "[ ecpho : 0  iter :529 ]train loss : 0.539896 ,train acc: 0.785330 ,val loss : 0.559656 ,val acc : 0.782288\n",
      "[ ecpho : 0  iter :530 ]train loss : 0.480481 ,train acc: 0.807302 ,val loss : 0.572945 ,val acc : 0.778778\n",
      "[ ecpho : 0  iter :531 ]train loss : 0.495858 ,train acc: 0.798625 ,val loss : 0.580476 ,val acc : 0.778503\n",
      "[ ecpho : 0  iter :532 ]train loss : 0.534829 ,train acc: 0.783875 ,val loss : 0.573634 ,val acc : 0.773956\n",
      "[ ecpho : 0  iter :533 ]train loss : 0.526935 ,train acc: 0.790284 ,val loss : 0.579379 ,val acc : 0.778717\n",
      "[ ecpho : 0  iter :534 ]train loss : 0.521500 ,train acc: 0.790101 ,val loss : 0.567183 ,val acc : 0.780609\n",
      "[ ecpho : 0  iter :535 ]train loss : 0.490778 ,train acc: 0.802684 ,val loss : 0.562085 ,val acc : 0.781525\n",
      "[ ecpho : 0  iter :536 ]train loss : 0.484655 ,train acc: 0.805776 ,val loss : 0.573504 ,val acc : 0.777039\n",
      "[ ecpho : 0  iter :537 ]train loss : 0.495807 ,train acc: 0.797577 ,val loss : 0.569032 ,val acc : 0.780060\n",
      "[ ecpho : 0  iter :538 ]train loss : 0.497482 ,train acc: 0.800476 ,val loss : 0.575639 ,val acc : 0.778259\n",
      "[ ecpho : 0  iter :539 ]train loss : 0.567868 ,train acc: 0.765188 ,val loss : 0.567293 ,val acc : 0.778748\n",
      "[ ecpho : 0  iter :540 ]train loss : 0.511812 ,train acc: 0.795665 ,val loss : 0.570402 ,val acc : 0.780731\n",
      "[ ecpho : 0  iter :541 ]train loss : 0.481766 ,train acc: 0.802389 ,val loss : 0.578143 ,val acc : 0.778961\n",
      "[ ecpho : 0  iter :542 ]train loss : 0.493231 ,train acc: 0.797760 ,val loss : 0.565777 ,val acc : 0.777802\n",
      "[ ecpho : 0  iter :543 ]train loss : 0.503956 ,train acc: 0.802043 ,val loss : 0.568116 ,val acc : 0.782288\n",
      "[ ecpho : 0  iter :544 ]train loss : 0.572124 ,train acc: 0.768230 ,val loss : 0.571728 ,val acc : 0.782562\n",
      "[ ecpho : 0  iter :545 ]train loss : 0.475962 ,train acc: 0.803406 ,val loss : 0.566794 ,val acc : 0.780823\n",
      "[ ecpho : 0  iter :546 ]train loss : 0.489399 ,train acc: 0.804495 ,val loss : 0.562639 ,val acc : 0.780365\n",
      "[ ecpho : 0  iter :547 ]train loss : 0.561505 ,train acc: 0.783539 ,val loss : 0.572823 ,val acc : 0.781769\n",
      "[ ecpho : 0  iter :548 ]train loss : 0.480747 ,train acc: 0.808635 ,val loss : 0.571035 ,val acc : 0.780304\n",
      "[ ecpho : 0  iter :549 ]train loss : 0.470702 ,train acc: 0.807211 ,val loss : 0.565293 ,val acc : 0.781433\n",
      "[ ecpho : 0  iter :550 ]train loss : 0.548860 ,train acc: 0.784679 ,val loss : 0.565355 ,val acc : 0.782074\n",
      "[ ecpho : 0  iter :551 ]train loss : 0.476837 ,train acc: 0.809794 ,val loss : 0.574076 ,val acc : 0.781281\n",
      "[ ecpho : 0  iter :552 ]train loss : 0.525670 ,train acc: 0.791392 ,val loss : 0.559355 ,val acc : 0.781982\n",
      "[ ecpho : 0  iter :553 ]train loss : 0.514522 ,train acc: 0.795604 ,val loss : 0.562595 ,val acc : 0.781525\n",
      "[ ecpho : 0  iter :554 ]train loss : 0.454916 ,train acc: 0.813284 ,val loss : 0.567803 ,val acc : 0.782898\n",
      "[ ecpho : 0  iter :555 ]train loss : 0.582316 ,train acc: 0.754487 ,val loss : 0.567845 ,val acc : 0.782013\n",
      "[ ecpho : 0  iter :556 ]train loss : 0.493422 ,train acc: 0.800934 ,val loss : 0.558384 ,val acc : 0.780579\n",
      "[ ecpho : 0  iter :557 ]train loss : 0.474189 ,train acc: 0.803488 ,val loss : 0.564215 ,val acc : 0.778198\n",
      "[ ecpho : 0  iter :558 ]train loss : 0.608853 ,train acc: 0.756908 ,val loss : 0.566430 ,val acc : 0.779633\n",
      "[ ecpho : 0  iter :559 ]train loss : 0.486573 ,train acc: 0.807221 ,val loss : 0.572038 ,val acc : 0.776245\n",
      "[ ecpho : 0  iter :560 ]train loss : 0.502368 ,train acc: 0.795166 ,val loss : 0.565408 ,val acc : 0.780212\n",
      "[ ecpho : 0  iter :561 ]train loss : 0.549816 ,train acc: 0.760987 ,val loss : 0.558176 ,val acc : 0.779419\n",
      "[ ecpho : 0  iter :562 ]train loss : 0.475137 ,train acc: 0.803660 ,val loss : 0.576477 ,val acc : 0.779816\n",
      "[ ecpho : 0  iter :563 ]train loss : 0.485932 ,train acc: 0.803579 ,val loss : 0.574060 ,val acc : 0.777771\n",
      "[ ecpho : 0  iter :564 ]train loss : 0.512727 ,train acc: 0.795685 ,val loss : 0.563899 ,val acc : 0.782074\n",
      "[ ecpho : 0  iter :565 ]train loss : 0.486630 ,train acc: 0.800955 ,val loss : 0.566622 ,val acc : 0.782166\n",
      "[ ecpho : 0  iter :566 ]train loss : 0.572853 ,train acc: 0.773987 ,val loss : 0.562364 ,val acc : 0.780548\n",
      "[ ecpho : 0  iter :567 ]train loss : 0.484937 ,train acc: 0.804718 ,val loss : 0.565674 ,val acc : 0.780029\n",
      "[ ecpho : 0  iter :568 ]train loss : 0.494700 ,train acc: 0.793183 ,val loss : 0.558569 ,val acc : 0.785156\n",
      "[ ecpho : 0  iter :569 ]train loss : 0.460770 ,train acc: 0.813365 ,val loss : 0.551997 ,val acc : 0.781586\n",
      "[ ecpho : 0  iter :570 ]train loss : 0.504797 ,train acc: 0.795848 ,val loss : 0.562858 ,val acc : 0.780975\n",
      "[ ecpho : 0  iter :571 ]train loss : 0.505580 ,train acc: 0.796407 ,val loss : 0.576105 ,val acc : 0.778778\n",
      "[ ecpho : 0  iter :572 ]train loss : 0.457979 ,train acc: 0.811524 ,val loss : 0.566458 ,val acc : 0.777344\n",
      "[ ecpho : 0  iter :573 ]train loss : 0.549588 ,train acc: 0.766612 ,val loss : 0.556019 ,val acc : 0.783905\n",
      "[ ecpho : 0  iter :574 ]train loss : 0.566575 ,train acc: 0.761007 ,val loss : 0.561442 ,val acc : 0.778503\n",
      "[ ecpho : 0  iter :575 ]train loss : 0.581004 ,train acc: 0.755748 ,val loss : 0.561040 ,val acc : 0.780579\n",
      "[ ecpho : 0  iter :576 ]train loss : 0.482133 ,train acc: 0.806763 ,val loss : 0.559448 ,val acc : 0.781921\n",
      "[ ecpho : 0  iter :577 ]train loss : 0.465013 ,train acc: 0.808411 ,val loss : 0.561241 ,val acc : 0.781525\n",
      "[ ecpho : 0  iter :578 ]train loss : 0.498436 ,train acc: 0.796855 ,val loss : 0.561649 ,val acc : 0.783112\n",
      "[ ecpho : 0  iter :579 ]train loss : 0.491898 ,train acc: 0.799174 ,val loss : 0.558489 ,val acc : 0.782288\n",
      "[ ecpho : 0  iter :580 ]train loss : 0.484096 ,train acc: 0.804037 ,val loss : 0.560231 ,val acc : 0.781494\n",
      "[ ecpho : 0  iter :581 ]train loss : 0.536563 ,train acc: 0.785848 ,val loss : 0.557837 ,val acc : 0.782623\n",
      "[ ecpho : 0  iter :582 ]train loss : 0.459146 ,train acc: 0.811259 ,val loss : 0.561560 ,val acc : 0.776459\n",
      "[ ecpho : 0  iter :583 ]train loss : 0.489722 ,train acc: 0.798971 ,val loss : 0.556905 ,val acc : 0.782440\n",
      "[ ecpho : 0  iter :584 ]train loss : 0.551670 ,train acc: 0.774333 ,val loss : 0.564584 ,val acc : 0.781067\n",
      "[ ecpho : 0  iter :585 ]train loss : 0.477985 ,train acc: 0.806855 ,val loss : 0.555071 ,val acc : 0.783295\n",
      "[ ecpho : 0  iter :586 ]train loss : 0.454986 ,train acc: 0.807404 ,val loss : 0.551509 ,val acc : 0.779907\n",
      "[ ecpho : 0  iter :587 ]train loss : 0.501090 ,train acc: 0.795909 ,val loss : 0.563183 ,val acc : 0.782318\n",
      "[ ecpho : 0  iter :588 ]train loss : 0.457701 ,train acc: 0.809642 ,val loss : 0.564105 ,val acc : 0.779053\n",
      "[ ecpho : 0  iter :589 ]train loss : 0.470123 ,train acc: 0.807872 ,val loss : 0.560949 ,val acc : 0.779633\n",
      "[ ecpho : 0  iter :590 ]train loss : 0.564171 ,train acc: 0.767731 ,val loss : 0.559415 ,val acc : 0.781799\n",
      "[ ecpho : 0  iter :591 ]train loss : 0.498176 ,train acc: 0.799500 ,val loss : 0.553832 ,val acc : 0.781555\n",
      "[ ecpho : 0  iter :592 ]train loss : 0.493493 ,train acc: 0.794780 ,val loss : 0.555006 ,val acc : 0.786072\n",
      "[ ecpho : 0  iter :593 ]train loss : 0.517204 ,train acc: 0.794129 ,val loss : 0.555534 ,val acc : 0.780304\n",
      "[ ecpho : 0  iter :594 ]train loss : 0.490233 ,train acc: 0.802836 ,val loss : 0.555021 ,val acc : 0.781555\n",
      "[ ecpho : 0  iter :595 ]train loss : 0.485889 ,train acc: 0.804749 ,val loss : 0.555700 ,val acc : 0.786682\n",
      "[ ecpho : 0  iter :596 ]train loss : 0.532829 ,train acc: 0.789063 ,val loss : 0.560652 ,val acc : 0.783691\n",
      "[ ecpho : 0  iter :597 ]train loss : 0.450697 ,train acc: 0.815857 ,val loss : 0.551327 ,val acc : 0.783203\n",
      "[ ecpho : 0  iter :598 ]train loss : 0.534310 ,train acc: 0.780742 ,val loss : 0.557229 ,val acc : 0.780365\n",
      "[ ecpho : 0  iter :599 ]train loss : 0.468861 ,train acc: 0.808177 ,val loss : 0.560689 ,val acc : 0.779999\n",
      "[ ecpho : 0  iter :600 ]train loss : 0.508060 ,train acc: 0.798523 ,val loss : 0.561946 ,val acc : 0.782135\n",
      "[ ecpho : 0  iter :601 ]train loss : 0.534684 ,train acc: 0.772960 ,val loss : 0.554454 ,val acc : 0.783447\n",
      "[ ecpho : 0  iter :602 ]train loss : 0.469711 ,train acc: 0.805969 ,val loss : 0.548462 ,val acc : 0.784973\n",
      "[ ecpho : 0  iter :603 ]train loss : 0.565996 ,train acc: 0.743815 ,val loss : 0.565785 ,val acc : 0.783173\n",
      "[ ecpho : 0  iter :604 ]train loss : 0.449333 ,train acc: 0.810669 ,val loss : 0.556070 ,val acc : 0.782288\n",
      "[ ecpho : 0  iter :605 ]train loss : 0.592316 ,train acc: 0.717163 ,val loss : 0.561049 ,val acc : 0.781464\n",
      "[ ecpho : 0  iter :606 ]train loss : 0.461801 ,train acc: 0.809825 ,val loss : 0.554654 ,val acc : 0.781616\n",
      "[ ecpho : 0  iter :607 ]train loss : 0.485297 ,train acc: 0.783325 ,val loss : 0.556475 ,val acc : 0.782990\n",
      "[ ecpho : 0  iter :608 ]train loss : 0.486529 ,train acc: 0.800171 ,val loss : 0.548964 ,val acc : 0.784088\n",
      "[ ecpho : 0  iter :609 ]train loss : 0.440000 ,train acc: 0.812531 ,val loss : 0.554332 ,val acc : 0.784180\n",
      "[ ecpho : 0  iter :610 ]train loss : 0.534359 ,train acc: 0.779440 ,val loss : 0.553130 ,val acc : 0.784393\n",
      "[ ecpho : 0  iter :611 ]train loss : 0.494885 ,train acc: 0.789470 ,val loss : 0.552268 ,val acc : 0.780304\n",
      "[ ecpho : 0  iter :612 ]train loss : 0.478541 ,train acc: 0.807750 ,val loss : 0.546869 ,val acc : 0.784302\n",
      "[ ecpho : 0  iter :613 ]train loss : 0.468687 ,train acc: 0.810517 ,val loss : 0.559870 ,val acc : 0.783447\n",
      "[ ecpho : 0  iter :614 ]train loss : 0.556195 ,train acc: 0.758556 ,val loss : 0.555950 ,val acc : 0.783691\n",
      "[ ecpho : 0  iter :615 ]train loss : 0.470991 ,train acc: 0.806763 ,val loss : 0.543739 ,val acc : 0.786163\n",
      "[ ecpho : 0  iter :616 ]train loss : 0.460206 ,train acc: 0.808726 ,val loss : 0.544944 ,val acc : 0.782593\n",
      "[ ecpho : 0  iter :617 ]train loss : 0.484692 ,train acc: 0.793630 ,val loss : 0.558581 ,val acc : 0.781982\n",
      "[ ecpho : 0  iter :618 ]train loss : 0.468768 ,train acc: 0.807017 ,val loss : 0.548182 ,val acc : 0.785004\n",
      "[ ecpho : 0  iter :619 ]train loss : 0.476984 ,train acc: 0.807556 ,val loss : 0.550725 ,val acc : 0.784576\n",
      "[ ecpho : 0  iter :620 ]train loss : 0.479075 ,train acc: 0.803192 ,val loss : 0.550119 ,val acc : 0.783051\n",
      "[ ecpho : 0  iter :621 ]train loss : 0.455043 ,train acc: 0.815603 ,val loss : 0.560043 ,val acc : 0.777863\n",
      "[ ecpho : 0  iter :622 ]train loss : 0.520153 ,train acc: 0.792277 ,val loss : 0.538322 ,val acc : 0.788269\n",
      "[ ecpho : 0  iter :623 ]train loss : 0.460642 ,train acc: 0.802043 ,val loss : 0.549035 ,val acc : 0.784119\n",
      "[ ecpho : 0  iter :624 ]train loss : 0.496226 ,train acc: 0.800731 ,val loss : 0.552410 ,val acc : 0.784882\n",
      "[ ecpho : 0  iter :625 ]train loss : 0.472566 ,train acc: 0.810384 ,val loss : 0.558710 ,val acc : 0.780518\n",
      "[ ecpho : 0  iter :626 ]train loss : 0.462916 ,train acc: 0.810212 ,val loss : 0.555842 ,val acc : 0.781830\n",
      "[ ecpho : 0  iter :627 ]train loss : 0.440988 ,train acc: 0.815481 ,val loss : 0.547989 ,val acc : 0.784515\n",
      "[ ecpho : 0  iter :628 ]train loss : 0.509519 ,train acc: 0.769664 ,val loss : 0.547392 ,val acc : 0.785736\n",
      "[ ecpho : 0  iter :629 ]train loss : 0.452765 ,train acc: 0.810557 ,val loss : 0.547949 ,val acc : 0.785309\n",
      "[ ecpho : 0  iter :630 ]train loss : 0.438531 ,train acc: 0.814972 ,val loss : 0.547804 ,val acc : 0.784485\n",
      "[ ecpho : 0  iter :631 ]train loss : 0.472046 ,train acc: 0.806732 ,val loss : 0.546748 ,val acc : 0.782410\n",
      "[ ecpho : 0  iter :632 ]train loss : 0.450582 ,train acc: 0.813202 ,val loss : 0.551762 ,val acc : 0.781708\n",
      "[ ecpho : 0  iter :633 ]train loss : 0.485492 ,train acc: 0.797791 ,val loss : 0.547658 ,val acc : 0.784485\n",
      "[ ecpho : 0  iter :634 ]train loss : 0.488071 ,train acc: 0.804067 ,val loss : 0.555129 ,val acc : 0.782349\n",
      "[ ecpho : 0  iter :635 ]train loss : 0.453156 ,train acc: 0.813690 ,val loss : 0.546063 ,val acc : 0.782471\n",
      "[ ecpho : 0  iter :636 ]train loss : 0.466965 ,train acc: 0.808360 ,val loss : 0.551898 ,val acc : 0.784271\n",
      "[ ecpho : 0  iter :637 ]train loss : 0.471976 ,train acc: 0.809255 ,val loss : 0.536972 ,val acc : 0.784729\n",
      "[ ecpho : 0  iter :638 ]train loss : 0.476825 ,train acc: 0.802623 ,val loss : 0.560078 ,val acc : 0.782776\n",
      "[ ecpho : 0  iter :639 ]train loss : 0.492056 ,train acc: 0.790446 ,val loss : 0.544522 ,val acc : 0.787079\n",
      "[ ecpho : 0  iter :640 ]train loss : 0.470491 ,train acc: 0.811066 ,val loss : 0.547780 ,val acc : 0.784271\n",
      "[ ecpho : 0  iter :641 ]train loss : 0.479785 ,train acc: 0.806041 ,val loss : 0.556642 ,val acc : 0.782867\n",
      "[ ecpho : 0  iter :642 ]train loss : 0.434852 ,train acc: 0.818675 ,val loss : 0.549346 ,val acc : 0.781982\n",
      "[ ecpho : 0  iter :643 ]train loss : 0.488740 ,train acc: 0.801585 ,val loss : 0.549826 ,val acc : 0.784424\n",
      "[ ecpho : 0  iter :644 ]train loss : 0.485153 ,train acc: 0.786662 ,val loss : 0.539396 ,val acc : 0.786896\n",
      "[ ecpho : 0  iter :645 ]train loss : 0.509952 ,train acc: 0.773499 ,val loss : 0.546998 ,val acc : 0.784088\n",
      "[ ecpho : 0  iter :646 ]train loss : 0.470757 ,train acc: 0.811982 ,val loss : 0.550665 ,val acc : 0.784332\n",
      "[ ecpho : 0  iter :647 ]train loss : 0.430638 ,train acc: 0.819529 ,val loss : 0.544494 ,val acc : 0.784393\n",
      "[ ecpho : 0  iter :648 ]train loss : 0.468932 ,train acc: 0.809530 ,val loss : 0.545667 ,val acc : 0.784180\n",
      "[ ecpho : 0  iter :649 ]train loss : 0.473230 ,train acc: 0.807068 ,val loss : 0.541298 ,val acc : 0.785004\n",
      "[ ecpho : 0  iter :650 ]train loss : 0.453295 ,train acc: 0.806844 ,val loss : 0.533553 ,val acc : 0.787109\n",
      "[ ecpho : 0  iter :651 ]train loss : 0.484735 ,train acc: 0.807282 ,val loss : 0.542180 ,val acc : 0.786804\n",
      "[ ecpho : 0  iter :652 ]train loss : 0.446376 ,train acc: 0.814352 ,val loss : 0.538674 ,val acc : 0.784363\n",
      "[ ecpho : 0  iter :653 ]train loss : 0.453211 ,train acc: 0.811463 ,val loss : 0.539811 ,val acc : 0.786102\n",
      "[ ecpho : 0  iter :654 ]train loss : 0.447037 ,train acc: 0.814626 ,val loss : 0.541835 ,val acc : 0.783661\n",
      "[ ecpho : 0  iter :655 ]train loss : 0.490340 ,train acc: 0.799978 ,val loss : 0.544743 ,val acc : 0.788177\n",
      "[ ecpho : 0  iter :656 ]train loss : 0.487179 ,train acc: 0.801219 ,val loss : 0.545049 ,val acc : 0.782684\n",
      "[ ecpho : 0  iter :657 ]train loss : 0.460292 ,train acc: 0.813151 ,val loss : 0.541211 ,val acc : 0.786987\n",
      "[ ecpho : 0  iter :658 ]train loss : 0.485108 ,train acc: 0.790131 ,val loss : 0.537295 ,val acc : 0.783020\n",
      "[ ecpho : 0  iter :659 ]train loss : 0.450903 ,train acc: 0.816183 ,val loss : 0.534350 ,val acc : 0.784729\n",
      "[ ecpho : 0  iter :660 ]train loss : 0.454799 ,train acc: 0.811483 ,val loss : 0.542680 ,val acc : 0.782654\n",
      "[ ecpho : 0  iter :661 ]train loss : 0.455561 ,train acc: 0.812724 ,val loss : 0.545550 ,val acc : 0.784637\n",
      "[ ecpho : 0  iter :662 ]train loss : 0.476636 ,train acc: 0.801738 ,val loss : 0.550807 ,val acc : 0.783752\n",
      "[ ecpho : 0  iter :663 ]train loss : 0.459805 ,train acc: 0.804556 ,val loss : 0.532629 ,val acc : 0.784180\n",
      "[ ecpho : 0  iter :664 ]train loss : 0.449326 ,train acc: 0.813223 ,val loss : 0.547574 ,val acc : 0.786316\n",
      "[ ecpho : 0  iter :665 ]train loss : 0.463635 ,train acc: 0.810710 ,val loss : 0.534194 ,val acc : 0.788727\n",
      "[ ecpho : 0  iter :666 ]train loss : 0.518799 ,train acc: 0.793559 ,val loss : 0.545331 ,val acc : 0.787262\n",
      "[ ecpho : 0  iter :667 ]train loss : 0.499024 ,train acc: 0.803152 ,val loss : 0.536006 ,val acc : 0.786377\n",
      "[ ecpho : 0  iter :668 ]train loss : 0.494090 ,train acc: 0.803376 ,val loss : 0.535561 ,val acc : 0.787994\n",
      "[ ecpho : 0  iter :669 ]train loss : 0.441388 ,train acc: 0.810578 ,val loss : 0.539767 ,val acc : 0.787994\n",
      "[ ecpho : 0  iter :670 ]train loss : 0.478597 ,train acc: 0.799744 ,val loss : 0.534192 ,val acc : 0.785858\n",
      "[ ecpho : 0  iter :671 ]train loss : 0.417512 ,train acc: 0.820720 ,val loss : 0.542964 ,val acc : 0.787598\n",
      "[ ecpho : 0  iter :672 ]train loss : 0.468247 ,train acc: 0.809408 ,val loss : 0.540029 ,val acc : 0.785889\n",
      "[ ecpho : 0  iter :673 ]train loss : 0.560921 ,train acc: 0.756948 ,val loss : 0.541902 ,val acc : 0.788635\n",
      "[ ecpho : 0  iter :674 ]train loss : 0.441582 ,train acc: 0.816610 ,val loss : 0.537399 ,val acc : 0.786102\n",
      "[ ecpho : 0  iter :675 ]train loss : 0.578880 ,train acc: 0.758820 ,val loss : 0.529842 ,val acc : 0.788269\n",
      "[ ecpho : 0  iter :676 ]train loss : 0.462048 ,train acc: 0.807791 ,val loss : 0.548924 ,val acc : 0.783539\n",
      "[ ecpho : 0  iter :677 ]train loss : 0.459437 ,train acc: 0.813904 ,val loss : 0.537673 ,val acc : 0.785858\n",
      "[ ecpho : 0  iter :678 ]train loss : 0.539198 ,train acc: 0.776897 ,val loss : 0.537023 ,val acc : 0.785980\n",
      "[ ecpho : 0  iter :679 ]train loss : 0.462220 ,train acc: 0.809510 ,val loss : 0.543243 ,val acc : 0.788879\n",
      "[ ecpho : 0  iter :680 ]train loss : 0.527618 ,train acc: 0.788625 ,val loss : 0.540948 ,val acc : 0.785431\n",
      "[ ecpho : 0  iter :681 ]train loss : 0.438694 ,train acc: 0.815796 ,val loss : 0.536981 ,val acc : 0.785583\n",
      "[ ecpho : 0  iter :682 ]train loss : 0.447948 ,train acc: 0.810557 ,val loss : 0.545116 ,val acc : 0.786041\n",
      "[ ecpho : 0  iter :683 ]train loss : 0.503445 ,train acc: 0.767029 ,val loss : 0.540004 ,val acc : 0.787262\n",
      "[ ecpho : 0  iter :684 ]train loss : 0.508442 ,train acc: 0.800680 ,val loss : 0.532244 ,val acc : 0.788605\n",
      "[ ecpho : 0  iter :685 ]train loss : 0.511717 ,train acc: 0.782034 ,val loss : 0.530921 ,val acc : 0.786072\n",
      "[ ecpho : 0  iter :686 ]train loss : 0.441300 ,train acc: 0.813792 ,val loss : 0.542565 ,val acc : 0.785126\n",
      "[ ecpho : 0  iter :687 ]train loss : 0.447951 ,train acc: 0.815267 ,val loss : 0.542016 ,val acc : 0.786407\n",
      "[ ecpho : 0  iter :688 ]train loss : 0.461445 ,train acc: 0.812744 ,val loss : 0.544763 ,val acc : 0.785004\n",
      "[ ecpho : 0  iter :689 ]train loss : 0.429066 ,train acc: 0.812663 ,val loss : 0.549534 ,val acc : 0.783997\n",
      "[ ecpho : 0  iter :690 ]train loss : 0.453745 ,train acc: 0.810974 ,val loss : 0.540312 ,val acc : 0.785217\n",
      "[ ecpho : 0  iter :691 ]train loss : 0.502134 ,train acc: 0.799754 ,val loss : 0.538600 ,val acc : 0.786774\n",
      "[ ecpho : 0  iter :692 ]train loss : 0.424203 ,train acc: 0.820191 ,val loss : 0.542836 ,val acc : 0.781647\n",
      "[ ecpho : 0  iter :693 ]train loss : 0.522254 ,train acc: 0.789958 ,val loss : 0.539623 ,val acc : 0.783936\n",
      "[ ecpho : 0  iter :694 ]train loss : 0.437009 ,train acc: 0.815929 ,val loss : 0.529663 ,val acc : 0.788574\n",
      "[ ecpho : 0  iter :695 ]train loss : 0.476144 ,train acc: 0.800954 ,val loss : 0.525616 ,val acc : 0.789734\n",
      "[ ecpho : 0  iter :696 ]train loss : 0.442643 ,train acc: 0.818034 ,val loss : 0.533373 ,val acc : 0.790253\n",
      "[ ecpho : 0  iter :697 ]train loss : 0.441388 ,train acc: 0.814565 ,val loss : 0.541906 ,val acc : 0.784027\n",
      "[ ecpho : 0  iter :698 ]train loss : 0.455300 ,train acc: 0.813650 ,val loss : 0.533310 ,val acc : 0.788391\n",
      "[ ecpho : 0  iter :699 ]train loss : 0.465331 ,train acc: 0.805451 ,val loss : 0.534742 ,val acc : 0.784821\n",
      "[ ecpho : 0  iter :700 ]train loss : 0.455207 ,train acc: 0.811412 ,val loss : 0.533842 ,val acc : 0.789307\n",
      "[ ecpho : 0  iter :701 ]train loss : 0.476313 ,train acc: 0.782359 ,val loss : 0.532443 ,val acc : 0.785645\n",
      "[ ecpho : 0  iter :702 ]train loss : 0.471063 ,train acc: 0.810649 ,val loss : 0.531725 ,val acc : 0.784241\n",
      "[ ecpho : 0  iter :703 ]train loss : 0.499346 ,train acc: 0.780630 ,val loss : 0.538665 ,val acc : 0.786499\n",
      "[ ecpho : 0  iter :704 ]train loss : 0.539817 ,train acc: 0.778921 ,val loss : 0.537322 ,val acc : 0.784454\n",
      "[ ecpho : 0  iter :705 ]train loss : 0.481243 ,train acc: 0.794831 ,val loss : 0.532710 ,val acc : 0.787659\n",
      "[ ecpho : 0  iter :706 ]train loss : 0.518881 ,train acc: 0.774872 ,val loss : 0.534206 ,val acc : 0.785400\n",
      "[ ecpho : 0  iter :707 ]train loss : 0.458808 ,train acc: 0.811493 ,val loss : 0.528907 ,val acc : 0.789276\n",
      "[ ecpho : 0  iter :708 ]train loss : 0.531291 ,train acc: 0.773316 ,val loss : 0.537127 ,val acc : 0.788147\n",
      "[ ecpho : 0  iter :709 ]train loss : 0.493536 ,train acc: 0.799825 ,val loss : 0.535725 ,val acc : 0.787109\n",
      "[ ecpho : 0  iter :710 ]train loss : 0.466858 ,train acc: 0.812338 ,val loss : 0.528495 ,val acc : 0.790283\n",
      "[ ecpho : 0  iter :711 ]train loss : 0.439522 ,train acc: 0.818919 ,val loss : 0.526376 ,val acc : 0.788513\n",
      "[ ecpho : 0  iter :712 ]train loss : 0.452717 ,train acc: 0.808645 ,val loss : 0.539672 ,val acc : 0.786255\n",
      "[ ecpho : 0  iter :713 ]train loss : 0.471186 ,train acc: 0.792796 ,val loss : 0.531486 ,val acc : 0.789917\n",
      "[ ecpho : 0  iter :714 ]train loss : 0.442054 ,train acc: 0.811229 ,val loss : 0.527989 ,val acc : 0.789276\n",
      "[ ecpho : 0  iter :715 ]train loss : 0.448292 ,train acc: 0.813029 ,val loss : 0.536397 ,val acc : 0.786255\n",
      "[ ecpho : 0  iter :716 ]train loss : 0.439080 ,train acc: 0.812093 ,val loss : 0.529619 ,val acc : 0.787750\n",
      "[ ecpho : 0  iter :717 ]train loss : 0.415713 ,train acc: 0.820852 ,val loss : 0.529625 ,val acc : 0.787292\n",
      "[ ecpho : 0  iter :718 ]train loss : 0.421566 ,train acc: 0.816091 ,val loss : 0.532243 ,val acc : 0.785797\n",
      "[ ecpho : 0  iter :719 ]train loss : 0.559388 ,train acc: 0.770071 ,val loss : 0.532991 ,val acc : 0.786865\n",
      "[ ecpho : 0  iter :720 ]train loss : 0.442565 ,train acc: 0.810038 ,val loss : 0.528158 ,val acc : 0.789429\n",
      "[ ecpho : 0  iter :721 ]train loss : 0.571823 ,train acc: 0.770518 ,val loss : 0.523924 ,val acc : 0.786713\n",
      "[ ecpho : 0  iter :722 ]train loss : 0.497120 ,train acc: 0.791575 ,val loss : 0.538296 ,val acc : 0.786987\n",
      "[ ecpho : 0  iter :723 ]train loss : 0.487690 ,train acc: 0.801188 ,val loss : 0.531922 ,val acc : 0.783844\n",
      "[ ecpho : 0  iter :724 ]train loss : 0.420301 ,train acc: 0.823049 ,val loss : 0.531366 ,val acc : 0.789093\n",
      "[ ecpho : 0  iter :725 ]train loss : 0.473340 ,train acc: 0.797414 ,val loss : 0.530685 ,val acc : 0.786163\n",
      "[ ecpho : 0  iter :726 ]train loss : 0.561984 ,train acc: 0.779409 ,val loss : 0.517870 ,val acc : 0.790558\n",
      "[ ecpho : 0  iter :727 ]train loss : 0.443246 ,train acc: 0.806865 ,val loss : 0.523927 ,val acc : 0.785706\n",
      "[ ecpho : 0  iter :728 ]train loss : 0.463895 ,train acc: 0.814932 ,val loss : 0.537394 ,val acc : 0.790222\n",
      "[ ecpho : 0  iter :729 ]train loss : 0.453931 ,train acc: 0.812348 ,val loss : 0.520562 ,val acc : 0.788849\n",
      "[ ecpho : 0  iter :730 ]train loss : 0.527203 ,train acc: 0.777487 ,val loss : 0.530322 ,val acc : 0.789673\n",
      "[ ecpho : 0  iter :731 ]train loss : 0.429891 ,train acc: 0.817831 ,val loss : 0.526913 ,val acc : 0.789124\n",
      "[ ecpho : 0  iter :732 ]train loss : 0.462043 ,train acc: 0.811249 ,val loss : 0.526847 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :733 ]train loss : 0.426534 ,train acc: 0.817251 ,val loss : 0.529210 ,val acc : 0.789062\n",
      "[ ecpho : 0  iter :734 ]train loss : 0.504114 ,train acc: 0.790558 ,val loss : 0.533602 ,val acc : 0.786926\n",
      "[ ecpho : 0  iter :735 ]train loss : 0.413410 ,train acc: 0.818400 ,val loss : 0.525973 ,val acc : 0.786743\n",
      "[ ecpho : 0  iter :736 ]train loss : 0.462494 ,train acc: 0.812785 ,val loss : 0.531758 ,val acc : 0.788605\n",
      "[ ecpho : 0  iter :737 ]train loss : 0.454145 ,train acc: 0.815521 ,val loss : 0.533974 ,val acc : 0.789734\n",
      "[ ecpho : 0  iter :738 ]train loss : 0.437138 ,train acc: 0.817190 ,val loss : 0.526883 ,val acc : 0.788239\n",
      "[ ecpho : 0  iter :739 ]train loss : 0.449285 ,train acc: 0.799571 ,val loss : 0.529628 ,val acc : 0.788788\n",
      "[ ecpho : 0  iter :740 ]train loss : 0.410111 ,train acc: 0.820516 ,val loss : 0.524092 ,val acc : 0.789520\n",
      "[ ecpho : 0  iter :741 ]train loss : 0.462642 ,train acc: 0.809377 ,val loss : 0.532022 ,val acc : 0.787415\n",
      "[ ecpho : 0  iter :742 ]train loss : 0.445036 ,train acc: 0.818980 ,val loss : 0.517730 ,val acc : 0.791840\n",
      "[ ecpho : 0  iter :743 ]train loss : 0.486724 ,train acc: 0.806865 ,val loss : 0.524163 ,val acc : 0.789032\n",
      "[ ecpho : 0  iter :744 ]train loss : 0.435320 ,train acc: 0.811300 ,val loss : 0.528481 ,val acc : 0.790283\n",
      "[ ecpho : 0  iter :745 ]train loss : 0.501831 ,train acc: 0.798310 ,val loss : 0.531532 ,val acc : 0.789154\n",
      "[ ecpho : 0  iter :746 ]train loss : 0.445245 ,train acc: 0.816732 ,val loss : 0.527851 ,val acc : 0.789001\n",
      "[ ecpho : 0  iter :747 ]train loss : 0.517180 ,train acc: 0.799062 ,val loss : 0.527331 ,val acc : 0.788910\n",
      "[ ecpho : 0  iter :748 ]train loss : 0.410414 ,train acc: 0.822947 ,val loss : 0.532209 ,val acc : 0.788269\n",
      "[ ecpho : 0  iter :749 ]train loss : 0.425859 ,train acc: 0.821554 ,val loss : 0.516931 ,val acc : 0.789490\n",
      "[ ecpho : 0  iter :750 ]train loss : 0.452867 ,train acc: 0.802155 ,val loss : 0.519066 ,val acc : 0.789246\n",
      "[ ecpho : 0  iter :751 ]train loss : 0.422473 ,train acc: 0.823537 ,val loss : 0.531680 ,val acc : 0.786896\n",
      "[ ecpho : 0  iter :752 ]train loss : 0.421404 ,train acc: 0.818451 ,val loss : 0.517688 ,val acc : 0.791504\n",
      "[ ecpho : 0  iter :753 ]train loss : 0.432089 ,train acc: 0.816162 ,val loss : 0.522376 ,val acc : 0.788818\n",
      "[ ecpho : 0  iter :754 ]train loss : 0.418425 ,train acc: 0.818675 ,val loss : 0.522682 ,val acc : 0.789337\n",
      "[ ecpho : 0  iter :755 ]train loss : 0.428654 ,train acc: 0.816742 ,val loss : 0.514354 ,val acc : 0.790527\n",
      "[ ecpho : 0  iter :756 ]train loss : 0.458612 ,train acc: 0.807628 ,val loss : 0.523782 ,val acc : 0.787781\n",
      "[ ecpho : 0  iter :757 ]train loss : 0.424903 ,train acc: 0.815705 ,val loss : 0.518851 ,val acc : 0.788177\n",
      "[ ecpho : 0  iter :758 ]train loss : 0.417924 ,train acc: 0.817882 ,val loss : 0.523021 ,val acc : 0.789917\n",
      "[ ecpho : 0  iter :759 ]train loss : 0.457335 ,train acc: 0.793091 ,val loss : 0.526282 ,val acc : 0.787628\n",
      "[ ecpho : 0  iter :760 ]train loss : 0.466199 ,train acc: 0.794444 ,val loss : 0.525293 ,val acc : 0.786346\n",
      "[ ecpho : 0  iter :761 ]train loss : 0.448253 ,train acc: 0.817169 ,val loss : 0.522231 ,val acc : 0.790375\n",
      "[ ecpho : 0  iter :762 ]train loss : 0.440105 ,train acc: 0.818441 ,val loss : 0.522425 ,val acc : 0.789612\n",
      "[ ecpho : 0  iter :763 ]train loss : 0.452774 ,train acc: 0.813243 ,val loss : 0.521385 ,val acc : 0.790680\n",
      "[ ecpho : 0  iter :764 ]train loss : 0.428506 ,train acc: 0.817902 ,val loss : 0.532034 ,val acc : 0.788452\n",
      "[ ecpho : 0  iter :765 ]train loss : 0.475645 ,train acc: 0.806214 ,val loss : 0.522913 ,val acc : 0.788879\n",
      "[ ecpho : 0  iter :766 ]train loss : 0.429648 ,train acc: 0.821300 ,val loss : 0.527644 ,val acc : 0.791779\n",
      "[ ecpho : 0  iter :767 ]train loss : 0.434302 ,train acc: 0.805858 ,val loss : 0.524436 ,val acc : 0.789490\n",
      "[ ecpho : 0  iter :768 ]train loss : 0.409905 ,train acc: 0.821086 ,val loss : 0.520006 ,val acc : 0.790131\n",
      "[ ecpho : 0  iter :769 ]train loss : 0.425782 ,train acc: 0.821106 ,val loss : 0.521023 ,val acc : 0.789948\n",
      "[ ecpho : 0  iter :770 ]train loss : 0.441320 ,train acc: 0.818054 ,val loss : 0.518627 ,val acc : 0.792175\n",
      "[ ecpho : 0  iter :771 ]train loss : 0.447674 ,train acc: 0.807404 ,val loss : 0.520297 ,val acc : 0.786163\n",
      "[ ecpho : 0  iter :772 ]train loss : 0.560939 ,train acc: 0.766297 ,val loss : 0.522557 ,val acc : 0.791016\n",
      "[ ecpho : 0  iter :773 ]train loss : 0.404680 ,train acc: 0.820954 ,val loss : 0.519417 ,val acc : 0.789551\n",
      "[ ecpho : 0  iter :774 ]train loss : 0.476319 ,train acc: 0.811809 ,val loss : 0.523204 ,val acc : 0.791382\n",
      "[ ecpho : 0  iter :775 ]train loss : 0.425676 ,train acc: 0.817108 ,val loss : 0.524176 ,val acc : 0.787994\n",
      "[ ecpho : 0  iter :776 ]train loss : 0.433871 ,train acc: 0.817607 ,val loss : 0.526834 ,val acc : 0.787872\n",
      "[ ecpho : 0  iter :777 ]train loss : 0.429008 ,train acc: 0.820608 ,val loss : 0.509465 ,val acc : 0.793030\n",
      "[ ecpho : 0  iter :778 ]train loss : 0.461576 ,train acc: 0.811503 ,val loss : 0.521090 ,val acc : 0.791626\n",
      "[ ecpho : 0  iter :779 ]train loss : 0.416700 ,train acc: 0.820415 ,val loss : 0.515142 ,val acc : 0.789307\n",
      "[ ecpho : 0  iter :780 ]train loss : 0.417139 ,train acc: 0.820648 ,val loss : 0.521221 ,val acc : 0.788940\n",
      "[ ecpho : 0  iter :781 ]train loss : 0.453847 ,train acc: 0.810079 ,val loss : 0.522178 ,val acc : 0.786469\n",
      "[ ecpho : 0  iter :782 ]train loss : 0.468514 ,train acc: 0.768606 ,val loss : 0.521363 ,val acc : 0.791290\n",
      "[ ecpho : 0  iter :783 ]train loss : 0.436921 ,train acc: 0.816813 ,val loss : 0.526965 ,val acc : 0.785828\n",
      "[ ecpho : 0  iter :784 ]train loss : 0.454179 ,train acc: 0.816935 ,val loss : 0.518612 ,val acc : 0.792206\n",
      "[ ecpho : 0  iter :785 ]train loss : 0.422561 ,train acc: 0.824351 ,val loss : 0.522896 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :786 ]train loss : 0.453895 ,train acc: 0.796224 ,val loss : 0.511636 ,val acc : 0.789337\n",
      "[ ecpho : 0  iter :787 ]train loss : 0.480003 ,train acc: 0.812622 ,val loss : 0.522333 ,val acc : 0.789337\n",
      "[ ecpho : 0  iter :788 ]train loss : 0.434093 ,train acc: 0.813731 ,val loss : 0.526006 ,val acc : 0.789429\n",
      "[ ecpho : 0  iter :789 ]train loss : 0.458452 ,train acc: 0.800202 ,val loss : 0.522411 ,val acc : 0.789490\n",
      "[ ecpho : 0  iter :790 ]train loss : 0.443283 ,train acc: 0.814799 ,val loss : 0.515407 ,val acc : 0.788940\n",
      "[ ecpho : 0  iter :791 ]train loss : 0.415764 ,train acc: 0.813741 ,val loss : 0.522996 ,val acc : 0.787842\n",
      "[ ecpho : 0  iter :792 ]train loss : 0.472553 ,train acc: 0.809357 ,val loss : 0.512144 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :793 ]train loss : 0.472061 ,train acc: 0.803833 ,val loss : 0.518866 ,val acc : 0.790222\n",
      "[ ecpho : 0  iter :794 ]train loss : 0.463975 ,train acc: 0.796936 ,val loss : 0.516069 ,val acc : 0.786682\n",
      "[ ecpho : 0  iter :795 ]train loss : 0.492265 ,train acc: 0.804505 ,val loss : 0.514311 ,val acc : 0.793091\n",
      "[ ecpho : 0  iter :796 ]train loss : 0.437958 ,train acc: 0.816569 ,val loss : 0.528628 ,val acc : 0.790222\n",
      "[ ecpho : 0  iter :797 ]train loss : 0.404065 ,train acc: 0.821717 ,val loss : 0.513161 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :798 ]train loss : 0.429615 ,train acc: 0.822510 ,val loss : 0.519289 ,val acc : 0.790253\n",
      "[ ecpho : 0  iter :799 ]train loss : 0.451199 ,train acc: 0.805532 ,val loss : 0.524495 ,val acc : 0.788666\n",
      "[ ecpho : 0  iter :800 ]train loss : 0.396935 ,train acc: 0.829153 ,val loss : 0.513274 ,val acc : 0.791595\n",
      "[ ecpho : 0  iter :801 ]train loss : 0.434646 ,train acc: 0.813487 ,val loss : 0.519113 ,val acc : 0.789246\n",
      "[ ecpho : 0  iter :802 ]train loss : 0.434716 ,train acc: 0.818644 ,val loss : 0.516833 ,val acc : 0.790710\n",
      "[ ecpho : 0  iter :803 ]train loss : 0.440662 ,train acc: 0.816966 ,val loss : 0.512228 ,val acc : 0.790741\n",
      "[ ecpho : 0  iter :804 ]train loss : 0.445431 ,train acc: 0.806000 ,val loss : 0.519486 ,val acc : 0.791870\n",
      "[ ecpho : 0  iter :805 ]train loss : 0.456350 ,train acc: 0.783793 ,val loss : 0.502739 ,val acc : 0.796356\n",
      "[ ecpho : 0  iter :806 ]train loss : 0.428663 ,train acc: 0.817495 ,val loss : 0.521991 ,val acc : 0.789764\n",
      "[ ecpho : 0  iter :807 ]train loss : 0.427272 ,train acc: 0.817800 ,val loss : 0.522925 ,val acc : 0.788483\n",
      "[ ecpho : 0  iter :808 ]train loss : 0.422880 ,train acc: 0.821279 ,val loss : 0.516839 ,val acc : 0.791534\n",
      "[ ecpho : 0  iter :809 ]train loss : 0.445817 ,train acc: 0.814097 ,val loss : 0.515837 ,val acc : 0.787964\n",
      "[ ecpho : 0  iter :810 ]train loss : 0.433444 ,train acc: 0.816844 ,val loss : 0.514019 ,val acc : 0.792908\n",
      "[ ecpho : 0  iter :811 ]train loss : 0.459351 ,train acc: 0.813446 ,val loss : 0.519449 ,val acc : 0.790985\n",
      "[ ecpho : 0  iter :812 ]train loss : 0.418559 ,train acc: 0.821096 ,val loss : 0.513251 ,val acc : 0.789215\n",
      "[ ecpho : 0  iter :813 ]train loss : 0.513005 ,train acc: 0.794770 ,val loss : 0.517616 ,val acc : 0.793091\n",
      "[ ecpho : 0  iter :814 ]train loss : 0.389788 ,train acc: 0.831848 ,val loss : 0.513898 ,val acc : 0.791473\n",
      "[ ecpho : 0  iter :815 ]train loss : 0.452196 ,train acc: 0.795187 ,val loss : 0.510927 ,val acc : 0.792969\n",
      "[ ecpho : 0  iter :816 ]train loss : 0.426940 ,train acc: 0.822307 ,val loss : 0.510137 ,val acc : 0.793640\n",
      "[ ecpho : 0  iter :817 ]train loss : 0.468459 ,train acc: 0.801870 ,val loss : 0.523709 ,val acc : 0.788422\n",
      "[ ecpho : 0  iter :818 ]train loss : 0.445593 ,train acc: 0.807465 ,val loss : 0.516736 ,val acc : 0.787811\n",
      "[ ecpho : 0  iter :819 ]train loss : 0.403762 ,train acc: 0.827495 ,val loss : 0.513140 ,val acc : 0.792786\n",
      "[ ecpho : 0  iter :820 ]train loss : 0.465549 ,train acc: 0.808248 ,val loss : 0.518762 ,val acc : 0.789886\n",
      "[ ecpho : 0  iter :821 ]train loss : 0.407788 ,train acc: 0.824219 ,val loss : 0.514446 ,val acc : 0.789001\n",
      "[ ecpho : 0  iter :822 ]train loss : 0.437664 ,train acc: 0.814677 ,val loss : 0.512837 ,val acc : 0.788818\n",
      "[ ecpho : 0  iter :823 ]train loss : 0.434756 ,train acc: 0.803660 ,val loss : 0.520276 ,val acc : 0.791382\n",
      "[ ecpho : 0  iter :824 ]train loss : 0.445593 ,train acc: 0.818166 ,val loss : 0.513670 ,val acc : 0.791534\n",
      "[ ecpho : 0  iter :825 ]train loss : 0.440113 ,train acc: 0.797760 ,val loss : 0.513692 ,val acc : 0.791077\n",
      "[ ecpho : 0  iter :826 ]train loss : 0.469234 ,train acc: 0.817922 ,val loss : 0.513599 ,val acc : 0.791595\n",
      "[ ecpho : 0  iter :827 ]train loss : 0.434030 ,train acc: 0.804464 ,val loss : 0.506260 ,val acc : 0.794281\n",
      "[ ecpho : 0  iter :828 ]train loss : 0.426095 ,train acc: 0.812999 ,val loss : 0.514587 ,val acc : 0.790436\n",
      "[ ecpho : 0  iter :829 ]train loss : 0.436394 ,train acc: 0.816183 ,val loss : 0.516091 ,val acc : 0.790802\n",
      "[ ecpho : 0  iter :830 ]train loss : 0.425879 ,train acc: 0.822032 ,val loss : 0.505226 ,val acc : 0.791626\n",
      "[ ecpho : 0  iter :831 ]train loss : 0.415301 ,train acc: 0.822876 ,val loss : 0.511332 ,val acc : 0.791107\n",
      "[ ecpho : 0  iter :832 ]train loss : 0.476947 ,train acc: 0.797333 ,val loss : 0.508861 ,val acc : 0.793365\n",
      "[ ecpho : 0  iter :833 ]train loss : 0.476085 ,train acc: 0.784323 ,val loss : 0.500736 ,val acc : 0.791443\n",
      "[ ecpho : 0  iter :834 ]train loss : 0.543975 ,train acc: 0.788076 ,val loss : 0.514477 ,val acc : 0.791138\n",
      "[ ecpho : 0  iter :835 ]train loss : 0.589070 ,train acc: 0.764110 ,val loss : 0.507208 ,val acc : 0.791992\n",
      "[ ecpho : 0  iter :836 ]train loss : 0.408057 ,train acc: 0.822663 ,val loss : 0.517377 ,val acc : 0.792267\n",
      "[ ecpho : 0  iter :837 ]train loss : 0.396631 ,train acc: 0.825206 ,val loss : 0.516117 ,val acc : 0.788422\n",
      "[ ecpho : 0  iter :838 ]train loss : 0.419943 ,train acc: 0.816803 ,val loss : 0.519543 ,val acc : 0.785980\n",
      "[ ecpho : 0  iter :839 ]train loss : 0.448644 ,train acc: 0.817729 ,val loss : 0.508628 ,val acc : 0.794434\n",
      "[ ecpho : 0  iter :840 ]train loss : 0.453384 ,train acc: 0.773346 ,val loss : 0.507920 ,val acc : 0.793488\n",
      "[ ecpho : 0  iter :841 ]train loss : 0.419784 ,train acc: 0.821625 ,val loss : 0.517376 ,val acc : 0.788483\n",
      "[ ecpho : 0  iter :842 ]train loss : 0.499468 ,train acc: 0.791535 ,val loss : 0.509408 ,val acc : 0.793762\n",
      "[ ecpho : 0  iter :843 ]train loss : 0.475495 ,train acc: 0.776540 ,val loss : 0.526029 ,val acc : 0.786499\n",
      "[ ecpho : 0  iter :844 ]train loss : 0.440419 ,train acc: 0.791443 ,val loss : 0.518365 ,val acc : 0.788666\n",
      "[ ecpho : 0  iter :845 ]train loss : 0.459346 ,train acc: 0.815654 ,val loss : 0.517446 ,val acc : 0.788971\n",
      "[ ecpho : 0  iter :846 ]train loss : 0.419262 ,train acc: 0.820547 ,val loss : 0.519707 ,val acc : 0.787048\n",
      "[ ecpho : 0  iter :847 ]train loss : 0.415763 ,train acc: 0.824270 ,val loss : 0.509471 ,val acc : 0.792114\n",
      "[ ecpho : 0  iter :848 ]train loss : 0.524887 ,train acc: 0.797709 ,val loss : 0.502101 ,val acc : 0.795715\n",
      "[ ecpho : 0  iter :849 ]train loss : 0.413411 ,train acc: 0.819021 ,val loss : 0.510017 ,val acc : 0.794891\n",
      "[ ecpho : 0  iter :850 ]train loss : 0.421125 ,train acc: 0.818288 ,val loss : 0.514923 ,val acc : 0.791077\n",
      "[ ecpho : 0  iter :851 ]train loss : 0.442011 ,train acc: 0.800934 ,val loss : 0.513404 ,val acc : 0.790192\n",
      "[ ecpho : 0  iter :852 ]train loss : 0.432144 ,train acc: 0.814667 ,val loss : 0.510448 ,val acc : 0.792206\n",
      "[ ecpho : 0  iter :853 ]train loss : 0.407605 ,train acc: 0.821462 ,val loss : 0.512515 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :854 ]train loss : 0.402550 ,train acc: 0.826793 ,val loss : 0.513208 ,val acc : 0.789185\n",
      "[ ecpho : 0  iter :855 ]train loss : 0.491104 ,train acc: 0.804871 ,val loss : 0.507159 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :856 ]train loss : 0.454864 ,train acc: 0.807495 ,val loss : 0.511012 ,val acc : 0.792267\n",
      "[ ecpho : 0  iter :857 ]train loss : 0.415847 ,train acc: 0.824178 ,val loss : 0.502004 ,val acc : 0.793579\n",
      "[ ecpho : 0  iter :858 ]train loss : 0.449544 ,train acc: 0.820343 ,val loss : 0.514396 ,val acc : 0.790009\n",
      "[ ecpho : 0  iter :859 ]train loss : 0.458194 ,train acc: 0.814596 ,val loss : 0.506718 ,val acc : 0.792450\n",
      "[ ecpho : 0  iter :860 ]train loss : 0.467235 ,train acc: 0.786041 ,val loss : 0.509986 ,val acc : 0.792236\n",
      "[ ecpho : 0  iter :861 ]train loss : 0.479315 ,train acc: 0.806641 ,val loss : 0.501919 ,val acc : 0.793640\n",
      "[ ecpho : 0  iter :862 ]train loss : 0.452342 ,train acc: 0.809418 ,val loss : 0.519319 ,val acc : 0.788452\n",
      "[ ecpho : 0  iter :863 ]train loss : 0.524029 ,train acc: 0.772634 ,val loss : 0.508523 ,val acc : 0.794891\n",
      "[ ecpho : 0  iter :864 ]train loss : 0.404231 ,train acc: 0.825674 ,val loss : 0.509861 ,val acc : 0.790100\n",
      "[ ecpho : 0  iter :865 ]train loss : 0.468966 ,train acc: 0.798625 ,val loss : 0.508166 ,val acc : 0.792053\n",
      "[ ecpho : 0  iter :866 ]train loss : 0.432750 ,train acc: 0.801138 ,val loss : 0.501144 ,val acc : 0.794342\n",
      "[ ecpho : 0  iter :867 ]train loss : 0.424919 ,train acc: 0.819082 ,val loss : 0.507878 ,val acc : 0.793457\n",
      "[ ecpho : 0  iter :868 ]train loss : 0.491198 ,train acc: 0.800842 ,val loss : 0.505287 ,val acc : 0.792816\n",
      "[ ecpho : 0  iter :869 ]train loss : 0.441557 ,train acc: 0.818838 ,val loss : 0.509626 ,val acc : 0.792755\n",
      "[ ecpho : 0  iter :870 ]train loss : 0.452148 ,train acc: 0.795034 ,val loss : 0.504581 ,val acc : 0.789673\n",
      "[ ecpho : 0  iter :871 ]train loss : 0.387252 ,train acc: 0.833130 ,val loss : 0.515696 ,val acc : 0.790710\n",
      "[ ecpho : 0  iter :872 ]train loss : 0.448757 ,train acc: 0.812073 ,val loss : 0.498297 ,val acc : 0.792908\n",
      "[ ecpho : 0  iter :873 ]train loss : 0.448180 ,train acc: 0.816295 ,val loss : 0.511233 ,val acc : 0.789490\n",
      "[ ecpho : 0  iter :874 ]train loss : 0.423453 ,train acc: 0.822744 ,val loss : 0.500265 ,val acc : 0.795105\n",
      "[ ecpho : 0  iter :875 ]train loss : 0.412190 ,train acc: 0.824453 ,val loss : 0.513268 ,val acc : 0.787567\n",
      "[ ecpho : 0  iter :876 ]train loss : 0.409133 ,train acc: 0.830119 ,val loss : 0.503933 ,val acc : 0.791077\n",
      "[ ecpho : 0  iter :877 ]train loss : 0.466602 ,train acc: 0.808350 ,val loss : 0.506826 ,val acc : 0.792816\n",
      "[ ecpho : 0  iter :878 ]train loss : 0.417875 ,train acc: 0.818421 ,val loss : 0.507406 ,val acc : 0.794373\n",
      "[ ecpho : 0  iter :879 ]train loss : 0.460136 ,train acc: 0.811219 ,val loss : 0.512250 ,val acc : 0.787811\n",
      "[ ecpho : 0  iter :880 ]train loss : 0.421635 ,train acc: 0.825104 ,val loss : 0.507089 ,val acc : 0.794739\n",
      "[ ecpho : 0  iter :881 ]train loss : 0.511041 ,train acc: 0.739299 ,val loss : 0.510430 ,val acc : 0.791382\n",
      "[ ecpho : 0  iter :882 ]train loss : 0.398640 ,train acc: 0.827647 ,val loss : 0.508166 ,val acc : 0.791351\n",
      "[ ecpho : 0  iter :883 ]train loss : 0.391033 ,train acc: 0.827505 ,val loss : 0.500796 ,val acc : 0.791473\n",
      "[ ecpho : 0  iter :884 ]train loss : 0.458506 ,train acc: 0.816458 ,val loss : 0.499480 ,val acc : 0.793243\n",
      "[ ecpho : 0  iter :885 ]train loss : 0.454136 ,train acc: 0.795543 ,val loss : 0.500433 ,val acc : 0.794067\n",
      "[ ecpho : 0  iter :886 ]train loss : 0.424135 ,train acc: 0.820567 ,val loss : 0.513005 ,val acc : 0.791748\n",
      "[ ecpho : 0  iter :887 ]train loss : 0.503318 ,train acc: 0.779653 ,val loss : 0.510796 ,val acc : 0.790009\n",
      "[ ecpho : 0  iter :888 ]train loss : 0.480299 ,train acc: 0.810974 ,val loss : 0.504137 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :889 ]train loss : 0.405501 ,train acc: 0.822520 ,val loss : 0.501025 ,val acc : 0.793762\n",
      "[ ecpho : 0  iter :890 ]train loss : 0.397430 ,train acc: 0.827576 ,val loss : 0.501001 ,val acc : 0.793579\n",
      "[ ecpho : 0  iter :891 ]train loss : 0.458500 ,train acc: 0.813701 ,val loss : 0.493924 ,val acc : 0.795074\n",
      "[ ecpho : 0  iter :892 ]train loss : 0.419765 ,train acc: 0.808065 ,val loss : 0.505338 ,val acc : 0.789825\n",
      "[ ecpho : 0  iter :893 ]train loss : 0.367756 ,train acc: 0.837993 ,val loss : 0.507979 ,val acc : 0.791504\n",
      "[ ecpho : 0  iter :894 ]train loss : 0.529786 ,train acc: 0.683584 ,val loss : 0.499046 ,val acc : 0.791656\n",
      "[ ecpho : 0  iter :895 ]train loss : 0.377920 ,train acc: 0.832581 ,val loss : 0.499318 ,val acc : 0.789001\n",
      "[ ecpho : 0  iter :896 ]train loss : 0.410435 ,train acc: 0.825430 ,val loss : 0.504389 ,val acc : 0.793396\n",
      "[ ecpho : 0  iter :897 ]train loss : 0.418511 ,train acc: 0.816915 ,val loss : 0.500619 ,val acc : 0.796844\n",
      "[ ecpho : 0  iter :898 ]train loss : 0.403363 ,train acc: 0.826630 ,val loss : 0.498408 ,val acc : 0.793457\n",
      "[ ecpho : 0  iter :899 ]train loss : 0.431707 ,train acc: 0.821391 ,val loss : 0.503235 ,val acc : 0.792297\n",
      "[ ecpho : 0  iter :900 ]train loss : 0.429038 ,train acc: 0.818380 ,val loss : 0.506021 ,val acc : 0.793274\n",
      "[ ecpho : 0  iter :901 ]train loss : 0.412200 ,train acc: 0.824758 ,val loss : 0.497024 ,val acc : 0.794769\n",
      "[ ecpho : 0  iter :902 ]train loss : 0.397669 ,train acc: 0.827851 ,val loss : 0.500606 ,val acc : 0.792328\n",
      "[ ecpho : 0  iter :903 ]train loss : 0.384557 ,train acc: 0.827281 ,val loss : 0.501079 ,val acc : 0.795441\n",
      "[ ecpho : 0  iter :904 ]train loss : 0.514618 ,train acc: 0.792776 ,val loss : 0.497262 ,val acc : 0.796143\n",
      "[ ecpho : 0  iter :905 ]train loss : 0.413811 ,train acc: 0.823995 ,val loss : 0.500805 ,val acc : 0.792450\n",
      "[ ecpho : 0  iter :906 ]train loss : 0.491073 ,train acc: 0.721324 ,val loss : 0.503281 ,val acc : 0.798401\n",
      "[ ecpho : 0  iter :907 ]train loss : 0.412248 ,train acc: 0.828074 ,val loss : 0.499397 ,val acc : 0.791412\n",
      "[ ecpho : 0  iter :908 ]train loss : 0.443472 ,train acc: 0.810740 ,val loss : 0.509010 ,val acc : 0.795227\n",
      "[ ecpho : 0  iter :909 ]train loss : 0.447056 ,train acc: 0.814311 ,val loss : 0.507555 ,val acc : 0.792114\n",
      "[ ecpho : 0  iter :910 ]train loss : 0.377302 ,train acc: 0.828502 ,val loss : 0.503327 ,val acc : 0.792847\n",
      "[ ecpho : 0  iter :911 ]train loss : 0.490719 ,train acc: 0.775777 ,val loss : 0.498149 ,val acc : 0.794647\n",
      "[ ecpho : 0  iter :912 ]train loss : 0.487682 ,train acc: 0.814606 ,val loss : 0.500540 ,val acc : 0.796173\n",
      "[ ecpho : 0  iter :913 ]train loss : 0.413152 ,train acc: 0.815572 ,val loss : 0.504836 ,val acc : 0.793671\n",
      "[ ecpho : 0  iter :914 ]train loss : 0.408716 ,train acc: 0.821106 ,val loss : 0.503584 ,val acc : 0.793365\n",
      "[ ecpho : 0  iter :915 ]train loss : 0.417310 ,train acc: 0.813619 ,val loss : 0.500398 ,val acc : 0.791595\n",
      "[ ecpho : 0  iter :916 ]train loss : 0.470329 ,train acc: 0.804606 ,val loss : 0.502676 ,val acc : 0.791687\n",
      "[ ecpho : 0  iter :917 ]train loss : 0.401189 ,train acc: 0.824636 ,val loss : 0.495324 ,val acc : 0.791840\n",
      "[ ecpho : 0  iter :918 ]train loss : 0.459314 ,train acc: 0.797913 ,val loss : 0.511161 ,val acc : 0.789337\n",
      "[ ecpho : 0  iter :919 ]train loss : 0.430357 ,train acc: 0.811758 ,val loss : 0.497980 ,val acc : 0.792297\n",
      "[ ecpho : 0  iter :920 ]train loss : 0.444446 ,train acc: 0.809642 ,val loss : 0.494486 ,val acc : 0.800720\n",
      "[ ecpho : 0  iter :921 ]train loss : 0.400468 ,train acc: 0.824036 ,val loss : 0.503281 ,val acc : 0.794678\n",
      "[ ecpho : 0  iter :922 ]train loss : 0.388189 ,train acc: 0.831340 ,val loss : 0.496942 ,val acc : 0.795990\n",
      "[ ecpho : 0  iter :923 ]train loss : 0.398974 ,train acc: 0.829224 ,val loss : 0.504581 ,val acc : 0.792511\n",
      "[ ecpho : 0  iter :924 ]train loss : 0.437218 ,train acc: 0.791372 ,val loss : 0.499615 ,val acc : 0.792847\n",
      "[ ecpho : 0  iter :925 ]train loss : 0.422421 ,train acc: 0.825236 ,val loss : 0.496369 ,val acc : 0.792908\n",
      "[ ecpho : 0  iter :926 ]train loss : 0.457608 ,train acc: 0.792979 ,val loss : 0.502243 ,val acc : 0.793884\n",
      "[ ecpho : 0  iter :927 ]train loss : 0.470683 ,train acc: 0.816854 ,val loss : 0.504138 ,val acc : 0.793549\n",
      "[ ecpho : 0  iter :928 ]train loss : 0.378235 ,train acc: 0.835378 ,val loss : 0.498999 ,val acc : 0.790039\n",
      "[ ecpho : 0  iter :929 ]train loss : 0.410829 ,train acc: 0.824422 ,val loss : 0.496002 ,val acc : 0.792755\n",
      "[ ecpho : 0  iter :930 ]train loss : 0.407458 ,train acc: 0.825470 ,val loss : 0.505871 ,val acc : 0.793823\n",
      "[ ecpho : 0  iter :931 ]train loss : 0.452799 ,train acc: 0.819662 ,val loss : 0.497649 ,val acc : 0.796936\n",
      "[ ecpho : 0  iter :932 ]train loss : 0.384242 ,train acc: 0.830984 ,val loss : 0.497501 ,val acc : 0.794250\n",
      "[ ecpho : 0  iter :933 ]train loss : 0.432205 ,train acc: 0.807801 ,val loss : 0.494069 ,val acc : 0.796082\n",
      "[ ecpho : 0  iter :934 ]train loss : 0.399762 ,train acc: 0.824117 ,val loss : 0.500750 ,val acc : 0.793579\n",
      "[ ecpho : 0  iter :935 ]train loss : 0.416987 ,train acc: 0.818746 ,val loss : 0.494867 ,val acc : 0.793457\n",
      "[ ecpho : 0  iter :936 ]train loss : 0.373105 ,train acc: 0.836039 ,val loss : 0.497770 ,val acc : 0.793335\n",
      "[ ecpho : 0  iter :937 ]train loss : 0.444856 ,train acc: 0.806305 ,val loss : 0.500308 ,val acc : 0.791656\n",
      "[ ecpho : 0  iter :938 ]train loss : 0.394129 ,train acc: 0.831533 ,val loss : 0.497835 ,val acc : 0.792694\n",
      "[ ecpho : 0  iter :939 ]train loss : 0.473732 ,train acc: 0.803620 ,val loss : 0.494077 ,val acc : 0.794189\n",
      "[ ecpho : 0  iter :940 ]train loss : 0.391310 ,train acc: 0.831309 ,val loss : 0.503006 ,val acc : 0.792297\n",
      "[ ecpho : 0  iter :941 ]train loss : 0.449867 ,train acc: 0.801107 ,val loss : 0.507712 ,val acc : 0.793121\n",
      "[ ecpho : 0  iter :942 ]train loss : 0.384805 ,train acc: 0.831533 ,val loss : 0.504671 ,val acc : 0.791077\n",
      "[ ecpho : 0  iter :943 ]train loss : 0.431008 ,train acc: 0.817210 ,val loss : 0.493251 ,val acc : 0.797424\n",
      "[ ecpho : 0  iter :944 ]train loss : 0.386662 ,train acc: 0.827678 ,val loss : 0.490659 ,val acc : 0.797058\n",
      "[ ecpho : 0  iter :945 ]train loss : 0.404024 ,train acc: 0.829559 ,val loss : 0.503164 ,val acc : 0.794342\n",
      "[ ecpho : 0  iter :946 ]train loss : 0.366142 ,train acc: 0.836670 ,val loss : 0.490030 ,val acc : 0.793945\n",
      "[ ecpho : 0  iter :947 ]train loss : 0.442922 ,train acc: 0.805797 ,val loss : 0.505983 ,val acc : 0.792969\n",
      "[ ecpho : 0  iter :948 ]train loss : 0.412777 ,train acc: 0.800476 ,val loss : 0.494767 ,val acc : 0.793732\n",
      "[ ecpho : 0  iter :949 ]train loss : 0.388508 ,train acc: 0.829407 ,val loss : 0.498889 ,val acc : 0.793549\n",
      "[ ecpho : 0  iter :950 ]train loss : 0.452590 ,train acc: 0.808563 ,val loss : 0.491670 ,val acc : 0.796631\n",
      "[ ecpho : 0  iter :951 ]train loss : 0.460233 ,train acc: 0.811656 ,val loss : 0.485418 ,val acc : 0.796967\n",
      "[ ecpho : 0  iter :952 ]train loss : 0.525928 ,train acc: 0.760152 ,val loss : 0.488415 ,val acc : 0.795288\n",
      "[ ecpho : 0  iter :953 ]train loss : 0.393496 ,train acc: 0.825043 ,val loss : 0.484982 ,val acc : 0.799713\n",
      "[ ecpho : 0  iter :954 ]train loss : 0.410382 ,train acc: 0.824209 ,val loss : 0.487713 ,val acc : 0.796051\n",
      "[ ecpho : 0  iter :955 ]train loss : 0.409954 ,train acc: 0.820872 ,val loss : 0.496774 ,val acc : 0.793823\n",
      "[ ecpho : 0  iter :956 ]train loss : 0.408129 ,train acc: 0.830383 ,val loss : 0.487162 ,val acc : 0.793793\n",
      "[ ecpho : 0  iter :957 ]train loss : 0.475320 ,train acc: 0.806600 ,val loss : 0.492178 ,val acc : 0.796173\n",
      "[ ecpho : 0  iter :958 ]train loss : 0.481956 ,train acc: 0.787384 ,val loss : 0.494962 ,val acc : 0.795227\n",
      "[ ecpho : 0  iter :959 ]train loss : 0.379777 ,train acc: 0.830414 ,val loss : 0.493486 ,val acc : 0.796356\n",
      "[ ecpho : 0  iter :960 ]train loss : 0.500466 ,train acc: 0.804851 ,val loss : 0.496835 ,val acc : 0.793274\n",
      "[ ecpho : 0  iter :961 ]train loss : 0.394300 ,train acc: 0.830241 ,val loss : 0.498754 ,val acc : 0.792755\n",
      "[ ecpho : 0  iter :962 ]train loss : 0.444662 ,train acc: 0.809957 ,val loss : 0.491785 ,val acc : 0.797150\n",
      "[ ecpho : 0  iter :963 ]train loss : 0.476745 ,train acc: 0.807852 ,val loss : 0.491694 ,val acc : 0.797485\n",
      "[ ecpho : 0  iter :964 ]train loss : 0.476822 ,train acc: 0.763855 ,val loss : 0.487015 ,val acc : 0.800323\n",
      "[ ecpho : 0  iter :965 ]train loss : 0.480002 ,train acc: 0.813670 ,val loss : 0.494696 ,val acc : 0.798523\n",
      "[ ecpho : 0  iter :966 ]train loss : 0.391622 ,train acc: 0.819306 ,val loss : 0.496155 ,val acc : 0.795166\n",
      "[ ecpho : 0  iter :967 ]train loss : 0.402908 ,train acc: 0.827932 ,val loss : 0.499074 ,val acc : 0.794678\n",
      "[ ecpho : 0  iter :968 ]train loss : 0.515752 ,train acc: 0.785350 ,val loss : 0.489184 ,val acc : 0.793671\n",
      "[ ecpho : 0  iter :969 ]train loss : 0.411359 ,train acc: 0.827983 ,val loss : 0.493770 ,val acc : 0.792755\n",
      "[ ecpho : 0  iter :970 ]train loss : 0.364881 ,train acc: 0.835836 ,val loss : 0.497278 ,val acc : 0.795471\n",
      "[ ecpho : 0  iter :971 ]train loss : 0.404345 ,train acc: 0.821971 ,val loss : 0.493735 ,val acc : 0.795380\n",
      "[ ecpho : 0  iter :972 ]train loss : 0.411915 ,train acc: 0.826254 ,val loss : 0.496249 ,val acc : 0.793488\n",
      "[ ecpho : 0  iter :973 ]train loss : 0.404897 ,train acc: 0.825002 ,val loss : 0.489451 ,val acc : 0.795044\n",
      "[ ecpho : 0  iter :974 ]train loss : 0.523766 ,train acc: 0.746806 ,val loss : 0.500474 ,val acc : 0.793365\n",
      "[ ecpho : 0  iter :975 ]train loss : 0.447354 ,train acc: 0.818024 ,val loss : 0.495295 ,val acc : 0.793030\n",
      "[ ecpho : 0  iter :976 ]train loss : 0.423201 ,train acc: 0.804708 ,val loss : 0.494570 ,val acc : 0.794067\n",
      "[ ecpho : 0  iter :977 ]train loss : 0.482081 ,train acc: 0.809906 ,val loss : 0.486422 ,val acc : 0.793274\n",
      "[ ecpho : 0  iter :978 ]train loss : 0.525975 ,train acc: 0.788737 ,val loss : 0.489348 ,val acc : 0.793396\n",
      "[ ecpho : 0  iter :979 ]train loss : 0.406994 ,train acc: 0.824402 ,val loss : 0.497318 ,val acc : 0.793549\n",
      "[ ecpho : 0  iter :980 ]train loss : 0.400650 ,train acc: 0.826559 ,val loss : 0.493711 ,val acc : 0.794250\n",
      "[ ecpho : 0  iter :981 ]train loss : 0.400116 ,train acc: 0.830485 ,val loss : 0.493461 ,val acc : 0.794800\n",
      "[ ecpho : 0  iter :982 ]train loss : 0.426169 ,train acc: 0.811453 ,val loss : 0.490322 ,val acc : 0.797668\n",
      "[ ecpho : 0  iter :983 ]train loss : 0.481348 ,train acc: 0.802724 ,val loss : 0.491714 ,val acc : 0.798706\n",
      "[ ecpho : 0  iter :984 ]train loss : 0.412174 ,train acc: 0.825623 ,val loss : 0.492881 ,val acc : 0.796722\n",
      "[ ecpho : 0  iter :985 ]train loss : 0.398283 ,train acc: 0.825999 ,val loss : 0.494183 ,val acc : 0.793793\n",
      "[ ecpho : 0  iter :986 ]train loss : 0.364517 ,train acc: 0.838776 ,val loss : 0.485812 ,val acc : 0.798004\n",
      "[ ecpho : 0  iter :987 ]train loss : 0.399662 ,train acc: 0.821788 ,val loss : 0.492915 ,val acc : 0.795929\n",
      "[ ecpho : 0  iter :988 ]train loss : 0.440984 ,train acc: 0.817668 ,val loss : 0.492204 ,val acc : 0.794952\n",
      "[ ecpho : 0  iter :989 ]train loss : 0.435081 ,train acc: 0.797628 ,val loss : 0.497261 ,val acc : 0.796448\n",
      "[ ecpho : 0  iter :990 ]train loss : 0.427507 ,train acc: 0.821411 ,val loss : 0.493203 ,val acc : 0.794464\n",
      "[ ecpho : 0  iter :991 ]train loss : 0.387220 ,train acc: 0.829824 ,val loss : 0.489794 ,val acc : 0.794250\n",
      "[ ecpho : 0  iter :992 ]train loss : 0.411655 ,train acc: 0.825287 ,val loss : 0.489135 ,val acc : 0.796234\n",
      "[ ecpho : 0  iter :993 ]train loss : 0.500681 ,train acc: 0.801534 ,val loss : 0.496586 ,val acc : 0.795258\n",
      "[ ecpho : 0  iter :994 ]train loss : 0.440832 ,train acc: 0.817922 ,val loss : 0.494067 ,val acc : 0.797546\n",
      "[ ecpho : 0  iter :995 ]train loss : 0.384147 ,train acc: 0.832876 ,val loss : 0.493693 ,val acc : 0.797577\n",
      "[ ecpho : 0  iter :996 ]train loss : 0.439128 ,train acc: 0.819977 ,val loss : 0.487971 ,val acc : 0.794800\n",
      "[ ecpho : 0  iter :997 ]train loss : 0.443323 ,train acc: 0.811565 ,val loss : 0.493740 ,val acc : 0.793335\n",
      "[ ecpho : 0  iter :998 ]train loss : 0.389800 ,train acc: 0.830404 ,val loss : 0.491539 ,val acc : 0.798462\n",
      "[ ecpho : 0  iter :999 ]train loss : 0.436581 ,train acc: 0.782308 ,val loss : 0.490056 ,val acc : 0.797729\n",
      "[ ecpho : 0  iter :1000 ]train loss : 0.458282 ,train acc: 0.777832 ,val loss : 0.486603 ,val acc : 0.799469\n",
      "=============================================\n",
      "[ 0 ] average train loss : 0.526200 train acc : 0.767856\n",
      "[ ecpho : 1  iter :1 ]train loss : 0.410342 ,train acc: 0.823080 ,val loss : 0.486727 ,val acc : 0.797272\n",
      "[ ecpho : 1  iter :2 ]train loss : 0.457857 ,train acc: 0.791138 ,val loss : 0.483715 ,val acc : 0.794983\n",
      "[ ecpho : 1  iter :3 ]train loss : 0.440469 ,train acc: 0.818919 ,val loss : 0.491645 ,val acc : 0.793518\n",
      "[ ecpho : 1  iter :4 ]train loss : 0.429018 ,train acc: 0.820293 ,val loss : 0.495307 ,val acc : 0.797699\n",
      "[ ecpho : 1  iter :5 ]train loss : 0.396514 ,train acc: 0.829804 ,val loss : 0.489863 ,val acc : 0.796295\n",
      "[ ecpho : 1  iter :6 ]train loss : 0.371967 ,train acc: 0.836640 ,val loss : 0.492355 ,val acc : 0.790405\n",
      "[ ecpho : 1  iter :7 ]train loss : 0.401308 ,train acc: 0.827393 ,val loss : 0.489071 ,val acc : 0.795410\n",
      "[ ecpho : 1  iter :8 ]train loss : 0.407578 ,train acc: 0.825063 ,val loss : 0.487316 ,val acc : 0.797089\n",
      "[ ecpho : 1  iter :9 ]train loss : 0.456746 ,train acc: 0.788981 ,val loss : 0.496939 ,val acc : 0.793335\n",
      "[ ecpho : 1  iter :10 ]train loss : 0.386121 ,train acc: 0.835104 ,val loss : 0.490417 ,val acc : 0.795074\n",
      "[ ecpho : 1  iter :11 ]train loss : 0.426100 ,train acc: 0.812500 ,val loss : 0.486555 ,val acc : 0.796295\n",
      "[ ecpho : 1  iter :12 ]train loss : 0.472579 ,train acc: 0.768758 ,val loss : 0.491343 ,val acc : 0.797577\n",
      "[ ecpho : 1  iter :13 ]train loss : 0.416400 ,train acc: 0.826508 ,val loss : 0.491649 ,val acc : 0.792358\n",
      "[ ecpho : 1  iter :14 ]train loss : 0.358406 ,train acc: 0.834483 ,val loss : 0.485871 ,val acc : 0.794922\n",
      "[ ecpho : 1  iter :15 ]train loss : 0.420270 ,train acc: 0.820699 ,val loss : 0.492235 ,val acc : 0.795654\n",
      "[ ecpho : 1  iter :16 ]train loss : 0.445330 ,train acc: 0.817831 ,val loss : 0.501028 ,val acc : 0.791107\n",
      "[ ecpho : 1  iter :17 ]train loss : 0.412845 ,train acc: 0.814779 ,val loss : 0.492294 ,val acc : 0.793732\n",
      "[ ecpho : 1  iter :18 ]train loss : 0.494689 ,train acc: 0.801372 ,val loss : 0.504533 ,val acc : 0.792267\n",
      "[ ecpho : 1  iter :19 ]train loss : 0.418878 ,train acc: 0.808014 ,val loss : 0.491326 ,val acc : 0.792877\n",
      "[ ecpho : 1  iter :20 ]train loss : 0.369277 ,train acc: 0.831950 ,val loss : 0.494765 ,val acc : 0.793427\n",
      "[ ecpho : 1  iter :21 ]train loss : 0.430156 ,train acc: 0.819235 ,val loss : 0.483347 ,val acc : 0.799988\n",
      "[ ecpho : 1  iter :22 ]train loss : 0.424392 ,train acc: 0.823649 ,val loss : 0.493594 ,val acc : 0.797577\n",
      "[ ecpho : 1  iter :23 ]train loss : 0.374690 ,train acc: 0.833568 ,val loss : 0.482916 ,val acc : 0.797180\n",
      "[ ecpho : 1  iter :24 ]train loss : 0.444500 ,train acc: 0.818807 ,val loss : 0.489290 ,val acc : 0.797180\n",
      "[ ecpho : 1  iter :25 ]train loss : 0.423298 ,train acc: 0.800924 ,val loss : 0.491355 ,val acc : 0.796204\n",
      "[ ecpho : 1  iter :26 ]train loss : 0.420174 ,train acc: 0.811666 ,val loss : 0.496870 ,val acc : 0.795258\n",
      "[ ecpho : 1  iter :27 ]train loss : 0.400877 ,train acc: 0.820883 ,val loss : 0.491141 ,val acc : 0.795837\n",
      "[ ecpho : 1  iter :28 ]train loss : 0.412203 ,train acc: 0.822246 ,val loss : 0.492798 ,val acc : 0.793213\n",
      "[ ecpho : 1  iter :29 ]train loss : 0.515116 ,train acc: 0.782013 ,val loss : 0.487464 ,val acc : 0.797729\n",
      "[ ecpho : 1  iter :30 ]train loss : 0.399003 ,train acc: 0.810924 ,val loss : 0.485761 ,val acc : 0.801788\n",
      "[ ecpho : 1  iter :31 ]train loss : 0.422379 ,train acc: 0.813355 ,val loss : 0.490250 ,val acc : 0.796844\n",
      "[ ecpho : 1  iter :32 ]train loss : 0.415992 ,train acc: 0.820445 ,val loss : 0.488406 ,val acc : 0.799500\n",
      "[ ecpho : 1  iter :33 ]train loss : 0.402197 ,train acc: 0.827718 ,val loss : 0.499761 ,val acc : 0.794098\n",
      "[ ecpho : 1  iter :34 ]train loss : 0.414342 ,train acc: 0.807485 ,val loss : 0.492604 ,val acc : 0.797852\n",
      "[ ecpho : 1  iter :35 ]train loss : 0.358767 ,train acc: 0.836080 ,val loss : 0.481415 ,val acc : 0.796692\n",
      "[ ecpho : 1  iter :36 ]train loss : 0.504650 ,train acc: 0.773000 ,val loss : 0.482441 ,val acc : 0.794739\n",
      "[ ecpho : 1  iter :37 ]train loss : 0.403033 ,train acc: 0.822378 ,val loss : 0.491843 ,val acc : 0.798676\n",
      "[ ecpho : 1  iter :38 ]train loss : 0.380522 ,train acc: 0.838867 ,val loss : 0.487022 ,val acc : 0.796448\n",
      "[ ecpho : 1  iter :39 ]train loss : 0.421926 ,train acc: 0.825460 ,val loss : 0.489573 ,val acc : 0.795837\n",
      "[ ecpho : 1  iter :40 ]train loss : 0.420416 ,train acc: 0.820282 ,val loss : 0.486520 ,val acc : 0.797485\n",
      "[ ecpho : 1  iter :41 ]train loss : 0.380453 ,train acc: 0.827393 ,val loss : 0.489942 ,val acc : 0.796753\n",
      "[ ecpho : 1  iter :42 ]train loss : 0.374294 ,train acc: 0.834005 ,val loss : 0.493082 ,val acc : 0.795135\n",
      "[ ecpho : 1  iter :43 ]train loss : 0.388727 ,train acc: 0.836202 ,val loss : 0.485529 ,val acc : 0.797028\n",
      "[ ecpho : 1  iter :44 ]train loss : 0.389836 ,train acc: 0.826416 ,val loss : 0.489084 ,val acc : 0.794495\n",
      "[ ecpho : 1  iter :45 ]train loss : 0.419747 ,train acc: 0.815471 ,val loss : 0.487206 ,val acc : 0.795654\n",
      "[ ecpho : 1  iter :46 ]train loss : 0.485955 ,train acc: 0.818583 ,val loss : 0.485961 ,val acc : 0.797058\n",
      "[ ecpho : 1  iter :47 ]train loss : 0.396859 ,train acc: 0.829672 ,val loss : 0.491863 ,val acc : 0.796051\n",
      "[ ecpho : 1  iter :48 ]train loss : 0.420732 ,train acc: 0.805227 ,val loss : 0.483203 ,val acc : 0.796387\n",
      "[ ecpho : 1  iter :49 ]train loss : 0.451435 ,train acc: 0.807465 ,val loss : 0.494311 ,val acc : 0.795532\n",
      "[ ecpho : 1  iter :50 ]train loss : 0.439420 ,train acc: 0.817231 ,val loss : 0.482564 ,val acc : 0.798492\n",
      "[ ecpho : 1  iter :51 ]train loss : 0.394298 ,train acc: 0.825918 ,val loss : 0.491651 ,val acc : 0.794830\n",
      "[ ecpho : 1  iter :52 ]train loss : 0.418395 ,train acc: 0.804952 ,val loss : 0.478614 ,val acc : 0.798401\n",
      "[ ecpho : 1  iter :53 ]train loss : 0.505989 ,train acc: 0.783010 ,val loss : 0.479985 ,val acc : 0.800140\n",
      "[ ecpho : 1  iter :54 ]train loss : 0.399854 ,train acc: 0.833954 ,val loss : 0.486101 ,val acc : 0.795990\n",
      "[ ecpho : 1  iter :55 ]train loss : 0.385478 ,train acc: 0.833822 ,val loss : 0.484489 ,val acc : 0.795654\n",
      "[ ecpho : 1  iter :56 ]train loss : 0.446200 ,train acc: 0.796804 ,val loss : 0.490330 ,val acc : 0.794342\n",
      "[ ecpho : 1  iter :57 ]train loss : 0.368885 ,train acc: 0.819794 ,val loss : 0.487342 ,val acc : 0.794250\n",
      "[ ecpho : 1  iter :58 ]train loss : 0.347289 ,train acc: 0.841431 ,val loss : 0.485344 ,val acc : 0.796265\n",
      "[ ecpho : 1  iter :59 ]train loss : 0.456925 ,train acc: 0.760071 ,val loss : 0.476596 ,val acc : 0.799500\n",
      "[ ecpho : 1  iter :60 ]train loss : 0.403644 ,train acc: 0.826579 ,val loss : 0.486618 ,val acc : 0.793518\n",
      "[ ecpho : 1  iter :61 ]train loss : 0.373496 ,train acc: 0.832825 ,val loss : 0.484001 ,val acc : 0.798431\n",
      "[ ecpho : 1  iter :62 ]train loss : 0.482202 ,train acc: 0.796041 ,val loss : 0.476296 ,val acc : 0.799622\n",
      "[ ecpho : 1  iter :63 ]train loss : 0.403287 ,train acc: 0.823405 ,val loss : 0.482783 ,val acc : 0.798187\n",
      "[ ecpho : 1  iter :64 ]train loss : 0.408829 ,train acc: 0.825725 ,val loss : 0.483856 ,val acc : 0.799652\n",
      "[ ecpho : 1  iter :65 ]train loss : 0.625622 ,train acc: 0.766531 ,val loss : 0.478355 ,val acc : 0.800110\n",
      "[ ecpho : 1  iter :66 ]train loss : 0.404716 ,train acc: 0.826660 ,val loss : 0.490634 ,val acc : 0.795013\n",
      "[ ecpho : 1  iter :67 ]train loss : 0.393164 ,train acc: 0.831940 ,val loss : 0.487190 ,val acc : 0.795105\n",
      "[ ecpho : 1  iter :68 ]train loss : 0.393095 ,train acc: 0.828909 ,val loss : 0.487762 ,val acc : 0.796173\n",
      "[ ecpho : 1  iter :69 ]train loss : 0.484876 ,train acc: 0.791199 ,val loss : 0.488236 ,val acc : 0.797180\n",
      "[ ecpho : 1  iter :70 ]train loss : 0.407176 ,train acc: 0.811493 ,val loss : 0.477274 ,val acc : 0.801392\n",
      "[ ecpho : 1  iter :71 ]train loss : 0.401622 ,train acc: 0.821686 ,val loss : 0.477079 ,val acc : 0.800171\n",
      "[ ecpho : 1  iter :72 ]train loss : 0.396201 ,train acc: 0.783519 ,val loss : 0.487921 ,val acc : 0.798279\n",
      "[ ecpho : 1  iter :73 ]train loss : 0.404793 ,train acc: 0.794525 ,val loss : 0.483385 ,val acc : 0.794617\n",
      "[ ecpho : 1  iter :74 ]train loss : 0.392251 ,train acc: 0.830241 ,val loss : 0.484702 ,val acc : 0.794861\n",
      "[ ecpho : 1  iter :75 ]train loss : 0.432533 ,train acc: 0.782441 ,val loss : 0.488671 ,val acc : 0.797607\n",
      "[ ecpho : 1  iter :76 ]train loss : 0.379216 ,train acc: 0.828227 ,val loss : 0.483337 ,val acc : 0.798523\n",
      "[ ecpho : 1  iter :77 ]train loss : 0.483544 ,train acc: 0.780762 ,val loss : 0.483523 ,val acc : 0.798279\n",
      "[ ecpho : 1  iter :78 ]train loss : 0.442012 ,train acc: 0.821900 ,val loss : 0.479264 ,val acc : 0.797363\n",
      "[ ecpho : 1  iter :79 ]train loss : 0.436012 ,train acc: 0.821330 ,val loss : 0.479540 ,val acc : 0.800812\n",
      "[ ecpho : 1  iter :80 ]train loss : 0.384781 ,train acc: 0.831808 ,val loss : 0.485178 ,val acc : 0.798553\n",
      "[ ecpho : 1  iter :81 ]train loss : 0.378923 ,train acc: 0.829122 ,val loss : 0.485350 ,val acc : 0.793671\n",
      "[ ecpho : 1  iter :82 ]train loss : 0.391885 ,train acc: 0.823273 ,val loss : 0.488668 ,val acc : 0.798309\n",
      "[ ecpho : 1  iter :83 ]train loss : 0.503434 ,train acc: 0.794505 ,val loss : 0.483143 ,val acc : 0.796936\n",
      "[ ecpho : 1  iter :84 ]train loss : 0.386488 ,train acc: 0.837118 ,val loss : 0.478103 ,val acc : 0.798798\n",
      "[ ecpho : 1  iter :85 ]train loss : 0.423398 ,train acc: 0.811158 ,val loss : 0.481153 ,val acc : 0.798553\n",
      "[ ecpho : 1  iter :86 ]train loss : 0.377485 ,train acc: 0.836253 ,val loss : 0.489277 ,val acc : 0.798767\n",
      "[ ecpho : 1  iter :87 ]train loss : 0.438264 ,train acc: 0.791382 ,val loss : 0.480647 ,val acc : 0.797363\n",
      "[ ecpho : 1  iter :88 ]train loss : 0.386828 ,train acc: 0.834514 ,val loss : 0.476367 ,val acc : 0.798584\n",
      "[ ecpho : 1  iter :89 ]train loss : 0.390823 ,train acc: 0.838959 ,val loss : 0.484201 ,val acc : 0.797607\n",
      "[ ecpho : 1  iter :90 ]train loss : 0.346421 ,train acc: 0.839814 ,val loss : 0.484277 ,val acc : 0.798309\n",
      "[ ecpho : 1  iter :91 ]train loss : 0.518199 ,train acc: 0.806488 ,val loss : 0.486655 ,val acc : 0.798431\n",
      "[ ecpho : 1  iter :92 ]train loss : 0.414570 ,train acc: 0.829600 ,val loss : 0.486444 ,val acc : 0.797546\n",
      "[ ecpho : 1  iter :93 ]train loss : 0.389687 ,train acc: 0.827067 ,val loss : 0.486633 ,val acc : 0.794281\n",
      "[ ecpho : 1  iter :94 ]train loss : 0.370523 ,train acc: 0.838318 ,val loss : 0.487123 ,val acc : 0.799652\n",
      "[ ecpho : 1  iter :95 ]train loss : 0.427832 ,train acc: 0.818970 ,val loss : 0.478310 ,val acc : 0.798340\n",
      "[ ecpho : 1  iter :96 ]train loss : 0.380732 ,train acc: 0.829071 ,val loss : 0.482553 ,val acc : 0.796539\n",
      "[ ecpho : 1  iter :97 ]train loss : 0.369350 ,train acc: 0.830190 ,val loss : 0.487734 ,val acc : 0.798859\n",
      "[ ecpho : 1  iter :98 ]train loss : 0.414243 ,train acc: 0.824127 ,val loss : 0.485071 ,val acc : 0.798309\n",
      "[ ecpho : 1  iter :99 ]train loss : 0.368664 ,train acc: 0.836080 ,val loss : 0.486488 ,val acc : 0.795349\n",
      "[ ecpho : 1  iter :100 ]train loss : 0.475764 ,train acc: 0.780874 ,val loss : 0.485218 ,val acc : 0.797546\n",
      "[ ecpho : 1  iter :101 ]train loss : 0.385716 ,train acc: 0.832011 ,val loss : 0.475168 ,val acc : 0.801239\n",
      "[ ecpho : 1  iter :102 ]train loss : 0.375987 ,train acc: 0.826955 ,val loss : 0.477194 ,val acc : 0.798004\n",
      "[ ecpho : 1  iter :103 ]train loss : 0.378448 ,train acc: 0.835612 ,val loss : 0.483198 ,val acc : 0.795654\n",
      "[ ecpho : 1  iter :104 ]train loss : 0.389493 ,train acc: 0.832255 ,val loss : 0.482391 ,val acc : 0.797272\n",
      "[ ecpho : 1  iter :105 ]train loss : 0.360756 ,train acc: 0.839284 ,val loss : 0.480927 ,val acc : 0.795929\n",
      "[ ecpho : 1  iter :106 ]train loss : 0.384883 ,train acc: 0.826467 ,val loss : 0.475021 ,val acc : 0.799591\n",
      "[ ecpho : 1  iter :107 ]train loss : 0.340657 ,train acc: 0.842173 ,val loss : 0.474451 ,val acc : 0.797211\n",
      "[ ecpho : 1  iter :108 ]train loss : 0.354216 ,train acc: 0.842051 ,val loss : 0.483047 ,val acc : 0.798553\n",
      "[ ecpho : 1  iter :109 ]train loss : 0.459751 ,train acc: 0.796397 ,val loss : 0.487232 ,val acc : 0.797577\n",
      "[ ecpho : 1  iter :110 ]train loss : 0.393556 ,train acc: 0.816844 ,val loss : 0.480182 ,val acc : 0.798950\n",
      "[ ecpho : 1  iter :111 ]train loss : 0.368796 ,train acc: 0.837016 ,val loss : 0.482355 ,val acc : 0.798523\n",
      "[ ecpho : 1  iter :112 ]train loss : 0.531878 ,train acc: 0.799785 ,val loss : 0.470274 ,val acc : 0.796906\n",
      "[ ecpho : 1  iter :113 ]train loss : 0.356021 ,train acc: 0.840810 ,val loss : 0.488840 ,val acc : 0.796173\n",
      "[ ecpho : 1  iter :114 ]train loss : 0.461347 ,train acc: 0.808930 ,val loss : 0.478642 ,val acc : 0.799316\n",
      "[ ecpho : 1  iter :115 ]train loss : 0.405712 ,train acc: 0.789653 ,val loss : 0.485195 ,val acc : 0.798676\n",
      "[ ecpho : 1  iter :116 ]train loss : 0.408153 ,train acc: 0.828359 ,val loss : 0.476043 ,val acc : 0.798828\n",
      "[ ecpho : 1  iter :117 ]train loss : 0.440512 ,train acc: 0.821452 ,val loss : 0.474898 ,val acc : 0.797699\n",
      "[ ecpho : 1  iter :118 ]train loss : 0.392737 ,train acc: 0.831604 ,val loss : 0.483261 ,val acc : 0.796783\n",
      "[ ecpho : 1  iter :119 ]train loss : 0.361258 ,train acc: 0.833242 ,val loss : 0.481946 ,val acc : 0.795441\n",
      "[ ecpho : 1  iter :120 ]train loss : 0.428132 ,train acc: 0.818075 ,val loss : 0.481598 ,val acc : 0.796692\n",
      "[ ecpho : 1  iter :121 ]train loss : 0.353668 ,train acc: 0.842814 ,val loss : 0.480762 ,val acc : 0.797699\n",
      "[ ecpho : 1  iter :122 ]train loss : 0.363504 ,train acc: 0.834412 ,val loss : 0.480558 ,val acc : 0.799561\n",
      "[ ecpho : 1  iter :123 ]train loss : 0.370305 ,train acc: 0.838206 ,val loss : 0.480190 ,val acc : 0.797852\n",
      "[ ecpho : 1  iter :124 ]train loss : 0.373301 ,train acc: 0.833618 ,val loss : 0.482192 ,val acc : 0.795868\n",
      "[ ecpho : 1  iter :125 ]train loss : 0.345872 ,train acc: 0.845103 ,val loss : 0.484456 ,val acc : 0.796814\n",
      "[ ecpho : 1  iter :126 ]train loss : 0.425207 ,train acc: 0.768758 ,val loss : 0.476093 ,val acc : 0.796783\n",
      "[ ecpho : 1  iter :127 ]train loss : 0.412676 ,train acc: 0.808737 ,val loss : 0.479049 ,val acc : 0.799988\n",
      "[ ecpho : 1  iter :128 ]train loss : 0.355191 ,train acc: 0.841339 ,val loss : 0.485592 ,val acc : 0.795288\n",
      "[ ecpho : 1  iter :129 ]train loss : 0.391369 ,train acc: 0.824331 ,val loss : 0.481455 ,val acc : 0.796326\n",
      "[ ecpho : 1  iter :130 ]train loss : 0.389830 ,train acc: 0.812256 ,val loss : 0.477516 ,val acc : 0.799713\n",
      "[ ecpho : 1  iter :131 ]train loss : 0.372013 ,train acc: 0.829244 ,val loss : 0.471348 ,val acc : 0.800110\n",
      "[ ecpho : 1  iter :132 ]train loss : 0.375592 ,train acc: 0.829560 ,val loss : 0.481242 ,val acc : 0.793884\n",
      "[ ecpho : 1  iter :133 ]train loss : 0.373785 ,train acc: 0.832805 ,val loss : 0.486532 ,val acc : 0.797943\n",
      "[ ecpho : 1  iter :134 ]train loss : 0.465053 ,train acc: 0.786092 ,val loss : 0.472266 ,val acc : 0.801666\n",
      "[ ecpho : 1  iter :135 ]train loss : 0.359942 ,train acc: 0.840739 ,val loss : 0.487976 ,val acc : 0.796326\n",
      "[ ecpho : 1  iter :136 ]train loss : 0.487061 ,train acc: 0.767497 ,val loss : 0.473870 ,val acc : 0.799683\n",
      "[ ecpho : 1  iter :137 ]train loss : 0.358649 ,train acc: 0.839071 ,val loss : 0.471646 ,val acc : 0.799622\n",
      "[ ecpho : 1  iter :138 ]train loss : 0.374903 ,train acc: 0.836568 ,val loss : 0.477741 ,val acc : 0.798431\n",
      "[ ecpho : 1  iter :139 ]train loss : 0.390972 ,train acc: 0.821432 ,val loss : 0.485355 ,val acc : 0.798004\n",
      "[ ecpho : 1  iter :140 ]train loss : 0.364786 ,train acc: 0.840607 ,val loss : 0.483212 ,val acc : 0.796509\n",
      "[ ecpho : 1  iter :141 ]train loss : 0.375757 ,train acc: 0.821523 ,val loss : 0.475398 ,val acc : 0.800140\n",
      "[ ecpho : 1  iter :142 ]train loss : 0.351486 ,train acc: 0.843435 ,val loss : 0.471648 ,val acc : 0.799347\n",
      "[ ecpho : 1  iter :143 ]train loss : 0.373676 ,train acc: 0.835978 ,val loss : 0.470110 ,val acc : 0.800293\n",
      "[ ecpho : 1  iter :144 ]train loss : 0.479281 ,train acc: 0.810374 ,val loss : 0.471286 ,val acc : 0.801453\n",
      "[ ecpho : 1  iter :145 ]train loss : 0.420893 ,train acc: 0.821208 ,val loss : 0.478778 ,val acc : 0.799438\n",
      "[ ecpho : 1  iter :146 ]train loss : 0.437410 ,train acc: 0.823039 ,val loss : 0.476903 ,val acc : 0.796631\n",
      "[ ecpho : 1  iter :147 ]train loss : 0.485325 ,train acc: 0.803304 ,val loss : 0.476918 ,val acc : 0.794312\n",
      "[ ecpho : 1  iter :148 ]train loss : 0.395593 ,train acc: 0.821330 ,val loss : 0.476317 ,val acc : 0.798523\n",
      "[ ecpho : 1  iter :149 ]train loss : 0.355634 ,train acc: 0.842926 ,val loss : 0.477046 ,val acc : 0.800262\n",
      "[ ecpho : 1  iter :150 ]train loss : 0.371606 ,train acc: 0.833283 ,val loss : 0.484111 ,val acc : 0.796448\n",
      "[ ecpho : 1  iter :151 ]train loss : 0.449604 ,train acc: 0.809123 ,val loss : 0.475659 ,val acc : 0.799408\n",
      "[ ecpho : 1  iter :152 ]train loss : 0.347182 ,train acc: 0.842041 ,val loss : 0.484943 ,val acc : 0.798523\n",
      "[ ecpho : 1  iter :153 ]train loss : 0.335961 ,train acc: 0.846110 ,val loss : 0.478557 ,val acc : 0.799652\n",
      "[ ecpho : 1  iter :154 ]train loss : 0.413790 ,train acc: 0.827108 ,val loss : 0.482336 ,val acc : 0.799194\n",
      "[ ecpho : 1  iter :155 ]train loss : 0.357083 ,train acc: 0.842906 ,val loss : 0.469438 ,val acc : 0.801453\n",
      "[ ecpho : 1  iter :156 ]train loss : 0.440998 ,train acc: 0.824982 ,val loss : 0.477193 ,val acc : 0.798767\n",
      "[ ecpho : 1  iter :157 ]train loss : 0.440506 ,train acc: 0.813619 ,val loss : 0.471542 ,val acc : 0.803650\n",
      "[ ecpho : 1  iter :158 ]train loss : 0.438244 ,train acc: 0.819285 ,val loss : 0.487413 ,val acc : 0.796082\n",
      "[ ecpho : 1  iter :159 ]train loss : 0.358793 ,train acc: 0.841482 ,val loss : 0.483963 ,val acc : 0.796173\n",
      "[ ecpho : 1  iter :160 ]train loss : 0.381952 ,train acc: 0.835968 ,val loss : 0.482378 ,val acc : 0.798370\n",
      "[ ecpho : 1  iter :161 ]train loss : 0.509285 ,train acc: 0.808960 ,val loss : 0.478230 ,val acc : 0.798920\n",
      "[ ecpho : 1  iter :162 ]train loss : 0.381958 ,train acc: 0.827383 ,val loss : 0.477987 ,val acc : 0.799652\n",
      "[ ecpho : 1  iter :163 ]train loss : 0.401895 ,train acc: 0.807333 ,val loss : 0.478372 ,val acc : 0.799530\n",
      "[ ecpho : 1  iter :164 ]train loss : 0.358058 ,train acc: 0.839956 ,val loss : 0.474962 ,val acc : 0.797638\n",
      "[ ecpho : 1  iter :165 ]train loss : 0.385794 ,train acc: 0.829356 ,val loss : 0.478028 ,val acc : 0.798248\n",
      "[ ecpho : 1  iter :166 ]train loss : 0.373152 ,train acc: 0.834483 ,val loss : 0.479928 ,val acc : 0.795105\n",
      "[ ecpho : 1  iter :167 ]train loss : 0.428715 ,train acc: 0.825460 ,val loss : 0.483881 ,val acc : 0.796600\n",
      "[ ecpho : 1  iter :168 ]train loss : 0.491636 ,train acc: 0.768677 ,val loss : 0.481040 ,val acc : 0.796051\n",
      "[ ecpho : 1  iter :169 ]train loss : 0.368279 ,train acc: 0.837667 ,val loss : 0.478965 ,val acc : 0.794098\n",
      "[ ecpho : 1  iter :170 ]train loss : 0.428294 ,train acc: 0.823782 ,val loss : 0.478756 ,val acc : 0.803375\n",
      "[ ecpho : 1  iter :171 ]train loss : 0.373193 ,train acc: 0.840617 ,val loss : 0.476153 ,val acc : 0.800049\n",
      "[ ecpho : 1  iter :172 ]train loss : 0.404284 ,train acc: 0.808665 ,val loss : 0.477572 ,val acc : 0.797485\n",
      "[ ecpho : 1  iter :173 ]train loss : 0.357191 ,train acc: 0.841410 ,val loss : 0.472041 ,val acc : 0.799866\n",
      "[ ecpho : 1  iter :174 ]train loss : 0.456217 ,train acc: 0.727783 ,val loss : 0.473959 ,val acc : 0.798798\n",
      "[ ecpho : 1  iter :175 ]train loss : 0.345918 ,train acc: 0.840047 ,val loss : 0.474826 ,val acc : 0.797638\n",
      "[ ecpho : 1  iter :176 ]train loss : 0.429417 ,train acc: 0.828502 ,val loss : 0.477685 ,val acc : 0.798523\n",
      "[ ecpho : 1  iter :177 ]train loss : 0.368809 ,train acc: 0.827484 ,val loss : 0.477230 ,val acc : 0.799133\n",
      "[ ecpho : 1  iter :178 ]train loss : 0.380755 ,train acc: 0.835104 ,val loss : 0.469554 ,val acc : 0.799591\n",
      "[ ecpho : 1  iter :179 ]train loss : 0.393744 ,train acc: 0.831218 ,val loss : 0.472137 ,val acc : 0.800537\n",
      "[ ecpho : 1  iter :180 ]train loss : 0.377750 ,train acc: 0.832896 ,val loss : 0.481414 ,val acc : 0.800049\n",
      "[ ecpho : 1  iter :181 ]train loss : 0.328428 ,train acc: 0.845601 ,val loss : 0.477652 ,val acc : 0.800049\n",
      "[ ecpho : 1  iter :182 ]train loss : 0.383218 ,train acc: 0.832815 ,val loss : 0.475338 ,val acc : 0.796021\n",
      "[ ecpho : 1  iter :183 ]train loss : 0.392453 ,train acc: 0.824341 ,val loss : 0.474155 ,val acc : 0.802246\n",
      "[ ecpho : 1  iter :184 ]train loss : 0.377920 ,train acc: 0.822418 ,val loss : 0.478441 ,val acc : 0.796478\n",
      "[ ecpho : 1  iter :185 ]train loss : 0.391068 ,train acc: 0.832896 ,val loss : 0.469477 ,val acc : 0.802582\n",
      "[ ecpho : 1  iter :186 ]train loss : 0.410780 ,train acc: 0.796570 ,val loss : 0.473753 ,val acc : 0.799713\n",
      "[ ecpho : 1  iter :187 ]train loss : 0.452605 ,train acc: 0.810150 ,val loss : 0.467703 ,val acc : 0.803192\n",
      "[ ecpho : 1  iter :188 ]train loss : 0.453673 ,train acc: 0.818136 ,val loss : 0.473510 ,val acc : 0.799622\n",
      "[ ecpho : 1  iter :189 ]train loss : 0.352896 ,train acc: 0.840820 ,val loss : 0.466786 ,val acc : 0.803314\n",
      "[ ecpho : 1  iter :190 ]train loss : 0.368932 ,train acc: 0.833751 ,val loss : 0.478543 ,val acc : 0.796997\n",
      "[ ecpho : 1  iter :191 ]train loss : 0.423160 ,train acc: 0.815125 ,val loss : 0.474665 ,val acc : 0.800598\n",
      "[ ecpho : 1  iter :192 ]train loss : 0.469148 ,train acc: 0.771800 ,val loss : 0.472774 ,val acc : 0.798065\n",
      "[ ecpho : 1  iter :193 ]train loss : 0.365234 ,train acc: 0.831197 ,val loss : 0.463818 ,val acc : 0.802979\n",
      "[ ecpho : 1  iter :194 ]train loss : 0.416997 ,train acc: 0.832367 ,val loss : 0.469368 ,val acc : 0.799042\n",
      "[ ecpho : 1  iter :195 ]train loss : 0.421376 ,train acc: 0.814443 ,val loss : 0.469352 ,val acc : 0.801178\n",
      "[ ecpho : 1  iter :196 ]train loss : 0.398028 ,train acc: 0.802551 ,val loss : 0.477453 ,val acc : 0.799316\n",
      "[ ecpho : 1  iter :197 ]train loss : 0.384694 ,train acc: 0.825674 ,val loss : 0.474914 ,val acc : 0.798279\n",
      "[ ecpho : 1  iter :198 ]train loss : 0.385348 ,train acc: 0.835399 ,val loss : 0.467125 ,val acc : 0.798218\n",
      "[ ecpho : 1  iter :199 ]train loss : 0.402183 ,train acc: 0.824839 ,val loss : 0.472675 ,val acc : 0.797974\n",
      "[ ecpho : 1  iter :200 ]train loss : 0.427641 ,train acc: 0.793773 ,val loss : 0.480759 ,val acc : 0.793884\n",
      "[ ecpho : 1  iter :201 ]train loss : 0.383275 ,train acc: 0.821483 ,val loss : 0.476796 ,val acc : 0.799377\n",
      "[ ecpho : 1  iter :202 ]train loss : 0.473025 ,train acc: 0.818217 ,val loss : 0.477458 ,val acc : 0.798492\n",
      "[ ecpho : 1  iter :203 ]train loss : 0.379855 ,train acc: 0.838857 ,val loss : 0.476144 ,val acc : 0.793182\n",
      "[ ecpho : 1  iter :204 ]train loss : 0.441579 ,train acc: 0.820048 ,val loss : 0.468357 ,val acc : 0.800690\n",
      "[ ecpho : 1  iter :205 ]train loss : 0.419105 ,train acc: 0.801585 ,val loss : 0.475935 ,val acc : 0.803223\n",
      "[ ecpho : 1  iter :206 ]train loss : 0.393553 ,train acc: 0.804291 ,val loss : 0.474235 ,val acc : 0.800659\n",
      "[ ecpho : 1  iter :207 ]train loss : 0.345363 ,train acc: 0.843475 ,val loss : 0.470852 ,val acc : 0.802521\n",
      "[ ecpho : 1  iter :208 ]train loss : 0.380844 ,train acc: 0.838521 ,val loss : 0.474613 ,val acc : 0.803040\n",
      "[ ecpho : 1  iter :209 ]train loss : 0.375123 ,train acc: 0.829539 ,val loss : 0.469263 ,val acc : 0.800262\n",
      "[ ecpho : 1  iter :210 ]train loss : 0.367436 ,train acc: 0.832510 ,val loss : 0.479160 ,val acc : 0.797668\n",
      "[ ecpho : 1  iter :211 ]train loss : 0.379913 ,train acc: 0.826915 ,val loss : 0.471866 ,val acc : 0.799988\n",
      "[ ecpho : 1  iter :212 ]train loss : 0.477465 ,train acc: 0.806061 ,val loss : 0.477701 ,val acc : 0.797394\n",
      "[ ecpho : 1  iter :213 ]train loss : 0.392567 ,train acc: 0.822500 ,val loss : 0.463839 ,val acc : 0.800079\n",
      "[ ecpho : 1  iter :214 ]train loss : 0.344731 ,train acc: 0.845398 ,val loss : 0.470253 ,val acc : 0.798096\n",
      "[ ecpho : 1  iter :215 ]train loss : 0.350766 ,train acc: 0.840200 ,val loss : 0.467611 ,val acc : 0.804657\n",
      "[ ecpho : 1  iter :216 ]train loss : 0.437284 ,train acc: 0.825094 ,val loss : 0.473956 ,val acc : 0.800262\n",
      "[ ecpho : 1  iter :217 ]train loss : 0.364372 ,train acc: 0.839254 ,val loss : 0.481439 ,val acc : 0.798859\n",
      "[ ecpho : 1  iter :218 ]train loss : 0.456139 ,train acc: 0.806671 ,val loss : 0.478872 ,val acc : 0.794647\n",
      "[ ecpho : 1  iter :219 ]train loss : 0.377570 ,train acc: 0.822785 ,val loss : 0.480098 ,val acc : 0.796051\n",
      "[ ecpho : 1  iter :220 ]train loss : 0.385277 ,train acc: 0.832265 ,val loss : 0.475240 ,val acc : 0.796875\n",
      "[ ecpho : 1  iter :221 ]train loss : 0.373026 ,train acc: 0.827149 ,val loss : 0.474589 ,val acc : 0.799774\n",
      "[ ecpho : 1  iter :222 ]train loss : 0.575151 ,train acc: 0.737102 ,val loss : 0.472395 ,val acc : 0.799225\n",
      "[ ecpho : 1  iter :223 ]train loss : 0.331797 ,train acc: 0.844910 ,val loss : 0.474195 ,val acc : 0.797363\n",
      "[ ecpho : 1  iter :224 ]train loss : 0.379243 ,train acc: 0.820404 ,val loss : 0.469125 ,val acc : 0.801270\n",
      "[ ecpho : 1  iter :225 ]train loss : 0.373663 ,train acc: 0.829946 ,val loss : 0.470782 ,val acc : 0.801880\n",
      "[ ecpho : 1  iter :226 ]train loss : 0.398600 ,train acc: 0.821310 ,val loss : 0.472859 ,val acc : 0.796967\n",
      "[ ecpho : 1  iter :227 ]train loss : 0.450131 ,train acc: 0.807211 ,val loss : 0.467037 ,val acc : 0.800812\n",
      "[ ecpho : 1  iter :228 ]train loss : 0.411734 ,train acc: 0.812073 ,val loss : 0.468774 ,val acc : 0.802917\n",
      "[ ecpho : 1  iter :229 ]train loss : 0.390885 ,train acc: 0.828176 ,val loss : 0.471761 ,val acc : 0.799103\n",
      "[ ecpho : 1  iter :230 ]train loss : 0.378320 ,train acc: 0.826518 ,val loss : 0.475912 ,val acc : 0.795624\n",
      "[ ecpho : 1  iter :231 ]train loss : 0.374485 ,train acc: 0.834900 ,val loss : 0.476239 ,val acc : 0.798004\n",
      "[ ecpho : 1  iter :232 ]train loss : 0.379911 ,train acc: 0.835612 ,val loss : 0.466786 ,val acc : 0.802521\n",
      "[ ecpho : 1  iter :233 ]train loss : 0.459941 ,train acc: 0.789816 ,val loss : 0.468261 ,val acc : 0.800598\n",
      "[ ecpho : 1  iter :234 ]train loss : 0.401760 ,train acc: 0.835185 ,val loss : 0.471542 ,val acc : 0.800385\n",
      "[ ecpho : 1  iter :235 ]train loss : 0.372547 ,train acc: 0.836599 ,val loss : 0.465191 ,val acc : 0.798340\n",
      "[ ecpho : 1  iter :236 ]train loss : 0.388640 ,train acc: 0.818197 ,val loss : 0.469477 ,val acc : 0.800690\n",
      "[ ecpho : 1  iter :237 ]train loss : 0.569350 ,train acc: 0.778138 ,val loss : 0.477660 ,val acc : 0.797302\n",
      "[ ecpho : 1  iter :238 ]train loss : 0.438358 ,train acc: 0.827647 ,val loss : 0.470735 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :239 ]train loss : 0.456279 ,train acc: 0.806448 ,val loss : 0.469391 ,val acc : 0.801971\n",
      "[ ecpho : 1  iter :240 ]train loss : 0.426580 ,train acc: 0.820852 ,val loss : 0.471491 ,val acc : 0.801208\n",
      "[ ecpho : 1  iter :241 ]train loss : 0.352881 ,train acc: 0.841421 ,val loss : 0.475093 ,val acc : 0.798096\n",
      "[ ecpho : 1  iter :242 ]train loss : 0.354693 ,train acc: 0.842804 ,val loss : 0.468957 ,val acc : 0.800842\n",
      "[ ecpho : 1  iter :243 ]train loss : 0.392861 ,train acc: 0.828034 ,val loss : 0.472163 ,val acc : 0.801727\n",
      "[ ecpho : 1  iter :244 ]train loss : 0.403522 ,train acc: 0.830180 ,val loss : 0.469409 ,val acc : 0.801117\n",
      "[ ecpho : 1  iter :245 ]train loss : 0.356429 ,train acc: 0.835409 ,val loss : 0.475244 ,val acc : 0.797424\n",
      "[ ecpho : 1  iter :246 ]train loss : 0.359016 ,train acc: 0.840892 ,val loss : 0.471258 ,val acc : 0.800507\n",
      "[ ecpho : 1  iter :247 ]train loss : 0.360663 ,train acc: 0.841858 ,val loss : 0.463634 ,val acc : 0.801270\n",
      "[ ecpho : 1  iter :248 ]train loss : 0.350805 ,train acc: 0.840434 ,val loss : 0.471736 ,val acc : 0.798004\n",
      "[ ecpho : 1  iter :249 ]train loss : 0.352884 ,train acc: 0.838847 ,val loss : 0.467075 ,val acc : 0.799927\n",
      "[ ecpho : 1  iter :250 ]train loss : 0.415790 ,train acc: 0.823171 ,val loss : 0.468742 ,val acc : 0.800354\n",
      "[ ecpho : 1  iter :251 ]train loss : 0.450937 ,train acc: 0.816264 ,val loss : 0.465082 ,val acc : 0.801880\n",
      "[ ecpho : 1  iter :252 ]train loss : 0.436038 ,train acc: 0.821472 ,val loss : 0.472136 ,val acc : 0.801086\n",
      "[ ecpho : 1  iter :253 ]train loss : 0.478912 ,train acc: 0.782227 ,val loss : 0.474164 ,val acc : 0.799622\n",
      "[ ecpho : 1  iter :254 ]train loss : 0.384019 ,train acc: 0.825704 ,val loss : 0.466305 ,val acc : 0.802429\n",
      "[ ecpho : 1  iter :255 ]train loss : 0.416805 ,train acc: 0.798177 ,val loss : 0.464300 ,val acc : 0.799927\n",
      "[ ecpho : 1  iter :256 ]train loss : 0.352683 ,train acc: 0.839162 ,val loss : 0.470130 ,val acc : 0.802155\n",
      "[ ecpho : 1  iter :257 ]train loss : 0.502684 ,train acc: 0.812897 ,val loss : 0.465573 ,val acc : 0.801331\n",
      "[ ecpho : 1  iter :258 ]train loss : 0.459016 ,train acc: 0.808543 ,val loss : 0.463005 ,val acc : 0.800812\n",
      "[ ecpho : 1  iter :259 ]train loss : 0.368212 ,train acc: 0.832774 ,val loss : 0.477401 ,val acc : 0.800018\n",
      "[ ecpho : 1  iter :260 ]train loss : 0.393563 ,train acc: 0.835887 ,val loss : 0.466998 ,val acc : 0.802887\n",
      "[ ecpho : 1  iter :261 ]train loss : 0.387632 ,train acc: 0.823446 ,val loss : 0.470986 ,val acc : 0.800018\n",
      "[ ecpho : 1  iter :262 ]train loss : 0.396981 ,train acc: 0.810181 ,val loss : 0.463783 ,val acc : 0.800110\n",
      "[ ecpho : 1  iter :263 ]train loss : 0.456721 ,train acc: 0.818451 ,val loss : 0.471020 ,val acc : 0.799255\n",
      "[ ecpho : 1  iter :264 ]train loss : 0.350318 ,train acc: 0.839112 ,val loss : 0.467607 ,val acc : 0.800293\n",
      "[ ecpho : 1  iter :265 ]train loss : 0.399966 ,train acc: 0.833842 ,val loss : 0.471988 ,val acc : 0.804474\n",
      "[ ecpho : 1  iter :266 ]train loss : 0.574568 ,train acc: 0.738170 ,val loss : 0.468921 ,val acc : 0.799744\n",
      "[ ecpho : 1  iter :267 ]train loss : 0.351917 ,train acc: 0.839386 ,val loss : 0.468993 ,val acc : 0.803345\n",
      "[ ecpho : 1  iter :268 ]train loss : 0.409768 ,train acc: 0.825358 ,val loss : 0.467871 ,val acc : 0.798859\n",
      "[ ecpho : 1  iter :269 ]train loss : 0.357457 ,train acc: 0.833547 ,val loss : 0.460886 ,val acc : 0.801697\n",
      "[ ecpho : 1  iter :270 ]train loss : 0.372432 ,train acc: 0.832886 ,val loss : 0.470554 ,val acc : 0.801270\n",
      "[ ecpho : 1  iter :271 ]train loss : 0.407399 ,train acc: 0.830394 ,val loss : 0.464601 ,val acc : 0.802643\n",
      "[ ecpho : 1  iter :272 ]train loss : 0.451572 ,train acc: 0.801972 ,val loss : 0.464809 ,val acc : 0.801575\n",
      "[ ecpho : 1  iter :273 ]train loss : 0.332920 ,train acc: 0.847952 ,val loss : 0.468095 ,val acc : 0.803009\n",
      "[ ecpho : 1  iter :274 ]train loss : 0.395870 ,train acc: 0.835144 ,val loss : 0.467267 ,val acc : 0.798615\n",
      "[ ecpho : 1  iter :275 ]train loss : 0.432649 ,train acc: 0.783570 ,val loss : 0.471522 ,val acc : 0.797852\n",
      "[ ecpho : 1  iter :276 ]train loss : 0.389715 ,train acc: 0.835683 ,val loss : 0.472515 ,val acc : 0.800598\n",
      "[ ecpho : 1  iter :277 ]train loss : 0.373681 ,train acc: 0.808370 ,val loss : 0.467391 ,val acc : 0.801086\n",
      "[ ecpho : 1  iter :278 ]train loss : 0.466861 ,train acc: 0.791331 ,val loss : 0.465697 ,val acc : 0.799011\n",
      "[ ecpho : 1  iter :279 ]train loss : 0.394439 ,train acc: 0.834422 ,val loss : 0.469701 ,val acc : 0.801605\n",
      "[ ecpho : 1  iter :280 ]train loss : 0.411239 ,train acc: 0.821015 ,val loss : 0.466224 ,val acc : 0.801514\n",
      "[ ecpho : 1  iter :281 ]train loss : 0.354093 ,train acc: 0.834432 ,val loss : 0.458307 ,val acc : 0.802490\n",
      "[ ecpho : 1  iter :282 ]train loss : 0.380710 ,train acc: 0.839000 ,val loss : 0.471208 ,val acc : 0.800659\n",
      "[ ecpho : 1  iter :283 ]train loss : 0.425152 ,train acc: 0.815643 ,val loss : 0.466995 ,val acc : 0.800568\n",
      "[ ecpho : 1  iter :284 ]train loss : 0.396080 ,train acc: 0.829102 ,val loss : 0.462266 ,val acc : 0.805115\n",
      "[ ecpho : 1  iter :285 ]train loss : 0.338775 ,train acc: 0.846303 ,val loss : 0.479180 ,val acc : 0.796753\n",
      "[ ecpho : 1  iter :286 ]train loss : 0.381280 ,train acc: 0.836884 ,val loss : 0.466414 ,val acc : 0.799988\n",
      "[ ecpho : 1  iter :287 ]train loss : 0.405851 ,train acc: 0.820821 ,val loss : 0.470368 ,val acc : 0.802399\n",
      "[ ecpho : 1  iter :288 ]train loss : 0.430721 ,train acc: 0.787079 ,val loss : 0.466829 ,val acc : 0.801147\n",
      "[ ecpho : 1  iter :289 ]train loss : 0.359062 ,train acc: 0.840098 ,val loss : 0.459207 ,val acc : 0.804565\n",
      "[ ecpho : 1  iter :290 ]train loss : 0.400260 ,train acc: 0.827546 ,val loss : 0.469369 ,val acc : 0.801819\n",
      "[ ecpho : 1  iter :291 ]train loss : 0.350138 ,train acc: 0.841705 ,val loss : 0.468205 ,val acc : 0.798340\n",
      "[ ecpho : 1  iter :292 ]train loss : 0.389404 ,train acc: 0.820201 ,val loss : 0.467576 ,val acc : 0.800323\n",
      "[ ecpho : 1  iter :293 ]train loss : 0.407021 ,train acc: 0.829020 ,val loss : 0.465803 ,val acc : 0.800568\n",
      "[ ecpho : 1  iter :294 ]train loss : 0.363506 ,train acc: 0.834107 ,val loss : 0.467765 ,val acc : 0.801208\n",
      "[ ecpho : 1  iter :295 ]train loss : 0.364667 ,train acc: 0.822846 ,val loss : 0.460691 ,val acc : 0.801331\n",
      "[ ecpho : 1  iter :296 ]train loss : 0.353985 ,train acc: 0.835582 ,val loss : 0.473920 ,val acc : 0.797089\n",
      "[ ecpho : 1  iter :297 ]train loss : 0.389981 ,train acc: 0.817475 ,val loss : 0.459765 ,val acc : 0.801697\n",
      "[ ecpho : 1  iter :298 ]train loss : 0.326836 ,train acc: 0.849304 ,val loss : 0.467374 ,val acc : 0.803253\n",
      "[ ecpho : 1  iter :299 ]train loss : 0.345744 ,train acc: 0.839040 ,val loss : 0.461291 ,val acc : 0.800659\n",
      "[ ecpho : 1  iter :300 ]train loss : 0.421173 ,train acc: 0.821422 ,val loss : 0.462208 ,val acc : 0.804291\n",
      "[ ecpho : 1  iter :301 ]train loss : 0.436428 ,train acc: 0.805878 ,val loss : 0.463960 ,val acc : 0.803650\n",
      "[ ecpho : 1  iter :302 ]train loss : 0.374182 ,train acc: 0.834585 ,val loss : 0.460623 ,val acc : 0.800720\n",
      "[ ecpho : 1  iter :303 ]train loss : 0.421938 ,train acc: 0.811351 ,val loss : 0.463331 ,val acc : 0.800385\n",
      "[ ecpho : 1  iter :304 ]train loss : 0.345783 ,train acc: 0.838521 ,val loss : 0.467553 ,val acc : 0.802185\n",
      "[ ecpho : 1  iter :305 ]train loss : 0.340482 ,train acc: 0.845408 ,val loss : 0.470929 ,val acc : 0.801849\n",
      "[ ecpho : 1  iter :306 ]train loss : 0.348709 ,train acc: 0.837372 ,val loss : 0.457521 ,val acc : 0.801331\n",
      "[ ecpho : 1  iter :307 ]train loss : 0.374778 ,train acc: 0.835521 ,val loss : 0.468482 ,val acc : 0.798828\n",
      "[ ecpho : 1  iter :308 ]train loss : 0.349120 ,train acc: 0.840373 ,val loss : 0.467384 ,val acc : 0.800568\n",
      "[ ecpho : 1  iter :309 ]train loss : 0.340834 ,train acc: 0.837657 ,val loss : 0.467775 ,val acc : 0.801392\n",
      "[ ecpho : 1  iter :310 ]train loss : 0.422547 ,train acc: 0.821289 ,val loss : 0.462342 ,val acc : 0.802521\n",
      "[ ecpho : 1  iter :311 ]train loss : 0.392787 ,train acc: 0.811839 ,val loss : 0.474936 ,val acc : 0.798187\n",
      "[ ecpho : 1  iter :312 ]train loss : 0.345938 ,train acc: 0.837250 ,val loss : 0.460430 ,val acc : 0.802612\n",
      "[ ecpho : 1  iter :313 ]train loss : 0.349846 ,train acc: 0.843648 ,val loss : 0.465849 ,val acc : 0.798706\n",
      "[ ecpho : 1  iter :314 ]train loss : 0.392676 ,train acc: 0.824239 ,val loss : 0.458717 ,val acc : 0.800568\n",
      "[ ecpho : 1  iter :315 ]train loss : 0.482411 ,train acc: 0.818675 ,val loss : 0.468062 ,val acc : 0.800781\n",
      "[ ecpho : 1  iter :316 ]train loss : 0.364769 ,train acc: 0.837626 ,val loss : 0.469180 ,val acc : 0.800171\n",
      "[ ecpho : 1  iter :317 ]train loss : 0.452057 ,train acc: 0.792267 ,val loss : 0.473352 ,val acc : 0.798248\n",
      "[ ecpho : 1  iter :318 ]train loss : 0.370513 ,train acc: 0.830740 ,val loss : 0.467237 ,val acc : 0.798615\n",
      "[ ecpho : 1  iter :319 ]train loss : 0.416337 ,train acc: 0.817444 ,val loss : 0.464333 ,val acc : 0.804047\n",
      "[ ecpho : 1  iter :320 ]train loss : 0.388249 ,train acc: 0.837230 ,val loss : 0.466354 ,val acc : 0.802124\n",
      "[ ecpho : 1  iter :321 ]train loss : 0.404844 ,train acc: 0.815521 ,val loss : 0.471034 ,val acc : 0.799713\n",
      "[ ecpho : 1  iter :322 ]train loss : 0.406206 ,train acc: 0.828593 ,val loss : 0.461753 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :323 ]train loss : 0.348788 ,train acc: 0.842153 ,val loss : 0.456864 ,val acc : 0.805023\n",
      "[ ecpho : 1  iter :324 ]train loss : 0.369997 ,train acc: 0.841492 ,val loss : 0.464042 ,val acc : 0.804108\n",
      "[ ecpho : 1  iter :325 ]train loss : 0.368462 ,train acc: 0.839366 ,val loss : 0.466870 ,val acc : 0.800385\n",
      "[ ecpho : 1  iter :326 ]train loss : 0.444509 ,train acc: 0.815735 ,val loss : 0.469709 ,val acc : 0.799286\n",
      "[ ecpho : 1  iter :327 ]train loss : 0.405378 ,train acc: 0.803935 ,val loss : 0.466567 ,val acc : 0.801270\n",
      "[ ecpho : 1  iter :328 ]train loss : 0.357101 ,train acc: 0.834778 ,val loss : 0.456209 ,val acc : 0.803436\n",
      "[ ecpho : 1  iter :329 ]train loss : 0.342779 ,train acc: 0.839752 ,val loss : 0.460351 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :330 ]train loss : 0.385448 ,train acc: 0.818746 ,val loss : 0.464214 ,val acc : 0.802277\n",
      "[ ecpho : 1  iter :331 ]train loss : 0.385344 ,train acc: 0.819916 ,val loss : 0.466592 ,val acc : 0.797638\n",
      "[ ecpho : 1  iter :332 ]train loss : 0.412659 ,train acc: 0.822378 ,val loss : 0.473240 ,val acc : 0.801086\n",
      "[ ecpho : 1  iter :333 ]train loss : 0.345525 ,train acc: 0.845998 ,val loss : 0.465239 ,val acc : 0.798615\n",
      "[ ecpho : 1  iter :334 ]train loss : 0.356338 ,train acc: 0.835734 ,val loss : 0.459346 ,val acc : 0.807159\n",
      "[ ecpho : 1  iter :335 ]train loss : 0.344065 ,train acc: 0.834432 ,val loss : 0.468445 ,val acc : 0.805054\n",
      "[ ecpho : 1  iter :336 ]train loss : 0.350389 ,train acc: 0.830607 ,val loss : 0.465452 ,val acc : 0.802673\n",
      "[ ecpho : 1  iter :337 ]train loss : 0.343953 ,train acc: 0.836131 ,val loss : 0.460203 ,val acc : 0.801147\n",
      "[ ecpho : 1  iter :338 ]train loss : 0.469757 ,train acc: 0.783000 ,val loss : 0.463740 ,val acc : 0.803284\n",
      "[ ecpho : 1  iter :339 ]train loss : 0.353838 ,train acc: 0.837158 ,val loss : 0.467938 ,val acc : 0.799438\n",
      "[ ecpho : 1  iter :340 ]train loss : 0.338781 ,train acc: 0.847148 ,val loss : 0.468314 ,val acc : 0.799194\n",
      "[ ecpho : 1  iter :341 ]train loss : 0.360477 ,train acc: 0.835948 ,val loss : 0.459732 ,val acc : 0.804504\n",
      "[ ecpho : 1  iter :342 ]train loss : 0.357770 ,train acc: 0.836467 ,val loss : 0.468219 ,val acc : 0.799774\n",
      "[ ecpho : 1  iter :343 ]train loss : 0.403251 ,train acc: 0.810985 ,val loss : 0.469894 ,val acc : 0.800995\n",
      "[ ecpho : 1  iter :344 ]train loss : 0.443498 ,train acc: 0.814311 ,val loss : 0.463094 ,val acc : 0.802216\n",
      "[ ecpho : 1  iter :345 ]train loss : 0.340238 ,train acc: 0.843852 ,val loss : 0.461061 ,val acc : 0.803650\n",
      "[ ecpho : 1  iter :346 ]train loss : 0.465861 ,train acc: 0.794261 ,val loss : 0.456606 ,val acc : 0.804108\n",
      "[ ecpho : 1  iter :347 ]train loss : 0.401716 ,train acc: 0.795176 ,val loss : 0.463546 ,val acc : 0.798523\n",
      "[ ecpho : 1  iter :348 ]train loss : 0.344266 ,train acc: 0.838867 ,val loss : 0.457494 ,val acc : 0.799957\n",
      "[ ecpho : 1  iter :349 ]train loss : 0.346345 ,train acc: 0.843831 ,val loss : 0.464874 ,val acc : 0.798584\n",
      "[ ecpho : 1  iter :350 ]train loss : 0.368662 ,train acc: 0.839376 ,val loss : 0.458155 ,val acc : 0.801392\n",
      "[ ecpho : 1  iter :351 ]train loss : 0.472921 ,train acc: 0.814484 ,val loss : 0.468596 ,val acc : 0.801575\n",
      "[ ecpho : 1  iter :352 ]train loss : 0.365222 ,train acc: 0.825318 ,val loss : 0.466395 ,val acc : 0.801910\n",
      "[ ecpho : 1  iter :353 ]train loss : 0.367084 ,train acc: 0.823883 ,val loss : 0.464745 ,val acc : 0.802368\n",
      "[ ecpho : 1  iter :354 ]train loss : 0.325510 ,train acc: 0.850413 ,val loss : 0.462883 ,val acc : 0.800751\n",
      "[ ecpho : 1  iter :355 ]train loss : 0.336585 ,train acc: 0.840902 ,val loss : 0.469349 ,val acc : 0.801910\n",
      "[ ecpho : 1  iter :356 ]train loss : 0.448992 ,train acc: 0.786357 ,val loss : 0.463110 ,val acc : 0.801483\n",
      "[ ecpho : 1  iter :357 ]train loss : 0.402278 ,train acc: 0.815745 ,val loss : 0.468887 ,val acc : 0.800720\n",
      "[ ecpho : 1  iter :358 ]train loss : 0.357477 ,train acc: 0.840759 ,val loss : 0.465903 ,val acc : 0.803833\n",
      "[ ecpho : 1  iter :359 ]train loss : 0.370805 ,train acc: 0.836375 ,val loss : 0.463770 ,val acc : 0.801788\n",
      "[ ecpho : 1  iter :360 ]train loss : 0.429865 ,train acc: 0.815776 ,val loss : 0.459951 ,val acc : 0.801727\n",
      "[ ecpho : 1  iter :361 ]train loss : 0.343431 ,train acc: 0.841807 ,val loss : 0.458062 ,val acc : 0.801025\n",
      "[ ecpho : 1  iter :362 ]train loss : 0.358246 ,train acc: 0.839508 ,val loss : 0.457980 ,val acc : 0.800720\n",
      "[ ecpho : 1  iter :363 ]train loss : 0.381882 ,train acc: 0.833496 ,val loss : 0.453652 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :364 ]train loss : 0.494641 ,train acc: 0.768341 ,val loss : 0.465022 ,val acc : 0.799805\n",
      "[ ecpho : 1  iter :365 ]train loss : 0.367275 ,train acc: 0.838898 ,val loss : 0.469336 ,val acc : 0.797180\n",
      "[ ecpho : 1  iter :366 ]train loss : 0.365592 ,train acc: 0.831981 ,val loss : 0.467178 ,val acc : 0.801605\n",
      "[ ecpho : 1  iter :367 ]train loss : 0.379108 ,train acc: 0.835775 ,val loss : 0.460493 ,val acc : 0.800995\n",
      "[ ecpho : 1  iter :368 ]train loss : 0.372689 ,train acc: 0.832611 ,val loss : 0.462680 ,val acc : 0.806885\n",
      "[ ecpho : 1  iter :369 ]train loss : 0.385544 ,train acc: 0.830007 ,val loss : 0.460615 ,val acc : 0.798553\n",
      "[ ecpho : 1  iter :370 ]train loss : 0.323533 ,train acc: 0.847901 ,val loss : 0.457730 ,val acc : 0.804016\n",
      "[ ecpho : 1  iter :371 ]train loss : 0.395382 ,train acc: 0.833018 ,val loss : 0.460628 ,val acc : 0.802979\n",
      "[ ecpho : 1  iter :372 ]train loss : 0.409961 ,train acc: 0.811544 ,val loss : 0.464913 ,val acc : 0.799042\n",
      "[ ecpho : 1  iter :373 ]train loss : 0.333475 ,train acc: 0.851624 ,val loss : 0.462430 ,val acc : 0.803375\n",
      "[ ecpho : 1  iter :374 ]train loss : 0.331511 ,train acc: 0.847056 ,val loss : 0.464194 ,val acc : 0.800629\n",
      "[ ecpho : 1  iter :375 ]train loss : 0.329757 ,train acc: 0.847097 ,val loss : 0.464324 ,val acc : 0.802368\n",
      "[ ecpho : 1  iter :376 ]train loss : 0.334892 ,train acc: 0.847728 ,val loss : 0.464683 ,val acc : 0.800751\n",
      "[ ecpho : 1  iter :377 ]train loss : 0.341533 ,train acc: 0.843048 ,val loss : 0.462827 ,val acc : 0.802185\n",
      "[ ecpho : 1  iter :378 ]train loss : 0.397917 ,train acc: 0.834259 ,val loss : 0.454529 ,val acc : 0.805023\n",
      "[ ecpho : 1  iter :379 ]train loss : 0.363663 ,train acc: 0.830658 ,val loss : 0.457483 ,val acc : 0.805267\n",
      "[ ecpho : 1  iter :380 ]train loss : 0.384234 ,train acc: 0.833049 ,val loss : 0.468240 ,val acc : 0.798798\n",
      "[ ecpho : 1  iter :381 ]train loss : 0.392789 ,train acc: 0.831340 ,val loss : 0.460366 ,val acc : 0.801636\n",
      "[ ecpho : 1  iter :382 ]train loss : 0.348044 ,train acc: 0.837504 ,val loss : 0.464810 ,val acc : 0.802002\n",
      "[ ecpho : 1  iter :383 ]train loss : 0.444159 ,train acc: 0.806356 ,val loss : 0.464665 ,val acc : 0.802521\n",
      "[ ecpho : 1  iter :384 ]train loss : 0.344972 ,train acc: 0.840108 ,val loss : 0.462821 ,val acc : 0.799530\n",
      "[ ecpho : 1  iter :385 ]train loss : 0.379308 ,train acc: 0.839142 ,val loss : 0.456688 ,val acc : 0.803925\n",
      "[ ecpho : 1  iter :386 ]train loss : 0.388872 ,train acc: 0.832154 ,val loss : 0.460196 ,val acc : 0.801086\n",
      "[ ecpho : 1  iter :387 ]train loss : 0.429059 ,train acc: 0.805980 ,val loss : 0.463332 ,val acc : 0.800262\n",
      "[ ecpho : 1  iter :388 ]train loss : 0.324208 ,train acc: 0.850678 ,val loss : 0.459613 ,val acc : 0.800995\n",
      "[ ecpho : 1  iter :389 ]train loss : 0.387885 ,train acc: 0.821269 ,val loss : 0.458996 ,val acc : 0.802460\n",
      "[ ecpho : 1  iter :390 ]train loss : 0.409234 ,train acc: 0.815664 ,val loss : 0.463128 ,val acc : 0.800323\n",
      "[ ecpho : 1  iter :391 ]train loss : 0.377038 ,train acc: 0.837097 ,val loss : 0.458300 ,val acc : 0.806183\n",
      "[ ecpho : 1  iter :392 ]train loss : 0.324540 ,train acc: 0.847229 ,val loss : 0.453181 ,val acc : 0.804138\n",
      "[ ecpho : 1  iter :393 ]train loss : 0.407359 ,train acc: 0.768748 ,val loss : 0.455525 ,val acc : 0.803955\n",
      "[ ecpho : 1  iter :394 ]train loss : 0.367179 ,train acc: 0.836731 ,val loss : 0.457753 ,val acc : 0.804657\n",
      "[ ecpho : 1  iter :395 ]train loss : 0.385070 ,train acc: 0.818828 ,val loss : 0.459347 ,val acc : 0.804749\n",
      "[ ecpho : 1  iter :396 ]train loss : 0.344534 ,train acc: 0.847219 ,val loss : 0.464327 ,val acc : 0.801056\n",
      "[ ecpho : 1  iter :397 ]train loss : 0.440977 ,train acc: 0.817291 ,val loss : 0.463450 ,val acc : 0.802490\n",
      "[ ecpho : 1  iter :398 ]train loss : 0.400268 ,train acc: 0.830984 ,val loss : 0.464816 ,val acc : 0.799316\n",
      "[ ecpho : 1  iter :399 ]train loss : 0.348989 ,train acc: 0.837881 ,val loss : 0.463443 ,val acc : 0.802551\n",
      "[ ecpho : 1  iter :400 ]train loss : 0.378984 ,train acc: 0.832092 ,val loss : 0.461106 ,val acc : 0.801300\n",
      "[ ecpho : 1  iter :401 ]train loss : 0.340376 ,train acc: 0.843781 ,val loss : 0.456000 ,val acc : 0.803406\n",
      "[ ecpho : 1  iter :402 ]train loss : 0.525929 ,train acc: 0.790640 ,val loss : 0.458628 ,val acc : 0.805603\n",
      "[ ecpho : 1  iter :403 ]train loss : 0.356522 ,train acc: 0.840546 ,val loss : 0.463822 ,val acc : 0.801636\n",
      "[ ecpho : 1  iter :404 ]train loss : 0.465429 ,train acc: 0.786204 ,val loss : 0.460952 ,val acc : 0.802460\n",
      "[ ecpho : 1  iter :405 ]train loss : 0.357662 ,train acc: 0.843303 ,val loss : 0.462300 ,val acc : 0.801422\n",
      "[ ecpho : 1  iter :406 ]train loss : 0.406127 ,train acc: 0.809652 ,val loss : 0.460870 ,val acc : 0.799286\n",
      "[ ecpho : 1  iter :407 ]train loss : 0.416199 ,train acc: 0.768311 ,val loss : 0.460125 ,val acc : 0.804626\n",
      "[ ecpho : 1  iter :408 ]train loss : 0.357984 ,train acc: 0.837697 ,val loss : 0.455589 ,val acc : 0.804077\n",
      "[ ecpho : 1  iter :409 ]train loss : 0.399049 ,train acc: 0.803518 ,val loss : 0.456455 ,val acc : 0.802734\n",
      "[ ecpho : 1  iter :410 ]train loss : 0.410698 ,train acc: 0.824819 ,val loss : 0.457185 ,val acc : 0.805695\n",
      "[ ecpho : 1  iter :411 ]train loss : 0.322493 ,train acc: 0.851308 ,val loss : 0.455844 ,val acc : 0.804077\n",
      "[ ecpho : 1  iter :412 ]train loss : 0.339103 ,train acc: 0.849762 ,val loss : 0.464826 ,val acc : 0.801025\n",
      "[ ecpho : 1  iter :413 ]train loss : 0.383924 ,train acc: 0.832906 ,val loss : 0.459172 ,val acc : 0.800323\n",
      "[ ecpho : 1  iter :414 ]train loss : 0.323035 ,train acc: 0.850576 ,val loss : 0.462672 ,val acc : 0.802307\n",
      "[ ecpho : 1  iter :415 ]train loss : 0.379828 ,train acc: 0.838643 ,val loss : 0.453632 ,val acc : 0.807678\n",
      "[ ecpho : 1  iter :416 ]train loss : 0.327695 ,train acc: 0.851013 ,val loss : 0.464837 ,val acc : 0.799988\n",
      "[ ecpho : 1  iter :417 ]train loss : 0.346368 ,train acc: 0.839640 ,val loss : 0.463695 ,val acc : 0.800537\n",
      "[ ecpho : 1  iter :418 ]train loss : 0.394598 ,train acc: 0.807414 ,val loss : 0.453924 ,val acc : 0.802124\n",
      "[ ecpho : 1  iter :419 ]train loss : 0.358073 ,train acc: 0.837352 ,val loss : 0.463421 ,val acc : 0.802155\n",
      "[ ecpho : 1  iter :420 ]train loss : 0.380068 ,train acc: 0.830353 ,val loss : 0.458983 ,val acc : 0.800537\n",
      "[ ecpho : 1  iter :421 ]train loss : 0.436904 ,train acc: 0.784353 ,val loss : 0.454856 ,val acc : 0.801636\n",
      "[ ecpho : 1  iter :422 ]train loss : 0.488709 ,train acc: 0.771973 ,val loss : 0.459939 ,val acc : 0.803864\n",
      "[ ecpho : 1  iter :423 ]train loss : 0.384172 ,train acc: 0.792176 ,val loss : 0.450966 ,val acc : 0.806671\n",
      "[ ecpho : 1  iter :424 ]train loss : 0.421749 ,train acc: 0.829193 ,val loss : 0.457671 ,val acc : 0.804352\n",
      "[ ecpho : 1  iter :425 ]train loss : 0.476220 ,train acc: 0.799622 ,val loss : 0.465551 ,val acc : 0.802460\n",
      "[ ecpho : 1  iter :426 ]train loss : 0.372982 ,train acc: 0.811615 ,val loss : 0.456179 ,val acc : 0.802094\n",
      "[ ecpho : 1  iter :427 ]train loss : 0.367918 ,train acc: 0.820597 ,val loss : 0.457031 ,val acc : 0.804352\n",
      "[ ecpho : 1  iter :428 ]train loss : 0.386387 ,train acc: 0.835582 ,val loss : 0.459368 ,val acc : 0.802979\n",
      "[ ecpho : 1  iter :429 ]train loss : 0.433743 ,train acc: 0.829254 ,val loss : 0.461667 ,val acc : 0.802032\n",
      "[ ecpho : 1  iter :430 ]train loss : 0.344616 ,train acc: 0.830058 ,val loss : 0.449671 ,val acc : 0.804108\n",
      "[ ecpho : 1  iter :431 ]train loss : 0.349819 ,train acc: 0.841319 ,val loss : 0.464085 ,val acc : 0.802521\n",
      "[ ecpho : 1  iter :432 ]train loss : 0.348727 ,train acc: 0.845601 ,val loss : 0.459998 ,val acc : 0.803955\n",
      "[ ecpho : 1  iter :433 ]train loss : 0.375646 ,train acc: 0.829977 ,val loss : 0.456841 ,val acc : 0.805206\n",
      "[ ecpho : 1  iter :434 ]train loss : 0.394552 ,train acc: 0.840241 ,val loss : 0.455579 ,val acc : 0.801819\n",
      "[ ecpho : 1  iter :435 ]train loss : 0.422040 ,train acc: 0.823548 ,val loss : 0.453042 ,val acc : 0.802185\n",
      "[ ecpho : 1  iter :436 ]train loss : 0.547515 ,train acc: 0.744884 ,val loss : 0.458676 ,val acc : 0.802551\n",
      "[ ecpho : 1  iter :437 ]train loss : 0.374317 ,train acc: 0.838308 ,val loss : 0.458323 ,val acc : 0.803009\n",
      "[ ecpho : 1  iter :438 ]train loss : 0.362061 ,train acc: 0.840353 ,val loss : 0.457546 ,val acc : 0.803436\n",
      "[ ecpho : 1  iter :439 ]train loss : 0.348986 ,train acc: 0.842885 ,val loss : 0.457841 ,val acc : 0.804016\n",
      "[ ecpho : 1  iter :440 ]train loss : 0.336103 ,train acc: 0.841828 ,val loss : 0.453758 ,val acc : 0.801666\n",
      "[ ecpho : 1  iter :441 ]train loss : 0.467919 ,train acc: 0.802562 ,val loss : 0.453463 ,val acc : 0.803467\n",
      "[ ecpho : 1  iter :442 ]train loss : 0.409885 ,train acc: 0.816946 ,val loss : 0.463725 ,val acc : 0.801453\n",
      "[ ecpho : 1  iter :443 ]train loss : 0.389773 ,train acc: 0.828451 ,val loss : 0.457936 ,val acc : 0.804230\n",
      "[ ecpho : 1  iter :444 ]train loss : 0.391161 ,train acc: 0.808299 ,val loss : 0.466823 ,val acc : 0.801056\n",
      "[ ecpho : 1  iter :445 ]train loss : 0.379160 ,train acc: 0.829377 ,val loss : 0.456484 ,val acc : 0.805328\n",
      "[ ecpho : 1  iter :446 ]train loss : 0.311968 ,train acc: 0.852234 ,val loss : 0.451842 ,val acc : 0.805084\n",
      "[ ecpho : 1  iter :447 ]train loss : 0.740034 ,train acc: 0.749543 ,val loss : 0.456818 ,val acc : 0.805267\n",
      "[ ecpho : 1  iter :448 ]train loss : 0.391697 ,train acc: 0.817922 ,val loss : 0.457697 ,val acc : 0.800842\n",
      "[ ecpho : 1  iter :449 ]train loss : 0.370201 ,train acc: 0.817434 ,val loss : 0.460654 ,val acc : 0.801514\n",
      "[ ecpho : 1  iter :450 ]train loss : 0.370158 ,train acc: 0.817149 ,val loss : 0.457778 ,val acc : 0.802856\n",
      "[ ecpho : 1  iter :451 ]train loss : 0.345305 ,train acc: 0.837199 ,val loss : 0.455539 ,val acc : 0.802887\n",
      "[ ecpho : 1  iter :452 ]train loss : 0.475000 ,train acc: 0.791982 ,val loss : 0.456878 ,val acc : 0.803925\n",
      "[ ecpho : 1  iter :453 ]train loss : 0.306585 ,train acc: 0.856791 ,val loss : 0.456379 ,val acc : 0.802765\n",
      "[ ecpho : 1  iter :454 ]train loss : 0.387427 ,train acc: 0.831726 ,val loss : 0.454222 ,val acc : 0.804535\n",
      "[ ecpho : 1  iter :455 ]train loss : 0.354490 ,train acc: 0.836701 ,val loss : 0.456279 ,val acc : 0.804535\n",
      "[ ecpho : 1  iter :456 ]train loss : 0.397107 ,train acc: 0.822276 ,val loss : 0.452248 ,val acc : 0.804077\n",
      "[ ecpho : 1  iter :457 ]train loss : 0.397096 ,train acc: 0.830648 ,val loss : 0.454428 ,val acc : 0.806030\n",
      "[ ecpho : 1  iter :458 ]train loss : 0.377118 ,train acc: 0.832011 ,val loss : 0.458863 ,val acc : 0.799896\n",
      "[ ecpho : 1  iter :459 ]train loss : 0.575201 ,train acc: 0.632935 ,val loss : 0.451135 ,val acc : 0.804169\n",
      "[ ecpho : 1  iter :460 ]train loss : 0.369799 ,train acc: 0.831513 ,val loss : 0.454099 ,val acc : 0.805206\n",
      "[ ecpho : 1  iter :461 ]train loss : 0.350420 ,train acc: 0.834300 ,val loss : 0.451875 ,val acc : 0.804260\n",
      "[ ecpho : 1  iter :462 ]train loss : 0.376556 ,train acc: 0.840149 ,val loss : 0.457191 ,val acc : 0.803253\n",
      "[ ecpho : 1  iter :463 ]train loss : 0.458803 ,train acc: 0.823487 ,val loss : 0.459662 ,val acc : 0.801788\n",
      "[ ecpho : 1  iter :464 ]train loss : 0.354346 ,train acc: 0.837514 ,val loss : 0.456016 ,val acc : 0.801910\n",
      "[ ecpho : 1  iter :465 ]train loss : 0.382873 ,train acc: 0.810506 ,val loss : 0.453511 ,val acc : 0.804230\n",
      "[ ecpho : 1  iter :466 ]train loss : 0.360527 ,train acc: 0.823904 ,val loss : 0.461557 ,val acc : 0.801819\n",
      "[ ecpho : 1  iter :467 ]train loss : 0.369616 ,train acc: 0.822815 ,val loss : 0.457718 ,val acc : 0.802551\n",
      "[ ecpho : 1  iter :468 ]train loss : 0.416914 ,train acc: 0.778829 ,val loss : 0.453494 ,val acc : 0.805878\n",
      "[ ecpho : 1  iter :469 ]train loss : 0.371061 ,train acc: 0.808502 ,val loss : 0.458182 ,val acc : 0.803558\n",
      "[ ecpho : 1  iter :470 ]train loss : 0.403723 ,train acc: 0.830526 ,val loss : 0.458873 ,val acc : 0.803009\n",
      "[ ecpho : 1  iter :471 ]train loss : 0.465084 ,train acc: 0.798432 ,val loss : 0.452850 ,val acc : 0.802216\n",
      "[ ecpho : 1  iter :472 ]train loss : 0.348863 ,train acc: 0.845103 ,val loss : 0.459196 ,val acc : 0.801086\n",
      "[ ecpho : 1  iter :473 ]train loss : 0.404728 ,train acc: 0.826701 ,val loss : 0.453839 ,val acc : 0.804230\n",
      "[ ecpho : 1  iter :474 ]train loss : 0.338820 ,train acc: 0.843577 ,val loss : 0.458608 ,val acc : 0.804382\n",
      "[ ecpho : 1  iter :475 ]train loss : 0.321538 ,train acc: 0.853383 ,val loss : 0.455021 ,val acc : 0.803345\n",
      "[ ecpho : 1  iter :476 ]train loss : 0.417961 ,train acc: 0.821747 ,val loss : 0.457670 ,val acc : 0.801453\n",
      "[ ecpho : 1  iter :477 ]train loss : 0.322269 ,train acc: 0.850759 ,val loss : 0.459727 ,val acc : 0.801605\n",
      "[ ecpho : 1  iter :478 ]train loss : 0.378040 ,train acc: 0.824524 ,val loss : 0.456705 ,val acc : 0.804474\n",
      "[ ecpho : 1  iter :479 ]train loss : 0.391005 ,train acc: 0.800781 ,val loss : 0.459885 ,val acc : 0.803497\n",
      "[ ecpho : 1  iter :480 ]train loss : 0.377512 ,train acc: 0.834198 ,val loss : 0.456285 ,val acc : 0.800781\n",
      "[ ecpho : 1  iter :481 ]train loss : 0.330684 ,train acc: 0.843282 ,val loss : 0.457191 ,val acc : 0.805084\n",
      "[ ecpho : 1  iter :482 ]train loss : 0.358091 ,train acc: 0.833578 ,val loss : 0.458204 ,val acc : 0.804047\n",
      "[ ecpho : 1  iter :483 ]train loss : 0.574787 ,train acc: 0.742890 ,val loss : 0.456899 ,val acc : 0.805084\n",
      "[ ecpho : 1  iter :484 ]train loss : 0.468279 ,train acc: 0.815064 ,val loss : 0.460552 ,val acc : 0.801208\n",
      "[ ecpho : 1  iter :485 ]train loss : 0.406338 ,train acc: 0.833974 ,val loss : 0.454420 ,val acc : 0.803284\n",
      "[ ecpho : 1  iter :486 ]train loss : 0.354796 ,train acc: 0.841838 ,val loss : 0.454042 ,val acc : 0.805786\n",
      "[ ecpho : 1  iter :487 ]train loss : 0.370128 ,train acc: 0.844981 ,val loss : 0.451112 ,val acc : 0.803711\n",
      "[ ecpho : 1  iter :488 ]train loss : 0.430410 ,train acc: 0.827596 ,val loss : 0.453458 ,val acc : 0.805267\n",
      "[ ecpho : 1  iter :489 ]train loss : 0.367031 ,train acc: 0.838155 ,val loss : 0.452647 ,val acc : 0.803619\n",
      "[ ecpho : 1  iter :490 ]train loss : 0.351199 ,train acc: 0.838918 ,val loss : 0.454496 ,val acc : 0.801514\n",
      "[ ecpho : 1  iter :491 ]train loss : 0.410756 ,train acc: 0.837108 ,val loss : 0.460175 ,val acc : 0.800964\n",
      "[ ecpho : 1  iter :492 ]train loss : 0.321794 ,train acc: 0.852631 ,val loss : 0.457060 ,val acc : 0.802948\n",
      "[ ecpho : 1  iter :493 ]train loss : 0.473788 ,train acc: 0.809896 ,val loss : 0.459208 ,val acc : 0.801117\n",
      "[ ecpho : 1  iter :494 ]train loss : 0.448985 ,train acc: 0.817719 ,val loss : 0.455623 ,val acc : 0.803528\n",
      "[ ecpho : 1  iter :495 ]train loss : 0.392078 ,train acc: 0.822612 ,val loss : 0.462562 ,val acc : 0.805206\n",
      "[ ecpho : 1  iter :496 ]train loss : 0.337928 ,train acc: 0.851298 ,val loss : 0.450741 ,val acc : 0.806274\n",
      "[ ecpho : 1  iter :497 ]train loss : 0.344971 ,train acc: 0.841492 ,val loss : 0.460513 ,val acc : 0.801605\n",
      "[ ecpho : 1  iter :498 ]train loss : 0.312820 ,train acc: 0.852895 ,val loss : 0.443160 ,val acc : 0.806000\n",
      "[ ecpho : 1  iter :499 ]train loss : 0.388763 ,train acc: 0.821442 ,val loss : 0.460632 ,val acc : 0.801544\n",
      "[ ecpho : 1  iter :500 ]train loss : 0.398359 ,train acc: 0.806102 ,val loss : 0.458168 ,val acc : 0.800049\n",
      "[ ecpho : 1  iter :501 ]train loss : 0.336035 ,train acc: 0.844066 ,val loss : 0.448261 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :502 ]train loss : 0.367394 ,train acc: 0.844025 ,val loss : 0.448228 ,val acc : 0.804993\n",
      "[ ecpho : 1  iter :503 ]train loss : 0.346020 ,train acc: 0.843608 ,val loss : 0.449011 ,val acc : 0.805084\n",
      "[ ecpho : 1  iter :504 ]train loss : 0.479085 ,train acc: 0.820313 ,val loss : 0.450055 ,val acc : 0.807220\n",
      "[ ecpho : 1  iter :505 ]train loss : 0.373299 ,train acc: 0.841807 ,val loss : 0.454559 ,val acc : 0.800629\n",
      "[ ecpho : 1  iter :506 ]train loss : 0.404141 ,train acc: 0.828034 ,val loss : 0.458455 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :507 ]train loss : 0.351738 ,train acc: 0.824432 ,val loss : 0.449855 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :508 ]train loss : 0.322523 ,train acc: 0.844940 ,val loss : 0.452183 ,val acc : 0.804657\n",
      "[ ecpho : 1  iter :509 ]train loss : 0.428528 ,train acc: 0.826325 ,val loss : 0.450051 ,val acc : 0.806396\n",
      "[ ecpho : 1  iter :510 ]train loss : 0.418868 ,train acc: 0.820048 ,val loss : 0.454482 ,val acc : 0.803162\n",
      "[ ecpho : 1  iter :511 ]train loss : 0.571975 ,train acc: 0.725362 ,val loss : 0.451871 ,val acc : 0.803741\n",
      "[ ecpho : 1  iter :512 ]train loss : 0.400268 ,train acc: 0.825663 ,val loss : 0.452300 ,val acc : 0.805664\n",
      "[ ecpho : 1  iter :513 ]train loss : 0.397965 ,train acc: 0.838684 ,val loss : 0.453112 ,val acc : 0.803650\n",
      "[ ecpho : 1  iter :514 ]train loss : 0.317803 ,train acc: 0.850088 ,val loss : 0.454820 ,val acc : 0.804901\n",
      "[ ecpho : 1  iter :515 ]train loss : 0.354166 ,train acc: 0.841736 ,val loss : 0.453752 ,val acc : 0.804504\n",
      "[ ecpho : 1  iter :516 ]train loss : 0.376211 ,train acc: 0.831716 ,val loss : 0.451000 ,val acc : 0.803772\n",
      "[ ecpho : 1  iter :517 ]train loss : 0.351368 ,train acc: 0.838186 ,val loss : 0.452205 ,val acc : 0.805237\n",
      "[ ecpho : 1  iter :518 ]train loss : 0.396373 ,train acc: 0.832906 ,val loss : 0.446642 ,val acc : 0.808136\n",
      "[ ecpho : 1  iter :519 ]train loss : 0.462964 ,train acc: 0.768982 ,val loss : 0.447365 ,val acc : 0.806091\n",
      "[ ecpho : 1  iter :520 ]train loss : 0.373254 ,train acc: 0.837687 ,val loss : 0.452861 ,val acc : 0.803833\n",
      "[ ecpho : 1  iter :521 ]train loss : 0.391157 ,train acc: 0.838491 ,val loss : 0.452624 ,val acc : 0.802399\n",
      "[ ecpho : 1  iter :522 ]train loss : 0.345286 ,train acc: 0.840973 ,val loss : 0.455691 ,val acc : 0.801788\n",
      "[ ecpho : 1  iter :523 ]train loss : 0.363167 ,train acc: 0.836090 ,val loss : 0.451369 ,val acc : 0.806793\n",
      "[ ecpho : 1  iter :524 ]train loss : 0.314553 ,train acc: 0.851797 ,val loss : 0.452004 ,val acc : 0.804352\n",
      "[ ecpho : 1  iter :525 ]train loss : 0.353700 ,train acc: 0.840434 ,val loss : 0.456424 ,val acc : 0.803284\n",
      "[ ecpho : 1  iter :526 ]train loss : 0.573488 ,train acc: 0.774018 ,val loss : 0.453403 ,val acc : 0.806427\n",
      "[ ecpho : 1  iter :527 ]train loss : 0.381666 ,train acc: 0.837779 ,val loss : 0.459708 ,val acc : 0.803986\n",
      "[ ecpho : 1  iter :528 ]train loss : 0.528401 ,train acc: 0.761088 ,val loss : 0.450557 ,val acc : 0.805908\n",
      "[ ecpho : 1  iter :529 ]train loss : 0.332529 ,train acc: 0.843384 ,val loss : 0.453453 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :530 ]train loss : 0.335281 ,train acc: 0.841187 ,val loss : 0.457423 ,val acc : 0.803528\n",
      "[ ecpho : 1  iter :531 ]train loss : 0.474340 ,train acc: 0.794444 ,val loss : 0.448053 ,val acc : 0.806061\n",
      "[ ecpho : 1  iter :532 ]train loss : 0.404254 ,train acc: 0.828278 ,val loss : 0.450841 ,val acc : 0.804993\n",
      "[ ecpho : 1  iter :533 ]train loss : 0.387840 ,train acc: 0.834015 ,val loss : 0.454042 ,val acc : 0.803741\n",
      "[ ecpho : 1  iter :534 ]train loss : 0.460153 ,train acc: 0.817037 ,val loss : 0.460700 ,val acc : 0.803253\n",
      "[ ecpho : 1  iter :535 ]train loss : 0.353010 ,train acc: 0.842356 ,val loss : 0.451386 ,val acc : 0.803955\n",
      "[ ecpho : 1  iter :536 ]train loss : 0.350223 ,train acc: 0.835124 ,val loss : 0.452619 ,val acc : 0.802582\n",
      "[ ecpho : 1  iter :537 ]train loss : 0.388667 ,train acc: 0.832082 ,val loss : 0.451525 ,val acc : 0.805542\n",
      "[ ecpho : 1  iter :538 ]train loss : 0.408802 ,train acc: 0.793986 ,val loss : 0.452714 ,val acc : 0.800873\n",
      "[ ecpho : 1  iter :539 ]train loss : 0.321775 ,train acc: 0.848562 ,val loss : 0.450515 ,val acc : 0.808563\n",
      "[ ecpho : 1  iter :540 ]train loss : 0.402958 ,train acc: 0.821737 ,val loss : 0.451312 ,val acc : 0.804138\n",
      "[ ecpho : 1  iter :541 ]train loss : 0.400073 ,train acc: 0.804494 ,val loss : 0.450521 ,val acc : 0.803955\n",
      "[ ecpho : 1  iter :542 ]train loss : 0.313776 ,train acc: 0.848908 ,val loss : 0.450501 ,val acc : 0.803802\n",
      "[ ecpho : 1  iter :543 ]train loss : 0.355730 ,train acc: 0.838054 ,val loss : 0.449768 ,val acc : 0.803314\n",
      "[ ecpho : 1  iter :544 ]train loss : 0.375454 ,train acc: 0.832896 ,val loss : 0.452071 ,val acc : 0.800598\n",
      "[ ecpho : 1  iter :545 ]train loss : 0.363974 ,train acc: 0.827545 ,val loss : 0.452765 ,val acc : 0.804718\n",
      "[ ecpho : 1  iter :546 ]train loss : 0.383352 ,train acc: 0.833395 ,val loss : 0.454335 ,val acc : 0.805664\n",
      "[ ecpho : 1  iter :547 ]train loss : 0.393591 ,train acc: 0.821828 ,val loss : 0.455381 ,val acc : 0.807709\n",
      "[ ecpho : 1  iter :548 ]train loss : 0.348890 ,train acc: 0.842814 ,val loss : 0.452754 ,val acc : 0.803955\n",
      "[ ecpho : 1  iter :549 ]train loss : 0.352512 ,train acc: 0.832937 ,val loss : 0.449542 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :550 ]train loss : 0.323479 ,train acc: 0.843913 ,val loss : 0.457228 ,val acc : 0.804932\n",
      "[ ecpho : 1  iter :551 ]train loss : 0.408315 ,train acc: 0.820832 ,val loss : 0.448699 ,val acc : 0.806061\n",
      "[ ecpho : 1  iter :552 ]train loss : 0.371099 ,train acc: 0.839285 ,val loss : 0.449200 ,val acc : 0.805542\n",
      "[ ecpho : 1  iter :553 ]train loss : 0.409318 ,train acc: 0.829193 ,val loss : 0.454818 ,val acc : 0.801971\n",
      "[ ecpho : 1  iter :554 ]train loss : 0.329718 ,train acc: 0.850627 ,val loss : 0.453645 ,val acc : 0.805847\n",
      "[ ecpho : 1  iter :555 ]train loss : 0.370852 ,train acc: 0.839488 ,val loss : 0.456086 ,val acc : 0.801422\n",
      "[ ecpho : 1  iter :556 ]train loss : 0.333964 ,train acc: 0.841177 ,val loss : 0.455228 ,val acc : 0.807312\n",
      "[ ecpho : 1  iter :557 ]train loss : 0.342583 ,train acc: 0.848114 ,val loss : 0.455881 ,val acc : 0.803223\n",
      "[ ecpho : 1  iter :558 ]train loss : 0.393088 ,train acc: 0.782135 ,val loss : 0.450459 ,val acc : 0.803680\n",
      "[ ecpho : 1  iter :559 ]train loss : 0.374861 ,train acc: 0.823883 ,val loss : 0.450473 ,val acc : 0.805145\n",
      "[ ecpho : 1  iter :560 ]train loss : 0.497804 ,train acc: 0.816641 ,val loss : 0.444820 ,val acc : 0.807068\n",
      "[ ecpho : 1  iter :561 ]train loss : 0.389706 ,train acc: 0.820455 ,val loss : 0.451734 ,val acc : 0.804382\n",
      "[ ecpho : 1  iter :562 ]train loss : 0.425323 ,train acc: 0.823507 ,val loss : 0.458068 ,val acc : 0.800751\n",
      "[ ecpho : 1  iter :563 ]train loss : 0.397281 ,train acc: 0.831096 ,val loss : 0.454775 ,val acc : 0.805847\n",
      "[ ecpho : 1  iter :564 ]train loss : 0.323290 ,train acc: 0.852254 ,val loss : 0.452969 ,val acc : 0.803375\n",
      "[ ecpho : 1  iter :565 ]train loss : 0.361343 ,train acc: 0.834666 ,val loss : 0.457282 ,val acc : 0.802826\n",
      "[ ecpho : 1  iter :566 ]train loss : 0.360806 ,train acc: 0.841726 ,val loss : 0.450721 ,val acc : 0.807007\n",
      "[ ecpho : 1  iter :567 ]train loss : 0.361832 ,train acc: 0.840047 ,val loss : 0.444046 ,val acc : 0.805847\n",
      "[ ecpho : 1  iter :568 ]train loss : 0.318591 ,train acc: 0.849386 ,val loss : 0.452993 ,val acc : 0.803589\n",
      "[ ecpho : 1  iter :569 ]train loss : 0.341078 ,train acc: 0.847921 ,val loss : 0.458704 ,val acc : 0.804443\n",
      "[ ecpho : 1  iter :570 ]train loss : 0.328471 ,train acc: 0.842733 ,val loss : 0.456721 ,val acc : 0.803497\n",
      "[ ecpho : 1  iter :571 ]train loss : 0.309459 ,train acc: 0.854696 ,val loss : 0.451019 ,val acc : 0.806335\n",
      "[ ecpho : 1  iter :572 ]train loss : 0.389954 ,train acc: 0.810161 ,val loss : 0.450877 ,val acc : 0.803284\n",
      "[ ecpho : 1  iter :573 ]train loss : 0.350920 ,train acc: 0.840688 ,val loss : 0.453221 ,val acc : 0.805878\n",
      "[ ecpho : 1  iter :574 ]train loss : 0.372703 ,train acc: 0.836385 ,val loss : 0.451745 ,val acc : 0.803864\n",
      "[ ecpho : 1  iter :575 ]train loss : 0.401756 ,train acc: 0.831157 ,val loss : 0.449105 ,val acc : 0.806488\n",
      "[ ecpho : 1  iter :576 ]train loss : 0.439336 ,train acc: 0.792735 ,val loss : 0.449488 ,val acc : 0.805786\n",
      "[ ecpho : 1  iter :577 ]train loss : 0.308832 ,train acc: 0.852366 ,val loss : 0.443710 ,val acc : 0.808380\n",
      "[ ecpho : 1  iter :578 ]train loss : 0.377509 ,train acc: 0.813833 ,val loss : 0.452959 ,val acc : 0.802612\n",
      "[ ecpho : 1  iter :579 ]train loss : 0.342695 ,train acc: 0.835622 ,val loss : 0.446178 ,val acc : 0.805389\n",
      "[ ecpho : 1  iter :580 ]train loss : 0.436101 ,train acc: 0.793061 ,val loss : 0.447030 ,val acc : 0.804443\n",
      "[ ecpho : 1  iter :581 ]train loss : 0.334427 ,train acc: 0.839722 ,val loss : 0.445790 ,val acc : 0.808472\n",
      "[ ecpho : 1  iter :582 ]train loss : 0.460169 ,train acc: 0.801727 ,val loss : 0.454637 ,val acc : 0.804565\n",
      "[ ecpho : 1  iter :583 ]train loss : 0.348042 ,train acc: 0.844401 ,val loss : 0.451130 ,val acc : 0.803955\n",
      "[ ecpho : 1  iter :584 ]train loss : 0.381611 ,train acc: 0.826782 ,val loss : 0.452354 ,val acc : 0.803467\n",
      "[ ecpho : 1  iter :585 ]train loss : 0.406770 ,train acc: 0.784170 ,val loss : 0.448801 ,val acc : 0.803558\n",
      "[ ecpho : 1  iter :586 ]train loss : 0.318532 ,train acc: 0.851400 ,val loss : 0.448652 ,val acc : 0.803497\n",
      "[ ecpho : 1  iter :587 ]train loss : 0.407862 ,train acc: 0.830953 ,val loss : 0.451359 ,val acc : 0.803772\n",
      "[ ecpho : 1  iter :588 ]train loss : 0.332652 ,train acc: 0.849233 ,val loss : 0.456947 ,val acc : 0.805969\n",
      "[ ecpho : 1  iter :589 ]train loss : 0.353137 ,train acc: 0.838044 ,val loss : 0.444380 ,val acc : 0.806915\n",
      "[ ecpho : 1  iter :590 ]train loss : 0.364749 ,train acc: 0.840078 ,val loss : 0.449458 ,val acc : 0.807892\n",
      "[ ecpho : 1  iter :591 ]train loss : 0.396395 ,train acc: 0.837860 ,val loss : 0.450904 ,val acc : 0.804413\n",
      "[ ecpho : 1  iter :592 ]train loss : 0.396611 ,train acc: 0.828868 ,val loss : 0.445556 ,val acc : 0.805634\n",
      "[ ecpho : 1  iter :593 ]train loss : 0.355537 ,train acc: 0.836802 ,val loss : 0.449782 ,val acc : 0.803009\n",
      "[ ecpho : 1  iter :594 ]train loss : 0.302664 ,train acc: 0.853485 ,val loss : 0.450176 ,val acc : 0.804718\n",
      "[ ecpho : 1  iter :595 ]train loss : 0.341056 ,train acc: 0.842112 ,val loss : 0.449708 ,val acc : 0.802368\n",
      "[ ecpho : 1  iter :596 ]train loss : 0.325712 ,train acc: 0.844127 ,val loss : 0.452678 ,val acc : 0.809204\n",
      "[ ecpho : 1  iter :597 ]train loss : 0.427123 ,train acc: 0.807597 ,val loss : 0.439452 ,val acc : 0.808502\n",
      "[ ecpho : 1  iter :598 ]train loss : 0.393379 ,train acc: 0.832438 ,val loss : 0.443852 ,val acc : 0.806366\n",
      "[ ecpho : 1  iter :599 ]train loss : 0.353578 ,train acc: 0.844543 ,val loss : 0.450699 ,val acc : 0.804688\n",
      "[ ecpho : 1  iter :600 ]train loss : 0.360789 ,train acc: 0.838379 ,val loss : 0.451758 ,val acc : 0.802582\n",
      "[ ecpho : 1  iter :601 ]train loss : 0.342118 ,train acc: 0.843282 ,val loss : 0.447673 ,val acc : 0.806519\n",
      "[ ecpho : 1  iter :602 ]train loss : 0.336734 ,train acc: 0.846456 ,val loss : 0.452686 ,val acc : 0.805542\n",
      "[ ecpho : 1  iter :603 ]train loss : 0.334146 ,train acc: 0.845469 ,val loss : 0.450022 ,val acc : 0.803101\n",
      "[ ecpho : 1  iter :604 ]train loss : 0.371056 ,train acc: 0.834758 ,val loss : 0.452136 ,val acc : 0.804169\n",
      "[ ecpho : 1  iter :605 ]train loss : 0.388235 ,train acc: 0.803335 ,val loss : 0.448074 ,val acc : 0.806213\n",
      "[ ecpho : 1  iter :606 ]train loss : 0.365283 ,train acc: 0.835877 ,val loss : 0.444982 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :607 ]train loss : 0.342237 ,train acc: 0.843465 ,val loss : 0.450746 ,val acc : 0.806488\n",
      "[ ecpho : 1  iter :608 ]train loss : 0.386448 ,train acc: 0.811941 ,val loss : 0.456531 ,val acc : 0.803162\n",
      "[ ecpho : 1  iter :609 ]train loss : 0.373307 ,train acc: 0.811168 ,val loss : 0.444105 ,val acc : 0.802704\n",
      "[ ecpho : 1  iter :610 ]train loss : 0.329248 ,train acc: 0.846954 ,val loss : 0.449032 ,val acc : 0.802155\n",
      "[ ecpho : 1  iter :611 ]train loss : 0.426840 ,train acc: 0.801931 ,val loss : 0.444206 ,val acc : 0.805359\n",
      "[ ecpho : 1  iter :612 ]train loss : 0.341020 ,train acc: 0.839630 ,val loss : 0.453323 ,val acc : 0.804077\n",
      "[ ecpho : 1  iter :613 ]train loss : 0.406421 ,train acc: 0.821706 ,val loss : 0.450371 ,val acc : 0.804993\n",
      "[ ecpho : 1  iter :614 ]train loss : 0.532857 ,train acc: 0.807363 ,val loss : 0.444626 ,val acc : 0.806641\n",
      "[ ecpho : 1  iter :615 ]train loss : 0.348295 ,train acc: 0.822245 ,val loss : 0.448609 ,val acc : 0.802765\n",
      "[ ecpho : 1  iter :616 ]train loss : 0.351750 ,train acc: 0.829071 ,val loss : 0.453481 ,val acc : 0.805756\n",
      "[ ecpho : 1  iter :617 ]train loss : 0.315544 ,train acc: 0.853445 ,val loss : 0.447438 ,val acc : 0.806213\n",
      "[ ecpho : 1  iter :618 ]train loss : 0.372753 ,train acc: 0.798350 ,val loss : 0.450674 ,val acc : 0.805328\n",
      "[ ecpho : 1  iter :619 ]train loss : 0.400743 ,train acc: 0.834666 ,val loss : 0.456003 ,val acc : 0.805176\n",
      "[ ecpho : 1  iter :620 ]train loss : 0.374089 ,train acc: 0.841512 ,val loss : 0.445787 ,val acc : 0.808838\n",
      "[ ecpho : 1  iter :621 ]train loss : 0.338302 ,train acc: 0.846151 ,val loss : 0.455401 ,val acc : 0.803467\n",
      "[ ecpho : 1  iter :622 ]train loss : 0.336081 ,train acc: 0.846334 ,val loss : 0.446527 ,val acc : 0.805695\n",
      "[ ecpho : 1  iter :623 ]train loss : 0.327992 ,train acc: 0.848063 ,val loss : 0.457898 ,val acc : 0.801575\n",
      "[ ecpho : 1  iter :624 ]train loss : 0.379651 ,train acc: 0.833435 ,val loss : 0.451341 ,val acc : 0.802490\n",
      "[ ecpho : 1  iter :625 ]train loss : 0.340498 ,train acc: 0.837423 ,val loss : 0.447349 ,val acc : 0.805267\n",
      "[ ecpho : 1  iter :626 ]train loss : 0.345720 ,train acc: 0.838806 ,val loss : 0.451257 ,val acc : 0.803253\n",
      "[ ecpho : 1  iter :627 ]train loss : 0.386352 ,train acc: 0.835887 ,val loss : 0.445692 ,val acc : 0.805664\n",
      "[ ecpho : 1  iter :628 ]train loss : 0.350715 ,train acc: 0.845286 ,val loss : 0.453080 ,val acc : 0.802429\n",
      "[ ecpho : 1  iter :629 ]train loss : 0.340041 ,train acc: 0.846080 ,val loss : 0.447440 ,val acc : 0.803680\n",
      "[ ecpho : 1  iter :630 ]train loss : 0.367985 ,train acc: 0.841583 ,val loss : 0.450423 ,val acc : 0.805054\n",
      "[ ecpho : 1  iter :631 ]train loss : 0.406742 ,train acc: 0.819051 ,val loss : 0.445888 ,val acc : 0.804932\n",
      "[ ecpho : 1  iter :632 ]train loss : 0.487109 ,train acc: 0.811168 ,val loss : 0.450179 ,val acc : 0.804169\n",
      "[ ecpho : 1  iter :633 ]train loss : 0.344078 ,train acc: 0.837474 ,val loss : 0.449690 ,val acc : 0.807495\n",
      "[ ecpho : 1  iter :634 ]train loss : 0.334834 ,train acc: 0.847158 ,val loss : 0.454597 ,val acc : 0.801056\n",
      "[ ecpho : 1  iter :635 ]train loss : 0.444545 ,train acc: 0.788005 ,val loss : 0.452215 ,val acc : 0.804291\n",
      "[ ecpho : 1  iter :636 ]train loss : 0.415409 ,train acc: 0.801666 ,val loss : 0.445991 ,val acc : 0.807556\n",
      "[ ecpho : 1  iter :637 ]train loss : 0.386444 ,train acc: 0.802551 ,val loss : 0.447043 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :638 ]train loss : 0.313076 ,train acc: 0.851380 ,val loss : 0.445365 ,val acc : 0.805237\n",
      "[ ecpho : 1  iter :639 ]train loss : 0.348009 ,train acc: 0.834239 ,val loss : 0.442709 ,val acc : 0.807465\n",
      "[ ecpho : 1  iter :640 ]train loss : 0.360173 ,train acc: 0.835989 ,val loss : 0.445039 ,val acc : 0.806702\n",
      "[ ecpho : 1  iter :641 ]train loss : 0.340661 ,train acc: 0.839508 ,val loss : 0.448084 ,val acc : 0.805756\n",
      "[ ecpho : 1  iter :642 ]train loss : 0.467606 ,train acc: 0.813914 ,val loss : 0.448178 ,val acc : 0.806000\n",
      "[ ecpho : 1  iter :643 ]train loss : 0.468649 ,train acc: 0.815450 ,val loss : 0.451814 ,val acc : 0.806183\n",
      "[ ecpho : 1  iter :644 ]train loss : 0.343318 ,train acc: 0.842499 ,val loss : 0.446666 ,val acc : 0.809601\n",
      "[ ecpho : 1  iter :645 ]train loss : 0.402644 ,train acc: 0.830333 ,val loss : 0.444412 ,val acc : 0.808258\n",
      "[ ecpho : 1  iter :646 ]train loss : 0.390518 ,train acc: 0.805491 ,val loss : 0.446300 ,val acc : 0.806030\n",
      "[ ecpho : 1  iter :647 ]train loss : 0.364486 ,train acc: 0.824249 ,val loss : 0.445921 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :648 ]train loss : 0.430004 ,train acc: 0.823314 ,val loss : 0.446849 ,val acc : 0.807373\n",
      "[ ecpho : 1  iter :649 ]train loss : 0.381171 ,train acc: 0.834859 ,val loss : 0.445598 ,val acc : 0.803436\n",
      "[ ecpho : 1  iter :650 ]train loss : 0.541478 ,train acc: 0.750926 ,val loss : 0.442768 ,val acc : 0.805084\n",
      "[ ecpho : 1  iter :651 ]train loss : 0.402863 ,train acc: 0.816620 ,val loss : 0.450145 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :652 ]train loss : 0.305144 ,train acc: 0.854167 ,val loss : 0.448040 ,val acc : 0.806549\n",
      "[ ecpho : 1  iter :653 ]train loss : 0.429128 ,train acc: 0.816681 ,val loss : 0.443368 ,val acc : 0.807037\n",
      "[ ecpho : 1  iter :654 ]train loss : 0.306057 ,train acc: 0.855530 ,val loss : 0.444626 ,val acc : 0.805389\n",
      "[ ecpho : 1  iter :655 ]train loss : 0.416759 ,train acc: 0.814087 ,val loss : 0.453065 ,val acc : 0.803162\n",
      "[ ecpho : 1  iter :656 ]train loss : 0.342566 ,train acc: 0.837881 ,val loss : 0.449237 ,val acc : 0.803101\n",
      "[ ecpho : 1  iter :657 ]train loss : 0.331705 ,train acc: 0.843394 ,val loss : 0.443365 ,val acc : 0.807343\n",
      "[ ecpho : 1  iter :658 ]train loss : 0.344907 ,train acc: 0.844228 ,val loss : 0.438462 ,val acc : 0.807892\n",
      "[ ecpho : 1  iter :659 ]train loss : 0.352682 ,train acc: 0.842021 ,val loss : 0.446801 ,val acc : 0.807281\n",
      "[ ecpho : 1  iter :660 ]train loss : 0.379796 ,train acc: 0.826365 ,val loss : 0.443260 ,val acc : 0.806335\n",
      "[ ecpho : 1  iter :661 ]train loss : 0.331283 ,train acc: 0.849660 ,val loss : 0.448990 ,val acc : 0.804657\n",
      "[ ecpho : 1  iter :662 ]train loss : 0.370076 ,train acc: 0.841726 ,val loss : 0.445140 ,val acc : 0.805664\n",
      "[ ecpho : 1  iter :663 ]train loss : 0.490792 ,train acc: 0.826284 ,val loss : 0.444816 ,val acc : 0.806000\n",
      "[ ecpho : 1  iter :664 ]train loss : 0.365578 ,train acc: 0.840627 ,val loss : 0.444579 ,val acc : 0.807465\n",
      "[ ecpho : 1  iter :665 ]train loss : 0.557252 ,train acc: 0.777517 ,val loss : 0.446689 ,val acc : 0.804718\n",
      "[ ecpho : 1  iter :666 ]train loss : 0.414073 ,train acc: 0.810730 ,val loss : 0.445634 ,val acc : 0.807220\n",
      "[ ecpho : 1  iter :667 ]train loss : 0.340113 ,train acc: 0.844818 ,val loss : 0.451700 ,val acc : 0.803680\n",
      "[ ecpho : 1  iter :668 ]train loss : 0.307453 ,train acc: 0.850830 ,val loss : 0.444778 ,val acc : 0.806488\n",
      "[ ecpho : 1  iter :669 ]train loss : 0.389620 ,train acc: 0.757141 ,val loss : 0.447695 ,val acc : 0.804321\n",
      "[ ecpho : 1  iter :670 ]train loss : 0.330826 ,train acc: 0.841532 ,val loss : 0.447805 ,val acc : 0.802551\n",
      "[ ecpho : 1  iter :671 ]train loss : 0.356284 ,train acc: 0.846354 ,val loss : 0.446881 ,val acc : 0.808105\n",
      "[ ecpho : 1  iter :672 ]train loss : 0.393932 ,train acc: 0.793457 ,val loss : 0.446979 ,val acc : 0.804504\n",
      "[ ecpho : 1  iter :673 ]train loss : 0.440848 ,train acc: 0.812968 ,val loss : 0.450291 ,val acc : 0.803833\n",
      "[ ecpho : 1  iter :674 ]train loss : 0.418694 ,train acc: 0.784862 ,val loss : 0.440373 ,val acc : 0.806671\n",
      "[ ecpho : 1  iter :675 ]train loss : 0.349221 ,train acc: 0.840820 ,val loss : 0.441553 ,val acc : 0.807678\n",
      "[ ecpho : 1  iter :676 ]train loss : 0.416714 ,train acc: 0.816691 ,val loss : 0.444851 ,val acc : 0.806122\n",
      "[ ecpho : 1  iter :677 ]train loss : 0.348094 ,train acc: 0.848674 ,val loss : 0.447668 ,val acc : 0.805328\n",
      "[ ecpho : 1  iter :678 ]train loss : 0.316567 ,train acc: 0.853221 ,val loss : 0.445378 ,val acc : 0.806732\n",
      "[ ecpho : 1  iter :679 ]train loss : 0.406207 ,train acc: 0.824697 ,val loss : 0.452693 ,val acc : 0.803040\n",
      "[ ecpho : 1  iter :680 ]train loss : 0.360281 ,train acc: 0.840495 ,val loss : 0.453051 ,val acc : 0.806824\n",
      "[ ecpho : 1  iter :681 ]train loss : 0.373243 ,train acc: 0.838989 ,val loss : 0.449476 ,val acc : 0.803101\n",
      "[ ecpho : 1  iter :682 ]train loss : 0.340613 ,train acc: 0.841411 ,val loss : 0.445341 ,val acc : 0.804596\n",
      "[ ecpho : 1  iter :683 ]train loss : 0.333185 ,train acc: 0.849996 ,val loss : 0.443787 ,val acc : 0.806152\n",
      "[ ecpho : 1  iter :684 ]train loss : 0.473212 ,train acc: 0.767660 ,val loss : 0.449924 ,val acc : 0.805756\n",
      "[ ecpho : 1  iter :685 ]train loss : 0.361325 ,train acc: 0.820577 ,val loss : 0.448083 ,val acc : 0.807709\n",
      "[ ecpho : 1  iter :686 ]train loss : 0.393141 ,train acc: 0.831553 ,val loss : 0.443746 ,val acc : 0.806488\n",
      "[ ecpho : 1  iter :687 ]train loss : 0.373015 ,train acc: 0.806671 ,val loss : 0.448940 ,val acc : 0.805237\n",
      "[ ecpho : 1  iter :688 ]train loss : 0.376819 ,train acc: 0.837169 ,val loss : 0.448437 ,val acc : 0.807678\n",
      "[ ecpho : 1  iter :689 ]train loss : 0.325890 ,train acc: 0.849406 ,val loss : 0.441922 ,val acc : 0.806885\n",
      "[ ecpho : 1  iter :690 ]train loss : 0.322217 ,train acc: 0.850932 ,val loss : 0.446068 ,val acc : 0.805450\n",
      "[ ecpho : 1  iter :691 ]train loss : 0.353728 ,train acc: 0.843740 ,val loss : 0.445887 ,val acc : 0.806885\n",
      "[ ecpho : 1  iter :692 ]train loss : 0.468485 ,train acc: 0.752747 ,val loss : 0.444031 ,val acc : 0.805542\n",
      "[ ecpho : 1  iter :693 ]train loss : 0.419683 ,train acc: 0.828471 ,val loss : 0.444173 ,val acc : 0.807098\n",
      "[ ecpho : 1  iter :694 ]train loss : 0.405259 ,train acc: 0.778514 ,val loss : 0.445767 ,val acc : 0.807983\n",
      "[ ecpho : 1  iter :695 ]train loss : 0.447501 ,train acc: 0.832703 ,val loss : 0.440794 ,val acc : 0.809540\n",
      "[ ecpho : 1  iter :696 ]train loss : 0.547496 ,train acc: 0.750031 ,val loss : 0.446204 ,val acc : 0.807770\n",
      "[ ecpho : 1  iter :697 ]train loss : 0.344191 ,train acc: 0.843557 ,val loss : 0.447462 ,val acc : 0.805389\n",
      "[ ecpho : 1  iter :698 ]train loss : 0.494341 ,train acc: 0.779663 ,val loss : 0.441391 ,val acc : 0.808533\n",
      "[ ecpho : 1  iter :699 ]train loss : 0.494664 ,train acc: 0.773377 ,val loss : 0.442184 ,val acc : 0.806458\n",
      "[ ecpho : 1  iter :700 ]train loss : 0.414660 ,train acc: 0.800558 ,val loss : 0.447508 ,val acc : 0.807251\n",
      "[ ecpho : 1  iter :701 ]train loss : 0.347576 ,train acc: 0.838125 ,val loss : 0.446587 ,val acc : 0.808228\n",
      "[ ecpho : 1  iter :702 ]train loss : 0.317775 ,train acc: 0.847829 ,val loss : 0.447985 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :703 ]train loss : 0.394862 ,train acc: 0.793793 ,val loss : 0.439494 ,val acc : 0.809814\n",
      "[ ecpho : 1  iter :704 ]train loss : 0.345861 ,train acc: 0.840587 ,val loss : 0.448239 ,val acc : 0.803833\n",
      "[ ecpho : 1  iter :705 ]train loss : 0.414105 ,train acc: 0.793854 ,val loss : 0.440490 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :706 ]train loss : 0.357260 ,train acc: 0.832123 ,val loss : 0.439759 ,val acc : 0.804810\n",
      "[ ecpho : 1  iter :707 ]train loss : 0.386805 ,train acc: 0.811585 ,val loss : 0.444433 ,val acc : 0.807068\n",
      "[ ecpho : 1  iter :708 ]train loss : 0.349101 ,train acc: 0.843394 ,val loss : 0.449857 ,val acc : 0.805664\n",
      "[ ecpho : 1  iter :709 ]train loss : 0.377447 ,train acc: 0.820303 ,val loss : 0.449272 ,val acc : 0.803070\n",
      "[ ecpho : 1  iter :710 ]train loss : 0.335147 ,train acc: 0.844432 ,val loss : 0.442514 ,val acc : 0.807007\n",
      "[ ecpho : 1  iter :711 ]train loss : 0.323433 ,train acc: 0.845022 ,val loss : 0.441847 ,val acc : 0.808441\n",
      "[ ecpho : 1  iter :712 ]train loss : 0.366692 ,train acc: 0.818614 ,val loss : 0.443225 ,val acc : 0.808746\n",
      "[ ecpho : 1  iter :713 ]train loss : 0.386011 ,train acc: 0.833527 ,val loss : 0.452580 ,val acc : 0.806458\n",
      "[ ecpho : 1  iter :714 ]train loss : 0.368752 ,train acc: 0.839122 ,val loss : 0.436518 ,val acc : 0.807892\n",
      "[ ecpho : 1  iter :715 ]train loss : 0.385684 ,train acc: 0.822408 ,val loss : 0.447285 ,val acc : 0.805206\n",
      "[ ecpho : 1  iter :716 ]train loss : 0.410370 ,train acc: 0.817363 ,val loss : 0.443916 ,val acc : 0.807434\n",
      "[ ecpho : 1  iter :717 ]train loss : 0.343725 ,train acc: 0.835114 ,val loss : 0.448305 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :718 ]train loss : 0.338708 ,train acc: 0.848440 ,val loss : 0.439483 ,val acc : 0.808441\n",
      "[ ecpho : 1  iter :719 ]train loss : 0.359344 ,train acc: 0.843018 ,val loss : 0.449564 ,val acc : 0.804932\n",
      "[ ecpho : 1  iter :720 ]train loss : 0.348806 ,train acc: 0.842377 ,val loss : 0.438655 ,val acc : 0.809540\n",
      "[ ecpho : 1  iter :721 ]train loss : 0.432874 ,train acc: 0.831299 ,val loss : 0.441139 ,val acc : 0.804810\n",
      "[ ecpho : 1  iter :722 ]train loss : 0.365250 ,train acc: 0.844035 ,val loss : 0.445667 ,val acc : 0.806671\n",
      "[ ecpho : 1  iter :723 ]train loss : 0.368170 ,train acc: 0.831523 ,val loss : 0.438826 ,val acc : 0.809692\n",
      "[ ecpho : 1  iter :724 ]train loss : 0.377231 ,train acc: 0.814504 ,val loss : 0.441222 ,val acc : 0.807922\n",
      "[ ecpho : 1  iter :725 ]train loss : 0.324111 ,train acc: 0.845998 ,val loss : 0.447446 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :726 ]train loss : 0.419107 ,train acc: 0.817668 ,val loss : 0.442933 ,val acc : 0.806946\n",
      "[ ecpho : 1  iter :727 ]train loss : 0.382845 ,train acc: 0.823507 ,val loss : 0.442143 ,val acc : 0.806763\n",
      "[ ecpho : 1  iter :728 ]train loss : 0.369000 ,train acc: 0.832784 ,val loss : 0.443539 ,val acc : 0.808228\n",
      "[ ecpho : 1  iter :729 ]train loss : 0.400862 ,train acc: 0.818166 ,val loss : 0.441924 ,val acc : 0.807220\n",
      "[ ecpho : 1  iter :730 ]train loss : 0.334718 ,train acc: 0.845805 ,val loss : 0.444590 ,val acc : 0.803345\n",
      "[ ecpho : 1  iter :731 ]train loss : 0.412438 ,train acc: 0.826304 ,val loss : 0.443622 ,val acc : 0.804871\n",
      "[ ecpho : 1  iter :732 ]train loss : 0.390841 ,train acc: 0.835093 ,val loss : 0.446561 ,val acc : 0.804901\n",
      "[ ecpho : 1  iter :733 ]train loss : 0.323626 ,train acc: 0.849569 ,val loss : 0.446604 ,val acc : 0.808319\n",
      "[ ecpho : 1  iter :734 ]train loss : 0.417531 ,train acc: 0.828441 ,val loss : 0.446150 ,val acc : 0.804230\n",
      "[ ecpho : 1  iter :735 ]train loss : 0.429150 ,train acc: 0.801066 ,val loss : 0.443713 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :736 ]train loss : 0.355452 ,train acc: 0.834859 ,val loss : 0.445060 ,val acc : 0.808868\n",
      "[ ecpho : 1  iter :737 ]train loss : 0.351413 ,train acc: 0.832377 ,val loss : 0.441868 ,val acc : 0.808014\n",
      "[ ecpho : 1  iter :738 ]train loss : 0.317692 ,train acc: 0.849254 ,val loss : 0.437699 ,val acc : 0.810944\n",
      "[ ecpho : 1  iter :739 ]train loss : 0.342117 ,train acc: 0.843303 ,val loss : 0.443699 ,val acc : 0.808136\n",
      "[ ecpho : 1  iter :740 ]train loss : 0.353383 ,train acc: 0.840261 ,val loss : 0.441713 ,val acc : 0.805450\n",
      "[ ecpho : 1  iter :741 ]train loss : 0.393362 ,train acc: 0.828705 ,val loss : 0.444537 ,val acc : 0.805298\n",
      "[ ecpho : 1  iter :742 ]train loss : 0.353453 ,train acc: 0.841645 ,val loss : 0.444718 ,val acc : 0.808563\n",
      "[ ecpho : 1  iter :743 ]train loss : 0.365148 ,train acc: 0.823436 ,val loss : 0.442172 ,val acc : 0.809326\n",
      "[ ecpho : 1  iter :744 ]train loss : 0.312613 ,train acc: 0.851318 ,val loss : 0.442144 ,val acc : 0.806152\n",
      "[ ecpho : 1  iter :745 ]train loss : 0.343835 ,train acc: 0.847850 ,val loss : 0.443973 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :746 ]train loss : 0.437138 ,train acc: 0.821818 ,val loss : 0.440052 ,val acc : 0.811035\n",
      "[ ecpho : 1  iter :747 ]train loss : 0.396345 ,train acc: 0.820008 ,val loss : 0.446840 ,val acc : 0.809143\n",
      "[ ecpho : 1  iter :748 ]train loss : 0.337023 ,train acc: 0.843486 ,val loss : 0.444266 ,val acc : 0.805054\n",
      "[ ecpho : 1  iter :749 ]train loss : 0.360295 ,train acc: 0.837179 ,val loss : 0.440102 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :750 ]train loss : 0.381566 ,train acc: 0.822235 ,val loss : 0.445158 ,val acc : 0.805420\n",
      "[ ecpho : 1  iter :751 ]train loss : 0.334259 ,train acc: 0.849610 ,val loss : 0.443351 ,val acc : 0.803436\n",
      "[ ecpho : 1  iter :752 ]train loss : 0.311765 ,train acc: 0.851268 ,val loss : 0.449328 ,val acc : 0.804626\n",
      "[ ecpho : 1  iter :753 ]train loss : 0.439072 ,train acc: 0.830801 ,val loss : 0.444967 ,val acc : 0.807159\n",
      "[ ecpho : 1  iter :754 ]train loss : 0.455681 ,train acc: 0.801392 ,val loss : 0.441195 ,val acc : 0.810913\n",
      "[ ecpho : 1  iter :755 ]train loss : 0.287770 ,train acc: 0.863129 ,val loss : 0.450067 ,val acc : 0.805359\n",
      "[ ecpho : 1  iter :756 ]train loss : 0.310483 ,train acc: 0.853628 ,val loss : 0.436876 ,val acc : 0.808258\n",
      "[ ecpho : 1  iter :757 ]train loss : 0.394650 ,train acc: 0.835968 ,val loss : 0.444777 ,val acc : 0.807465\n",
      "[ ecpho : 1  iter :758 ]train loss : 0.531924 ,train acc: 0.737753 ,val loss : 0.447124 ,val acc : 0.804382\n",
      "[ ecpho : 1  iter :759 ]train loss : 0.322059 ,train acc: 0.847392 ,val loss : 0.443857 ,val acc : 0.806061\n",
      "[ ecpho : 1  iter :760 ]train loss : 0.404131 ,train acc: 0.827993 ,val loss : 0.446860 ,val acc : 0.804749\n",
      "[ ecpho : 1  iter :761 ]train loss : 0.332309 ,train acc: 0.842133 ,val loss : 0.444585 ,val acc : 0.804321\n",
      "[ ecpho : 1  iter :762 ]train loss : 0.330606 ,train acc: 0.841685 ,val loss : 0.435087 ,val acc : 0.807983\n",
      "[ ecpho : 1  iter :763 ]train loss : 0.316348 ,train acc: 0.850454 ,val loss : 0.447694 ,val acc : 0.803253\n",
      "[ ecpho : 1  iter :764 ]train loss : 0.328997 ,train acc: 0.841878 ,val loss : 0.444347 ,val acc : 0.808228\n",
      "[ ecpho : 1  iter :765 ]train loss : 0.331127 ,train acc: 0.852651 ,val loss : 0.444876 ,val acc : 0.806641\n",
      "[ ecpho : 1  iter :766 ]train loss : 0.320124 ,train acc: 0.847890 ,val loss : 0.439155 ,val acc : 0.808624\n",
      "[ ecpho : 1  iter :767 ]train loss : 0.367977 ,train acc: 0.818085 ,val loss : 0.441692 ,val acc : 0.805969\n",
      "[ ecpho : 1  iter :768 ]train loss : 0.321172 ,train acc: 0.851441 ,val loss : 0.450029 ,val acc : 0.804779\n",
      "[ ecpho : 1  iter :769 ]train loss : 0.381470 ,train acc: 0.835155 ,val loss : 0.441308 ,val acc : 0.809082\n",
      "[ ecpho : 1  iter :770 ]train loss : 0.384406 ,train acc: 0.806875 ,val loss : 0.444941 ,val acc : 0.803406\n",
      "[ ecpho : 1  iter :771 ]train loss : 0.370730 ,train acc: 0.839905 ,val loss : 0.435054 ,val acc : 0.809906\n",
      "[ ecpho : 1  iter :772 ]train loss : 0.376585 ,train acc: 0.830984 ,val loss : 0.444316 ,val acc : 0.806335\n",
      "[ ecpho : 1  iter :773 ]train loss : 0.460651 ,train acc: 0.781362 ,val loss : 0.448686 ,val acc : 0.805237\n",
      "[ ecpho : 1  iter :774 ]train loss : 0.377149 ,train acc: 0.827820 ,val loss : 0.440762 ,val acc : 0.807648\n",
      "[ ecpho : 1  iter :775 ]train loss : 0.366350 ,train acc: 0.815349 ,val loss : 0.435529 ,val acc : 0.808441\n",
      "[ ecpho : 1  iter :776 ]train loss : 0.404860 ,train acc: 0.800944 ,val loss : 0.440882 ,val acc : 0.806000\n",
      "[ ecpho : 1  iter :777 ]train loss : 0.344874 ,train acc: 0.839112 ,val loss : 0.441228 ,val acc : 0.807129\n",
      "[ ecpho : 1  iter :778 ]train loss : 0.342861 ,train acc: 0.844076 ,val loss : 0.438602 ,val acc : 0.807587\n",
      "[ ecpho : 1  iter :779 ]train loss : 0.422284 ,train acc: 0.802948 ,val loss : 0.444075 ,val acc : 0.804626\n",
      "[ ecpho : 1  iter :780 ]train loss : 0.309539 ,train acc: 0.854848 ,val loss : 0.441651 ,val acc : 0.809540\n",
      "[ ecpho : 1  iter :781 ]train loss : 0.346610 ,train acc: 0.845144 ,val loss : 0.442247 ,val acc : 0.806519\n",
      "[ ecpho : 1  iter :782 ]train loss : 0.407567 ,train acc: 0.834076 ,val loss : 0.444057 ,val acc : 0.808075\n",
      "[ ecpho : 1  iter :783 ]train loss : 0.441850 ,train acc: 0.719859 ,val loss : 0.438337 ,val acc : 0.807495\n",
      "[ ecpho : 1  iter :784 ]train loss : 0.341028 ,train acc: 0.845286 ,val loss : 0.438995 ,val acc : 0.807678\n",
      "[ ecpho : 1  iter :785 ]train loss : 0.325056 ,train acc: 0.847361 ,val loss : 0.444729 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :786 ]train loss : 0.344888 ,train acc: 0.837779 ,val loss : 0.443250 ,val acc : 0.807739\n",
      "[ ecpho : 1  iter :787 ]train loss : 0.337693 ,train acc: 0.843160 ,val loss : 0.446306 ,val acc : 0.807434\n",
      "[ ecpho : 1  iter :788 ]train loss : 0.355920 ,train acc: 0.846710 ,val loss : 0.446072 ,val acc : 0.806763\n",
      "[ ecpho : 1  iter :789 ]train loss : 0.346594 ,train acc: 0.847809 ,val loss : 0.440432 ,val acc : 0.808014\n",
      "[ ecpho : 1  iter :790 ]train loss : 0.361212 ,train acc: 0.829519 ,val loss : 0.447068 ,val acc : 0.805267\n",
      "[ ecpho : 1  iter :791 ]train loss : 0.467103 ,train acc: 0.822449 ,val loss : 0.440473 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :792 ]train loss : 0.400248 ,train acc: 0.829610 ,val loss : 0.436928 ,val acc : 0.808929\n",
      "[ ecpho : 1  iter :793 ]train loss : 0.453177 ,train acc: 0.810079 ,val loss : 0.435484 ,val acc : 0.809143\n",
      "[ ecpho : 1  iter :794 ]train loss : 0.354474 ,train acc: 0.846303 ,val loss : 0.443328 ,val acc : 0.809357\n",
      "[ ecpho : 1  iter :795 ]train loss : 0.344734 ,train acc: 0.842814 ,val loss : 0.444014 ,val acc : 0.804352\n",
      "[ ecpho : 1  iter :796 ]train loss : 0.338341 ,train acc: 0.842733 ,val loss : 0.437605 ,val acc : 0.809784\n",
      "[ ecpho : 1  iter :797 ]train loss : 0.397117 ,train acc: 0.809927 ,val loss : 0.438043 ,val acc : 0.805054\n",
      "[ ecpho : 1  iter :798 ]train loss : 0.393171 ,train acc: 0.828003 ,val loss : 0.441862 ,val acc : 0.805695\n",
      "[ ecpho : 1  iter :799 ]train loss : 0.289544 ,train acc: 0.860464 ,val loss : 0.447913 ,val acc : 0.808228\n",
      "[ ecpho : 1  iter :800 ]train loss : 0.410416 ,train acc: 0.827210 ,val loss : 0.440363 ,val acc : 0.806335\n",
      "[ ecpho : 1  iter :801 ]train loss : 0.369744 ,train acc: 0.837514 ,val loss : 0.436085 ,val acc : 0.806671\n",
      "[ ecpho : 1  iter :802 ]train loss : 0.352057 ,train acc: 0.840637 ,val loss : 0.442096 ,val acc : 0.808197\n",
      "[ ecpho : 1  iter :803 ]train loss : 0.353904 ,train acc: 0.826620 ,val loss : 0.440137 ,val acc : 0.806396\n",
      "[ ecpho : 1  iter :804 ]train loss : 0.408863 ,train acc: 0.817414 ,val loss : 0.443773 ,val acc : 0.803925\n",
      "[ ecpho : 1  iter :805 ]train loss : 0.299635 ,train acc: 0.859497 ,val loss : 0.441129 ,val acc : 0.806305\n",
      "[ ecpho : 1  iter :806 ]train loss : 0.354571 ,train acc: 0.843231 ,val loss : 0.435687 ,val acc : 0.807465\n",
      "[ ecpho : 1  iter :807 ]train loss : 0.381537 ,train acc: 0.805217 ,val loss : 0.443013 ,val acc : 0.809021\n",
      "[ ecpho : 1  iter :808 ]train loss : 0.339872 ,train acc: 0.838298 ,val loss : 0.437725 ,val acc : 0.809875\n",
      "[ ecpho : 1  iter :809 ]train loss : 0.337165 ,train acc: 0.846059 ,val loss : 0.445587 ,val acc : 0.805939\n",
      "[ ecpho : 1  iter :810 ]train loss : 0.353373 ,train acc: 0.848033 ,val loss : 0.446046 ,val acc : 0.808014\n",
      "[ ecpho : 1  iter :811 ]train loss : 0.354896 ,train acc: 0.842682 ,val loss : 0.437193 ,val acc : 0.809814\n",
      "[ ecpho : 1  iter :812 ]train loss : 0.340289 ,train acc: 0.838684 ,val loss : 0.444827 ,val acc : 0.808350\n",
      "[ ecpho : 1  iter :813 ]train loss : 0.355977 ,train acc: 0.846914 ,val loss : 0.444612 ,val acc : 0.804626\n",
      "[ ecpho : 1  iter :814 ]train loss : 0.343818 ,train acc: 0.837362 ,val loss : 0.446296 ,val acc : 0.807373\n",
      "[ ecpho : 1  iter :815 ]train loss : 0.298404 ,train acc: 0.860962 ,val loss : 0.441345 ,val acc : 0.807922\n",
      "[ ecpho : 1  iter :816 ]train loss : 0.422504 ,train acc: 0.808279 ,val loss : 0.438891 ,val acc : 0.809784\n",
      "[ ecpho : 1  iter :817 ]train loss : 0.345242 ,train acc: 0.833720 ,val loss : 0.444886 ,val acc : 0.806061\n",
      "[ ecpho : 1  iter :818 ]train loss : 0.318630 ,train acc: 0.852794 ,val loss : 0.440872 ,val acc : 0.804047\n",
      "[ ecpho : 1  iter :819 ]train loss : 0.349155 ,train acc: 0.828207 ,val loss : 0.441577 ,val acc : 0.805878\n",
      "[ ecpho : 1  iter :820 ]train loss : 0.343747 ,train acc: 0.847483 ,val loss : 0.439838 ,val acc : 0.806946\n",
      "[ ecpho : 1  iter :821 ]train loss : 0.364007 ,train acc: 0.845083 ,val loss : 0.434205 ,val acc : 0.808868\n",
      "[ ecpho : 1  iter :822 ]train loss : 0.365324 ,train acc: 0.837932 ,val loss : 0.438071 ,val acc : 0.807373\n",
      "[ ecpho : 1  iter :823 ]train loss : 0.331625 ,train acc: 0.844686 ,val loss : 0.438161 ,val acc : 0.806488\n",
      "[ ecpho : 1  iter :824 ]train loss : 0.483514 ,train acc: 0.797669 ,val loss : 0.440364 ,val acc : 0.806976\n",
      "[ ecpho : 1  iter :825 ]train loss : 0.311582 ,train acc: 0.850271 ,val loss : 0.438736 ,val acc : 0.809052\n",
      "[ ecpho : 1  iter :826 ]train loss : 0.288167 ,train acc: 0.862132 ,val loss : 0.444756 ,val acc : 0.809448\n",
      "[ ecpho : 1  iter :827 ]train loss : 0.338323 ,train acc: 0.845073 ,val loss : 0.446130 ,val acc : 0.807159\n",
      "[ ecpho : 1  iter :828 ]train loss : 0.429216 ,train acc: 0.777303 ,val loss : 0.437647 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :829 ]train loss : 0.329150 ,train acc: 0.844218 ,val loss : 0.450644 ,val acc : 0.802917\n",
      "[ ecpho : 1  iter :830 ]train loss : 0.485626 ,train acc: 0.727468 ,val loss : 0.435412 ,val acc : 0.809814\n",
      "[ ecpho : 1  iter :831 ]train loss : 0.487263 ,train acc: 0.821971 ,val loss : 0.433088 ,val acc : 0.811432\n",
      "[ ecpho : 1  iter :832 ]train loss : 0.339325 ,train acc: 0.851634 ,val loss : 0.447072 ,val acc : 0.806396\n",
      "[ ecpho : 1  iter :833 ]train loss : 0.301377 ,train acc: 0.858978 ,val loss : 0.442231 ,val acc : 0.808807\n",
      "[ ecpho : 1  iter :834 ]train loss : 0.458011 ,train acc: 0.716756 ,val loss : 0.437089 ,val acc : 0.808441\n",
      "[ ecpho : 1  iter :835 ]train loss : 0.407312 ,train acc: 0.830597 ,val loss : 0.444912 ,val acc : 0.801453\n",
      "[ ecpho : 1  iter :836 ]train loss : 0.438390 ,train acc: 0.797516 ,val loss : 0.434231 ,val acc : 0.811707\n",
      "[ ecpho : 1  iter :837 ]train loss : 0.361632 ,train acc: 0.838125 ,val loss : 0.444520 ,val acc : 0.806854\n",
      "[ ecpho : 1  iter :838 ]train loss : 0.367558 ,train acc: 0.838216 ,val loss : 0.442139 ,val acc : 0.804352\n",
      "[ ecpho : 1  iter :839 ]train loss : 0.312128 ,train acc: 0.858338 ,val loss : 0.437607 ,val acc : 0.807892\n",
      "[ ecpho : 1  iter :840 ]train loss : 0.350857 ,train acc: 0.844910 ,val loss : 0.439128 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :841 ]train loss : 0.342564 ,train acc: 0.849284 ,val loss : 0.438787 ,val acc : 0.808563\n",
      "[ ecpho : 1  iter :842 ]train loss : 0.348817 ,train acc: 0.849518 ,val loss : 0.434250 ,val acc : 0.810730\n",
      "[ ecpho : 1  iter :843 ]train loss : 0.353704 ,train acc: 0.833333 ,val loss : 0.431960 ,val acc : 0.812408\n",
      "[ ecpho : 1  iter :844 ]train loss : 0.398692 ,train acc: 0.836345 ,val loss : 0.441402 ,val acc : 0.806427\n",
      "[ ecpho : 1  iter :845 ]train loss : 0.344752 ,train acc: 0.846537 ,val loss : 0.441027 ,val acc : 0.808075\n",
      "[ ecpho : 1  iter :846 ]train loss : 0.414045 ,train acc: 0.827281 ,val loss : 0.438010 ,val acc : 0.808044\n",
      "[ ecpho : 1  iter :847 ]train loss : 0.394748 ,train acc: 0.836406 ,val loss : 0.445215 ,val acc : 0.807220\n",
      "[ ecpho : 1  iter :848 ]train loss : 0.316315 ,train acc: 0.853465 ,val loss : 0.431526 ,val acc : 0.811920\n",
      "[ ecpho : 1  iter :849 ]train loss : 0.400416 ,train acc: 0.817627 ,val loss : 0.439371 ,val acc : 0.808289\n",
      "[ ecpho : 1  iter :850 ]train loss : 0.423582 ,train acc: 0.802775 ,val loss : 0.433599 ,val acc : 0.806702\n",
      "[ ecpho : 1  iter :851 ]train loss : 0.357144 ,train acc: 0.839142 ,val loss : 0.438589 ,val acc : 0.808502\n",
      "[ ecpho : 1  iter :852 ]train loss : 0.389656 ,train acc: 0.837433 ,val loss : 0.434980 ,val acc : 0.809570\n",
      "[ ecpho : 1  iter :853 ]train loss : 0.313880 ,train acc: 0.848948 ,val loss : 0.436219 ,val acc : 0.809296\n",
      "[ ecpho : 1  iter :854 ]train loss : 0.296720 ,train acc: 0.857656 ,val loss : 0.434208 ,val acc : 0.808716\n",
      "[ ecpho : 1  iter :855 ]train loss : 0.498046 ,train acc: 0.817342 ,val loss : 0.435651 ,val acc : 0.809845\n",
      "[ ecpho : 1  iter :856 ]train loss : 0.433040 ,train acc: 0.800476 ,val loss : 0.434420 ,val acc : 0.809021\n",
      "[ ecpho : 1  iter :857 ]train loss : 0.343289 ,train acc: 0.851023 ,val loss : 0.434565 ,val acc : 0.809692\n",
      "[ ecpho : 1  iter :858 ]train loss : 0.340186 ,train acc: 0.842580 ,val loss : 0.437612 ,val acc : 0.805359\n",
      "[ ecpho : 1  iter :859 ]train loss : 0.358665 ,train acc: 0.826131 ,val loss : 0.442111 ,val acc : 0.804138\n",
      "[ ecpho : 1  iter :860 ]train loss : 0.371398 ,train acc: 0.829366 ,val loss : 0.436971 ,val acc : 0.808624\n",
      "[ ecpho : 1  iter :861 ]train loss : 0.312246 ,train acc: 0.854014 ,val loss : 0.439545 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :862 ]train loss : 0.386494 ,train acc: 0.834900 ,val loss : 0.440530 ,val acc : 0.808319\n",
      "[ ecpho : 1  iter :863 ]train loss : 0.354672 ,train acc: 0.846314 ,val loss : 0.440308 ,val acc : 0.807709\n",
      "[ ecpho : 1  iter :864 ]train loss : 0.394506 ,train acc: 0.817637 ,val loss : 0.441892 ,val acc : 0.810089\n",
      "[ ecpho : 1  iter :865 ]train loss : 0.407496 ,train acc: 0.800151 ,val loss : 0.441456 ,val acc : 0.806458\n",
      "[ ecpho : 1  iter :866 ]train loss : 0.330224 ,train acc: 0.851522 ,val loss : 0.436571 ,val acc : 0.808960\n",
      "[ ecpho : 1  iter :867 ]train loss : 0.278035 ,train acc: 0.866954 ,val loss : 0.434672 ,val acc : 0.812103\n",
      "[ ecpho : 1  iter :868 ]train loss : 0.468007 ,train acc: 0.778331 ,val loss : 0.437973 ,val acc : 0.811127\n",
      "[ ecpho : 1  iter :869 ]train loss : 0.364937 ,train acc: 0.828919 ,val loss : 0.445918 ,val acc : 0.804352\n",
      "[ ecpho : 1  iter :870 ]train loss : 0.338047 ,train acc: 0.845022 ,val loss : 0.437596 ,val acc : 0.808014\n",
      "[ ecpho : 1  iter :871 ]train loss : 0.301538 ,train acc: 0.857870 ,val loss : 0.438090 ,val acc : 0.807983\n",
      "[ ecpho : 1  iter :872 ]train loss : 0.351974 ,train acc: 0.843252 ,val loss : 0.433438 ,val acc : 0.810547\n",
      "[ ecpho : 1  iter :873 ]train loss : 0.383376 ,train acc: 0.831940 ,val loss : 0.437004 ,val acc : 0.806519\n",
      "[ ecpho : 1  iter :874 ]train loss : 0.343568 ,train acc: 0.821635 ,val loss : 0.434063 ,val acc : 0.808289\n",
      "[ ecpho : 1  iter :875 ]train loss : 0.371603 ,train acc: 0.828339 ,val loss : 0.434917 ,val acc : 0.809692\n",
      "[ ecpho : 1  iter :876 ]train loss : 0.350875 ,train acc: 0.839223 ,val loss : 0.439072 ,val acc : 0.807526\n",
      "[ ecpho : 1  iter :877 ]train loss : 0.339353 ,train acc: 0.846670 ,val loss : 0.440698 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :878 ]train loss : 0.322076 ,train acc: 0.850993 ,val loss : 0.438817 ,val acc : 0.807648\n",
      "[ ecpho : 1  iter :879 ]train loss : 0.340263 ,train acc: 0.845876 ,val loss : 0.442678 ,val acc : 0.804932\n",
      "[ ecpho : 1  iter :880 ]train loss : 0.346542 ,train acc: 0.846131 ,val loss : 0.431914 ,val acc : 0.808472\n",
      "[ ecpho : 1  iter :881 ]train loss : 0.511473 ,train acc: 0.766765 ,val loss : 0.437079 ,val acc : 0.809814\n",
      "[ ecpho : 1  iter :882 ]train loss : 0.385766 ,train acc: 0.808838 ,val loss : 0.440672 ,val acc : 0.808105\n",
      "[ ecpho : 1  iter :883 ]train loss : 0.311564 ,train acc: 0.852509 ,val loss : 0.433605 ,val acc : 0.809418\n",
      "[ ecpho : 1  iter :884 ]train loss : 0.397838 ,train acc: 0.790700 ,val loss : 0.438495 ,val acc : 0.807617\n",
      "[ ecpho : 1  iter :885 ]train loss : 0.300678 ,train acc: 0.855815 ,val loss : 0.439756 ,val acc : 0.806458\n",
      "[ ecpho : 1  iter :886 ]train loss : 0.381392 ,train acc: 0.832977 ,val loss : 0.434801 ,val acc : 0.809509\n",
      "[ ecpho : 1  iter :887 ]train loss : 0.398737 ,train acc: 0.809438 ,val loss : 0.435238 ,val acc : 0.807831\n",
      "[ ecpho : 1  iter :888 ]train loss : 0.326974 ,train acc: 0.848297 ,val loss : 0.441564 ,val acc : 0.807190\n",
      "[ ecpho : 1  iter :889 ]train loss : 0.450016 ,train acc: 0.805786 ,val loss : 0.434520 ,val acc : 0.809906\n",
      "[ ecpho : 1  iter :890 ]train loss : 0.440612 ,train acc: 0.827189 ,val loss : 0.441133 ,val acc : 0.807373\n",
      "[ ecpho : 1  iter :891 ]train loss : 0.393100 ,train acc: 0.838725 ,val loss : 0.440464 ,val acc : 0.807983\n",
      "[ ecpho : 1  iter :892 ]train loss : 0.379468 ,train acc: 0.825694 ,val loss : 0.441038 ,val acc : 0.810181\n",
      "[ ecpho : 1  iter :893 ]train loss : 0.329297 ,train acc: 0.828034 ,val loss : 0.431625 ,val acc : 0.812103\n",
      "[ ecpho : 1  iter :894 ]train loss : 0.410328 ,train acc: 0.787496 ,val loss : 0.441763 ,val acc : 0.807617\n",
      "[ ecpho : 1  iter :895 ]train loss : 0.344852 ,train acc: 0.845286 ,val loss : 0.437205 ,val acc : 0.806030\n",
      "[ ecpho : 1  iter :896 ]train loss : 0.339683 ,train acc: 0.833344 ,val loss : 0.432444 ,val acc : 0.807434\n",
      "[ ecpho : 1  iter :897 ]train loss : 0.381674 ,train acc: 0.846405 ,val loss : 0.436172 ,val acc : 0.807068\n",
      "[ ecpho : 1  iter :898 ]train loss : 0.349637 ,train acc: 0.827454 ,val loss : 0.432350 ,val acc : 0.807495\n",
      "[ ecpho : 1  iter :899 ]train loss : 0.355761 ,train acc: 0.849325 ,val loss : 0.436719 ,val acc : 0.810486\n",
      "[ ecpho : 1  iter :900 ]train loss : 0.327557 ,train acc: 0.849813 ,val loss : 0.438659 ,val acc : 0.810028\n",
      "[ ecpho : 1  iter :901 ]train loss : 0.367736 ,train acc: 0.837565 ,val loss : 0.441849 ,val acc : 0.806641\n",
      "[ ecpho : 1  iter :902 ]train loss : 0.485927 ,train acc: 0.814881 ,val loss : 0.432898 ,val acc : 0.809357\n",
      "[ ecpho : 1  iter :903 ]train loss : 0.385852 ,train acc: 0.805715 ,val loss : 0.433831 ,val acc : 0.808929\n",
      "[ ecpho : 1  iter :904 ]train loss : 0.333647 ,train acc: 0.842194 ,val loss : 0.437838 ,val acc : 0.806671\n",
      "[ ecpho : 1  iter :905 ]train loss : 0.316551 ,train acc: 0.855703 ,val loss : 0.438764 ,val acc : 0.805359\n",
      "[ ecpho : 1  iter :906 ]train loss : 0.350281 ,train acc: 0.843486 ,val loss : 0.430790 ,val acc : 0.809753\n",
      "[ ecpho : 1  iter :907 ]train loss : 0.354923 ,train acc: 0.844472 ,val loss : 0.444874 ,val acc : 0.808075\n",
      "[ ecpho : 1  iter :908 ]train loss : 0.364592 ,train acc: 0.828898 ,val loss : 0.434709 ,val acc : 0.810089\n",
      "[ ecpho : 1  iter :909 ]train loss : 0.336763 ,train acc: 0.845764 ,val loss : 0.449094 ,val acc : 0.806549\n",
      "[ ecpho : 1  iter :910 ]train loss : 0.377495 ,train acc: 0.836070 ,val loss : 0.435668 ,val acc : 0.809631\n",
      "[ ecpho : 1  iter :911 ]train loss : 0.301255 ,train acc: 0.853424 ,val loss : 0.439339 ,val acc : 0.808197\n",
      "[ ecpho : 1  iter :912 ]train loss : 0.340611 ,train acc: 0.845825 ,val loss : 0.439937 ,val acc : 0.802216\n",
      "[ ecpho : 1  iter :913 ]train loss : 0.312327 ,train acc: 0.851725 ,val loss : 0.433227 ,val acc : 0.811371\n",
      "[ ecpho : 1  iter :914 ]train loss : 0.417042 ,train acc: 0.814179 ,val loss : 0.442003 ,val acc : 0.807861\n",
      "[ ecpho : 1  iter :915 ]train loss : 0.309518 ,train acc: 0.855357 ,val loss : 0.437587 ,val acc : 0.807190\n",
      "[ ecpho : 1  iter :916 ]train loss : 0.336720 ,train acc: 0.838562 ,val loss : 0.432903 ,val acc : 0.812347\n",
      "[ ecpho : 1  iter :917 ]train loss : 0.342994 ,train acc: 0.842011 ,val loss : 0.437237 ,val acc : 0.808411\n",
      "[ ecpho : 1  iter :918 ]train loss : 0.323220 ,train acc: 0.839335 ,val loss : 0.442164 ,val acc : 0.808777\n",
      "[ ecpho : 1  iter :919 ]train loss : 0.372418 ,train acc: 0.834910 ,val loss : 0.433511 ,val acc : 0.807404\n",
      "[ ecpho : 1  iter :920 ]train loss : 0.717959 ,train acc: 0.715861 ,val loss : 0.435124 ,val acc : 0.807251\n",
      "[ ecpho : 1  iter :921 ]train loss : 0.334318 ,train acc: 0.847829 ,val loss : 0.434597 ,val acc : 0.811523\n",
      "[ ecpho : 1  iter :922 ]train loss : 0.351462 ,train acc: 0.851207 ,val loss : 0.432571 ,val acc : 0.810638\n",
      "[ ecpho : 1  iter :923 ]train loss : 0.341709 ,train acc: 0.840902 ,val loss : 0.433915 ,val acc : 0.806305\n",
      "[ ecpho : 1  iter :924 ]train loss : 0.295406 ,train acc: 0.860464 ,val loss : 0.434140 ,val acc : 0.808716\n",
      "[ ecpho : 1  iter :925 ]train loss : 0.332665 ,train acc: 0.846537 ,val loss : 0.433296 ,val acc : 0.810760\n",
      "[ ecpho : 1  iter :926 ]train loss : 0.318633 ,train acc: 0.847799 ,val loss : 0.438566 ,val acc : 0.805176\n",
      "[ ecpho : 1  iter :927 ]train loss : 0.368153 ,train acc: 0.841065 ,val loss : 0.435873 ,val acc : 0.807343\n",
      "[ ecpho : 1  iter :928 ]train loss : 0.351753 ,train acc: 0.840505 ,val loss : 0.437458 ,val acc : 0.806274\n",
      "[ ecpho : 1  iter :929 ]train loss : 0.307285 ,train acc: 0.855896 ,val loss : 0.437484 ,val acc : 0.809296\n",
      "[ ecpho : 1  iter :930 ]train loss : 0.375324 ,train acc: 0.809326 ,val loss : 0.435833 ,val acc : 0.810455\n",
      "[ ecpho : 1  iter :931 ]train loss : 0.351525 ,train acc: 0.832825 ,val loss : 0.438344 ,val acc : 0.806610\n",
      "[ ecpho : 1  iter :932 ]train loss : 0.367994 ,train acc: 0.836843 ,val loss : 0.433726 ,val acc : 0.811249\n",
      "[ ecpho : 1  iter :933 ]train loss : 0.350327 ,train acc: 0.834534 ,val loss : 0.437931 ,val acc : 0.808441\n",
      "[ ecpho : 1  iter :934 ]train loss : 0.390029 ,train acc: 0.811137 ,val loss : 0.435996 ,val acc : 0.808075\n",
      "[ ecpho : 1  iter :935 ]train loss : 0.399413 ,train acc: 0.776337 ,val loss : 0.437775 ,val acc : 0.809479\n",
      "[ ecpho : 1  iter :936 ]train loss : 0.408726 ,train acc: 0.800415 ,val loss : 0.441122 ,val acc : 0.808563\n",
      "[ ecpho : 1  iter :937 ]train loss : 0.346650 ,train acc: 0.844076 ,val loss : 0.433913 ,val acc : 0.805817\n",
      "[ ecpho : 1  iter :938 ]train loss : 0.329081 ,train acc: 0.841197 ,val loss : 0.430957 ,val acc : 0.809814\n",
      "[ ecpho : 1  iter :939 ]train loss : 0.365011 ,train acc: 0.840871 ,val loss : 0.435911 ,val acc : 0.809174\n",
      "[ ecpho : 1  iter :940 ]train loss : 0.311341 ,train acc: 0.855896 ,val loss : 0.440961 ,val acc : 0.808014\n",
      "[ ecpho : 1  iter :941 ]train loss : 0.460009 ,train acc: 0.785055 ,val loss : 0.441524 ,val acc : 0.805664\n",
      "[ ecpho : 1  iter :942 ]train loss : 0.356580 ,train acc: 0.851186 ,val loss : 0.436611 ,val acc : 0.808990\n",
      "[ ecpho : 1  iter :943 ]train loss : 0.443470 ,train acc: 0.830607 ,val loss : 0.441795 ,val acc : 0.808868\n",
      "[ ecpho : 1  iter :944 ]train loss : 0.349684 ,train acc: 0.846303 ,val loss : 0.437119 ,val acc : 0.808075\n",
      "[ ecpho : 1  iter :945 ]train loss : 0.350957 ,train acc: 0.839152 ,val loss : 0.434911 ,val acc : 0.807739\n",
      "[ ecpho : 1  iter :946 ]train loss : 0.387424 ,train acc: 0.837128 ,val loss : 0.428717 ,val acc : 0.810608\n",
      "[ ecpho : 1  iter :947 ]train loss : 0.377393 ,train acc: 0.834086 ,val loss : 0.436223 ,val acc : 0.805481\n",
      "[ ecpho : 1  iter :948 ]train loss : 0.300871 ,train acc: 0.857239 ,val loss : 0.432655 ,val acc : 0.810791\n",
      "[ ecpho : 1  iter :949 ]train loss : 0.510126 ,train acc: 0.712575 ,val loss : 0.433266 ,val acc : 0.807251\n",
      "[ ecpho : 1  iter :950 ]train loss : 0.310731 ,train acc: 0.838877 ,val loss : 0.431506 ,val acc : 0.810272\n",
      "[ ecpho : 1  iter :951 ]train loss : 0.413055 ,train acc: 0.804881 ,val loss : 0.439411 ,val acc : 0.807159\n",
      "[ ecpho : 1  iter :952 ]train loss : 0.311584 ,train acc: 0.855967 ,val loss : 0.437785 ,val acc : 0.805450\n",
      "[ ecpho : 1  iter :953 ]train loss : 0.365241 ,train acc: 0.833222 ,val loss : 0.433666 ,val acc : 0.806976\n",
      "[ ecpho : 1  iter :954 ]train loss : 0.305930 ,train acc: 0.855062 ,val loss : 0.438157 ,val acc : 0.808319\n",
      "[ ecpho : 1  iter :955 ]train loss : 0.376765 ,train acc: 0.834341 ,val loss : 0.436974 ,val acc : 0.809418\n",
      "[ ecpho : 1  iter :956 ]train loss : 0.369482 ,train acc: 0.833730 ,val loss : 0.436055 ,val acc : 0.809631\n",
      "[ ecpho : 1  iter :957 ]train loss : 0.327757 ,train acc: 0.838125 ,val loss : 0.433586 ,val acc : 0.808899\n",
      "[ ecpho : 1  iter :958 ]train loss : 0.361008 ,train acc: 0.840851 ,val loss : 0.429908 ,val acc : 0.809967\n",
      "[ ecpho : 1  iter :959 ]train loss : 0.420900 ,train acc: 0.835165 ,val loss : 0.432533 ,val acc : 0.807465\n",
      "[ ecpho : 1  iter :960 ]train loss : 0.405512 ,train acc: 0.844727 ,val loss : 0.435460 ,val acc : 0.808716\n",
      "[ ecpho : 1  iter :961 ]train loss : 0.328506 ,train acc: 0.844004 ,val loss : 0.437182 ,val acc : 0.808624\n",
      "[ ecpho : 1  iter :962 ]train loss : 0.384599 ,train acc: 0.830343 ,val loss : 0.439407 ,val acc : 0.808533\n",
      "[ ecpho : 1  iter :963 ]train loss : 0.412395 ,train acc: 0.803345 ,val loss : 0.432686 ,val acc : 0.812531\n",
      "[ ecpho : 1  iter :964 ]train loss : 0.303380 ,train acc: 0.855693 ,val loss : 0.429932 ,val acc : 0.809021\n",
      "[ ecpho : 1  iter :965 ]train loss : 0.371611 ,train acc: 0.835083 ,val loss : 0.435632 ,val acc : 0.808777\n",
      "[ ecpho : 1  iter :966 ]train loss : 0.376397 ,train acc: 0.836884 ,val loss : 0.435560 ,val acc : 0.810181\n",
      "[ ecpho : 1  iter :967 ]train loss : 0.339338 ,train acc: 0.844869 ,val loss : 0.436175 ,val acc : 0.809784\n",
      "[ ecpho : 1  iter :968 ]train loss : 0.324798 ,train acc: 0.845398 ,val loss : 0.428874 ,val acc : 0.811768\n",
      "[ ecpho : 1  iter :969 ]train loss : 0.387972 ,train acc: 0.792521 ,val loss : 0.435855 ,val acc : 0.809052\n",
      "[ ecpho : 1  iter :970 ]train loss : 0.426017 ,train acc: 0.788625 ,val loss : 0.432132 ,val acc : 0.808838\n",
      "[ ecpho : 1  iter :971 ]train loss : 0.394143 ,train acc: 0.811035 ,val loss : 0.432843 ,val acc : 0.809113\n",
      "[ ecpho : 1  iter :972 ]train loss : 0.330537 ,train acc: 0.849253 ,val loss : 0.437788 ,val acc : 0.807098\n",
      "[ ecpho : 1  iter :973 ]train loss : 0.356906 ,train acc: 0.836538 ,val loss : 0.426806 ,val acc : 0.811279\n",
      "[ ecpho : 1  iter :974 ]train loss : 0.310964 ,train acc: 0.856049 ,val loss : 0.434284 ,val acc : 0.807373\n",
      "[ ecpho : 1  iter :975 ]train loss : 0.310895 ,train acc: 0.853699 ,val loss : 0.434230 ,val acc : 0.809204\n",
      "[ ecpho : 1  iter :976 ]train loss : 0.348254 ,train acc: 0.836772 ,val loss : 0.439797 ,val acc : 0.805206\n",
      "[ ecpho : 1  iter :977 ]train loss : 0.314761 ,train acc: 0.854035 ,val loss : 0.439837 ,val acc : 0.809479\n",
      "[ ecpho : 1  iter :978 ]train loss : 0.327678 ,train acc: 0.850413 ,val loss : 0.436116 ,val acc : 0.808533\n",
      "[ ecpho : 1  iter :979 ]train loss : 0.409857 ,train acc: 0.829946 ,val loss : 0.438059 ,val acc : 0.810883\n",
      "[ ecpho : 1  iter :980 ]train loss : 0.398243 ,train acc: 0.808675 ,val loss : 0.427356 ,val acc : 0.812347\n",
      "[ ecpho : 1  iter :981 ]train loss : 0.313835 ,train acc: 0.854848 ,val loss : 0.434135 ,val acc : 0.808594\n",
      "[ ecpho : 1  iter :982 ]train loss : 0.340570 ,train acc: 0.832784 ,val loss : 0.439087 ,val acc : 0.807281\n",
      "[ ecpho : 1  iter :983 ]train loss : 0.345955 ,train acc: 0.846192 ,val loss : 0.436584 ,val acc : 0.810547\n",
      "[ ecpho : 1  iter :984 ]train loss : 0.358052 ,train acc: 0.845073 ,val loss : 0.441454 ,val acc : 0.804962\n",
      "[ ecpho : 1  iter :985 ]train loss : 0.399593 ,train acc: 0.799245 ,val loss : 0.435757 ,val acc : 0.808350\n",
      "[ ecpho : 1  iter :986 ]train loss : 0.482642 ,train acc: 0.782562 ,val loss : 0.432111 ,val acc : 0.810425\n",
      "[ ecpho : 1  iter :987 ]train loss : 0.300171 ,train acc: 0.858175 ,val loss : 0.431567 ,val acc : 0.810760\n",
      "[ ecpho : 1  iter :988 ]train loss : 0.322220 ,train acc: 0.853719 ,val loss : 0.432592 ,val acc : 0.809906\n",
      "[ ecpho : 1  iter :989 ]train loss : 0.366248 ,train acc: 0.837128 ,val loss : 0.440120 ,val acc : 0.810120\n",
      "[ ecpho : 1  iter :990 ]train loss : 0.349119 ,train acc: 0.851675 ,val loss : 0.434530 ,val acc : 0.811005\n",
      "[ ecpho : 1  iter :991 ]train loss : 0.337378 ,train acc: 0.841187 ,val loss : 0.434537 ,val acc : 0.808472\n",
      "[ ecpho : 1  iter :992 ]train loss : 0.353545 ,train acc: 0.819438 ,val loss : 0.430543 ,val acc : 0.807648\n",
      "[ ecpho : 1  iter :993 ]train loss : 0.468714 ,train acc: 0.827861 ,val loss : 0.433241 ,val acc : 0.807556\n",
      "[ ecpho : 1  iter :994 ]train loss : 0.409911 ,train acc: 0.826172 ,val loss : 0.434100 ,val acc : 0.808533\n",
      "[ ecpho : 1  iter :995 ]train loss : 0.507722 ,train acc: 0.776143 ,val loss : 0.437979 ,val acc : 0.812164\n",
      "[ ecpho : 1  iter :996 ]train loss : 0.284995 ,train acc: 0.859467 ,val loss : 0.434723 ,val acc : 0.807953\n",
      "[ ecpho : 1  iter :997 ]train loss : 0.349269 ,train acc: 0.842987 ,val loss : 0.426316 ,val acc : 0.812103\n",
      "[ ecpho : 1  iter :998 ]train loss : 0.377090 ,train acc: 0.833578 ,val loss : 0.428386 ,val acc : 0.809387\n",
      "[ ecpho : 1  iter :999 ]train loss : 0.372462 ,train acc: 0.833456 ,val loss : 0.436941 ,val acc : 0.806000\n",
      "[ ecpho : 1  iter :1000 ]train loss : 0.324717 ,train acc: 0.848460 ,val loss : 0.432097 ,val acc : 0.811035\n",
      "=============================================\n",
      "[ 1 ] average train loss : 0.384617 train acc : 0.826700\n",
      "[ ecpho : 2  iter :1 ]train loss : 0.393209 ,train acc: 0.831594 ,val loss : 0.432223 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :2 ]train loss : 0.355059 ,train acc: 0.809418 ,val loss : 0.438141 ,val acc : 0.808716\n",
      "[ ecpho : 2  iter :3 ]train loss : 0.412251 ,train acc: 0.829600 ,val loss : 0.431019 ,val acc : 0.808167\n",
      "[ ecpho : 2  iter :4 ]train loss : 0.454471 ,train acc: 0.769613 ,val loss : 0.434258 ,val acc : 0.808075\n",
      "[ ecpho : 2  iter :5 ]train loss : 0.409113 ,train acc: 0.829437 ,val loss : 0.438875 ,val acc : 0.805481\n",
      "[ ecpho : 2  iter :6 ]train loss : 0.318218 ,train acc: 0.853038 ,val loss : 0.436880 ,val acc : 0.806976\n",
      "[ ecpho : 2  iter :7 ]train loss : 0.307272 ,train acc: 0.854696 ,val loss : 0.426794 ,val acc : 0.812225\n",
      "[ ecpho : 2  iter :8 ]train loss : 0.450772 ,train acc: 0.791931 ,val loss : 0.435329 ,val acc : 0.809143\n",
      "[ ecpho : 2  iter :9 ]train loss : 0.355326 ,train acc: 0.842845 ,val loss : 0.435355 ,val acc : 0.810028\n",
      "[ ecpho : 2  iter :10 ]train loss : 0.326771 ,train acc: 0.840251 ,val loss : 0.434020 ,val acc : 0.808838\n",
      "[ ecpho : 2  iter :11 ]train loss : 0.494949 ,train acc: 0.752157 ,val loss : 0.430503 ,val acc : 0.810242\n",
      "[ ecpho : 2  iter :12 ]train loss : 0.379810 ,train acc: 0.839284 ,val loss : 0.431840 ,val acc : 0.810242\n",
      "[ ecpho : 2  iter :13 ]train loss : 0.371547 ,train acc: 0.802012 ,val loss : 0.432360 ,val acc : 0.809601\n",
      "[ ecpho : 2  iter :14 ]train loss : 0.290353 ,train acc: 0.862366 ,val loss : 0.438616 ,val acc : 0.801971\n",
      "[ ecpho : 2  iter :15 ]train loss : 0.362641 ,train acc: 0.843170 ,val loss : 0.428062 ,val acc : 0.811157\n",
      "[ ecpho : 2  iter :16 ]train loss : 0.332618 ,train acc: 0.848409 ,val loss : 0.427632 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :17 ]train loss : 0.342735 ,train acc: 0.850260 ,val loss : 0.429704 ,val acc : 0.812897\n",
      "[ ecpho : 2  iter :18 ]train loss : 0.348154 ,train acc: 0.848999 ,val loss : 0.430839 ,val acc : 0.810486\n",
      "[ ecpho : 2  iter :19 ]train loss : 0.359139 ,train acc: 0.841075 ,val loss : 0.429681 ,val acc : 0.810394\n",
      "[ ecpho : 2  iter :20 ]train loss : 0.369309 ,train acc: 0.846853 ,val loss : 0.434019 ,val acc : 0.811218\n",
      "[ ecpho : 2  iter :21 ]train loss : 0.339681 ,train acc: 0.844025 ,val loss : 0.437065 ,val acc : 0.808350\n",
      "[ ecpho : 2  iter :22 ]train loss : 0.297854 ,train acc: 0.859182 ,val loss : 0.434232 ,val acc : 0.808716\n",
      "[ ecpho : 2  iter :23 ]train loss : 0.383168 ,train acc: 0.837596 ,val loss : 0.433978 ,val acc : 0.808350\n",
      "[ ecpho : 2  iter :24 ]train loss : 0.486771 ,train acc: 0.822042 ,val loss : 0.431850 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :25 ]train loss : 0.300090 ,train acc: 0.855906 ,val loss : 0.431784 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :26 ]train loss : 0.361326 ,train acc: 0.822703 ,val loss : 0.431596 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :27 ]train loss : 0.318907 ,train acc: 0.830994 ,val loss : 0.435835 ,val acc : 0.805756\n",
      "[ ecpho : 2  iter :28 ]train loss : 0.422090 ,train acc: 0.840047 ,val loss : 0.431050 ,val acc : 0.811310\n",
      "[ ecpho : 2  iter :29 ]train loss : 0.370673 ,train acc: 0.836690 ,val loss : 0.433296 ,val acc : 0.810089\n",
      "[ ecpho : 2  iter :30 ]train loss : 0.306546 ,train acc: 0.854126 ,val loss : 0.440316 ,val acc : 0.805695\n",
      "[ ecpho : 2  iter :31 ]train loss : 0.346971 ,train acc: 0.845591 ,val loss : 0.432668 ,val acc : 0.810791\n",
      "[ ecpho : 2  iter :32 ]train loss : 0.429156 ,train acc: 0.785116 ,val loss : 0.431642 ,val acc : 0.810425\n",
      "[ ecpho : 2  iter :33 ]train loss : 0.334291 ,train acc: 0.845378 ,val loss : 0.430597 ,val acc : 0.809814\n",
      "[ ecpho : 2  iter :34 ]train loss : 0.433516 ,train acc: 0.787669 ,val loss : 0.427810 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :35 ]train loss : 0.313830 ,train acc: 0.851868 ,val loss : 0.426026 ,val acc : 0.811737\n",
      "[ ecpho : 2  iter :36 ]train loss : 0.439627 ,train acc: 0.806783 ,val loss : 0.432270 ,val acc : 0.809387\n",
      "[ ecpho : 2  iter :37 ]train loss : 0.433053 ,train acc: 0.808920 ,val loss : 0.428100 ,val acc : 0.806915\n",
      "[ ecpho : 2  iter :38 ]train loss : 0.340292 ,train acc: 0.848348 ,val loss : 0.433266 ,val acc : 0.809448\n",
      "[ ecpho : 2  iter :39 ]train loss : 0.364157 ,train acc: 0.839244 ,val loss : 0.437533 ,val acc : 0.808777\n",
      "[ ecpho : 2  iter :40 ]train loss : 0.517338 ,train acc: 0.748332 ,val loss : 0.433583 ,val acc : 0.810181\n",
      "[ ecpho : 2  iter :41 ]train loss : 0.348908 ,train acc: 0.848572 ,val loss : 0.427961 ,val acc : 0.811798\n",
      "[ ecpho : 2  iter :42 ]train loss : 0.393148 ,train acc: 0.797302 ,val loss : 0.431952 ,val acc : 0.809937\n",
      "[ ecpho : 2  iter :43 ]train loss : 0.332551 ,train acc: 0.838399 ,val loss : 0.436663 ,val acc : 0.809967\n",
      "[ ecpho : 2  iter :44 ]train loss : 0.416835 ,train acc: 0.725322 ,val loss : 0.433066 ,val acc : 0.806671\n",
      "[ ecpho : 2  iter :45 ]train loss : 0.339057 ,train acc: 0.835114 ,val loss : 0.432751 ,val acc : 0.811462\n",
      "[ ecpho : 2  iter :46 ]train loss : 0.355462 ,train acc: 0.813182 ,val loss : 0.435106 ,val acc : 0.807098\n",
      "[ ecpho : 2  iter :47 ]train loss : 0.330501 ,train acc: 0.835856 ,val loss : 0.433024 ,val acc : 0.809723\n",
      "[ ecpho : 2  iter :48 ]train loss : 0.322260 ,train acc: 0.850179 ,val loss : 0.428996 ,val acc : 0.813232\n",
      "[ ecpho : 2  iter :49 ]train loss : 0.348971 ,train acc: 0.839457 ,val loss : 0.428701 ,val acc : 0.812561\n",
      "[ ecpho : 2  iter :50 ]train loss : 0.402687 ,train acc: 0.830862 ,val loss : 0.435770 ,val acc : 0.812012\n",
      "[ ecpho : 2  iter :51 ]train loss : 0.424592 ,train acc: 0.811168 ,val loss : 0.438391 ,val acc : 0.805237\n",
      "[ ecpho : 2  iter :52 ]train loss : 0.426406 ,train acc: 0.819590 ,val loss : 0.428788 ,val acc : 0.810028\n",
      "[ ecpho : 2  iter :53 ]train loss : 0.375016 ,train acc: 0.820282 ,val loss : 0.427013 ,val acc : 0.811188\n",
      "[ ecpho : 2  iter :54 ]train loss : 0.313751 ,train acc: 0.854370 ,val loss : 0.437640 ,val acc : 0.810547\n",
      "[ ecpho : 2  iter :55 ]train loss : 0.405255 ,train acc: 0.834707 ,val loss : 0.436133 ,val acc : 0.805786\n",
      "[ ecpho : 2  iter :56 ]train loss : 0.333289 ,train acc: 0.843821 ,val loss : 0.429934 ,val acc : 0.811920\n",
      "[ ecpho : 2  iter :57 ]train loss : 0.592810 ,train acc: 0.764720 ,val loss : 0.432486 ,val acc : 0.807983\n",
      "[ ecpho : 2  iter :58 ]train loss : 0.351647 ,train acc: 0.837830 ,val loss : 0.431906 ,val acc : 0.810211\n",
      "[ ecpho : 2  iter :59 ]train loss : 0.506509 ,train acc: 0.815135 ,val loss : 0.431228 ,val acc : 0.810059\n",
      "[ ecpho : 2  iter :60 ]train loss : 0.311870 ,train acc: 0.850973 ,val loss : 0.426149 ,val acc : 0.810059\n",
      "[ ecpho : 2  iter :61 ]train loss : 0.319291 ,train acc: 0.842987 ,val loss : 0.434009 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :62 ]train loss : 0.315384 ,train acc: 0.851980 ,val loss : 0.432600 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :63 ]train loss : 0.382902 ,train acc: 0.826508 ,val loss : 0.432661 ,val acc : 0.810394\n",
      "[ ecpho : 2  iter :64 ]train loss : 0.394184 ,train acc: 0.821900 ,val loss : 0.428359 ,val acc : 0.814392\n",
      "[ ecpho : 2  iter :65 ]train loss : 0.421526 ,train acc: 0.808899 ,val loss : 0.432847 ,val acc : 0.807861\n",
      "[ ecpho : 2  iter :66 ]train loss : 0.414011 ,train acc: 0.798330 ,val loss : 0.433696 ,val acc : 0.807312\n",
      "[ ecpho : 2  iter :67 ]train loss : 0.371928 ,train acc: 0.844828 ,val loss : 0.431484 ,val acc : 0.810791\n",
      "[ ecpho : 2  iter :68 ]train loss : 0.298521 ,train acc: 0.858378 ,val loss : 0.424591 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :69 ]train loss : 0.319899 ,train acc: 0.843496 ,val loss : 0.433707 ,val acc : 0.808563\n",
      "[ ecpho : 2  iter :70 ]train loss : 0.416945 ,train acc: 0.832672 ,val loss : 0.434032 ,val acc : 0.809235\n",
      "[ ecpho : 2  iter :71 ]train loss : 0.341901 ,train acc: 0.844096 ,val loss : 0.435465 ,val acc : 0.808685\n",
      "[ ecpho : 2  iter :72 ]train loss : 0.318915 ,train acc: 0.850759 ,val loss : 0.428201 ,val acc : 0.813599\n",
      "[ ecpho : 2  iter :73 ]train loss : 0.295280 ,train acc: 0.856395 ,val loss : 0.432330 ,val acc : 0.811646\n",
      "[ ecpho : 2  iter :74 ]train loss : 0.382627 ,train acc: 0.832744 ,val loss : 0.432445 ,val acc : 0.809082\n",
      "[ ecpho : 2  iter :75 ]train loss : 0.297625 ,train acc: 0.856710 ,val loss : 0.432756 ,val acc : 0.809326\n",
      "[ ecpho : 2  iter :76 ]train loss : 0.361816 ,train acc: 0.819387 ,val loss : 0.430056 ,val acc : 0.812805\n",
      "[ ecpho : 2  iter :77 ]train loss : 0.385817 ,train acc: 0.818410 ,val loss : 0.432296 ,val acc : 0.808838\n",
      "[ ecpho : 2  iter :78 ]train loss : 0.336291 ,train acc: 0.850495 ,val loss : 0.431132 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :79 ]train loss : 0.340420 ,train acc: 0.840831 ,val loss : 0.437252 ,val acc : 0.810028\n",
      "[ ecpho : 2  iter :80 ]train loss : 0.276578 ,train acc: 0.866150 ,val loss : 0.429554 ,val acc : 0.809967\n",
      "[ ecpho : 2  iter :81 ]train loss : 0.297319 ,train acc: 0.857300 ,val loss : 0.431616 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :82 ]train loss : 0.302680 ,train acc: 0.855286 ,val loss : 0.426759 ,val acc : 0.809418\n",
      "[ ecpho : 2  iter :83 ]train loss : 0.353468 ,train acc: 0.846253 ,val loss : 0.431218 ,val acc : 0.811493\n",
      "[ ecpho : 2  iter :84 ]train loss : 0.300621 ,train acc: 0.856690 ,val loss : 0.435250 ,val acc : 0.807617\n",
      "[ ecpho : 2  iter :85 ]train loss : 0.376409 ,train acc: 0.831635 ,val loss : 0.430430 ,val acc : 0.812073\n",
      "[ ecpho : 2  iter :86 ]train loss : 0.499271 ,train acc: 0.803294 ,val loss : 0.429267 ,val acc : 0.809998\n",
      "[ ecpho : 2  iter :87 ]train loss : 0.438057 ,train acc: 0.789724 ,val loss : 0.430570 ,val acc : 0.809326\n",
      "[ ecpho : 2  iter :88 ]train loss : 0.362689 ,train acc: 0.841929 ,val loss : 0.435995 ,val acc : 0.806793\n",
      "[ ecpho : 2  iter :89 ]train loss : 0.443013 ,train acc: 0.803965 ,val loss : 0.432867 ,val acc : 0.810455\n",
      "[ ecpho : 2  iter :90 ]train loss : 0.297910 ,train acc: 0.860494 ,val loss : 0.426500 ,val acc : 0.814575\n",
      "[ ecpho : 2  iter :91 ]train loss : 0.334506 ,train acc: 0.841075 ,val loss : 0.434499 ,val acc : 0.810181\n",
      "[ ecpho : 2  iter :92 ]train loss : 0.346443 ,train acc: 0.827708 ,val loss : 0.431059 ,val acc : 0.810547\n",
      "[ ecpho : 2  iter :93 ]train loss : 0.299372 ,train acc: 0.855042 ,val loss : 0.434029 ,val acc : 0.809082\n",
      "[ ecpho : 2  iter :94 ]train loss : 0.390800 ,train acc: 0.821625 ,val loss : 0.430529 ,val acc : 0.810303\n",
      "[ ecpho : 2  iter :95 ]train loss : 0.347999 ,train acc: 0.846222 ,val loss : 0.428354 ,val acc : 0.806854\n",
      "[ ecpho : 2  iter :96 ]train loss : 0.358698 ,train acc: 0.832225 ,val loss : 0.429336 ,val acc : 0.814545\n",
      "[ ecpho : 2  iter :97 ]train loss : 0.366862 ,train acc: 0.742188 ,val loss : 0.427780 ,val acc : 0.811218\n",
      "[ ecpho : 2  iter :98 ]train loss : 0.337278 ,train acc: 0.843323 ,val loss : 0.438746 ,val acc : 0.812286\n",
      "[ ecpho : 2  iter :99 ]train loss : 0.343636 ,train acc: 0.840800 ,val loss : 0.427386 ,val acc : 0.811249\n",
      "[ ecpho : 2  iter :100 ]train loss : 0.357322 ,train acc: 0.825267 ,val loss : 0.432694 ,val acc : 0.809387\n",
      "[ ecpho : 2  iter :101 ]train loss : 0.353319 ,train acc: 0.846904 ,val loss : 0.427024 ,val acc : 0.809296\n",
      "[ ecpho : 2  iter :102 ]train loss : 0.334295 ,train acc: 0.850688 ,val loss : 0.437747 ,val acc : 0.809998\n",
      "[ ecpho : 2  iter :103 ]train loss : 0.380126 ,train acc: 0.838359 ,val loss : 0.428072 ,val acc : 0.812073\n",
      "[ ecpho : 2  iter :104 ]train loss : 0.450987 ,train acc: 0.741180 ,val loss : 0.435002 ,val acc : 0.806274\n",
      "[ ecpho : 2  iter :105 ]train loss : 0.357444 ,train acc: 0.822663 ,val loss : 0.430123 ,val acc : 0.808105\n",
      "[ ecpho : 2  iter :106 ]train loss : 0.330641 ,train acc: 0.854248 ,val loss : 0.433024 ,val acc : 0.808777\n",
      "[ ecpho : 2  iter :107 ]train loss : 0.375711 ,train acc: 0.808889 ,val loss : 0.435511 ,val acc : 0.810669\n",
      "[ ecpho : 2  iter :108 ]train loss : 0.319048 ,train acc: 0.846975 ,val loss : 0.432503 ,val acc : 0.813110\n",
      "[ ecpho : 2  iter :109 ]train loss : 0.484153 ,train acc: 0.824687 ,val loss : 0.432745 ,val acc : 0.808167\n",
      "[ ecpho : 2  iter :110 ]train loss : 0.421144 ,train acc: 0.831523 ,val loss : 0.429614 ,val acc : 0.812256\n",
      "[ ecpho : 2  iter :111 ]train loss : 0.392001 ,train acc: 0.822581 ,val loss : 0.435656 ,val acc : 0.809509\n",
      "[ ecpho : 2  iter :112 ]train loss : 0.389018 ,train acc: 0.831177 ,val loss : 0.428374 ,val acc : 0.810913\n",
      "[ ecpho : 2  iter :113 ]train loss : 0.383348 ,train acc: 0.834798 ,val loss : 0.429681 ,val acc : 0.810760\n",
      "[ ecpho : 2  iter :114 ]train loss : 0.380633 ,train acc: 0.828146 ,val loss : 0.430674 ,val acc : 0.811646\n",
      "[ ecpho : 2  iter :115 ]train loss : 0.428834 ,train acc: 0.829844 ,val loss : 0.434446 ,val acc : 0.806793\n",
      "[ ecpho : 2  iter :116 ]train loss : 0.368687 ,train acc: 0.840973 ,val loss : 0.429695 ,val acc : 0.810638\n",
      "[ ecpho : 2  iter :117 ]train loss : 0.354183 ,train acc: 0.843120 ,val loss : 0.429672 ,val acc : 0.813965\n",
      "[ ecpho : 2  iter :118 ]train loss : 0.326921 ,train acc: 0.848379 ,val loss : 0.429706 ,val acc : 0.809265\n",
      "[ ecpho : 2  iter :119 ]train loss : 0.342252 ,train acc: 0.844483 ,val loss : 0.431345 ,val acc : 0.811432\n",
      "[ ecpho : 2  iter :120 ]train loss : 0.319519 ,train acc: 0.851095 ,val loss : 0.427977 ,val acc : 0.811188\n",
      "[ ecpho : 2  iter :121 ]train loss : 0.473715 ,train acc: 0.806499 ,val loss : 0.432031 ,val acc : 0.812653\n",
      "[ ecpho : 2  iter :122 ]train loss : 0.285556 ,train acc: 0.865122 ,val loss : 0.435772 ,val acc : 0.808960\n",
      "[ ecpho : 2  iter :123 ]train loss : 0.398621 ,train acc: 0.830048 ,val loss : 0.430938 ,val acc : 0.807220\n",
      "[ ecpho : 2  iter :124 ]train loss : 0.350246 ,train acc: 0.846019 ,val loss : 0.426759 ,val acc : 0.814972\n",
      "[ ecpho : 2  iter :125 ]train loss : 0.329902 ,train acc: 0.842448 ,val loss : 0.436794 ,val acc : 0.807343\n",
      "[ ecpho : 2  iter :126 ]train loss : 0.403230 ,train acc: 0.821513 ,val loss : 0.424509 ,val acc : 0.811890\n",
      "[ ecpho : 2  iter :127 ]train loss : 0.344450 ,train acc: 0.845652 ,val loss : 0.426393 ,val acc : 0.812042\n",
      "[ ecpho : 2  iter :128 ]train loss : 0.325068 ,train acc: 0.854279 ,val loss : 0.433868 ,val acc : 0.809570\n",
      "[ ecpho : 2  iter :129 ]train loss : 0.374462 ,train acc: 0.836579 ,val loss : 0.430419 ,val acc : 0.810211\n",
      "[ ecpho : 2  iter :130 ]train loss : 0.318727 ,train acc: 0.845215 ,val loss : 0.428121 ,val acc : 0.812103\n",
      "[ ecpho : 2  iter :131 ]train loss : 0.380092 ,train acc: 0.841502 ,val loss : 0.422911 ,val acc : 0.813293\n",
      "[ ecpho : 2  iter :132 ]train loss : 0.373959 ,train acc: 0.850495 ,val loss : 0.431614 ,val acc : 0.811432\n",
      "[ ecpho : 2  iter :133 ]train loss : 0.308420 ,train acc: 0.855825 ,val loss : 0.432666 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :134 ]train loss : 0.374524 ,train acc: 0.836802 ,val loss : 0.428310 ,val acc : 0.810730\n",
      "[ ecpho : 2  iter :135 ]train loss : 0.327077 ,train acc: 0.842489 ,val loss : 0.428190 ,val acc : 0.810669\n",
      "[ ecpho : 2  iter :136 ]train loss : 0.308273 ,train acc: 0.860402 ,val loss : 0.434089 ,val acc : 0.810730\n",
      "[ ecpho : 2  iter :137 ]train loss : 0.309614 ,train acc: 0.858653 ,val loss : 0.427720 ,val acc : 0.809174\n",
      "[ ecpho : 2  iter :138 ]train loss : 0.359313 ,train acc: 0.832133 ,val loss : 0.430211 ,val acc : 0.810059\n",
      "[ ecpho : 2  iter :139 ]train loss : 0.322063 ,train acc: 0.853160 ,val loss : 0.427428 ,val acc : 0.810303\n",
      "[ ecpho : 2  iter :140 ]train loss : 0.414788 ,train acc: 0.805685 ,val loss : 0.430816 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :141 ]train loss : 0.340914 ,train acc: 0.844951 ,val loss : 0.427169 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :142 ]train loss : 0.296765 ,train acc: 0.853190 ,val loss : 0.430963 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :143 ]train loss : 0.347465 ,train acc: 0.849396 ,val loss : 0.424488 ,val acc : 0.814178\n",
      "[ ecpho : 2  iter :144 ]train loss : 0.482284 ,train acc: 0.798859 ,val loss : 0.428641 ,val acc : 0.812256\n",
      "[ ecpho : 2  iter :145 ]train loss : 0.293197 ,train acc: 0.863159 ,val loss : 0.427659 ,val acc : 0.811584\n",
      "[ ecpho : 2  iter :146 ]train loss : 0.307291 ,train acc: 0.851583 ,val loss : 0.426724 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :147 ]train loss : 0.384753 ,train acc: 0.827250 ,val loss : 0.435038 ,val acc : 0.809052\n",
      "[ ecpho : 2  iter :148 ]train loss : 0.353927 ,train acc: 0.844808 ,val loss : 0.430334 ,val acc : 0.812073\n",
      "[ ecpho : 2  iter :149 ]train loss : 0.361876 ,train acc: 0.808828 ,val loss : 0.429557 ,val acc : 0.812988\n",
      "[ ecpho : 2  iter :150 ]train loss : 0.620817 ,train acc: 0.805135 ,val loss : 0.430807 ,val acc : 0.811798\n",
      "[ ecpho : 2  iter :151 ]train loss : 0.287122 ,train acc: 0.863119 ,val loss : 0.426791 ,val acc : 0.811768\n",
      "[ ecpho : 2  iter :152 ]train loss : 0.364817 ,train acc: 0.828634 ,val loss : 0.429094 ,val acc : 0.813171\n",
      "[ ecpho : 2  iter :153 ]train loss : 0.424436 ,train acc: 0.791881 ,val loss : 0.430809 ,val acc : 0.809509\n",
      "[ ecpho : 2  iter :154 ]train loss : 0.399025 ,train acc: 0.832194 ,val loss : 0.432687 ,val acc : 0.810303\n",
      "[ ecpho : 2  iter :155 ]train loss : 0.432350 ,train acc: 0.824280 ,val loss : 0.427944 ,val acc : 0.809845\n",
      "[ ecpho : 2  iter :156 ]train loss : 0.423942 ,train acc: 0.822856 ,val loss : 0.431031 ,val acc : 0.812164\n",
      "[ ecpho : 2  iter :157 ]train loss : 0.296207 ,train acc: 0.858154 ,val loss : 0.430510 ,val acc : 0.809143\n",
      "[ ecpho : 2  iter :158 ]train loss : 0.329701 ,train acc: 0.841034 ,val loss : 0.430812 ,val acc : 0.810760\n",
      "[ ecpho : 2  iter :159 ]train loss : 0.294151 ,train acc: 0.856537 ,val loss : 0.427661 ,val acc : 0.809692\n",
      "[ ecpho : 2  iter :160 ]train loss : 0.291562 ,train acc: 0.859202 ,val loss : 0.432389 ,val acc : 0.807007\n",
      "[ ecpho : 2  iter :161 ]train loss : 0.502272 ,train acc: 0.819835 ,val loss : 0.430393 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :162 ]train loss : 0.338731 ,train acc: 0.843547 ,val loss : 0.425602 ,val acc : 0.810852\n",
      "[ ecpho : 2  iter :163 ]train loss : 0.284253 ,train acc: 0.862488 ,val loss : 0.430650 ,val acc : 0.807953\n",
      "[ ecpho : 2  iter :164 ]train loss : 0.328996 ,train acc: 0.855103 ,val loss : 0.426730 ,val acc : 0.810822\n",
      "[ ecpho : 2  iter :165 ]train loss : 0.358950 ,train acc: 0.817902 ,val loss : 0.437449 ,val acc : 0.809174\n",
      "[ ecpho : 2  iter :166 ]train loss : 0.330797 ,train acc: 0.851898 ,val loss : 0.433867 ,val acc : 0.810516\n",
      "[ ecpho : 2  iter :167 ]train loss : 0.351348 ,train acc: 0.825806 ,val loss : 0.431766 ,val acc : 0.808411\n",
      "[ ecpho : 2  iter :168 ]train loss : 0.460939 ,train acc: 0.761078 ,val loss : 0.430983 ,val acc : 0.809753\n",
      "[ ecpho : 2  iter :169 ]train loss : 0.288613 ,train acc: 0.860616 ,val loss : 0.428668 ,val acc : 0.808136\n",
      "[ ecpho : 2  iter :170 ]train loss : 0.348903 ,train acc: 0.843740 ,val loss : 0.426818 ,val acc : 0.810760\n",
      "[ ecpho : 2  iter :171 ]train loss : 0.279655 ,train acc: 0.864472 ,val loss : 0.426293 ,val acc : 0.812378\n",
      "[ ecpho : 2  iter :172 ]train loss : 0.299579 ,train acc: 0.854360 ,val loss : 0.429674 ,val acc : 0.809662\n",
      "[ ecpho : 2  iter :173 ]train loss : 0.443430 ,train acc: 0.744578 ,val loss : 0.431090 ,val acc : 0.807312\n",
      "[ ecpho : 2  iter :174 ]train loss : 0.315446 ,train acc: 0.853017 ,val loss : 0.428781 ,val acc : 0.810883\n",
      "[ ecpho : 2  iter :175 ]train loss : 0.305884 ,train acc: 0.856313 ,val loss : 0.434314 ,val acc : 0.808228\n",
      "[ ecpho : 2  iter :176 ]train loss : 0.377864 ,train acc: 0.838756 ,val loss : 0.433306 ,val acc : 0.808563\n",
      "[ ecpho : 2  iter :177 ]train loss : 0.378859 ,train acc: 0.825419 ,val loss : 0.429187 ,val acc : 0.812988\n",
      "[ ecpho : 2  iter :178 ]train loss : 0.397664 ,train acc: 0.838969 ,val loss : 0.432079 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :179 ]train loss : 0.337927 ,train acc: 0.849111 ,val loss : 0.430864 ,val acc : 0.806824\n",
      "[ ecpho : 2  iter :180 ]train loss : 0.398389 ,train acc: 0.829641 ,val loss : 0.430898 ,val acc : 0.811005\n",
      "[ ecpho : 2  iter :181 ]train loss : 0.322965 ,train acc: 0.849894 ,val loss : 0.428401 ,val acc : 0.811615\n",
      "[ ecpho : 2  iter :182 ]train loss : 0.520764 ,train acc: 0.783590 ,val loss : 0.431657 ,val acc : 0.807495\n",
      "[ ecpho : 2  iter :183 ]train loss : 0.398412 ,train acc: 0.824656 ,val loss : 0.433628 ,val acc : 0.810699\n",
      "[ ecpho : 2  iter :184 ]train loss : 0.339946 ,train acc: 0.844564 ,val loss : 0.423870 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :185 ]train loss : 0.433487 ,train acc: 0.795685 ,val loss : 0.429301 ,val acc : 0.811981\n",
      "[ ecpho : 2  iter :186 ]train loss : 0.344269 ,train acc: 0.854157 ,val loss : 0.429561 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :187 ]train loss : 0.320323 ,train acc: 0.854696 ,val loss : 0.432482 ,val acc : 0.808441\n",
      "[ ecpho : 2  iter :188 ]train loss : 0.308143 ,train acc: 0.852193 ,val loss : 0.426183 ,val acc : 0.812225\n",
      "[ ecpho : 2  iter :189 ]train loss : 0.320803 ,train acc: 0.852102 ,val loss : 0.421010 ,val acc : 0.811066\n",
      "[ ecpho : 2  iter :190 ]train loss : 0.332663 ,train acc: 0.842692 ,val loss : 0.429585 ,val acc : 0.809998\n",
      "[ ecpho : 2  iter :191 ]train loss : 0.376115 ,train acc: 0.829387 ,val loss : 0.423588 ,val acc : 0.811859\n",
      "[ ecpho : 2  iter :192 ]train loss : 0.304785 ,train acc: 0.856303 ,val loss : 0.428497 ,val acc : 0.813782\n",
      "[ ecpho : 2  iter :193 ]train loss : 0.363036 ,train acc: 0.841502 ,val loss : 0.428295 ,val acc : 0.811890\n",
      "[ ecpho : 2  iter :194 ]train loss : 0.339090 ,train acc: 0.856547 ,val loss : 0.427614 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :195 ]train loss : 0.342737 ,train acc: 0.848165 ,val loss : 0.433665 ,val acc : 0.811035\n",
      "[ ecpho : 2  iter :196 ]train loss : 0.294252 ,train acc: 0.856700 ,val loss : 0.424496 ,val acc : 0.812378\n",
      "[ ecpho : 2  iter :197 ]train loss : 0.307490 ,train acc: 0.855876 ,val loss : 0.429218 ,val acc : 0.809448\n",
      "[ ecpho : 2  iter :198 ]train loss : 0.311361 ,train acc: 0.858439 ,val loss : 0.430193 ,val acc : 0.812958\n",
      "[ ecpho : 2  iter :199 ]train loss : 0.293630 ,train acc: 0.859782 ,val loss : 0.427299 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :200 ]train loss : 0.350879 ,train acc: 0.838562 ,val loss : 0.428886 ,val acc : 0.810150\n",
      "[ ecpho : 2  iter :201 ]train loss : 0.307076 ,train acc: 0.852783 ,val loss : 0.426676 ,val acc : 0.808075\n",
      "[ ecpho : 2  iter :202 ]train loss : 0.324799 ,train acc: 0.844910 ,val loss : 0.432579 ,val acc : 0.809662\n",
      "[ ecpho : 2  iter :203 ]train loss : 0.355469 ,train acc: 0.839061 ,val loss : 0.428988 ,val acc : 0.812134\n",
      "[ ecpho : 2  iter :204 ]train loss : 0.306582 ,train acc: 0.850271 ,val loss : 0.426244 ,val acc : 0.810577\n",
      "[ ecpho : 2  iter :205 ]train loss : 0.346483 ,train acc: 0.841644 ,val loss : 0.430493 ,val acc : 0.807739\n",
      "[ ecpho : 2  iter :206 ]train loss : 0.327345 ,train acc: 0.848999 ,val loss : 0.426415 ,val acc : 0.814758\n",
      "[ ecpho : 2  iter :207 ]train loss : 0.293974 ,train acc: 0.856832 ,val loss : 0.419750 ,val acc : 0.812469\n",
      "[ ecpho : 2  iter :208 ]train loss : 0.338256 ,train acc: 0.833425 ,val loss : 0.423543 ,val acc : 0.811829\n",
      "[ ecpho : 2  iter :209 ]train loss : 0.277201 ,train acc: 0.864288 ,val loss : 0.428374 ,val acc : 0.810425\n",
      "[ ecpho : 2  iter :210 ]train loss : 0.408347 ,train acc: 0.792267 ,val loss : 0.428434 ,val acc : 0.810150\n",
      "[ ecpho : 2  iter :211 ]train loss : 0.273114 ,train acc: 0.867106 ,val loss : 0.423186 ,val acc : 0.811401\n",
      "[ ecpho : 2  iter :212 ]train loss : 0.425781 ,train acc: 0.827759 ,val loss : 0.424604 ,val acc : 0.810638\n",
      "[ ecpho : 2  iter :213 ]train loss : 0.347930 ,train acc: 0.842306 ,val loss : 0.429801 ,val acc : 0.811005\n",
      "[ ecpho : 2  iter :214 ]train loss : 0.295708 ,train acc: 0.858785 ,val loss : 0.428975 ,val acc : 0.812103\n",
      "[ ecpho : 2  iter :215 ]train loss : 0.334166 ,train acc: 0.843801 ,val loss : 0.416362 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :216 ]train loss : 0.316799 ,train acc: 0.853516 ,val loss : 0.421399 ,val acc : 0.813599\n",
      "[ ecpho : 2  iter :217 ]train loss : 0.433731 ,train acc: 0.809204 ,val loss : 0.430166 ,val acc : 0.808716\n",
      "[ ecpho : 2  iter :218 ]train loss : 0.399033 ,train acc: 0.813782 ,val loss : 0.422237 ,val acc : 0.811462\n",
      "[ ecpho : 2  iter :219 ]train loss : 0.318312 ,train acc: 0.849813 ,val loss : 0.427048 ,val acc : 0.809601\n",
      "[ ecpho : 2  iter :220 ]train loss : 0.319519 ,train acc: 0.849996 ,val loss : 0.424089 ,val acc : 0.813171\n",
      "[ ecpho : 2  iter :221 ]train loss : 0.329883 ,train acc: 0.849660 ,val loss : 0.427590 ,val acc : 0.811279\n",
      "[ ecpho : 2  iter :222 ]train loss : 0.504058 ,train acc: 0.776398 ,val loss : 0.424669 ,val acc : 0.810669\n",
      "[ ecpho : 2  iter :223 ]train loss : 0.452549 ,train acc: 0.794027 ,val loss : 0.425356 ,val acc : 0.813507\n",
      "[ ecpho : 2  iter :224 ]train loss : 0.359531 ,train acc: 0.845134 ,val loss : 0.421786 ,val acc : 0.813354\n",
      "[ ecpho : 2  iter :225 ]train loss : 0.326184 ,train acc: 0.841665 ,val loss : 0.426232 ,val acc : 0.811615\n",
      "[ ecpho : 2  iter :226 ]train loss : 0.315950 ,train acc: 0.848897 ,val loss : 0.420033 ,val acc : 0.812866\n",
      "[ ecpho : 2  iter :227 ]train loss : 0.313332 ,train acc: 0.849996 ,val loss : 0.420207 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :228 ]train loss : 0.312679 ,train acc: 0.850657 ,val loss : 0.420555 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :229 ]train loss : 0.317607 ,train acc: 0.843933 ,val loss : 0.422218 ,val acc : 0.814423\n",
      "[ ecpho : 2  iter :230 ]train loss : 0.424814 ,train acc: 0.803315 ,val loss : 0.422220 ,val acc : 0.810059\n",
      "[ ecpho : 2  iter :231 ]train loss : 0.358856 ,train acc: 0.839956 ,val loss : 0.431983 ,val acc : 0.807709\n",
      "[ ecpho : 2  iter :232 ]train loss : 0.302228 ,train acc: 0.853831 ,val loss : 0.435877 ,val acc : 0.806030\n",
      "[ ecpho : 2  iter :233 ]train loss : 0.291200 ,train acc: 0.859843 ,val loss : 0.423199 ,val acc : 0.814789\n",
      "[ ecpho : 2  iter :234 ]train loss : 0.325299 ,train acc: 0.842194 ,val loss : 0.424280 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :235 ]train loss : 0.331740 ,train acc: 0.844890 ,val loss : 0.425401 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :236 ]train loss : 0.293380 ,train acc: 0.860942 ,val loss : 0.430693 ,val acc : 0.812012\n",
      "[ ecpho : 2  iter :237 ]train loss : 0.517627 ,train acc: 0.756918 ,val loss : 0.425415 ,val acc : 0.810455\n",
      "[ ecpho : 2  iter :238 ]train loss : 0.341606 ,train acc: 0.849396 ,val loss : 0.423398 ,val acc : 0.809357\n",
      "[ ecpho : 2  iter :239 ]train loss : 0.348452 ,train acc: 0.844117 ,val loss : 0.421800 ,val acc : 0.812958\n",
      "[ ecpho : 2  iter :240 ]train loss : 0.296790 ,train acc: 0.854258 ,val loss : 0.428371 ,val acc : 0.811615\n",
      "[ ecpho : 2  iter :241 ]train loss : 0.428209 ,train acc: 0.832398 ,val loss : 0.430920 ,val acc : 0.810791\n",
      "[ ecpho : 2  iter :242 ]train loss : 0.363244 ,train acc: 0.819875 ,val loss : 0.431717 ,val acc : 0.809052\n",
      "[ ecpho : 2  iter :243 ]train loss : 0.420008 ,train acc: 0.767344 ,val loss : 0.427488 ,val acc : 0.811493\n",
      "[ ecpho : 2  iter :244 ]train loss : 0.305016 ,train acc: 0.855021 ,val loss : 0.427849 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :245 ]train loss : 0.316577 ,train acc: 0.854635 ,val loss : 0.426656 ,val acc : 0.811615\n",
      "[ ecpho : 2  iter :246 ]train loss : 0.330665 ,train acc: 0.840353 ,val loss : 0.425364 ,val acc : 0.811249\n",
      "[ ecpho : 2  iter :247 ]train loss : 0.440138 ,train acc: 0.813843 ,val loss : 0.425093 ,val acc : 0.810699\n",
      "[ ecpho : 2  iter :248 ]train loss : 0.400905 ,train acc: 0.818115 ,val loss : 0.429882 ,val acc : 0.811859\n",
      "[ ecpho : 2  iter :249 ]train loss : 0.482968 ,train acc: 0.777497 ,val loss : 0.421420 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :250 ]train loss : 0.436317 ,train acc: 0.814657 ,val loss : 0.424129 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :251 ]train loss : 0.355683 ,train acc: 0.817159 ,val loss : 0.425970 ,val acc : 0.814819\n",
      "[ ecpho : 2  iter :252 ]train loss : 0.398901 ,train acc: 0.838929 ,val loss : 0.425595 ,val acc : 0.812469\n",
      "[ ecpho : 2  iter :253 ]train loss : 0.299506 ,train acc: 0.854533 ,val loss : 0.433434 ,val acc : 0.809601\n",
      "[ ecpho : 2  iter :254 ]train loss : 0.310736 ,train acc: 0.850983 ,val loss : 0.430043 ,val acc : 0.808289\n",
      "[ ecpho : 2  iter :255 ]train loss : 0.284420 ,train acc: 0.859416 ,val loss : 0.430326 ,val acc : 0.811951\n",
      "[ ecpho : 2  iter :256 ]train loss : 0.365205 ,train acc: 0.837728 ,val loss : 0.428308 ,val acc : 0.809692\n",
      "[ ecpho : 2  iter :257 ]train loss : 0.306624 ,train acc: 0.858419 ,val loss : 0.429908 ,val acc : 0.807739\n",
      "[ ecpho : 2  iter :258 ]train loss : 0.285138 ,train acc: 0.862183 ,val loss : 0.430673 ,val acc : 0.808777\n",
      "[ ecpho : 2  iter :259 ]train loss : 0.359711 ,train acc: 0.842713 ,val loss : 0.427992 ,val acc : 0.809113\n",
      "[ ecpho : 2  iter :260 ]train loss : 0.364133 ,train acc: 0.829773 ,val loss : 0.424798 ,val acc : 0.811768\n",
      "[ ecpho : 2  iter :261 ]train loss : 0.468940 ,train acc: 0.826233 ,val loss : 0.425431 ,val acc : 0.808807\n",
      "[ ecpho : 2  iter :262 ]train loss : 0.451040 ,train acc: 0.814311 ,val loss : 0.421332 ,val acc : 0.813721\n",
      "[ ecpho : 2  iter :263 ]train loss : 0.303653 ,train acc: 0.854960 ,val loss : 0.428235 ,val acc : 0.808563\n",
      "[ ecpho : 2  iter :264 ]train loss : 0.356757 ,train acc: 0.841482 ,val loss : 0.418984 ,val acc : 0.811890\n",
      "[ ecpho : 2  iter :265 ]train loss : 0.337720 ,train acc: 0.841390 ,val loss : 0.427670 ,val acc : 0.810608\n",
      "[ ecpho : 2  iter :266 ]train loss : 0.292831 ,train acc: 0.857391 ,val loss : 0.422476 ,val acc : 0.810333\n",
      "[ ecpho : 2  iter :267 ]train loss : 0.427918 ,train acc: 0.810293 ,val loss : 0.424087 ,val acc : 0.809967\n",
      "[ ecpho : 2  iter :268 ]train loss : 0.303052 ,train acc: 0.857758 ,val loss : 0.425039 ,val acc : 0.810638\n",
      "[ ecpho : 2  iter :269 ]train loss : 0.357294 ,train acc: 0.786621 ,val loss : 0.425464 ,val acc : 0.809448\n",
      "[ ecpho : 2  iter :270 ]train loss : 0.431986 ,train acc: 0.791402 ,val loss : 0.423940 ,val acc : 0.810638\n",
      "[ ecpho : 2  iter :271 ]train loss : 0.452839 ,train acc: 0.795288 ,val loss : 0.419870 ,val acc : 0.814270\n",
      "[ ecpho : 2  iter :272 ]train loss : 0.345673 ,train acc: 0.837382 ,val loss : 0.423933 ,val acc : 0.811829\n",
      "[ ecpho : 2  iter :273 ]train loss : 0.303421 ,train acc: 0.857056 ,val loss : 0.423136 ,val acc : 0.812592\n",
      "[ ecpho : 2  iter :274 ]train loss : 0.320451 ,train acc: 0.847270 ,val loss : 0.425314 ,val acc : 0.812256\n",
      "[ ecpho : 2  iter :275 ]train loss : 0.434091 ,train acc: 0.832571 ,val loss : 0.421792 ,val acc : 0.812958\n",
      "[ ecpho : 2  iter :276 ]train loss : 0.327364 ,train acc: 0.850332 ,val loss : 0.423082 ,val acc : 0.812408\n",
      "[ ecpho : 2  iter :277 ]train loss : 0.358220 ,train acc: 0.838806 ,val loss : 0.426218 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :278 ]train loss : 0.334586 ,train acc: 0.850016 ,val loss : 0.425106 ,val acc : 0.812164\n",
      "[ ecpho : 2  iter :279 ]train loss : 0.441648 ,train acc: 0.817871 ,val loss : 0.422444 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :280 ]train loss : 0.311139 ,train acc: 0.853811 ,val loss : 0.429391 ,val acc : 0.810608\n",
      "[ ecpho : 2  iter :281 ]train loss : 0.361972 ,train acc: 0.833629 ,val loss : 0.428752 ,val acc : 0.811523\n",
      "[ ecpho : 2  iter :282 ]train loss : 0.351658 ,train acc: 0.819662 ,val loss : 0.424902 ,val acc : 0.812714\n",
      "[ ecpho : 2  iter :283 ]train loss : 0.438661 ,train acc: 0.821595 ,val loss : 0.421422 ,val acc : 0.808105\n",
      "[ ecpho : 2  iter :284 ]train loss : 0.306599 ,train acc: 0.853821 ,val loss : 0.422067 ,val acc : 0.811737\n",
      "[ ecpho : 2  iter :285 ]train loss : 0.403967 ,train acc: 0.836548 ,val loss : 0.424385 ,val acc : 0.809509\n",
      "[ ecpho : 2  iter :286 ]train loss : 0.347045 ,train acc: 0.838989 ,val loss : 0.428214 ,val acc : 0.810822\n",
      "[ ecpho : 2  iter :287 ]train loss : 0.412733 ,train acc: 0.807099 ,val loss : 0.420773 ,val acc : 0.813538\n",
      "[ ecpho : 2  iter :288 ]train loss : 0.327610 ,train acc: 0.851481 ,val loss : 0.423269 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :289 ]train loss : 0.334322 ,train acc: 0.849508 ,val loss : 0.426902 ,val acc : 0.811096\n",
      "[ ecpho : 2  iter :290 ]train loss : 0.363953 ,train acc: 0.841207 ,val loss : 0.428175 ,val acc : 0.815063\n",
      "[ ecpho : 2  iter :291 ]train loss : 0.342217 ,train acc: 0.842804 ,val loss : 0.421619 ,val acc : 0.809509\n",
      "[ ecpho : 2  iter :292 ]train loss : 0.277778 ,train acc: 0.864665 ,val loss : 0.422518 ,val acc : 0.814087\n",
      "[ ecpho : 2  iter :293 ]train loss : 0.392187 ,train acc: 0.829560 ,val loss : 0.425177 ,val acc : 0.809113\n",
      "[ ecpho : 2  iter :294 ]train loss : 0.341836 ,train acc: 0.846191 ,val loss : 0.421657 ,val acc : 0.813293\n",
      "[ ecpho : 2  iter :295 ]train loss : 0.299805 ,train acc: 0.851247 ,val loss : 0.420879 ,val acc : 0.814453\n",
      "[ ecpho : 2  iter :296 ]train loss : 0.369290 ,train acc: 0.839610 ,val loss : 0.428254 ,val acc : 0.809174\n",
      "[ ecpho : 2  iter :297 ]train loss : 0.286419 ,train acc: 0.859711 ,val loss : 0.416917 ,val acc : 0.811432\n",
      "[ ecpho : 2  iter :298 ]train loss : 0.406142 ,train acc: 0.795675 ,val loss : 0.422120 ,val acc : 0.815063\n",
      "[ ecpho : 2  iter :299 ]train loss : 0.278013 ,train acc: 0.865570 ,val loss : 0.429658 ,val acc : 0.809845\n",
      "[ ecpho : 2  iter :300 ]train loss : 0.301072 ,train acc: 0.850352 ,val loss : 0.425785 ,val acc : 0.810181\n",
      "[ ecpho : 2  iter :301 ]train loss : 0.306072 ,train acc: 0.844737 ,val loss : 0.423438 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :302 ]train loss : 0.291124 ,train acc: 0.857056 ,val loss : 0.422734 ,val acc : 0.809875\n",
      "[ ecpho : 2  iter :303 ]train loss : 0.362468 ,train acc: 0.838684 ,val loss : 0.424730 ,val acc : 0.810913\n",
      "[ ecpho : 2  iter :304 ]train loss : 0.297249 ,train acc: 0.857392 ,val loss : 0.426788 ,val acc : 0.811462\n",
      "[ ecpho : 2  iter :305 ]train loss : 0.427518 ,train acc: 0.782603 ,val loss : 0.430550 ,val acc : 0.810638\n",
      "[ ecpho : 2  iter :306 ]train loss : 0.384589 ,train acc: 0.824341 ,val loss : 0.420470 ,val acc : 0.810211\n",
      "[ ecpho : 2  iter :307 ]train loss : 0.307160 ,train acc: 0.854614 ,val loss : 0.425874 ,val acc : 0.812073\n",
      "[ ecpho : 2  iter :308 ]train loss : 0.388719 ,train acc: 0.827891 ,val loss : 0.418453 ,val acc : 0.814148\n",
      "[ ecpho : 2  iter :309 ]train loss : 0.470041 ,train acc: 0.827332 ,val loss : 0.432024 ,val acc : 0.808350\n",
      "[ ecpho : 2  iter :310 ]train loss : 0.360705 ,train acc: 0.834859 ,val loss : 0.426198 ,val acc : 0.811951\n",
      "[ ecpho : 2  iter :311 ]train loss : 0.332498 ,train acc: 0.858134 ,val loss : 0.423978 ,val acc : 0.810913\n",
      "[ ecpho : 2  iter :312 ]train loss : 0.439349 ,train acc: 0.760671 ,val loss : 0.430401 ,val acc : 0.808533\n",
      "[ ecpho : 2  iter :313 ]train loss : 0.327325 ,train acc: 0.836802 ,val loss : 0.428844 ,val acc : 0.809479\n",
      "[ ecpho : 2  iter :314 ]train loss : 0.325620 ,train acc: 0.850413 ,val loss : 0.423341 ,val acc : 0.808838\n",
      "[ ecpho : 2  iter :315 ]train loss : 0.364584 ,train acc: 0.810191 ,val loss : 0.419790 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :316 ]train loss : 0.313792 ,train acc: 0.851786 ,val loss : 0.428806 ,val acc : 0.808594\n",
      "[ ecpho : 2  iter :317 ]train loss : 0.335821 ,train acc: 0.829692 ,val loss : 0.424280 ,val acc : 0.811768\n",
      "[ ecpho : 2  iter :318 ]train loss : 0.369823 ,train acc: 0.835327 ,val loss : 0.427637 ,val acc : 0.809509\n",
      "[ ecpho : 2  iter :319 ]train loss : 0.291950 ,train acc: 0.859945 ,val loss : 0.424857 ,val acc : 0.812469\n",
      "[ ecpho : 2  iter :320 ]train loss : 0.315722 ,train acc: 0.856476 ,val loss : 0.425295 ,val acc : 0.810669\n",
      "[ ecpho : 2  iter :321 ]train loss : 0.298444 ,train acc: 0.853485 ,val loss : 0.422794 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :322 ]train loss : 0.299989 ,train acc: 0.856242 ,val loss : 0.419930 ,val acc : 0.814697\n",
      "[ ecpho : 2  iter :323 ]train loss : 0.335625 ,train acc: 0.852458 ,val loss : 0.425765 ,val acc : 0.812714\n",
      "[ ecpho : 2  iter :324 ]train loss : 0.338035 ,train acc: 0.852661 ,val loss : 0.422500 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :325 ]train loss : 0.422637 ,train acc: 0.832296 ,val loss : 0.423102 ,val acc : 0.810852\n",
      "[ ecpho : 2  iter :326 ]train loss : 0.339153 ,train acc: 0.842580 ,val loss : 0.423110 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :327 ]train loss : 0.378110 ,train acc: 0.835521 ,val loss : 0.427178 ,val acc : 0.808838\n",
      "[ ecpho : 2  iter :328 ]train loss : 0.336922 ,train acc: 0.842204 ,val loss : 0.427567 ,val acc : 0.810089\n",
      "[ ecpho : 2  iter :329 ]train loss : 0.327936 ,train acc: 0.833018 ,val loss : 0.419538 ,val acc : 0.816040\n",
      "[ ecpho : 2  iter :330 ]train loss : 0.282413 ,train acc: 0.859629 ,val loss : 0.423463 ,val acc : 0.813110\n",
      "[ ecpho : 2  iter :331 ]train loss : 0.306164 ,train acc: 0.857412 ,val loss : 0.420512 ,val acc : 0.814453\n",
      "[ ecpho : 2  iter :332 ]train loss : 0.294097 ,train acc: 0.859945 ,val loss : 0.429103 ,val acc : 0.810577\n",
      "[ ecpho : 2  iter :333 ]train loss : 0.433405 ,train acc: 0.835124 ,val loss : 0.428263 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :334 ]train loss : 0.463836 ,train acc: 0.822001 ,val loss : 0.426272 ,val acc : 0.810150\n",
      "[ ecpho : 2  iter :335 ]train loss : 0.397887 ,train acc: 0.784597 ,val loss : 0.420676 ,val acc : 0.813934\n",
      "[ ecpho : 2  iter :336 ]train loss : 0.333850 ,train acc: 0.851674 ,val loss : 0.423794 ,val acc : 0.812134\n",
      "[ ecpho : 2  iter :337 ]train loss : 0.369185 ,train acc: 0.824453 ,val loss : 0.423265 ,val acc : 0.813385\n",
      "[ ecpho : 2  iter :338 ]train loss : 0.284722 ,train acc: 0.861654 ,val loss : 0.425937 ,val acc : 0.810394\n",
      "[ ecpho : 2  iter :339 ]train loss : 0.350496 ,train acc: 0.834025 ,val loss : 0.427182 ,val acc : 0.808502\n",
      "[ ecpho : 2  iter :340 ]train loss : 0.293654 ,train acc: 0.859080 ,val loss : 0.422737 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :341 ]train loss : 0.399252 ,train acc: 0.830150 ,val loss : 0.424947 ,val acc : 0.811676\n",
      "[ ecpho : 2  iter :342 ]train loss : 0.335824 ,train acc: 0.838369 ,val loss : 0.420176 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :343 ]train loss : 0.396847 ,train acc: 0.835887 ,val loss : 0.426577 ,val acc : 0.812592\n",
      "[ ecpho : 2  iter :344 ]train loss : 0.296891 ,train acc: 0.856873 ,val loss : 0.423148 ,val acc : 0.810547\n",
      "[ ecpho : 2  iter :345 ]train loss : 0.313955 ,train acc: 0.857432 ,val loss : 0.426900 ,val acc : 0.812073\n",
      "[ ecpho : 2  iter :346 ]train loss : 0.310492 ,train acc: 0.857330 ,val loss : 0.426358 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :347 ]train loss : 0.336515 ,train acc: 0.831085 ,val loss : 0.424855 ,val acc : 0.812805\n",
      "[ ecpho : 2  iter :348 ]train loss : 0.483063 ,train acc: 0.826081 ,val loss : 0.422685 ,val acc : 0.814209\n",
      "[ ecpho : 2  iter :349 ]train loss : 0.333109 ,train acc: 0.821910 ,val loss : 0.426804 ,val acc : 0.811035\n",
      "[ ecpho : 2  iter :350 ]train loss : 0.451796 ,train acc: 0.826803 ,val loss : 0.420767 ,val acc : 0.811127\n",
      "[ ecpho : 2  iter :351 ]train loss : 0.359089 ,train acc: 0.843638 ,val loss : 0.422800 ,val acc : 0.811371\n",
      "[ ecpho : 2  iter :352 ]train loss : 0.469572 ,train acc: 0.757528 ,val loss : 0.422344 ,val acc : 0.811798\n",
      "[ ecpho : 2  iter :353 ]train loss : 0.335602 ,train acc: 0.845062 ,val loss : 0.420968 ,val acc : 0.811432\n",
      "[ ecpho : 2  iter :354 ]train loss : 0.493111 ,train acc: 0.765635 ,val loss : 0.419267 ,val acc : 0.811066\n",
      "[ ecpho : 2  iter :355 ]train loss : 0.310718 ,train acc: 0.851939 ,val loss : 0.424280 ,val acc : 0.807007\n",
      "[ ecpho : 2  iter :356 ]train loss : 0.438709 ,train acc: 0.792023 ,val loss : 0.432528 ,val acc : 0.810333\n",
      "[ ecpho : 2  iter :357 ]train loss : 0.355056 ,train acc: 0.842194 ,val loss : 0.421632 ,val acc : 0.816284\n",
      "[ ecpho : 2  iter :358 ]train loss : 0.338273 ,train acc: 0.850932 ,val loss : 0.424101 ,val acc : 0.815094\n",
      "[ ecpho : 2  iter :359 ]train loss : 0.474725 ,train acc: 0.718008 ,val loss : 0.428651 ,val acc : 0.809662\n",
      "[ ecpho : 2  iter :360 ]train loss : 0.347034 ,train acc: 0.831523 ,val loss : 0.418959 ,val acc : 0.811127\n",
      "[ ecpho : 2  iter :361 ]train loss : 0.292042 ,train acc: 0.862050 ,val loss : 0.428582 ,val acc : 0.807953\n",
      "[ ecpho : 2  iter :362 ]train loss : 0.390428 ,train acc: 0.788798 ,val loss : 0.424240 ,val acc : 0.810822\n",
      "[ ecpho : 2  iter :363 ]train loss : 0.315949 ,train acc: 0.848826 ,val loss : 0.414481 ,val acc : 0.814301\n",
      "[ ecpho : 2  iter :364 ]train loss : 0.292345 ,train acc: 0.858266 ,val loss : 0.424457 ,val acc : 0.811768\n",
      "[ ecpho : 2  iter :365 ]train loss : 0.367549 ,train acc: 0.811107 ,val loss : 0.428318 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :366 ]train loss : 0.318759 ,train acc: 0.854696 ,val loss : 0.428464 ,val acc : 0.814606\n",
      "[ ecpho : 2  iter :367 ]train loss : 0.352603 ,train acc: 0.839284 ,val loss : 0.426084 ,val acc : 0.810822\n",
      "[ ecpho : 2  iter :368 ]train loss : 0.328070 ,train acc: 0.820923 ,val loss : 0.427898 ,val acc : 0.810852\n",
      "[ ecpho : 2  iter :369 ]train loss : 0.335664 ,train acc: 0.856038 ,val loss : 0.418906 ,val acc : 0.812927\n",
      "[ ecpho : 2  iter :370 ]train loss : 0.342882 ,train acc: 0.844310 ,val loss : 0.424693 ,val acc : 0.810883\n",
      "[ ecpho : 2  iter :371 ]train loss : 0.368726 ,train acc: 0.843730 ,val loss : 0.424604 ,val acc : 0.811310\n",
      "[ ecpho : 2  iter :372 ]train loss : 0.291840 ,train acc: 0.859538 ,val loss : 0.425197 ,val acc : 0.811523\n",
      "[ ecpho : 2  iter :373 ]train loss : 0.346985 ,train acc: 0.830872 ,val loss : 0.421004 ,val acc : 0.814423\n",
      "[ ecpho : 2  iter :374 ]train loss : 0.442993 ,train acc: 0.831441 ,val loss : 0.426134 ,val acc : 0.811646\n",
      "[ ecpho : 2  iter :375 ]train loss : 0.284226 ,train acc: 0.863007 ,val loss : 0.418146 ,val acc : 0.814636\n",
      "[ ecpho : 2  iter :376 ]train loss : 0.399561 ,train acc: 0.799754 ,val loss : 0.418206 ,val acc : 0.809387\n",
      "[ ecpho : 2  iter :377 ]train loss : 0.288738 ,train acc: 0.860504 ,val loss : 0.422078 ,val acc : 0.810059\n",
      "[ ecpho : 2  iter :378 ]train loss : 0.351127 ,train acc: 0.830353 ,val loss : 0.427445 ,val acc : 0.810364\n",
      "[ ecpho : 2  iter :379 ]train loss : 0.360105 ,train acc: 0.827515 ,val loss : 0.420523 ,val acc : 0.811798\n",
      "[ ecpho : 2  iter :380 ]train loss : 0.289432 ,train acc: 0.861003 ,val loss : 0.426237 ,val acc : 0.811493\n",
      "[ ecpho : 2  iter :381 ]train loss : 0.352917 ,train acc: 0.815674 ,val loss : 0.416503 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :382 ]train loss : 0.394106 ,train acc: 0.778534 ,val loss : 0.427100 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :383 ]train loss : 0.317231 ,train acc: 0.845317 ,val loss : 0.423698 ,val acc : 0.812866\n",
      "[ ecpho : 2  iter :384 ]train loss : 0.465241 ,train acc: 0.713298 ,val loss : 0.421981 ,val acc : 0.812317\n",
      "[ ecpho : 2  iter :385 ]train loss : 0.337477 ,train acc: 0.850383 ,val loss : 0.419499 ,val acc : 0.812500\n",
      "[ ecpho : 2  iter :386 ]train loss : 0.302578 ,train acc: 0.853384 ,val loss : 0.418545 ,val acc : 0.814392\n",
      "[ ecpho : 2  iter :387 ]train loss : 0.288639 ,train acc: 0.863129 ,val loss : 0.419156 ,val acc : 0.815308\n",
      "[ ecpho : 2  iter :388 ]train loss : 0.319010 ,train acc: 0.853526 ,val loss : 0.429113 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :389 ]train loss : 0.330507 ,train acc: 0.847270 ,val loss : 0.422361 ,val acc : 0.811829\n",
      "[ ecpho : 2  iter :390 ]train loss : 0.392584 ,train acc: 0.797516 ,val loss : 0.421363 ,val acc : 0.813324\n",
      "[ ecpho : 2  iter :391 ]train loss : 0.342162 ,train acc: 0.804138 ,val loss : 0.423072 ,val acc : 0.815796\n",
      "[ ecpho : 2  iter :392 ]train loss : 0.469827 ,train acc: 0.824789 ,val loss : 0.416240 ,val acc : 0.813446\n",
      "[ ecpho : 2  iter :393 ]train loss : 0.268978 ,train acc: 0.868205 ,val loss : 0.421047 ,val acc : 0.813690\n",
      "[ ecpho : 2  iter :394 ]train loss : 0.304563 ,train acc: 0.855906 ,val loss : 0.419351 ,val acc : 0.812286\n",
      "[ ecpho : 2  iter :395 ]train loss : 0.295660 ,train acc: 0.862346 ,val loss : 0.422243 ,val acc : 0.815369\n",
      "[ ecpho : 2  iter :396 ]train loss : 0.304126 ,train acc: 0.857554 ,val loss : 0.424978 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :397 ]train loss : 0.368011 ,train acc: 0.839152 ,val loss : 0.421717 ,val acc : 0.812500\n",
      "[ ecpho : 2  iter :398 ]train loss : 0.483720 ,train acc: 0.815369 ,val loss : 0.421728 ,val acc : 0.813446\n",
      "[ ecpho : 2  iter :399 ]train loss : 0.297014 ,train acc: 0.864411 ,val loss : 0.418558 ,val acc : 0.815674\n",
      "[ ecpho : 2  iter :400 ]train loss : 0.339652 ,train acc: 0.824036 ,val loss : 0.418133 ,val acc : 0.816132\n",
      "[ ecpho : 2  iter :401 ]train loss : 0.343282 ,train acc: 0.830811 ,val loss : 0.425019 ,val acc : 0.810486\n",
      "[ ecpho : 2  iter :402 ]train loss : 0.647542 ,train acc: 0.744721 ,val loss : 0.416687 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :403 ]train loss : 0.288911 ,train acc: 0.859324 ,val loss : 0.420444 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :404 ]train loss : 0.366016 ,train acc: 0.842692 ,val loss : 0.422006 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :405 ]train loss : 0.348656 ,train acc: 0.844534 ,val loss : 0.415960 ,val acc : 0.815338\n",
      "[ ecpho : 2  iter :406 ]train loss : 0.344677 ,train acc: 0.847839 ,val loss : 0.418392 ,val acc : 0.812103\n",
      "[ ecpho : 2  iter :407 ]train loss : 0.336492 ,train acc: 0.835795 ,val loss : 0.416435 ,val acc : 0.817261\n",
      "[ ecpho : 2  iter :408 ]train loss : 0.539894 ,train acc: 0.790345 ,val loss : 0.422560 ,val acc : 0.812317\n",
      "[ ecpho : 2  iter :409 ]train loss : 0.302877 ,train acc: 0.853190 ,val loss : 0.420109 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :410 ]train loss : 0.293210 ,train acc: 0.859172 ,val loss : 0.422747 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :411 ]train loss : 0.308564 ,train acc: 0.856761 ,val loss : 0.420735 ,val acc : 0.811127\n",
      "[ ecpho : 2  iter :412 ]train loss : 0.393194 ,train acc: 0.833913 ,val loss : 0.425764 ,val acc : 0.810852\n",
      "[ ecpho : 2  iter :413 ]train loss : 0.428440 ,train acc: 0.825368 ,val loss : 0.414067 ,val acc : 0.814362\n",
      "[ ecpho : 2  iter :414 ]train loss : 0.319172 ,train acc: 0.854502 ,val loss : 0.418981 ,val acc : 0.812653\n",
      "[ ecpho : 2  iter :415 ]train loss : 0.343600 ,train acc: 0.845286 ,val loss : 0.422943 ,val acc : 0.815521\n",
      "[ ecpho : 2  iter :416 ]train loss : 0.276262 ,train acc: 0.864339 ,val loss : 0.426394 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :417 ]train loss : 0.504586 ,train acc: 0.808645 ,val loss : 0.425802 ,val acc : 0.812042\n",
      "[ ecpho : 2  iter :418 ]train loss : 0.318083 ,train acc: 0.845632 ,val loss : 0.427396 ,val acc : 0.810303\n",
      "[ ecpho : 2  iter :419 ]train loss : 0.348411 ,train acc: 0.815328 ,val loss : 0.422971 ,val acc : 0.808807\n",
      "[ ecpho : 2  iter :420 ]train loss : 0.319660 ,train acc: 0.850220 ,val loss : 0.423485 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :421 ]train loss : 0.315134 ,train acc: 0.847524 ,val loss : 0.427312 ,val acc : 0.811676\n",
      "[ ecpho : 2  iter :422 ]train loss : 0.360770 ,train acc: 0.832367 ,val loss : 0.408835 ,val acc : 0.817230\n",
      "[ ecpho : 2  iter :423 ]train loss : 0.258160 ,train acc: 0.873932 ,val loss : 0.424341 ,val acc : 0.811554\n",
      "[ ecpho : 2  iter :424 ]train loss : 0.304730 ,train acc: 0.852570 ,val loss : 0.424944 ,val acc : 0.811676\n",
      "[ ecpho : 2  iter :425 ]train loss : 0.438586 ,train acc: 0.737061 ,val loss : 0.426154 ,val acc : 0.812256\n",
      "[ ecpho : 2  iter :426 ]train loss : 0.352327 ,train acc: 0.822001 ,val loss : 0.418376 ,val acc : 0.812592\n",
      "[ ecpho : 2  iter :427 ]train loss : 0.337241 ,train acc: 0.850627 ,val loss : 0.425297 ,val acc : 0.812439\n",
      "[ ecpho : 2  iter :428 ]train loss : 0.373759 ,train acc: 0.832856 ,val loss : 0.415993 ,val acc : 0.813477\n",
      "[ ecpho : 2  iter :429 ]train loss : 0.381684 ,train acc: 0.815847 ,val loss : 0.422380 ,val acc : 0.811279\n",
      "[ ecpho : 2  iter :430 ]train loss : 0.352019 ,train acc: 0.851736 ,val loss : 0.422256 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :431 ]train loss : 0.344963 ,train acc: 0.848246 ,val loss : 0.419052 ,val acc : 0.814270\n",
      "[ ecpho : 2  iter :432 ]train loss : 0.341554 ,train acc: 0.847229 ,val loss : 0.421651 ,val acc : 0.808990\n",
      "[ ecpho : 2  iter :433 ]train loss : 0.272754 ,train acc: 0.868601 ,val loss : 0.425015 ,val acc : 0.812775\n",
      "[ ecpho : 2  iter :434 ]train loss : 0.377924 ,train acc: 0.840515 ,val loss : 0.425347 ,val acc : 0.811554\n",
      "[ ecpho : 2  iter :435 ]train loss : 0.279755 ,train acc: 0.863485 ,val loss : 0.418705 ,val acc : 0.809204\n",
      "[ ecpho : 2  iter :436 ]train loss : 0.328624 ,train acc: 0.850515 ,val loss : 0.419214 ,val acc : 0.815979\n",
      "[ ecpho : 2  iter :437 ]train loss : 0.285708 ,train acc: 0.865774 ,val loss : 0.418959 ,val acc : 0.815094\n",
      "[ ecpho : 2  iter :438 ]train loss : 0.306919 ,train acc: 0.855103 ,val loss : 0.419556 ,val acc : 0.812286\n",
      "[ ecpho : 2  iter :439 ]train loss : 0.311464 ,train acc: 0.856252 ,val loss : 0.421317 ,val acc : 0.815094\n",
      "[ ecpho : 2  iter :440 ]train loss : 0.285574 ,train acc: 0.860352 ,val loss : 0.426842 ,val acc : 0.812286\n",
      "[ ecpho : 2  iter :441 ]train loss : 0.318647 ,train acc: 0.836721 ,val loss : 0.419504 ,val acc : 0.809967\n",
      "[ ecpho : 2  iter :442 ]train loss : 0.394912 ,train acc: 0.833964 ,val loss : 0.416922 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :443 ]train loss : 0.330324 ,train acc: 0.841288 ,val loss : 0.424361 ,val acc : 0.811249\n",
      "[ ecpho : 2  iter :444 ]train loss : 0.387996 ,train acc: 0.836538 ,val loss : 0.422511 ,val acc : 0.811951\n",
      "[ ecpho : 2  iter :445 ]train loss : 0.313503 ,train acc: 0.854543 ,val loss : 0.421410 ,val acc : 0.809387\n",
      "[ ecpho : 2  iter :446 ]train loss : 0.283082 ,train acc: 0.866353 ,val loss : 0.426543 ,val acc : 0.810547\n",
      "[ ecpho : 2  iter :447 ]train loss : 0.308057 ,train acc: 0.857117 ,val loss : 0.419467 ,val acc : 0.812103\n",
      "[ ecpho : 2  iter :448 ]train loss : 0.338430 ,train acc: 0.838054 ,val loss : 0.424097 ,val acc : 0.809540\n",
      "[ ecpho : 2  iter :449 ]train loss : 0.420307 ,train acc: 0.818166 ,val loss : 0.420819 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :450 ]train loss : 0.338325 ,train acc: 0.839081 ,val loss : 0.423618 ,val acc : 0.809174\n",
      "[ ecpho : 2  iter :451 ]train loss : 0.418567 ,train acc: 0.843791 ,val loss : 0.426656 ,val acc : 0.811432\n",
      "[ ecpho : 2  iter :452 ]train loss : 0.318746 ,train acc: 0.851695 ,val loss : 0.425091 ,val acc : 0.811066\n",
      "[ ecpho : 2  iter :453 ]train loss : 0.316709 ,train acc: 0.857503 ,val loss : 0.419094 ,val acc : 0.814850\n",
      "[ ecpho : 2  iter :454 ]train loss : 0.358015 ,train acc: 0.824992 ,val loss : 0.422495 ,val acc : 0.813965\n",
      "[ ecpho : 2  iter :455 ]train loss : 0.275631 ,train acc: 0.864421 ,val loss : 0.421961 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :456 ]train loss : 0.331490 ,train acc: 0.847606 ,val loss : 0.423854 ,val acc : 0.813232\n",
      "[ ecpho : 2  iter :457 ]train loss : 0.298698 ,train acc: 0.860108 ,val loss : 0.424554 ,val acc : 0.810577\n",
      "[ ecpho : 2  iter :458 ]train loss : 0.272391 ,train acc: 0.868073 ,val loss : 0.419664 ,val acc : 0.814545\n",
      "[ ecpho : 2  iter :459 ]train loss : 0.401261 ,train acc: 0.833171 ,val loss : 0.419686 ,val acc : 0.814758\n",
      "[ ecpho : 2  iter :460 ]train loss : 0.329083 ,train acc: 0.846212 ,val loss : 0.425057 ,val acc : 0.810883\n",
      "[ ecpho : 2  iter :461 ]train loss : 0.309336 ,train acc: 0.858917 ,val loss : 0.427597 ,val acc : 0.811615\n",
      "[ ecpho : 2  iter :462 ]train loss : 0.358647 ,train acc: 0.812724 ,val loss : 0.415211 ,val acc : 0.815125\n",
      "[ ecpho : 2  iter :463 ]train loss : 0.304516 ,train acc: 0.853272 ,val loss : 0.413788 ,val acc : 0.816803\n",
      "[ ecpho : 2  iter :464 ]train loss : 0.331808 ,train acc: 0.853628 ,val loss : 0.424034 ,val acc : 0.813995\n",
      "[ ecpho : 2  iter :465 ]train loss : 0.404931 ,train acc: 0.795929 ,val loss : 0.421514 ,val acc : 0.813385\n",
      "[ ecpho : 2  iter :466 ]train loss : 0.274180 ,train acc: 0.866933 ,val loss : 0.418824 ,val acc : 0.813965\n",
      "[ ecpho : 2  iter :467 ]train loss : 0.384951 ,train acc: 0.836253 ,val loss : 0.424728 ,val acc : 0.813477\n",
      "[ ecpho : 2  iter :468 ]train loss : 0.318063 ,train acc: 0.860942 ,val loss : 0.423892 ,val acc : 0.812775\n",
      "[ ecpho : 2  iter :469 ]train loss : 0.349078 ,train acc: 0.819285 ,val loss : 0.421172 ,val acc : 0.809113\n",
      "[ ecpho : 2  iter :470 ]train loss : 0.271476 ,train acc: 0.869425 ,val loss : 0.425493 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :471 ]train loss : 0.360045 ,train acc: 0.826549 ,val loss : 0.418769 ,val acc : 0.811646\n",
      "[ ecpho : 2  iter :472 ]train loss : 0.453596 ,train acc: 0.830689 ,val loss : 0.416381 ,val acc : 0.816040\n",
      "[ ecpho : 2  iter :473 ]train loss : 0.329001 ,train acc: 0.841645 ,val loss : 0.424938 ,val acc : 0.810150\n",
      "[ ecpho : 2  iter :474 ]train loss : 0.319997 ,train acc: 0.853160 ,val loss : 0.421616 ,val acc : 0.813324\n",
      "[ ecpho : 2  iter :475 ]train loss : 0.348375 ,train acc: 0.845561 ,val loss : 0.418686 ,val acc : 0.811798\n",
      "[ ecpho : 2  iter :476 ]train loss : 0.353051 ,train acc: 0.824931 ,val loss : 0.422251 ,val acc : 0.812958\n",
      "[ ecpho : 2  iter :477 ]train loss : 0.355367 ,train acc: 0.827139 ,val loss : 0.421005 ,val acc : 0.815094\n",
      "[ ecpho : 2  iter :478 ]train loss : 0.397582 ,train acc: 0.831208 ,val loss : 0.417141 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :479 ]train loss : 0.313993 ,train acc: 0.843282 ,val loss : 0.414441 ,val acc : 0.816132\n",
      "[ ecpho : 2  iter :480 ]train loss : 0.306713 ,train acc: 0.860626 ,val loss : 0.415566 ,val acc : 0.814178\n",
      "[ ecpho : 2  iter :481 ]train loss : 0.343069 ,train acc: 0.842652 ,val loss : 0.420528 ,val acc : 0.815857\n",
      "[ ecpho : 2  iter :482 ]train loss : 0.375054 ,train acc: 0.826844 ,val loss : 0.419922 ,val acc : 0.813843\n",
      "[ ecpho : 2  iter :483 ]train loss : 0.326820 ,train acc: 0.847758 ,val loss : 0.420382 ,val acc : 0.812897\n",
      "[ ecpho : 2  iter :484 ]train loss : 0.366914 ,train acc: 0.839040 ,val loss : 0.417571 ,val acc : 0.813568\n",
      "[ ecpho : 2  iter :485 ]train loss : 0.381772 ,train acc: 0.814189 ,val loss : 0.425841 ,val acc : 0.813904\n",
      "[ ecpho : 2  iter :486 ]train loss : 0.338090 ,train acc: 0.845581 ,val loss : 0.419803 ,val acc : 0.812988\n",
      "[ ecpho : 2  iter :487 ]train loss : 0.329153 ,train acc: 0.845490 ,val loss : 0.422221 ,val acc : 0.813171\n",
      "[ ecpho : 2  iter :488 ]train loss : 0.376320 ,train acc: 0.836996 ,val loss : 0.420523 ,val acc : 0.811279\n",
      "[ ecpho : 2  iter :489 ]train loss : 0.332204 ,train acc: 0.840261 ,val loss : 0.420537 ,val acc : 0.811340\n",
      "[ ecpho : 2  iter :490 ]train loss : 0.311364 ,train acc: 0.844513 ,val loss : 0.419861 ,val acc : 0.812775\n",
      "[ ecpho : 2  iter :491 ]train loss : 0.347793 ,train acc: 0.825124 ,val loss : 0.420439 ,val acc : 0.811829\n",
      "[ ecpho : 2  iter :492 ]train loss : 0.315021 ,train acc: 0.849375 ,val loss : 0.420376 ,val acc : 0.815613\n",
      "[ ecpho : 2  iter :493 ]train loss : 0.433137 ,train acc: 0.827403 ,val loss : 0.415073 ,val acc : 0.814270\n",
      "[ ecpho : 2  iter :494 ]train loss : 0.395450 ,train acc: 0.828095 ,val loss : 0.415949 ,val acc : 0.814728\n",
      "[ ecpho : 2  iter :495 ]train loss : 0.319080 ,train acc: 0.841960 ,val loss : 0.418553 ,val acc : 0.813507\n",
      "[ ecpho : 2  iter :496 ]train loss : 0.483595 ,train acc: 0.828491 ,val loss : 0.421014 ,val acc : 0.809723\n",
      "[ ecpho : 2  iter :497 ]train loss : 0.323461 ,train acc: 0.855672 ,val loss : 0.426622 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :498 ]train loss : 0.325109 ,train acc: 0.852122 ,val loss : 0.420370 ,val acc : 0.810669\n",
      "[ ecpho : 2  iter :499 ]train loss : 0.272584 ,train acc: 0.869741 ,val loss : 0.423354 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :500 ]train loss : 0.397636 ,train acc: 0.833801 ,val loss : 0.419517 ,val acc : 0.811859\n",
      "[ ecpho : 2  iter :501 ]train loss : 0.298800 ,train acc: 0.852031 ,val loss : 0.421428 ,val acc : 0.811462\n",
      "[ ecpho : 2  iter :502 ]train loss : 0.313693 ,train acc: 0.849233 ,val loss : 0.419152 ,val acc : 0.812012\n",
      "[ ecpho : 2  iter :503 ]train loss : 0.405929 ,train acc: 0.800893 ,val loss : 0.411990 ,val acc : 0.813446\n",
      "[ ecpho : 2  iter :504 ]train loss : 0.291320 ,train acc: 0.862417 ,val loss : 0.414574 ,val acc : 0.813446\n",
      "[ ecpho : 2  iter :505 ]train loss : 0.327134 ,train acc: 0.834096 ,val loss : 0.419384 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :506 ]train loss : 0.258589 ,train acc: 0.872579 ,val loss : 0.412147 ,val acc : 0.813995\n",
      "[ ecpho : 2  iter :507 ]train loss : 0.373292 ,train acc: 0.842275 ,val loss : 0.419411 ,val acc : 0.813293\n",
      "[ ecpho : 2  iter :508 ]train loss : 0.295969 ,train acc: 0.860972 ,val loss : 0.417725 ,val acc : 0.815704\n",
      "[ ecpho : 2  iter :509 ]train loss : 0.459221 ,train acc: 0.805786 ,val loss : 0.417373 ,val acc : 0.813660\n",
      "[ ecpho : 2  iter :510 ]train loss : 0.354313 ,train acc: 0.850708 ,val loss : 0.419555 ,val acc : 0.813049\n",
      "[ ecpho : 2  iter :511 ]train loss : 0.371405 ,train acc: 0.825785 ,val loss : 0.416909 ,val acc : 0.809021\n",
      "[ ecpho : 2  iter :512 ]train loss : 0.322549 ,train acc: 0.856039 ,val loss : 0.421618 ,val acc : 0.812073\n",
      "[ ecpho : 2  iter :513 ]train loss : 0.312012 ,train acc: 0.855449 ,val loss : 0.425975 ,val acc : 0.809113\n",
      "[ ecpho : 2  iter :514 ]train loss : 0.360862 ,train acc: 0.812317 ,val loss : 0.419781 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :515 ]train loss : 0.311477 ,train acc: 0.858490 ,val loss : 0.416642 ,val acc : 0.817474\n",
      "[ ecpho : 2  iter :516 ]train loss : 0.307427 ,train acc: 0.852122 ,val loss : 0.421505 ,val acc : 0.816223\n",
      "[ ecpho : 2  iter :517 ]train loss : 0.304152 ,train acc: 0.860697 ,val loss : 0.415487 ,val acc : 0.815186\n",
      "[ ecpho : 2  iter :518 ]train loss : 0.290789 ,train acc: 0.863983 ,val loss : 0.418093 ,val acc : 0.815796\n",
      "[ ecpho : 2  iter :519 ]train loss : 0.411409 ,train acc: 0.844808 ,val loss : 0.421968 ,val acc : 0.811218\n",
      "[ ecpho : 2  iter :520 ]train loss : 0.382516 ,train acc: 0.826691 ,val loss : 0.419418 ,val acc : 0.815430\n",
      "[ ecpho : 2  iter :521 ]train loss : 0.322474 ,train acc: 0.849579 ,val loss : 0.418011 ,val acc : 0.815216\n",
      "[ ecpho : 2  iter :522 ]train loss : 0.391096 ,train acc: 0.835368 ,val loss : 0.419078 ,val acc : 0.815582\n",
      "[ ecpho : 2  iter :523 ]train loss : 0.364092 ,train acc: 0.845937 ,val loss : 0.423021 ,val acc : 0.811462\n",
      "[ ecpho : 2  iter :524 ]train loss : 0.330637 ,train acc: 0.849772 ,val loss : 0.421922 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :525 ]train loss : 0.324923 ,train acc: 0.856171 ,val loss : 0.416828 ,val acc : 0.812225\n",
      "[ ecpho : 2  iter :526 ]train loss : 0.317126 ,train acc: 0.852346 ,val loss : 0.418969 ,val acc : 0.812958\n",
      "[ ecpho : 2  iter :527 ]train loss : 0.286760 ,train acc: 0.864237 ,val loss : 0.415881 ,val acc : 0.817139\n",
      "[ ecpho : 2  iter :528 ]train loss : 0.391413 ,train acc: 0.837901 ,val loss : 0.414798 ,val acc : 0.811890\n",
      "[ ecpho : 2  iter :529 ]train loss : 0.344080 ,train acc: 0.849233 ,val loss : 0.420436 ,val acc : 0.814209\n",
      "[ ecpho : 2  iter :530 ]train loss : 0.355258 ,train acc: 0.808340 ,val loss : 0.414214 ,val acc : 0.813019\n",
      "[ ecpho : 2  iter :531 ]train loss : 0.300116 ,train acc: 0.855469 ,val loss : 0.414552 ,val acc : 0.814575\n",
      "[ ecpho : 2  iter :532 ]train loss : 0.308061 ,train acc: 0.856435 ,val loss : 0.420881 ,val acc : 0.811035\n",
      "[ ecpho : 2  iter :533 ]train loss : 0.388024 ,train acc: 0.819031 ,val loss : 0.414185 ,val acc : 0.815308\n",
      "[ ecpho : 2  iter :534 ]train loss : 0.275439 ,train acc: 0.869649 ,val loss : 0.421001 ,val acc : 0.812714\n",
      "[ ecpho : 2  iter :535 ]train loss : 0.396992 ,train acc: 0.830943 ,val loss : 0.422094 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :536 ]train loss : 0.352443 ,train acc: 0.833740 ,val loss : 0.419058 ,val acc : 0.814301\n",
      "[ ecpho : 2  iter :537 ]train loss : 0.506918 ,train acc: 0.818634 ,val loss : 0.413693 ,val acc : 0.813995\n",
      "[ ecpho : 2  iter :538 ]train loss : 0.297409 ,train acc: 0.853109 ,val loss : 0.423677 ,val acc : 0.811493\n",
      "[ ecpho : 2  iter :539 ]train loss : 0.276752 ,train acc: 0.864746 ,val loss : 0.417289 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :540 ]train loss : 0.376426 ,train acc: 0.839529 ,val loss : 0.417197 ,val acc : 0.812103\n",
      "[ ecpho : 2  iter :541 ]train loss : 0.387692 ,train acc: 0.845866 ,val loss : 0.418828 ,val acc : 0.812225\n",
      "[ ecpho : 2  iter :542 ]train loss : 0.414701 ,train acc: 0.832774 ,val loss : 0.423516 ,val acc : 0.811249\n",
      "[ ecpho : 2  iter :543 ]train loss : 0.369359 ,train acc: 0.807078 ,val loss : 0.416508 ,val acc : 0.815643\n",
      "[ ecpho : 2  iter :544 ]train loss : 0.447145 ,train acc: 0.816030 ,val loss : 0.417501 ,val acc : 0.814758\n",
      "[ ecpho : 2  iter :545 ]train loss : 0.333934 ,train acc: 0.854309 ,val loss : 0.421494 ,val acc : 0.815491\n",
      "[ ecpho : 2  iter :546 ]train loss : 0.292953 ,train acc: 0.851400 ,val loss : 0.416861 ,val acc : 0.815094\n",
      "[ ecpho : 2  iter :547 ]train loss : 0.316388 ,train acc: 0.857259 ,val loss : 0.422495 ,val acc : 0.813843\n",
      "[ ecpho : 2  iter :548 ]train loss : 0.362291 ,train acc: 0.847412 ,val loss : 0.417472 ,val acc : 0.814697\n",
      "[ ecpho : 2  iter :549 ]train loss : 0.339806 ,train acc: 0.848399 ,val loss : 0.415480 ,val acc : 0.816132\n",
      "[ ecpho : 2  iter :550 ]train loss : 0.292860 ,train acc: 0.859222 ,val loss : 0.420890 ,val acc : 0.811676\n",
      "[ ecpho : 2  iter :551 ]train loss : 0.606331 ,train acc: 0.765574 ,val loss : 0.419477 ,val acc : 0.811218\n",
      "[ ecpho : 2  iter :552 ]train loss : 0.430257 ,train acc: 0.834880 ,val loss : 0.416775 ,val acc : 0.812164\n",
      "[ ecpho : 2  iter :553 ]train loss : 0.476165 ,train acc: 0.818116 ,val loss : 0.419382 ,val acc : 0.811981\n",
      "[ ecpho : 2  iter :554 ]train loss : 0.294497 ,train acc: 0.856334 ,val loss : 0.420258 ,val acc : 0.816467\n",
      "[ ecpho : 2  iter :555 ]train loss : 0.304892 ,train acc: 0.849264 ,val loss : 0.413748 ,val acc : 0.813080\n",
      "[ ecpho : 2  iter :556 ]train loss : 0.410029 ,train acc: 0.839274 ,val loss : 0.418975 ,val acc : 0.811829\n",
      "[ ecpho : 2  iter :557 ]train loss : 0.320164 ,train acc: 0.837636 ,val loss : 0.420750 ,val acc : 0.814972\n",
      "[ ecpho : 2  iter :558 ]train loss : 0.322056 ,train acc: 0.856201 ,val loss : 0.417884 ,val acc : 0.813507\n",
      "[ ecpho : 2  iter :559 ]train loss : 0.287918 ,train acc: 0.862986 ,val loss : 0.424239 ,val acc : 0.810272\n",
      "[ ecpho : 2  iter :560 ]train loss : 0.361933 ,train acc: 0.833374 ,val loss : 0.421008 ,val acc : 0.812988\n",
      "[ ecpho : 2  iter :561 ]train loss : 0.331951 ,train acc: 0.827881 ,val loss : 0.422273 ,val acc : 0.814484\n",
      "[ ecpho : 2  iter :562 ]train loss : 0.356191 ,train acc: 0.835175 ,val loss : 0.419154 ,val acc : 0.810852\n",
      "[ ecpho : 2  iter :563 ]train loss : 0.305865 ,train acc: 0.853373 ,val loss : 0.419460 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :564 ]train loss : 0.391129 ,train acc: 0.833883 ,val loss : 0.420619 ,val acc : 0.815002\n",
      "[ ecpho : 2  iter :565 ]train loss : 0.435822 ,train acc: 0.833517 ,val loss : 0.427530 ,val acc : 0.810852\n",
      "[ ecpho : 2  iter :566 ]train loss : 0.285705 ,train acc: 0.863037 ,val loss : 0.417570 ,val acc : 0.811035\n",
      "[ ecpho : 2  iter :567 ]train loss : 0.359255 ,train acc: 0.838389 ,val loss : 0.423682 ,val acc : 0.811340\n",
      "[ ecpho : 2  iter :568 ]train loss : 0.401351 ,train acc: 0.762584 ,val loss : 0.413449 ,val acc : 0.814941\n",
      "[ ecpho : 2  iter :569 ]train loss : 0.302304 ,train acc: 0.861043 ,val loss : 0.418407 ,val acc : 0.813812\n",
      "[ ecpho : 2  iter :570 ]train loss : 0.346407 ,train acc: 0.839661 ,val loss : 0.422956 ,val acc : 0.811707\n",
      "[ ecpho : 2  iter :571 ]train loss : 0.394730 ,train acc: 0.833089 ,val loss : 0.417692 ,val acc : 0.815186\n",
      "[ ecpho : 2  iter :572 ]train loss : 0.410231 ,train acc: 0.808248 ,val loss : 0.418842 ,val acc : 0.814392\n",
      "[ ecpho : 2  iter :573 ]train loss : 0.366157 ,train acc: 0.812093 ,val loss : 0.414505 ,val acc : 0.813538\n",
      "[ ecpho : 2  iter :574 ]train loss : 0.285123 ,train acc: 0.863424 ,val loss : 0.418624 ,val acc : 0.813812\n",
      "[ ecpho : 2  iter :575 ]train loss : 0.332094 ,train acc: 0.840119 ,val loss : 0.424666 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :576 ]train loss : 0.468807 ,train acc: 0.797709 ,val loss : 0.416726 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :577 ]train loss : 0.391855 ,train acc: 0.818522 ,val loss : 0.418745 ,val acc : 0.813873\n",
      "[ ecpho : 2  iter :578 ]train loss : 0.311042 ,train acc: 0.854452 ,val loss : 0.422163 ,val acc : 0.812408\n",
      "[ ecpho : 2  iter :579 ]train loss : 0.282616 ,train acc: 0.865428 ,val loss : 0.416918 ,val acc : 0.811035\n",
      "[ ecpho : 2  iter :580 ]train loss : 0.380444 ,train acc: 0.838806 ,val loss : 0.419534 ,val acc : 0.814545\n",
      "[ ecpho : 2  iter :581 ]train loss : 0.393973 ,train acc: 0.838532 ,val loss : 0.410391 ,val acc : 0.815735\n",
      "[ ecpho : 2  iter :582 ]train loss : 0.322184 ,train acc: 0.849009 ,val loss : 0.419559 ,val acc : 0.814636\n",
      "[ ecpho : 2  iter :583 ]train loss : 0.417038 ,train acc: 0.800171 ,val loss : 0.418162 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :584 ]train loss : 0.341082 ,train acc: 0.833374 ,val loss : 0.420555 ,val acc : 0.812744\n",
      "[ ecpho : 2  iter :585 ]train loss : 0.345845 ,train acc: 0.835724 ,val loss : 0.417500 ,val acc : 0.815765\n",
      "[ ecpho : 2  iter :586 ]train loss : 0.320198 ,train acc: 0.851359 ,val loss : 0.416775 ,val acc : 0.814484\n",
      "[ ecpho : 2  iter :587 ]train loss : 0.353585 ,train acc: 0.832845 ,val loss : 0.420624 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :588 ]train loss : 0.332272 ,train acc: 0.836589 ,val loss : 0.418407 ,val acc : 0.814819\n",
      "[ ecpho : 2  iter :589 ]train loss : 0.292596 ,train acc: 0.861023 ,val loss : 0.421267 ,val acc : 0.812897\n",
      "[ ecpho : 2  iter :590 ]train loss : 0.363488 ,train acc: 0.814718 ,val loss : 0.415461 ,val acc : 0.816010\n",
      "[ ecpho : 2  iter :591 ]train loss : 0.334740 ,train acc: 0.834920 ,val loss : 0.418971 ,val acc : 0.810608\n",
      "[ ecpho : 2  iter :592 ]train loss : 0.430040 ,train acc: 0.818950 ,val loss : 0.415775 ,val acc : 0.814911\n",
      "[ ecpho : 2  iter :593 ]train loss : 0.403146 ,train acc: 0.813060 ,val loss : 0.418268 ,val acc : 0.813904\n",
      "[ ecpho : 2  iter :594 ]train loss : 0.410357 ,train acc: 0.812348 ,val loss : 0.417194 ,val acc : 0.813812\n",
      "[ ecpho : 2  iter :595 ]train loss : 0.369571 ,train acc: 0.841024 ,val loss : 0.424020 ,val acc : 0.813721\n",
      "[ ecpho : 2  iter :596 ]train loss : 0.275603 ,train acc: 0.864248 ,val loss : 0.421092 ,val acc : 0.812317\n",
      "[ ecpho : 2  iter :597 ]train loss : 0.309672 ,train acc: 0.839946 ,val loss : 0.419505 ,val acc : 0.810181\n",
      "[ ecpho : 2  iter :598 ]train loss : 0.295332 ,train acc: 0.859385 ,val loss : 0.417558 ,val acc : 0.814453\n",
      "[ ecpho : 2  iter :599 ]train loss : 0.295647 ,train acc: 0.858887 ,val loss : 0.421091 ,val acc : 0.813843\n",
      "[ ecpho : 2  iter :600 ]train loss : 0.310940 ,train acc: 0.857432 ,val loss : 0.418950 ,val acc : 0.813049\n",
      "[ ecpho : 2  iter :601 ]train loss : 0.304744 ,train acc: 0.856272 ,val loss : 0.414713 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :602 ]train loss : 0.269523 ,train acc: 0.868418 ,val loss : 0.417987 ,val acc : 0.813171\n",
      "[ ecpho : 2  iter :603 ]train loss : 0.365395 ,train acc: 0.846161 ,val loss : 0.416613 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :604 ]train loss : 0.305654 ,train acc: 0.855296 ,val loss : 0.419056 ,val acc : 0.812592\n",
      "[ ecpho : 2  iter :605 ]train loss : 0.265104 ,train acc: 0.869314 ,val loss : 0.417097 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :606 ]train loss : 0.306868 ,train acc: 0.837341 ,val loss : 0.421894 ,val acc : 0.816132\n",
      "[ ecpho : 2  iter :607 ]train loss : 0.326175 ,train acc: 0.854991 ,val loss : 0.412229 ,val acc : 0.816406\n",
      "[ ecpho : 2  iter :608 ]train loss : 0.318477 ,train acc: 0.859121 ,val loss : 0.416541 ,val acc : 0.814240\n",
      "[ ecpho : 2  iter :609 ]train loss : 0.307382 ,train acc: 0.856537 ,val loss : 0.413696 ,val acc : 0.814789\n",
      "[ ecpho : 2  iter :610 ]train loss : 0.303306 ,train acc: 0.853170 ,val loss : 0.412405 ,val acc : 0.816040\n",
      "[ ecpho : 2  iter :611 ]train loss : 0.433708 ,train acc: 0.824443 ,val loss : 0.422803 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :612 ]train loss : 0.305094 ,train acc: 0.851502 ,val loss : 0.414263 ,val acc : 0.814148\n",
      "[ ecpho : 2  iter :613 ]train loss : 0.282517 ,train acc: 0.865682 ,val loss : 0.417453 ,val acc : 0.812714\n",
      "[ ecpho : 2  iter :614 ]train loss : 0.289097 ,train acc: 0.857432 ,val loss : 0.418171 ,val acc : 0.813660\n",
      "[ ecpho : 2  iter :615 ]train loss : 0.339710 ,train acc: 0.849660 ,val loss : 0.412849 ,val acc : 0.819122\n",
      "[ ecpho : 2  iter :616 ]train loss : 0.307440 ,train acc: 0.858785 ,val loss : 0.413823 ,val acc : 0.814606\n",
      "[ ecpho : 2  iter :617 ]train loss : 0.333540 ,train acc: 0.831157 ,val loss : 0.417651 ,val acc : 0.814178\n",
      "[ ecpho : 2  iter :618 ]train loss : 0.309575 ,train acc: 0.856415 ,val loss : 0.418130 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :619 ]train loss : 0.272439 ,train acc: 0.866333 ,val loss : 0.417050 ,val acc : 0.812927\n",
      "[ ecpho : 2  iter :620 ]train loss : 0.324325 ,train acc: 0.835215 ,val loss : 0.419551 ,val acc : 0.814575\n",
      "[ ecpho : 2  iter :621 ]train loss : 0.367996 ,train acc: 0.842784 ,val loss : 0.421836 ,val acc : 0.813690\n",
      "[ ecpho : 2  iter :622 ]train loss : 0.392755 ,train acc: 0.833679 ,val loss : 0.417320 ,val acc : 0.814850\n",
      "[ ecpho : 2  iter :623 ]train loss : 0.363061 ,train acc: 0.846334 ,val loss : 0.419543 ,val acc : 0.815338\n",
      "[ ecpho : 2  iter :624 ]train loss : 0.280156 ,train acc: 0.861888 ,val loss : 0.421776 ,val acc : 0.813538\n",
      "[ ecpho : 2  iter :625 ]train loss : 0.306486 ,train acc: 0.848908 ,val loss : 0.422834 ,val acc : 0.810974\n",
      "[ ecpho : 2  iter :626 ]train loss : 0.383036 ,train acc: 0.842580 ,val loss : 0.417345 ,val acc : 0.811005\n",
      "[ ecpho : 2  iter :627 ]train loss : 0.347396 ,train acc: 0.838430 ,val loss : 0.415665 ,val acc : 0.814484\n",
      "[ ecpho : 2  iter :628 ]train loss : 0.354546 ,train acc: 0.838847 ,val loss : 0.410880 ,val acc : 0.815582\n",
      "[ ecpho : 2  iter :629 ]train loss : 0.480290 ,train acc: 0.785279 ,val loss : 0.417535 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :630 ]train loss : 0.410642 ,train acc: 0.798055 ,val loss : 0.415883 ,val acc : 0.815247\n",
      "[ ecpho : 2  iter :631 ]train loss : 0.274372 ,train acc: 0.864451 ,val loss : 0.413720 ,val acc : 0.814423\n",
      "[ ecpho : 2  iter :632 ]train loss : 0.342817 ,train acc: 0.837982 ,val loss : 0.420601 ,val acc : 0.816559\n",
      "[ ecpho : 2  iter :633 ]train loss : 0.431362 ,train acc: 0.784190 ,val loss : 0.418474 ,val acc : 0.816071\n",
      "[ ecpho : 2  iter :634 ]train loss : 0.418616 ,train acc: 0.829010 ,val loss : 0.419514 ,val acc : 0.813843\n",
      "[ ecpho : 2  iter :635 ]train loss : 0.425159 ,train acc: 0.826274 ,val loss : 0.418768 ,val acc : 0.814453\n",
      "[ ecpho : 2  iter :636 ]train loss : 0.283103 ,train acc: 0.862691 ,val loss : 0.425611 ,val acc : 0.811035\n",
      "[ ecpho : 2  iter :637 ]train loss : 0.316436 ,train acc: 0.852234 ,val loss : 0.407865 ,val acc : 0.816711\n",
      "[ ecpho : 2  iter :638 ]train loss : 0.343186 ,train acc: 0.829610 ,val loss : 0.418458 ,val acc : 0.813232\n",
      "[ ecpho : 2  iter :639 ]train loss : 0.285348 ,train acc: 0.857961 ,val loss : 0.418067 ,val acc : 0.812775\n",
      "[ ecpho : 2  iter :640 ]train loss : 0.274791 ,train acc: 0.868276 ,val loss : 0.419581 ,val acc : 0.814209\n",
      "[ ecpho : 2  iter :641 ]train loss : 0.364291 ,train acc: 0.831614 ,val loss : 0.416388 ,val acc : 0.814575\n",
      "[ ecpho : 2  iter :642 ]train loss : 0.323175 ,train acc: 0.852041 ,val loss : 0.410653 ,val acc : 0.817474\n",
      "[ ecpho : 2  iter :643 ]train loss : 0.410884 ,train acc: 0.822144 ,val loss : 0.412001 ,val acc : 0.816986\n",
      "[ ecpho : 2  iter :644 ]train loss : 0.321516 ,train acc: 0.844594 ,val loss : 0.424076 ,val acc : 0.812317\n",
      "[ ecpho : 2  iter :645 ]train loss : 0.357184 ,train acc: 0.844411 ,val loss : 0.415753 ,val acc : 0.809753\n",
      "[ ecpho : 2  iter :646 ]train loss : 0.296588 ,train acc: 0.862641 ,val loss : 0.409343 ,val acc : 0.815796\n",
      "[ ecpho : 2  iter :647 ]train loss : 0.297206 ,train acc: 0.856272 ,val loss : 0.410669 ,val acc : 0.815613\n",
      "[ ecpho : 2  iter :648 ]train loss : 0.355913 ,train acc: 0.836894 ,val loss : 0.419009 ,val acc : 0.813110\n",
      "[ ecpho : 2  iter :649 ]train loss : 0.493372 ,train acc: 0.818075 ,val loss : 0.419757 ,val acc : 0.810364\n",
      "[ ecpho : 2  iter :650 ]train loss : 0.398303 ,train acc: 0.835927 ,val loss : 0.422281 ,val acc : 0.810883\n",
      "[ ecpho : 2  iter :651 ]train loss : 0.294252 ,train acc: 0.862742 ,val loss : 0.415056 ,val acc : 0.814941\n",
      "[ ecpho : 2  iter :652 ]train loss : 0.550687 ,train acc: 0.809052 ,val loss : 0.415320 ,val acc : 0.812622\n",
      "[ ecpho : 2  iter :653 ]train loss : 0.348230 ,train acc: 0.840709 ,val loss : 0.411101 ,val acc : 0.817413\n",
      "[ ecpho : 2  iter :654 ]train loss : 0.341812 ,train acc: 0.827657 ,val loss : 0.416123 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :655 ]train loss : 0.306878 ,train acc: 0.862701 ,val loss : 0.418135 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :656 ]train loss : 0.415332 ,train acc: 0.834544 ,val loss : 0.413629 ,val acc : 0.818085\n",
      "[ ecpho : 2  iter :657 ]train loss : 0.305718 ,train acc: 0.847616 ,val loss : 0.418101 ,val acc : 0.813416\n",
      "[ ecpho : 2  iter :658 ]train loss : 0.400148 ,train acc: 0.834941 ,val loss : 0.408878 ,val acc : 0.816437\n",
      "[ ecpho : 2  iter :659 ]train loss : 0.412622 ,train acc: 0.776255 ,val loss : 0.417714 ,val acc : 0.810730\n",
      "[ ecpho : 2  iter :660 ]train loss : 0.297713 ,train acc: 0.856669 ,val loss : 0.421582 ,val acc : 0.813965\n",
      "[ ecpho : 2  iter :661 ]train loss : 0.397972 ,train acc: 0.819102 ,val loss : 0.414107 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :662 ]train loss : 0.371152 ,train acc: 0.842804 ,val loss : 0.416409 ,val acc : 0.814056\n",
      "[ ecpho : 2  iter :663 ]train loss : 0.530913 ,train acc: 0.815694 ,val loss : 0.418837 ,val acc : 0.811859\n",
      "[ ecpho : 2  iter :664 ]train loss : 0.341010 ,train acc: 0.847870 ,val loss : 0.419816 ,val acc : 0.813995\n",
      "[ ecpho : 2  iter :665 ]train loss : 0.400174 ,train acc: 0.813090 ,val loss : 0.421227 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :666 ]train loss : 0.324605 ,train acc: 0.846619 ,val loss : 0.424118 ,val acc : 0.812958\n",
      "[ ecpho : 2  iter :667 ]train loss : 0.325335 ,train acc: 0.837982 ,val loss : 0.417565 ,val acc : 0.814819\n",
      "[ ecpho : 2  iter :668 ]train loss : 0.392794 ,train acc: 0.838226 ,val loss : 0.419193 ,val acc : 0.812775\n",
      "[ ecpho : 2  iter :669 ]train loss : 0.326952 ,train acc: 0.841461 ,val loss : 0.414808 ,val acc : 0.816528\n",
      "[ ecpho : 2  iter :670 ]train loss : 0.307151 ,train acc: 0.855927 ,val loss : 0.422556 ,val acc : 0.813965\n",
      "[ ecpho : 2  iter :671 ]train loss : 0.324042 ,train acc: 0.857666 ,val loss : 0.413249 ,val acc : 0.817780\n",
      "[ ecpho : 2  iter :672 ]train loss : 0.295730 ,train acc: 0.865997 ,val loss : 0.417922 ,val acc : 0.815430\n",
      "[ ecpho : 2  iter :673 ]train loss : 0.336170 ,train acc: 0.848836 ,val loss : 0.417079 ,val acc : 0.814148\n",
      "[ ecpho : 2  iter :674 ]train loss : 0.372373 ,train acc: 0.830404 ,val loss : 0.416857 ,val acc : 0.815125\n",
      "[ ecpho : 2  iter :675 ]train loss : 0.442942 ,train acc: 0.822907 ,val loss : 0.415110 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :676 ]train loss : 0.345168 ,train acc: 0.824209 ,val loss : 0.417036 ,val acc : 0.813904\n",
      "[ ecpho : 2  iter :677 ]train loss : 0.467235 ,train acc: 0.824921 ,val loss : 0.423515 ,val acc : 0.811646\n",
      "[ ecpho : 2  iter :678 ]train loss : 0.313853 ,train acc: 0.853272 ,val loss : 0.416749 ,val acc : 0.814636\n",
      "[ ecpho : 2  iter :679 ]train loss : 0.650587 ,train acc: 0.673645 ,val loss : 0.418979 ,val acc : 0.810059\n",
      "[ ecpho : 2  iter :680 ]train loss : 0.475058 ,train acc: 0.825470 ,val loss : 0.417141 ,val acc : 0.813843\n",
      "[ ecpho : 2  iter :681 ]train loss : 0.519727 ,train acc: 0.746765 ,val loss : 0.413034 ,val acc : 0.814972\n",
      "[ ecpho : 2  iter :682 ]train loss : 0.327450 ,train acc: 0.849508 ,val loss : 0.412411 ,val acc : 0.815033\n",
      "[ ecpho : 2  iter :683 ]train loss : 0.316768 ,train acc: 0.849294 ,val loss : 0.418092 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :684 ]train loss : 0.311472 ,train acc: 0.851217 ,val loss : 0.415082 ,val acc : 0.814606\n",
      "[ ecpho : 2  iter :685 ]train loss : 0.287586 ,train acc: 0.858337 ,val loss : 0.416295 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :686 ]train loss : 0.435317 ,train acc: 0.826935 ,val loss : 0.418819 ,val acc : 0.814026\n",
      "[ ecpho : 2  iter :687 ]train loss : 0.279092 ,train acc: 0.863607 ,val loss : 0.417614 ,val acc : 0.814941\n",
      "[ ecpho : 2  iter :688 ]train loss : 0.295377 ,train acc: 0.858510 ,val loss : 0.419007 ,val acc : 0.815216\n",
      "[ ecpho : 2  iter :689 ]train loss : 0.303960 ,train acc: 0.845022 ,val loss : 0.416277 ,val acc : 0.814484\n",
      "[ ecpho : 2  iter :690 ]train loss : 0.368542 ,train acc: 0.838562 ,val loss : 0.419116 ,val acc : 0.813019\n",
      "[ ecpho : 2  iter :691 ]train loss : 0.403808 ,train acc: 0.840037 ,val loss : 0.418191 ,val acc : 0.811676\n",
      "[ ecpho : 2  iter :692 ]train loss : 0.319607 ,train acc: 0.848145 ,val loss : 0.421372 ,val acc : 0.812195\n",
      "[ ecpho : 2  iter :693 ]train loss : 0.278238 ,train acc: 0.868103 ,val loss : 0.409876 ,val acc : 0.817688\n",
      "[ ecpho : 2  iter :694 ]train loss : 0.295632 ,train acc: 0.860565 ,val loss : 0.412307 ,val acc : 0.816101\n",
      "[ ecpho : 2  iter :695 ]train loss : 0.406842 ,train acc: 0.786662 ,val loss : 0.410681 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :696 ]train loss : 0.319241 ,train acc: 0.854869 ,val loss : 0.413468 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :697 ]train loss : 0.365373 ,train acc: 0.828471 ,val loss : 0.421323 ,val acc : 0.810089\n",
      "[ ecpho : 2  iter :698 ]train loss : 0.783350 ,train acc: 0.792369 ,val loss : 0.410925 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :699 ]train loss : 0.338959 ,train acc: 0.836874 ,val loss : 0.410915 ,val acc : 0.813690\n",
      "[ ecpho : 2  iter :700 ]train loss : 0.355234 ,train acc: 0.839864 ,val loss : 0.419475 ,val acc : 0.812988\n",
      "[ ecpho : 2  iter :701 ]train loss : 0.368245 ,train acc: 0.843252 ,val loss : 0.413537 ,val acc : 0.814972\n",
      "[ ecpho : 2  iter :702 ]train loss : 0.374856 ,train acc: 0.837026 ,val loss : 0.411166 ,val acc : 0.814301\n",
      "[ ecpho : 2  iter :703 ]train loss : 0.417716 ,train acc: 0.791799 ,val loss : 0.414614 ,val acc : 0.816772\n",
      "[ ecpho : 2  iter :704 ]train loss : 0.321667 ,train acc: 0.853750 ,val loss : 0.416495 ,val acc : 0.815826\n",
      "[ ecpho : 2  iter :705 ]train loss : 0.291847 ,train acc: 0.859111 ,val loss : 0.416301 ,val acc : 0.812927\n",
      "[ ecpho : 2  iter :706 ]train loss : 0.383436 ,train acc: 0.836914 ,val loss : 0.418381 ,val acc : 0.814819\n",
      "[ ecpho : 2  iter :707 ]train loss : 0.304475 ,train acc: 0.853668 ,val loss : 0.416739 ,val acc : 0.815277\n",
      "[ ecpho : 2  iter :708 ]train loss : 0.286550 ,train acc: 0.861654 ,val loss : 0.411956 ,val acc : 0.819519\n",
      "[ ecpho : 2  iter :709 ]train loss : 0.337558 ,train acc: 0.841339 ,val loss : 0.414492 ,val acc : 0.811920\n",
      "[ ecpho : 2  iter :710 ]train loss : 0.367244 ,train acc: 0.834493 ,val loss : 0.417647 ,val acc : 0.811554\n",
      "[ ecpho : 2  iter :711 ]train loss : 0.361223 ,train acc: 0.842601 ,val loss : 0.420064 ,val acc : 0.813507\n",
      "[ ecpho : 2  iter :712 ]train loss : 0.303611 ,train acc: 0.846120 ,val loss : 0.413461 ,val acc : 0.814026\n",
      "[ ecpho : 2  iter :713 ]train loss : 0.296045 ,train acc: 0.858093 ,val loss : 0.411230 ,val acc : 0.814240\n",
      "[ ecpho : 2  iter :714 ]train loss : 0.294267 ,train acc: 0.854197 ,val loss : 0.411797 ,val acc : 0.817322\n",
      "[ ecpho : 2  iter :715 ]train loss : 0.338277 ,train acc: 0.852560 ,val loss : 0.415743 ,val acc : 0.814911\n",
      "[ ecpho : 2  iter :716 ]train loss : 0.375758 ,train acc: 0.831279 ,val loss : 0.417783 ,val acc : 0.815155\n",
      "[ ecpho : 2  iter :717 ]train loss : 0.279112 ,train acc: 0.864868 ,val loss : 0.419858 ,val acc : 0.812927\n",
      "[ ecpho : 2  iter :718 ]train loss : 0.299762 ,train acc: 0.856242 ,val loss : 0.411057 ,val acc : 0.818512\n",
      "[ ecpho : 2  iter :719 ]train loss : 0.322462 ,train acc: 0.844187 ,val loss : 0.422854 ,val acc : 0.809662\n",
      "[ ecpho : 2  iter :720 ]train loss : 0.359697 ,train acc: 0.841207 ,val loss : 0.421675 ,val acc : 0.813477\n",
      "[ ecpho : 2  iter :721 ]train loss : 0.320610 ,train acc: 0.845693 ,val loss : 0.416642 ,val acc : 0.815857\n",
      "[ ecpho : 2  iter :722 ]train loss : 0.295580 ,train acc: 0.860016 ,val loss : 0.414456 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :723 ]train loss : 0.348508 ,train acc: 0.838715 ,val loss : 0.416953 ,val acc : 0.812012\n",
      "[ ecpho : 2  iter :724 ]train loss : 0.322599 ,train acc: 0.835277 ,val loss : 0.416329 ,val acc : 0.815338\n",
      "[ ecpho : 2  iter :725 ]train loss : 0.317244 ,train acc: 0.846883 ,val loss : 0.410237 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :726 ]train loss : 0.341427 ,train acc: 0.854594 ,val loss : 0.414288 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :727 ]train loss : 0.508016 ,train acc: 0.797384 ,val loss : 0.414439 ,val acc : 0.815948\n",
      "[ ecpho : 2  iter :728 ]train loss : 0.262685 ,train acc: 0.872681 ,val loss : 0.416124 ,val acc : 0.814392\n",
      "[ ecpho : 2  iter :729 ]train loss : 0.298520 ,train acc: 0.859731 ,val loss : 0.413713 ,val acc : 0.816681\n",
      "[ ecpho : 2  iter :730 ]train loss : 0.423530 ,train acc: 0.825155 ,val loss : 0.411163 ,val acc : 0.815948\n",
      "[ ecpho : 2  iter :731 ]train loss : 0.321425 ,train acc: 0.853790 ,val loss : 0.415390 ,val acc : 0.814209\n",
      "[ ecpho : 2  iter :732 ]train loss : 0.325078 ,train acc: 0.819102 ,val loss : 0.417741 ,val acc : 0.809845\n",
      "[ ecpho : 2  iter :733 ]train loss : 0.386294 ,train acc: 0.833130 ,val loss : 0.414233 ,val acc : 0.815552\n",
      "[ ecpho : 2  iter :734 ]train loss : 0.394486 ,train acc: 0.788635 ,val loss : 0.413508 ,val acc : 0.817902\n",
      "[ ecpho : 2  iter :735 ]train loss : 0.460253 ,train acc: 0.807150 ,val loss : 0.414962 ,val acc : 0.814819\n",
      "[ ecpho : 2  iter :736 ]train loss : 0.281617 ,train acc: 0.865824 ,val loss : 0.407388 ,val acc : 0.819366\n",
      "[ ecpho : 2  iter :737 ]train loss : 0.344001 ,train acc: 0.820079 ,val loss : 0.413287 ,val acc : 0.816711\n",
      "[ ecpho : 2  iter :738 ]train loss : 0.331109 ,train acc: 0.844574 ,val loss : 0.414281 ,val acc : 0.815887\n",
      "[ ecpho : 2  iter :739 ]train loss : 0.294159 ,train acc: 0.861878 ,val loss : 0.420085 ,val acc : 0.814209\n",
      "[ ecpho : 2  iter :740 ]train loss : 0.287202 ,train acc: 0.864746 ,val loss : 0.420414 ,val acc : 0.811829\n",
      "[ ecpho : 2  iter :741 ]train loss : 0.429469 ,train acc: 0.805003 ,val loss : 0.420998 ,val acc : 0.812897\n",
      "[ ecpho : 2  iter :742 ]train loss : 0.358913 ,train acc: 0.823019 ,val loss : 0.414745 ,val acc : 0.813385\n",
      "[ ecpho : 2  iter :743 ]train loss : 0.311264 ,train acc: 0.854065 ,val loss : 0.413880 ,val acc : 0.813965\n",
      "[ ecpho : 2  iter :744 ]train loss : 0.305320 ,train acc: 0.860341 ,val loss : 0.410150 ,val acc : 0.814026\n",
      "[ ecpho : 2  iter :745 ]train loss : 0.357896 ,train acc: 0.836273 ,val loss : 0.416334 ,val acc : 0.815857\n",
      "[ ecpho : 2  iter :746 ]train loss : 0.471999 ,train acc: 0.818177 ,val loss : 0.412231 ,val acc : 0.816833\n",
      "[ ecpho : 2  iter :747 ]train loss : 0.386483 ,train acc: 0.812897 ,val loss : 0.414572 ,val acc : 0.815826\n",
      "[ ecpho : 2  iter :748 ]train loss : 0.289325 ,train acc: 0.858175 ,val loss : 0.409898 ,val acc : 0.817749\n",
      "[ ecpho : 2  iter :749 ]train loss : 0.313900 ,train acc: 0.850240 ,val loss : 0.413984 ,val acc : 0.812164\n",
      "[ ecpho : 2  iter :750 ]train loss : 0.312964 ,train acc: 0.845775 ,val loss : 0.410594 ,val acc : 0.813904\n",
      "[ ecpho : 2  iter :751 ]train loss : 0.352288 ,train acc: 0.819672 ,val loss : 0.415364 ,val acc : 0.816345\n",
      "[ ecpho : 2  iter :752 ]train loss : 0.351322 ,train acc: 0.834595 ,val loss : 0.420569 ,val acc : 0.812347\n",
      "[ ecpho : 2  iter :753 ]train loss : 0.290098 ,train acc: 0.856771 ,val loss : 0.419300 ,val acc : 0.815643\n",
      "[ ecpho : 2  iter :754 ]train loss : 0.283299 ,train acc: 0.864970 ,val loss : 0.415854 ,val acc : 0.813568\n",
      "[ ecpho : 2  iter :755 ]train loss : 0.393736 ,train acc: 0.823527 ,val loss : 0.412202 ,val acc : 0.813843\n",
      "[ ecpho : 2  iter :756 ]train loss : 0.307102 ,train acc: 0.856517 ,val loss : 0.410354 ,val acc : 0.817230\n",
      "[ ecpho : 2  iter :757 ]train loss : 0.325640 ,train acc: 0.851105 ,val loss : 0.413087 ,val acc : 0.813660\n",
      "[ ecpho : 2  iter :758 ]train loss : 0.356711 ,train acc: 0.838318 ,val loss : 0.419138 ,val acc : 0.815033\n",
      "[ ecpho : 2  iter :759 ]train loss : 0.351622 ,train acc: 0.813446 ,val loss : 0.417510 ,val acc : 0.812561\n",
      "[ ecpho : 2  iter :760 ]train loss : 0.302316 ,train acc: 0.858612 ,val loss : 0.413860 ,val acc : 0.813110\n",
      "[ ecpho : 2  iter :761 ]train loss : 0.530010 ,train acc: 0.769216 ,val loss : 0.415259 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :762 ]train loss : 0.276620 ,train acc: 0.863678 ,val loss : 0.410078 ,val acc : 0.813385\n",
      "[ ecpho : 2  iter :763 ]train loss : 0.534545 ,train acc: 0.707286 ,val loss : 0.420113 ,val acc : 0.811340\n",
      "[ ecpho : 2  iter :764 ]train loss : 0.289870 ,train acc: 0.860118 ,val loss : 0.409213 ,val acc : 0.817047\n",
      "[ ecpho : 2  iter :765 ]train loss : 0.312610 ,train acc: 0.848664 ,val loss : 0.406860 ,val acc : 0.816742\n",
      "[ ecpho : 2  iter :766 ]train loss : 0.281292 ,train acc: 0.862274 ,val loss : 0.410354 ,val acc : 0.817230\n",
      "[ ecpho : 2  iter :767 ]train loss : 0.366176 ,train acc: 0.831045 ,val loss : 0.419629 ,val acc : 0.817047\n",
      "[ ecpho : 2  iter :768 ]train loss : 0.289173 ,train acc: 0.861471 ,val loss : 0.414276 ,val acc : 0.813293\n",
      "[ ecpho : 2  iter :769 ]train loss : 0.457144 ,train acc: 0.779399 ,val loss : 0.415633 ,val acc : 0.815186\n",
      "[ ecpho : 2  iter :770 ]train loss : 0.405840 ,train acc: 0.831116 ,val loss : 0.412621 ,val acc : 0.816986\n",
      "[ ecpho : 2  iter :771 ]train loss : 0.394019 ,train acc: 0.797353 ,val loss : 0.419084 ,val acc : 0.813690\n",
      "[ ecpho : 2  iter :772 ]train loss : 0.352129 ,train acc: 0.844818 ,val loss : 0.408708 ,val acc : 0.816406\n",
      "[ ecpho : 2  iter :773 ]train loss : 0.292706 ,train acc: 0.862101 ,val loss : 0.418238 ,val acc : 0.813690\n",
      "[ ecpho : 2  iter :774 ]train loss : 0.283026 ,train acc: 0.858612 ,val loss : 0.414437 ,val acc : 0.814697\n",
      "[ ecpho : 2  iter :775 ]train loss : 0.303808 ,train acc: 0.855062 ,val loss : 0.414810 ,val acc : 0.814606\n",
      "[ ecpho : 2  iter :776 ]train loss : 0.381805 ,train acc: 0.814809 ,val loss : 0.416912 ,val acc : 0.812439\n",
      "[ ecpho : 2  iter :777 ]train loss : 0.356011 ,train acc: 0.840576 ,val loss : 0.418975 ,val acc : 0.811584\n",
      "[ ecpho : 2  iter :778 ]train loss : 0.264652 ,train acc: 0.869110 ,val loss : 0.409683 ,val acc : 0.814575\n",
      "[ ecpho : 2  iter :779 ]train loss : 0.348031 ,train acc: 0.838806 ,val loss : 0.416319 ,val acc : 0.813202\n",
      "[ ecpho : 2  iter :780 ]train loss : 0.331080 ,train acc: 0.848704 ,val loss : 0.412886 ,val acc : 0.815826\n",
      "[ ecpho : 2  iter :781 ]train loss : 0.367353 ,train acc: 0.840607 ,val loss : 0.411124 ,val acc : 0.813721\n",
      "[ ecpho : 2  iter :782 ]train loss : 0.291831 ,train acc: 0.859670 ,val loss : 0.413847 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :783 ]train loss : 0.351280 ,train acc: 0.840973 ,val loss : 0.410349 ,val acc : 0.818695\n",
      "[ ecpho : 2  iter :784 ]train loss : 0.303661 ,train acc: 0.860107 ,val loss : 0.418601 ,val acc : 0.810150\n",
      "[ ecpho : 2  iter :785 ]train loss : 0.300542 ,train acc: 0.856628 ,val loss : 0.418540 ,val acc : 0.813812\n",
      "[ ecpho : 2  iter :786 ]train loss : 0.307030 ,train acc: 0.854136 ,val loss : 0.418232 ,val acc : 0.814301\n",
      "[ ecpho : 2  iter :787 ]train loss : 0.280119 ,train acc: 0.866170 ,val loss : 0.412862 ,val acc : 0.814636\n",
      "[ ecpho : 2  iter :788 ]train loss : 0.329496 ,train acc: 0.844544 ,val loss : 0.414094 ,val acc : 0.815887\n",
      "[ ecpho : 2  iter :789 ]train loss : 0.377230 ,train acc: 0.837677 ,val loss : 0.411533 ,val acc : 0.816986\n",
      "[ ecpho : 2  iter :790 ]train loss : 0.323186 ,train acc: 0.851695 ,val loss : 0.411200 ,val acc : 0.814484\n",
      "[ ecpho : 2  iter :791 ]train loss : 0.337924 ,train acc: 0.846446 ,val loss : 0.417926 ,val acc : 0.815369\n",
      "[ ecpho : 2  iter :792 ]train loss : 0.330330 ,train acc: 0.829590 ,val loss : 0.416048 ,val acc : 0.816650\n",
      "[ ecpho : 2  iter :793 ]train loss : 0.360986 ,train acc: 0.843404 ,val loss : 0.419350 ,val acc : 0.813293\n",
      "[ ecpho : 2  iter :794 ]train loss : 0.270535 ,train acc: 0.868856 ,val loss : 0.413528 ,val acc : 0.815704\n",
      "[ ecpho : 2  iter :795 ]train loss : 0.398034 ,train acc: 0.777812 ,val loss : 0.410296 ,val acc : 0.815765\n",
      "[ ecpho : 2  iter :796 ]train loss : 0.401327 ,train acc: 0.836477 ,val loss : 0.409242 ,val acc : 0.817474\n",
      "[ ecpho : 2  iter :797 ]train loss : 0.316165 ,train acc: 0.848775 ,val loss : 0.416541 ,val acc : 0.813812\n",
      "[ ecpho : 2  iter :798 ]train loss : 0.289684 ,train acc: 0.857168 ,val loss : 0.414977 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :799 ]train loss : 0.375273 ,train acc: 0.799561 ,val loss : 0.414554 ,val acc : 0.813690\n",
      "[ ecpho : 2  iter :800 ]train loss : 0.323494 ,train acc: 0.843821 ,val loss : 0.410354 ,val acc : 0.817352\n",
      "[ ecpho : 2  iter :801 ]train loss : 0.455504 ,train acc: 0.828654 ,val loss : 0.417902 ,val acc : 0.812347\n",
      "[ ecpho : 2  iter :802 ]train loss : 0.317418 ,train acc: 0.842489 ,val loss : 0.416574 ,val acc : 0.814972\n",
      "[ ecpho : 2  iter :803 ]train loss : 0.284492 ,train acc: 0.863475 ,val loss : 0.415392 ,val acc : 0.816803\n",
      "[ ecpho : 2  iter :804 ]train loss : 0.373097 ,train acc: 0.836273 ,val loss : 0.402806 ,val acc : 0.817902\n",
      "[ ecpho : 2  iter :805 ]train loss : 0.352182 ,train acc: 0.833049 ,val loss : 0.413208 ,val acc : 0.813477\n",
      "[ ecpho : 2  iter :806 ]train loss : 0.309088 ,train acc: 0.853729 ,val loss : 0.410777 ,val acc : 0.813171\n",
      "[ ecpho : 2  iter :807 ]train loss : 0.417799 ,train acc: 0.831329 ,val loss : 0.413004 ,val acc : 0.817383\n",
      "[ ecpho : 2  iter :808 ]train loss : 0.319282 ,train acc: 0.851868 ,val loss : 0.415763 ,val acc : 0.814453\n",
      "[ ecpho : 2  iter :809 ]train loss : 0.431188 ,train acc: 0.813080 ,val loss : 0.413875 ,val acc : 0.815186\n",
      "[ ecpho : 2  iter :810 ]train loss : 0.366474 ,train acc: 0.833730 ,val loss : 0.423321 ,val acc : 0.811920\n",
      "[ ecpho : 2  iter :811 ]train loss : 0.386897 ,train acc: 0.805084 ,val loss : 0.413672 ,val acc : 0.815735\n",
      "[ ecpho : 2  iter :812 ]train loss : 0.359834 ,train acc: 0.841370 ,val loss : 0.412484 ,val acc : 0.815979\n",
      "[ ecpho : 2  iter :813 ]train loss : 0.287754 ,train acc: 0.862691 ,val loss : 0.413201 ,val acc : 0.815826\n",
      "[ ecpho : 2  iter :814 ]train loss : 0.303379 ,train acc: 0.857992 ,val loss : 0.419109 ,val acc : 0.812500\n",
      "[ ecpho : 2  iter :815 ]train loss : 0.302342 ,train acc: 0.857564 ,val loss : 0.417699 ,val acc : 0.814728\n",
      "[ ecpho : 2  iter :816 ]train loss : 0.339325 ,train acc: 0.815908 ,val loss : 0.415383 ,val acc : 0.815521\n",
      "[ ecpho : 2  iter :817 ]train loss : 0.302877 ,train acc: 0.861298 ,val loss : 0.411451 ,val acc : 0.816956\n",
      "[ ecpho : 2  iter :818 ]train loss : 0.286620 ,train acc: 0.860891 ,val loss : 0.405448 ,val acc : 0.816925\n",
      "[ ecpho : 2  iter :819 ]train loss : 0.346051 ,train acc: 0.821401 ,val loss : 0.412907 ,val acc : 0.813477\n",
      "[ ecpho : 2  iter :820 ]train loss : 0.404831 ,train acc: 0.833100 ,val loss : 0.409329 ,val acc : 0.815460\n",
      "[ ecpho : 2  iter :821 ]train loss : 0.354543 ,train acc: 0.844249 ,val loss : 0.412156 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :822 ]train loss : 0.286592 ,train acc: 0.862091 ,val loss : 0.419593 ,val acc : 0.813904\n",
      "[ ecpho : 2  iter :823 ]train loss : 0.540354 ,train acc: 0.772828 ,val loss : 0.415232 ,val acc : 0.815948\n",
      "[ ecpho : 2  iter :824 ]train loss : 0.415957 ,train acc: 0.836904 ,val loss : 0.413240 ,val acc : 0.814819\n",
      "[ ecpho : 2  iter :825 ]train loss : 0.334801 ,train acc: 0.827576 ,val loss : 0.417216 ,val acc : 0.817932\n",
      "[ ecpho : 2  iter :826 ]train loss : 0.472293 ,train acc: 0.810201 ,val loss : 0.424578 ,val acc : 0.811432\n",
      "[ ecpho : 2  iter :827 ]train loss : 0.302330 ,train acc: 0.860108 ,val loss : 0.415789 ,val acc : 0.814178\n",
      "[ ecpho : 2  iter :828 ]train loss : 0.297672 ,train acc: 0.860687 ,val loss : 0.415900 ,val acc : 0.815735\n",
      "[ ecpho : 2  iter :829 ]train loss : 0.277800 ,train acc: 0.864258 ,val loss : 0.414634 ,val acc : 0.816223\n",
      "[ ecpho : 2  iter :830 ]train loss : 0.359005 ,train acc: 0.817688 ,val loss : 0.414240 ,val acc : 0.816437\n",
      "[ ecpho : 2  iter :831 ]train loss : 0.292050 ,train acc: 0.860850 ,val loss : 0.408998 ,val acc : 0.814697\n",
      "[ ecpho : 2  iter :832 ]train loss : 0.336614 ,train acc: 0.840251 ,val loss : 0.407860 ,val acc : 0.817841\n",
      "[ ecpho : 2  iter :833 ]train loss : 0.309886 ,train acc: 0.854645 ,val loss : 0.416468 ,val acc : 0.815613\n",
      "[ ecpho : 2  iter :834 ]train loss : 0.408854 ,train acc: 0.778392 ,val loss : 0.413499 ,val acc : 0.816772\n",
      "[ ecpho : 2  iter :835 ]train loss : 0.453841 ,train acc: 0.784902 ,val loss : 0.407994 ,val acc : 0.816162\n",
      "[ ecpho : 2  iter :836 ]train loss : 0.358742 ,train acc: 0.828003 ,val loss : 0.412028 ,val acc : 0.819214\n",
      "[ ecpho : 2  iter :837 ]train loss : 0.416050 ,train acc: 0.794973 ,val loss : 0.413279 ,val acc : 0.818085\n",
      "[ ecpho : 2  iter :838 ]train loss : 0.323086 ,train acc: 0.838725 ,val loss : 0.409837 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :839 ]train loss : 0.311155 ,train acc: 0.854736 ,val loss : 0.410434 ,val acc : 0.818329\n",
      "[ ecpho : 2  iter :840 ]train loss : 0.382161 ,train acc: 0.839793 ,val loss : 0.419936 ,val acc : 0.809937\n",
      "[ ecpho : 2  iter :841 ]train loss : 0.301175 ,train acc: 0.858002 ,val loss : 0.416976 ,val acc : 0.814087\n",
      "[ ecpho : 2  iter :842 ]train loss : 0.316798 ,train acc: 0.852885 ,val loss : 0.408761 ,val acc : 0.816315\n",
      "[ ecpho : 2  iter :843 ]train loss : 0.365871 ,train acc: 0.811564 ,val loss : 0.411430 ,val acc : 0.812988\n",
      "[ ecpho : 2  iter :844 ]train loss : 0.300160 ,train acc: 0.858409 ,val loss : 0.414720 ,val acc : 0.812897\n",
      "[ ecpho : 2  iter :845 ]train loss : 0.397079 ,train acc: 0.839396 ,val loss : 0.412651 ,val acc : 0.814941\n",
      "[ ecpho : 2  iter :846 ]train loss : 0.265484 ,train acc: 0.872752 ,val loss : 0.411077 ,val acc : 0.815308\n",
      "[ ecpho : 2  iter :847 ]train loss : 0.353170 ,train acc: 0.843303 ,val loss : 0.412505 ,val acc : 0.817719\n",
      "[ ecpho : 2  iter :848 ]train loss : 0.483925 ,train acc: 0.764018 ,val loss : 0.414290 ,val acc : 0.813507\n",
      "[ ecpho : 2  iter :849 ]train loss : 0.305068 ,train acc: 0.853953 ,val loss : 0.415529 ,val acc : 0.817535\n",
      "[ ecpho : 2  iter :850 ]train loss : 0.264902 ,train acc: 0.871094 ,val loss : 0.418442 ,val acc : 0.814117\n",
      "[ ecpho : 2  iter :851 ]train loss : 0.298158 ,train acc: 0.848877 ,val loss : 0.413537 ,val acc : 0.813629\n",
      "[ ecpho : 2  iter :852 ]train loss : 0.295620 ,train acc: 0.863841 ,val loss : 0.411430 ,val acc : 0.815308\n",
      "[ ecpho : 2  iter :853 ]train loss : 0.277824 ,train acc: 0.864929 ,val loss : 0.412608 ,val acc : 0.813782\n",
      "[ ecpho : 2  iter :854 ]train loss : 0.337053 ,train acc: 0.837026 ,val loss : 0.407757 ,val acc : 0.816223\n",
      "[ ecpho : 2  iter :855 ]train loss : 0.372294 ,train acc: 0.815206 ,val loss : 0.406769 ,val acc : 0.817627\n",
      "[ ecpho : 2  iter :856 ]train loss : 0.363068 ,train acc: 0.840098 ,val loss : 0.405933 ,val acc : 0.820557\n",
      "[ ecpho : 2  iter :857 ]train loss : 0.342457 ,train acc: 0.842611 ,val loss : 0.413395 ,val acc : 0.816376\n",
      "[ ecpho : 2  iter :858 ]train loss : 0.394341 ,train acc: 0.801666 ,val loss : 0.411792 ,val acc : 0.813049\n",
      "[ ecpho : 2  iter :859 ]train loss : 0.334945 ,train acc: 0.850739 ,val loss : 0.415982 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :860 ]train loss : 0.343624 ,train acc: 0.844137 ,val loss : 0.415779 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :861 ]train loss : 0.338633 ,train acc: 0.848867 ,val loss : 0.417500 ,val acc : 0.814850\n",
      "[ ecpho : 2  iter :862 ]train loss : 0.422083 ,train acc: 0.833568 ,val loss : 0.410299 ,val acc : 0.812683\n",
      "[ ecpho : 2  iter :863 ]train loss : 0.404420 ,train acc: 0.794708 ,val loss : 0.408232 ,val acc : 0.817383\n",
      "[ ecpho : 2  iter :864 ]train loss : 0.347500 ,train acc: 0.845266 ,val loss : 0.409572 ,val acc : 0.818329\n",
      "[ ecpho : 2  iter :865 ]train loss : 0.287888 ,train acc: 0.857585 ,val loss : 0.416306 ,val acc : 0.811188\n",
      "[ ecpho : 2  iter :866 ]train loss : 0.274865 ,train acc: 0.866486 ,val loss : 0.409150 ,val acc : 0.817993\n",
      "[ ecpho : 2  iter :867 ]train loss : 0.337002 ,train acc: 0.849040 ,val loss : 0.413080 ,val acc : 0.813324\n",
      "[ ecpho : 2  iter :868 ]train loss : 0.328501 ,train acc: 0.843221 ,val loss : 0.416280 ,val acc : 0.814728\n",
      "[ ecpho : 2  iter :869 ]train loss : 0.354581 ,train acc: 0.830383 ,val loss : 0.412025 ,val acc : 0.817261\n",
      "[ ecpho : 2  iter :870 ]train loss : 0.292765 ,train acc: 0.860942 ,val loss : 0.415854 ,val acc : 0.815582\n",
      "[ ecpho : 2  iter :871 ]train loss : 0.275247 ,train acc: 0.866974 ,val loss : 0.409963 ,val acc : 0.815430\n",
      "[ ecpho : 2  iter :872 ]train loss : 0.327008 ,train acc: 0.850749 ,val loss : 0.413609 ,val acc : 0.815796\n",
      "[ ecpho : 2  iter :873 ]train loss : 0.308504 ,train acc: 0.848643 ,val loss : 0.418347 ,val acc : 0.813263\n",
      "[ ecpho : 2  iter :874 ]train loss : 0.292728 ,train acc: 0.857483 ,val loss : 0.409580 ,val acc : 0.819489\n",
      "[ ecpho : 2  iter :875 ]train loss : 0.307482 ,train acc: 0.849325 ,val loss : 0.410474 ,val acc : 0.815033\n",
      "[ ecpho : 2  iter :876 ]train loss : 0.310670 ,train acc: 0.854787 ,val loss : 0.409451 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :877 ]train loss : 0.478229 ,train acc: 0.794088 ,val loss : 0.413420 ,val acc : 0.813599\n",
      "[ ecpho : 2  iter :878 ]train loss : 0.292783 ,train acc: 0.862284 ,val loss : 0.414378 ,val acc : 0.814453\n",
      "[ ecpho : 2  iter :879 ]train loss : 0.428558 ,train acc: 0.820943 ,val loss : 0.415444 ,val acc : 0.814240\n",
      "[ ecpho : 2  iter :880 ]train loss : 0.290273 ,train acc: 0.864197 ,val loss : 0.411835 ,val acc : 0.816620\n",
      "[ ecpho : 2  iter :881 ]train loss : 0.325994 ,train acc: 0.856974 ,val loss : 0.416104 ,val acc : 0.818970\n",
      "[ ecpho : 2  iter :882 ]train loss : 0.302526 ,train acc: 0.856476 ,val loss : 0.411281 ,val acc : 0.816833\n",
      "[ ecpho : 2  iter :883 ]train loss : 0.438637 ,train acc: 0.694143 ,val loss : 0.408090 ,val acc : 0.816803\n",
      "[ ecpho : 2  iter :884 ]train loss : 0.273220 ,train acc: 0.862763 ,val loss : 0.413972 ,val acc : 0.817383\n",
      "[ ecpho : 2  iter :885 ]train loss : 0.297559 ,train acc: 0.857788 ,val loss : 0.415709 ,val acc : 0.818726\n",
      "[ ecpho : 2  iter :886 ]train loss : 0.308654 ,train acc: 0.855235 ,val loss : 0.407728 ,val acc : 0.817474\n",
      "[ ecpho : 2  iter :887 ]train loss : 0.392969 ,train acc: 0.815440 ,val loss : 0.414572 ,val acc : 0.817963\n",
      "[ ecpho : 2  iter :888 ]train loss : 0.365556 ,train acc: 0.839223 ,val loss : 0.411872 ,val acc : 0.816742\n",
      "[ ecpho : 2  iter :889 ]train loss : 0.303741 ,train acc: 0.856954 ,val loss : 0.416963 ,val acc : 0.813782\n",
      "[ ecpho : 2  iter :890 ]train loss : 0.325461 ,train acc: 0.849864 ,val loss : 0.423413 ,val acc : 0.814514\n",
      "[ ecpho : 2  iter :891 ]train loss : 0.301549 ,train acc: 0.857198 ,val loss : 0.406184 ,val acc : 0.816437\n",
      "[ ecpho : 2  iter :892 ]train loss : 0.288429 ,train acc: 0.861755 ,val loss : 0.408413 ,val acc : 0.817261\n",
      "[ ecpho : 2  iter :893 ]train loss : 0.338212 ,train acc: 0.848674 ,val loss : 0.408230 ,val acc : 0.816010\n",
      "[ ecpho : 2  iter :894 ]train loss : 0.308506 ,train acc: 0.855886 ,val loss : 0.409736 ,val acc : 0.818939\n",
      "[ ecpho : 2  iter :895 ]train loss : 0.324712 ,train acc: 0.848206 ,val loss : 0.411919 ,val acc : 0.818756\n",
      "[ ecpho : 2  iter :896 ]train loss : 0.378323 ,train acc: 0.818624 ,val loss : 0.409249 ,val acc : 0.816010\n",
      "[ ecpho : 2  iter :897 ]train loss : 0.358862 ,train acc: 0.844564 ,val loss : 0.408194 ,val acc : 0.814667\n",
      "[ ecpho : 2  iter :898 ]train loss : 0.380556 ,train acc: 0.832632 ,val loss : 0.412476 ,val acc : 0.816376\n",
      "[ ecpho : 2  iter :899 ]train loss : 0.369800 ,train acc: 0.816742 ,val loss : 0.408736 ,val acc : 0.819489\n",
      "[ ecpho : 2  iter :900 ]train loss : 0.283275 ,train acc: 0.868083 ,val loss : 0.412560 ,val acc : 0.815979\n",
      "[ ecpho : 2  iter :901 ]train loss : 0.355109 ,train acc: 0.839447 ,val loss : 0.410031 ,val acc : 0.816620\n",
      "[ ecpho : 2  iter :902 ]train loss : 0.491270 ,train acc: 0.832347 ,val loss : 0.414747 ,val acc : 0.816223\n",
      "[ ecpho : 2  iter :903 ]train loss : 0.416476 ,train acc: 0.832296 ,val loss : 0.414607 ,val acc : 0.813232\n",
      "[ ecpho : 2  iter :904 ]train loss : 0.327994 ,train acc: 0.847372 ,val loss : 0.408391 ,val acc : 0.817261\n",
      "[ ecpho : 2  iter :905 ]train loss : 0.436475 ,train acc: 0.816874 ,val loss : 0.408522 ,val acc : 0.816010\n",
      "[ ecpho : 2  iter :906 ]train loss : 0.390040 ,train acc: 0.786367 ,val loss : 0.410387 ,val acc : 0.816284\n",
      "[ ecpho : 2  iter :907 ]train loss : 0.291024 ,train acc: 0.861562 ,val loss : 0.416021 ,val acc : 0.814087\n",
      "[ ecpho : 2  iter :908 ]train loss : 0.281289 ,train acc: 0.864838 ,val loss : 0.410425 ,val acc : 0.819183\n",
      "[ ecpho : 2  iter :909 ]train loss : 0.422928 ,train acc: 0.833893 ,val loss : 0.413050 ,val acc : 0.816132\n",
      "[ ecpho : 2  iter :910 ]train loss : 0.313016 ,train acc: 0.851461 ,val loss : 0.408574 ,val acc : 0.813293\n",
      "[ ecpho : 2  iter :911 ]train loss : 0.320742 ,train acc: 0.841787 ,val loss : 0.408878 ,val acc : 0.815308\n",
      "[ ecpho : 2  iter :912 ]train loss : 0.495570 ,train acc: 0.752767 ,val loss : 0.421966 ,val acc : 0.813782\n",
      "[ ecpho : 2  iter :913 ]train loss : 0.280675 ,train acc: 0.866018 ,val loss : 0.412368 ,val acc : 0.816040\n",
      "[ ecpho : 2  iter :914 ]train loss : 0.323504 ,train acc: 0.851888 ,val loss : 0.418194 ,val acc : 0.812531\n",
      "[ ecpho : 2  iter :915 ]train loss : 0.361938 ,train acc: 0.846660 ,val loss : 0.408602 ,val acc : 0.818512\n",
      "[ ecpho : 2  iter :916 ]train loss : 0.293077 ,train acc: 0.857829 ,val loss : 0.411499 ,val acc : 0.815521\n",
      "[ ecpho : 2  iter :917 ]train loss : 0.331416 ,train acc: 0.832265 ,val loss : 0.411132 ,val acc : 0.815948\n",
      "[ ecpho : 2  iter :918 ]train loss : 0.283931 ,train acc: 0.863281 ,val loss : 0.410164 ,val acc : 0.816803\n",
      "[ ecpho : 2  iter :919 ]train loss : 0.329421 ,train acc: 0.851044 ,val loss : 0.408608 ,val acc : 0.816345\n",
      "[ ecpho : 2  iter :920 ]train loss : 0.258449 ,train acc: 0.874023 ,val loss : 0.405236 ,val acc : 0.818024\n",
      "[ ecpho : 2  iter :921 ]train loss : 0.360474 ,train acc: 0.811544 ,val loss : 0.415317 ,val acc : 0.817596\n",
      "[ ecpho : 2  iter :922 ]train loss : 0.290860 ,train acc: 0.863993 ,val loss : 0.408528 ,val acc : 0.813019\n",
      "[ ecpho : 2  iter :923 ]train loss : 0.285923 ,train acc: 0.861979 ,val loss : 0.412404 ,val acc : 0.814636\n",
      "[ ecpho : 2  iter :924 ]train loss : 0.391878 ,train acc: 0.826243 ,val loss : 0.401580 ,val acc : 0.820190\n",
      "[ ecpho : 2  iter :925 ]train loss : 0.310152 ,train acc: 0.856476 ,val loss : 0.413292 ,val acc : 0.816589\n",
      "[ ecpho : 2  iter :926 ]train loss : 0.329571 ,train acc: 0.854624 ,val loss : 0.405522 ,val acc : 0.817871\n",
      "[ ecpho : 2  iter :927 ]train loss : 0.291168 ,train acc: 0.865479 ,val loss : 0.415113 ,val acc : 0.814697\n",
      "[ ecpho : 2  iter :928 ]train loss : 0.349726 ,train acc: 0.851664 ,val loss : 0.419421 ,val acc : 0.816833\n",
      "[ ecpho : 2  iter :929 ]train loss : 0.322697 ,train acc: 0.841634 ,val loss : 0.407618 ,val acc : 0.820740\n",
      "[ ecpho : 2  iter :930 ]train loss : 0.397689 ,train acc: 0.829600 ,val loss : 0.406526 ,val acc : 0.819183\n",
      "[ ecpho : 2  iter :931 ]train loss : 0.279038 ,train acc: 0.863251 ,val loss : 0.412502 ,val acc : 0.812561\n",
      "[ ecpho : 2  iter :932 ]train loss : 0.344513 ,train acc: 0.843689 ,val loss : 0.407437 ,val acc : 0.815857\n",
      "[ ecpho : 2  iter :933 ]train loss : 0.310909 ,train acc: 0.854207 ,val loss : 0.413818 ,val acc : 0.814087\n",
      "[ ecpho : 2  iter :934 ]train loss : 0.359916 ,train acc: 0.837270 ,val loss : 0.403350 ,val acc : 0.819427\n",
      "[ ecpho : 2  iter :935 ]train loss : 0.329865 ,train acc: 0.857239 ,val loss : 0.412061 ,val acc : 0.815277\n",
      "[ ecpho : 2  iter :936 ]train loss : 0.273344 ,train acc: 0.868093 ,val loss : 0.413187 ,val acc : 0.815674\n",
      "[ ecpho : 2  iter :937 ]train loss : 0.258241 ,train acc: 0.871368 ,val loss : 0.410490 ,val acc : 0.816803\n",
      "[ ecpho : 2  iter :938 ]train loss : 0.272094 ,train acc: 0.866638 ,val loss : 0.412366 ,val acc : 0.817200\n",
      "[ ecpho : 2  iter :939 ]train loss : 0.302535 ,train acc: 0.854319 ,val loss : 0.413504 ,val acc : 0.814423\n",
      "[ ecpho : 2  iter :940 ]train loss : 0.457800 ,train acc: 0.829295 ,val loss : 0.407398 ,val acc : 0.818542\n",
      "[ ecpho : 2  iter :941 ]train loss : 0.318857 ,train acc: 0.851217 ,val loss : 0.406748 ,val acc : 0.814178\n",
      "[ ecpho : 2  iter :942 ]train loss : 0.341877 ,train acc: 0.837026 ,val loss : 0.414419 ,val acc : 0.815521\n",
      "[ ecpho : 2  iter :943 ]train loss : 0.285201 ,train acc: 0.864085 ,val loss : 0.409393 ,val acc : 0.814026\n",
      "[ ecpho : 2  iter :944 ]train loss : 0.285403 ,train acc: 0.864370 ,val loss : 0.409790 ,val acc : 0.820618\n",
      "[ ecpho : 2  iter :945 ]train loss : 0.327297 ,train acc: 0.840129 ,val loss : 0.407523 ,val acc : 0.816711\n",
      "[ ecpho : 2  iter :946 ]train loss : 0.335359 ,train acc: 0.841665 ,val loss : 0.418737 ,val acc : 0.813873\n",
      "[ ecpho : 2  iter :947 ]train loss : 0.297103 ,train acc: 0.859619 ,val loss : 0.409631 ,val acc : 0.817352\n",
      "[ ecpho : 2  iter :948 ]train loss : 0.293035 ,train acc: 0.860769 ,val loss : 0.404541 ,val acc : 0.820007\n",
      "[ ecpho : 2  iter :949 ]train loss : 0.280649 ,train acc: 0.862396 ,val loss : 0.412668 ,val acc : 0.817047\n",
      "[ ecpho : 2  iter :950 ]train loss : 0.357553 ,train acc: 0.813141 ,val loss : 0.408840 ,val acc : 0.815338\n",
      "[ ecpho : 2  iter :951 ]train loss : 0.314714 ,train acc: 0.847728 ,val loss : 0.417076 ,val acc : 0.814240\n",
      "[ ecpho : 2  iter :952 ]train loss : 0.293765 ,train acc: 0.861186 ,val loss : 0.414076 ,val acc : 0.811615\n",
      "[ ecpho : 2  iter :953 ]train loss : 0.298441 ,train acc: 0.858002 ,val loss : 0.409648 ,val acc : 0.818909\n",
      "[ ecpho : 2  iter :954 ]train loss : 0.374577 ,train acc: 0.837860 ,val loss : 0.411163 ,val acc : 0.816437\n",
      "[ ecpho : 2  iter :955 ]train loss : 0.412293 ,train acc: 0.810303 ,val loss : 0.414931 ,val acc : 0.815063\n",
      "[ ecpho : 2  iter :956 ]train loss : 0.266734 ,train acc: 0.870890 ,val loss : 0.406863 ,val acc : 0.819916\n",
      "[ ecpho : 2  iter :957 ]train loss : 0.370261 ,train acc: 0.840292 ,val loss : 0.410932 ,val acc : 0.814850\n",
      "[ ecpho : 2  iter :958 ]train loss : 0.325015 ,train acc: 0.850352 ,val loss : 0.407959 ,val acc : 0.816895\n",
      "[ ecpho : 2  iter :959 ]train loss : 0.410414 ,train acc: 0.827637 ,val loss : 0.415442 ,val acc : 0.815063\n",
      "[ ecpho : 2  iter :960 ]train loss : 0.372287 ,train acc: 0.831380 ,val loss : 0.408436 ,val acc : 0.817383\n",
      "[ ecpho : 2  iter :961 ]train loss : 0.336851 ,train acc: 0.852539 ,val loss : 0.410827 ,val acc : 0.818787\n",
      "[ ecpho : 2  iter :962 ]train loss : 0.396618 ,train acc: 0.831563 ,val loss : 0.405480 ,val acc : 0.817383\n",
      "[ ecpho : 2  iter :963 ]train loss : 0.321850 ,train acc: 0.845927 ,val loss : 0.409001 ,val acc : 0.816925\n",
      "[ ecpho : 2  iter :964 ]train loss : 0.433535 ,train acc: 0.813009 ,val loss : 0.413203 ,val acc : 0.814850\n",
      "[ ecpho : 2  iter :965 ]train loss : 0.385589 ,train acc: 0.803701 ,val loss : 0.413723 ,val acc : 0.818909\n",
      "[ ecpho : 2  iter :966 ]train loss : 0.331108 ,train acc: 0.857178 ,val loss : 0.412862 ,val acc : 0.813507\n",
      "[ ecpho : 2  iter :967 ]train loss : 0.330271 ,train acc: 0.850901 ,val loss : 0.414012 ,val acc : 0.816071\n",
      "[ ecpho : 2  iter :968 ]train loss : 0.314004 ,train acc: 0.854706 ,val loss : 0.410381 ,val acc : 0.815796\n",
      "[ ecpho : 2  iter :969 ]train loss : 0.307981 ,train acc: 0.851949 ,val loss : 0.416201 ,val acc : 0.813599\n",
      "[ ecpho : 2  iter :970 ]train loss : 0.309626 ,train acc: 0.857564 ,val loss : 0.409259 ,val acc : 0.814270\n",
      "[ ecpho : 2  iter :971 ]train loss : 0.410248 ,train acc: 0.833262 ,val loss : 0.405352 ,val acc : 0.822083\n",
      "[ ecpho : 2  iter :972 ]train loss : 0.310459 ,train acc: 0.854960 ,val loss : 0.409006 ,val acc : 0.821655\n",
      "[ ecpho : 2  iter :973 ]train loss : 0.253039 ,train acc: 0.875651 ,val loss : 0.415645 ,val acc : 0.815918\n",
      "[ ecpho : 2  iter :974 ]train loss : 0.304979 ,train acc: 0.836467 ,val loss : 0.409127 ,val acc : 0.817383\n",
      "[ ecpho : 2  iter :975 ]train loss : 0.447371 ,train acc: 0.717682 ,val loss : 0.408873 ,val acc : 0.816132\n",
      "[ ecpho : 2  iter :976 ]train loss : 0.472092 ,train acc: 0.831950 ,val loss : 0.413861 ,val acc : 0.815308\n",
      "[ ecpho : 2  iter :977 ]train loss : 0.342905 ,train acc: 0.850952 ,val loss : 0.414073 ,val acc : 0.818085\n",
      "[ ecpho : 2  iter :978 ]train loss : 0.478987 ,train acc: 0.793996 ,val loss : 0.417595 ,val acc : 0.813385\n",
      "[ ecpho : 2  iter :979 ]train loss : 0.290522 ,train acc: 0.862457 ,val loss : 0.416809 ,val acc : 0.814880\n",
      "[ ecpho : 2  iter :980 ]train loss : 0.294987 ,train acc: 0.863139 ,val loss : 0.406490 ,val acc : 0.820526\n",
      "[ ecpho : 2  iter :981 ]train loss : 0.298089 ,train acc: 0.859284 ,val loss : 0.407171 ,val acc : 0.817780\n",
      "[ ecpho : 2  iter :982 ]train loss : 0.349409 ,train acc: 0.843771 ,val loss : 0.406735 ,val acc : 0.817200\n",
      "[ ecpho : 2  iter :983 ]train loss : 0.390253 ,train acc: 0.848938 ,val loss : 0.407900 ,val acc : 0.817261\n",
      "[ ecpho : 2  iter :984 ]train loss : 0.401209 ,train acc: 0.798747 ,val loss : 0.406286 ,val acc : 0.817444\n",
      "[ ecpho : 2  iter :985 ]train loss : 0.369500 ,train acc: 0.808268 ,val loss : 0.407346 ,val acc : 0.816986\n",
      "[ ecpho : 2  iter :986 ]train loss : 0.448274 ,train acc: 0.832571 ,val loss : 0.409127 ,val acc : 0.817261\n",
      "[ ecpho : 2  iter :987 ]train loss : 0.365904 ,train acc: 0.835215 ,val loss : 0.408255 ,val acc : 0.814545\n",
      "[ ecpho : 2  iter :988 ]train loss : 0.384034 ,train acc: 0.817953 ,val loss : 0.413270 ,val acc : 0.814117\n",
      "[ ecpho : 2  iter :989 ]train loss : 0.302841 ,train acc: 0.853923 ,val loss : 0.413560 ,val acc : 0.816772\n",
      "[ ecpho : 2  iter :990 ]train loss : 0.328257 ,train acc: 0.856568 ,val loss : 0.412523 ,val acc : 0.816376\n",
      "[ ecpho : 2  iter :991 ]train loss : 0.246288 ,train acc: 0.881846 ,val loss : 0.407266 ,val acc : 0.815399\n",
      "[ ecpho : 2  iter :992 ]train loss : 0.323629 ,train acc: 0.854909 ,val loss : 0.405674 ,val acc : 0.820374\n",
      "[ ecpho : 2  iter :993 ]train loss : 0.310167 ,train acc: 0.860311 ,val loss : 0.408988 ,val acc : 0.815857\n",
      "[ ecpho : 2  iter :994 ]train loss : 0.280304 ,train acc: 0.865051 ,val loss : 0.412352 ,val acc : 0.816284\n",
      "[ ecpho : 2  iter :995 ]train loss : 0.302176 ,train acc: 0.855164 ,val loss : 0.409064 ,val acc : 0.814331\n",
      "[ ecpho : 2  iter :996 ]train loss : 0.333055 ,train acc: 0.850586 ,val loss : 0.409539 ,val acc : 0.820038\n",
      "[ ecpho : 2  iter :997 ]train loss : 0.325907 ,train acc: 0.843140 ,val loss : 0.412433 ,val acc : 0.812897\n",
      "[ ecpho : 2  iter :998 ]train loss : 0.256332 ,train acc: 0.874603 ,val loss : 0.409932 ,val acc : 0.818878\n",
      "[ ecpho : 2  iter :999 ]train loss : 0.280156 ,train acc: 0.860525 ,val loss : 0.408700 ,val acc : 0.817871\n",
      "[ ecpho : 2  iter :1000 ]train loss : 0.355484 ,train acc: 0.852753 ,val loss : 0.407166 ,val acc : 0.814758\n",
      "=============================================\n",
      "[ 2 ] average train loss : 0.350905 train acc : 0.838250\n",
      "[ ecpho : 3  iter :1 ]train loss : 0.272016 ,train acc: 0.869354 ,val loss : 0.412962 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :2 ]train loss : 0.374491 ,train acc: 0.831136 ,val loss : 0.413007 ,val acc : 0.814728\n",
      "[ ecpho : 3  iter :3 ]train loss : 0.349965 ,train acc: 0.824555 ,val loss : 0.402798 ,val acc : 0.820374\n",
      "[ ecpho : 3  iter :4 ]train loss : 0.353522 ,train acc: 0.844533 ,val loss : 0.406896 ,val acc : 0.816711\n",
      "[ ecpho : 3  iter :5 ]train loss : 0.308229 ,train acc: 0.846141 ,val loss : 0.408829 ,val acc : 0.817688\n",
      "[ ecpho : 3  iter :6 ]train loss : 0.359505 ,train acc: 0.838715 ,val loss : 0.410245 ,val acc : 0.818451\n",
      "[ ecpho : 3  iter :7 ]train loss : 0.438570 ,train acc: 0.829631 ,val loss : 0.409055 ,val acc : 0.816956\n",
      "[ ecpho : 3  iter :8 ]train loss : 0.344392 ,train acc: 0.848623 ,val loss : 0.412128 ,val acc : 0.816437\n",
      "[ ecpho : 3  iter :9 ]train loss : 0.269014 ,train acc: 0.874929 ,val loss : 0.411795 ,val acc : 0.816223\n",
      "[ ecpho : 3  iter :10 ]train loss : 0.368116 ,train acc: 0.806132 ,val loss : 0.410858 ,val acc : 0.818420\n",
      "[ ecpho : 3  iter :11 ]train loss : 0.417391 ,train acc: 0.807516 ,val loss : 0.415274 ,val acc : 0.816284\n",
      "[ ecpho : 3  iter :12 ]train loss : 0.288638 ,train acc: 0.860270 ,val loss : 0.407626 ,val acc : 0.815613\n",
      "[ ecpho : 3  iter :13 ]train loss : 0.464907 ,train acc: 0.819642 ,val loss : 0.411395 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :14 ]train loss : 0.311527 ,train acc: 0.858663 ,val loss : 0.407583 ,val acc : 0.816132\n",
      "[ ecpho : 3  iter :15 ]train loss : 0.286182 ,train acc: 0.863047 ,val loss : 0.404410 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :16 ]train loss : 0.264430 ,train acc: 0.869253 ,val loss : 0.419111 ,val acc : 0.812103\n",
      "[ ecpho : 3  iter :17 ]train loss : 0.286831 ,train acc: 0.866547 ,val loss : 0.405853 ,val acc : 0.817169\n",
      "[ ecpho : 3  iter :18 ]train loss : 0.422743 ,train acc: 0.786835 ,val loss : 0.411451 ,val acc : 0.818848\n",
      "[ ecpho : 3  iter :19 ]train loss : 0.405951 ,train acc: 0.830923 ,val loss : 0.408267 ,val acc : 0.816254\n",
      "[ ecpho : 3  iter :20 ]train loss : 0.285203 ,train acc: 0.860748 ,val loss : 0.413616 ,val acc : 0.813171\n",
      "[ ecpho : 3  iter :21 ]train loss : 0.360958 ,train acc: 0.751984 ,val loss : 0.411420 ,val acc : 0.816772\n",
      "[ ecpho : 3  iter :22 ]train loss : 0.303265 ,train acc: 0.855591 ,val loss : 0.409031 ,val acc : 0.814789\n",
      "[ ecpho : 3  iter :23 ]train loss : 0.340259 ,train acc: 0.848796 ,val loss : 0.409197 ,val acc : 0.816772\n",
      "[ ecpho : 3  iter :24 ]train loss : 0.278360 ,train acc: 0.867421 ,val loss : 0.400941 ,val acc : 0.820679\n",
      "[ ecpho : 3  iter :25 ]train loss : 0.397160 ,train acc: 0.834503 ,val loss : 0.404523 ,val acc : 0.816315\n",
      "[ ecpho : 3  iter :26 ]train loss : 0.324352 ,train acc: 0.835215 ,val loss : 0.410114 ,val acc : 0.818207\n",
      "[ ecpho : 3  iter :27 ]train loss : 0.295192 ,train acc: 0.855225 ,val loss : 0.411158 ,val acc : 0.818420\n",
      "[ ecpho : 3  iter :28 ]train loss : 0.305604 ,train acc: 0.860240 ,val loss : 0.407123 ,val acc : 0.820068\n",
      "[ ecpho : 3  iter :29 ]train loss : 0.391373 ,train acc: 0.789673 ,val loss : 0.402573 ,val acc : 0.822510\n",
      "[ ecpho : 3  iter :30 ]train loss : 0.385536 ,train acc: 0.835022 ,val loss : 0.413769 ,val acc : 0.815613\n",
      "[ ecpho : 3  iter :31 ]train loss : 0.287178 ,train acc: 0.860199 ,val loss : 0.408687 ,val acc : 0.816956\n",
      "[ ecpho : 3  iter :32 ]train loss : 0.408165 ,train acc: 0.786784 ,val loss : 0.404557 ,val acc : 0.818604\n",
      "[ ecpho : 3  iter :33 ]train loss : 0.394372 ,train acc: 0.796387 ,val loss : 0.407326 ,val acc : 0.818054\n",
      "[ ecpho : 3  iter :34 ]train loss : 0.365390 ,train acc: 0.837840 ,val loss : 0.409506 ,val acc : 0.817657\n",
      "[ ecpho : 3  iter :35 ]train loss : 0.321564 ,train acc: 0.844452 ,val loss : 0.410434 ,val acc : 0.814850\n",
      "[ ecpho : 3  iter :36 ]train loss : 0.404677 ,train acc: 0.830068 ,val loss : 0.411720 ,val acc : 0.816223\n",
      "[ ecpho : 3  iter :37 ]train loss : 0.395349 ,train acc: 0.828827 ,val loss : 0.412592 ,val acc : 0.814758\n",
      "[ ecpho : 3  iter :38 ]train loss : 0.341398 ,train acc: 0.848755 ,val loss : 0.409738 ,val acc : 0.821716\n",
      "[ ecpho : 3  iter :39 ]train loss : 0.312611 ,train acc: 0.857066 ,val loss : 0.409844 ,val acc : 0.815216\n",
      "[ ecpho : 3  iter :40 ]train loss : 0.281408 ,train acc: 0.864349 ,val loss : 0.408908 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :41 ]train loss : 0.300207 ,train acc: 0.856618 ,val loss : 0.407827 ,val acc : 0.818268\n",
      "[ ecpho : 3  iter :42 ]train loss : 0.451497 ,train acc: 0.756063 ,val loss : 0.409879 ,val acc : 0.816101\n",
      "[ ecpho : 3  iter :43 ]train loss : 0.348586 ,train acc: 0.841288 ,val loss : 0.407631 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :44 ]train loss : 0.351069 ,train acc: 0.845276 ,val loss : 0.415029 ,val acc : 0.815887\n",
      "[ ecpho : 3  iter :45 ]train loss : 0.313039 ,train acc: 0.846965 ,val loss : 0.411455 ,val acc : 0.816162\n",
      "[ ecpho : 3  iter :46 ]train loss : 0.322469 ,train acc: 0.851023 ,val loss : 0.411228 ,val acc : 0.817993\n",
      "[ ecpho : 3  iter :47 ]train loss : 0.394917 ,train acc: 0.835409 ,val loss : 0.404979 ,val acc : 0.816925\n",
      "[ ecpho : 3  iter :48 ]train loss : 0.320128 ,train acc: 0.845785 ,val loss : 0.407685 ,val acc : 0.816498\n",
      "[ ecpho : 3  iter :49 ]train loss : 0.345469 ,train acc: 0.844676 ,val loss : 0.408617 ,val acc : 0.816376\n",
      "[ ecpho : 3  iter :50 ]train loss : 0.359429 ,train acc: 0.846680 ,val loss : 0.404635 ,val acc : 0.819672\n",
      "[ ecpho : 3  iter :51 ]train loss : 0.481453 ,train acc: 0.764547 ,val loss : 0.409342 ,val acc : 0.815765\n",
      "[ ecpho : 3  iter :52 ]train loss : 0.414266 ,train acc: 0.801829 ,val loss : 0.411754 ,val acc : 0.817688\n",
      "[ ecpho : 3  iter :53 ]train loss : 0.282536 ,train acc: 0.863373 ,val loss : 0.409570 ,val acc : 0.814850\n",
      "[ ecpho : 3  iter :54 ]train loss : 0.299524 ,train acc: 0.859609 ,val loss : 0.406491 ,val acc : 0.817993\n",
      "[ ecpho : 3  iter :55 ]train loss : 0.339010 ,train acc: 0.852061 ,val loss : 0.409546 ,val acc : 0.816498\n",
      "[ ecpho : 3  iter :56 ]train loss : 0.281511 ,train acc: 0.867920 ,val loss : 0.406025 ,val acc : 0.817566\n",
      "[ ecpho : 3  iter :57 ]train loss : 0.338143 ,train acc: 0.824504 ,val loss : 0.409053 ,val acc : 0.817719\n",
      "[ ecpho : 3  iter :58 ]train loss : 0.397564 ,train acc: 0.831136 ,val loss : 0.407654 ,val acc : 0.819641\n",
      "[ ecpho : 3  iter :59 ]train loss : 0.365887 ,train acc: 0.844615 ,val loss : 0.409447 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :60 ]train loss : 0.321708 ,train acc: 0.853780 ,val loss : 0.410676 ,val acc : 0.817657\n",
      "[ ecpho : 3  iter :61 ]train loss : 0.445334 ,train acc: 0.803701 ,val loss : 0.407831 ,val acc : 0.814392\n",
      "[ ecpho : 3  iter :62 ]train loss : 0.443197 ,train acc: 0.802195 ,val loss : 0.410407 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :63 ]train loss : 0.397972 ,train acc: 0.833710 ,val loss : 0.412891 ,val acc : 0.814240\n",
      "[ ecpho : 3  iter :64 ]train loss : 0.357679 ,train acc: 0.836192 ,val loss : 0.407572 ,val acc : 0.817352\n",
      "[ ecpho : 3  iter :65 ]train loss : 0.416292 ,train acc: 0.793834 ,val loss : 0.414636 ,val acc : 0.816040\n",
      "[ ecpho : 3  iter :66 ]train loss : 0.299503 ,train acc: 0.858938 ,val loss : 0.405475 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :67 ]train loss : 0.360638 ,train acc: 0.843059 ,val loss : 0.409254 ,val acc : 0.815735\n",
      "[ ecpho : 3  iter :68 ]train loss : 0.293561 ,train acc: 0.861786 ,val loss : 0.407167 ,val acc : 0.816864\n",
      "[ ecpho : 3  iter :69 ]train loss : 0.345863 ,train acc: 0.840902 ,val loss : 0.405769 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :70 ]train loss : 0.351302 ,train acc: 0.822632 ,val loss : 0.409132 ,val acc : 0.815491\n",
      "[ ecpho : 3  iter :71 ]train loss : 0.403395 ,train acc: 0.803375 ,val loss : 0.405242 ,val acc : 0.819763\n",
      "[ ecpho : 3  iter :72 ]train loss : 0.293988 ,train acc: 0.861969 ,val loss : 0.411493 ,val acc : 0.816772\n",
      "[ ecpho : 3  iter :73 ]train loss : 0.317702 ,train acc: 0.846904 ,val loss : 0.414161 ,val acc : 0.814880\n",
      "[ ecpho : 3  iter :74 ]train loss : 0.306055 ,train acc: 0.853373 ,val loss : 0.409689 ,val acc : 0.814880\n",
      "[ ecpho : 3  iter :75 ]train loss : 0.359351 ,train acc: 0.828827 ,val loss : 0.408565 ,val acc : 0.815948\n",
      "[ ecpho : 3  iter :76 ]train loss : 0.311182 ,train acc: 0.851919 ,val loss : 0.406071 ,val acc : 0.820740\n",
      "[ ecpho : 3  iter :77 ]train loss : 0.296138 ,train acc: 0.860616 ,val loss : 0.409823 ,val acc : 0.814758\n",
      "[ ecpho : 3  iter :78 ]train loss : 0.343679 ,train acc: 0.855194 ,val loss : 0.407595 ,val acc : 0.816895\n",
      "[ ecpho : 3  iter :79 ]train loss : 0.335215 ,train acc: 0.851898 ,val loss : 0.411148 ,val acc : 0.817017\n",
      "[ ecpho : 3  iter :80 ]train loss : 0.312396 ,train acc: 0.855530 ,val loss : 0.409063 ,val acc : 0.818298\n",
      "[ ecpho : 3  iter :81 ]train loss : 0.411982 ,train acc: 0.827749 ,val loss : 0.408809 ,val acc : 0.816437\n",
      "[ ecpho : 3  iter :82 ]train loss : 0.419656 ,train acc: 0.818583 ,val loss : 0.410975 ,val acc : 0.816772\n",
      "[ ecpho : 3  iter :83 ]train loss : 0.462766 ,train acc: 0.796356 ,val loss : 0.407246 ,val acc : 0.818024\n",
      "[ ecpho : 3  iter :84 ]train loss : 0.332007 ,train acc: 0.843180 ,val loss : 0.402984 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :85 ]train loss : 0.376746 ,train acc: 0.838572 ,val loss : 0.405235 ,val acc : 0.814758\n",
      "[ ecpho : 3  iter :86 ]train loss : 0.263187 ,train acc: 0.873586 ,val loss : 0.407039 ,val acc : 0.816071\n",
      "[ ecpho : 3  iter :87 ]train loss : 0.312784 ,train acc: 0.848643 ,val loss : 0.413700 ,val acc : 0.814606\n",
      "[ ecpho : 3  iter :88 ]train loss : 0.301830 ,train acc: 0.859721 ,val loss : 0.409684 ,val acc : 0.815002\n",
      "[ ecpho : 3  iter :89 ]train loss : 0.354756 ,train acc: 0.843221 ,val loss : 0.404815 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :90 ]train loss : 0.279976 ,train acc: 0.863515 ,val loss : 0.412870 ,val acc : 0.814789\n",
      "[ ecpho : 3  iter :91 ]train loss : 0.323775 ,train acc: 0.852326 ,val loss : 0.404326 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :92 ]train loss : 0.395827 ,train acc: 0.833568 ,val loss : 0.409961 ,val acc : 0.816711\n",
      "[ ecpho : 3  iter :93 ]train loss : 0.287296 ,train acc: 0.864278 ,val loss : 0.404531 ,val acc : 0.818146\n",
      "[ ecpho : 3  iter :94 ]train loss : 0.351153 ,train acc: 0.846843 ,val loss : 0.404189 ,val acc : 0.817444\n",
      "[ ecpho : 3  iter :95 ]train loss : 0.460476 ,train acc: 0.833191 ,val loss : 0.411748 ,val acc : 0.814240\n",
      "[ ecpho : 3  iter :96 ]train loss : 0.378682 ,train acc: 0.806325 ,val loss : 0.406120 ,val acc : 0.815613\n",
      "[ ecpho : 3  iter :97 ]train loss : 0.269318 ,train acc: 0.866608 ,val loss : 0.407378 ,val acc : 0.815826\n",
      "[ ecpho : 3  iter :98 ]train loss : 0.300139 ,train acc: 0.853841 ,val loss : 0.407635 ,val acc : 0.817719\n",
      "[ ecpho : 3  iter :99 ]train loss : 0.303042 ,train acc: 0.856883 ,val loss : 0.407405 ,val acc : 0.817078\n",
      "[ ecpho : 3  iter :100 ]train loss : 0.342882 ,train acc: 0.833557 ,val loss : 0.402015 ,val acc : 0.818909\n",
      "[ ecpho : 3  iter :101 ]train loss : 0.292574 ,train acc: 0.862935 ,val loss : 0.405303 ,val acc : 0.816559\n",
      "[ ecpho : 3  iter :102 ]train loss : 0.277137 ,train acc: 0.868103 ,val loss : 0.411768 ,val acc : 0.817719\n",
      "[ ecpho : 3  iter :103 ]train loss : 0.287330 ,train acc: 0.859823 ,val loss : 0.406071 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :104 ]train loss : 0.387723 ,train acc: 0.809804 ,val loss : 0.405924 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :105 ]train loss : 0.424909 ,train acc: 0.804047 ,val loss : 0.409897 ,val acc : 0.814758\n",
      "[ ecpho : 3  iter :106 ]train loss : 0.290000 ,train acc: 0.862478 ,val loss : 0.409972 ,val acc : 0.816071\n",
      "[ ecpho : 3  iter :107 ]train loss : 0.313468 ,train acc: 0.851563 ,val loss : 0.412223 ,val acc : 0.814972\n",
      "[ ecpho : 3  iter :108 ]train loss : 0.363943 ,train acc: 0.838664 ,val loss : 0.411019 ,val acc : 0.814331\n",
      "[ ecpho : 3  iter :109 ]train loss : 0.313955 ,train acc: 0.843414 ,val loss : 0.408243 ,val acc : 0.815277\n",
      "[ ecpho : 3  iter :110 ]train loss : 0.386742 ,train acc: 0.834198 ,val loss : 0.408000 ,val acc : 0.816589\n",
      "[ ecpho : 3  iter :111 ]train loss : 0.408862 ,train acc: 0.722972 ,val loss : 0.409588 ,val acc : 0.816345\n",
      "[ ecpho : 3  iter :112 ]train loss : 0.260224 ,train acc: 0.872233 ,val loss : 0.411281 ,val acc : 0.815552\n",
      "[ ecpho : 3  iter :113 ]train loss : 0.339139 ,train acc: 0.852427 ,val loss : 0.406181 ,val acc : 0.819733\n",
      "[ ecpho : 3  iter :114 ]train loss : 0.358876 ,train acc: 0.808523 ,val loss : 0.406763 ,val acc : 0.815277\n",
      "[ ecpho : 3  iter :115 ]train loss : 0.368012 ,train acc: 0.843323 ,val loss : 0.404509 ,val acc : 0.820007\n",
      "[ ecpho : 3  iter :116 ]train loss : 0.324266 ,train acc: 0.847911 ,val loss : 0.410750 ,val acc : 0.816406\n",
      "[ ecpho : 3  iter :117 ]train loss : 0.305335 ,train acc: 0.846232 ,val loss : 0.412747 ,val acc : 0.814545\n",
      "[ ecpho : 3  iter :118 ]train loss : 0.364050 ,train acc: 0.832143 ,val loss : 0.413146 ,val acc : 0.818024\n",
      "[ ecpho : 3  iter :119 ]train loss : 0.329893 ,train acc: 0.850037 ,val loss : 0.407406 ,val acc : 0.814850\n",
      "[ ecpho : 3  iter :120 ]train loss : 0.327582 ,train acc: 0.825450 ,val loss : 0.409898 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :121 ]train loss : 0.274545 ,train acc: 0.867167 ,val loss : 0.409716 ,val acc : 0.817322\n",
      "[ ecpho : 3  iter :122 ]train loss : 0.406099 ,train acc: 0.838521 ,val loss : 0.407091 ,val acc : 0.818390\n",
      "[ ecpho : 3  iter :123 ]train loss : 0.320304 ,train acc: 0.851054 ,val loss : 0.403649 ,val acc : 0.817963\n",
      "[ ecpho : 3  iter :124 ]train loss : 0.327674 ,train acc: 0.851685 ,val loss : 0.402141 ,val acc : 0.817505\n",
      "[ ecpho : 3  iter :125 ]train loss : 0.290506 ,train acc: 0.864299 ,val loss : 0.402397 ,val acc : 0.818085\n",
      "[ ecpho : 3  iter :126 ]train loss : 0.320882 ,train acc: 0.854675 ,val loss : 0.402245 ,val acc : 0.817871\n",
      "[ ecpho : 3  iter :127 ]train loss : 0.415256 ,train acc: 0.846975 ,val loss : 0.407448 ,val acc : 0.817291\n",
      "[ ecpho : 3  iter :128 ]train loss : 0.431667 ,train acc: 0.827556 ,val loss : 0.409118 ,val acc : 0.816010\n",
      "[ ecpho : 3  iter :129 ]train loss : 0.266473 ,train acc: 0.872294 ,val loss : 0.406413 ,val acc : 0.813324\n",
      "[ ecpho : 3  iter :130 ]train loss : 0.355346 ,train acc: 0.852102 ,val loss : 0.408170 ,val acc : 0.819000\n",
      "[ ecpho : 3  iter :131 ]train loss : 0.364258 ,train acc: 0.841665 ,val loss : 0.402112 ,val acc : 0.816498\n",
      "[ ecpho : 3  iter :132 ]train loss : 0.289023 ,train acc: 0.862142 ,val loss : 0.410014 ,val acc : 0.816742\n",
      "[ ecpho : 3  iter :133 ]train loss : 0.409398 ,train acc: 0.825918 ,val loss : 0.407137 ,val acc : 0.821045\n",
      "[ ecpho : 3  iter :134 ]train loss : 0.421146 ,train acc: 0.826040 ,val loss : 0.409121 ,val acc : 0.818207\n",
      "[ ecpho : 3  iter :135 ]train loss : 0.420151 ,train acc: 0.777018 ,val loss : 0.404337 ,val acc : 0.817047\n",
      "[ ecpho : 3  iter :136 ]train loss : 0.275166 ,train acc: 0.861694 ,val loss : 0.404022 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :137 ]train loss : 0.258350 ,train acc: 0.874319 ,val loss : 0.411472 ,val acc : 0.815094\n",
      "[ ecpho : 3  iter :138 ]train loss : 0.441163 ,train acc: 0.773784 ,val loss : 0.407321 ,val acc : 0.820068\n",
      "[ ecpho : 3  iter :139 ]train loss : 0.273097 ,train acc: 0.868632 ,val loss : 0.402766 ,val acc : 0.815704\n",
      "[ ecpho : 3  iter :140 ]train loss : 0.294058 ,train acc: 0.856903 ,val loss : 0.405710 ,val acc : 0.815491\n",
      "[ ecpho : 3  iter :141 ]train loss : 0.337567 ,train acc: 0.819041 ,val loss : 0.405413 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :142 ]train loss : 0.430207 ,train acc: 0.822418 ,val loss : 0.407481 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :143 ]train loss : 0.357950 ,train acc: 0.841980 ,val loss : 0.415239 ,val acc : 0.814362\n",
      "[ ecpho : 3  iter :144 ]train loss : 0.426673 ,train acc: 0.833639 ,val loss : 0.413350 ,val acc : 0.815033\n",
      "[ ecpho : 3  iter :145 ]train loss : 0.265454 ,train acc: 0.869161 ,val loss : 0.405901 ,val acc : 0.815277\n",
      "[ ecpho : 3  iter :146 ]train loss : 0.370757 ,train acc: 0.848104 ,val loss : 0.408090 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :147 ]train loss : 0.401721 ,train acc: 0.831970 ,val loss : 0.411277 ,val acc : 0.816864\n",
      "[ ecpho : 3  iter :148 ]train loss : 0.296680 ,train acc: 0.863271 ,val loss : 0.404316 ,val acc : 0.818665\n",
      "[ ecpho : 3  iter :149 ]train loss : 0.327178 ,train acc: 0.842875 ,val loss : 0.408651 ,val acc : 0.817780\n",
      "[ ecpho : 3  iter :150 ]train loss : 0.414474 ,train acc: 0.829031 ,val loss : 0.405424 ,val acc : 0.817841\n",
      "[ ecpho : 3  iter :151 ]train loss : 0.378271 ,train acc: 0.821218 ,val loss : 0.405729 ,val acc : 0.816986\n",
      "[ ecpho : 3  iter :152 ]train loss : 0.329538 ,train acc: 0.841655 ,val loss : 0.413318 ,val acc : 0.816406\n",
      "[ ecpho : 3  iter :153 ]train loss : 0.350003 ,train acc: 0.842713 ,val loss : 0.405640 ,val acc : 0.815430\n",
      "[ ecpho : 3  iter :154 ]train loss : 0.317976 ,train acc: 0.856272 ,val loss : 0.406384 ,val acc : 0.816193\n",
      "[ ecpho : 3  iter :155 ]train loss : 0.348101 ,train acc: 0.840719 ,val loss : 0.412753 ,val acc : 0.816681\n",
      "[ ecpho : 3  iter :156 ]train loss : 0.413868 ,train acc: 0.827494 ,val loss : 0.413864 ,val acc : 0.815796\n",
      "[ ecpho : 3  iter :157 ]train loss : 0.308478 ,train acc: 0.860077 ,val loss : 0.405368 ,val acc : 0.818695\n",
      "[ ecpho : 3  iter :158 ]train loss : 0.344254 ,train acc: 0.841472 ,val loss : 0.401513 ,val acc : 0.817108\n",
      "[ ecpho : 3  iter :159 ]train loss : 0.312989 ,train acc: 0.842651 ,val loss : 0.408946 ,val acc : 0.815826\n",
      "[ ecpho : 3  iter :160 ]train loss : 0.351415 ,train acc: 0.846273 ,val loss : 0.405226 ,val acc : 0.819733\n",
      "[ ecpho : 3  iter :161 ]train loss : 0.408783 ,train acc: 0.819234 ,val loss : 0.405976 ,val acc : 0.818817\n",
      "[ ecpho : 3  iter :162 ]train loss : 0.274323 ,train acc: 0.865468 ,val loss : 0.407659 ,val acc : 0.816956\n",
      "[ ecpho : 3  iter :163 ]train loss : 0.415180 ,train acc: 0.825592 ,val loss : 0.406848 ,val acc : 0.820831\n",
      "[ ecpho : 3  iter :164 ]train loss : 0.300292 ,train acc: 0.851054 ,val loss : 0.411391 ,val acc : 0.815979\n",
      "[ ecpho : 3  iter :165 ]train loss : 0.359246 ,train acc: 0.842692 ,val loss : 0.406479 ,val acc : 0.820007\n",
      "[ ecpho : 3  iter :166 ]train loss : 0.450051 ,train acc: 0.793356 ,val loss : 0.408954 ,val acc : 0.816711\n",
      "[ ecpho : 3  iter :167 ]train loss : 0.252750 ,train acc: 0.876811 ,val loss : 0.410109 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :168 ]train loss : 0.436587 ,train acc: 0.767466 ,val loss : 0.409568 ,val acc : 0.816437\n",
      "[ ecpho : 3  iter :169 ]train loss : 0.355241 ,train acc: 0.840271 ,val loss : 0.409117 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :170 ]train loss : 0.259360 ,train acc: 0.874298 ,val loss : 0.409254 ,val acc : 0.815674\n",
      "[ ecpho : 3  iter :171 ]train loss : 0.300782 ,train acc: 0.852743 ,val loss : 0.402526 ,val acc : 0.819122\n",
      "[ ecpho : 3  iter :172 ]train loss : 0.339701 ,train acc: 0.850322 ,val loss : 0.409359 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :173 ]train loss : 0.307277 ,train acc: 0.850505 ,val loss : 0.403819 ,val acc : 0.818787\n",
      "[ ecpho : 3  iter :174 ]train loss : 0.281280 ,train acc: 0.864655 ,val loss : 0.408797 ,val acc : 0.818085\n",
      "[ ecpho : 3  iter :175 ]train loss : 0.321972 ,train acc: 0.854533 ,val loss : 0.411436 ,val acc : 0.815979\n",
      "[ ecpho : 3  iter :176 ]train loss : 0.390308 ,train acc: 0.791758 ,val loss : 0.407205 ,val acc : 0.817505\n",
      "[ ecpho : 3  iter :177 ]train loss : 0.391509 ,train acc: 0.834595 ,val loss : 0.404570 ,val acc : 0.818085\n",
      "[ ecpho : 3  iter :178 ]train loss : 0.387091 ,train acc: 0.778554 ,val loss : 0.404027 ,val acc : 0.817963\n",
      "[ ecpho : 3  iter :179 ]train loss : 0.299639 ,train acc: 0.856079 ,val loss : 0.405918 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :180 ]train loss : 0.256440 ,train acc: 0.878377 ,val loss : 0.410810 ,val acc : 0.816589\n",
      "[ ecpho : 3  iter :181 ]train loss : 0.388414 ,train acc: 0.831096 ,val loss : 0.405562 ,val acc : 0.816711\n",
      "[ ecpho : 3  iter :182 ]train loss : 0.269247 ,train acc: 0.868144 ,val loss : 0.405873 ,val acc : 0.820312\n",
      "[ ecpho : 3  iter :183 ]train loss : 0.279623 ,train acc: 0.862763 ,val loss : 0.410117 ,val acc : 0.815796\n",
      "[ ecpho : 3  iter :184 ]train loss : 0.332617 ,train acc: 0.847799 ,val loss : 0.405832 ,val acc : 0.818451\n",
      "[ ecpho : 3  iter :185 ]train loss : 0.301699 ,train acc: 0.855683 ,val loss : 0.401579 ,val acc : 0.820801\n",
      "[ ecpho : 3  iter :186 ]train loss : 0.282856 ,train acc: 0.865021 ,val loss : 0.403115 ,val acc : 0.820435\n",
      "[ ecpho : 3  iter :187 ]train loss : 0.327073 ,train acc: 0.849874 ,val loss : 0.400572 ,val acc : 0.818726\n",
      "[ ecpho : 3  iter :188 ]train loss : 0.308444 ,train acc: 0.856405 ,val loss : 0.407511 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :189 ]train loss : 0.326402 ,train acc: 0.854981 ,val loss : 0.407831 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :190 ]train loss : 0.269901 ,train acc: 0.870951 ,val loss : 0.409061 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :191 ]train loss : 0.625756 ,train acc: 0.802134 ,val loss : 0.410147 ,val acc : 0.818970\n",
      "[ ecpho : 3  iter :192 ]train loss : 0.529205 ,train acc: 0.750733 ,val loss : 0.402746 ,val acc : 0.818542\n",
      "[ ecpho : 3  iter :193 ]train loss : 0.297430 ,train acc: 0.859874 ,val loss : 0.402538 ,val acc : 0.819336\n",
      "[ ecpho : 3  iter :194 ]train loss : 0.393759 ,train acc: 0.786143 ,val loss : 0.410751 ,val acc : 0.814148\n",
      "[ ecpho : 3  iter :195 ]train loss : 0.326348 ,train acc: 0.851685 ,val loss : 0.406480 ,val acc : 0.817139\n",
      "[ ecpho : 3  iter :196 ]train loss : 0.449673 ,train acc: 0.760112 ,val loss : 0.408564 ,val acc : 0.815399\n",
      "[ ecpho : 3  iter :197 ]train loss : 0.396724 ,train acc: 0.824656 ,val loss : 0.403236 ,val acc : 0.819336\n",
      "[ ecpho : 3  iter :198 ]train loss : 0.285965 ,train acc: 0.862976 ,val loss : 0.407919 ,val acc : 0.816772\n",
      "[ ecpho : 3  iter :199 ]train loss : 0.407977 ,train acc: 0.815918 ,val loss : 0.400957 ,val acc : 0.821014\n",
      "[ ecpho : 3  iter :200 ]train loss : 0.322417 ,train acc: 0.851430 ,val loss : 0.414583 ,val acc : 0.819397\n",
      "[ ecpho : 3  iter :201 ]train loss : 0.316736 ,train acc: 0.841390 ,val loss : 0.403453 ,val acc : 0.820465\n",
      "[ ecpho : 3  iter :202 ]train loss : 0.323225 ,train acc: 0.848358 ,val loss : 0.412452 ,val acc : 0.815735\n",
      "[ ecpho : 3  iter :203 ]train loss : 0.303314 ,train acc: 0.860748 ,val loss : 0.404181 ,val acc : 0.818665\n",
      "[ ecpho : 3  iter :204 ]train loss : 0.286611 ,train acc: 0.857829 ,val loss : 0.407454 ,val acc : 0.817627\n",
      "[ ecpho : 3  iter :205 ]train loss : 0.353948 ,train acc: 0.852885 ,val loss : 0.405401 ,val acc : 0.818665\n",
      "[ ecpho : 3  iter :206 ]train loss : 0.334122 ,train acc: 0.840342 ,val loss : 0.406299 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :207 ]train loss : 0.380002 ,train acc: 0.831909 ,val loss : 0.403102 ,val acc : 0.823883\n",
      "[ ecpho : 3  iter :208 ]train loss : 0.300560 ,train acc: 0.863526 ,val loss : 0.408937 ,val acc : 0.815125\n",
      "[ ecpho : 3  iter :209 ]train loss : 0.343351 ,train acc: 0.817393 ,val loss : 0.404995 ,val acc : 0.816376\n",
      "[ ecpho : 3  iter :210 ]train loss : 0.353163 ,train acc: 0.839335 ,val loss : 0.403502 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :211 ]train loss : 0.398029 ,train acc: 0.822815 ,val loss : 0.407879 ,val acc : 0.816437\n",
      "[ ecpho : 3  iter :212 ]train loss : 0.408058 ,train acc: 0.806173 ,val loss : 0.403125 ,val acc : 0.819366\n",
      "[ ecpho : 3  iter :213 ]train loss : 0.340750 ,train acc: 0.843374 ,val loss : 0.410844 ,val acc : 0.816315\n",
      "[ ecpho : 3  iter :214 ]train loss : 0.313012 ,train acc: 0.855428 ,val loss : 0.405344 ,val acc : 0.816345\n",
      "[ ecpho : 3  iter :215 ]train loss : 0.436843 ,train acc: 0.777029 ,val loss : 0.402668 ,val acc : 0.816803\n",
      "[ ecpho : 3  iter :216 ]train loss : 0.296007 ,train acc: 0.858917 ,val loss : 0.405873 ,val acc : 0.817352\n",
      "[ ecpho : 3  iter :217 ]train loss : 0.321271 ,train acc: 0.858063 ,val loss : 0.404582 ,val acc : 0.816864\n",
      "[ ecpho : 3  iter :218 ]train loss : 0.359749 ,train acc: 0.799805 ,val loss : 0.411743 ,val acc : 0.814850\n",
      "[ ecpho : 3  iter :219 ]train loss : 0.298530 ,train acc: 0.863993 ,val loss : 0.402661 ,val acc : 0.816864\n",
      "[ ecpho : 3  iter :220 ]train loss : 0.279194 ,train acc: 0.865601 ,val loss : 0.410508 ,val acc : 0.815491\n",
      "[ ecpho : 3  iter :221 ]train loss : 0.513371 ,train acc: 0.760539 ,val loss : 0.404036 ,val acc : 0.819702\n",
      "[ ecpho : 3  iter :222 ]train loss : 0.329061 ,train acc: 0.845195 ,val loss : 0.405226 ,val acc : 0.820251\n",
      "[ ecpho : 3  iter :223 ]train loss : 0.333504 ,train acc: 0.855133 ,val loss : 0.400525 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :224 ]train loss : 0.292459 ,train acc: 0.864807 ,val loss : 0.403458 ,val acc : 0.821228\n",
      "[ ecpho : 3  iter :225 ]train loss : 0.438159 ,train acc: 0.748444 ,val loss : 0.410781 ,val acc : 0.814026\n",
      "[ ecpho : 3  iter :226 ]train loss : 0.351311 ,train acc: 0.850901 ,val loss : 0.407167 ,val acc : 0.817078\n",
      "[ ecpho : 3  iter :227 ]train loss : 0.365538 ,train acc: 0.847300 ,val loss : 0.406187 ,val acc : 0.816650\n",
      "[ ecpho : 3  iter :228 ]train loss : 0.311654 ,train acc: 0.847585 ,val loss : 0.409904 ,val acc : 0.821106\n",
      "[ ecpho : 3  iter :229 ]train loss : 0.401923 ,train acc: 0.835551 ,val loss : 0.401490 ,val acc : 0.818909\n",
      "[ ecpho : 3  iter :230 ]train loss : 0.399838 ,train acc: 0.831492 ,val loss : 0.408620 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :231 ]train loss : 0.279719 ,train acc: 0.863363 ,val loss : 0.403731 ,val acc : 0.820343\n",
      "[ ecpho : 3  iter :232 ]train loss : 0.345007 ,train acc: 0.844035 ,val loss : 0.400307 ,val acc : 0.818573\n",
      "[ ecpho : 3  iter :233 ]train loss : 0.309852 ,train acc: 0.850657 ,val loss : 0.404391 ,val acc : 0.819244\n",
      "[ ecpho : 3  iter :234 ]train loss : 0.348337 ,train acc: 0.842713 ,val loss : 0.405084 ,val acc : 0.821350\n",
      "[ ecpho : 3  iter :235 ]train loss : 0.294698 ,train acc: 0.859955 ,val loss : 0.400333 ,val acc : 0.821411\n",
      "[ ecpho : 3  iter :236 ]train loss : 0.257646 ,train acc: 0.877055 ,val loss : 0.411644 ,val acc : 0.818207\n",
      "[ ecpho : 3  iter :237 ]train loss : 0.339748 ,train acc: 0.853272 ,val loss : 0.399942 ,val acc : 0.820984\n",
      "[ ecpho : 3  iter :238 ]train loss : 0.328053 ,train acc: 0.835175 ,val loss : 0.403133 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :239 ]train loss : 0.265917 ,train acc: 0.871562 ,val loss : 0.407881 ,val acc : 0.817383\n",
      "[ ecpho : 3  iter :240 ]train loss : 0.334852 ,train acc: 0.852855 ,val loss : 0.411537 ,val acc : 0.816559\n",
      "[ ecpho : 3  iter :241 ]train loss : 0.453858 ,train acc: 0.836680 ,val loss : 0.405858 ,val acc : 0.816406\n",
      "[ ecpho : 3  iter :242 ]train loss : 0.284393 ,train acc: 0.868663 ,val loss : 0.402382 ,val acc : 0.821442\n",
      "[ ecpho : 3  iter :243 ]train loss : 0.373080 ,train acc: 0.840658 ,val loss : 0.403828 ,val acc : 0.818817\n",
      "[ ecpho : 3  iter :244 ]train loss : 0.285110 ,train acc: 0.865529 ,val loss : 0.403494 ,val acc : 0.816895\n",
      "[ ecpho : 3  iter :245 ]train loss : 0.275359 ,train acc: 0.864350 ,val loss : 0.411566 ,val acc : 0.813354\n",
      "[ ecpho : 3  iter :246 ]train loss : 0.291770 ,train acc: 0.863129 ,val loss : 0.405064 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :247 ]train loss : 0.313222 ,train acc: 0.857127 ,val loss : 0.405307 ,val acc : 0.817596\n",
      "[ ecpho : 3  iter :248 ]train loss : 0.319723 ,train acc: 0.853516 ,val loss : 0.403759 ,val acc : 0.820221\n",
      "[ ecpho : 3  iter :249 ]train loss : 0.455999 ,train acc: 0.792216 ,val loss : 0.406678 ,val acc : 0.817108\n",
      "[ ecpho : 3  iter :250 ]train loss : 0.306911 ,train acc: 0.862132 ,val loss : 0.399755 ,val acc : 0.820404\n",
      "[ ecpho : 3  iter :251 ]train loss : 0.445311 ,train acc: 0.797750 ,val loss : 0.408993 ,val acc : 0.815552\n",
      "[ ecpho : 3  iter :252 ]train loss : 0.306284 ,train acc: 0.861654 ,val loss : 0.405947 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :253 ]train loss : 0.454966 ,train acc: 0.815959 ,val loss : 0.409937 ,val acc : 0.817688\n",
      "[ ecpho : 3  iter :254 ]train loss : 0.361465 ,train acc: 0.837982 ,val loss : 0.410200 ,val acc : 0.816406\n",
      "[ ecpho : 3  iter :255 ]train loss : 0.359906 ,train acc: 0.839630 ,val loss : 0.408731 ,val acc : 0.818939\n",
      "[ ecpho : 3  iter :256 ]train loss : 0.263908 ,train acc: 0.873261 ,val loss : 0.404748 ,val acc : 0.818451\n",
      "[ ecpho : 3  iter :257 ]train loss : 0.345207 ,train acc: 0.848592 ,val loss : 0.399948 ,val acc : 0.818970\n",
      "[ ecpho : 3  iter :258 ]train loss : 0.265911 ,train acc: 0.869324 ,val loss : 0.402668 ,val acc : 0.817169\n",
      "[ ecpho : 3  iter :259 ]train loss : 0.350221 ,train acc: 0.844279 ,val loss : 0.405426 ,val acc : 0.817993\n",
      "[ ecpho : 3  iter :260 ]train loss : 0.359207 ,train acc: 0.851410 ,val loss : 0.402414 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :261 ]train loss : 0.374559 ,train acc: 0.841665 ,val loss : 0.405323 ,val acc : 0.819855\n",
      "[ ecpho : 3  iter :262 ]train loss : 0.343131 ,train acc: 0.829143 ,val loss : 0.405095 ,val acc : 0.820770\n",
      "[ ecpho : 3  iter :263 ]train loss : 0.340746 ,train acc: 0.846548 ,val loss : 0.404662 ,val acc : 0.818787\n",
      "[ ecpho : 3  iter :264 ]train loss : 0.398255 ,train acc: 0.836009 ,val loss : 0.405780 ,val acc : 0.818237\n",
      "[ ecpho : 3  iter :265 ]train loss : 0.314421 ,train acc: 0.854726 ,val loss : 0.403624 ,val acc : 0.818695\n",
      "[ ecpho : 3  iter :266 ]train loss : 0.284448 ,train acc: 0.860870 ,val loss : 0.405775 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :267 ]train loss : 0.335052 ,train acc: 0.825755 ,val loss : 0.410716 ,val acc : 0.813995\n",
      "[ ecpho : 3  iter :268 ]train loss : 0.305479 ,train acc: 0.853740 ,val loss : 0.404572 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :269 ]train loss : 0.472453 ,train acc: 0.822836 ,val loss : 0.399637 ,val acc : 0.818237\n",
      "[ ecpho : 3  iter :270 ]train loss : 0.369329 ,train acc: 0.835297 ,val loss : 0.405457 ,val acc : 0.816711\n",
      "[ ecpho : 3  iter :271 ]train loss : 0.380510 ,train acc: 0.830658 ,val loss : 0.404577 ,val acc : 0.816315\n",
      "[ ecpho : 3  iter :272 ]train loss : 0.338771 ,train acc: 0.829600 ,val loss : 0.402315 ,val acc : 0.820801\n",
      "[ ecpho : 3  iter :273 ]train loss : 0.349118 ,train acc: 0.837291 ,val loss : 0.406536 ,val acc : 0.818390\n",
      "[ ecpho : 3  iter :274 ]train loss : 0.517845 ,train acc: 0.725973 ,val loss : 0.403546 ,val acc : 0.814331\n",
      "[ ecpho : 3  iter :275 ]train loss : 0.285940 ,train acc: 0.866953 ,val loss : 0.403129 ,val acc : 0.820160\n",
      "[ ecpho : 3  iter :276 ]train loss : 0.330137 ,train acc: 0.819478 ,val loss : 0.410405 ,val acc : 0.816681\n",
      "[ ecpho : 3  iter :277 ]train loss : 0.259760 ,train acc: 0.870382 ,val loss : 0.401879 ,val acc : 0.819763\n",
      "[ ecpho : 3  iter :278 ]train loss : 0.358218 ,train acc: 0.844951 ,val loss : 0.407255 ,val acc : 0.817688\n",
      "[ ecpho : 3  iter :279 ]train loss : 0.352534 ,train acc: 0.843750 ,val loss : 0.409625 ,val acc : 0.817627\n",
      "[ ecpho : 3  iter :280 ]train loss : 0.288567 ,train acc: 0.857595 ,val loss : 0.401773 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :281 ]train loss : 0.390162 ,train acc: 0.831869 ,val loss : 0.408469 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :282 ]train loss : 0.288297 ,train acc: 0.858612 ,val loss : 0.401702 ,val acc : 0.818726\n",
      "[ ecpho : 3  iter :283 ]train loss : 0.306933 ,train acc: 0.856242 ,val loss : 0.410778 ,val acc : 0.816803\n",
      "[ ecpho : 3  iter :284 ]train loss : 0.290237 ,train acc: 0.864034 ,val loss : 0.409514 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :285 ]train loss : 0.402111 ,train acc: 0.827321 ,val loss : 0.399679 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :286 ]train loss : 0.297425 ,train acc: 0.858968 ,val loss : 0.400673 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :287 ]train loss : 0.261820 ,train acc: 0.873729 ,val loss : 0.401633 ,val acc : 0.816925\n",
      "[ ecpho : 3  iter :288 ]train loss : 0.328187 ,train acc: 0.846629 ,val loss : 0.410833 ,val acc : 0.818817\n",
      "[ ecpho : 3  iter :289 ]train loss : 0.264951 ,train acc: 0.869904 ,val loss : 0.407366 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :290 ]train loss : 0.336332 ,train acc: 0.855143 ,val loss : 0.404716 ,val acc : 0.821014\n",
      "[ ecpho : 3  iter :291 ]train loss : 0.254993 ,train acc: 0.876211 ,val loss : 0.408998 ,val acc : 0.818146\n",
      "[ ecpho : 3  iter :292 ]train loss : 0.313747 ,train acc: 0.854218 ,val loss : 0.403887 ,val acc : 0.820190\n",
      "[ ecpho : 3  iter :293 ]train loss : 0.323115 ,train acc: 0.850871 ,val loss : 0.402267 ,val acc : 0.818359\n",
      "[ ecpho : 3  iter :294 ]train loss : 0.317744 ,train acc: 0.854919 ,val loss : 0.408431 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :295 ]train loss : 0.272990 ,train acc: 0.871908 ,val loss : 0.411286 ,val acc : 0.815491\n",
      "[ ecpho : 3  iter :296 ]train loss : 0.563999 ,train acc: 0.727244 ,val loss : 0.406354 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :297 ]train loss : 0.271767 ,train acc: 0.865855 ,val loss : 0.409156 ,val acc : 0.816833\n",
      "[ ecpho : 3  iter :298 ]train loss : 0.286369 ,train acc: 0.865407 ,val loss : 0.406214 ,val acc : 0.817596\n",
      "[ ecpho : 3  iter :299 ]train loss : 0.348879 ,train acc: 0.845825 ,val loss : 0.407564 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :300 ]train loss : 0.277771 ,train acc: 0.861115 ,val loss : 0.406046 ,val acc : 0.817474\n",
      "[ ecpho : 3  iter :301 ]train loss : 0.266873 ,train acc: 0.872813 ,val loss : 0.408501 ,val acc : 0.817474\n",
      "[ ecpho : 3  iter :302 ]train loss : 0.591521 ,train acc: 0.744578 ,val loss : 0.405083 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :303 ]train loss : 0.407891 ,train acc: 0.798584 ,val loss : 0.410379 ,val acc : 0.816193\n",
      "[ ecpho : 3  iter :304 ]train loss : 0.351007 ,train acc: 0.848002 ,val loss : 0.412774 ,val acc : 0.815552\n",
      "[ ecpho : 3  iter :305 ]train loss : 0.395470 ,train acc: 0.835958 ,val loss : 0.409276 ,val acc : 0.818817\n",
      "[ ecpho : 3  iter :306 ]train loss : 0.429594 ,train acc: 0.838776 ,val loss : 0.406522 ,val acc : 0.817474\n",
      "[ ecpho : 3  iter :307 ]train loss : 0.270990 ,train acc: 0.868276 ,val loss : 0.408943 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :308 ]train loss : 0.400137 ,train acc: 0.822093 ,val loss : 0.410214 ,val acc : 0.820221\n",
      "[ ecpho : 3  iter :309 ]train loss : 0.331023 ,train acc: 0.836192 ,val loss : 0.409051 ,val acc : 0.816071\n",
      "[ ecpho : 3  iter :310 ]train loss : 0.258086 ,train acc: 0.871908 ,val loss : 0.402812 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :311 ]train loss : 0.304029 ,train acc: 0.859110 ,val loss : 0.408886 ,val acc : 0.815277\n",
      "[ ecpho : 3  iter :312 ]train loss : 0.280949 ,train acc: 0.862122 ,val loss : 0.405864 ,val acc : 0.819031\n",
      "[ ecpho : 3  iter :313 ]train loss : 0.326812 ,train acc: 0.843648 ,val loss : 0.409926 ,val acc : 0.817291\n",
      "[ ecpho : 3  iter :314 ]train loss : 0.264252 ,train acc: 0.870504 ,val loss : 0.403170 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :315 ]train loss : 0.376999 ,train acc: 0.816549 ,val loss : 0.396863 ,val acc : 0.822418\n",
      "[ ecpho : 3  iter :316 ]train loss : 0.389104 ,train acc: 0.817597 ,val loss : 0.401524 ,val acc : 0.819733\n",
      "[ ecpho : 3  iter :317 ]train loss : 0.275273 ,train acc: 0.870911 ,val loss : 0.401752 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :318 ]train loss : 0.340368 ,train acc: 0.844188 ,val loss : 0.398640 ,val acc : 0.822601\n",
      "[ ecpho : 3  iter :319 ]train loss : 0.254626 ,train acc: 0.875193 ,val loss : 0.403682 ,val acc : 0.815430\n",
      "[ ecpho : 3  iter :320 ]train loss : 0.300012 ,train acc: 0.849223 ,val loss : 0.409566 ,val acc : 0.820007\n",
      "[ ecpho : 3  iter :321 ]train loss : 0.399685 ,train acc: 0.835195 ,val loss : 0.400388 ,val acc : 0.818604\n",
      "[ ecpho : 3  iter :322 ]train loss : 0.352134 ,train acc: 0.814616 ,val loss : 0.409660 ,val acc : 0.817383\n",
      "[ ecpho : 3  iter :323 ]train loss : 0.366567 ,train acc: 0.823558 ,val loss : 0.398642 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :324 ]train loss : 0.391705 ,train acc: 0.801819 ,val loss : 0.402413 ,val acc : 0.815186\n",
      "[ ecpho : 3  iter :325 ]train loss : 0.372011 ,train acc: 0.844208 ,val loss : 0.403668 ,val acc : 0.817444\n",
      "[ ecpho : 3  iter :326 ]train loss : 0.423870 ,train acc: 0.827769 ,val loss : 0.403783 ,val acc : 0.817688\n",
      "[ ecpho : 3  iter :327 ]train loss : 0.296078 ,train acc: 0.851878 ,val loss : 0.407781 ,val acc : 0.816528\n",
      "[ ecpho : 3  iter :328 ]train loss : 0.269727 ,train acc: 0.870870 ,val loss : 0.405078 ,val acc : 0.820770\n",
      "[ ecpho : 3  iter :329 ]train loss : 0.284393 ,train acc: 0.866455 ,val loss : 0.402612 ,val acc : 0.816498\n",
      "[ ecpho : 3  iter :330 ]train loss : 0.344706 ,train acc: 0.840190 ,val loss : 0.403659 ,val acc : 0.821167\n",
      "[ ecpho : 3  iter :331 ]train loss : 0.343731 ,train acc: 0.827657 ,val loss : 0.401480 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :332 ]train loss : 0.364636 ,train acc: 0.816844 ,val loss : 0.403995 ,val acc : 0.817200\n",
      "[ ecpho : 3  iter :333 ]train loss : 0.315045 ,train acc: 0.843699 ,val loss : 0.408813 ,val acc : 0.815796\n",
      "[ ecpho : 3  iter :334 ]train loss : 0.288492 ,train acc: 0.863180 ,val loss : 0.403506 ,val acc : 0.818787\n",
      "[ ecpho : 3  iter :335 ]train loss : 0.384295 ,train acc: 0.841716 ,val loss : 0.405035 ,val acc : 0.817719\n",
      "[ ecpho : 3  iter :336 ]train loss : 0.336947 ,train acc: 0.849081 ,val loss : 0.400648 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :337 ]train loss : 0.262946 ,train acc: 0.870931 ,val loss : 0.408860 ,val acc : 0.817352\n",
      "[ ecpho : 3  iter :338 ]train loss : 0.448674 ,train acc: 0.789846 ,val loss : 0.408264 ,val acc : 0.818298\n",
      "[ ecpho : 3  iter :339 ]train loss : 0.387120 ,train acc: 0.832184 ,val loss : 0.402615 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :340 ]train loss : 0.292863 ,train acc: 0.865662 ,val loss : 0.403020 ,val acc : 0.819885\n",
      "[ ecpho : 3  iter :341 ]train loss : 0.302348 ,train acc: 0.858144 ,val loss : 0.403617 ,val acc : 0.818695\n",
      "[ ecpho : 3  iter :342 ]train loss : 0.383047 ,train acc: 0.832408 ,val loss : 0.402026 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :343 ]train loss : 0.273451 ,train acc: 0.862508 ,val loss : 0.407733 ,val acc : 0.817871\n",
      "[ ecpho : 3  iter :344 ]train loss : 0.395673 ,train acc: 0.805379 ,val loss : 0.409571 ,val acc : 0.815216\n",
      "[ ecpho : 3  iter :345 ]train loss : 0.273148 ,train acc: 0.866801 ,val loss : 0.409309 ,val acc : 0.815491\n",
      "[ ecpho : 3  iter :346 ]train loss : 0.515814 ,train acc: 0.822663 ,val loss : 0.404461 ,val acc : 0.818817\n",
      "[ ecpho : 3  iter :347 ]train loss : 0.281107 ,train acc: 0.866384 ,val loss : 0.409166 ,val acc : 0.815887\n",
      "[ ecpho : 3  iter :348 ]train loss : 0.326176 ,train acc: 0.849538 ,val loss : 0.406732 ,val acc : 0.820312\n",
      "[ ecpho : 3  iter :349 ]train loss : 0.305823 ,train acc: 0.856710 ,val loss : 0.399532 ,val acc : 0.820160\n",
      "[ ecpho : 3  iter :350 ]train loss : 0.296880 ,train acc: 0.856944 ,val loss : 0.406953 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :351 ]train loss : 0.273015 ,train acc: 0.866964 ,val loss : 0.410498 ,val acc : 0.816589\n",
      "[ ecpho : 3  iter :352 ]train loss : 0.288056 ,train acc: 0.868337 ,val loss : 0.405296 ,val acc : 0.819366\n",
      "[ ecpho : 3  iter :353 ]train loss : 0.373588 ,train acc: 0.827881 ,val loss : 0.397085 ,val acc : 0.818787\n",
      "[ ecpho : 3  iter :354 ]train loss : 0.302913 ,train acc: 0.860402 ,val loss : 0.398551 ,val acc : 0.820740\n",
      "[ ecpho : 3  iter :355 ]train loss : 0.304224 ,train acc: 0.861593 ,val loss : 0.408265 ,val acc : 0.817932\n",
      "[ ecpho : 3  iter :356 ]train loss : 0.323662 ,train acc: 0.843587 ,val loss : 0.409805 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :357 ]train loss : 0.354055 ,train acc: 0.813182 ,val loss : 0.403498 ,val acc : 0.817780\n",
      "[ ecpho : 3  iter :358 ]train loss : 0.291243 ,train acc: 0.864777 ,val loss : 0.408377 ,val acc : 0.820038\n",
      "[ ecpho : 3  iter :359 ]train loss : 0.303672 ,train acc: 0.853048 ,val loss : 0.402696 ,val acc : 0.820038\n",
      "[ ecpho : 3  iter :360 ]train loss : 0.299852 ,train acc: 0.859039 ,val loss : 0.405846 ,val acc : 0.817200\n",
      "[ ecpho : 3  iter :361 ]train loss : 0.492800 ,train acc: 0.805756 ,val loss : 0.402543 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :362 ]train loss : 0.308522 ,train acc: 0.852000 ,val loss : 0.402471 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :363 ]train loss : 0.287332 ,train acc: 0.862712 ,val loss : 0.405353 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :364 ]train loss : 0.314594 ,train acc: 0.852641 ,val loss : 0.401522 ,val acc : 0.817139\n",
      "[ ecpho : 3  iter :365 ]train loss : 0.308717 ,train acc: 0.853302 ,val loss : 0.400158 ,val acc : 0.822083\n",
      "[ ecpho : 3  iter :366 ]train loss : 0.319666 ,train acc: 0.842804 ,val loss : 0.408049 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :367 ]train loss : 0.286187 ,train acc: 0.860779 ,val loss : 0.400170 ,val acc : 0.822662\n",
      "[ ecpho : 3  iter :368 ]train loss : 0.346386 ,train acc: 0.830668 ,val loss : 0.404747 ,val acc : 0.820892\n",
      "[ ecpho : 3  iter :369 ]train loss : 0.350550 ,train acc: 0.848165 ,val loss : 0.406899 ,val acc : 0.817719\n",
      "[ ecpho : 3  iter :370 ]train loss : 0.298132 ,train acc: 0.857870 ,val loss : 0.406479 ,val acc : 0.817108\n",
      "[ ecpho : 3  iter :371 ]train loss : 0.273090 ,train acc: 0.871816 ,val loss : 0.405167 ,val acc : 0.815491\n",
      "[ ecpho : 3  iter :372 ]train loss : 0.289528 ,train acc: 0.854940 ,val loss : 0.404299 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :373 ]train loss : 0.333029 ,train acc: 0.844706 ,val loss : 0.399938 ,val acc : 0.822723\n",
      "[ ecpho : 3  iter :374 ]train loss : 0.315546 ,train acc: 0.838796 ,val loss : 0.401016 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :375 ]train loss : 0.381205 ,train acc: 0.822337 ,val loss : 0.400329 ,val acc : 0.820831\n",
      "[ ecpho : 3  iter :376 ]train loss : 0.281553 ,train acc: 0.861166 ,val loss : 0.400634 ,val acc : 0.821655\n",
      "[ ecpho : 3  iter :377 ]train loss : 0.299895 ,train acc: 0.856252 ,val loss : 0.399448 ,val acc : 0.818024\n",
      "[ ecpho : 3  iter :378 ]train loss : 0.291916 ,train acc: 0.856466 ,val loss : 0.403770 ,val acc : 0.818268\n",
      "[ ecpho : 3  iter :379 ]train loss : 0.384417 ,train acc: 0.834900 ,val loss : 0.405038 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :380 ]train loss : 0.378264 ,train acc: 0.792643 ,val loss : 0.403546 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :381 ]train loss : 0.266291 ,train acc: 0.869232 ,val loss : 0.406362 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :382 ]train loss : 0.350115 ,train acc: 0.849803 ,val loss : 0.403138 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :383 ]train loss : 0.357672 ,train acc: 0.842082 ,val loss : 0.403801 ,val acc : 0.816895\n",
      "[ ecpho : 3  iter :384 ]train loss : 0.357021 ,train acc: 0.850240 ,val loss : 0.400784 ,val acc : 0.820648\n",
      "[ ecpho : 3  iter :385 ]train loss : 0.282851 ,train acc: 0.862457 ,val loss : 0.402353 ,val acc : 0.819061\n",
      "[ ecpho : 3  iter :386 ]train loss : 0.312819 ,train acc: 0.855377 ,val loss : 0.406881 ,val acc : 0.819611\n",
      "[ ecpho : 3  iter :387 ]train loss : 0.381390 ,train acc: 0.840220 ,val loss : 0.406685 ,val acc : 0.816956\n",
      "[ ecpho : 3  iter :388 ]train loss : 0.281805 ,train acc: 0.863892 ,val loss : 0.401562 ,val acc : 0.818024\n",
      "[ ecpho : 3  iter :389 ]train loss : 0.313600 ,train acc: 0.850454 ,val loss : 0.397673 ,val acc : 0.822418\n",
      "[ ecpho : 3  iter :390 ]train loss : 0.305738 ,train acc: 0.855621 ,val loss : 0.405759 ,val acc : 0.815277\n",
      "[ ecpho : 3  iter :391 ]train loss : 0.280841 ,train acc: 0.864288 ,val loss : 0.404544 ,val acc : 0.815002\n",
      "[ ecpho : 3  iter :392 ]train loss : 0.414925 ,train acc: 0.805176 ,val loss : 0.400218 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :393 ]train loss : 0.433086 ,train acc: 0.832286 ,val loss : 0.406834 ,val acc : 0.817078\n",
      "[ ecpho : 3  iter :394 ]train loss : 0.259281 ,train acc: 0.872203 ,val loss : 0.411829 ,val acc : 0.814819\n",
      "[ ecpho : 3  iter :395 ]train loss : 0.351392 ,train acc: 0.845907 ,val loss : 0.404729 ,val acc : 0.819122\n",
      "[ ecpho : 3  iter :396 ]train loss : 0.391068 ,train acc: 0.829844 ,val loss : 0.397078 ,val acc : 0.819000\n",
      "[ ecpho : 3  iter :397 ]train loss : 0.387327 ,train acc: 0.833262 ,val loss : 0.408703 ,val acc : 0.819000\n",
      "[ ecpho : 3  iter :398 ]train loss : 0.337234 ,train acc: 0.848338 ,val loss : 0.406919 ,val acc : 0.817230\n",
      "[ ecpho : 3  iter :399 ]train loss : 0.387559 ,train acc: 0.796784 ,val loss : 0.413409 ,val acc : 0.816254\n",
      "[ ecpho : 3  iter :400 ]train loss : 0.347780 ,train acc: 0.853434 ,val loss : 0.400560 ,val acc : 0.820953\n",
      "[ ecpho : 3  iter :401 ]train loss : 0.349028 ,train acc: 0.831838 ,val loss : 0.404625 ,val acc : 0.816254\n",
      "[ ecpho : 3  iter :402 ]train loss : 0.286077 ,train acc: 0.863414 ,val loss : 0.407983 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :403 ]train loss : 0.316952 ,train acc: 0.856985 ,val loss : 0.407848 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :404 ]train loss : 0.348215 ,train acc: 0.855591 ,val loss : 0.402750 ,val acc : 0.819946\n",
      "[ ecpho : 3  iter :405 ]train loss : 0.332802 ,train acc: 0.830190 ,val loss : 0.402005 ,val acc : 0.818726\n",
      "[ ecpho : 3  iter :406 ]train loss : 0.382358 ,train acc: 0.796824 ,val loss : 0.406555 ,val acc : 0.817719\n",
      "[ ecpho : 3  iter :407 ]train loss : 0.391331 ,train acc: 0.822886 ,val loss : 0.399241 ,val acc : 0.818024\n",
      "[ ecpho : 3  iter :408 ]train loss : 0.357778 ,train acc: 0.843109 ,val loss : 0.404826 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :409 ]train loss : 0.320984 ,train acc: 0.840546 ,val loss : 0.401066 ,val acc : 0.821716\n",
      "[ ecpho : 3  iter :410 ]train loss : 0.365121 ,train acc: 0.830689 ,val loss : 0.399441 ,val acc : 0.820679\n",
      "[ ecpho : 3  iter :411 ]train loss : 0.339651 ,train acc: 0.845459 ,val loss : 0.405826 ,val acc : 0.818726\n",
      "[ ecpho : 3  iter :412 ]train loss : 0.295953 ,train acc: 0.858460 ,val loss : 0.406300 ,val acc : 0.815948\n",
      "[ ecpho : 3  iter :413 ]train loss : 0.257073 ,train acc: 0.877981 ,val loss : 0.408439 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :414 ]train loss : 0.266674 ,train acc: 0.869639 ,val loss : 0.400485 ,val acc : 0.819702\n",
      "[ ecpho : 3  iter :415 ]train loss : 0.329436 ,train acc: 0.852234 ,val loss : 0.403036 ,val acc : 0.818573\n",
      "[ ecpho : 3  iter :416 ]train loss : 0.326080 ,train acc: 0.856883 ,val loss : 0.407528 ,val acc : 0.815613\n",
      "[ ecpho : 3  iter :417 ]train loss : 0.318345 ,train acc: 0.861064 ,val loss : 0.401487 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :418 ]train loss : 0.289771 ,train acc: 0.865163 ,val loss : 0.404977 ,val acc : 0.817596\n",
      "[ ecpho : 3  iter :419 ]train loss : 0.296783 ,train acc: 0.866170 ,val loss : 0.400055 ,val acc : 0.820709\n",
      "[ ecpho : 3  iter :420 ]train loss : 0.312293 ,train acc: 0.859243 ,val loss : 0.404299 ,val acc : 0.818665\n",
      "[ ecpho : 3  iter :421 ]train loss : 0.351910 ,train acc: 0.824372 ,val loss : 0.404980 ,val acc : 0.817749\n",
      "[ ecpho : 3  iter :422 ]train loss : 0.388655 ,train acc: 0.831492 ,val loss : 0.399689 ,val acc : 0.817291\n",
      "[ ecpho : 3  iter :423 ]train loss : 0.467599 ,train acc: 0.829743 ,val loss : 0.405528 ,val acc : 0.819885\n",
      "[ ecpho : 3  iter :424 ]train loss : 0.351257 ,train acc: 0.844015 ,val loss : 0.406545 ,val acc : 0.817780\n",
      "[ ecpho : 3  iter :425 ]train loss : 0.310714 ,train acc: 0.853516 ,val loss : 0.404119 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :426 ]train loss : 0.469534 ,train acc: 0.740245 ,val loss : 0.409484 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :427 ]train loss : 0.239398 ,train acc: 0.883240 ,val loss : 0.400711 ,val acc : 0.819336\n",
      "[ ecpho : 3  iter :428 ]train loss : 0.261536 ,train acc: 0.870433 ,val loss : 0.399424 ,val acc : 0.820496\n",
      "[ ecpho : 3  iter :429 ]train loss : 0.286890 ,train acc: 0.862376 ,val loss : 0.406902 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :430 ]train loss : 0.285215 ,train acc: 0.865936 ,val loss : 0.407377 ,val acc : 0.816772\n",
      "[ ecpho : 3  iter :431 ]train loss : 0.340474 ,train acc: 0.852509 ,val loss : 0.401243 ,val acc : 0.818695\n",
      "[ ecpho : 3  iter :432 ]train loss : 0.261212 ,train acc: 0.872650 ,val loss : 0.400899 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :433 ]train loss : 0.354407 ,train acc: 0.840322 ,val loss : 0.403101 ,val acc : 0.821259\n",
      "[ ecpho : 3  iter :434 ]train loss : 0.269413 ,train acc: 0.868022 ,val loss : 0.405523 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :435 ]train loss : 0.333705 ,train acc: 0.846995 ,val loss : 0.408720 ,val acc : 0.816223\n",
      "[ ecpho : 3  iter :436 ]train loss : 0.438665 ,train acc: 0.785177 ,val loss : 0.403144 ,val acc : 0.817352\n",
      "[ ecpho : 3  iter :437 ]train loss : 0.328445 ,train acc: 0.827718 ,val loss : 0.400154 ,val acc : 0.820770\n",
      "[ ecpho : 3  iter :438 ]train loss : 0.341879 ,train acc: 0.818441 ,val loss : 0.403699 ,val acc : 0.820251\n",
      "[ ecpho : 3  iter :439 ]train loss : 0.410310 ,train acc: 0.832754 ,val loss : 0.403162 ,val acc : 0.820679\n",
      "[ ecpho : 3  iter :440 ]train loss : 0.305665 ,train acc: 0.838409 ,val loss : 0.402910 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :441 ]train loss : 0.328324 ,train acc: 0.853495 ,val loss : 0.408316 ,val acc : 0.816376\n",
      "[ ecpho : 3  iter :442 ]train loss : 0.329238 ,train acc: 0.853790 ,val loss : 0.400914 ,val acc : 0.821075\n",
      "[ ecpho : 3  iter :443 ]train loss : 0.278903 ,train acc: 0.867259 ,val loss : 0.407204 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :444 ]train loss : 0.339362 ,train acc: 0.853139 ,val loss : 0.392762 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :445 ]train loss : 0.312362 ,train acc: 0.855896 ,val loss : 0.406890 ,val acc : 0.816193\n",
      "[ ecpho : 3  iter :446 ]train loss : 0.341436 ,train acc: 0.832265 ,val loss : 0.399388 ,val acc : 0.819458\n",
      "[ ecpho : 3  iter :447 ]train loss : 0.321492 ,train acc: 0.853689 ,val loss : 0.406141 ,val acc : 0.817047\n",
      "[ ecpho : 3  iter :448 ]train loss : 0.259719 ,train acc: 0.872213 ,val loss : 0.402621 ,val acc : 0.819397\n",
      "[ ecpho : 3  iter :449 ]train loss : 0.375694 ,train acc: 0.840698 ,val loss : 0.395528 ,val acc : 0.821167\n",
      "[ ecpho : 3  iter :450 ]train loss : 0.254768 ,train acc: 0.872793 ,val loss : 0.399180 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :451 ]train loss : 0.272956 ,train acc: 0.872416 ,val loss : 0.402657 ,val acc : 0.821442\n",
      "[ ecpho : 3  iter :452 ]train loss : 0.333158 ,train acc: 0.853180 ,val loss : 0.401105 ,val acc : 0.821320\n",
      "[ ecpho : 3  iter :453 ]train loss : 0.287268 ,train acc: 0.859955 ,val loss : 0.405757 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :454 ]train loss : 0.320195 ,train acc: 0.857992 ,val loss : 0.403249 ,val acc : 0.815826\n",
      "[ ecpho : 3  iter :455 ]train loss : 0.369088 ,train acc: 0.841594 ,val loss : 0.407186 ,val acc : 0.815857\n",
      "[ ecpho : 3  iter :456 ]train loss : 0.362698 ,train acc: 0.836924 ,val loss : 0.403747 ,val acc : 0.819855\n",
      "[ ecpho : 3  iter :457 ]train loss : 0.344549 ,train acc: 0.845744 ,val loss : 0.400985 ,val acc : 0.820496\n",
      "[ ecpho : 3  iter :458 ]train loss : 0.293240 ,train acc: 0.861725 ,val loss : 0.403918 ,val acc : 0.819031\n",
      "[ ecpho : 3  iter :459 ]train loss : 0.347137 ,train acc: 0.850667 ,val loss : 0.402266 ,val acc : 0.817627\n",
      "[ ecpho : 3  iter :460 ]train loss : 0.261368 ,train acc: 0.874786 ,val loss : 0.404336 ,val acc : 0.817200\n",
      "[ ecpho : 3  iter :461 ]train loss : 0.286736 ,train acc: 0.862579 ,val loss : 0.402711 ,val acc : 0.820404\n",
      "[ ecpho : 3  iter :462 ]train loss : 0.275246 ,train acc: 0.872518 ,val loss : 0.408090 ,val acc : 0.820038\n",
      "[ ecpho : 3  iter :463 ]train loss : 0.344900 ,train acc: 0.833862 ,val loss : 0.405189 ,val acc : 0.817596\n",
      "[ ecpho : 3  iter :464 ]train loss : 0.373355 ,train acc: 0.827016 ,val loss : 0.403289 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :465 ]train loss : 0.365719 ,train acc: 0.839722 ,val loss : 0.408070 ,val acc : 0.816864\n",
      "[ ecpho : 3  iter :466 ]train loss : 0.352934 ,train acc: 0.833211 ,val loss : 0.405502 ,val acc : 0.817902\n",
      "[ ecpho : 3  iter :467 ]train loss : 0.287763 ,train acc: 0.864644 ,val loss : 0.399222 ,val acc : 0.818115\n",
      "[ ecpho : 3  iter :468 ]train loss : 0.279362 ,train acc: 0.864675 ,val loss : 0.405307 ,val acc : 0.817749\n",
      "[ ecpho : 3  iter :469 ]train loss : 0.343111 ,train acc: 0.847260 ,val loss : 0.402065 ,val acc : 0.818542\n",
      "[ ecpho : 3  iter :470 ]train loss : 0.319671 ,train acc: 0.847341 ,val loss : 0.400787 ,val acc : 0.815796\n",
      "[ ecpho : 3  iter :471 ]train loss : 0.314381 ,train acc: 0.849386 ,val loss : 0.399102 ,val acc : 0.817993\n",
      "[ ecpho : 3  iter :472 ]train loss : 0.311435 ,train acc: 0.852081 ,val loss : 0.404088 ,val acc : 0.818268\n",
      "[ ecpho : 3  iter :473 ]train loss : 0.246204 ,train acc: 0.877675 ,val loss : 0.406366 ,val acc : 0.817596\n",
      "[ ecpho : 3  iter :474 ]train loss : 0.289498 ,train acc: 0.860698 ,val loss : 0.403427 ,val acc : 0.819122\n",
      "[ ecpho : 3  iter :475 ]train loss : 0.322301 ,train acc: 0.851766 ,val loss : 0.396822 ,val acc : 0.821014\n",
      "[ ecpho : 3  iter :476 ]train loss : 0.267798 ,train acc: 0.871094 ,val loss : 0.398639 ,val acc : 0.821472\n",
      "[ ecpho : 3  iter :477 ]train loss : 0.293484 ,train acc: 0.867879 ,val loss : 0.397572 ,val acc : 0.819702\n",
      "[ ecpho : 3  iter :478 ]train loss : 0.375269 ,train acc: 0.822469 ,val loss : 0.395343 ,val acc : 0.821136\n",
      "[ ecpho : 3  iter :479 ]train loss : 0.615345 ,train acc: 0.723216 ,val loss : 0.401486 ,val acc : 0.817627\n",
      "[ ecpho : 3  iter :480 ]train loss : 0.288003 ,train acc: 0.863373 ,val loss : 0.399958 ,val acc : 0.818787\n",
      "[ ecpho : 3  iter :481 ]train loss : 0.263374 ,train acc: 0.869914 ,val loss : 0.398416 ,val acc : 0.821289\n",
      "[ ecpho : 3  iter :482 ]train loss : 0.298224 ,train acc: 0.854075 ,val loss : 0.404250 ,val acc : 0.819977\n",
      "[ ecpho : 3  iter :483 ]train loss : 0.352220 ,train acc: 0.850169 ,val loss : 0.406498 ,val acc : 0.818146\n",
      "[ ecpho : 3  iter :484 ]train loss : 0.392324 ,train acc: 0.837667 ,val loss : 0.404122 ,val acc : 0.816498\n",
      "[ ecpho : 3  iter :485 ]train loss : 0.323818 ,train acc: 0.837514 ,val loss : 0.406343 ,val acc : 0.819336\n",
      "[ ecpho : 3  iter :486 ]train loss : 0.282144 ,train acc: 0.860830 ,val loss : 0.399304 ,val acc : 0.821259\n",
      "[ ecpho : 3  iter :487 ]train loss : 0.278908 ,train acc: 0.864644 ,val loss : 0.402048 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :488 ]train loss : 0.251324 ,train acc: 0.876353 ,val loss : 0.400590 ,val acc : 0.819580\n",
      "[ ecpho : 3  iter :489 ]train loss : 0.298315 ,train acc: 0.859395 ,val loss : 0.403408 ,val acc : 0.817932\n",
      "[ ecpho : 3  iter :490 ]train loss : 0.392166 ,train acc: 0.819580 ,val loss : 0.404246 ,val acc : 0.819061\n",
      "[ ecpho : 3  iter :491 ]train loss : 0.387598 ,train acc: 0.831767 ,val loss : 0.401513 ,val acc : 0.817383\n",
      "[ ecpho : 3  iter :492 ]train loss : 0.296563 ,train acc: 0.851868 ,val loss : 0.400842 ,val acc : 0.818420\n",
      "[ ecpho : 3  iter :493 ]train loss : 0.326815 ,train acc: 0.855042 ,val loss : 0.399601 ,val acc : 0.820190\n",
      "[ ecpho : 3  iter :494 ]train loss : 0.285933 ,train acc: 0.863729 ,val loss : 0.407840 ,val acc : 0.817078\n",
      "[ ecpho : 3  iter :495 ]train loss : 0.307710 ,train acc: 0.853892 ,val loss : 0.407051 ,val acc : 0.818665\n",
      "[ ecpho : 3  iter :496 ]train loss : 0.268499 ,train acc: 0.870789 ,val loss : 0.399320 ,val acc : 0.821930\n",
      "[ ecpho : 3  iter :497 ]train loss : 0.481518 ,train acc: 0.784546 ,val loss : 0.404603 ,val acc : 0.816376\n",
      "[ ecpho : 3  iter :498 ]train loss : 0.506025 ,train acc: 0.803406 ,val loss : 0.406362 ,val acc : 0.819000\n",
      "[ ecpho : 3  iter :499 ]train loss : 0.434489 ,train acc: 0.812887 ,val loss : 0.407591 ,val acc : 0.818390\n",
      "[ ecpho : 3  iter :500 ]train loss : 0.449266 ,train acc: 0.810303 ,val loss : 0.406837 ,val acc : 0.818359\n",
      "[ ecpho : 3  iter :501 ]train loss : 0.347213 ,train acc: 0.823629 ,val loss : 0.402414 ,val acc : 0.819855\n",
      "[ ecpho : 3  iter :502 ]train loss : 0.359266 ,train acc: 0.850789 ,val loss : 0.410613 ,val acc : 0.815674\n",
      "[ ecpho : 3  iter :503 ]train loss : 0.356902 ,train acc: 0.822652 ,val loss : 0.402274 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :504 ]train loss : 0.272374 ,train acc: 0.867951 ,val loss : 0.401521 ,val acc : 0.821014\n",
      "[ ecpho : 3  iter :505 ]train loss : 0.321306 ,train acc: 0.853953 ,val loss : 0.399201 ,val acc : 0.822327\n",
      "[ ecpho : 3  iter :506 ]train loss : 0.302029 ,train acc: 0.857849 ,val loss : 0.401474 ,val acc : 0.821259\n",
      "[ ecpho : 3  iter :507 ]train loss : 0.312553 ,train acc: 0.853038 ,val loss : 0.397729 ,val acc : 0.822052\n",
      "[ ecpho : 3  iter :508 ]train loss : 0.264709 ,train acc: 0.869700 ,val loss : 0.405666 ,val acc : 0.817841\n",
      "[ ecpho : 3  iter :509 ]train loss : 0.471340 ,train acc: 0.793122 ,val loss : 0.396204 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :510 ]train loss : 0.298155 ,train acc: 0.857768 ,val loss : 0.396921 ,val acc : 0.820343\n",
      "[ ecpho : 3  iter :511 ]train loss : 0.422181 ,train acc: 0.840790 ,val loss : 0.403333 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :512 ]train loss : 0.259112 ,train acc: 0.870361 ,val loss : 0.398745 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :513 ]train loss : 0.360048 ,train acc: 0.841746 ,val loss : 0.402328 ,val acc : 0.816833\n",
      "[ ecpho : 3  iter :514 ]train loss : 0.328466 ,train acc: 0.849528 ,val loss : 0.403030 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :515 ]train loss : 0.277553 ,train acc: 0.868693 ,val loss : 0.409287 ,val acc : 0.817474\n",
      "[ ecpho : 3  iter :516 ]train loss : 0.309529 ,train acc: 0.855713 ,val loss : 0.396522 ,val acc : 0.818970\n",
      "[ ecpho : 3  iter :517 ]train loss : 0.304378 ,train acc: 0.849976 ,val loss : 0.400240 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :518 ]train loss : 0.265340 ,train acc: 0.874746 ,val loss : 0.400093 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :519 ]train loss : 0.327668 ,train acc: 0.852427 ,val loss : 0.400440 ,val acc : 0.821289\n",
      "[ ecpho : 3  iter :520 ]train loss : 0.269769 ,train acc: 0.868205 ,val loss : 0.405917 ,val acc : 0.819946\n",
      "[ ecpho : 3  iter :521 ]train loss : 0.309898 ,train acc: 0.852478 ,val loss : 0.399981 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :522 ]train loss : 0.357846 ,train acc: 0.838013 ,val loss : 0.396104 ,val acc : 0.822205\n",
      "[ ecpho : 3  iter :523 ]train loss : 0.261104 ,train acc: 0.872935 ,val loss : 0.398524 ,val acc : 0.818573\n",
      "[ ecpho : 3  iter :524 ]train loss : 0.350960 ,train acc: 0.844574 ,val loss : 0.406228 ,val acc : 0.815216\n",
      "[ ecpho : 3  iter :525 ]train loss : 0.265846 ,train acc: 0.873535 ,val loss : 0.406613 ,val acc : 0.819061\n",
      "[ ecpho : 3  iter :526 ]train loss : 0.424503 ,train acc: 0.792369 ,val loss : 0.400130 ,val acc : 0.819427\n",
      "[ ecpho : 3  iter :527 ]train loss : 0.417244 ,train acc: 0.842580 ,val loss : 0.402684 ,val acc : 0.819366\n",
      "[ ecpho : 3  iter :528 ]train loss : 0.351527 ,train acc: 0.846914 ,val loss : 0.403965 ,val acc : 0.817871\n",
      "[ ecpho : 3  iter :529 ]train loss : 0.312480 ,train acc: 0.848867 ,val loss : 0.404922 ,val acc : 0.817169\n",
      "[ ecpho : 3  iter :530 ]train loss : 0.361695 ,train acc: 0.839061 ,val loss : 0.410958 ,val acc : 0.814972\n",
      "[ ecpho : 3  iter :531 ]train loss : 0.355768 ,train acc: 0.828583 ,val loss : 0.405148 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :532 ]train loss : 0.324039 ,train acc: 0.858215 ,val loss : 0.396509 ,val acc : 0.824493\n",
      "[ ecpho : 3  iter :533 ]train loss : 0.423995 ,train acc: 0.819763 ,val loss : 0.403634 ,val acc : 0.817047\n",
      "[ ecpho : 3  iter :534 ]train loss : 0.288333 ,train acc: 0.863586 ,val loss : 0.403428 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :535 ]train loss : 0.286191 ,train acc: 0.866272 ,val loss : 0.399734 ,val acc : 0.820831\n",
      "[ ecpho : 3  iter :536 ]train loss : 0.336511 ,train acc: 0.814474 ,val loss : 0.397432 ,val acc : 0.823303\n",
      "[ ecpho : 3  iter :537 ]train loss : 0.317427 ,train acc: 0.846690 ,val loss : 0.395548 ,val acc : 0.820770\n",
      "[ ecpho : 3  iter :538 ]train loss : 0.317615 ,train acc: 0.845052 ,val loss : 0.400084 ,val acc : 0.815369\n",
      "[ ecpho : 3  iter :539 ]train loss : 0.391152 ,train acc: 0.828390 ,val loss : 0.402755 ,val acc : 0.818939\n",
      "[ ecpho : 3  iter :540 ]train loss : 0.490805 ,train acc: 0.798045 ,val loss : 0.404813 ,val acc : 0.821442\n",
      "[ ecpho : 3  iter :541 ]train loss : 0.339411 ,train acc: 0.851644 ,val loss : 0.403665 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :542 ]train loss : 0.316443 ,train acc: 0.859456 ,val loss : 0.403052 ,val acc : 0.817810\n",
      "[ ecpho : 3  iter :543 ]train loss : 0.307989 ,train acc: 0.861532 ,val loss : 0.405198 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :544 ]train loss : 0.266881 ,train acc: 0.871531 ,val loss : 0.398330 ,val acc : 0.822174\n",
      "[ ecpho : 3  iter :545 ]train loss : 0.337569 ,train acc: 0.820069 ,val loss : 0.397650 ,val acc : 0.821442\n",
      "[ ecpho : 3  iter :546 ]train loss : 0.361430 ,train acc: 0.808116 ,val loss : 0.403503 ,val acc : 0.816711\n",
      "[ ecpho : 3  iter :547 ]train loss : 0.323918 ,train acc: 0.839406 ,val loss : 0.403471 ,val acc : 0.818359\n",
      "[ ecpho : 3  iter :548 ]train loss : 0.347941 ,train acc: 0.844849 ,val loss : 0.405935 ,val acc : 0.815552\n",
      "[ ecpho : 3  iter :549 ]train loss : 0.302749 ,train acc: 0.853363 ,val loss : 0.403077 ,val acc : 0.818726\n",
      "[ ecpho : 3  iter :550 ]train loss : 0.348240 ,train acc: 0.839478 ,val loss : 0.404690 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :551 ]train loss : 0.330325 ,train acc: 0.836395 ,val loss : 0.401720 ,val acc : 0.816956\n",
      "[ ecpho : 3  iter :552 ]train loss : 0.409851 ,train acc: 0.835277 ,val loss : 0.398756 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :553 ]train loss : 0.461779 ,train acc: 0.827444 ,val loss : 0.403487 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :554 ]train loss : 0.349664 ,train acc: 0.819021 ,val loss : 0.408611 ,val acc : 0.815277\n",
      "[ ecpho : 3  iter :555 ]train loss : 0.361006 ,train acc: 0.850332 ,val loss : 0.399249 ,val acc : 0.820953\n",
      "[ ecpho : 3  iter :556 ]train loss : 0.373342 ,train acc: 0.810995 ,val loss : 0.402614 ,val acc : 0.818268\n",
      "[ ecpho : 3  iter :557 ]train loss : 0.598494 ,train acc: 0.778483 ,val loss : 0.402017 ,val acc : 0.819916\n",
      "[ ecpho : 3  iter :558 ]train loss : 0.274746 ,train acc: 0.865692 ,val loss : 0.405182 ,val acc : 0.818970\n",
      "[ ecpho : 3  iter :559 ]train loss : 0.334882 ,train acc: 0.823263 ,val loss : 0.397554 ,val acc : 0.820068\n",
      "[ ecpho : 3  iter :560 ]train loss : 0.388333 ,train acc: 0.834992 ,val loss : 0.403700 ,val acc : 0.822052\n",
      "[ ecpho : 3  iter :561 ]train loss : 0.338322 ,train acc: 0.849691 ,val loss : 0.400512 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :562 ]train loss : 0.283887 ,train acc: 0.866048 ,val loss : 0.399325 ,val acc : 0.820343\n",
      "[ ecpho : 3  iter :563 ]train loss : 0.339072 ,train acc: 0.821452 ,val loss : 0.405530 ,val acc : 0.821289\n",
      "[ ecpho : 3  iter :564 ]train loss : 0.343640 ,train acc: 0.839081 ,val loss : 0.402487 ,val acc : 0.822510\n",
      "[ ecpho : 3  iter :565 ]train loss : 0.377942 ,train acc: 0.839132 ,val loss : 0.405668 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :566 ]train loss : 0.420905 ,train acc: 0.759420 ,val loss : 0.402514 ,val acc : 0.818604\n",
      "[ ecpho : 3  iter :567 ]train loss : 0.311939 ,train acc: 0.857188 ,val loss : 0.401586 ,val acc : 0.816833\n",
      "[ ecpho : 3  iter :568 ]train loss : 0.366553 ,train acc: 0.845266 ,val loss : 0.404606 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :569 ]train loss : 0.286116 ,train acc: 0.861908 ,val loss : 0.399935 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :570 ]train loss : 0.420849 ,train acc: 0.796458 ,val loss : 0.401072 ,val acc : 0.818970\n",
      "[ ecpho : 3  iter :571 ]train loss : 0.353161 ,train acc: 0.851685 ,val loss : 0.399444 ,val acc : 0.820831\n",
      "[ ecpho : 3  iter :572 ]train loss : 0.333303 ,train acc: 0.844961 ,val loss : 0.401522 ,val acc : 0.821747\n",
      "[ ecpho : 3  iter :573 ]train loss : 0.302504 ,train acc: 0.858816 ,val loss : 0.403583 ,val acc : 0.818054\n",
      "[ ecpho : 3  iter :574 ]train loss : 0.348134 ,train acc: 0.847300 ,val loss : 0.402844 ,val acc : 0.819580\n",
      "[ ecpho : 3  iter :575 ]train loss : 0.325831 ,train acc: 0.853149 ,val loss : 0.396441 ,val acc : 0.819336\n",
      "[ ecpho : 3  iter :576 ]train loss : 0.278286 ,train acc: 0.870595 ,val loss : 0.399003 ,val acc : 0.821716\n",
      "[ ecpho : 3  iter :577 ]train loss : 0.291220 ,train acc: 0.855611 ,val loss : 0.406481 ,val acc : 0.817383\n",
      "[ ecpho : 3  iter :578 ]train loss : 0.283139 ,train acc: 0.865194 ,val loss : 0.399152 ,val acc : 0.818848\n",
      "[ ecpho : 3  iter :579 ]train loss : 0.378245 ,train acc: 0.796183 ,val loss : 0.407306 ,val acc : 0.817780\n",
      "[ ecpho : 3  iter :580 ]train loss : 0.362217 ,train acc: 0.826141 ,val loss : 0.400227 ,val acc : 0.822205\n",
      "[ ecpho : 3  iter :581 ]train loss : 0.414526 ,train acc: 0.804474 ,val loss : 0.399095 ,val acc : 0.820862\n",
      "[ ecpho : 3  iter :582 ]train loss : 0.352094 ,train acc: 0.835246 ,val loss : 0.406319 ,val acc : 0.817108\n",
      "[ ecpho : 3  iter :583 ]train loss : 0.364378 ,train acc: 0.840363 ,val loss : 0.403530 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :584 ]train loss : 0.365767 ,train acc: 0.843170 ,val loss : 0.405280 ,val acc : 0.817688\n",
      "[ ecpho : 3  iter :585 ]train loss : 0.415033 ,train acc: 0.775960 ,val loss : 0.402010 ,val acc : 0.818970\n",
      "[ ecpho : 3  iter :586 ]train loss : 0.329071 ,train acc: 0.854584 ,val loss : 0.407891 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :587 ]train loss : 0.310914 ,train acc: 0.851481 ,val loss : 0.396575 ,val acc : 0.821014\n",
      "[ ecpho : 3  iter :588 ]train loss : 0.258589 ,train acc: 0.874054 ,val loss : 0.402228 ,val acc : 0.817841\n",
      "[ ecpho : 3  iter :589 ]train loss : 0.323141 ,train acc: 0.847992 ,val loss : 0.401377 ,val acc : 0.821503\n",
      "[ ecpho : 3  iter :590 ]train loss : 0.381213 ,train acc: 0.839213 ,val loss : 0.407674 ,val acc : 0.817230\n",
      "[ ecpho : 3  iter :591 ]train loss : 0.312507 ,train acc: 0.846476 ,val loss : 0.400655 ,val acc : 0.819031\n",
      "[ ecpho : 3  iter :592 ]train loss : 0.344818 ,train acc: 0.851390 ,val loss : 0.397780 ,val acc : 0.820770\n",
      "[ ecpho : 3  iter :593 ]train loss : 0.407159 ,train acc: 0.829590 ,val loss : 0.404332 ,val acc : 0.819733\n",
      "[ ecpho : 3  iter :594 ]train loss : 0.375304 ,train acc: 0.847270 ,val loss : 0.403154 ,val acc : 0.820160\n",
      "[ ecpho : 3  iter :595 ]train loss : 0.360746 ,train acc: 0.832723 ,val loss : 0.404562 ,val acc : 0.818939\n",
      "[ ecpho : 3  iter :596 ]train loss : 0.338311 ,train acc: 0.835348 ,val loss : 0.404543 ,val acc : 0.819702\n",
      "[ ecpho : 3  iter :597 ]train loss : 0.301844 ,train acc: 0.862305 ,val loss : 0.400742 ,val acc : 0.819946\n",
      "[ ecpho : 3  iter :598 ]train loss : 0.278399 ,train acc: 0.868195 ,val loss : 0.403935 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :599 ]train loss : 0.411975 ,train acc: 0.821554 ,val loss : 0.405584 ,val acc : 0.820953\n",
      "[ ecpho : 3  iter :600 ]train loss : 0.303934 ,train acc: 0.858470 ,val loss : 0.398791 ,val acc : 0.819061\n",
      "[ ecpho : 3  iter :601 ]train loss : 0.346621 ,train acc: 0.845001 ,val loss : 0.400415 ,val acc : 0.819763\n",
      "[ ecpho : 3  iter :602 ]train loss : 0.281054 ,train acc: 0.868683 ,val loss : 0.399957 ,val acc : 0.821289\n",
      "[ ecpho : 3  iter :603 ]train loss : 0.262211 ,train acc: 0.872284 ,val loss : 0.399899 ,val acc : 0.822906\n",
      "[ ecpho : 3  iter :604 ]train loss : 0.325512 ,train acc: 0.854146 ,val loss : 0.400289 ,val acc : 0.818909\n",
      "[ ecpho : 3  iter :605 ]train loss : 0.270010 ,train acc: 0.870545 ,val loss : 0.399330 ,val acc : 0.820770\n",
      "[ ecpho : 3  iter :606 ]train loss : 0.338069 ,train acc: 0.852631 ,val loss : 0.404471 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :607 ]train loss : 0.354737 ,train acc: 0.846049 ,val loss : 0.404143 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :608 ]train loss : 0.305250 ,train acc: 0.847249 ,val loss : 0.397258 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :609 ]train loss : 0.273743 ,train acc: 0.866648 ,val loss : 0.397931 ,val acc : 0.819672\n",
      "[ ecpho : 3  iter :610 ]train loss : 0.311230 ,train acc: 0.838369 ,val loss : 0.399745 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :611 ]train loss : 0.256733 ,train acc: 0.872131 ,val loss : 0.405900 ,val acc : 0.815979\n",
      "[ ecpho : 3  iter :612 ]train loss : 0.340207 ,train acc: 0.839610 ,val loss : 0.394471 ,val acc : 0.824524\n",
      "[ ecpho : 3  iter :613 ]train loss : 0.333927 ,train acc: 0.847117 ,val loss : 0.396777 ,val acc : 0.820984\n",
      "[ ecpho : 3  iter :614 ]train loss : 0.344990 ,train acc: 0.822327 ,val loss : 0.403090 ,val acc : 0.818420\n",
      "[ ecpho : 3  iter :615 ]train loss : 0.309926 ,train acc: 0.856832 ,val loss : 0.398364 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :616 ]train loss : 0.290384 ,train acc: 0.862895 ,val loss : 0.403918 ,val acc : 0.818207\n",
      "[ ecpho : 3  iter :617 ]train loss : 0.309238 ,train acc: 0.858246 ,val loss : 0.397260 ,val acc : 0.822510\n",
      "[ ecpho : 3  iter :618 ]train loss : 0.287092 ,train acc: 0.858114 ,val loss : 0.404323 ,val acc : 0.816589\n",
      "[ ecpho : 3  iter :619 ]train loss : 0.284910 ,train acc: 0.868174 ,val loss : 0.405401 ,val acc : 0.816650\n",
      "[ ecpho : 3  iter :620 ]train loss : 0.304915 ,train acc: 0.859080 ,val loss : 0.400169 ,val acc : 0.820435\n",
      "[ ecpho : 3  iter :621 ]train loss : 0.420174 ,train acc: 0.810822 ,val loss : 0.402805 ,val acc : 0.820648\n",
      "[ ecpho : 3  iter :622 ]train loss : 0.296018 ,train acc: 0.862407 ,val loss : 0.401450 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :623 ]train loss : 0.335155 ,train acc: 0.857595 ,val loss : 0.403099 ,val acc : 0.817657\n",
      "[ ecpho : 3  iter :624 ]train loss : 0.263919 ,train acc: 0.872101 ,val loss : 0.399191 ,val acc : 0.822327\n",
      "[ ecpho : 3  iter :625 ]train loss : 0.355418 ,train acc: 0.838745 ,val loss : 0.399591 ,val acc : 0.821136\n",
      "[ ecpho : 3  iter :626 ]train loss : 0.355570 ,train acc: 0.844269 ,val loss : 0.406331 ,val acc : 0.816040\n",
      "[ ecpho : 3  iter :627 ]train loss : 0.331388 ,train acc: 0.859955 ,val loss : 0.404076 ,val acc : 0.820953\n",
      "[ ecpho : 3  iter :628 ]train loss : 0.435880 ,train acc: 0.815084 ,val loss : 0.403237 ,val acc : 0.819977\n",
      "[ ecpho : 3  iter :629 ]train loss : 0.329500 ,train acc: 0.823253 ,val loss : 0.408035 ,val acc : 0.814453\n",
      "[ ecpho : 3  iter :630 ]train loss : 0.323013 ,train acc: 0.859131 ,val loss : 0.400456 ,val acc : 0.820679\n",
      "[ ecpho : 3  iter :631 ]train loss : 0.339931 ,train acc: 0.825786 ,val loss : 0.402742 ,val acc : 0.817627\n",
      "[ ecpho : 3  iter :632 ]train loss : 0.328182 ,train acc: 0.853465 ,val loss : 0.398116 ,val acc : 0.821472\n",
      "[ ecpho : 3  iter :633 ]train loss : 0.360050 ,train acc: 0.841797 ,val loss : 0.404841 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :634 ]train loss : 0.296705 ,train acc: 0.863271 ,val loss : 0.401787 ,val acc : 0.817627\n",
      "[ ecpho : 3  iter :635 ]train loss : 0.380832 ,train acc: 0.845469 ,val loss : 0.397499 ,val acc : 0.820862\n",
      "[ ecpho : 3  iter :636 ]train loss : 0.263294 ,train acc: 0.871104 ,val loss : 0.401982 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :637 ]train loss : 0.294626 ,train acc: 0.864573 ,val loss : 0.402702 ,val acc : 0.814972\n",
      "[ ecpho : 3  iter :638 ]train loss : 0.253992 ,train acc: 0.876790 ,val loss : 0.399271 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :639 ]train loss : 0.300691 ,train acc: 0.859701 ,val loss : 0.397131 ,val acc : 0.821869\n",
      "[ ecpho : 3  iter :640 ]train loss : 0.388426 ,train acc: 0.833415 ,val loss : 0.404028 ,val acc : 0.816864\n",
      "[ ecpho : 3  iter :641 ]train loss : 0.334970 ,train acc: 0.850423 ,val loss : 0.401179 ,val acc : 0.818939\n",
      "[ ecpho : 3  iter :642 ]train loss : 0.329678 ,train acc: 0.851481 ,val loss : 0.403322 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :643 ]train loss : 0.295951 ,train acc: 0.855499 ,val loss : 0.396594 ,val acc : 0.817017\n",
      "[ ecpho : 3  iter :644 ]train loss : 0.357001 ,train acc: 0.823415 ,val loss : 0.395312 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :645 ]train loss : 0.293042 ,train acc: 0.865418 ,val loss : 0.402108 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :646 ]train loss : 0.259687 ,train acc: 0.874379 ,val loss : 0.398219 ,val acc : 0.820312\n",
      "[ ecpho : 3  iter :647 ]train loss : 0.403902 ,train acc: 0.816010 ,val loss : 0.402920 ,val acc : 0.818726\n",
      "[ ecpho : 3  iter :648 ]train loss : 0.268174 ,train acc: 0.868917 ,val loss : 0.402567 ,val acc : 0.819855\n",
      "[ ecpho : 3  iter :649 ]train loss : 0.406050 ,train acc: 0.809418 ,val loss : 0.402949 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :650 ]train loss : 0.294512 ,train acc: 0.862559 ,val loss : 0.394027 ,val acc : 0.821930\n",
      "[ ecpho : 3  iter :651 ]train loss : 0.315314 ,train acc: 0.851217 ,val loss : 0.399986 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :652 ]train loss : 0.312697 ,train acc: 0.855866 ,val loss : 0.402729 ,val acc : 0.818054\n",
      "[ ecpho : 3  iter :653 ]train loss : 0.346814 ,train acc: 0.822652 ,val loss : 0.404791 ,val acc : 0.820953\n",
      "[ ecpho : 3  iter :654 ]train loss : 0.349858 ,train acc: 0.842336 ,val loss : 0.401546 ,val acc : 0.818542\n",
      "[ ecpho : 3  iter :655 ]train loss : 0.615143 ,train acc: 0.777731 ,val loss : 0.400612 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :656 ]train loss : 0.401094 ,train acc: 0.822673 ,val loss : 0.396487 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :657 ]train loss : 0.321224 ,train acc: 0.861491 ,val loss : 0.400182 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :658 ]train loss : 0.330811 ,train acc: 0.849376 ,val loss : 0.402934 ,val acc : 0.820007\n",
      "[ ecpho : 3  iter :659 ]train loss : 0.279386 ,train acc: 0.862468 ,val loss : 0.402288 ,val acc : 0.818573\n",
      "[ ecpho : 3  iter :660 ]train loss : 0.337234 ,train acc: 0.847961 ,val loss : 0.396902 ,val acc : 0.818359\n",
      "[ ecpho : 3  iter :661 ]train loss : 0.283990 ,train acc: 0.861959 ,val loss : 0.403477 ,val acc : 0.821167\n",
      "[ ecpho : 3  iter :662 ]train loss : 0.417942 ,train acc: 0.836558 ,val loss : 0.400957 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :663 ]train loss : 0.314610 ,train acc: 0.845734 ,val loss : 0.395940 ,val acc : 0.821045\n",
      "[ ecpho : 3  iter :664 ]train loss : 0.285212 ,train acc: 0.864634 ,val loss : 0.392935 ,val acc : 0.823120\n",
      "[ ecpho : 3  iter :665 ]train loss : 0.335858 ,train acc: 0.824331 ,val loss : 0.395850 ,val acc : 0.821686\n",
      "[ ecpho : 3  iter :666 ]train loss : 0.309843 ,train acc: 0.852346 ,val loss : 0.396867 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :667 ]train loss : 0.493507 ,train acc: 0.762848 ,val loss : 0.400588 ,val acc : 0.819672\n",
      "[ ecpho : 3  iter :668 ]train loss : 0.258926 ,train acc: 0.872213 ,val loss : 0.401321 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :669 ]train loss : 0.375487 ,train acc: 0.802724 ,val loss : 0.399070 ,val acc : 0.823761\n",
      "[ ecpho : 3  iter :670 ]train loss : 0.340789 ,train acc: 0.847575 ,val loss : 0.403996 ,val acc : 0.817902\n",
      "[ ecpho : 3  iter :671 ]train loss : 0.411635 ,train acc: 0.833130 ,val loss : 0.405682 ,val acc : 0.815948\n",
      "[ ecpho : 3  iter :672 ]train loss : 0.322502 ,train acc: 0.854462 ,val loss : 0.400599 ,val acc : 0.819885\n",
      "[ ecpho : 3  iter :673 ]train loss : 0.378343 ,train acc: 0.816030 ,val loss : 0.400900 ,val acc : 0.819885\n",
      "[ ecpho : 3  iter :674 ]train loss : 0.441458 ,train acc: 0.827556 ,val loss : 0.398207 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :675 ]train loss : 0.311124 ,train acc: 0.845612 ,val loss : 0.400748 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :676 ]train loss : 0.287249 ,train acc: 0.864828 ,val loss : 0.402869 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :677 ]train loss : 0.328247 ,train acc: 0.850016 ,val loss : 0.405540 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :678 ]train loss : 0.525812 ,train acc: 0.815094 ,val loss : 0.401824 ,val acc : 0.820221\n",
      "[ ecpho : 3  iter :679 ]train loss : 0.291321 ,train acc: 0.862386 ,val loss : 0.402581 ,val acc : 0.818024\n",
      "[ ecpho : 3  iter :680 ]train loss : 0.389174 ,train acc: 0.837820 ,val loss : 0.398812 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :681 ]train loss : 0.381567 ,train acc: 0.825948 ,val loss : 0.398764 ,val acc : 0.820007\n",
      "[ ecpho : 3  iter :682 ]train loss : 0.336572 ,train acc: 0.840149 ,val loss : 0.405575 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :683 ]train loss : 0.306696 ,train acc: 0.861460 ,val loss : 0.387463 ,val acc : 0.824036\n",
      "[ ecpho : 3  iter :684 ]train loss : 0.297422 ,train acc: 0.855723 ,val loss : 0.402521 ,val acc : 0.818604\n",
      "[ ecpho : 3  iter :685 ]train loss : 0.278939 ,train acc: 0.871409 ,val loss : 0.396327 ,val acc : 0.822113\n",
      "[ ecpho : 3  iter :686 ]train loss : 0.265412 ,train acc: 0.872843 ,val loss : 0.401326 ,val acc : 0.817352\n",
      "[ ecpho : 3  iter :687 ]train loss : 0.320068 ,train acc: 0.857483 ,val loss : 0.401286 ,val acc : 0.819733\n",
      "[ ecpho : 3  iter :688 ]train loss : 0.337016 ,train acc: 0.837341 ,val loss : 0.399344 ,val acc : 0.819244\n",
      "[ ecpho : 3  iter :689 ]train loss : 0.308065 ,train acc: 0.847138 ,val loss : 0.393789 ,val acc : 0.820831\n",
      "[ ecpho : 3  iter :690 ]train loss : 0.319818 ,train acc: 0.852865 ,val loss : 0.397784 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :691 ]train loss : 0.361346 ,train acc: 0.816050 ,val loss : 0.400508 ,val acc : 0.821747\n",
      "[ ecpho : 3  iter :692 ]train loss : 0.261907 ,train acc: 0.871460 ,val loss : 0.400443 ,val acc : 0.821350\n",
      "[ ecpho : 3  iter :693 ]train loss : 0.370813 ,train acc: 0.835856 ,val loss : 0.394624 ,val acc : 0.822205\n",
      "[ ecpho : 3  iter :694 ]train loss : 0.433692 ,train acc: 0.827993 ,val loss : 0.401440 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :695 ]train loss : 0.329370 ,train acc: 0.849182 ,val loss : 0.402834 ,val acc : 0.821198\n",
      "[ ecpho : 3  iter :696 ]train loss : 0.307936 ,train acc: 0.847494 ,val loss : 0.401341 ,val acc : 0.821075\n",
      "[ ecpho : 3  iter :697 ]train loss : 0.402542 ,train acc: 0.835653 ,val loss : 0.397826 ,val acc : 0.820038\n",
      "[ ecpho : 3  iter :698 ]train loss : 0.395029 ,train acc: 0.835419 ,val loss : 0.393640 ,val acc : 0.819031\n",
      "[ ecpho : 3  iter :699 ]train loss : 0.336681 ,train acc: 0.841156 ,val loss : 0.403481 ,val acc : 0.817749\n",
      "[ ecpho : 3  iter :700 ]train loss : 0.328370 ,train acc: 0.835866 ,val loss : 0.400996 ,val acc : 0.818085\n",
      "[ ecpho : 3  iter :701 ]train loss : 0.311449 ,train acc: 0.857707 ,val loss : 0.401252 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :702 ]train loss : 0.326450 ,train acc: 0.839468 ,val loss : 0.398107 ,val acc : 0.821899\n",
      "[ ecpho : 3  iter :703 ]train loss : 0.270986 ,train acc: 0.866638 ,val loss : 0.401437 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :704 ]train loss : 0.351596 ,train acc: 0.818451 ,val loss : 0.402053 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :705 ]train loss : 0.351450 ,train acc: 0.842245 ,val loss : 0.399258 ,val acc : 0.819031\n",
      "[ ecpho : 3  iter :706 ]train loss : 0.355156 ,train acc: 0.818258 ,val loss : 0.401048 ,val acc : 0.821075\n",
      "[ ecpho : 3  iter :707 ]train loss : 0.279704 ,train acc: 0.864248 ,val loss : 0.394257 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :708 ]train loss : 0.306629 ,train acc: 0.852712 ,val loss : 0.401773 ,val acc : 0.820801\n",
      "[ ecpho : 3  iter :709 ]train loss : 0.332435 ,train acc: 0.821411 ,val loss : 0.405569 ,val acc : 0.818848\n",
      "[ ecpho : 3  iter :710 ]train loss : 0.242060 ,train acc: 0.879476 ,val loss : 0.402946 ,val acc : 0.818573\n",
      "[ ecpho : 3  iter :711 ]train loss : 0.293193 ,train acc: 0.859599 ,val loss : 0.399030 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :712 ]train loss : 0.275344 ,train acc: 0.866791 ,val loss : 0.400399 ,val acc : 0.819122\n",
      "[ ecpho : 3  iter :713 ]train loss : 0.279612 ,train acc: 0.864980 ,val loss : 0.398509 ,val acc : 0.820801\n",
      "[ ecpho : 3  iter :714 ]train loss : 0.266450 ,train acc: 0.869792 ,val loss : 0.400665 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :715 ]train loss : 0.430699 ,train acc: 0.832835 ,val loss : 0.399525 ,val acc : 0.817993\n",
      "[ ecpho : 3  iter :716 ]train loss : 0.544512 ,train acc: 0.769501 ,val loss : 0.399340 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :717 ]train loss : 0.274878 ,train acc: 0.865224 ,val loss : 0.400430 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :718 ]train loss : 0.248869 ,train acc: 0.878530 ,val loss : 0.398177 ,val acc : 0.821564\n",
      "[ ecpho : 3  iter :719 ]train loss : 0.279251 ,train acc: 0.867269 ,val loss : 0.402316 ,val acc : 0.821167\n",
      "[ ecpho : 3  iter :720 ]train loss : 0.284562 ,train acc: 0.863383 ,val loss : 0.398381 ,val acc : 0.821289\n",
      "[ ecpho : 3  iter :721 ]train loss : 0.330519 ,train acc: 0.840017 ,val loss : 0.396569 ,val acc : 0.819275\n",
      "[ ecpho : 3  iter :722 ]train loss : 0.312250 ,train acc: 0.845012 ,val loss : 0.394751 ,val acc : 0.821930\n",
      "[ ecpho : 3  iter :723 ]train loss : 0.253389 ,train acc: 0.876516 ,val loss : 0.402640 ,val acc : 0.820557\n",
      "[ ecpho : 3  iter :724 ]train loss : 0.351784 ,train acc: 0.850952 ,val loss : 0.399280 ,val acc : 0.816345\n",
      "[ ecpho : 3  iter :725 ]train loss : 0.299269 ,train acc: 0.858490 ,val loss : 0.396563 ,val acc : 0.820374\n",
      "[ ecpho : 3  iter :726 ]train loss : 0.294440 ,train acc: 0.862417 ,val loss : 0.401159 ,val acc : 0.818542\n",
      "[ ecpho : 3  iter :727 ]train loss : 0.446241 ,train acc: 0.799205 ,val loss : 0.403381 ,val acc : 0.821472\n",
      "[ ecpho : 3  iter :728 ]train loss : 0.310136 ,train acc: 0.843028 ,val loss : 0.401990 ,val acc : 0.817963\n",
      "[ ecpho : 3  iter :729 ]train loss : 0.311820 ,train acc: 0.838145 ,val loss : 0.396170 ,val acc : 0.819885\n",
      "[ ecpho : 3  iter :730 ]train loss : 0.332433 ,train acc: 0.852794 ,val loss : 0.403789 ,val acc : 0.817780\n",
      "[ ecpho : 3  iter :731 ]train loss : 0.316955 ,train acc: 0.854177 ,val loss : 0.398183 ,val acc : 0.819855\n",
      "[ ecpho : 3  iter :732 ]train loss : 0.264740 ,train acc: 0.870972 ,val loss : 0.404223 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :733 ]train loss : 0.350318 ,train acc: 0.831350 ,val loss : 0.401097 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :734 ]train loss : 0.276848 ,train acc: 0.870239 ,val loss : 0.404224 ,val acc : 0.821136\n",
      "[ ecpho : 3  iter :735 ]train loss : 0.354673 ,train acc: 0.849803 ,val loss : 0.397669 ,val acc : 0.821655\n",
      "[ ecpho : 3  iter :736 ]train loss : 0.375979 ,train acc: 0.837372 ,val loss : 0.401659 ,val acc : 0.817902\n",
      "[ ecpho : 3  iter :737 ]train loss : 0.315427 ,train acc: 0.835348 ,val loss : 0.395208 ,val acc : 0.822083\n",
      "[ ecpho : 3  iter :738 ]train loss : 0.339288 ,train acc: 0.855662 ,val loss : 0.397225 ,val acc : 0.821198\n",
      "[ ecpho : 3  iter :739 ]train loss : 0.369399 ,train acc: 0.839345 ,val loss : 0.403947 ,val acc : 0.817749\n",
      "[ ecpho : 3  iter :740 ]train loss : 0.260052 ,train acc: 0.870951 ,val loss : 0.397645 ,val acc : 0.818420\n",
      "[ ecpho : 3  iter :741 ]train loss : 0.295028 ,train acc: 0.865469 ,val loss : 0.403420 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :742 ]train loss : 0.283405 ,train acc: 0.861359 ,val loss : 0.400871 ,val acc : 0.820038\n",
      "[ ecpho : 3  iter :743 ]train loss : 0.252363 ,train acc: 0.874644 ,val loss : 0.397550 ,val acc : 0.820282\n",
      "[ ecpho : 3  iter :744 ]train loss : 0.268224 ,train acc: 0.869222 ,val loss : 0.397954 ,val acc : 0.822662\n",
      "[ ecpho : 3  iter :745 ]train loss : 0.381824 ,train acc: 0.798961 ,val loss : 0.393407 ,val acc : 0.818298\n",
      "[ ecpho : 3  iter :746 ]train loss : 0.338041 ,train acc: 0.855845 ,val loss : 0.398451 ,val acc : 0.817566\n",
      "[ ecpho : 3  iter :747 ]train loss : 0.359126 ,train acc: 0.845612 ,val loss : 0.396844 ,val acc : 0.819977\n",
      "[ ecpho : 3  iter :748 ]train loss : 0.277800 ,train acc: 0.865102 ,val loss : 0.395177 ,val acc : 0.822937\n",
      "[ ecpho : 3  iter :749 ]train loss : 0.423142 ,train acc: 0.818044 ,val loss : 0.399343 ,val acc : 0.821228\n",
      "[ ecpho : 3  iter :750 ]train loss : 0.405972 ,train acc: 0.844564 ,val loss : 0.396000 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :751 ]train loss : 0.276319 ,train acc: 0.865824 ,val loss : 0.401073 ,val acc : 0.819000\n",
      "[ ecpho : 3  iter :752 ]train loss : 0.276077 ,train acc: 0.864980 ,val loss : 0.401149 ,val acc : 0.819763\n",
      "[ ecpho : 3  iter :753 ]train loss : 0.449309 ,train acc: 0.811635 ,val loss : 0.396627 ,val acc : 0.819641\n",
      "[ ecpho : 3  iter :754 ]train loss : 0.269419 ,train acc: 0.869446 ,val loss : 0.402830 ,val acc : 0.820465\n",
      "[ ecpho : 3  iter :755 ]train loss : 0.322733 ,train acc: 0.852834 ,val loss : 0.393163 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :756 ]train loss : 0.293816 ,train acc: 0.857168 ,val loss : 0.403359 ,val acc : 0.818085\n",
      "[ ecpho : 3  iter :757 ]train loss : 0.362534 ,train acc: 0.848725 ,val loss : 0.396239 ,val acc : 0.821899\n",
      "[ ecpho : 3  iter :758 ]train loss : 0.284487 ,train acc: 0.859782 ,val loss : 0.402473 ,val acc : 0.819946\n",
      "[ ecpho : 3  iter :759 ]train loss : 0.275286 ,train acc: 0.868846 ,val loss : 0.397514 ,val acc : 0.818756\n",
      "[ ecpho : 3  iter :760 ]train loss : 0.271758 ,train acc: 0.875112 ,val loss : 0.393794 ,val acc : 0.821564\n",
      "[ ecpho : 3  iter :761 ]train loss : 0.281822 ,train acc: 0.868032 ,val loss : 0.402703 ,val acc : 0.818176\n",
      "[ ecpho : 3  iter :762 ]train loss : 0.371716 ,train acc: 0.837748 ,val loss : 0.402672 ,val acc : 0.820892\n",
      "[ ecpho : 3  iter :763 ]train loss : 0.339944 ,train acc: 0.848043 ,val loss : 0.402625 ,val acc : 0.821899\n",
      "[ ecpho : 3  iter :764 ]train loss : 0.309419 ,train acc: 0.845937 ,val loss : 0.401284 ,val acc : 0.821472\n",
      "[ ecpho : 3  iter :765 ]train loss : 0.335502 ,train acc: 0.837545 ,val loss : 0.395523 ,val acc : 0.821747\n",
      "[ ecpho : 3  iter :766 ]train loss : 0.281977 ,train acc: 0.869120 ,val loss : 0.398437 ,val acc : 0.820984\n",
      "[ ecpho : 3  iter :767 ]train loss : 0.262129 ,train acc: 0.874054 ,val loss : 0.401762 ,val acc : 0.822723\n",
      "[ ecpho : 3  iter :768 ]train loss : 0.269502 ,train acc: 0.870015 ,val loss : 0.396869 ,val acc : 0.820435\n",
      "[ ecpho : 3  iter :769 ]train loss : 0.285878 ,train acc: 0.866394 ,val loss : 0.402091 ,val acc : 0.821075\n",
      "[ ecpho : 3  iter :770 ]train loss : 0.330187 ,train acc: 0.847412 ,val loss : 0.396307 ,val acc : 0.821167\n",
      "[ ecpho : 3  iter :771 ]train loss : 0.326065 ,train acc: 0.827118 ,val loss : 0.403380 ,val acc : 0.819244\n",
      "[ ecpho : 3  iter :772 ]train loss : 0.368215 ,train acc: 0.845815 ,val loss : 0.405820 ,val acc : 0.817566\n",
      "[ ecpho : 3  iter :773 ]train loss : 0.332007 ,train acc: 0.824850 ,val loss : 0.402710 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :774 ]train loss : 0.256897 ,train acc: 0.876445 ,val loss : 0.396131 ,val acc : 0.820343\n",
      "[ ecpho : 3  iter :775 ]train loss : 0.328356 ,train acc: 0.852092 ,val loss : 0.400497 ,val acc : 0.821198\n",
      "[ ecpho : 3  iter :776 ]train loss : 0.346180 ,train acc: 0.854248 ,val loss : 0.397709 ,val acc : 0.822754\n",
      "[ ecpho : 3  iter :777 ]train loss : 0.426684 ,train acc: 0.833852 ,val loss : 0.400198 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :778 ]train loss : 0.288809 ,train acc: 0.854869 ,val loss : 0.397235 ,val acc : 0.818359\n",
      "[ ecpho : 3  iter :779 ]train loss : 0.332590 ,train acc: 0.838796 ,val loss : 0.399676 ,val acc : 0.822540\n",
      "[ ecpho : 3  iter :780 ]train loss : 0.428187 ,train acc: 0.813894 ,val loss : 0.403483 ,val acc : 0.821045\n",
      "[ ecpho : 3  iter :781 ]train loss : 0.260170 ,train acc: 0.874786 ,val loss : 0.396597 ,val acc : 0.818359\n",
      "[ ecpho : 3  iter :782 ]train loss : 0.335516 ,train acc: 0.853546 ,val loss : 0.400969 ,val acc : 0.821320\n",
      "[ ecpho : 3  iter :783 ]train loss : 0.341854 ,train acc: 0.852570 ,val loss : 0.398962 ,val acc : 0.820160\n",
      "[ ecpho : 3  iter :784 ]train loss : 0.392388 ,train acc: 0.837281 ,val loss : 0.399930 ,val acc : 0.818512\n",
      "[ ecpho : 3  iter :785 ]train loss : 0.333585 ,train acc: 0.831126 ,val loss : 0.402524 ,val acc : 0.819122\n",
      "[ ecpho : 3  iter :786 ]train loss : 0.399012 ,train acc: 0.827647 ,val loss : 0.401516 ,val acc : 0.819702\n",
      "[ ecpho : 3  iter :787 ]train loss : 0.261510 ,train acc: 0.873088 ,val loss : 0.401340 ,val acc : 0.821472\n",
      "[ ecpho : 3  iter :788 ]train loss : 0.258582 ,train acc: 0.872854 ,val loss : 0.395248 ,val acc : 0.823029\n",
      "[ ecpho : 3  iter :789 ]train loss : 0.341971 ,train acc: 0.835175 ,val loss : 0.403881 ,val acc : 0.821014\n",
      "[ ecpho : 3  iter :790 ]train loss : 0.308124 ,train acc: 0.860637 ,val loss : 0.391747 ,val acc : 0.820984\n",
      "[ ecpho : 3  iter :791 ]train loss : 0.439603 ,train acc: 0.798411 ,val loss : 0.397039 ,val acc : 0.820404\n",
      "[ ecpho : 3  iter :792 ]train loss : 0.358712 ,train acc: 0.836436 ,val loss : 0.400086 ,val acc : 0.820007\n",
      "[ ecpho : 3  iter :793 ]train loss : 0.329775 ,train acc: 0.862223 ,val loss : 0.397955 ,val acc : 0.821716\n",
      "[ ecpho : 3  iter :794 ]train loss : 0.282252 ,train acc: 0.861389 ,val loss : 0.397723 ,val acc : 0.822327\n",
      "[ ecpho : 3  iter :795 ]train loss : 0.301147 ,train acc: 0.857076 ,val loss : 0.397801 ,val acc : 0.822571\n",
      "[ ecpho : 3  iter :796 ]train loss : 0.351573 ,train acc: 0.818217 ,val loss : 0.398896 ,val acc : 0.821564\n",
      "[ ecpho : 3  iter :797 ]train loss : 0.359071 ,train acc: 0.814931 ,val loss : 0.391562 ,val acc : 0.822235\n",
      "[ ecpho : 3  iter :798 ]train loss : 0.296530 ,train acc: 0.860453 ,val loss : 0.394366 ,val acc : 0.819702\n",
      "[ ecpho : 3  iter :799 ]train loss : 0.245845 ,train acc: 0.879801 ,val loss : 0.404111 ,val acc : 0.820404\n",
      "[ ecpho : 3  iter :800 ]train loss : 0.296136 ,train acc: 0.863454 ,val loss : 0.398189 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :801 ]train loss : 0.288510 ,train acc: 0.864482 ,val loss : 0.401196 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :802 ]train loss : 0.525518 ,train acc: 0.779897 ,val loss : 0.401129 ,val acc : 0.821960\n",
      "[ ecpho : 3  iter :803 ]train loss : 0.277037 ,train acc: 0.870239 ,val loss : 0.396365 ,val acc : 0.820465\n",
      "[ ecpho : 3  iter :804 ]train loss : 0.235684 ,train acc: 0.884379 ,val loss : 0.400148 ,val acc : 0.821564\n",
      "[ ecpho : 3  iter :805 ]train loss : 0.260787 ,train acc: 0.870870 ,val loss : 0.394969 ,val acc : 0.822113\n",
      "[ ecpho : 3  iter :806 ]train loss : 0.303527 ,train acc: 0.851847 ,val loss : 0.399994 ,val acc : 0.820282\n",
      "[ ecpho : 3  iter :807 ]train loss : 0.253504 ,train acc: 0.874329 ,val loss : 0.401179 ,val acc : 0.820648\n",
      "[ ecpho : 3  iter :808 ]train loss : 0.306145 ,train acc: 0.854024 ,val loss : 0.398464 ,val acc : 0.817566\n",
      "[ ecpho : 3  iter :809 ]train loss : 0.274370 ,train acc: 0.871389 ,val loss : 0.394772 ,val acc : 0.823395\n",
      "[ ecpho : 3  iter :810 ]train loss : 0.272892 ,train acc: 0.866323 ,val loss : 0.404351 ,val acc : 0.820068\n",
      "[ ecpho : 3  iter :811 ]train loss : 0.304831 ,train acc: 0.863739 ,val loss : 0.399654 ,val acc : 0.819183\n",
      "[ ecpho : 3  iter :812 ]train loss : 0.280292 ,train acc: 0.856354 ,val loss : 0.397927 ,val acc : 0.819916\n",
      "[ ecpho : 3  iter :813 ]train loss : 0.340704 ,train acc: 0.859975 ,val loss : 0.400742 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :814 ]train loss : 0.264674 ,train acc: 0.870921 ,val loss : 0.403535 ,val acc : 0.816956\n",
      "[ ecpho : 3  iter :815 ]train loss : 0.393100 ,train acc: 0.800405 ,val loss : 0.399208 ,val acc : 0.821869\n",
      "[ ecpho : 3  iter :816 ]train loss : 0.314595 ,train acc: 0.860158 ,val loss : 0.398344 ,val acc : 0.819733\n",
      "[ ecpho : 3  iter :817 ]train loss : 0.276809 ,train acc: 0.864828 ,val loss : 0.405599 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :818 ]train loss : 0.289135 ,train acc: 0.855988 ,val loss : 0.398501 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :819 ]train loss : 0.379765 ,train acc: 0.810801 ,val loss : 0.399290 ,val acc : 0.819641\n",
      "[ ecpho : 3  iter :820 ]train loss : 0.366022 ,train acc: 0.834341 ,val loss : 0.400160 ,val acc : 0.820557\n",
      "[ ecpho : 3  iter :821 ]train loss : 0.257647 ,train acc: 0.875956 ,val loss : 0.403719 ,val acc : 0.820160\n",
      "[ ecpho : 3  iter :822 ]train loss : 0.287960 ,train acc: 0.862763 ,val loss : 0.397754 ,val acc : 0.822510\n",
      "[ ecpho : 3  iter :823 ]train loss : 0.291644 ,train acc: 0.857758 ,val loss : 0.400621 ,val acc : 0.823853\n",
      "[ ecpho : 3  iter :824 ]train loss : 0.357371 ,train acc: 0.843526 ,val loss : 0.406371 ,val acc : 0.817352\n",
      "[ ecpho : 3  iter :825 ]train loss : 0.405650 ,train acc: 0.790639 ,val loss : 0.398262 ,val acc : 0.822113\n",
      "[ ecpho : 3  iter :826 ]train loss : 0.305119 ,train acc: 0.859273 ,val loss : 0.391095 ,val acc : 0.823761\n",
      "[ ecpho : 3  iter :827 ]train loss : 0.373004 ,train acc: 0.843099 ,val loss : 0.396631 ,val acc : 0.821381\n",
      "[ ecpho : 3  iter :828 ]train loss : 0.288966 ,train acc: 0.861583 ,val loss : 0.399050 ,val acc : 0.818604\n",
      "[ ecpho : 3  iter :829 ]train loss : 0.367868 ,train acc: 0.818909 ,val loss : 0.396206 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :830 ]train loss : 0.337250 ,train acc: 0.850423 ,val loss : 0.398606 ,val acc : 0.821045\n",
      "[ ecpho : 3  iter :831 ]train loss : 0.373496 ,train acc: 0.848826 ,val loss : 0.400012 ,val acc : 0.821136\n",
      "[ ecpho : 3  iter :832 ]train loss : 0.249286 ,train acc: 0.880056 ,val loss : 0.400427 ,val acc : 0.821564\n",
      "[ ecpho : 3  iter :833 ]train loss : 0.281656 ,train acc: 0.865448 ,val loss : 0.399078 ,val acc : 0.817902\n",
      "[ ecpho : 3  iter :834 ]train loss : 0.352653 ,train acc: 0.848979 ,val loss : 0.399562 ,val acc : 0.817505\n",
      "[ ecpho : 3  iter :835 ]train loss : 0.365622 ,train acc: 0.842906 ,val loss : 0.396001 ,val acc : 0.821472\n",
      "[ ecpho : 3  iter :836 ]train loss : 0.297891 ,train acc: 0.854146 ,val loss : 0.399757 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :837 ]train loss : 0.294492 ,train acc: 0.854777 ,val loss : 0.399913 ,val acc : 0.818207\n",
      "[ ecpho : 3  iter :838 ]train loss : 0.316564 ,train acc: 0.856049 ,val loss : 0.397906 ,val acc : 0.820068\n",
      "[ ecpho : 3  iter :839 ]train loss : 0.263002 ,train acc: 0.874359 ,val loss : 0.397421 ,val acc : 0.819977\n",
      "[ ecpho : 3  iter :840 ]train loss : 0.248895 ,train acc: 0.878571 ,val loss : 0.398414 ,val acc : 0.821350\n",
      "[ ecpho : 3  iter :841 ]train loss : 0.259595 ,train acc: 0.871002 ,val loss : 0.392772 ,val acc : 0.821594\n",
      "[ ecpho : 3  iter :842 ]train loss : 0.298397 ,train acc: 0.860698 ,val loss : 0.396872 ,val acc : 0.823883\n",
      "[ ecpho : 3  iter :843 ]train loss : 0.278831 ,train acc: 0.870453 ,val loss : 0.401939 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :844 ]train loss : 0.490611 ,train acc: 0.715525 ,val loss : 0.398441 ,val acc : 0.816498\n",
      "[ ecpho : 3  iter :845 ]train loss : 0.316382 ,train acc: 0.859843 ,val loss : 0.393680 ,val acc : 0.820740\n",
      "[ ecpho : 3  iter :846 ]train loss : 0.276211 ,train acc: 0.870748 ,val loss : 0.400908 ,val acc : 0.819397\n",
      "[ ecpho : 3  iter :847 ]train loss : 0.282710 ,train acc: 0.866262 ,val loss : 0.398040 ,val acc : 0.820862\n",
      "[ ecpho : 3  iter :848 ]train loss : 0.299927 ,train acc: 0.858490 ,val loss : 0.402628 ,val acc : 0.825073\n",
      "[ ecpho : 3  iter :849 ]train loss : 0.355884 ,train acc: 0.825653 ,val loss : 0.398963 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :850 ]train loss : 0.277408 ,train acc: 0.865590 ,val loss : 0.396438 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :851 ]train loss : 0.381405 ,train acc: 0.809723 ,val loss : 0.393887 ,val acc : 0.821655\n",
      "[ ecpho : 3  iter :852 ]train loss : 0.247025 ,train acc: 0.879812 ,val loss : 0.400945 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :853 ]train loss : 0.355994 ,train acc: 0.806865 ,val loss : 0.402492 ,val acc : 0.819336\n",
      "[ ecpho : 3  iter :854 ]train loss : 0.270257 ,train acc: 0.867890 ,val loss : 0.398592 ,val acc : 0.819153\n",
      "[ ecpho : 3  iter :855 ]train loss : 0.268773 ,train acc: 0.865184 ,val loss : 0.402127 ,val acc : 0.820068\n",
      "[ ecpho : 3  iter :856 ]train loss : 0.332026 ,train acc: 0.852468 ,val loss : 0.397252 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :857 ]train loss : 0.294726 ,train acc: 0.860901 ,val loss : 0.397309 ,val acc : 0.821228\n",
      "[ ecpho : 3  iter :858 ]train loss : 0.285140 ,train acc: 0.865285 ,val loss : 0.399924 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :859 ]train loss : 0.280317 ,train acc: 0.866363 ,val loss : 0.398175 ,val acc : 0.823120\n",
      "[ ecpho : 3  iter :860 ]train loss : 0.259060 ,train acc: 0.875041 ,val loss : 0.393902 ,val acc : 0.820312\n",
      "[ ecpho : 3  iter :861 ]train loss : 0.291946 ,train acc: 0.859782 ,val loss : 0.398263 ,val acc : 0.819580\n",
      "[ ecpho : 3  iter :862 ]train loss : 0.315586 ,train acc: 0.854869 ,val loss : 0.402849 ,val acc : 0.822571\n",
      "[ ecpho : 3  iter :863 ]train loss : 0.300111 ,train acc: 0.863688 ,val loss : 0.402751 ,val acc : 0.819977\n",
      "[ ecpho : 3  iter :864 ]train loss : 0.341781 ,train acc: 0.849721 ,val loss : 0.398878 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :865 ]train loss : 0.304576 ,train acc: 0.857168 ,val loss : 0.397634 ,val acc : 0.819916\n",
      "[ ecpho : 3  iter :866 ]train loss : 0.358742 ,train acc: 0.843282 ,val loss : 0.390115 ,val acc : 0.824921\n",
      "[ ecpho : 3  iter :867 ]train loss : 0.305788 ,train acc: 0.859487 ,val loss : 0.400685 ,val acc : 0.820099\n",
      "[ ecpho : 3  iter :868 ]train loss : 0.409716 ,train acc: 0.817688 ,val loss : 0.392477 ,val acc : 0.822845\n",
      "[ ecpho : 3  iter :869 ]train loss : 0.293520 ,train acc: 0.863464 ,val loss : 0.397908 ,val acc : 0.819794\n",
      "[ ecpho : 3  iter :870 ]train loss : 0.305799 ,train acc: 0.850372 ,val loss : 0.394824 ,val acc : 0.821716\n",
      "[ ecpho : 3  iter :871 ]train loss : 0.273516 ,train acc: 0.867910 ,val loss : 0.398456 ,val acc : 0.821777\n",
      "[ ecpho : 3  iter :872 ]train loss : 0.336296 ,train acc: 0.827606 ,val loss : 0.401139 ,val acc : 0.817535\n",
      "[ ecpho : 3  iter :873 ]train loss : 0.279509 ,train acc: 0.866455 ,val loss : 0.398486 ,val acc : 0.823700\n",
      "[ ecpho : 3  iter :874 ]train loss : 0.330618 ,train acc: 0.840352 ,val loss : 0.398806 ,val acc : 0.820496\n",
      "[ ecpho : 3  iter :875 ]train loss : 0.340799 ,train acc: 0.846822 ,val loss : 0.398344 ,val acc : 0.821686\n",
      "[ ecpho : 3  iter :876 ]train loss : 0.267301 ,train acc: 0.870504 ,val loss : 0.401681 ,val acc : 0.822998\n",
      "[ ecpho : 3  iter :877 ]train loss : 0.267587 ,train acc: 0.869527 ,val loss : 0.401083 ,val acc : 0.818542\n",
      "[ ecpho : 3  iter :878 ]train loss : 0.281364 ,train acc: 0.860189 ,val loss : 0.396665 ,val acc : 0.819550\n",
      "[ ecpho : 3  iter :879 ]train loss : 0.281454 ,train acc: 0.867045 ,val loss : 0.397271 ,val acc : 0.819580\n",
      "[ ecpho : 3  iter :880 ]train loss : 0.312047 ,train acc: 0.857819 ,val loss : 0.397378 ,val acc : 0.816345\n",
      "[ ecpho : 3  iter :881 ]train loss : 0.292561 ,train acc: 0.858765 ,val loss : 0.404587 ,val acc : 0.823120\n",
      "[ ecpho : 3  iter :882 ]train loss : 0.295188 ,train acc: 0.862701 ,val loss : 0.396714 ,val acc : 0.820282\n",
      "[ ecpho : 3  iter :883 ]train loss : 0.265999 ,train acc: 0.872671 ,val loss : 0.398379 ,val acc : 0.819366\n",
      "[ ecpho : 3  iter :884 ]train loss : 0.247612 ,train acc: 0.877909 ,val loss : 0.391323 ,val acc : 0.824188\n",
      "[ ecpho : 3  iter :885 ]train loss : 0.297543 ,train acc: 0.860219 ,val loss : 0.396071 ,val acc : 0.815521\n",
      "[ ecpho : 3  iter :886 ]train loss : 0.399563 ,train acc: 0.811229 ,val loss : 0.401659 ,val acc : 0.820496\n",
      "[ ecpho : 3  iter :887 ]train loss : 0.319343 ,train acc: 0.851044 ,val loss : 0.392502 ,val acc : 0.822662\n",
      "[ ecpho : 3  iter :888 ]train loss : 0.371728 ,train acc: 0.834890 ,val loss : 0.398010 ,val acc : 0.821625\n",
      "[ ecpho : 3  iter :889 ]train loss : 0.323476 ,train acc: 0.852885 ,val loss : 0.396297 ,val acc : 0.820801\n",
      "[ ecpho : 3  iter :890 ]train loss : 0.334554 ,train acc: 0.849955 ,val loss : 0.397842 ,val acc : 0.819885\n",
      "[ ecpho : 3  iter :891 ]train loss : 0.315506 ,train acc: 0.853760 ,val loss : 0.398206 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :892 ]train loss : 0.272838 ,train acc: 0.874481 ,val loss : 0.398473 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :893 ]train loss : 0.296541 ,train acc: 0.863902 ,val loss : 0.395632 ,val acc : 0.817749\n",
      "[ ecpho : 3  iter :894 ]train loss : 0.377157 ,train acc: 0.835042 ,val loss : 0.397591 ,val acc : 0.822021\n",
      "[ ecpho : 3  iter :895 ]train loss : 0.381039 ,train acc: 0.795187 ,val loss : 0.397106 ,val acc : 0.819641\n",
      "[ ecpho : 3  iter :896 ]train loss : 0.272510 ,train acc: 0.864085 ,val loss : 0.394580 ,val acc : 0.823212\n",
      "[ ecpho : 3  iter :897 ]train loss : 0.353980 ,train acc: 0.845337 ,val loss : 0.388399 ,val acc : 0.824341\n",
      "[ ecpho : 3  iter :898 ]train loss : 0.310042 ,train acc: 0.857127 ,val loss : 0.393152 ,val acc : 0.824249\n",
      "[ ecpho : 3  iter :899 ]train loss : 0.257349 ,train acc: 0.874054 ,val loss : 0.396493 ,val acc : 0.816315\n",
      "[ ecpho : 3  iter :900 ]train loss : 0.318720 ,train acc: 0.848023 ,val loss : 0.397309 ,val acc : 0.818695\n",
      "[ ecpho : 3  iter :901 ]train loss : 0.325154 ,train acc: 0.853333 ,val loss : 0.393658 ,val acc : 0.822174\n",
      "[ ecpho : 3  iter :902 ]train loss : 0.253751 ,train acc: 0.878601 ,val loss : 0.399687 ,val acc : 0.821533\n",
      "[ ecpho : 3  iter :903 ]train loss : 0.241674 ,train acc: 0.883748 ,val loss : 0.397134 ,val acc : 0.821411\n",
      "[ ecpho : 3  iter :904 ]train loss : 0.497765 ,train acc: 0.780518 ,val loss : 0.401236 ,val acc : 0.820984\n",
      "[ ecpho : 3  iter :905 ]train loss : 0.518252 ,train acc: 0.833273 ,val loss : 0.397770 ,val acc : 0.818787\n",
      "[ ecpho : 3  iter :906 ]train loss : 0.275466 ,train acc: 0.868215 ,val loss : 0.400541 ,val acc : 0.820435\n",
      "[ ecpho : 3  iter :907 ]train loss : 0.350574 ,train acc: 0.848999 ,val loss : 0.396582 ,val acc : 0.821655\n",
      "[ ecpho : 3  iter :908 ]train loss : 0.376901 ,train acc: 0.802480 ,val loss : 0.393796 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :909 ]train loss : 0.291779 ,train acc: 0.870921 ,val loss : 0.398796 ,val acc : 0.820892\n",
      "[ ecpho : 3  iter :910 ]train loss : 0.458101 ,train acc: 0.743215 ,val loss : 0.401261 ,val acc : 0.816620\n",
      "[ ecpho : 3  iter :911 ]train loss : 0.288703 ,train acc: 0.865794 ,val loss : 0.397491 ,val acc : 0.820526\n",
      "[ ecpho : 3  iter :912 ]train loss : 0.352348 ,train acc: 0.844106 ,val loss : 0.398536 ,val acc : 0.822388\n",
      "[ ecpho : 3  iter :913 ]train loss : 0.290200 ,train acc: 0.864258 ,val loss : 0.397264 ,val acc : 0.822876\n",
      "[ ecpho : 3  iter :914 ]train loss : 0.357463 ,train acc: 0.845622 ,val loss : 0.397857 ,val acc : 0.818481\n",
      "[ ecpho : 3  iter :915 ]train loss : 0.338448 ,train acc: 0.841319 ,val loss : 0.402764 ,val acc : 0.821594\n",
      "[ ecpho : 3  iter :916 ]train loss : 0.436494 ,train acc: 0.837789 ,val loss : 0.401663 ,val acc : 0.818451\n",
      "[ ecpho : 3  iter :917 ]train loss : 0.310197 ,train acc: 0.862061 ,val loss : 0.399934 ,val acc : 0.818237\n",
      "[ ecpho : 3  iter :918 ]train loss : 0.288687 ,train acc: 0.859497 ,val loss : 0.398278 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :919 ]train loss : 0.267795 ,train acc: 0.868296 ,val loss : 0.394462 ,val acc : 0.821045\n",
      "[ ecpho : 3  iter :920 ]train loss : 0.271586 ,train acc: 0.867055 ,val loss : 0.398229 ,val acc : 0.822937\n",
      "[ ecpho : 3  iter :921 ]train loss : 0.302721 ,train acc: 0.846527 ,val loss : 0.396731 ,val acc : 0.823364\n",
      "[ ecpho : 3  iter :922 ]train loss : 0.417723 ,train acc: 0.802531 ,val loss : 0.398736 ,val acc : 0.821899\n",
      "[ ecpho : 3  iter :923 ]train loss : 0.321153 ,train acc: 0.851410 ,val loss : 0.404464 ,val acc : 0.818146\n",
      "[ ecpho : 3  iter :924 ]train loss : 0.376430 ,train acc: 0.809265 ,val loss : 0.398752 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :925 ]train loss : 0.281946 ,train acc: 0.866008 ,val loss : 0.396517 ,val acc : 0.819824\n",
      "[ ecpho : 3  iter :926 ]train loss : 0.339145 ,train acc: 0.845601 ,val loss : 0.397637 ,val acc : 0.820312\n",
      "[ ecpho : 3  iter :927 ]train loss : 0.326331 ,train acc: 0.847209 ,val loss : 0.404637 ,val acc : 0.819519\n",
      "[ ecpho : 3  iter :928 ]train loss : 0.277948 ,train acc: 0.863352 ,val loss : 0.393027 ,val acc : 0.821808\n",
      "[ ecpho : 3  iter :929 ]train loss : 0.369664 ,train acc: 0.829804 ,val loss : 0.396957 ,val acc : 0.817017\n",
      "[ ecpho : 3  iter :930 ]train loss : 0.409686 ,train acc: 0.797638 ,val loss : 0.402906 ,val acc : 0.819641\n",
      "[ ecpho : 3  iter :931 ]train loss : 0.338406 ,train acc: 0.849152 ,val loss : 0.396321 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :932 ]train loss : 0.259775 ,train acc: 0.873861 ,val loss : 0.400860 ,val acc : 0.818878\n",
      "[ ecpho : 3  iter :933 ]train loss : 0.310885 ,train acc: 0.852071 ,val loss : 0.399350 ,val acc : 0.816223\n",
      "[ ecpho : 3  iter :934 ]train loss : 0.389111 ,train acc: 0.830923 ,val loss : 0.399330 ,val acc : 0.821625\n",
      "[ ecpho : 3  iter :935 ]train loss : 0.333547 ,train acc: 0.849233 ,val loss : 0.395937 ,val acc : 0.824005\n",
      "[ ecpho : 3  iter :936 ]train loss : 0.278788 ,train acc: 0.866577 ,val loss : 0.396757 ,val acc : 0.823639\n",
      "[ ecpho : 3  iter :937 ]train loss : 0.304301 ,train acc: 0.858826 ,val loss : 0.392226 ,val acc : 0.821106\n",
      "[ ecpho : 3  iter :938 ]train loss : 0.277829 ,train acc: 0.868724 ,val loss : 0.397572 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :939 ]train loss : 0.395152 ,train acc: 0.832886 ,val loss : 0.395087 ,val acc : 0.822113\n",
      "[ ecpho : 3  iter :940 ]train loss : 0.254299 ,train acc: 0.878510 ,val loss : 0.401231 ,val acc : 0.820709\n",
      "[ ecpho : 3  iter :941 ]train loss : 0.350560 ,train acc: 0.850362 ,val loss : 0.401461 ,val acc : 0.822235\n",
      "[ ecpho : 3  iter :942 ]train loss : 0.394676 ,train acc: 0.836690 ,val loss : 0.394525 ,val acc : 0.822632\n",
      "[ ecpho : 3  iter :943 ]train loss : 0.328530 ,train acc: 0.847880 ,val loss : 0.396050 ,val acc : 0.822327\n",
      "[ ecpho : 3  iter :944 ]train loss : 0.352202 ,train acc: 0.822469 ,val loss : 0.397535 ,val acc : 0.820587\n",
      "[ ecpho : 3  iter :945 ]train loss : 0.326753 ,train acc: 0.854553 ,val loss : 0.400395 ,val acc : 0.820251\n",
      "[ ecpho : 3  iter :946 ]train loss : 0.342334 ,train acc: 0.813741 ,val loss : 0.399113 ,val acc : 0.821686\n",
      "[ ecpho : 3  iter :947 ]train loss : 0.542408 ,train acc: 0.818207 ,val loss : 0.399637 ,val acc : 0.820740\n",
      "[ ecpho : 3  iter :948 ]train loss : 0.356042 ,train acc: 0.849874 ,val loss : 0.394268 ,val acc : 0.821838\n",
      "[ ecpho : 3  iter :949 ]train loss : 0.381060 ,train acc: 0.813751 ,val loss : 0.396445 ,val acc : 0.821869\n",
      "[ ecpho : 3  iter :950 ]train loss : 0.350873 ,train acc: 0.839620 ,val loss : 0.391852 ,val acc : 0.822693\n",
      "[ ecpho : 3  iter :951 ]train loss : 0.269884 ,train acc: 0.870575 ,val loss : 0.398404 ,val acc : 0.819458\n",
      "[ ecpho : 3  iter :952 ]train loss : 0.325009 ,train acc: 0.860413 ,val loss : 0.401275 ,val acc : 0.817413\n",
      "[ ecpho : 3  iter :953 ]train loss : 0.301616 ,train acc: 0.855123 ,val loss : 0.395324 ,val acc : 0.825897\n",
      "[ ecpho : 3  iter :954 ]train loss : 0.315341 ,train acc: 0.839467 ,val loss : 0.393351 ,val acc : 0.822784\n",
      "[ ecpho : 3  iter :955 ]train loss : 0.263776 ,train acc: 0.869080 ,val loss : 0.404596 ,val acc : 0.821228\n",
      "[ ecpho : 3  iter :956 ]train loss : 0.252691 ,train acc: 0.874481 ,val loss : 0.396218 ,val acc : 0.822052\n",
      "[ ecpho : 3  iter :957 ]train loss : 0.266674 ,train acc: 0.877167 ,val loss : 0.397530 ,val acc : 0.819305\n",
      "[ ecpho : 3  iter :958 ]train loss : 0.333137 ,train acc: 0.850505 ,val loss : 0.392403 ,val acc : 0.819977\n",
      "[ ecpho : 3  iter :959 ]train loss : 0.344059 ,train acc: 0.847901 ,val loss : 0.404546 ,val acc : 0.819092\n",
      "[ ecpho : 3  iter :960 ]train loss : 0.284274 ,train acc: 0.864858 ,val loss : 0.399349 ,val acc : 0.821045\n",
      "[ ecpho : 3  iter :961 ]train loss : 0.250346 ,train acc: 0.878815 ,val loss : 0.398420 ,val acc : 0.819489\n",
      "[ ecpho : 3  iter :962 ]train loss : 0.407094 ,train acc: 0.807465 ,val loss : 0.400518 ,val acc : 0.817993\n",
      "[ ecpho : 3  iter :963 ]train loss : 0.489101 ,train acc: 0.813609 ,val loss : 0.400001 ,val acc : 0.821655\n",
      "[ ecpho : 3  iter :964 ]train loss : 0.279635 ,train acc: 0.872192 ,val loss : 0.397253 ,val acc : 0.819611\n",
      "[ ecpho : 3  iter :965 ]train loss : 0.249997 ,train acc: 0.877696 ,val loss : 0.395882 ,val acc : 0.822632\n",
      "[ ecpho : 3  iter :966 ]train loss : 0.375847 ,train acc: 0.854635 ,val loss : 0.399009 ,val acc : 0.819244\n",
      "[ ecpho : 3  iter :967 ]train loss : 0.405536 ,train acc: 0.839172 ,val loss : 0.391783 ,val acc : 0.823700\n",
      "[ ecpho : 3  iter :968 ]train loss : 0.500692 ,train acc: 0.787638 ,val loss : 0.396642 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :969 ]train loss : 0.266973 ,train acc: 0.870158 ,val loss : 0.397424 ,val acc : 0.820251\n",
      "[ ecpho : 3  iter :970 ]train loss : 0.339625 ,train acc: 0.847616 ,val loss : 0.394459 ,val acc : 0.820862\n",
      "[ ecpho : 3  iter :971 ]train loss : 0.367875 ,train acc: 0.847026 ,val loss : 0.397497 ,val acc : 0.821747\n",
      "[ ecpho : 3  iter :972 ]train loss : 0.306438 ,train acc: 0.858002 ,val loss : 0.396215 ,val acc : 0.820221\n",
      "[ ecpho : 3  iter :973 ]train loss : 0.329293 ,train acc: 0.853516 ,val loss : 0.402333 ,val acc : 0.823395\n",
      "[ ecpho : 3  iter :974 ]train loss : 0.300660 ,train acc: 0.865570 ,val loss : 0.395911 ,val acc : 0.821167\n",
      "[ ecpho : 3  iter :975 ]train loss : 0.307964 ,train acc: 0.855957 ,val loss : 0.394086 ,val acc : 0.821655\n",
      "[ ecpho : 3  iter :976 ]train loss : 0.258572 ,train acc: 0.874542 ,val loss : 0.394757 ,val acc : 0.819550\n",
      "[ ecpho : 3  iter :977 ]train loss : 0.390508 ,train acc: 0.807984 ,val loss : 0.393352 ,val acc : 0.823700\n",
      "[ ecpho : 3  iter :978 ]train loss : 0.300922 ,train acc: 0.861104 ,val loss : 0.389172 ,val acc : 0.824432\n",
      "[ ecpho : 3  iter :979 ]train loss : 0.303959 ,train acc: 0.849620 ,val loss : 0.401882 ,val acc : 0.818909\n",
      "[ ecpho : 3  iter :980 ]train loss : 0.353065 ,train acc: 0.846710 ,val loss : 0.391060 ,val acc : 0.824799\n",
      "[ ecpho : 3  iter :981 ]train loss : 0.448266 ,train acc: 0.812500 ,val loss : 0.394011 ,val acc : 0.820557\n",
      "[ ecpho : 3  iter :982 ]train loss : 0.287920 ,train acc: 0.864878 ,val loss : 0.396606 ,val acc : 0.819946\n",
      "[ ecpho : 3  iter :983 ]train loss : 0.271132 ,train acc: 0.867890 ,val loss : 0.395175 ,val acc : 0.821198\n",
      "[ ecpho : 3  iter :984 ]train loss : 0.261807 ,train acc: 0.874044 ,val loss : 0.399576 ,val acc : 0.818848\n",
      "[ ecpho : 3  iter :985 ]train loss : 0.357892 ,train acc: 0.845001 ,val loss : 0.395843 ,val acc : 0.818329\n",
      "[ ecpho : 3  iter :986 ]train loss : 0.297089 ,train acc: 0.861033 ,val loss : 0.400051 ,val acc : 0.819855\n",
      "[ ecpho : 3  iter :987 ]train loss : 0.386624 ,train acc: 0.826406 ,val loss : 0.402284 ,val acc : 0.820129\n",
      "[ ecpho : 3  iter :988 ]train loss : 0.301435 ,train acc: 0.849925 ,val loss : 0.397105 ,val acc : 0.820923\n",
      "[ ecpho : 3  iter :989 ]train loss : 0.371543 ,train acc: 0.839997 ,val loss : 0.390434 ,val acc : 0.821777\n",
      "[ ecpho : 3  iter :990 ]train loss : 0.320192 ,train acc: 0.854553 ,val loss : 0.398213 ,val acc : 0.822144\n",
      "[ ecpho : 3  iter :991 ]train loss : 0.425127 ,train acc: 0.755168 ,val loss : 0.400787 ,val acc : 0.819611\n",
      "[ ecpho : 3  iter :992 ]train loss : 0.263985 ,train acc: 0.870077 ,val loss : 0.390678 ,val acc : 0.824188\n",
      "[ ecpho : 3  iter :993 ]train loss : 0.332219 ,train acc: 0.850138 ,val loss : 0.391306 ,val acc : 0.822144\n",
      "[ ecpho : 3  iter :994 ]train loss : 0.310815 ,train acc: 0.835195 ,val loss : 0.400374 ,val acc : 0.818634\n",
      "[ ecpho : 3  iter :995 ]train loss : 0.265328 ,train acc: 0.868571 ,val loss : 0.396634 ,val acc : 0.820374\n",
      "[ ecpho : 3  iter :996 ]train loss : 0.292489 ,train acc: 0.857564 ,val loss : 0.397874 ,val acc : 0.820465\n",
      "[ ecpho : 3  iter :997 ]train loss : 0.343240 ,train acc: 0.834849 ,val loss : 0.394640 ,val acc : 0.823212\n",
      "[ ecpho : 3  iter :998 ]train loss : 0.372886 ,train acc: 0.806346 ,val loss : 0.397790 ,val acc : 0.819214\n",
      "[ ecpho : 3  iter :999 ]train loss : 0.329855 ,train acc: 0.858907 ,val loss : 0.397110 ,val acc : 0.820038\n",
      "[ ecpho : 3  iter :1000 ]train loss : 0.271693 ,train acc: 0.869975 ,val loss : 0.403908 ,val acc : 0.822449\n",
      "=============================================\n",
      "[ 3 ] average train loss : 0.333958 train acc : 0.845111\n",
      "[ ecpho : 4  iter :1 ]train loss : 0.311487 ,train acc: 0.857188 ,val loss : 0.397615 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :2 ]train loss : 0.409716 ,train acc: 0.826376 ,val loss : 0.398209 ,val acc : 0.819641\n",
      "[ ecpho : 4  iter :3 ]train loss : 0.279873 ,train acc: 0.859711 ,val loss : 0.393248 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :4 ]train loss : 0.383775 ,train acc: 0.815165 ,val loss : 0.394550 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :5 ]train loss : 0.270040 ,train acc: 0.870341 ,val loss : 0.397976 ,val acc : 0.821289\n",
      "[ ecpho : 4  iter :6 ]train loss : 0.309475 ,train acc: 0.859009 ,val loss : 0.393263 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :7 ]train loss : 0.423064 ,train acc: 0.830546 ,val loss : 0.395744 ,val acc : 0.823120\n",
      "[ ecpho : 4  iter :8 ]train loss : 0.366031 ,train acc: 0.819397 ,val loss : 0.396687 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :9 ]train loss : 0.256828 ,train acc: 0.875722 ,val loss : 0.394601 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :10 ]train loss : 0.406986 ,train acc: 0.808930 ,val loss : 0.399160 ,val acc : 0.820831\n",
      "[ ecpho : 4  iter :11 ]train loss : 0.361856 ,train acc: 0.809408 ,val loss : 0.396731 ,val acc : 0.822266\n",
      "[ ecpho : 4  iter :12 ]train loss : 0.266320 ,train acc: 0.871246 ,val loss : 0.398808 ,val acc : 0.821198\n",
      "[ ecpho : 4  iter :13 ]train loss : 0.372544 ,train acc: 0.846192 ,val loss : 0.395470 ,val acc : 0.823090\n",
      "[ ecpho : 4  iter :14 ]train loss : 0.332579 ,train acc: 0.853821 ,val loss : 0.397497 ,val acc : 0.820465\n",
      "[ ecpho : 4  iter :15 ]train loss : 0.287061 ,train acc: 0.863495 ,val loss : 0.394508 ,val acc : 0.818939\n",
      "[ ecpho : 4  iter :16 ]train loss : 0.313752 ,train acc: 0.858510 ,val loss : 0.397227 ,val acc : 0.821198\n",
      "[ ecpho : 4  iter :17 ]train loss : 0.429800 ,train acc: 0.821839 ,val loss : 0.394432 ,val acc : 0.820282\n",
      "[ ecpho : 4  iter :18 ]train loss : 0.309275 ,train acc: 0.862091 ,val loss : 0.398690 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :19 ]train loss : 0.318857 ,train acc: 0.835165 ,val loss : 0.394098 ,val acc : 0.821228\n",
      "[ ecpho : 4  iter :20 ]train loss : 0.288835 ,train acc: 0.864665 ,val loss : 0.388776 ,val acc : 0.826080\n",
      "[ ecpho : 4  iter :21 ]train loss : 0.277772 ,train acc: 0.867737 ,val loss : 0.393524 ,val acc : 0.821320\n",
      "[ ecpho : 4  iter :22 ]train loss : 0.356259 ,train acc: 0.847494 ,val loss : 0.400381 ,val acc : 0.816711\n",
      "[ ecpho : 4  iter :23 ]train loss : 0.381617 ,train acc: 0.827027 ,val loss : 0.395055 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :24 ]train loss : 0.368786 ,train acc: 0.838908 ,val loss : 0.392214 ,val acc : 0.824951\n",
      "[ ecpho : 4  iter :25 ]train loss : 0.300508 ,train acc: 0.864878 ,val loss : 0.399107 ,val acc : 0.821777\n",
      "[ ecpho : 4  iter :26 ]train loss : 0.324928 ,train acc: 0.846680 ,val loss : 0.395620 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :27 ]train loss : 0.266644 ,train acc: 0.871938 ,val loss : 0.397646 ,val acc : 0.821503\n",
      "[ ecpho : 4  iter :28 ]train loss : 0.262952 ,train acc: 0.871104 ,val loss : 0.398624 ,val acc : 0.821167\n",
      "[ ecpho : 4  iter :29 ]train loss : 0.336414 ,train acc: 0.847789 ,val loss : 0.397569 ,val acc : 0.822876\n",
      "[ ecpho : 4  iter :30 ]train loss : 0.367497 ,train acc: 0.818726 ,val loss : 0.397206 ,val acc : 0.821930\n",
      "[ ecpho : 4  iter :31 ]train loss : 0.280488 ,train acc: 0.863281 ,val loss : 0.397564 ,val acc : 0.825195\n",
      "[ ecpho : 4  iter :32 ]train loss : 0.291847 ,train acc: 0.856893 ,val loss : 0.394940 ,val acc : 0.819580\n",
      "[ ecpho : 4  iter :33 ]train loss : 0.264196 ,train acc: 0.871185 ,val loss : 0.397671 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :34 ]train loss : 0.367320 ,train acc: 0.843160 ,val loss : 0.396862 ,val acc : 0.820679\n",
      "[ ecpho : 4  iter :35 ]train loss : 0.281307 ,train acc: 0.870758 ,val loss : 0.401337 ,val acc : 0.819153\n",
      "[ ecpho : 4  iter :36 ]train loss : 0.311513 ,train acc: 0.844483 ,val loss : 0.397918 ,val acc : 0.819366\n",
      "[ ecpho : 4  iter :37 ]train loss : 0.381017 ,train acc: 0.845632 ,val loss : 0.401608 ,val acc : 0.817871\n",
      "[ ecpho : 4  iter :38 ]train loss : 0.329636 ,train acc: 0.850383 ,val loss : 0.392858 ,val acc : 0.821442\n",
      "[ ecpho : 4  iter :39 ]train loss : 0.322972 ,train acc: 0.852834 ,val loss : 0.394953 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :40 ]train loss : 0.356846 ,train acc: 0.853740 ,val loss : 0.403289 ,val acc : 0.819244\n",
      "[ ecpho : 4  iter :41 ]train loss : 0.429246 ,train acc: 0.840302 ,val loss : 0.397039 ,val acc : 0.823730\n",
      "[ ecpho : 4  iter :42 ]train loss : 0.371474 ,train acc: 0.775340 ,val loss : 0.400391 ,val acc : 0.819336\n",
      "[ ecpho : 4  iter :43 ]train loss : 0.302163 ,train acc: 0.858704 ,val loss : 0.392922 ,val acc : 0.820312\n",
      "[ ecpho : 4  iter :44 ]train loss : 0.298169 ,train acc: 0.859090 ,val loss : 0.397744 ,val acc : 0.821228\n",
      "[ ecpho : 4  iter :45 ]train loss : 0.265397 ,train acc: 0.871694 ,val loss : 0.395724 ,val acc : 0.822540\n",
      "[ ecpho : 4  iter :46 ]train loss : 0.287963 ,train acc: 0.858287 ,val loss : 0.397600 ,val acc : 0.820435\n",
      "[ ecpho : 4  iter :47 ]train loss : 0.330995 ,train acc: 0.853282 ,val loss : 0.396676 ,val acc : 0.819611\n",
      "[ ecpho : 4  iter :48 ]train loss : 0.335070 ,train acc: 0.849376 ,val loss : 0.390927 ,val acc : 0.825897\n",
      "[ ecpho : 4  iter :49 ]train loss : 0.273011 ,train acc: 0.869975 ,val loss : 0.398370 ,val acc : 0.821106\n",
      "[ ecpho : 4  iter :50 ]train loss : 0.350615 ,train acc: 0.852519 ,val loss : 0.398491 ,val acc : 0.819305\n",
      "[ ecpho : 4  iter :51 ]train loss : 0.345464 ,train acc: 0.830892 ,val loss : 0.396880 ,val acc : 0.819366\n",
      "[ ecpho : 4  iter :52 ]train loss : 0.351606 ,train acc: 0.822897 ,val loss : 0.398637 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :53 ]train loss : 0.279141 ,train acc: 0.869059 ,val loss : 0.395474 ,val acc : 0.821777\n",
      "[ ecpho : 4  iter :54 ]train loss : 0.287080 ,train acc: 0.858744 ,val loss : 0.396934 ,val acc : 0.819885\n",
      "[ ecpho : 4  iter :55 ]train loss : 0.260817 ,train acc: 0.873861 ,val loss : 0.390378 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :56 ]train loss : 0.336010 ,train acc: 0.851685 ,val loss : 0.402584 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :57 ]train loss : 0.365012 ,train acc: 0.816651 ,val loss : 0.398028 ,val acc : 0.819733\n",
      "[ ecpho : 4  iter :58 ]train loss : 0.254583 ,train acc: 0.875031 ,val loss : 0.390218 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :59 ]train loss : 0.262131 ,train acc: 0.871389 ,val loss : 0.391228 ,val acc : 0.821442\n",
      "[ ecpho : 4  iter :60 ]train loss : 0.358270 ,train acc: 0.839640 ,val loss : 0.392905 ,val acc : 0.824341\n",
      "[ ecpho : 4  iter :61 ]train loss : 0.297075 ,train acc: 0.859619 ,val loss : 0.400218 ,val acc : 0.819366\n",
      "[ ecpho : 4  iter :62 ]train loss : 0.378315 ,train acc: 0.840729 ,val loss : 0.394738 ,val acc : 0.821045\n",
      "[ ecpho : 4  iter :63 ]train loss : 0.298286 ,train acc: 0.865224 ,val loss : 0.394609 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :64 ]train loss : 0.300225 ,train acc: 0.851034 ,val loss : 0.396779 ,val acc : 0.819550\n",
      "[ ecpho : 4  iter :65 ]train loss : 0.294567 ,train acc: 0.846558 ,val loss : 0.393009 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :66 ]train loss : 0.417838 ,train acc: 0.836202 ,val loss : 0.391554 ,val acc : 0.824768\n",
      "[ ecpho : 4  iter :67 ]train loss : 0.421409 ,train acc: 0.800751 ,val loss : 0.394348 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :68 ]train loss : 0.287129 ,train acc: 0.862223 ,val loss : 0.394663 ,val acc : 0.821899\n",
      "[ ecpho : 4  iter :69 ]train loss : 0.258448 ,train acc: 0.872569 ,val loss : 0.395423 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :70 ]train loss : 0.274291 ,train acc: 0.866455 ,val loss : 0.395648 ,val acc : 0.820587\n",
      "[ ecpho : 4  iter :71 ]train loss : 0.363338 ,train acc: 0.812419 ,val loss : 0.395313 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :72 ]train loss : 0.307172 ,train acc: 0.864553 ,val loss : 0.394998 ,val acc : 0.820404\n",
      "[ ecpho : 4  iter :73 ]train loss : 0.379514 ,train acc: 0.804128 ,val loss : 0.396537 ,val acc : 0.822906\n",
      "[ ecpho : 4  iter :74 ]train loss : 0.262655 ,train acc: 0.876546 ,val loss : 0.391137 ,val acc : 0.820221\n",
      "[ ecpho : 4  iter :75 ]train loss : 0.406309 ,train acc: 0.802612 ,val loss : 0.395033 ,val acc : 0.822174\n",
      "[ ecpho : 4  iter :76 ]train loss : 0.307065 ,train acc: 0.846670 ,val loss : 0.394140 ,val acc : 0.821136\n",
      "[ ecpho : 4  iter :77 ]train loss : 0.347674 ,train acc: 0.837494 ,val loss : 0.395254 ,val acc : 0.820587\n",
      "[ ecpho : 4  iter :78 ]train loss : 0.362424 ,train acc: 0.825104 ,val loss : 0.400241 ,val acc : 0.820587\n",
      "[ ecpho : 4  iter :79 ]train loss : 0.288907 ,train acc: 0.863739 ,val loss : 0.390529 ,val acc : 0.819275\n",
      "[ ecpho : 4  iter :80 ]train loss : 0.487298 ,train acc: 0.719991 ,val loss : 0.396379 ,val acc : 0.822906\n",
      "[ ecpho : 4  iter :81 ]train loss : 0.318767 ,train acc: 0.836680 ,val loss : 0.405366 ,val acc : 0.818756\n",
      "[ ecpho : 4  iter :82 ]train loss : 0.326388 ,train acc: 0.853445 ,val loss : 0.397231 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :83 ]train loss : 0.335198 ,train acc: 0.853841 ,val loss : 0.395494 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :84 ]train loss : 0.314371 ,train acc: 0.856039 ,val loss : 0.394601 ,val acc : 0.820038\n",
      "[ ecpho : 4  iter :85 ]train loss : 0.272807 ,train acc: 0.870026 ,val loss : 0.396224 ,val acc : 0.821594\n",
      "[ ecpho : 4  iter :86 ]train loss : 0.396677 ,train acc: 0.836253 ,val loss : 0.395958 ,val acc : 0.819641\n",
      "[ ecpho : 4  iter :87 ]train loss : 0.289387 ,train acc: 0.863241 ,val loss : 0.398793 ,val acc : 0.818634\n",
      "[ ecpho : 4  iter :88 ]train loss : 0.267046 ,train acc: 0.872467 ,val loss : 0.394525 ,val acc : 0.821167\n",
      "[ ecpho : 4  iter :89 ]train loss : 0.287052 ,train acc: 0.846049 ,val loss : 0.396018 ,val acc : 0.818756\n",
      "[ ecpho : 4  iter :90 ]train loss : 0.316272 ,train acc: 0.843211 ,val loss : 0.395548 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :91 ]train loss : 0.308862 ,train acc: 0.852946 ,val loss : 0.392915 ,val acc : 0.820435\n",
      "[ ecpho : 4  iter :92 ]train loss : 0.272008 ,train acc: 0.875122 ,val loss : 0.397495 ,val acc : 0.820709\n",
      "[ ecpho : 4  iter :93 ]train loss : 0.470959 ,train acc: 0.781362 ,val loss : 0.397423 ,val acc : 0.820587\n",
      "[ ecpho : 4  iter :94 ]train loss : 0.398993 ,train acc: 0.778534 ,val loss : 0.394725 ,val acc : 0.821014\n",
      "[ ecpho : 4  iter :95 ]train loss : 0.284575 ,train acc: 0.867686 ,val loss : 0.394679 ,val acc : 0.821106\n",
      "[ ecpho : 4  iter :96 ]train loss : 0.440408 ,train acc: 0.793559 ,val loss : 0.401242 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :97 ]train loss : 0.400403 ,train acc: 0.830953 ,val loss : 0.399376 ,val acc : 0.821869\n",
      "[ ecpho : 4  iter :98 ]train loss : 0.295809 ,train acc: 0.855591 ,val loss : 0.393901 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :99 ]train loss : 0.242872 ,train acc: 0.877686 ,val loss : 0.388768 ,val acc : 0.824341\n",
      "[ ecpho : 4  iter :100 ]train loss : 0.274118 ,train acc: 0.868245 ,val loss : 0.398804 ,val acc : 0.818359\n",
      "[ ecpho : 4  iter :101 ]train loss : 0.427952 ,train acc: 0.771668 ,val loss : 0.389454 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :102 ]train loss : 0.285128 ,train acc: 0.863464 ,val loss : 0.391632 ,val acc : 0.821747\n",
      "[ ecpho : 4  iter :103 ]train loss : 0.317251 ,train acc: 0.833181 ,val loss : 0.400295 ,val acc : 0.819946\n",
      "[ ecpho : 4  iter :104 ]train loss : 0.283253 ,train acc: 0.870117 ,val loss : 0.385664 ,val acc : 0.824921\n",
      "[ ecpho : 4  iter :105 ]train loss : 0.275181 ,train acc: 0.863485 ,val loss : 0.396167 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :106 ]train loss : 0.322300 ,train acc: 0.856110 ,val loss : 0.400097 ,val acc : 0.819122\n",
      "[ ecpho : 4  iter :107 ]train loss : 0.311693 ,train acc: 0.848857 ,val loss : 0.399259 ,val acc : 0.820129\n",
      "[ ecpho : 4  iter :108 ]train loss : 0.304123 ,train acc: 0.857595 ,val loss : 0.391972 ,val acc : 0.822083\n",
      "[ ecpho : 4  iter :109 ]train loss : 0.365163 ,train acc: 0.852356 ,val loss : 0.397040 ,val acc : 0.820312\n",
      "[ ecpho : 4  iter :110 ]train loss : 0.264510 ,train acc: 0.871958 ,val loss : 0.394064 ,val acc : 0.822937\n",
      "[ ecpho : 4  iter :111 ]train loss : 0.280281 ,train acc: 0.868469 ,val loss : 0.396046 ,val acc : 0.821472\n",
      "[ ecpho : 4  iter :112 ]train loss : 0.267520 ,train acc: 0.869771 ,val loss : 0.400034 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :113 ]train loss : 0.286366 ,train acc: 0.859538 ,val loss : 0.389546 ,val acc : 0.820953\n",
      "[ ecpho : 4  iter :114 ]train loss : 0.296684 ,train acc: 0.862020 ,val loss : 0.391243 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :115 ]train loss : 0.275428 ,train acc: 0.871755 ,val loss : 0.398700 ,val acc : 0.822021\n",
      "[ ecpho : 4  iter :116 ]train loss : 0.343397 ,train acc: 0.781332 ,val loss : 0.398287 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :117 ]train loss : 0.467996 ,train acc: 0.797719 ,val loss : 0.401136 ,val acc : 0.819336\n",
      "[ ecpho : 4  iter :118 ]train loss : 0.288764 ,train acc: 0.858124 ,val loss : 0.397293 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :119 ]train loss : 0.432723 ,train acc: 0.828695 ,val loss : 0.399502 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :120 ]train loss : 0.315702 ,train acc: 0.852356 ,val loss : 0.394299 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :121 ]train loss : 0.304187 ,train acc: 0.859050 ,val loss : 0.390470 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :122 ]train loss : 0.265051 ,train acc: 0.873789 ,val loss : 0.399545 ,val acc : 0.818726\n",
      "[ ecpho : 4  iter :123 ]train loss : 0.343498 ,train acc: 0.846192 ,val loss : 0.396409 ,val acc : 0.825043\n",
      "[ ecpho : 4  iter :124 ]train loss : 0.294599 ,train acc: 0.865570 ,val loss : 0.389848 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :125 ]train loss : 0.284669 ,train acc: 0.866353 ,val loss : 0.401195 ,val acc : 0.824402\n",
      "[ ecpho : 4  iter :126 ]train loss : 0.305199 ,train acc: 0.860382 ,val loss : 0.399394 ,val acc : 0.820953\n",
      "[ ecpho : 4  iter :127 ]train loss : 0.270955 ,train acc: 0.864024 ,val loss : 0.400314 ,val acc : 0.822083\n",
      "[ ecpho : 4  iter :128 ]train loss : 0.338072 ,train acc: 0.820333 ,val loss : 0.394840 ,val acc : 0.819824\n",
      "[ ecpho : 4  iter :129 ]train loss : 0.289248 ,train acc: 0.865245 ,val loss : 0.396663 ,val acc : 0.821869\n",
      "[ ecpho : 4  iter :130 ]train loss : 0.323140 ,train acc: 0.855398 ,val loss : 0.395671 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :131 ]train loss : 0.412095 ,train acc: 0.836223 ,val loss : 0.399182 ,val acc : 0.819794\n",
      "[ ecpho : 4  iter :132 ]train loss : 0.240164 ,train acc: 0.884328 ,val loss : 0.392998 ,val acc : 0.823242\n",
      "[ ecpho : 4  iter :133 ]train loss : 0.251145 ,train acc: 0.877238 ,val loss : 0.396352 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :134 ]train loss : 0.236699 ,train acc: 0.884206 ,val loss : 0.397169 ,val acc : 0.823059\n",
      "[ ecpho : 4  iter :135 ]train loss : 0.258493 ,train acc: 0.876312 ,val loss : 0.396453 ,val acc : 0.820404\n",
      "[ ecpho : 4  iter :136 ]train loss : 0.381545 ,train acc: 0.804159 ,val loss : 0.391324 ,val acc : 0.821472\n",
      "[ ecpho : 4  iter :137 ]train loss : 0.364703 ,train acc: 0.840831 ,val loss : 0.386067 ,val acc : 0.823486\n",
      "[ ecpho : 4  iter :138 ]train loss : 0.266082 ,train acc: 0.876770 ,val loss : 0.394218 ,val acc : 0.821594\n",
      "[ ecpho : 4  iter :139 ]train loss : 0.272844 ,train acc: 0.867879 ,val loss : 0.393746 ,val acc : 0.821167\n",
      "[ ecpho : 4  iter :140 ]train loss : 0.382082 ,train acc: 0.802023 ,val loss : 0.393282 ,val acc : 0.824341\n",
      "[ ecpho : 4  iter :141 ]train loss : 0.275425 ,train acc: 0.866567 ,val loss : 0.394530 ,val acc : 0.823181\n",
      "[ ecpho : 4  iter :142 ]train loss : 0.289155 ,train acc: 0.864360 ,val loss : 0.391679 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :143 ]train loss : 0.328558 ,train acc: 0.849966 ,val loss : 0.396875 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :144 ]train loss : 0.356131 ,train acc: 0.847626 ,val loss : 0.398025 ,val acc : 0.822968\n",
      "[ ecpho : 4  iter :145 ]train loss : 0.305006 ,train acc: 0.841197 ,val loss : 0.396072 ,val acc : 0.821899\n",
      "[ ecpho : 4  iter :146 ]train loss : 0.314108 ,train acc: 0.846853 ,val loss : 0.395954 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :147 ]train loss : 0.353587 ,train acc: 0.843079 ,val loss : 0.397667 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :148 ]train loss : 0.323278 ,train acc: 0.853821 ,val loss : 0.399085 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :149 ]train loss : 0.349600 ,train acc: 0.835398 ,val loss : 0.392305 ,val acc : 0.825684\n",
      "[ ecpho : 4  iter :150 ]train loss : 0.293078 ,train acc: 0.855520 ,val loss : 0.395424 ,val acc : 0.821136\n",
      "[ ecpho : 4  iter :151 ]train loss : 0.273431 ,train acc: 0.871185 ,val loss : 0.398790 ,val acc : 0.821106\n",
      "[ ecpho : 4  iter :152 ]train loss : 0.322965 ,train acc: 0.845490 ,val loss : 0.391871 ,val acc : 0.823395\n",
      "[ ecpho : 4  iter :153 ]train loss : 0.320970 ,train acc: 0.850240 ,val loss : 0.394031 ,val acc : 0.824310\n",
      "[ ecpho : 4  iter :154 ]train loss : 0.292810 ,train acc: 0.864705 ,val loss : 0.396813 ,val acc : 0.820312\n",
      "[ ecpho : 4  iter :155 ]train loss : 0.270745 ,train acc: 0.874156 ,val loss : 0.396806 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :156 ]train loss : 0.396034 ,train acc: 0.828237 ,val loss : 0.393275 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :157 ]train loss : 0.275337 ,train acc: 0.868571 ,val loss : 0.399168 ,val acc : 0.820007\n",
      "[ ecpho : 4  iter :158 ]train loss : 0.265097 ,train acc: 0.871796 ,val loss : 0.395190 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :159 ]train loss : 0.363409 ,train acc: 0.847392 ,val loss : 0.392484 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :160 ]train loss : 0.461151 ,train acc: 0.756256 ,val loss : 0.395726 ,val acc : 0.819672\n",
      "[ ecpho : 4  iter :161 ]train loss : 0.304181 ,train acc: 0.860993 ,val loss : 0.392870 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :162 ]train loss : 0.289092 ,train acc: 0.865784 ,val loss : 0.392204 ,val acc : 0.822235\n",
      "[ ecpho : 4  iter :163 ]train loss : 0.360823 ,train acc: 0.844839 ,val loss : 0.394828 ,val acc : 0.818695\n",
      "[ ecpho : 4  iter :164 ]train loss : 0.352984 ,train acc: 0.813762 ,val loss : 0.390750 ,val acc : 0.826813\n",
      "[ ecpho : 4  iter :165 ]train loss : 0.268204 ,train acc: 0.870310 ,val loss : 0.397038 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :166 ]train loss : 0.321750 ,train acc: 0.852244 ,val loss : 0.396265 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :167 ]train loss : 0.317427 ,train acc: 0.854635 ,val loss : 0.391980 ,val acc : 0.823456\n",
      "[ ecpho : 4  iter :168 ]train loss : 0.295589 ,train acc: 0.846446 ,val loss : 0.393427 ,val acc : 0.821991\n",
      "[ ecpho : 4  iter :169 ]train loss : 0.283133 ,train acc: 0.867564 ,val loss : 0.390357 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :170 ]train loss : 0.350562 ,train acc: 0.845174 ,val loss : 0.395101 ,val acc : 0.821533\n",
      "[ ecpho : 4  iter :171 ]train loss : 0.311451 ,train acc: 0.857025 ,val loss : 0.395850 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :172 ]train loss : 0.308568 ,train acc: 0.847015 ,val loss : 0.395982 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :173 ]train loss : 0.319915 ,train acc: 0.860616 ,val loss : 0.395534 ,val acc : 0.819672\n",
      "[ ecpho : 4  iter :174 ]train loss : 0.274789 ,train acc: 0.871236 ,val loss : 0.395049 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :175 ]train loss : 0.393110 ,train acc: 0.806091 ,val loss : 0.391075 ,val acc : 0.826080\n",
      "[ ecpho : 4  iter :176 ]train loss : 0.368574 ,train acc: 0.844238 ,val loss : 0.396988 ,val acc : 0.820496\n",
      "[ ecpho : 4  iter :177 ]train loss : 0.286070 ,train acc: 0.864227 ,val loss : 0.394269 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :178 ]train loss : 0.245620 ,train acc: 0.881470 ,val loss : 0.393582 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :179 ]train loss : 0.286239 ,train acc: 0.865906 ,val loss : 0.396379 ,val acc : 0.819397\n",
      "[ ecpho : 4  iter :180 ]train loss : 0.260129 ,train acc: 0.874532 ,val loss : 0.395826 ,val acc : 0.825531\n",
      "[ ecpho : 4  iter :181 ]train loss : 0.312028 ,train acc: 0.857371 ,val loss : 0.392999 ,val acc : 0.826111\n",
      "[ ecpho : 4  iter :182 ]train loss : 0.353776 ,train acc: 0.803274 ,val loss : 0.397165 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :183 ]train loss : 0.292869 ,train acc: 0.862254 ,val loss : 0.396336 ,val acc : 0.820038\n",
      "[ ecpho : 4  iter :184 ]train loss : 0.441846 ,train acc: 0.787384 ,val loss : 0.394777 ,val acc : 0.822235\n",
      "[ ecpho : 4  iter :185 ]train loss : 0.528488 ,train acc: 0.777547 ,val loss : 0.395135 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :186 ]train loss : 0.268843 ,train acc: 0.871765 ,val loss : 0.394600 ,val acc : 0.817413\n",
      "[ ecpho : 4  iter :187 ]train loss : 0.296490 ,train acc: 0.869965 ,val loss : 0.398611 ,val acc : 0.817780\n",
      "[ ecpho : 4  iter :188 ]train loss : 0.337407 ,train acc: 0.836273 ,val loss : 0.396621 ,val acc : 0.827332\n",
      "[ ecpho : 4  iter :189 ]train loss : 0.301860 ,train acc: 0.858256 ,val loss : 0.392571 ,val acc : 0.827301\n",
      "[ ecpho : 4  iter :190 ]train loss : 0.291598 ,train acc: 0.867839 ,val loss : 0.396480 ,val acc : 0.820831\n",
      "[ ecpho : 4  iter :191 ]train loss : 0.375574 ,train acc: 0.767761 ,val loss : 0.399227 ,val acc : 0.820953\n",
      "[ ecpho : 4  iter :192 ]train loss : 0.424557 ,train acc: 0.830628 ,val loss : 0.388102 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :193 ]train loss : 0.321552 ,train acc: 0.858663 ,val loss : 0.398603 ,val acc : 0.820557\n",
      "[ ecpho : 4  iter :194 ]train loss : 0.332432 ,train acc: 0.857005 ,val loss : 0.391224 ,val acc : 0.823700\n",
      "[ ecpho : 4  iter :195 ]train loss : 0.320886 ,train acc: 0.856689 ,val loss : 0.392972 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :196 ]train loss : 0.367622 ,train acc: 0.843994 ,val loss : 0.396721 ,val acc : 0.820435\n",
      "[ ecpho : 4  iter :197 ]train loss : 0.312646 ,train acc: 0.865479 ,val loss : 0.396931 ,val acc : 0.821106\n",
      "[ ecpho : 4  iter :198 ]train loss : 0.312852 ,train acc: 0.857920 ,val loss : 0.396329 ,val acc : 0.819214\n",
      "[ ecpho : 4  iter :199 ]train loss : 0.334809 ,train acc: 0.839864 ,val loss : 0.396363 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :200 ]train loss : 0.339791 ,train acc: 0.814016 ,val loss : 0.395392 ,val acc : 0.821442\n",
      "[ ecpho : 4  iter :201 ]train loss : 0.330893 ,train acc: 0.839844 ,val loss : 0.394352 ,val acc : 0.825043\n",
      "[ ecpho : 4  iter :202 ]train loss : 0.319992 ,train acc: 0.859752 ,val loss : 0.394498 ,val acc : 0.820892\n",
      "[ ecpho : 4  iter :203 ]train loss : 0.317722 ,train acc: 0.857809 ,val loss : 0.390082 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :204 ]train loss : 0.355502 ,train acc: 0.830994 ,val loss : 0.393112 ,val acc : 0.824738\n",
      "[ ecpho : 4  iter :205 ]train loss : 0.357239 ,train acc: 0.831757 ,val loss : 0.395935 ,val acc : 0.819275\n",
      "[ ecpho : 4  iter :206 ]train loss : 0.292621 ,train acc: 0.863871 ,val loss : 0.392637 ,val acc : 0.822449\n",
      "[ ecpho : 4  iter :207 ]train loss : 0.271711 ,train acc: 0.869904 ,val loss : 0.394327 ,val acc : 0.818207\n",
      "[ ecpho : 4  iter :208 ]train loss : 0.255879 ,train acc: 0.881866 ,val loss : 0.394335 ,val acc : 0.823120\n",
      "[ ecpho : 4  iter :209 ]train loss : 0.335675 ,train acc: 0.823222 ,val loss : 0.394087 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :210 ]train loss : 0.300898 ,train acc: 0.863922 ,val loss : 0.393518 ,val acc : 0.821655\n",
      "[ ecpho : 4  iter :211 ]train loss : 0.648400 ,train acc: 0.814728 ,val loss : 0.392319 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :212 ]train loss : 0.310918 ,train acc: 0.844248 ,val loss : 0.394255 ,val acc : 0.820923\n",
      "[ ecpho : 4  iter :213 ]train loss : 0.289585 ,train acc: 0.860168 ,val loss : 0.392898 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :214 ]train loss : 0.334725 ,train acc: 0.848979 ,val loss : 0.396271 ,val acc : 0.819580\n",
      "[ ecpho : 4  iter :215 ]train loss : 0.371478 ,train acc: 0.845154 ,val loss : 0.395312 ,val acc : 0.819580\n",
      "[ ecpho : 4  iter :216 ]train loss : 0.274583 ,train acc: 0.865346 ,val loss : 0.400367 ,val acc : 0.820770\n",
      "[ ecpho : 4  iter :217 ]train loss : 0.271844 ,train acc: 0.868775 ,val loss : 0.398068 ,val acc : 0.821411\n",
      "[ ecpho : 4  iter :218 ]train loss : 0.337411 ,train acc: 0.860647 ,val loss : 0.394547 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :219 ]train loss : 0.269919 ,train acc: 0.874380 ,val loss : 0.398131 ,val acc : 0.820099\n",
      "[ ecpho : 4  iter :220 ]train loss : 0.276271 ,train acc: 0.862712 ,val loss : 0.393150 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :221 ]train loss : 0.278987 ,train acc: 0.872304 ,val loss : 0.394336 ,val acc : 0.822113\n",
      "[ ecpho : 4  iter :222 ]train loss : 0.318897 ,train acc: 0.850678 ,val loss : 0.395259 ,val acc : 0.820465\n",
      "[ ecpho : 4  iter :223 ]train loss : 0.381770 ,train acc: 0.784363 ,val loss : 0.393371 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :224 ]train loss : 0.335417 ,train acc: 0.816823 ,val loss : 0.394452 ,val acc : 0.822174\n",
      "[ ecpho : 4  iter :225 ]train loss : 0.244361 ,train acc: 0.878815 ,val loss : 0.392487 ,val acc : 0.826813\n",
      "[ ecpho : 4  iter :226 ]train loss : 0.302931 ,train acc: 0.862132 ,val loss : 0.398642 ,val acc : 0.823334\n",
      "[ ecpho : 4  iter :227 ]train loss : 0.348876 ,train acc: 0.808441 ,val loss : 0.395904 ,val acc : 0.817810\n",
      "[ ecpho : 4  iter :228 ]train loss : 0.322076 ,train acc: 0.843119 ,val loss : 0.394957 ,val acc : 0.822052\n",
      "[ ecpho : 4  iter :229 ]train loss : 0.318009 ,train acc: 0.836192 ,val loss : 0.394994 ,val acc : 0.824921\n",
      "[ ecpho : 4  iter :230 ]train loss : 0.288680 ,train acc: 0.864126 ,val loss : 0.391404 ,val acc : 0.821075\n",
      "[ ecpho : 4  iter :231 ]train loss : 0.301118 ,train acc: 0.855398 ,val loss : 0.402067 ,val acc : 0.819733\n",
      "[ ecpho : 4  iter :232 ]train loss : 0.371375 ,train acc: 0.843872 ,val loss : 0.397454 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :233 ]train loss : 0.252401 ,train acc: 0.876241 ,val loss : 0.394999 ,val acc : 0.822083\n",
      "[ ecpho : 4  iter :234 ]train loss : 0.287574 ,train acc: 0.867167 ,val loss : 0.400530 ,val acc : 0.822113\n",
      "[ ecpho : 4  iter :235 ]train loss : 0.301981 ,train acc: 0.853963 ,val loss : 0.396813 ,val acc : 0.821167\n",
      "[ ecpho : 4  iter :236 ]train loss : 0.277664 ,train acc: 0.861827 ,val loss : 0.393449 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :237 ]train loss : 0.336690 ,train acc: 0.849894 ,val loss : 0.397919 ,val acc : 0.821320\n",
      "[ ecpho : 4  iter :238 ]train loss : 0.250508 ,train acc: 0.879761 ,val loss : 0.392487 ,val acc : 0.827057\n",
      "[ ecpho : 4  iter :239 ]train loss : 0.271751 ,train acc: 0.872538 ,val loss : 0.395650 ,val acc : 0.820526\n",
      "[ ecpho : 4  iter :240 ]train loss : 0.299562 ,train acc: 0.860677 ,val loss : 0.396204 ,val acc : 0.820679\n",
      "[ ecpho : 4  iter :241 ]train loss : 0.373033 ,train acc: 0.845856 ,val loss : 0.388616 ,val acc : 0.824738\n",
      "[ ecpho : 4  iter :242 ]train loss : 0.344982 ,train acc: 0.826142 ,val loss : 0.390055 ,val acc : 0.824158\n",
      "[ ecpho : 4  iter :243 ]train loss : 0.498754 ,train acc: 0.724121 ,val loss : 0.392367 ,val acc : 0.821869\n",
      "[ ecpho : 4  iter :244 ]train loss : 0.284424 ,train acc: 0.861359 ,val loss : 0.389616 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :245 ]train loss : 0.312521 ,train acc: 0.842499 ,val loss : 0.397253 ,val acc : 0.824310\n",
      "[ ecpho : 4  iter :246 ]train loss : 0.376199 ,train acc: 0.844778 ,val loss : 0.397323 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :247 ]train loss : 0.287787 ,train acc: 0.858205 ,val loss : 0.399017 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :248 ]train loss : 0.343254 ,train acc: 0.855448 ,val loss : 0.392178 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :249 ]train loss : 0.319305 ,train acc: 0.851064 ,val loss : 0.396623 ,val acc : 0.819305\n",
      "[ ecpho : 4  iter :250 ]train loss : 0.261670 ,train acc: 0.874634 ,val loss : 0.395056 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :251 ]train loss : 0.306155 ,train acc: 0.857025 ,val loss : 0.393295 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :252 ]train loss : 0.313359 ,train acc: 0.847463 ,val loss : 0.394250 ,val acc : 0.823273\n",
      "[ ecpho : 4  iter :253 ]train loss : 0.365679 ,train acc: 0.833944 ,val loss : 0.399129 ,val acc : 0.820282\n",
      "[ ecpho : 4  iter :254 ]train loss : 0.270479 ,train acc: 0.865397 ,val loss : 0.389973 ,val acc : 0.824677\n",
      "[ ecpho : 4  iter :255 ]train loss : 0.270517 ,train acc: 0.867218 ,val loss : 0.394656 ,val acc : 0.822021\n",
      "[ ecpho : 4  iter :256 ]train loss : 0.298376 ,train acc: 0.866862 ,val loss : 0.397716 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :257 ]train loss : 0.362493 ,train acc: 0.828868 ,val loss : 0.396520 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :258 ]train loss : 0.281207 ,train acc: 0.869100 ,val loss : 0.393372 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :259 ]train loss : 0.339198 ,train acc: 0.848745 ,val loss : 0.397373 ,val acc : 0.823059\n",
      "[ ecpho : 4  iter :260 ]train loss : 0.404095 ,train acc: 0.838298 ,val loss : 0.393044 ,val acc : 0.821747\n",
      "[ ecpho : 4  iter :261 ]train loss : 0.452402 ,train acc: 0.838359 ,val loss : 0.391133 ,val acc : 0.821320\n",
      "[ ecpho : 4  iter :262 ]train loss : 0.277953 ,train acc: 0.864492 ,val loss : 0.396195 ,val acc : 0.820892\n",
      "[ ecpho : 4  iter :263 ]train loss : 0.334807 ,train acc: 0.849742 ,val loss : 0.395004 ,val acc : 0.819946\n",
      "[ ecpho : 4  iter :264 ]train loss : 0.407035 ,train acc: 0.838450 ,val loss : 0.391405 ,val acc : 0.826111\n",
      "[ ecpho : 4  iter :265 ]train loss : 0.316947 ,train acc: 0.857117 ,val loss : 0.391138 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :266 ]train loss : 0.287276 ,train acc: 0.864878 ,val loss : 0.394363 ,val acc : 0.819702\n",
      "[ ecpho : 4  iter :267 ]train loss : 0.299142 ,train acc: 0.858490 ,val loss : 0.397564 ,val acc : 0.820374\n",
      "[ ecpho : 4  iter :268 ]train loss : 0.317200 ,train acc: 0.844798 ,val loss : 0.395095 ,val acc : 0.826416\n",
      "[ ecpho : 4  iter :269 ]train loss : 0.331820 ,train acc: 0.847575 ,val loss : 0.385101 ,val acc : 0.826782\n",
      "[ ecpho : 4  iter :270 ]train loss : 0.302250 ,train acc: 0.858928 ,val loss : 0.394629 ,val acc : 0.822357\n",
      "[ ecpho : 4  iter :271 ]train loss : 0.285825 ,train acc: 0.858277 ,val loss : 0.396313 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :272 ]train loss : 0.350093 ,train acc: 0.810883 ,val loss : 0.393157 ,val acc : 0.821136\n",
      "[ ecpho : 4  iter :273 ]train loss : 0.362208 ,train acc: 0.843384 ,val loss : 0.387318 ,val acc : 0.826904\n",
      "[ ecpho : 4  iter :274 ]train loss : 0.394211 ,train acc: 0.840627 ,val loss : 0.394623 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :275 ]train loss : 0.290378 ,train acc: 0.869375 ,val loss : 0.391721 ,val acc : 0.824036\n",
      "[ ecpho : 4  iter :276 ]train loss : 0.340824 ,train acc: 0.846660 ,val loss : 0.393561 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :277 ]train loss : 0.369148 ,train acc: 0.797923 ,val loss : 0.398385 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :278 ]train loss : 0.240817 ,train acc: 0.883799 ,val loss : 0.395380 ,val acc : 0.820862\n",
      "[ ecpho : 4  iter :279 ]train loss : 0.286938 ,train acc: 0.863586 ,val loss : 0.402599 ,val acc : 0.820709\n",
      "[ ecpho : 4  iter :280 ]train loss : 0.266372 ,train acc: 0.877696 ,val loss : 0.401208 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :281 ]train loss : 0.328938 ,train acc: 0.850566 ,val loss : 0.392213 ,val acc : 0.818481\n",
      "[ ecpho : 4  iter :282 ]train loss : 0.466124 ,train acc: 0.739044 ,val loss : 0.391350 ,val acc : 0.824005\n",
      "[ ecpho : 4  iter :283 ]train loss : 0.384907 ,train acc: 0.793294 ,val loss : 0.396137 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :284 ]train loss : 0.257667 ,train acc: 0.878540 ,val loss : 0.392900 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :285 ]train loss : 0.331807 ,train acc: 0.853628 ,val loss : 0.390741 ,val acc : 0.824738\n",
      "[ ecpho : 4  iter :286 ]train loss : 0.273778 ,train acc: 0.871592 ,val loss : 0.393451 ,val acc : 0.822937\n",
      "[ ecpho : 4  iter :287 ]train loss : 0.342775 ,train acc: 0.827128 ,val loss : 0.393818 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :288 ]train loss : 0.342818 ,train acc: 0.825022 ,val loss : 0.391400 ,val acc : 0.822662\n",
      "[ ecpho : 4  iter :289 ]train loss : 0.406177 ,train acc: 0.840678 ,val loss : 0.403849 ,val acc : 0.818726\n",
      "[ ecpho : 4  iter :290 ]train loss : 0.309086 ,train acc: 0.860504 ,val loss : 0.393502 ,val acc : 0.823700\n",
      "[ ecpho : 4  iter :291 ]train loss : 0.245018 ,train acc: 0.883260 ,val loss : 0.393461 ,val acc : 0.823914\n",
      "[ ecpho : 4  iter :292 ]train loss : 0.305189 ,train acc: 0.846242 ,val loss : 0.393186 ,val acc : 0.820465\n",
      "[ ecpho : 4  iter :293 ]train loss : 0.342013 ,train acc: 0.837341 ,val loss : 0.394942 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :294 ]train loss : 0.292413 ,train acc: 0.865092 ,val loss : 0.397715 ,val acc : 0.820007\n",
      "[ ecpho : 4  iter :295 ]train loss : 0.244313 ,train acc: 0.882843 ,val loss : 0.386582 ,val acc : 0.827332\n",
      "[ ecpho : 4  iter :296 ]train loss : 0.307108 ,train acc: 0.859121 ,val loss : 0.391743 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :297 ]train loss : 0.479540 ,train acc: 0.792481 ,val loss : 0.392734 ,val acc : 0.823181\n",
      "[ ecpho : 4  iter :298 ]train loss : 0.342464 ,train acc: 0.848948 ,val loss : 0.391121 ,val acc : 0.825775\n",
      "[ ecpho : 4  iter :299 ]train loss : 0.265705 ,train acc: 0.871918 ,val loss : 0.393312 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :300 ]train loss : 0.249726 ,train acc: 0.878764 ,val loss : 0.396805 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :301 ]train loss : 0.273789 ,train acc: 0.867483 ,val loss : 0.395872 ,val acc : 0.821960\n",
      "[ ecpho : 4  iter :302 ]train loss : 0.360398 ,train acc: 0.847351 ,val loss : 0.396869 ,val acc : 0.820099\n",
      "[ ecpho : 4  iter :303 ]train loss : 0.279919 ,train acc: 0.858226 ,val loss : 0.391587 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :304 ]train loss : 0.301049 ,train acc: 0.839305 ,val loss : 0.397601 ,val acc : 0.820801\n",
      "[ ecpho : 4  iter :305 ]train loss : 0.297060 ,train acc: 0.861399 ,val loss : 0.398101 ,val acc : 0.820496\n",
      "[ ecpho : 4  iter :306 ]train loss : 0.330096 ,train acc: 0.853078 ,val loss : 0.398129 ,val acc : 0.823120\n",
      "[ ecpho : 4  iter :307 ]train loss : 0.337182 ,train acc: 0.818685 ,val loss : 0.396368 ,val acc : 0.821045\n",
      "[ ecpho : 4  iter :308 ]train loss : 0.316974 ,train acc: 0.865062 ,val loss : 0.390683 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :309 ]train loss : 0.246206 ,train acc: 0.877614 ,val loss : 0.399869 ,val acc : 0.823120\n",
      "[ ecpho : 4  iter :310 ]train loss : 0.296622 ,train acc: 0.865133 ,val loss : 0.391128 ,val acc : 0.823456\n",
      "[ ecpho : 4  iter :311 ]train loss : 0.286116 ,train acc: 0.862996 ,val loss : 0.389955 ,val acc : 0.821198\n",
      "[ ecpho : 4  iter :312 ]train loss : 0.293958 ,train acc: 0.868124 ,val loss : 0.391498 ,val acc : 0.823456\n",
      "[ ecpho : 4  iter :313 ]train loss : 0.274197 ,train acc: 0.868459 ,val loss : 0.396793 ,val acc : 0.820862\n",
      "[ ecpho : 4  iter :314 ]train loss : 0.454327 ,train acc: 0.814352 ,val loss : 0.396879 ,val acc : 0.819550\n",
      "[ ecpho : 4  iter :315 ]train loss : 0.298837 ,train acc: 0.859996 ,val loss : 0.394204 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :316 ]train loss : 0.328300 ,train acc: 0.861806 ,val loss : 0.392581 ,val acc : 0.820374\n",
      "[ ecpho : 4  iter :317 ]train loss : 0.252366 ,train acc: 0.878154 ,val loss : 0.397231 ,val acc : 0.822205\n",
      "[ ecpho : 4  iter :318 ]train loss : 0.333699 ,train acc: 0.844472 ,val loss : 0.393498 ,val acc : 0.819489\n",
      "[ ecpho : 4  iter :319 ]train loss : 0.262481 ,train acc: 0.877930 ,val loss : 0.397910 ,val acc : 0.820038\n",
      "[ ecpho : 4  iter :320 ]train loss : 0.245912 ,train acc: 0.880737 ,val loss : 0.398006 ,val acc : 0.822266\n",
      "[ ecpho : 4  iter :321 ]train loss : 0.297239 ,train acc: 0.855937 ,val loss : 0.387733 ,val acc : 0.821960\n",
      "[ ecpho : 4  iter :322 ]train loss : 0.350711 ,train acc: 0.847555 ,val loss : 0.391342 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :323 ]train loss : 0.278568 ,train acc: 0.865529 ,val loss : 0.389390 ,val acc : 0.826355\n",
      "[ ecpho : 4  iter :324 ]train loss : 0.328931 ,train acc: 0.857737 ,val loss : 0.396727 ,val acc : 0.821014\n",
      "[ ecpho : 4  iter :325 ]train loss : 0.312003 ,train acc: 0.850281 ,val loss : 0.390209 ,val acc : 0.823730\n",
      "[ ecpho : 4  iter :326 ]train loss : 0.296490 ,train acc: 0.866425 ,val loss : 0.390864 ,val acc : 0.820984\n",
      "[ ecpho : 4  iter :327 ]train loss : 0.263064 ,train acc: 0.872182 ,val loss : 0.387347 ,val acc : 0.823273\n",
      "[ ecpho : 4  iter :328 ]train loss : 0.317891 ,train acc: 0.841400 ,val loss : 0.392281 ,val acc : 0.823090\n",
      "[ ecpho : 4  iter :329 ]train loss : 0.336185 ,train acc: 0.841217 ,val loss : 0.389870 ,val acc : 0.823547\n",
      "[ ecpho : 4  iter :330 ]train loss : 0.273600 ,train acc: 0.876811 ,val loss : 0.395918 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :331 ]train loss : 0.279499 ,train acc: 0.865469 ,val loss : 0.393699 ,val acc : 0.822510\n",
      "[ ecpho : 4  iter :332 ]train loss : 0.304180 ,train acc: 0.860860 ,val loss : 0.392039 ,val acc : 0.824524\n",
      "[ ecpho : 4  iter :333 ]train loss : 0.285415 ,train acc: 0.866323 ,val loss : 0.392928 ,val acc : 0.821472\n",
      "[ ecpho : 4  iter :334 ]train loss : 0.300992 ,train acc: 0.861796 ,val loss : 0.400712 ,val acc : 0.820984\n",
      "[ ecpho : 4  iter :335 ]train loss : 0.342378 ,train acc: 0.850515 ,val loss : 0.393672 ,val acc : 0.825470\n",
      "[ ecpho : 4  iter :336 ]train loss : 0.238968 ,train acc: 0.880198 ,val loss : 0.391472 ,val acc : 0.821991\n",
      "[ ecpho : 4  iter :337 ]train loss : 0.365084 ,train acc: 0.793356 ,val loss : 0.394850 ,val acc : 0.823761\n",
      "[ ecpho : 4  iter :338 ]train loss : 0.281154 ,train acc: 0.867127 ,val loss : 0.401436 ,val acc : 0.821259\n",
      "[ ecpho : 4  iter :339 ]train loss : 0.315577 ,train acc: 0.858104 ,val loss : 0.400385 ,val acc : 0.820618\n",
      "[ ecpho : 4  iter :340 ]train loss : 0.266079 ,train acc: 0.867330 ,val loss : 0.391277 ,val acc : 0.825928\n",
      "[ ecpho : 4  iter :341 ]train loss : 0.339239 ,train acc: 0.834513 ,val loss : 0.390524 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :342 ]train loss : 0.299325 ,train acc: 0.864329 ,val loss : 0.392759 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :343 ]train loss : 0.263432 ,train acc: 0.878388 ,val loss : 0.387159 ,val acc : 0.825165\n",
      "[ ecpho : 4  iter :344 ]train loss : 0.365093 ,train acc: 0.847270 ,val loss : 0.389071 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :345 ]train loss : 0.351854 ,train acc: 0.846263 ,val loss : 0.388094 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :346 ]train loss : 0.374314 ,train acc: 0.853200 ,val loss : 0.394860 ,val acc : 0.821594\n",
      "[ ecpho : 4  iter :347 ]train loss : 0.302138 ,train acc: 0.855062 ,val loss : 0.391328 ,val acc : 0.823639\n",
      "[ ecpho : 4  iter :348 ]train loss : 0.341013 ,train acc: 0.856466 ,val loss : 0.395017 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :349 ]train loss : 0.322700 ,train acc: 0.832744 ,val loss : 0.387181 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :350 ]train loss : 0.296660 ,train acc: 0.858734 ,val loss : 0.388123 ,val acc : 0.824982\n",
      "[ ecpho : 4  iter :351 ]train loss : 0.295550 ,train acc: 0.859284 ,val loss : 0.392794 ,val acc : 0.821198\n",
      "[ ecpho : 4  iter :352 ]train loss : 0.299455 ,train acc: 0.860840 ,val loss : 0.390618 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :353 ]train loss : 0.328042 ,train acc: 0.851888 ,val loss : 0.386844 ,val acc : 0.823273\n",
      "[ ecpho : 4  iter :354 ]train loss : 0.285073 ,train acc: 0.872986 ,val loss : 0.389965 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :355 ]train loss : 0.328330 ,train acc: 0.840556 ,val loss : 0.392398 ,val acc : 0.823059\n",
      "[ ecpho : 4  iter :356 ]train loss : 0.297370 ,train acc: 0.865102 ,val loss : 0.388737 ,val acc : 0.826599\n",
      "[ ecpho : 4  iter :357 ]train loss : 0.302330 ,train acc: 0.850403 ,val loss : 0.390881 ,val acc : 0.823761\n",
      "[ ecpho : 4  iter :358 ]train loss : 0.353895 ,train acc: 0.843872 ,val loss : 0.395405 ,val acc : 0.822815\n",
      "[ ecpho : 4  iter :359 ]train loss : 0.298227 ,train acc: 0.861552 ,val loss : 0.397794 ,val acc : 0.822449\n",
      "[ ecpho : 4  iter :360 ]train loss : 0.273587 ,train acc: 0.868113 ,val loss : 0.395688 ,val acc : 0.820923\n",
      "[ ecpho : 4  iter :361 ]train loss : 0.250959 ,train acc: 0.876038 ,val loss : 0.392931 ,val acc : 0.824951\n",
      "[ ecpho : 4  iter :362 ]train loss : 0.301948 ,train acc: 0.850322 ,val loss : 0.396058 ,val acc : 0.820892\n",
      "[ ecpho : 4  iter :363 ]train loss : 0.287907 ,train acc: 0.866801 ,val loss : 0.389358 ,val acc : 0.826660\n",
      "[ ecpho : 4  iter :364 ]train loss : 0.349977 ,train acc: 0.841848 ,val loss : 0.395990 ,val acc : 0.818604\n",
      "[ ecpho : 4  iter :365 ]train loss : 0.275452 ,train acc: 0.868947 ,val loss : 0.393509 ,val acc : 0.821533\n",
      "[ ecpho : 4  iter :366 ]train loss : 0.321786 ,train acc: 0.862671 ,val loss : 0.393257 ,val acc : 0.821472\n",
      "[ ecpho : 4  iter :367 ]train loss : 0.322403 ,train acc: 0.844147 ,val loss : 0.388335 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :368 ]train loss : 0.291373 ,train acc: 0.858358 ,val loss : 0.390549 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :369 ]train loss : 0.313332 ,train acc: 0.854981 ,val loss : 0.398103 ,val acc : 0.820770\n",
      "[ ecpho : 4  iter :370 ]train loss : 0.318088 ,train acc: 0.847250 ,val loss : 0.393430 ,val acc : 0.822937\n",
      "[ ecpho : 4  iter :371 ]train loss : 0.314689 ,train acc: 0.849019 ,val loss : 0.392451 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :372 ]train loss : 0.240364 ,train acc: 0.880910 ,val loss : 0.389389 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :373 ]train loss : 0.286551 ,train acc: 0.868825 ,val loss : 0.393491 ,val acc : 0.821350\n",
      "[ ecpho : 4  iter :374 ]train loss : 0.267085 ,train acc: 0.872691 ,val loss : 0.398431 ,val acc : 0.820801\n",
      "[ ecpho : 4  iter :375 ]train loss : 0.283241 ,train acc: 0.870158 ,val loss : 0.388682 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :376 ]train loss : 0.287588 ,train acc: 0.860433 ,val loss : 0.395322 ,val acc : 0.822052\n",
      "[ ecpho : 4  iter :377 ]train loss : 0.288796 ,train acc: 0.868744 ,val loss : 0.391534 ,val acc : 0.819641\n",
      "[ ecpho : 4  iter :378 ]train loss : 0.343561 ,train acc: 0.843994 ,val loss : 0.389099 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :379 ]train loss : 0.267837 ,train acc: 0.869517 ,val loss : 0.398346 ,val acc : 0.820068\n",
      "[ ecpho : 4  iter :380 ]train loss : 0.367430 ,train acc: 0.826477 ,val loss : 0.390855 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :381 ]train loss : 0.343112 ,train acc: 0.840637 ,val loss : 0.392821 ,val acc : 0.821503\n",
      "[ ecpho : 4  iter :382 ]train loss : 0.300800 ,train acc: 0.852661 ,val loss : 0.389495 ,val acc : 0.826172\n",
      "[ ecpho : 4  iter :383 ]train loss : 0.337293 ,train acc: 0.839071 ,val loss : 0.392226 ,val acc : 0.820770\n",
      "[ ecpho : 4  iter :384 ]train loss : 0.323468 ,train acc: 0.859640 ,val loss : 0.395714 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :385 ]train loss : 0.330068 ,train acc: 0.852163 ,val loss : 0.397940 ,val acc : 0.820465\n",
      "[ ecpho : 4  iter :386 ]train loss : 0.411004 ,train acc: 0.834117 ,val loss : 0.396201 ,val acc : 0.822083\n",
      "[ ecpho : 4  iter :387 ]train loss : 0.400244 ,train acc: 0.804647 ,val loss : 0.390818 ,val acc : 0.825287\n",
      "[ ecpho : 4  iter :388 ]train loss : 0.474967 ,train acc: 0.815461 ,val loss : 0.393138 ,val acc : 0.821503\n",
      "[ ecpho : 4  iter :389 ]train loss : 0.377109 ,train acc: 0.830149 ,val loss : 0.391707 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :390 ]train loss : 0.400874 ,train acc: 0.837738 ,val loss : 0.389779 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :391 ]train loss : 0.315506 ,train acc: 0.863098 ,val loss : 0.389174 ,val acc : 0.824280\n",
      "[ ecpho : 4  iter :392 ]train loss : 0.331543 ,train acc: 0.847412 ,val loss : 0.393992 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :393 ]train loss : 0.324892 ,train acc: 0.839701 ,val loss : 0.397788 ,val acc : 0.818237\n",
      "[ ecpho : 4  iter :394 ]train loss : 0.288450 ,train acc: 0.864065 ,val loss : 0.391684 ,val acc : 0.819336\n",
      "[ ecpho : 4  iter :395 ]train loss : 0.312540 ,train acc: 0.838247 ,val loss : 0.395633 ,val acc : 0.822083\n",
      "[ ecpho : 4  iter :396 ]train loss : 0.266465 ,train acc: 0.868245 ,val loss : 0.391084 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :397 ]train loss : 0.306633 ,train acc: 0.851858 ,val loss : 0.394179 ,val acc : 0.820221\n",
      "[ ecpho : 4  iter :398 ]train loss : 0.290946 ,train acc: 0.866943 ,val loss : 0.395394 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :399 ]train loss : 0.266772 ,train acc: 0.868683 ,val loss : 0.389038 ,val acc : 0.822876\n",
      "[ ecpho : 4  iter :400 ]train loss : 0.309404 ,train acc: 0.855713 ,val loss : 0.393473 ,val acc : 0.823456\n",
      "[ ecpho : 4  iter :401 ]train loss : 0.279327 ,train acc: 0.869680 ,val loss : 0.392202 ,val acc : 0.822021\n",
      "[ ecpho : 4  iter :402 ]train loss : 0.312638 ,train acc: 0.848541 ,val loss : 0.394173 ,val acc : 0.825378\n",
      "[ ecpho : 4  iter :403 ]train loss : 0.468838 ,train acc: 0.825724 ,val loss : 0.395591 ,val acc : 0.821899\n",
      "[ ecpho : 4  iter :404 ]train loss : 0.285913 ,train acc: 0.861613 ,val loss : 0.391585 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :405 ]train loss : 0.317340 ,train acc: 0.849528 ,val loss : 0.393213 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :406 ]train loss : 0.434836 ,train acc: 0.821645 ,val loss : 0.390972 ,val acc : 0.821442\n",
      "[ ecpho : 4  iter :407 ]train loss : 0.278396 ,train acc: 0.864960 ,val loss : 0.394991 ,val acc : 0.820953\n",
      "[ ecpho : 4  iter :408 ]train loss : 0.403381 ,train acc: 0.793356 ,val loss : 0.393538 ,val acc : 0.821289\n",
      "[ ecpho : 4  iter :409 ]train loss : 0.285080 ,train acc: 0.865234 ,val loss : 0.396599 ,val acc : 0.822968\n",
      "[ ecpho : 4  iter :410 ]train loss : 0.287567 ,train acc: 0.864614 ,val loss : 0.393349 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :411 ]train loss : 0.439657 ,train acc: 0.792715 ,val loss : 0.395225 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :412 ]train loss : 0.375259 ,train acc: 0.844056 ,val loss : 0.388032 ,val acc : 0.826538\n",
      "[ ecpho : 4  iter :413 ]train loss : 0.310703 ,train acc: 0.854696 ,val loss : 0.392297 ,val acc : 0.818207\n",
      "[ ecpho : 4  iter :414 ]train loss : 0.335676 ,train acc: 0.849894 ,val loss : 0.393784 ,val acc : 0.822144\n",
      "[ ecpho : 4  iter :415 ]train loss : 0.291631 ,train acc: 0.867533 ,val loss : 0.386395 ,val acc : 0.824158\n",
      "[ ecpho : 4  iter :416 ]train loss : 0.311990 ,train acc: 0.848775 ,val loss : 0.389129 ,val acc : 0.824036\n",
      "[ ecpho : 4  iter :417 ]train loss : 0.334283 ,train acc: 0.839478 ,val loss : 0.394819 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :418 ]train loss : 0.271483 ,train acc: 0.869975 ,val loss : 0.390960 ,val acc : 0.823486\n",
      "[ ecpho : 4  iter :419 ]train loss : 0.338822 ,train acc: 0.842367 ,val loss : 0.395606 ,val acc : 0.821198\n",
      "[ ecpho : 4  iter :420 ]train loss : 0.293091 ,train acc: 0.871063 ,val loss : 0.392850 ,val acc : 0.820496\n",
      "[ ecpho : 4  iter :421 ]train loss : 0.276651 ,train acc: 0.867767 ,val loss : 0.393775 ,val acc : 0.823120\n",
      "[ ecpho : 4  iter :422 ]train loss : 0.270680 ,train acc: 0.871378 ,val loss : 0.391457 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :423 ]train loss : 0.378196 ,train acc: 0.829834 ,val loss : 0.394531 ,val acc : 0.820587\n",
      "[ ecpho : 4  iter :424 ]train loss : 0.395584 ,train acc: 0.803080 ,val loss : 0.392564 ,val acc : 0.823547\n",
      "[ ecpho : 4  iter :425 ]train loss : 0.273039 ,train acc: 0.869263 ,val loss : 0.392170 ,val acc : 0.824402\n",
      "[ ecpho : 4  iter :426 ]train loss : 0.275102 ,train acc: 0.869059 ,val loss : 0.394496 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :427 ]train loss : 0.298297 ,train acc: 0.850047 ,val loss : 0.389376 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :428 ]train loss : 0.284769 ,train acc: 0.862183 ,val loss : 0.399058 ,val acc : 0.820740\n",
      "[ ecpho : 4  iter :429 ]train loss : 0.412668 ,train acc: 0.839905 ,val loss : 0.396966 ,val acc : 0.822662\n",
      "[ ecpho : 4  iter :430 ]train loss : 0.237550 ,train acc: 0.882813 ,val loss : 0.392786 ,val acc : 0.826416\n",
      "[ ecpho : 4  iter :431 ]train loss : 0.347498 ,train acc: 0.834808 ,val loss : 0.393723 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :432 ]train loss : 0.299757 ,train acc: 0.863302 ,val loss : 0.391524 ,val acc : 0.825043\n",
      "[ ecpho : 4  iter :433 ]train loss : 0.278531 ,train acc: 0.863841 ,val loss : 0.391567 ,val acc : 0.820038\n",
      "[ ecpho : 4  iter :434 ]train loss : 0.437213 ,train acc: 0.781403 ,val loss : 0.394387 ,val acc : 0.820770\n",
      "[ ecpho : 4  iter :435 ]train loss : 0.362079 ,train acc: 0.848531 ,val loss : 0.388152 ,val acc : 0.824921\n",
      "[ ecpho : 4  iter :436 ]train loss : 0.506306 ,train acc: 0.801626 ,val loss : 0.392492 ,val acc : 0.821808\n",
      "[ ecpho : 4  iter :437 ]train loss : 0.267452 ,train acc: 0.869965 ,val loss : 0.388017 ,val acc : 0.821259\n",
      "[ ecpho : 4  iter :438 ]train loss : 0.249246 ,train acc: 0.880595 ,val loss : 0.392293 ,val acc : 0.820892\n",
      "[ ecpho : 4  iter :439 ]train loss : 0.296565 ,train acc: 0.871246 ,val loss : 0.390560 ,val acc : 0.823975\n",
      "[ ecpho : 4  iter :440 ]train loss : 0.253015 ,train acc: 0.873810 ,val loss : 0.386391 ,val acc : 0.824463\n",
      "[ ecpho : 4  iter :441 ]train loss : 0.287660 ,train acc: 0.860301 ,val loss : 0.392315 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :442 ]train loss : 0.249529 ,train acc: 0.877482 ,val loss : 0.393161 ,val acc : 0.821808\n",
      "[ ecpho : 4  iter :443 ]train loss : 0.281388 ,train acc: 0.869497 ,val loss : 0.390952 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :444 ]train loss : 0.269851 ,train acc: 0.860321 ,val loss : 0.392849 ,val acc : 0.824585\n",
      "[ ecpho : 4  iter :445 ]train loss : 0.356355 ,train acc: 0.839284 ,val loss : 0.387664 ,val acc : 0.825165\n",
      "[ ecpho : 4  iter :446 ]train loss : 0.332827 ,train acc: 0.846893 ,val loss : 0.387632 ,val acc : 0.826355\n",
      "[ ecpho : 4  iter :447 ]train loss : 0.275123 ,train acc: 0.867859 ,val loss : 0.394712 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :448 ]train loss : 0.296689 ,train acc: 0.860647 ,val loss : 0.391721 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :449 ]train loss : 0.343431 ,train acc: 0.853048 ,val loss : 0.393473 ,val acc : 0.826263\n",
      "[ ecpho : 4  iter :450 ]train loss : 0.351301 ,train acc: 0.832143 ,val loss : 0.396052 ,val acc : 0.822113\n",
      "[ ecpho : 4  iter :451 ]train loss : 0.333908 ,train acc: 0.844422 ,val loss : 0.395604 ,val acc : 0.819305\n",
      "[ ecpho : 4  iter :452 ]train loss : 0.260377 ,train acc: 0.872803 ,val loss : 0.393441 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :453 ]train loss : 0.299541 ,train acc: 0.868347 ,val loss : 0.393725 ,val acc : 0.822052\n",
      "[ ecpho : 4  iter :454 ]train loss : 0.340728 ,train acc: 0.818899 ,val loss : 0.390307 ,val acc : 0.822998\n",
      "[ ecpho : 4  iter :455 ]train loss : 0.359021 ,train acc: 0.844299 ,val loss : 0.390231 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :456 ]train loss : 0.283565 ,train acc: 0.863464 ,val loss : 0.389825 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :457 ]train loss : 0.420859 ,train acc: 0.832906 ,val loss : 0.396794 ,val acc : 0.822906\n",
      "[ ecpho : 4  iter :458 ]train loss : 0.315901 ,train acc: 0.843109 ,val loss : 0.385766 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :459 ]train loss : 0.306174 ,train acc: 0.851542 ,val loss : 0.399114 ,val acc : 0.819916\n",
      "[ ecpho : 4  iter :460 ]train loss : 0.433401 ,train acc: 0.752787 ,val loss : 0.397382 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :461 ]train loss : 0.276291 ,train acc: 0.858663 ,val loss : 0.395375 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :462 ]train loss : 0.317685 ,train acc: 0.842356 ,val loss : 0.392467 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :463 ]train loss : 0.261727 ,train acc: 0.880391 ,val loss : 0.391613 ,val acc : 0.823975\n",
      "[ ecpho : 4  iter :464 ]train loss : 0.281118 ,train acc: 0.866099 ,val loss : 0.387964 ,val acc : 0.826538\n",
      "[ ecpho : 4  iter :465 ]train loss : 0.329922 ,train acc: 0.851858 ,val loss : 0.392354 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :466 ]train loss : 0.322470 ,train acc: 0.849030 ,val loss : 0.386976 ,val acc : 0.824677\n",
      "[ ecpho : 4  iter :467 ]train loss : 0.297370 ,train acc: 0.857809 ,val loss : 0.393475 ,val acc : 0.823578\n",
      "[ ecpho : 4  iter :468 ]train loss : 0.397283 ,train acc: 0.818095 ,val loss : 0.394462 ,val acc : 0.823639\n",
      "[ ecpho : 4  iter :469 ]train loss : 0.259442 ,train acc: 0.878296 ,val loss : 0.394369 ,val acc : 0.825317\n",
      "[ ecpho : 4  iter :470 ]train loss : 0.345184 ,train acc: 0.838847 ,val loss : 0.394368 ,val acc : 0.821808\n",
      "[ ecpho : 4  iter :471 ]train loss : 0.301567 ,train acc: 0.856791 ,val loss : 0.395692 ,val acc : 0.820892\n",
      "[ ecpho : 4  iter :472 ]train loss : 0.344319 ,train acc: 0.814921 ,val loss : 0.392736 ,val acc : 0.822266\n",
      "[ ecpho : 4  iter :473 ]train loss : 0.363011 ,train acc: 0.847280 ,val loss : 0.395511 ,val acc : 0.821777\n",
      "[ ecpho : 4  iter :474 ]train loss : 0.259043 ,train acc: 0.873840 ,val loss : 0.394561 ,val acc : 0.821228\n",
      "[ ecpho : 4  iter :475 ]train loss : 0.419686 ,train acc: 0.830312 ,val loss : 0.395768 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :476 ]train loss : 0.354064 ,train acc: 0.819814 ,val loss : 0.389692 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :477 ]train loss : 0.292595 ,train acc: 0.865784 ,val loss : 0.393389 ,val acc : 0.822357\n",
      "[ ecpho : 4  iter :478 ]train loss : 0.314280 ,train acc: 0.844686 ,val loss : 0.393114 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :479 ]train loss : 0.252171 ,train acc: 0.874624 ,val loss : 0.389425 ,val acc : 0.825317\n",
      "[ ecpho : 4  iter :480 ]train loss : 0.246252 ,train acc: 0.879313 ,val loss : 0.390752 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :481 ]train loss : 0.312603 ,train acc: 0.863739 ,val loss : 0.392545 ,val acc : 0.821350\n",
      "[ ecpho : 4  iter :482 ]train loss : 0.369361 ,train acc: 0.850322 ,val loss : 0.398395 ,val acc : 0.820343\n",
      "[ ecpho : 4  iter :483 ]train loss : 0.365397 ,train acc: 0.844269 ,val loss : 0.392041 ,val acc : 0.823547\n",
      "[ ecpho : 4  iter :484 ]train loss : 0.284925 ,train acc: 0.863922 ,val loss : 0.396182 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :485 ]train loss : 0.330089 ,train acc: 0.850973 ,val loss : 0.392095 ,val acc : 0.821503\n",
      "[ ecpho : 4  iter :486 ]train loss : 0.360187 ,train acc: 0.833323 ,val loss : 0.389007 ,val acc : 0.823029\n",
      "[ ecpho : 4  iter :487 ]train loss : 0.317075 ,train acc: 0.859233 ,val loss : 0.394251 ,val acc : 0.820923\n",
      "[ ecpho : 4  iter :488 ]train loss : 0.276663 ,train acc: 0.869548 ,val loss : 0.393588 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :489 ]train loss : 0.350575 ,train acc: 0.843231 ,val loss : 0.395817 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :490 ]train loss : 0.276091 ,train acc: 0.870046 ,val loss : 0.393965 ,val acc : 0.825104\n",
      "[ ecpho : 4  iter :491 ]train loss : 0.374310 ,train acc: 0.845286 ,val loss : 0.390755 ,val acc : 0.822113\n",
      "[ ecpho : 4  iter :492 ]train loss : 0.274122 ,train acc: 0.865336 ,val loss : 0.394463 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :493 ]train loss : 0.364462 ,train acc: 0.846507 ,val loss : 0.390812 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :494 ]train loss : 0.325324 ,train acc: 0.857035 ,val loss : 0.396767 ,val acc : 0.824005\n",
      "[ ecpho : 4  iter :495 ]train loss : 0.254973 ,train acc: 0.876851 ,val loss : 0.396083 ,val acc : 0.821777\n",
      "[ ecpho : 4  iter :496 ]train loss : 0.261423 ,train acc: 0.877096 ,val loss : 0.393347 ,val acc : 0.824463\n",
      "[ ecpho : 4  iter :497 ]train loss : 0.305974 ,train acc: 0.850901 ,val loss : 0.385175 ,val acc : 0.826172\n",
      "[ ecpho : 4  iter :498 ]train loss : 0.339404 ,train acc: 0.857636 ,val loss : 0.395854 ,val acc : 0.820862\n",
      "[ ecpho : 4  iter :499 ]train loss : 0.303846 ,train acc: 0.851634 ,val loss : 0.393681 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :500 ]train loss : 0.257380 ,train acc: 0.876139 ,val loss : 0.393326 ,val acc : 0.820343\n",
      "[ ecpho : 4  iter :501 ]train loss : 0.251608 ,train acc: 0.876882 ,val loss : 0.395016 ,val acc : 0.821320\n",
      "[ ecpho : 4  iter :502 ]train loss : 0.245715 ,train acc: 0.881236 ,val loss : 0.391225 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :503 ]train loss : 0.319115 ,train acc: 0.847880 ,val loss : 0.394775 ,val acc : 0.818909\n",
      "[ ecpho : 4  iter :504 ]train loss : 0.288127 ,train acc: 0.859914 ,val loss : 0.393729 ,val acc : 0.823853\n",
      "[ ecpho : 4  iter :505 ]train loss : 0.278150 ,train acc: 0.864970 ,val loss : 0.391744 ,val acc : 0.824432\n",
      "[ ecpho : 4  iter :506 ]train loss : 0.318817 ,train acc: 0.856222 ,val loss : 0.391136 ,val acc : 0.824829\n",
      "[ ecpho : 4  iter :507 ]train loss : 0.296424 ,train acc: 0.860413 ,val loss : 0.392395 ,val acc : 0.822662\n",
      "[ ecpho : 4  iter :508 ]train loss : 0.297805 ,train acc: 0.855093 ,val loss : 0.392839 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :509 ]train loss : 0.294340 ,train acc: 0.854706 ,val loss : 0.396198 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :510 ]train loss : 0.325628 ,train acc: 0.839162 ,val loss : 0.388206 ,val acc : 0.825592\n",
      "[ ecpho : 4  iter :511 ]train loss : 0.306306 ,train acc: 0.848165 ,val loss : 0.396924 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :512 ]train loss : 0.300374 ,train acc: 0.864889 ,val loss : 0.390948 ,val acc : 0.819092\n",
      "[ ecpho : 4  iter :513 ]train loss : 0.305444 ,train acc: 0.839498 ,val loss : 0.390531 ,val acc : 0.822205\n",
      "[ ecpho : 4  iter :514 ]train loss : 0.319820 ,train acc: 0.846375 ,val loss : 0.395469 ,val acc : 0.826111\n",
      "[ ecpho : 4  iter :515 ]train loss : 0.271796 ,train acc: 0.866669 ,val loss : 0.393020 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :516 ]train loss : 0.267641 ,train acc: 0.870361 ,val loss : 0.390090 ,val acc : 0.821350\n",
      "[ ecpho : 4  iter :517 ]train loss : 0.347788 ,train acc: 0.818329 ,val loss : 0.392339 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :518 ]train loss : 0.278164 ,train acc: 0.868479 ,val loss : 0.390439 ,val acc : 0.821411\n",
      "[ ecpho : 4  iter :519 ]train loss : 0.352940 ,train acc: 0.846721 ,val loss : 0.393188 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :520 ]train loss : 0.329126 ,train acc: 0.827545 ,val loss : 0.396244 ,val acc : 0.820526\n",
      "[ ecpho : 4  iter :521 ]train loss : 0.322256 ,train acc: 0.854716 ,val loss : 0.394188 ,val acc : 0.818756\n",
      "[ ecpho : 4  iter :522 ]train loss : 0.244780 ,train acc: 0.882050 ,val loss : 0.395372 ,val acc : 0.819794\n",
      "[ ecpho : 4  iter :523 ]train loss : 0.352457 ,train acc: 0.831146 ,val loss : 0.393282 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :524 ]train loss : 0.430872 ,train acc: 0.799927 ,val loss : 0.391818 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :525 ]train loss : 0.365592 ,train acc: 0.841766 ,val loss : 0.389113 ,val acc : 0.824402\n",
      "[ ecpho : 4  iter :526 ]train loss : 0.323592 ,train acc: 0.836355 ,val loss : 0.392944 ,val acc : 0.820190\n",
      "[ ecpho : 4  iter :527 ]train loss : 0.299297 ,train acc: 0.844859 ,val loss : 0.392035 ,val acc : 0.825653\n",
      "[ ecpho : 4  iter :528 ]train loss : 0.260428 ,train acc: 0.875468 ,val loss : 0.392313 ,val acc : 0.819946\n",
      "[ ecpho : 4  iter :529 ]train loss : 0.342012 ,train acc: 0.833751 ,val loss : 0.392323 ,val acc : 0.824829\n",
      "[ ecpho : 4  iter :530 ]train loss : 0.291495 ,train acc: 0.853221 ,val loss : 0.397713 ,val acc : 0.818939\n",
      "[ ecpho : 4  iter :531 ]train loss : 0.263200 ,train acc: 0.870158 ,val loss : 0.396058 ,val acc : 0.820862\n",
      "[ ecpho : 4  iter :532 ]train loss : 0.348810 ,train acc: 0.834076 ,val loss : 0.398181 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :533 ]train loss : 0.435200 ,train acc: 0.814209 ,val loss : 0.391050 ,val acc : 0.821930\n",
      "[ ecpho : 4  iter :534 ]train loss : 0.280665 ,train acc: 0.867371 ,val loss : 0.387127 ,val acc : 0.825806\n",
      "[ ecpho : 4  iter :535 ]train loss : 0.295972 ,train acc: 0.863597 ,val loss : 0.391215 ,val acc : 0.826965\n",
      "[ ecpho : 4  iter :536 ]train loss : 0.293377 ,train acc: 0.856598 ,val loss : 0.393888 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :537 ]train loss : 0.277553 ,train acc: 0.875326 ,val loss : 0.398458 ,val acc : 0.820679\n",
      "[ ecpho : 4  iter :538 ]train loss : 0.318667 ,train acc: 0.856568 ,val loss : 0.389662 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :539 ]train loss : 0.292831 ,train acc: 0.857391 ,val loss : 0.389734 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :540 ]train loss : 0.329715 ,train acc: 0.845479 ,val loss : 0.390804 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :541 ]train loss : 0.395439 ,train acc: 0.816325 ,val loss : 0.396567 ,val acc : 0.821289\n",
      "[ ecpho : 4  iter :542 ]train loss : 0.253961 ,train acc: 0.878143 ,val loss : 0.383305 ,val acc : 0.827667\n",
      "[ ecpho : 4  iter :543 ]train loss : 0.236821 ,train acc: 0.883820 ,val loss : 0.396885 ,val acc : 0.822906\n",
      "[ ecpho : 4  iter :544 ]train loss : 0.272054 ,train acc: 0.869517 ,val loss : 0.393322 ,val acc : 0.818451\n",
      "[ ecpho : 4  iter :545 ]train loss : 0.279441 ,train acc: 0.865509 ,val loss : 0.394356 ,val acc : 0.824280\n",
      "[ ecpho : 4  iter :546 ]train loss : 0.342216 ,train acc: 0.849976 ,val loss : 0.397924 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :547 ]train loss : 0.392284 ,train acc: 0.834076 ,val loss : 0.391628 ,val acc : 0.824951\n",
      "[ ecpho : 4  iter :548 ]train loss : 0.296303 ,train acc: 0.866353 ,val loss : 0.389885 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :549 ]train loss : 0.373497 ,train acc: 0.823639 ,val loss : 0.393977 ,val acc : 0.821136\n",
      "[ ecpho : 4  iter :550 ]train loss : 0.409948 ,train acc: 0.838532 ,val loss : 0.392686 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :551 ]train loss : 0.293918 ,train acc: 0.856374 ,val loss : 0.387946 ,val acc : 0.826752\n",
      "[ ecpho : 4  iter :552 ]train loss : 0.296954 ,train acc: 0.861410 ,val loss : 0.385364 ,val acc : 0.822937\n",
      "[ ecpho : 4  iter :553 ]train loss : 0.278549 ,train acc: 0.865275 ,val loss : 0.391352 ,val acc : 0.824219\n",
      "[ ecpho : 4  iter :554 ]train loss : 0.356278 ,train acc: 0.844523 ,val loss : 0.389597 ,val acc : 0.820557\n",
      "[ ecpho : 4  iter :555 ]train loss : 0.249162 ,train acc: 0.880839 ,val loss : 0.389218 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :556 ]train loss : 0.304012 ,train acc: 0.858978 ,val loss : 0.390731 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :557 ]train loss : 0.382345 ,train acc: 0.822235 ,val loss : 0.393525 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :558 ]train loss : 0.295161 ,train acc: 0.863109 ,val loss : 0.392175 ,val acc : 0.820831\n",
      "[ ecpho : 4  iter :559 ]train loss : 0.541285 ,train acc: 0.818268 ,val loss : 0.389774 ,val acc : 0.826141\n",
      "[ ecpho : 4  iter :560 ]train loss : 0.314467 ,train acc: 0.857269 ,val loss : 0.389947 ,val acc : 0.823730\n",
      "[ ecpho : 4  iter :561 ]train loss : 0.290465 ,train acc: 0.870310 ,val loss : 0.386548 ,val acc : 0.824615\n",
      "[ ecpho : 4  iter :562 ]train loss : 0.391453 ,train acc: 0.785095 ,val loss : 0.393167 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :563 ]train loss : 0.288062 ,train acc: 0.864299 ,val loss : 0.387851 ,val acc : 0.825928\n",
      "[ ecpho : 4  iter :564 ]train loss : 0.355879 ,train acc: 0.846080 ,val loss : 0.390590 ,val acc : 0.826019\n",
      "[ ecpho : 4  iter :565 ]train loss : 0.354574 ,train acc: 0.844930 ,val loss : 0.386680 ,val acc : 0.824677\n",
      "[ ecpho : 4  iter :566 ]train loss : 0.294396 ,train acc: 0.851654 ,val loss : 0.392773 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :567 ]train loss : 0.357641 ,train acc: 0.839518 ,val loss : 0.386896 ,val acc : 0.826050\n",
      "[ ecpho : 4  iter :568 ]train loss : 0.488892 ,train acc: 0.831442 ,val loss : 0.394330 ,val acc : 0.819489\n",
      "[ ecpho : 4  iter :569 ]train loss : 0.285748 ,train acc: 0.863556 ,val loss : 0.389872 ,val acc : 0.819763\n",
      "[ ecpho : 4  iter :570 ]train loss : 0.282555 ,train acc: 0.868795 ,val loss : 0.396903 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :571 ]train loss : 0.319690 ,train acc: 0.848684 ,val loss : 0.392851 ,val acc : 0.819763\n",
      "[ ecpho : 4  iter :572 ]train loss : 0.310107 ,train acc: 0.845235 ,val loss : 0.392752 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :573 ]train loss : 0.315583 ,train acc: 0.850973 ,val loss : 0.393774 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :574 ]train loss : 0.333405 ,train acc: 0.850291 ,val loss : 0.394444 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :575 ]train loss : 0.254577 ,train acc: 0.876790 ,val loss : 0.389126 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :576 ]train loss : 0.289159 ,train acc: 0.869904 ,val loss : 0.390564 ,val acc : 0.824158\n",
      "[ ecpho : 4  iter :577 ]train loss : 0.324560 ,train acc: 0.843547 ,val loss : 0.396297 ,val acc : 0.823181\n",
      "[ ecpho : 4  iter :578 ]train loss : 0.328332 ,train acc: 0.832103 ,val loss : 0.395403 ,val acc : 0.819000\n",
      "[ ecpho : 4  iter :579 ]train loss : 0.275065 ,train acc: 0.864746 ,val loss : 0.397838 ,val acc : 0.819641\n",
      "[ ecpho : 4  iter :580 ]train loss : 0.262534 ,train acc: 0.869812 ,val loss : 0.397592 ,val acc : 0.823700\n",
      "[ ecpho : 4  iter :581 ]train loss : 0.345280 ,train acc: 0.826101 ,val loss : 0.396806 ,val acc : 0.823120\n",
      "[ ecpho : 4  iter :582 ]train loss : 0.307343 ,train acc: 0.845144 ,val loss : 0.390568 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :583 ]train loss : 0.410626 ,train acc: 0.824921 ,val loss : 0.395032 ,val acc : 0.824310\n",
      "[ ecpho : 4  iter :584 ]train loss : 0.292523 ,train acc: 0.852102 ,val loss : 0.393323 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :585 ]train loss : 0.258122 ,train acc: 0.876261 ,val loss : 0.392121 ,val acc : 0.823395\n",
      "[ ecpho : 4  iter :586 ]train loss : 0.416500 ,train acc: 0.821961 ,val loss : 0.395221 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :587 ]train loss : 0.297085 ,train acc: 0.862681 ,val loss : 0.398967 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :588 ]train loss : 0.312367 ,train acc: 0.848460 ,val loss : 0.390954 ,val acc : 0.824432\n",
      "[ ecpho : 4  iter :589 ]train loss : 0.317380 ,train acc: 0.855001 ,val loss : 0.389659 ,val acc : 0.820526\n",
      "[ ecpho : 4  iter :590 ]train loss : 0.361687 ,train acc: 0.829448 ,val loss : 0.396534 ,val acc : 0.821747\n",
      "[ ecpho : 4  iter :591 ]train loss : 0.317347 ,train acc: 0.857432 ,val loss : 0.403077 ,val acc : 0.818695\n",
      "[ ecpho : 4  iter :592 ]train loss : 0.339733 ,train acc: 0.832550 ,val loss : 0.384668 ,val acc : 0.825226\n",
      "[ ecpho : 4  iter :593 ]train loss : 0.291529 ,train acc: 0.855367 ,val loss : 0.386434 ,val acc : 0.826172\n",
      "[ ecpho : 4  iter :594 ]train loss : 0.275955 ,train acc: 0.866984 ,val loss : 0.389360 ,val acc : 0.823639\n",
      "[ ecpho : 4  iter :595 ]train loss : 0.723732 ,train acc: 0.759054 ,val loss : 0.386068 ,val acc : 0.826752\n",
      "[ ecpho : 4  iter :596 ]train loss : 0.269035 ,train acc: 0.872121 ,val loss : 0.387277 ,val acc : 0.827393\n",
      "[ ecpho : 4  iter :597 ]train loss : 0.307615 ,train acc: 0.857147 ,val loss : 0.393450 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :598 ]train loss : 0.336185 ,train acc: 0.821930 ,val loss : 0.386735 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :599 ]train loss : 0.257277 ,train acc: 0.879384 ,val loss : 0.390650 ,val acc : 0.822815\n",
      "[ ecpho : 4  iter :600 ]train loss : 0.393736 ,train acc: 0.833954 ,val loss : 0.394023 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :601 ]train loss : 0.265414 ,train acc: 0.876333 ,val loss : 0.391492 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :602 ]train loss : 0.335836 ,train acc: 0.841624 ,val loss : 0.394626 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :603 ]train loss : 0.320861 ,train acc: 0.841990 ,val loss : 0.391546 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :604 ]train loss : 0.375645 ,train acc: 0.848023 ,val loss : 0.396785 ,val acc : 0.824310\n",
      "[ ecpho : 4  iter :605 ]train loss : 0.277630 ,train acc: 0.868622 ,val loss : 0.397281 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :606 ]train loss : 0.312391 ,train acc: 0.846985 ,val loss : 0.389307 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :607 ]train loss : 0.397624 ,train acc: 0.835856 ,val loss : 0.396159 ,val acc : 0.823486\n",
      "[ ecpho : 4  iter :608 ]train loss : 0.309570 ,train acc: 0.858826 ,val loss : 0.391429 ,val acc : 0.823029\n",
      "[ ecpho : 4  iter :609 ]train loss : 0.256224 ,train acc: 0.873342 ,val loss : 0.390240 ,val acc : 0.821869\n",
      "[ ecpho : 4  iter :610 ]train loss : 0.275407 ,train acc: 0.866160 ,val loss : 0.394142 ,val acc : 0.823608\n",
      "[ ecpho : 4  iter :611 ]train loss : 0.536951 ,train acc: 0.792104 ,val loss : 0.388825 ,val acc : 0.825348\n",
      "[ ecpho : 4  iter :612 ]train loss : 0.303899 ,train acc: 0.863210 ,val loss : 0.393828 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :613 ]train loss : 0.419086 ,train acc: 0.810100 ,val loss : 0.390620 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :614 ]train loss : 0.279450 ,train acc: 0.869771 ,val loss : 0.394233 ,val acc : 0.822327\n",
      "[ ecpho : 4  iter :615 ]train loss : 0.360922 ,train acc: 0.841278 ,val loss : 0.388791 ,val acc : 0.824585\n",
      "[ ecpho : 4  iter :616 ]train loss : 0.268830 ,train acc: 0.872599 ,val loss : 0.391436 ,val acc : 0.821655\n",
      "[ ecpho : 4  iter :617 ]train loss : 0.404016 ,train acc: 0.783661 ,val loss : 0.397692 ,val acc : 0.822205\n",
      "[ ecpho : 4  iter :618 ]train loss : 0.296766 ,train acc: 0.861125 ,val loss : 0.392004 ,val acc : 0.823944\n",
      "[ ecpho : 4  iter :619 ]train loss : 0.276000 ,train acc: 0.868408 ,val loss : 0.393010 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :620 ]train loss : 0.383447 ,train acc: 0.815938 ,val loss : 0.394029 ,val acc : 0.820007\n",
      "[ ecpho : 4  iter :621 ]train loss : 0.273559 ,train acc: 0.869741 ,val loss : 0.390768 ,val acc : 0.822266\n",
      "[ ecpho : 4  iter :622 ]train loss : 0.355959 ,train acc: 0.811127 ,val loss : 0.391954 ,val acc : 0.821930\n",
      "[ ecpho : 4  iter :623 ]train loss : 0.336908 ,train acc: 0.859538 ,val loss : 0.387325 ,val acc : 0.825623\n",
      "[ ecpho : 4  iter :624 ]train loss : 0.299025 ,train acc: 0.863251 ,val loss : 0.390528 ,val acc : 0.820648\n",
      "[ ecpho : 4  iter :625 ]train loss : 0.331260 ,train acc: 0.837128 ,val loss : 0.394122 ,val acc : 0.821991\n",
      "[ ecpho : 4  iter :626 ]train loss : 0.385048 ,train acc: 0.818695 ,val loss : 0.388457 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :627 ]train loss : 0.283527 ,train acc: 0.867554 ,val loss : 0.388141 ,val acc : 0.825378\n",
      "[ ecpho : 4  iter :628 ]train loss : 0.389969 ,train acc: 0.845398 ,val loss : 0.389325 ,val acc : 0.822083\n",
      "[ ecpho : 4  iter :629 ]train loss : 0.318424 ,train acc: 0.858490 ,val loss : 0.393561 ,val acc : 0.822601\n",
      "[ ecpho : 4  iter :630 ]train loss : 0.277143 ,train acc: 0.863647 ,val loss : 0.389511 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :631 ]train loss : 0.266008 ,train acc: 0.872396 ,val loss : 0.389310 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :632 ]train loss : 0.292260 ,train acc: 0.862010 ,val loss : 0.388446 ,val acc : 0.827362\n",
      "[ ecpho : 4  iter :633 ]train loss : 0.352482 ,train acc: 0.845154 ,val loss : 0.387746 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :634 ]train loss : 0.344356 ,train acc: 0.840790 ,val loss : 0.385296 ,val acc : 0.827026\n",
      "[ ecpho : 4  iter :635 ]train loss : 0.288205 ,train acc: 0.860372 ,val loss : 0.391422 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :636 ]train loss : 0.294897 ,train acc: 0.862854 ,val loss : 0.388540 ,val acc : 0.827881\n",
      "[ ecpho : 4  iter :637 ]train loss : 0.335478 ,train acc: 0.853434 ,val loss : 0.398564 ,val acc : 0.820618\n",
      "[ ecpho : 4  iter :638 ]train loss : 0.361764 ,train acc: 0.834310 ,val loss : 0.389626 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :639 ]train loss : 0.433947 ,train acc: 0.800100 ,val loss : 0.395972 ,val acc : 0.823334\n",
      "[ ecpho : 4  iter :640 ]train loss : 0.243360 ,train acc: 0.882660 ,val loss : 0.391208 ,val acc : 0.823334\n",
      "[ ecpho : 4  iter :641 ]train loss : 0.357316 ,train acc: 0.854777 ,val loss : 0.390451 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :642 ]train loss : 0.252511 ,train acc: 0.879059 ,val loss : 0.383300 ,val acc : 0.829681\n",
      "[ ecpho : 4  iter :643 ]train loss : 0.365334 ,train acc: 0.832337 ,val loss : 0.388034 ,val acc : 0.828522\n",
      "[ ecpho : 4  iter :644 ]train loss : 0.313445 ,train acc: 0.851878 ,val loss : 0.389607 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :645 ]train loss : 0.302371 ,train acc: 0.864360 ,val loss : 0.395668 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :646 ]train loss : 0.299306 ,train acc: 0.867706 ,val loss : 0.393032 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :647 ]train loss : 0.300138 ,train acc: 0.859019 ,val loss : 0.393911 ,val acc : 0.821472\n",
      "[ ecpho : 4  iter :648 ]train loss : 0.317093 ,train acc: 0.838654 ,val loss : 0.393586 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :649 ]train loss : 0.281853 ,train acc: 0.864797 ,val loss : 0.391725 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :650 ]train loss : 0.360172 ,train acc: 0.850138 ,val loss : 0.392599 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :651 ]train loss : 0.283917 ,train acc: 0.867462 ,val loss : 0.395134 ,val acc : 0.825012\n",
      "[ ecpho : 4  iter :652 ]train loss : 0.275226 ,train acc: 0.868174 ,val loss : 0.388550 ,val acc : 0.823761\n",
      "[ ecpho : 4  iter :653 ]train loss : 0.356658 ,train acc: 0.841370 ,val loss : 0.394876 ,val acc : 0.820435\n",
      "[ ecpho : 4  iter :654 ]train loss : 0.306993 ,train acc: 0.857930 ,val loss : 0.396812 ,val acc : 0.824738\n",
      "[ ecpho : 4  iter :655 ]train loss : 0.286793 ,train acc: 0.868001 ,val loss : 0.392562 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :656 ]train loss : 0.277556 ,train acc: 0.862457 ,val loss : 0.386561 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :657 ]train loss : 0.296510 ,train acc: 0.853740 ,val loss : 0.393232 ,val acc : 0.821808\n",
      "[ ecpho : 4  iter :658 ]train loss : 0.432359 ,train acc: 0.798198 ,val loss : 0.393688 ,val acc : 0.821991\n",
      "[ ecpho : 4  iter :659 ]train loss : 0.372699 ,train acc: 0.817017 ,val loss : 0.391153 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :660 ]train loss : 0.248656 ,train acc: 0.878764 ,val loss : 0.391668 ,val acc : 0.825012\n",
      "[ ecpho : 4  iter :661 ]train loss : 0.256419 ,train acc: 0.875214 ,val loss : 0.393837 ,val acc : 0.822540\n",
      "[ ecpho : 4  iter :662 ]train loss : 0.265757 ,train acc: 0.868032 ,val loss : 0.390734 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :663 ]train loss : 0.323593 ,train acc: 0.858683 ,val loss : 0.386674 ,val acc : 0.823639\n",
      "[ ecpho : 4  iter :664 ]train loss : 0.258745 ,train acc: 0.877909 ,val loss : 0.389828 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :665 ]train loss : 0.331881 ,train acc: 0.861501 ,val loss : 0.395592 ,val acc : 0.822266\n",
      "[ ecpho : 4  iter :666 ]train loss : 0.274551 ,train acc: 0.871867 ,val loss : 0.390989 ,val acc : 0.824921\n",
      "[ ecpho : 4  iter :667 ]train loss : 0.297815 ,train acc: 0.863108 ,val loss : 0.389579 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :668 ]train loss : 0.378491 ,train acc: 0.814219 ,val loss : 0.394864 ,val acc : 0.818268\n",
      "[ ecpho : 4  iter :669 ]train loss : 0.284202 ,train acc: 0.871684 ,val loss : 0.387073 ,val acc : 0.822937\n",
      "[ ecpho : 4  iter :670 ]train loss : 0.272661 ,train acc: 0.870473 ,val loss : 0.389327 ,val acc : 0.822174\n",
      "[ ecpho : 4  iter :671 ]train loss : 0.354494 ,train acc: 0.838989 ,val loss : 0.389918 ,val acc : 0.825623\n",
      "[ ecpho : 4  iter :672 ]train loss : 0.335651 ,train acc: 0.845042 ,val loss : 0.391022 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :673 ]train loss : 0.271595 ,train acc: 0.869171 ,val loss : 0.389635 ,val acc : 0.824615\n",
      "[ ecpho : 4  iter :674 ]train loss : 0.320448 ,train acc: 0.854401 ,val loss : 0.387179 ,val acc : 0.825317\n",
      "[ ecpho : 4  iter :675 ]train loss : 0.273394 ,train acc: 0.868785 ,val loss : 0.392322 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :676 ]train loss : 0.348334 ,train acc: 0.848928 ,val loss : 0.389756 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :677 ]train loss : 0.269926 ,train acc: 0.868703 ,val loss : 0.390635 ,val acc : 0.820709\n",
      "[ ecpho : 4  iter :678 ]train loss : 0.348080 ,train acc: 0.856944 ,val loss : 0.384575 ,val acc : 0.824280\n",
      "[ ecpho : 4  iter :679 ]train loss : 0.450165 ,train acc: 0.814830 ,val loss : 0.395548 ,val acc : 0.821655\n",
      "[ ecpho : 4  iter :680 ]train loss : 0.251579 ,train acc: 0.879812 ,val loss : 0.389236 ,val acc : 0.826385\n",
      "[ ecpho : 4  iter :681 ]train loss : 0.279200 ,train acc: 0.872193 ,val loss : 0.387645 ,val acc : 0.823639\n",
      "[ ecpho : 4  iter :682 ]train loss : 0.290436 ,train acc: 0.865255 ,val loss : 0.386884 ,val acc : 0.825958\n",
      "[ ecpho : 4  iter :683 ]train loss : 0.327457 ,train acc: 0.844076 ,val loss : 0.390611 ,val acc : 0.823242\n",
      "[ ecpho : 4  iter :684 ]train loss : 0.319777 ,train acc: 0.855876 ,val loss : 0.385595 ,val acc : 0.826843\n",
      "[ ecpho : 4  iter :685 ]train loss : 0.232610 ,train acc: 0.886292 ,val loss : 0.401448 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :686 ]train loss : 0.307868 ,train acc: 0.861094 ,val loss : 0.390587 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :687 ]train loss : 0.270376 ,train acc: 0.869069 ,val loss : 0.388195 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :688 ]train loss : 0.334862 ,train acc: 0.858755 ,val loss : 0.390904 ,val acc : 0.821747\n",
      "[ ecpho : 4  iter :689 ]train loss : 0.279107 ,train acc: 0.867757 ,val loss : 0.389553 ,val acc : 0.825348\n",
      "[ ecpho : 4  iter :690 ]train loss : 0.352132 ,train acc: 0.841024 ,val loss : 0.390668 ,val acc : 0.823395\n",
      "[ ecpho : 4  iter :691 ]train loss : 0.287747 ,train acc: 0.864034 ,val loss : 0.391878 ,val acc : 0.822113\n",
      "[ ecpho : 4  iter :692 ]train loss : 0.283253 ,train acc: 0.862946 ,val loss : 0.398082 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :693 ]train loss : 0.273590 ,train acc: 0.873372 ,val loss : 0.393718 ,val acc : 0.823914\n",
      "[ ecpho : 4  iter :694 ]train loss : 0.409574 ,train acc: 0.802206 ,val loss : 0.389043 ,val acc : 0.820770\n",
      "[ ecpho : 4  iter :695 ]train loss : 0.324663 ,train acc: 0.851817 ,val loss : 0.383801 ,val acc : 0.823761\n",
      "[ ecpho : 4  iter :696 ]train loss : 0.386708 ,train acc: 0.801056 ,val loss : 0.386165 ,val acc : 0.826019\n",
      "[ ecpho : 4  iter :697 ]train loss : 0.284704 ,train acc: 0.860179 ,val loss : 0.388457 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :698 ]train loss : 0.266813 ,train acc: 0.868388 ,val loss : 0.391709 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :699 ]train loss : 0.432242 ,train acc: 0.809448 ,val loss : 0.395121 ,val acc : 0.820435\n",
      "[ ecpho : 4  iter :700 ]train loss : 0.287327 ,train acc: 0.861979 ,val loss : 0.388424 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :701 ]train loss : 0.418586 ,train acc: 0.813935 ,val loss : 0.389838 ,val acc : 0.825073\n",
      "[ ecpho : 4  iter :702 ]train loss : 0.232932 ,train acc: 0.885152 ,val loss : 0.394312 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :703 ]train loss : 0.279146 ,train acc: 0.872213 ,val loss : 0.396508 ,val acc : 0.821777\n",
      "[ ecpho : 4  iter :704 ]train loss : 0.359831 ,train acc: 0.844076 ,val loss : 0.387936 ,val acc : 0.826172\n",
      "[ ecpho : 4  iter :705 ]train loss : 0.267693 ,train acc: 0.868724 ,val loss : 0.393673 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :706 ]train loss : 0.349714 ,train acc: 0.843303 ,val loss : 0.389842 ,val acc : 0.824982\n",
      "[ ecpho : 4  iter :707 ]train loss : 0.257139 ,train acc: 0.877442 ,val loss : 0.385304 ,val acc : 0.825592\n",
      "[ ecpho : 4  iter :708 ]train loss : 0.354055 ,train acc: 0.844849 ,val loss : 0.393097 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :709 ]train loss : 0.256283 ,train acc: 0.869273 ,val loss : 0.394240 ,val acc : 0.822784\n",
      "[ ecpho : 4  iter :710 ]train loss : 0.259723 ,train acc: 0.871491 ,val loss : 0.389678 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :711 ]train loss : 0.277759 ,train acc: 0.862488 ,val loss : 0.392455 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :712 ]train loss : 0.324253 ,train acc: 0.843333 ,val loss : 0.390460 ,val acc : 0.820923\n",
      "[ ecpho : 4  iter :713 ]train loss : 0.442703 ,train acc: 0.801005 ,val loss : 0.394326 ,val acc : 0.821808\n",
      "[ ecpho : 4  iter :714 ]train loss : 0.301744 ,train acc: 0.857707 ,val loss : 0.393153 ,val acc : 0.822968\n",
      "[ ecpho : 4  iter :715 ]train loss : 0.272241 ,train acc: 0.866282 ,val loss : 0.393292 ,val acc : 0.823456\n",
      "[ ecpho : 4  iter :716 ]train loss : 0.353417 ,train acc: 0.836365 ,val loss : 0.385685 ,val acc : 0.828094\n",
      "[ ecpho : 4  iter :717 ]train loss : 0.411440 ,train acc: 0.807862 ,val loss : 0.391637 ,val acc : 0.820496\n",
      "[ ecpho : 4  iter :718 ]train loss : 0.377340 ,train acc: 0.816142 ,val loss : 0.392126 ,val acc : 0.825531\n",
      "[ ecpho : 4  iter :719 ]train loss : 0.272059 ,train acc: 0.868001 ,val loss : 0.391823 ,val acc : 0.827423\n",
      "[ ecpho : 4  iter :720 ]train loss : 0.416383 ,train acc: 0.814504 ,val loss : 0.398153 ,val acc : 0.819275\n",
      "[ ecpho : 4  iter :721 ]train loss : 0.494382 ,train acc: 0.823833 ,val loss : 0.390540 ,val acc : 0.821747\n",
      "[ ecpho : 4  iter :722 ]train loss : 0.355948 ,train acc: 0.848063 ,val loss : 0.387980 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :723 ]train loss : 0.355081 ,train acc: 0.839030 ,val loss : 0.394826 ,val acc : 0.821716\n",
      "[ ecpho : 4  iter :724 ]train loss : 0.293283 ,train acc: 0.865468 ,val loss : 0.387842 ,val acc : 0.824554\n",
      "[ ecpho : 4  iter :725 ]train loss : 0.297882 ,train acc: 0.863892 ,val loss : 0.393119 ,val acc : 0.825592\n",
      "[ ecpho : 4  iter :726 ]train loss : 0.430429 ,train acc: 0.774374 ,val loss : 0.392250 ,val acc : 0.821442\n",
      "[ ecpho : 4  iter :727 ]train loss : 0.278116 ,train acc: 0.870504 ,val loss : 0.389022 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :728 ]train loss : 0.384831 ,train acc: 0.839356 ,val loss : 0.392534 ,val acc : 0.821808\n",
      "[ ecpho : 4  iter :729 ]train loss : 0.321652 ,train acc: 0.842428 ,val loss : 0.387300 ,val acc : 0.826721\n",
      "[ ecpho : 4  iter :730 ]train loss : 0.288717 ,train acc: 0.867300 ,val loss : 0.389826 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :731 ]train loss : 0.305434 ,train acc: 0.862834 ,val loss : 0.389515 ,val acc : 0.825134\n",
      "[ ecpho : 4  iter :732 ]train loss : 0.338223 ,train acc: 0.830556 ,val loss : 0.389091 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :733 ]train loss : 0.440345 ,train acc: 0.814179 ,val loss : 0.390878 ,val acc : 0.824280\n",
      "[ ecpho : 4  iter :734 ]train loss : 0.299767 ,train acc: 0.858470 ,val loss : 0.384724 ,val acc : 0.825836\n",
      "[ ecpho : 4  iter :735 ]train loss : 0.352783 ,train acc: 0.817454 ,val loss : 0.392377 ,val acc : 0.820862\n",
      "[ ecpho : 4  iter :736 ]train loss : 0.298377 ,train acc: 0.861104 ,val loss : 0.391902 ,val acc : 0.825165\n",
      "[ ecpho : 4  iter :737 ]train loss : 0.329015 ,train acc: 0.838216 ,val loss : 0.389807 ,val acc : 0.825500\n",
      "[ ecpho : 4  iter :738 ]train loss : 0.290540 ,train acc: 0.865794 ,val loss : 0.391317 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :739 ]train loss : 0.299559 ,train acc: 0.855662 ,val loss : 0.391104 ,val acc : 0.822540\n",
      "[ ecpho : 4  iter :740 ]train loss : 0.240805 ,train acc: 0.881246 ,val loss : 0.389032 ,val acc : 0.823700\n",
      "[ ecpho : 4  iter :741 ]train loss : 0.376189 ,train acc: 0.844198 ,val loss : 0.386923 ,val acc : 0.826080\n",
      "[ ecpho : 4  iter :742 ]train loss : 0.255710 ,train acc: 0.877228 ,val loss : 0.387658 ,val acc : 0.825500\n",
      "[ ecpho : 4  iter :743 ]train loss : 0.335743 ,train acc: 0.857859 ,val loss : 0.395820 ,val acc : 0.824829\n",
      "[ ecpho : 4  iter :744 ]train loss : 0.334680 ,train acc: 0.847636 ,val loss : 0.388433 ,val acc : 0.825226\n",
      "[ ecpho : 4  iter :745 ]train loss : 0.403998 ,train acc: 0.801687 ,val loss : 0.390041 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :746 ]train loss : 0.432027 ,train acc: 0.782491 ,val loss : 0.389093 ,val acc : 0.824310\n",
      "[ ecpho : 4  iter :747 ]train loss : 0.273531 ,train acc: 0.870168 ,val loss : 0.387730 ,val acc : 0.823944\n",
      "[ ecpho : 4  iter :748 ]train loss : 0.305332 ,train acc: 0.860453 ,val loss : 0.389510 ,val acc : 0.823578\n",
      "[ ecpho : 4  iter :749 ]train loss : 0.326415 ,train acc: 0.856944 ,val loss : 0.393258 ,val acc : 0.821899\n",
      "[ ecpho : 4  iter :750 ]train loss : 0.261915 ,train acc: 0.878733 ,val loss : 0.389145 ,val acc : 0.821625\n",
      "[ ecpho : 4  iter :751 ]train loss : 0.262708 ,train acc: 0.872752 ,val loss : 0.389405 ,val acc : 0.825409\n",
      "[ ecpho : 4  iter :752 ]train loss : 0.496144 ,train acc: 0.809347 ,val loss : 0.390731 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :753 ]train loss : 0.320710 ,train acc: 0.829132 ,val loss : 0.389381 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :754 ]train loss : 0.309903 ,train acc: 0.853333 ,val loss : 0.392264 ,val acc : 0.820953\n",
      "[ ecpho : 4  iter :755 ]train loss : 0.314575 ,train acc: 0.849630 ,val loss : 0.394890 ,val acc : 0.822662\n",
      "[ ecpho : 4  iter :756 ]train loss : 0.243778 ,train acc: 0.881460 ,val loss : 0.387148 ,val acc : 0.822388\n",
      "[ ecpho : 4  iter :757 ]train loss : 0.296320 ,train acc: 0.860484 ,val loss : 0.394861 ,val acc : 0.823059\n",
      "[ ecpho : 4  iter :758 ]train loss : 0.308935 ,train acc: 0.861013 ,val loss : 0.389291 ,val acc : 0.820160\n",
      "[ ecpho : 4  iter :759 ]train loss : 0.309903 ,train acc: 0.849131 ,val loss : 0.389390 ,val acc : 0.826385\n",
      "[ ecpho : 4  iter :760 ]train loss : 0.324636 ,train acc: 0.836314 ,val loss : 0.391688 ,val acc : 0.823730\n",
      "[ ecpho : 4  iter :761 ]train loss : 0.248432 ,train acc: 0.879079 ,val loss : 0.386201 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :762 ]train loss : 0.336217 ,train acc: 0.855723 ,val loss : 0.388250 ,val acc : 0.826141\n",
      "[ ecpho : 4  iter :763 ]train loss : 0.410294 ,train acc: 0.829326 ,val loss : 0.392247 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :764 ]train loss : 0.291470 ,train acc: 0.862661 ,val loss : 0.390374 ,val acc : 0.822571\n",
      "[ ecpho : 4  iter :765 ]train loss : 0.379023 ,train acc: 0.788198 ,val loss : 0.388836 ,val acc : 0.822357\n",
      "[ ecpho : 4  iter :766 ]train loss : 0.284280 ,train acc: 0.858907 ,val loss : 0.387892 ,val acc : 0.823181\n",
      "[ ecpho : 4  iter :767 ]train loss : 0.392582 ,train acc: 0.835439 ,val loss : 0.392438 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :768 ]train loss : 0.243375 ,train acc: 0.881398 ,val loss : 0.388127 ,val acc : 0.825226\n",
      "[ ecpho : 4  iter :769 ]train loss : 0.299270 ,train acc: 0.858948 ,val loss : 0.392602 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :770 ]train loss : 0.291718 ,train acc: 0.862956 ,val loss : 0.387517 ,val acc : 0.823853\n",
      "[ ecpho : 4  iter :771 ]train loss : 0.379872 ,train acc: 0.840597 ,val loss : 0.391998 ,val acc : 0.825287\n",
      "[ ecpho : 4  iter :772 ]train loss : 0.366013 ,train acc: 0.834839 ,val loss : 0.395274 ,val acc : 0.823059\n",
      "[ ecpho : 4  iter :773 ]train loss : 0.353242 ,train acc: 0.827983 ,val loss : 0.385755 ,val acc : 0.824646\n",
      "[ ecpho : 4  iter :774 ]train loss : 0.269850 ,train acc: 0.871002 ,val loss : 0.389114 ,val acc : 0.822968\n",
      "[ ecpho : 4  iter :775 ]train loss : 0.358611 ,train acc: 0.828023 ,val loss : 0.391118 ,val acc : 0.824524\n",
      "[ ecpho : 4  iter :776 ]train loss : 0.289313 ,train acc: 0.863881 ,val loss : 0.387928 ,val acc : 0.826447\n",
      "[ ecpho : 4  iter :777 ]train loss : 0.294194 ,train acc: 0.849701 ,val loss : 0.391752 ,val acc : 0.821533\n",
      "[ ecpho : 4  iter :778 ]train loss : 0.281447 ,train acc: 0.853678 ,val loss : 0.391231 ,val acc : 0.821533\n",
      "[ ecpho : 4  iter :779 ]train loss : 0.285939 ,train acc: 0.864166 ,val loss : 0.387562 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :780 ]train loss : 0.278033 ,train acc: 0.855906 ,val loss : 0.388377 ,val acc : 0.825623\n",
      "[ ecpho : 4  iter :781 ]train loss : 0.273899 ,train acc: 0.872142 ,val loss : 0.393692 ,val acc : 0.823517\n",
      "[ ecpho : 4  iter :782 ]train loss : 0.287938 ,train acc: 0.867391 ,val loss : 0.389597 ,val acc : 0.823029\n",
      "[ ecpho : 4  iter :783 ]train loss : 0.269031 ,train acc: 0.869955 ,val loss : 0.390763 ,val acc : 0.826324\n",
      "[ ecpho : 4  iter :784 ]train loss : 0.373937 ,train acc: 0.829753 ,val loss : 0.392372 ,val acc : 0.821075\n",
      "[ ecpho : 4  iter :785 ]train loss : 0.257006 ,train acc: 0.880076 ,val loss : 0.393121 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :786 ]train loss : 0.317699 ,train acc: 0.862172 ,val loss : 0.387892 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :787 ]train loss : 0.280137 ,train acc: 0.868337 ,val loss : 0.385984 ,val acc : 0.826050\n",
      "[ ecpho : 4  iter :788 ]train loss : 0.305499 ,train acc: 0.855164 ,val loss : 0.388339 ,val acc : 0.821350\n",
      "[ ecpho : 4  iter :789 ]train loss : 0.275322 ,train acc: 0.870687 ,val loss : 0.388367 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :790 ]train loss : 0.398924 ,train acc: 0.818451 ,val loss : 0.389447 ,val acc : 0.823730\n",
      "[ ecpho : 4  iter :791 ]train loss : 0.526523 ,train acc: 0.822439 ,val loss : 0.388596 ,val acc : 0.825745\n",
      "[ ecpho : 4  iter :792 ]train loss : 0.292223 ,train acc: 0.864349 ,val loss : 0.395544 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :793 ]train loss : 0.262172 ,train acc: 0.877513 ,val loss : 0.392974 ,val acc : 0.821014\n",
      "[ ecpho : 4  iter :794 ]train loss : 0.305484 ,train acc: 0.859396 ,val loss : 0.383988 ,val acc : 0.824829\n",
      "[ ecpho : 4  iter :795 ]train loss : 0.303059 ,train acc: 0.846995 ,val loss : 0.392597 ,val acc : 0.823090\n",
      "[ ecpho : 4  iter :796 ]train loss : 0.289710 ,train acc: 0.856445 ,val loss : 0.386325 ,val acc : 0.826324\n",
      "[ ecpho : 4  iter :797 ]train loss : 0.346639 ,train acc: 0.843872 ,val loss : 0.383793 ,val acc : 0.826996\n",
      "[ ecpho : 4  iter :798 ]train loss : 0.263184 ,train acc: 0.871969 ,val loss : 0.394972 ,val acc : 0.822479\n",
      "[ ecpho : 4  iter :799 ]train loss : 0.466909 ,train acc: 0.795298 ,val loss : 0.390591 ,val acc : 0.821533\n",
      "[ ecpho : 4  iter :800 ]train loss : 0.347087 ,train acc: 0.843760 ,val loss : 0.385104 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :801 ]train loss : 0.307555 ,train acc: 0.858734 ,val loss : 0.391545 ,val acc : 0.820038\n",
      "[ ecpho : 4  iter :802 ]train loss : 0.320154 ,train acc: 0.847738 ,val loss : 0.395287 ,val acc : 0.821014\n",
      "[ ecpho : 4  iter :803 ]train loss : 0.341049 ,train acc: 0.845052 ,val loss : 0.391164 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :804 ]train loss : 0.263814 ,train acc: 0.878011 ,val loss : 0.389066 ,val acc : 0.826721\n",
      "[ ecpho : 4  iter :805 ]train loss : 0.293360 ,train acc: 0.860931 ,val loss : 0.389570 ,val acc : 0.825012\n",
      "[ ecpho : 4  iter :806 ]train loss : 0.435903 ,train acc: 0.826833 ,val loss : 0.390110 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :807 ]train loss : 0.336890 ,train acc: 0.850383 ,val loss : 0.387197 ,val acc : 0.822113\n",
      "[ ecpho : 4  iter :808 ]train loss : 0.482839 ,train acc: 0.808563 ,val loss : 0.388716 ,val acc : 0.827515\n",
      "[ ecpho : 4  iter :809 ]train loss : 0.432409 ,train acc: 0.804006 ,val loss : 0.380657 ,val acc : 0.827332\n",
      "[ ecpho : 4  iter :810 ]train loss : 0.311675 ,train acc: 0.867116 ,val loss : 0.389840 ,val acc : 0.822937\n",
      "[ ecpho : 4  iter :811 ]train loss : 0.271402 ,train acc: 0.874135 ,val loss : 0.392127 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :812 ]train loss : 0.278280 ,train acc: 0.868174 ,val loss : 0.395052 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :813 ]train loss : 0.393899 ,train acc: 0.822540 ,val loss : 0.391741 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :814 ]train loss : 0.271215 ,train acc: 0.866587 ,val loss : 0.391487 ,val acc : 0.823242\n",
      "[ ecpho : 4  iter :815 ]train loss : 0.314197 ,train acc: 0.847616 ,val loss : 0.399108 ,val acc : 0.821136\n",
      "[ ecpho : 4  iter :816 ]train loss : 0.388737 ,train acc: 0.828685 ,val loss : 0.387664 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :817 ]train loss : 0.336161 ,train acc: 0.844452 ,val loss : 0.388346 ,val acc : 0.824554\n",
      "[ ecpho : 4  iter :818 ]train loss : 0.346999 ,train acc: 0.811534 ,val loss : 0.386166 ,val acc : 0.825897\n",
      "[ ecpho : 4  iter :819 ]train loss : 0.306301 ,train acc: 0.838582 ,val loss : 0.385189 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :820 ]train loss : 0.345670 ,train acc: 0.851268 ,val loss : 0.387839 ,val acc : 0.824280\n",
      "[ ecpho : 4  iter :821 ]train loss : 0.353820 ,train acc: 0.829346 ,val loss : 0.391136 ,val acc : 0.825378\n",
      "[ ecpho : 4  iter :822 ]train loss : 0.312828 ,train acc: 0.855662 ,val loss : 0.385900 ,val acc : 0.823273\n",
      "[ ecpho : 4  iter :823 ]train loss : 0.294425 ,train acc: 0.859294 ,val loss : 0.390727 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :824 ]train loss : 0.265653 ,train acc: 0.869049 ,val loss : 0.386808 ,val acc : 0.828003\n",
      "[ ecpho : 4  iter :825 ]train loss : 0.241606 ,train acc: 0.881877 ,val loss : 0.389655 ,val acc : 0.824768\n",
      "[ ecpho : 4  iter :826 ]train loss : 0.266594 ,train acc: 0.869995 ,val loss : 0.387659 ,val acc : 0.825684\n",
      "[ ecpho : 4  iter :827 ]train loss : 0.267903 ,train acc: 0.871867 ,val loss : 0.393673 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :828 ]train loss : 0.331046 ,train acc: 0.845622 ,val loss : 0.388389 ,val acc : 0.823914\n",
      "[ ecpho : 4  iter :829 ]train loss : 0.294779 ,train acc: 0.862956 ,val loss : 0.389382 ,val acc : 0.820435\n",
      "[ ecpho : 4  iter :830 ]train loss : 0.312022 ,train acc: 0.852041 ,val loss : 0.385369 ,val acc : 0.821899\n",
      "[ ecpho : 4  iter :831 ]train loss : 0.310998 ,train acc: 0.853638 ,val loss : 0.388627 ,val acc : 0.825836\n",
      "[ ecpho : 4  iter :832 ]train loss : 0.333416 ,train acc: 0.829661 ,val loss : 0.391944 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :833 ]train loss : 0.324024 ,train acc: 0.858968 ,val loss : 0.392486 ,val acc : 0.820221\n",
      "[ ecpho : 4  iter :834 ]train loss : 0.285536 ,train acc: 0.859955 ,val loss : 0.388603 ,val acc : 0.826050\n",
      "[ ecpho : 4  iter :835 ]train loss : 0.278181 ,train acc: 0.864919 ,val loss : 0.393177 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :836 ]train loss : 0.279390 ,train acc: 0.864258 ,val loss : 0.393013 ,val acc : 0.822845\n",
      "[ ecpho : 4  iter :837 ]train loss : 0.314088 ,train acc: 0.865906 ,val loss : 0.388373 ,val acc : 0.825134\n",
      "[ ecpho : 4  iter :838 ]train loss : 0.390533 ,train acc: 0.790233 ,val loss : 0.391288 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :839 ]train loss : 0.272023 ,train acc: 0.872406 ,val loss : 0.391262 ,val acc : 0.826263\n",
      "[ ecpho : 4  iter :840 ]train loss : 0.431602 ,train acc: 0.804810 ,val loss : 0.388286 ,val acc : 0.823029\n",
      "[ ecpho : 4  iter :841 ]train loss : 0.332362 ,train acc: 0.817475 ,val loss : 0.389240 ,val acc : 0.825104\n",
      "[ ecpho : 4  iter :842 ]train loss : 0.401617 ,train acc: 0.804830 ,val loss : 0.384809 ,val acc : 0.826477\n",
      "[ ecpho : 4  iter :843 ]train loss : 0.453183 ,train acc: 0.806356 ,val loss : 0.388329 ,val acc : 0.825867\n",
      "[ ecpho : 4  iter :844 ]train loss : 0.248633 ,train acc: 0.879354 ,val loss : 0.384887 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :845 ]train loss : 0.238189 ,train acc: 0.882823 ,val loss : 0.389739 ,val acc : 0.825195\n",
      "[ ecpho : 4  iter :846 ]train loss : 0.266057 ,train acc: 0.869883 ,val loss : 0.387549 ,val acc : 0.823059\n",
      "[ ecpho : 4  iter :847 ]train loss : 0.269231 ,train acc: 0.871063 ,val loss : 0.386430 ,val acc : 0.825073\n",
      "[ ecpho : 4  iter :848 ]train loss : 0.307442 ,train acc: 0.854553 ,val loss : 0.389753 ,val acc : 0.823547\n",
      "[ ecpho : 4  iter :849 ]train loss : 0.285816 ,train acc: 0.861755 ,val loss : 0.385764 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :850 ]train loss : 0.317933 ,train acc: 0.854838 ,val loss : 0.389187 ,val acc : 0.825745\n",
      "[ ecpho : 4  iter :851 ]train loss : 0.289107 ,train acc: 0.860423 ,val loss : 0.390629 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :852 ]train loss : 0.334801 ,train acc: 0.847168 ,val loss : 0.393651 ,val acc : 0.822510\n",
      "[ ecpho : 4  iter :853 ]train loss : 0.319008 ,train acc: 0.861003 ,val loss : 0.391883 ,val acc : 0.824158\n",
      "[ ecpho : 4  iter :854 ]train loss : 0.351763 ,train acc: 0.830933 ,val loss : 0.383528 ,val acc : 0.826294\n",
      "[ ecpho : 4  iter :855 ]train loss : 0.321659 ,train acc: 0.838521 ,val loss : 0.388101 ,val acc : 0.826447\n",
      "[ ecpho : 4  iter :856 ]train loss : 0.317226 ,train acc: 0.858368 ,val loss : 0.391286 ,val acc : 0.821686\n",
      "[ ecpho : 4  iter :857 ]train loss : 0.303990 ,train acc: 0.855682 ,val loss : 0.387099 ,val acc : 0.820557\n",
      "[ ecpho : 4  iter :858 ]train loss : 0.255702 ,train acc: 0.878103 ,val loss : 0.391605 ,val acc : 0.821594\n",
      "[ ecpho : 4  iter :859 ]train loss : 0.292748 ,train acc: 0.868520 ,val loss : 0.390969 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :860 ]train loss : 0.357594 ,train acc: 0.821472 ,val loss : 0.388424 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :861 ]train loss : 0.268305 ,train acc: 0.874786 ,val loss : 0.386695 ,val acc : 0.826660\n",
      "[ ecpho : 4  iter :862 ]train loss : 0.348149 ,train acc: 0.841217 ,val loss : 0.389350 ,val acc : 0.822540\n",
      "[ ecpho : 4  iter :863 ]train loss : 0.282823 ,train acc: 0.864136 ,val loss : 0.387806 ,val acc : 0.825531\n",
      "[ ecpho : 4  iter :864 ]train loss : 0.346082 ,train acc: 0.854055 ,val loss : 0.395522 ,val acc : 0.822632\n",
      "[ ecpho : 4  iter :865 ]train loss : 0.304034 ,train acc: 0.847728 ,val loss : 0.393312 ,val acc : 0.822754\n",
      "[ ecpho : 4  iter :866 ]train loss : 0.294325 ,train acc: 0.860799 ,val loss : 0.386547 ,val acc : 0.821747\n",
      "[ ecpho : 4  iter :867 ]train loss : 0.302537 ,train acc: 0.836609 ,val loss : 0.395311 ,val acc : 0.824615\n",
      "[ ecpho : 4  iter :868 ]train loss : 0.241791 ,train acc: 0.883270 ,val loss : 0.392363 ,val acc : 0.826691\n",
      "[ ecpho : 4  iter :869 ]train loss : 0.300816 ,train acc: 0.862813 ,val loss : 0.393182 ,val acc : 0.824249\n",
      "[ ecpho : 4  iter :870 ]train loss : 0.283505 ,train acc: 0.858215 ,val loss : 0.390177 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :871 ]train loss : 0.290785 ,train acc: 0.861115 ,val loss : 0.384037 ,val acc : 0.825409\n",
      "[ ecpho : 4  iter :872 ]train loss : 0.245014 ,train acc: 0.881175 ,val loss : 0.396175 ,val acc : 0.821259\n",
      "[ ecpho : 4  iter :873 ]train loss : 0.287013 ,train acc: 0.862162 ,val loss : 0.388683 ,val acc : 0.826813\n",
      "[ ecpho : 4  iter :874 ]train loss : 0.296126 ,train acc: 0.858287 ,val loss : 0.392965 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :875 ]train loss : 0.261777 ,train acc: 0.870056 ,val loss : 0.392362 ,val acc : 0.824036\n",
      "[ ecpho : 4  iter :876 ]train loss : 0.342995 ,train acc: 0.851125 ,val loss : 0.391784 ,val acc : 0.820160\n",
      "[ ecpho : 4  iter :877 ]train loss : 0.356164 ,train acc: 0.855754 ,val loss : 0.386418 ,val acc : 0.825195\n",
      "[ ecpho : 4  iter :878 ]train loss : 0.252563 ,train acc: 0.880147 ,val loss : 0.391045 ,val acc : 0.821014\n",
      "[ ecpho : 4  iter :879 ]train loss : 0.314535 ,train acc: 0.858602 ,val loss : 0.388889 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :880 ]train loss : 0.251439 ,train acc: 0.881042 ,val loss : 0.389459 ,val acc : 0.827789\n",
      "[ ecpho : 4  iter :881 ]train loss : 0.316740 ,train acc: 0.850312 ,val loss : 0.393311 ,val acc : 0.825439\n",
      "[ ecpho : 4  iter :882 ]train loss : 0.300975 ,train acc: 0.851542 ,val loss : 0.387344 ,val acc : 0.821320\n",
      "[ ecpho : 4  iter :883 ]train loss : 0.291229 ,train acc: 0.860352 ,val loss : 0.390227 ,val acc : 0.823334\n",
      "[ ecpho : 4  iter :884 ]train loss : 0.280990 ,train acc: 0.879079 ,val loss : 0.386350 ,val acc : 0.821533\n",
      "[ ecpho : 4  iter :885 ]train loss : 0.318055 ,train acc: 0.856425 ,val loss : 0.384590 ,val acc : 0.826782\n",
      "[ ecpho : 4  iter :886 ]train loss : 0.261340 ,train acc: 0.873881 ,val loss : 0.387617 ,val acc : 0.826019\n",
      "[ ecpho : 4  iter :887 ]train loss : 0.381106 ,train acc: 0.845368 ,val loss : 0.387789 ,val acc : 0.825623\n",
      "[ ecpho : 4  iter :888 ]train loss : 0.304360 ,train acc: 0.859731 ,val loss : 0.392801 ,val acc : 0.821350\n",
      "[ ecpho : 4  iter :889 ]train loss : 0.261471 ,train acc: 0.873901 ,val loss : 0.386117 ,val acc : 0.824310\n",
      "[ ecpho : 4  iter :890 ]train loss : 0.315543 ,train acc: 0.867177 ,val loss : 0.389266 ,val acc : 0.825653\n",
      "[ ecpho : 4  iter :891 ]train loss : 0.371889 ,train acc: 0.806152 ,val loss : 0.386342 ,val acc : 0.823151\n",
      "[ ecpho : 4  iter :892 ]train loss : 0.274983 ,train acc: 0.867147 ,val loss : 0.386001 ,val acc : 0.825256\n",
      "[ ecpho : 4  iter :893 ]train loss : 0.377076 ,train acc: 0.852631 ,val loss : 0.395547 ,val acc : 0.819427\n",
      "[ ecpho : 4  iter :894 ]train loss : 0.339797 ,train acc: 0.848979 ,val loss : 0.395123 ,val acc : 0.822021\n",
      "[ ecpho : 4  iter :895 ]train loss : 0.351873 ,train acc: 0.815989 ,val loss : 0.390021 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :896 ]train loss : 0.378133 ,train acc: 0.847158 ,val loss : 0.395042 ,val acc : 0.821289\n",
      "[ ecpho : 4  iter :897 ]train loss : 0.438904 ,train acc: 0.821320 ,val loss : 0.391489 ,val acc : 0.821289\n",
      "[ ecpho : 4  iter :898 ]train loss : 0.244658 ,train acc: 0.883708 ,val loss : 0.398247 ,val acc : 0.824463\n",
      "[ ecpho : 4  iter :899 ]train loss : 0.272487 ,train acc: 0.866516 ,val loss : 0.391294 ,val acc : 0.823273\n",
      "[ ecpho : 4  iter :900 ]train loss : 0.444043 ,train acc: 0.694916 ,val loss : 0.390798 ,val acc : 0.821381\n",
      "[ ecpho : 4  iter :901 ]train loss : 0.355241 ,train acc: 0.850108 ,val loss : 0.388777 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :902 ]train loss : 0.232561 ,train acc: 0.884969 ,val loss : 0.389235 ,val acc : 0.824219\n",
      "[ ecpho : 4  iter :903 ]train loss : 0.348667 ,train acc: 0.820933 ,val loss : 0.387298 ,val acc : 0.825836\n",
      "[ ecpho : 4  iter :904 ]train loss : 0.333841 ,train acc: 0.851359 ,val loss : 0.394882 ,val acc : 0.824188\n",
      "[ ecpho : 4  iter :905 ]train loss : 0.325534 ,train acc: 0.848104 ,val loss : 0.396216 ,val acc : 0.823853\n",
      "[ ecpho : 4  iter :906 ]train loss : 0.342579 ,train acc: 0.838064 ,val loss : 0.388264 ,val acc : 0.824951\n",
      "[ ecpho : 4  iter :907 ]train loss : 0.270610 ,train acc: 0.867605 ,val loss : 0.385919 ,val acc : 0.829010\n",
      "[ ecpho : 4  iter :908 ]train loss : 0.273833 ,train acc: 0.861745 ,val loss : 0.389343 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :909 ]train loss : 0.316976 ,train acc: 0.860209 ,val loss : 0.393469 ,val acc : 0.821564\n",
      "[ ecpho : 4  iter :910 ]train loss : 0.431003 ,train acc: 0.814647 ,val loss : 0.387256 ,val acc : 0.823242\n",
      "[ ecpho : 4  iter :911 ]train loss : 0.331423 ,train acc: 0.845490 ,val loss : 0.384748 ,val acc : 0.824799\n",
      "[ ecpho : 4  iter :912 ]train loss : 0.348774 ,train acc: 0.849599 ,val loss : 0.396192 ,val acc : 0.822235\n",
      "[ ecpho : 4  iter :913 ]train loss : 0.323028 ,train acc: 0.854116 ,val loss : 0.391783 ,val acc : 0.823608\n",
      "[ ecpho : 4  iter :914 ]train loss : 0.275530 ,train acc: 0.873210 ,val loss : 0.393335 ,val acc : 0.821960\n",
      "[ ecpho : 4  iter :915 ]train loss : 0.304274 ,train acc: 0.849111 ,val loss : 0.393882 ,val acc : 0.820618\n",
      "[ ecpho : 4  iter :916 ]train loss : 0.273808 ,train acc: 0.866669 ,val loss : 0.396533 ,val acc : 0.822235\n",
      "[ ecpho : 4  iter :917 ]train loss : 0.421430 ,train acc: 0.837209 ,val loss : 0.384561 ,val acc : 0.822998\n",
      "[ ecpho : 4  iter :918 ]train loss : 0.238609 ,train acc: 0.883240 ,val loss : 0.386414 ,val acc : 0.822723\n",
      "[ ecpho : 4  iter :919 ]train loss : 0.228031 ,train acc: 0.888306 ,val loss : 0.389485 ,val acc : 0.821838\n",
      "[ ecpho : 4  iter :920 ]train loss : 0.328122 ,train acc: 0.855642 ,val loss : 0.387433 ,val acc : 0.823853\n",
      "[ ecpho : 4  iter :921 ]train loss : 0.380585 ,train acc: 0.823853 ,val loss : 0.388773 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :922 ]train loss : 0.346752 ,train acc: 0.845469 ,val loss : 0.383193 ,val acc : 0.823730\n",
      "[ ecpho : 4  iter :923 ]train loss : 0.337168 ,train acc: 0.828776 ,val loss : 0.384720 ,val acc : 0.825531\n",
      "[ ecpho : 4  iter :924 ]train loss : 0.278432 ,train acc: 0.855520 ,val loss : 0.391270 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :925 ]train loss : 0.277751 ,train acc: 0.863627 ,val loss : 0.385284 ,val acc : 0.823883\n",
      "[ ecpho : 4  iter :926 ]train loss : 0.279832 ,train acc: 0.872040 ,val loss : 0.383055 ,val acc : 0.827118\n",
      "[ ecpho : 4  iter :927 ]train loss : 0.324580 ,train acc: 0.838481 ,val loss : 0.389975 ,val acc : 0.826294\n",
      "[ ecpho : 4  iter :928 ]train loss : 0.296294 ,train acc: 0.862854 ,val loss : 0.391858 ,val acc : 0.823792\n",
      "[ ecpho : 4  iter :929 ]train loss : 0.364490 ,train acc: 0.843038 ,val loss : 0.386503 ,val acc : 0.827057\n",
      "[ ecpho : 4  iter :930 ]train loss : 0.310954 ,train acc: 0.858124 ,val loss : 0.391620 ,val acc : 0.825592\n",
      "[ ecpho : 4  iter :931 ]train loss : 0.266202 ,train acc: 0.869120 ,val loss : 0.389512 ,val acc : 0.828339\n",
      "[ ecpho : 4  iter :932 ]train loss : 0.295044 ,train acc: 0.858154 ,val loss : 0.388779 ,val acc : 0.826660\n",
      "[ ecpho : 4  iter :933 ]train loss : 0.264749 ,train acc: 0.877167 ,val loss : 0.389614 ,val acc : 0.822418\n",
      "[ ecpho : 4  iter :934 ]train loss : 0.309350 ,train acc: 0.849640 ,val loss : 0.384308 ,val acc : 0.823212\n",
      "[ ecpho : 4  iter :935 ]train loss : 0.290855 ,train acc: 0.864939 ,val loss : 0.387553 ,val acc : 0.823669\n",
      "[ ecpho : 4  iter :936 ]train loss : 0.309288 ,train acc: 0.860382 ,val loss : 0.392478 ,val acc : 0.823334\n",
      "[ ecpho : 4  iter :937 ]train loss : 0.530474 ,train acc: 0.775350 ,val loss : 0.385975 ,val acc : 0.825623\n",
      "[ ecpho : 4  iter :938 ]train loss : 0.280724 ,train acc: 0.858907 ,val loss : 0.383854 ,val acc : 0.825348\n",
      "[ ecpho : 4  iter :939 ]train loss : 0.369908 ,train acc: 0.825552 ,val loss : 0.383793 ,val acc : 0.826904\n",
      "[ ecpho : 4  iter :940 ]train loss : 0.271512 ,train acc: 0.872874 ,val loss : 0.393662 ,val acc : 0.822296\n",
      "[ ecpho : 4  iter :941 ]train loss : 0.318949 ,train acc: 0.849915 ,val loss : 0.389783 ,val acc : 0.825134\n",
      "[ ecpho : 4  iter :942 ]train loss : 0.325655 ,train acc: 0.856405 ,val loss : 0.386994 ,val acc : 0.825592\n",
      "[ ecpho : 4  iter :943 ]train loss : 0.236350 ,train acc: 0.886057 ,val loss : 0.393693 ,val acc : 0.824463\n",
      "[ ecpho : 4  iter :944 ]train loss : 0.348052 ,train acc: 0.844991 ,val loss : 0.387502 ,val acc : 0.825348\n",
      "[ ecpho : 4  iter :945 ]train loss : 0.270354 ,train acc: 0.870473 ,val loss : 0.387376 ,val acc : 0.825775\n",
      "[ ecpho : 4  iter :946 ]train loss : 0.316990 ,train acc: 0.838939 ,val loss : 0.389737 ,val acc : 0.823975\n",
      "[ ecpho : 4  iter :947 ]train loss : 0.362351 ,train acc: 0.845246 ,val loss : 0.389402 ,val acc : 0.823914\n",
      "[ ecpho : 4  iter :948 ]train loss : 0.307646 ,train acc: 0.851756 ,val loss : 0.387266 ,val acc : 0.823608\n",
      "[ ecpho : 4  iter :949 ]train loss : 0.290815 ,train acc: 0.864146 ,val loss : 0.385797 ,val acc : 0.826019\n",
      "[ ecpho : 4  iter :950 ]train loss : 0.261675 ,train acc: 0.878998 ,val loss : 0.391236 ,val acc : 0.824951\n",
      "[ ecpho : 4  iter :951 ]train loss : 0.264576 ,train acc: 0.870951 ,val loss : 0.397197 ,val acc : 0.819153\n",
      "[ ecpho : 4  iter :952 ]train loss : 0.297932 ,train acc: 0.866659 ,val loss : 0.390505 ,val acc : 0.825958\n",
      "[ ecpho : 4  iter :953 ]train loss : 0.280367 ,train acc: 0.856690 ,val loss : 0.385843 ,val acc : 0.824097\n",
      "[ ecpho : 4  iter :954 ]train loss : 0.427802 ,train acc: 0.842001 ,val loss : 0.386273 ,val acc : 0.823853\n",
      "[ ecpho : 4  iter :955 ]train loss : 0.272202 ,train acc: 0.868266 ,val loss : 0.393543 ,val acc : 0.825470\n",
      "[ ecpho : 4  iter :956 ]train loss : 0.262926 ,train acc: 0.873159 ,val loss : 0.391693 ,val acc : 0.828369\n",
      "[ ecpho : 4  iter :957 ]train loss : 0.300489 ,train acc: 0.852529 ,val loss : 0.388136 ,val acc : 0.824066\n",
      "[ ecpho : 4  iter :958 ]train loss : 0.345381 ,train acc: 0.845693 ,val loss : 0.388112 ,val acc : 0.824158\n",
      "[ ecpho : 4  iter :959 ]train loss : 0.251344 ,train acc: 0.877838 ,val loss : 0.385912 ,val acc : 0.826172\n",
      "[ ecpho : 4  iter :960 ]train loss : 0.301229 ,train acc: 0.854940 ,val loss : 0.384495 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :961 ]train loss : 0.269288 ,train acc: 0.868693 ,val loss : 0.390221 ,val acc : 0.823456\n",
      "[ ecpho : 4  iter :962 ]train loss : 0.311548 ,train acc: 0.855652 ,val loss : 0.398490 ,val acc : 0.821686\n",
      "[ ecpho : 4  iter :963 ]train loss : 0.283784 ,train acc: 0.870351 ,val loss : 0.390105 ,val acc : 0.822449\n",
      "[ ecpho : 4  iter :964 ]train loss : 0.398327 ,train acc: 0.780874 ,val loss : 0.392050 ,val acc : 0.822693\n",
      "[ ecpho : 4  iter :965 ]train loss : 0.289866 ,train acc: 0.858134 ,val loss : 0.387767 ,val acc : 0.829254\n",
      "[ ecpho : 4  iter :966 ]train loss : 0.281990 ,train acc: 0.858633 ,val loss : 0.391673 ,val acc : 0.823303\n",
      "[ ecpho : 4  iter :967 ]train loss : 0.297301 ,train acc: 0.864329 ,val loss : 0.382785 ,val acc : 0.825043\n",
      "[ ecpho : 4  iter :968 ]train loss : 0.263206 ,train acc: 0.873830 ,val loss : 0.385066 ,val acc : 0.824860\n",
      "[ ecpho : 4  iter :969 ]train loss : 0.275405 ,train acc: 0.868347 ,val loss : 0.383562 ,val acc : 0.825165\n",
      "[ ecpho : 4  iter :970 ]train loss : 0.323951 ,train acc: 0.858551 ,val loss : 0.392438 ,val acc : 0.823425\n",
      "[ ecpho : 4  iter :971 ]train loss : 0.252577 ,train acc: 0.879486 ,val loss : 0.385453 ,val acc : 0.824432\n",
      "[ ecpho : 4  iter :972 ]train loss : 0.306241 ,train acc: 0.852834 ,val loss : 0.386008 ,val acc : 0.826385\n",
      "[ ecpho : 4  iter :973 ]train loss : 0.452668 ,train acc: 0.792755 ,val loss : 0.390532 ,val acc : 0.825897\n",
      "[ ecpho : 4  iter :974 ]train loss : 0.322220 ,train acc: 0.850525 ,val loss : 0.390120 ,val acc : 0.825165\n",
      "[ ecpho : 4  iter :975 ]train loss : 0.418480 ,train acc: 0.842234 ,val loss : 0.386461 ,val acc : 0.825409\n",
      "[ ecpho : 4  iter :976 ]train loss : 0.266923 ,train acc: 0.871287 ,val loss : 0.388343 ,val acc : 0.823364\n",
      "[ ecpho : 4  iter :977 ]train loss : 0.277823 ,train acc: 0.870931 ,val loss : 0.391939 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :978 ]train loss : 0.294778 ,train acc: 0.867605 ,val loss : 0.388059 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :979 ]train loss : 0.274463 ,train acc: 0.867584 ,val loss : 0.396164 ,val acc : 0.823822\n",
      "[ ecpho : 4  iter :980 ]train loss : 0.358667 ,train acc: 0.820771 ,val loss : 0.388127 ,val acc : 0.824677\n",
      "[ ecpho : 4  iter :981 ]train loss : 0.383941 ,train acc: 0.840485 ,val loss : 0.390002 ,val acc : 0.826477\n",
      "[ ecpho : 4  iter :982 ]train loss : 0.332820 ,train acc: 0.849264 ,val loss : 0.387302 ,val acc : 0.824707\n",
      "[ ecpho : 4  iter :983 ]train loss : 0.459871 ,train acc: 0.837148 ,val loss : 0.387670 ,val acc : 0.824738\n",
      "[ ecpho : 4  iter :984 ]train loss : 0.396637 ,train acc: 0.789602 ,val loss : 0.385252 ,val acc : 0.824493\n",
      "[ ecpho : 4  iter :985 ]train loss : 0.253625 ,train acc: 0.878642 ,val loss : 0.387376 ,val acc : 0.824371\n",
      "[ ecpho : 4  iter :986 ]train loss : 0.287145 ,train acc: 0.867116 ,val loss : 0.392960 ,val acc : 0.823181\n",
      "[ ecpho : 4  iter :987 ]train loss : 0.289002 ,train acc: 0.871826 ,val loss : 0.394845 ,val acc : 0.821289\n",
      "[ ecpho : 4  iter :988 ]train loss : 0.297593 ,train acc: 0.871704 ,val loss : 0.389945 ,val acc : 0.824677\n",
      "[ ecpho : 4  iter :989 ]train loss : 0.390015 ,train acc: 0.841248 ,val loss : 0.391320 ,val acc : 0.823273\n",
      "[ ecpho : 4  iter :990 ]train loss : 0.267899 ,train acc: 0.871785 ,val loss : 0.384827 ,val acc : 0.826599\n",
      "[ ecpho : 4  iter :991 ]train loss : 0.425309 ,train acc: 0.825216 ,val loss : 0.389551 ,val acc : 0.825928\n",
      "[ ecpho : 4  iter :992 ]train loss : 0.249655 ,train acc: 0.877523 ,val loss : 0.383888 ,val acc : 0.826050\n",
      "[ ecpho : 4  iter :993 ]train loss : 0.270538 ,train acc: 0.868978 ,val loss : 0.386760 ,val acc : 0.826508\n",
      "[ ecpho : 4  iter :994 ]train loss : 0.361575 ,train acc: 0.807841 ,val loss : 0.391047 ,val acc : 0.824127\n",
      "[ ecpho : 4  iter :995 ]train loss : 0.287492 ,train acc: 0.864777 ,val loss : 0.387702 ,val acc : 0.822815\n",
      "[ ecpho : 4  iter :996 ]train loss : 0.374508 ,train acc: 0.829183 ,val loss : 0.388120 ,val acc : 0.824036\n",
      "[ ecpho : 4  iter :997 ]train loss : 0.313652 ,train acc: 0.861460 ,val loss : 0.393188 ,val acc : 0.822205\n",
      "[ ecpho : 4  iter :998 ]train loss : 0.284146 ,train acc: 0.864777 ,val loss : 0.389823 ,val acc : 0.829071\n",
      "[ ecpho : 4  iter :999 ]train loss : 0.324093 ,train acc: 0.851817 ,val loss : 0.389854 ,val acc : 0.823334\n",
      "[ ecpho : 4  iter :1000 ]train loss : 0.366467 ,train acc: 0.815298 ,val loss : 0.388494 ,val acc : 0.826782\n",
      "=============================================\n",
      "[ 4 ] average train loss : 0.319665 train acc : 0.850928\n",
      "[ ecpho : 5  iter :1 ]train loss : 0.312236 ,train acc: 0.835948 ,val loss : 0.387427 ,val acc : 0.824921\n",
      "[ ecpho : 5  iter :2 ]train loss : 0.314718 ,train acc: 0.864563 ,val loss : 0.387162 ,val acc : 0.823059\n",
      "[ ecpho : 5  iter :3 ]train loss : 0.324933 ,train acc: 0.862508 ,val loss : 0.385624 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :4 ]train loss : 0.276653 ,train acc: 0.871592 ,val loss : 0.385461 ,val acc : 0.828217\n",
      "[ ecpho : 5  iter :5 ]train loss : 0.439405 ,train acc: 0.818889 ,val loss : 0.388528 ,val acc : 0.826874\n",
      "[ ecpho : 5  iter :6 ]train loss : 0.225515 ,train acc: 0.891886 ,val loss : 0.395145 ,val acc : 0.825348\n",
      "[ ecpho : 5  iter :7 ]train loss : 0.321676 ,train acc: 0.844747 ,val loss : 0.386942 ,val acc : 0.823090\n",
      "[ ecpho : 5  iter :8 ]train loss : 0.289660 ,train acc: 0.867055 ,val loss : 0.391939 ,val acc : 0.825073\n",
      "[ ecpho : 5  iter :9 ]train loss : 0.264040 ,train acc: 0.872986 ,val loss : 0.382399 ,val acc : 0.825928\n",
      "[ ecpho : 5  iter :10 ]train loss : 0.286821 ,train acc: 0.861430 ,val loss : 0.386167 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :11 ]train loss : 0.265053 ,train acc: 0.875193 ,val loss : 0.391361 ,val acc : 0.823486\n",
      "[ ecpho : 5  iter :12 ]train loss : 0.280940 ,train acc: 0.869415 ,val loss : 0.390365 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :13 ]train loss : 0.253127 ,train acc: 0.876475 ,val loss : 0.389859 ,val acc : 0.824585\n",
      "[ ecpho : 5  iter :14 ]train loss : 0.311956 ,train acc: 0.857076 ,val loss : 0.398169 ,val acc : 0.820923\n",
      "[ ecpho : 5  iter :15 ]train loss : 0.273364 ,train acc: 0.872803 ,val loss : 0.390117 ,val acc : 0.824402\n",
      "[ ecpho : 5  iter :16 ]train loss : 0.483079 ,train acc: 0.824178 ,val loss : 0.388167 ,val acc : 0.827179\n",
      "[ ecpho : 5  iter :17 ]train loss : 0.289810 ,train acc: 0.859975 ,val loss : 0.390922 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :18 ]train loss : 0.435170 ,train acc: 0.839773 ,val loss : 0.386441 ,val acc : 0.825989\n",
      "[ ecpho : 5  iter :19 ]train loss : 0.284052 ,train acc: 0.866150 ,val loss : 0.390761 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :20 ]train loss : 0.286833 ,train acc: 0.869904 ,val loss : 0.388239 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :21 ]train loss : 0.282650 ,train acc: 0.868428 ,val loss : 0.385476 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :22 ]train loss : 0.320617 ,train acc: 0.860301 ,val loss : 0.388050 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :23 ]train loss : 0.314334 ,train acc: 0.841339 ,val loss : 0.394685 ,val acc : 0.821655\n",
      "[ ecpho : 5  iter :24 ]train loss : 0.437740 ,train acc: 0.791657 ,val loss : 0.389492 ,val acc : 0.821228\n",
      "[ ecpho : 5  iter :25 ]train loss : 0.299607 ,train acc: 0.859975 ,val loss : 0.383928 ,val acc : 0.825623\n",
      "[ ecpho : 5  iter :26 ]train loss : 0.265961 ,train acc: 0.872874 ,val loss : 0.388577 ,val acc : 0.824127\n",
      "[ ecpho : 5  iter :27 ]train loss : 0.306754 ,train acc: 0.819285 ,val loss : 0.392122 ,val acc : 0.822845\n",
      "[ ecpho : 5  iter :28 ]train loss : 0.292543 ,train acc: 0.861613 ,val loss : 0.391354 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :29 ]train loss : 0.241022 ,train acc: 0.884349 ,val loss : 0.383303 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :30 ]train loss : 0.305390 ,train acc: 0.845368 ,val loss : 0.384598 ,val acc : 0.827057\n",
      "[ ecpho : 5  iter :31 ]train loss : 0.330984 ,train acc: 0.849203 ,val loss : 0.386427 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :32 ]train loss : 0.289302 ,train acc: 0.866211 ,val loss : 0.393927 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :33 ]train loss : 0.284266 ,train acc: 0.867310 ,val loss : 0.392096 ,val acc : 0.823517\n",
      "[ ecpho : 5  iter :34 ]train loss : 0.282498 ,train acc: 0.863149 ,val loss : 0.391397 ,val acc : 0.821014\n",
      "[ ecpho : 5  iter :35 ]train loss : 0.291536 ,train acc: 0.861908 ,val loss : 0.385682 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :36 ]train loss : 0.298375 ,train acc: 0.856262 ,val loss : 0.384360 ,val acc : 0.824249\n",
      "[ ecpho : 5  iter :37 ]train loss : 0.724345 ,train acc: 0.649343 ,val loss : 0.390265 ,val acc : 0.824799\n",
      "[ ecpho : 5  iter :38 ]train loss : 0.364621 ,train acc: 0.850464 ,val loss : 0.393823 ,val acc : 0.820160\n",
      "[ ecpho : 5  iter :39 ]train loss : 0.268062 ,train acc: 0.869537 ,val loss : 0.394020 ,val acc : 0.822357\n",
      "[ ecpho : 5  iter :40 ]train loss : 0.255556 ,train acc: 0.873851 ,val loss : 0.384009 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :41 ]train loss : 0.309576 ,train acc: 0.845988 ,val loss : 0.385639 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :42 ]train loss : 0.346122 ,train acc: 0.840505 ,val loss : 0.392986 ,val acc : 0.821991\n",
      "[ ecpho : 5  iter :43 ]train loss : 0.414522 ,train acc: 0.831248 ,val loss : 0.388529 ,val acc : 0.826904\n",
      "[ ecpho : 5  iter :44 ]train loss : 0.359952 ,train acc: 0.853811 ,val loss : 0.387288 ,val acc : 0.823090\n",
      "[ ecpho : 5  iter :45 ]train loss : 0.313637 ,train acc: 0.855245 ,val loss : 0.384688 ,val acc : 0.824677\n",
      "[ ecpho : 5  iter :46 ]train loss : 0.321336 ,train acc: 0.851858 ,val loss : 0.394312 ,val acc : 0.819794\n",
      "[ ecpho : 5  iter :47 ]train loss : 0.342935 ,train acc: 0.848511 ,val loss : 0.386339 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :48 ]train loss : 0.291338 ,train acc: 0.854024 ,val loss : 0.385609 ,val acc : 0.827332\n",
      "[ ecpho : 5  iter :49 ]train loss : 0.272578 ,train acc: 0.868510 ,val loss : 0.382393 ,val acc : 0.825470\n",
      "[ ecpho : 5  iter :50 ]train loss : 0.276686 ,train acc: 0.865092 ,val loss : 0.398701 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :51 ]train loss : 0.282064 ,train acc: 0.875376 ,val loss : 0.395802 ,val acc : 0.822479\n",
      "[ ecpho : 5  iter :52 ]train loss : 0.252964 ,train acc: 0.874959 ,val loss : 0.388936 ,val acc : 0.823303\n",
      "[ ecpho : 5  iter :53 ]train loss : 0.328046 ,train acc: 0.856771 ,val loss : 0.391717 ,val acc : 0.821625\n",
      "[ ecpho : 5  iter :54 ]train loss : 0.304652 ,train acc: 0.861532 ,val loss : 0.392195 ,val acc : 0.822601\n",
      "[ ecpho : 5  iter :55 ]train loss : 0.239170 ,train acc: 0.887543 ,val loss : 0.389794 ,val acc : 0.827179\n",
      "[ ecpho : 5  iter :56 ]train loss : 0.318579 ,train acc: 0.864817 ,val loss : 0.390708 ,val acc : 0.823303\n",
      "[ ecpho : 5  iter :57 ]train loss : 0.322606 ,train acc: 0.838837 ,val loss : 0.389394 ,val acc : 0.827301\n",
      "[ ecpho : 5  iter :58 ]train loss : 0.342063 ,train acc: 0.835795 ,val loss : 0.386461 ,val acc : 0.823151\n",
      "[ ecpho : 5  iter :59 ]train loss : 0.293365 ,train acc: 0.859212 ,val loss : 0.385691 ,val acc : 0.826477\n",
      "[ ecpho : 5  iter :60 ]train loss : 0.266719 ,train acc: 0.873840 ,val loss : 0.386873 ,val acc : 0.824402\n",
      "[ ecpho : 5  iter :61 ]train loss : 0.315437 ,train acc: 0.863688 ,val loss : 0.389484 ,val acc : 0.827240\n",
      "[ ecpho : 5  iter :62 ]train loss : 0.389279 ,train acc: 0.843821 ,val loss : 0.386119 ,val acc : 0.824005\n",
      "[ ecpho : 5  iter :63 ]train loss : 0.584459 ,train acc: 0.742951 ,val loss : 0.388325 ,val acc : 0.827637\n",
      "[ ecpho : 5  iter :64 ]train loss : 0.290329 ,train acc: 0.868022 ,val loss : 0.386555 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :65 ]train loss : 0.319096 ,train acc: 0.838013 ,val loss : 0.389128 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :66 ]train loss : 0.323510 ,train acc: 0.840627 ,val loss : 0.390727 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :67 ]train loss : 0.405002 ,train acc: 0.811290 ,val loss : 0.387317 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :68 ]train loss : 0.318963 ,train acc: 0.857290 ,val loss : 0.392240 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :69 ]train loss : 0.360988 ,train acc: 0.851735 ,val loss : 0.390415 ,val acc : 0.824585\n",
      "[ ecpho : 5  iter :70 ]train loss : 0.320036 ,train acc: 0.855896 ,val loss : 0.389949 ,val acc : 0.822632\n",
      "[ ecpho : 5  iter :71 ]train loss : 0.254092 ,train acc: 0.877950 ,val loss : 0.383685 ,val acc : 0.824005\n",
      "[ ecpho : 5  iter :72 ]train loss : 0.245704 ,train acc: 0.881297 ,val loss : 0.389125 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :73 ]train loss : 0.324905 ,train acc: 0.856242 ,val loss : 0.389486 ,val acc : 0.824951\n",
      "[ ecpho : 5  iter :74 ]train loss : 0.332000 ,train acc: 0.851400 ,val loss : 0.384739 ,val acc : 0.825409\n",
      "[ ecpho : 5  iter :75 ]train loss : 0.385604 ,train acc: 0.845083 ,val loss : 0.384854 ,val acc : 0.828491\n",
      "[ ecpho : 5  iter :76 ]train loss : 0.299479 ,train acc: 0.855978 ,val loss : 0.381273 ,val acc : 0.829346\n",
      "[ ecpho : 5  iter :77 ]train loss : 0.251712 ,train acc: 0.881124 ,val loss : 0.387339 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :78 ]train loss : 0.250606 ,train acc: 0.879181 ,val loss : 0.388710 ,val acc : 0.824341\n",
      "[ ecpho : 5  iter :79 ]train loss : 0.252902 ,train acc: 0.878917 ,val loss : 0.391390 ,val acc : 0.823181\n",
      "[ ecpho : 5  iter :80 ]train loss : 0.318600 ,train acc: 0.855174 ,val loss : 0.391329 ,val acc : 0.822540\n",
      "[ ecpho : 5  iter :81 ]train loss : 0.376741 ,train acc: 0.831350 ,val loss : 0.386296 ,val acc : 0.824249\n",
      "[ ecpho : 5  iter :82 ]train loss : 0.288692 ,train acc: 0.863607 ,val loss : 0.390103 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :83 ]train loss : 0.339300 ,train acc: 0.855164 ,val loss : 0.387912 ,val acc : 0.823914\n",
      "[ ecpho : 5  iter :84 ]train loss : 0.293781 ,train acc: 0.857086 ,val loss : 0.390341 ,val acc : 0.821045\n",
      "[ ecpho : 5  iter :85 ]train loss : 0.303332 ,train acc: 0.858398 ,val loss : 0.386395 ,val acc : 0.824310\n",
      "[ ecpho : 5  iter :86 ]train loss : 0.313679 ,train acc: 0.854289 ,val loss : 0.383492 ,val acc : 0.827881\n",
      "[ ecpho : 5  iter :87 ]train loss : 0.280484 ,train acc: 0.872569 ,val loss : 0.393795 ,val acc : 0.819916\n",
      "[ ecpho : 5  iter :88 ]train loss : 0.281979 ,train acc: 0.869934 ,val loss : 0.392565 ,val acc : 0.823608\n",
      "[ ecpho : 5  iter :89 ]train loss : 0.295302 ,train acc: 0.857045 ,val loss : 0.386771 ,val acc : 0.820923\n",
      "[ ecpho : 5  iter :90 ]train loss : 0.389471 ,train acc: 0.800181 ,val loss : 0.385988 ,val acc : 0.827911\n",
      "[ ecpho : 5  iter :91 ]train loss : 0.429742 ,train acc: 0.788401 ,val loss : 0.392227 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :92 ]train loss : 0.296606 ,train acc: 0.868124 ,val loss : 0.387653 ,val acc : 0.825073\n",
      "[ ecpho : 5  iter :93 ]train loss : 0.383098 ,train acc: 0.842377 ,val loss : 0.389857 ,val acc : 0.821808\n",
      "[ ecpho : 5  iter :94 ]train loss : 0.402626 ,train acc: 0.844177 ,val loss : 0.390077 ,val acc : 0.823120\n",
      "[ ecpho : 5  iter :95 ]train loss : 0.248694 ,train acc: 0.877879 ,val loss : 0.387059 ,val acc : 0.825409\n",
      "[ ecpho : 5  iter :96 ]train loss : 0.305840 ,train acc: 0.861684 ,val loss : 0.386220 ,val acc : 0.822754\n",
      "[ ecpho : 5  iter :97 ]train loss : 0.331508 ,train acc: 0.822479 ,val loss : 0.389442 ,val acc : 0.824280\n",
      "[ ecpho : 5  iter :98 ]train loss : 0.285422 ,train acc: 0.866272 ,val loss : 0.389059 ,val acc : 0.827667\n",
      "[ ecpho : 5  iter :99 ]train loss : 0.315062 ,train acc: 0.861786 ,val loss : 0.387624 ,val acc : 0.822266\n",
      "[ ecpho : 5  iter :100 ]train loss : 0.322889 ,train acc: 0.826437 ,val loss : 0.389781 ,val acc : 0.821350\n",
      "[ ecpho : 5  iter :101 ]train loss : 0.249774 ,train acc: 0.877777 ,val loss : 0.391524 ,val acc : 0.821442\n",
      "[ ecpho : 5  iter :102 ]train loss : 0.389809 ,train acc: 0.831004 ,val loss : 0.393134 ,val acc : 0.824524\n",
      "[ ecpho : 5  iter :103 ]train loss : 0.328833 ,train acc: 0.845510 ,val loss : 0.392570 ,val acc : 0.822784\n",
      "[ ecpho : 5  iter :104 ]train loss : 0.296859 ,train acc: 0.866242 ,val loss : 0.384932 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :105 ]train loss : 0.268058 ,train acc: 0.871124 ,val loss : 0.393240 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :106 ]train loss : 0.301280 ,train acc: 0.863810 ,val loss : 0.389637 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :107 ]train loss : 0.478178 ,train acc: 0.796885 ,val loss : 0.385174 ,val acc : 0.822052\n",
      "[ ecpho : 5  iter :108 ]train loss : 0.393083 ,train acc: 0.821859 ,val loss : 0.394371 ,val acc : 0.821686\n",
      "[ ecpho : 5  iter :109 ]train loss : 0.371341 ,train acc: 0.841828 ,val loss : 0.386882 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :110 ]train loss : 0.415005 ,train acc: 0.767426 ,val loss : 0.382435 ,val acc : 0.826752\n",
      "[ ecpho : 5  iter :111 ]train loss : 0.236253 ,train acc: 0.886088 ,val loss : 0.386076 ,val acc : 0.825470\n",
      "[ ecpho : 5  iter :112 ]train loss : 0.266223 ,train acc: 0.868642 ,val loss : 0.388385 ,val acc : 0.823639\n",
      "[ ecpho : 5  iter :113 ]train loss : 0.314567 ,train acc: 0.856822 ,val loss : 0.386349 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :114 ]train loss : 0.277504 ,train acc: 0.867198 ,val loss : 0.385368 ,val acc : 0.825867\n",
      "[ ecpho : 5  iter :115 ]train loss : 0.270372 ,train acc: 0.865814 ,val loss : 0.385553 ,val acc : 0.829529\n",
      "[ ecpho : 5  iter :116 ]train loss : 0.237396 ,train acc: 0.883016 ,val loss : 0.391234 ,val acc : 0.822937\n",
      "[ ecpho : 5  iter :117 ]train loss : 0.277751 ,train acc: 0.864889 ,val loss : 0.393728 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :118 ]train loss : 0.525894 ,train acc: 0.697164 ,val loss : 0.393365 ,val acc : 0.822418\n",
      "[ ecpho : 5  iter :119 ]train loss : 0.291090 ,train acc: 0.860545 ,val loss : 0.385398 ,val acc : 0.827087\n",
      "[ ecpho : 5  iter :120 ]train loss : 0.297453 ,train acc: 0.866181 ,val loss : 0.391801 ,val acc : 0.821411\n",
      "[ ecpho : 5  iter :121 ]train loss : 0.284296 ,train acc: 0.870778 ,val loss : 0.388666 ,val acc : 0.826263\n",
      "[ ecpho : 5  iter :122 ]train loss : 0.306471 ,train acc: 0.857452 ,val loss : 0.389690 ,val acc : 0.824677\n",
      "[ ecpho : 5  iter :123 ]train loss : 0.252448 ,train acc: 0.879822 ,val loss : 0.390426 ,val acc : 0.824341\n",
      "[ ecpho : 5  iter :124 ]train loss : 0.296194 ,train acc: 0.862539 ,val loss : 0.380504 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :125 ]train loss : 0.339208 ,train acc: 0.852773 ,val loss : 0.389154 ,val acc : 0.821869\n",
      "[ ecpho : 5  iter :126 ]train loss : 0.520333 ,train acc: 0.818044 ,val loss : 0.392321 ,val acc : 0.820435\n",
      "[ ecpho : 5  iter :127 ]train loss : 0.387391 ,train acc: 0.806020 ,val loss : 0.391151 ,val acc : 0.822998\n",
      "[ ecpho : 5  iter :128 ]train loss : 0.344229 ,train acc: 0.844452 ,val loss : 0.386244 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :129 ]train loss : 0.332565 ,train acc: 0.856995 ,val loss : 0.387346 ,val acc : 0.822754\n",
      "[ ecpho : 5  iter :130 ]train loss : 0.281518 ,train acc: 0.870005 ,val loss : 0.392105 ,val acc : 0.824402\n",
      "[ ecpho : 5  iter :131 ]train loss : 0.312712 ,train acc: 0.854645 ,val loss : 0.391975 ,val acc : 0.824158\n",
      "[ ecpho : 5  iter :132 ]train loss : 0.344423 ,train acc: 0.848633 ,val loss : 0.382627 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :133 ]train loss : 0.280489 ,train acc: 0.858531 ,val loss : 0.394530 ,val acc : 0.821014\n",
      "[ ecpho : 5  iter :134 ]train loss : 0.256232 ,train acc: 0.874776 ,val loss : 0.390546 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :135 ]train loss : 0.247667 ,train acc: 0.882426 ,val loss : 0.385563 ,val acc : 0.824249\n",
      "[ ecpho : 5  iter :136 ]train loss : 0.256013 ,train acc: 0.875031 ,val loss : 0.389512 ,val acc : 0.824097\n",
      "[ ecpho : 5  iter :137 ]train loss : 0.270988 ,train acc: 0.866974 ,val loss : 0.388412 ,val acc : 0.826935\n",
      "[ ecpho : 5  iter :138 ]train loss : 0.284562 ,train acc: 0.864685 ,val loss : 0.387936 ,val acc : 0.822540\n",
      "[ ecpho : 5  iter :139 ]train loss : 0.277420 ,train acc: 0.874847 ,val loss : 0.385283 ,val acc : 0.827942\n",
      "[ ecpho : 5  iter :140 ]train loss : 0.279236 ,train acc: 0.870840 ,val loss : 0.391886 ,val acc : 0.822418\n",
      "[ ecpho : 5  iter :141 ]train loss : 0.240090 ,train acc: 0.881907 ,val loss : 0.387149 ,val acc : 0.825592\n",
      "[ ecpho : 5  iter :142 ]train loss : 0.310553 ,train acc: 0.856384 ,val loss : 0.381345 ,val acc : 0.826935\n",
      "[ ecpho : 5  iter :143 ]train loss : 0.402164 ,train acc: 0.838939 ,val loss : 0.385252 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :144 ]train loss : 0.279188 ,train acc: 0.867503 ,val loss : 0.387923 ,val acc : 0.821014\n",
      "[ ecpho : 5  iter :145 ]train loss : 0.314418 ,train acc: 0.855215 ,val loss : 0.394175 ,val acc : 0.822632\n",
      "[ ecpho : 5  iter :146 ]train loss : 0.264763 ,train acc: 0.874288 ,val loss : 0.388348 ,val acc : 0.823181\n",
      "[ ecpho : 5  iter :147 ]train loss : 0.334831 ,train acc: 0.859965 ,val loss : 0.386371 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :148 ]train loss : 0.240854 ,train acc: 0.883209 ,val loss : 0.388362 ,val acc : 0.823608\n",
      "[ ecpho : 5  iter :149 ]train loss : 0.276546 ,train acc: 0.867208 ,val loss : 0.387570 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :150 ]train loss : 0.367894 ,train acc: 0.841156 ,val loss : 0.383415 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :151 ]train loss : 0.459944 ,train acc: 0.783509 ,val loss : 0.389422 ,val acc : 0.823029\n",
      "[ ecpho : 5  iter :152 ]train loss : 0.285173 ,train acc: 0.871531 ,val loss : 0.385859 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :153 ]train loss : 0.357541 ,train acc: 0.850596 ,val loss : 0.390372 ,val acc : 0.824127\n",
      "[ ecpho : 5  iter :154 ]train loss : 0.316900 ,train acc: 0.853790 ,val loss : 0.395009 ,val acc : 0.821594\n",
      "[ ecpho : 5  iter :155 ]train loss : 0.270336 ,train acc: 0.867116 ,val loss : 0.386796 ,val acc : 0.826111\n",
      "[ ecpho : 5  iter :156 ]train loss : 0.333708 ,train acc: 0.852448 ,val loss : 0.386508 ,val acc : 0.824341\n",
      "[ ecpho : 5  iter :157 ]train loss : 0.302597 ,train acc: 0.862946 ,val loss : 0.391633 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :158 ]train loss : 0.279939 ,train acc: 0.867706 ,val loss : 0.386829 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :159 ]train loss : 0.300447 ,train acc: 0.851522 ,val loss : 0.385399 ,val acc : 0.825836\n",
      "[ ecpho : 5  iter :160 ]train loss : 0.425903 ,train acc: 0.838196 ,val loss : 0.385531 ,val acc : 0.826172\n",
      "[ ecpho : 5  iter :161 ]train loss : 0.381527 ,train acc: 0.828949 ,val loss : 0.390757 ,val acc : 0.823151\n",
      "[ ecpho : 5  iter :162 ]train loss : 0.332941 ,train acc: 0.850993 ,val loss : 0.386898 ,val acc : 0.824829\n",
      "[ ecpho : 5  iter :163 ]train loss : 0.358907 ,train acc: 0.850098 ,val loss : 0.390948 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :164 ]train loss : 0.318955 ,train acc: 0.854970 ,val loss : 0.387501 ,val acc : 0.823822\n",
      "[ ecpho : 5  iter :165 ]train loss : 0.324024 ,train acc: 0.824677 ,val loss : 0.387153 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :166 ]train loss : 0.279313 ,train acc: 0.867299 ,val loss : 0.387348 ,val acc : 0.826874\n",
      "[ ecpho : 5  iter :167 ]train loss : 0.321013 ,train acc: 0.849843 ,val loss : 0.393615 ,val acc : 0.822632\n",
      "[ ecpho : 5  iter :168 ]train loss : 0.290420 ,train acc: 0.866486 ,val loss : 0.378582 ,val acc : 0.824677\n",
      "[ ecpho : 5  iter :169 ]train loss : 0.287360 ,train acc: 0.862539 ,val loss : 0.386524 ,val acc : 0.824341\n",
      "[ ecpho : 5  iter :170 ]train loss : 0.292177 ,train acc: 0.859385 ,val loss : 0.387216 ,val acc : 0.823761\n",
      "[ ecpho : 5  iter :171 ]train loss : 0.289122 ,train acc: 0.862132 ,val loss : 0.384349 ,val acc : 0.824829\n",
      "[ ecpho : 5  iter :172 ]train loss : 0.249391 ,train acc: 0.880361 ,val loss : 0.390909 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :173 ]train loss : 0.293690 ,train acc: 0.866282 ,val loss : 0.382639 ,val acc : 0.826782\n",
      "[ ecpho : 5  iter :174 ]train loss : 0.301834 ,train acc: 0.850627 ,val loss : 0.387904 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :175 ]train loss : 0.364913 ,train acc: 0.815471 ,val loss : 0.389124 ,val acc : 0.822449\n",
      "[ ecpho : 5  iter :176 ]train loss : 0.451025 ,train acc: 0.800252 ,val loss : 0.389879 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :177 ]train loss : 0.370986 ,train acc: 0.809052 ,val loss : 0.388093 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :178 ]train loss : 0.329972 ,train acc: 0.834483 ,val loss : 0.390161 ,val acc : 0.826996\n",
      "[ ecpho : 5  iter :179 ]train loss : 0.335624 ,train acc: 0.851298 ,val loss : 0.382016 ,val acc : 0.824829\n",
      "[ ecpho : 5  iter :180 ]train loss : 0.308202 ,train acc: 0.843882 ,val loss : 0.386795 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :181 ]train loss : 0.296089 ,train acc: 0.862600 ,val loss : 0.390317 ,val acc : 0.824554\n",
      "[ ecpho : 5  iter :182 ]train loss : 0.357655 ,train acc: 0.839935 ,val loss : 0.386450 ,val acc : 0.824524\n",
      "[ ecpho : 5  iter :183 ]train loss : 0.293580 ,train acc: 0.864136 ,val loss : 0.388688 ,val acc : 0.824432\n",
      "[ ecpho : 5  iter :184 ]train loss : 0.243042 ,train acc: 0.878886 ,val loss : 0.387563 ,val acc : 0.825684\n",
      "[ ecpho : 5  iter :185 ]train loss : 0.301250 ,train acc: 0.855499 ,val loss : 0.388159 ,val acc : 0.822784\n",
      "[ ecpho : 5  iter :186 ]train loss : 0.383449 ,train acc: 0.843231 ,val loss : 0.389300 ,val acc : 0.822968\n",
      "[ ecpho : 5  iter :187 ]train loss : 0.337020 ,train acc: 0.824880 ,val loss : 0.385917 ,val acc : 0.824463\n",
      "[ ecpho : 5  iter :188 ]train loss : 0.276068 ,train acc: 0.867269 ,val loss : 0.392338 ,val acc : 0.822510\n",
      "[ ecpho : 5  iter :189 ]train loss : 0.327516 ,train acc: 0.838481 ,val loss : 0.385342 ,val acc : 0.830231\n",
      "[ ecpho : 5  iter :190 ]train loss : 0.356949 ,train acc: 0.840464 ,val loss : 0.387003 ,val acc : 0.827362\n",
      "[ ecpho : 5  iter :191 ]train loss : 0.306216 ,train acc: 0.852285 ,val loss : 0.384203 ,val acc : 0.828369\n",
      "[ ecpho : 5  iter :192 ]train loss : 0.335309 ,train acc: 0.851105 ,val loss : 0.390348 ,val acc : 0.827026\n",
      "[ ecpho : 5  iter :193 ]train loss : 0.256710 ,train acc: 0.867706 ,val loss : 0.389230 ,val acc : 0.824951\n",
      "[ ecpho : 5  iter :194 ]train loss : 0.297213 ,train acc: 0.855917 ,val loss : 0.383615 ,val acc : 0.824860\n",
      "[ ecpho : 5  iter :195 ]train loss : 0.296945 ,train acc: 0.873698 ,val loss : 0.388149 ,val acc : 0.826263\n",
      "[ ecpho : 5  iter :196 ]train loss : 0.322369 ,train acc: 0.855286 ,val loss : 0.396583 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :197 ]train loss : 0.262458 ,train acc: 0.872569 ,val loss : 0.388171 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :198 ]train loss : 0.271222 ,train acc: 0.870646 ,val loss : 0.383398 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :199 ]train loss : 0.299501 ,train acc: 0.858989 ,val loss : 0.385062 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :200 ]train loss : 0.281334 ,train acc: 0.859863 ,val loss : 0.389793 ,val acc : 0.821808\n",
      "[ ecpho : 5  iter :201 ]train loss : 0.255140 ,train acc: 0.873250 ,val loss : 0.387161 ,val acc : 0.824280\n",
      "[ ecpho : 5  iter :202 ]train loss : 0.257000 ,train acc: 0.876678 ,val loss : 0.386043 ,val acc : 0.827332\n",
      "[ ecpho : 5  iter :203 ]train loss : 0.301551 ,train acc: 0.860637 ,val loss : 0.390697 ,val acc : 0.823914\n",
      "[ ecpho : 5  iter :204 ]train loss : 0.379242 ,train acc: 0.836019 ,val loss : 0.390506 ,val acc : 0.823730\n",
      "[ ecpho : 5  iter :205 ]train loss : 0.281884 ,train acc: 0.865234 ,val loss : 0.388181 ,val acc : 0.826721\n",
      "[ ecpho : 5  iter :206 ]train loss : 0.328783 ,train acc: 0.844961 ,val loss : 0.388507 ,val acc : 0.826080\n",
      "[ ecpho : 5  iter :207 ]train loss : 0.246576 ,train acc: 0.876017 ,val loss : 0.391255 ,val acc : 0.824432\n",
      "[ ecpho : 5  iter :208 ]train loss : 0.241243 ,train acc: 0.885732 ,val loss : 0.384716 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :209 ]train loss : 0.295667 ,train acc: 0.862579 ,val loss : 0.385389 ,val acc : 0.823669\n",
      "[ ecpho : 5  iter :210 ]train loss : 0.293559 ,train acc: 0.869059 ,val loss : 0.386946 ,val acc : 0.822968\n",
      "[ ecpho : 5  iter :211 ]train loss : 0.324290 ,train acc: 0.851624 ,val loss : 0.388194 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :212 ]train loss : 0.287539 ,train acc: 0.862030 ,val loss : 0.389137 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :213 ]train loss : 0.347836 ,train acc: 0.845398 ,val loss : 0.386116 ,val acc : 0.822632\n",
      "[ ecpho : 5  iter :214 ]train loss : 0.336352 ,train acc: 0.846731 ,val loss : 0.387326 ,val acc : 0.827057\n",
      "[ ecpho : 5  iter :215 ]train loss : 0.256820 ,train acc: 0.875071 ,val loss : 0.386384 ,val acc : 0.822052\n",
      "[ ecpho : 5  iter :216 ]train loss : 0.249740 ,train acc: 0.881521 ,val loss : 0.386236 ,val acc : 0.822235\n",
      "[ ecpho : 5  iter :217 ]train loss : 0.335839 ,train acc: 0.855031 ,val loss : 0.389201 ,val acc : 0.822327\n",
      "[ ecpho : 5  iter :218 ]train loss : 0.269197 ,train acc: 0.872843 ,val loss : 0.388585 ,val acc : 0.826263\n",
      "[ ecpho : 5  iter :219 ]train loss : 0.258379 ,train acc: 0.875173 ,val loss : 0.391865 ,val acc : 0.823273\n",
      "[ ecpho : 5  iter :220 ]train loss : 0.282155 ,train acc: 0.870819 ,val loss : 0.386048 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :221 ]train loss : 0.288771 ,train acc: 0.868968 ,val loss : 0.387954 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :222 ]train loss : 0.346710 ,train acc: 0.813243 ,val loss : 0.382950 ,val acc : 0.825928\n",
      "[ ecpho : 5  iter :223 ]train loss : 0.255592 ,train acc: 0.878103 ,val loss : 0.389764 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :224 ]train loss : 0.323669 ,train acc: 0.829041 ,val loss : 0.389610 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :225 ]train loss : 0.269092 ,train acc: 0.872304 ,val loss : 0.389317 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :226 ]train loss : 0.371241 ,train acc: 0.817159 ,val loss : 0.383633 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :227 ]train loss : 0.307566 ,train acc: 0.860576 ,val loss : 0.391116 ,val acc : 0.823669\n",
      "[ ecpho : 5  iter :228 ]train loss : 0.366180 ,train acc: 0.816101 ,val loss : 0.388514 ,val acc : 0.821503\n",
      "[ ecpho : 5  iter :229 ]train loss : 0.272117 ,train acc: 0.875305 ,val loss : 0.391959 ,val acc : 0.821472\n",
      "[ ecpho : 5  iter :230 ]train loss : 0.308413 ,train acc: 0.858348 ,val loss : 0.387802 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :231 ]train loss : 0.238725 ,train acc: 0.883891 ,val loss : 0.389455 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :232 ]train loss : 0.273332 ,train acc: 0.866536 ,val loss : 0.387464 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :233 ]train loss : 0.261894 ,train acc: 0.870270 ,val loss : 0.392551 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :234 ]train loss : 0.250265 ,train acc: 0.875956 ,val loss : 0.389027 ,val acc : 0.824707\n",
      "[ ecpho : 5  iter :235 ]train loss : 0.275562 ,train acc: 0.871816 ,val loss : 0.387759 ,val acc : 0.821960\n",
      "[ ecpho : 5  iter :236 ]train loss : 0.288034 ,train acc: 0.859477 ,val loss : 0.386170 ,val acc : 0.824799\n",
      "[ ecpho : 5  iter :237 ]train loss : 0.366279 ,train acc: 0.793722 ,val loss : 0.391457 ,val acc : 0.824493\n",
      "[ ecpho : 5  iter :238 ]train loss : 0.309255 ,train acc: 0.868957 ,val loss : 0.390314 ,val acc : 0.822174\n",
      "[ ecpho : 5  iter :239 ]train loss : 0.288313 ,train acc: 0.868256 ,val loss : 0.384118 ,val acc : 0.821350\n",
      "[ ecpho : 5  iter :240 ]train loss : 0.319215 ,train acc: 0.861359 ,val loss : 0.384655 ,val acc : 0.826752\n",
      "[ ecpho : 5  iter :241 ]train loss : 0.310581 ,train acc: 0.861257 ,val loss : 0.392883 ,val acc : 0.820984\n",
      "[ ecpho : 5  iter :242 ]train loss : 0.265403 ,train acc: 0.876007 ,val loss : 0.390083 ,val acc : 0.824615\n",
      "[ ecpho : 5  iter :243 ]train loss : 0.248659 ,train acc: 0.878998 ,val loss : 0.388486 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :244 ]train loss : 0.350488 ,train acc: 0.842509 ,val loss : 0.386806 ,val acc : 0.823669\n",
      "[ ecpho : 5  iter :245 ]train loss : 0.305999 ,train acc: 0.860586 ,val loss : 0.389194 ,val acc : 0.821625\n",
      "[ ecpho : 5  iter :246 ]train loss : 0.357617 ,train acc: 0.808645 ,val loss : 0.397523 ,val acc : 0.821442\n",
      "[ ecpho : 5  iter :247 ]train loss : 0.367786 ,train acc: 0.809530 ,val loss : 0.388000 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :248 ]train loss : 0.386432 ,train acc: 0.822652 ,val loss : 0.387162 ,val acc : 0.823242\n",
      "[ ecpho : 5  iter :249 ]train loss : 0.272529 ,train acc: 0.866964 ,val loss : 0.386404 ,val acc : 0.823883\n",
      "[ ecpho : 5  iter :250 ]train loss : 0.281604 ,train acc: 0.867798 ,val loss : 0.387594 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :251 ]train loss : 0.266535 ,train acc: 0.865407 ,val loss : 0.381952 ,val acc : 0.827850\n",
      "[ ecpho : 5  iter :252 ]train loss : 0.434326 ,train acc: 0.814840 ,val loss : 0.393384 ,val acc : 0.821472\n",
      "[ ecpho : 5  iter :253 ]train loss : 0.589407 ,train acc: 0.776489 ,val loss : 0.394130 ,val acc : 0.821533\n",
      "[ ecpho : 5  iter :254 ]train loss : 0.283850 ,train acc: 0.858165 ,val loss : 0.383295 ,val acc : 0.826355\n",
      "[ ecpho : 5  iter :255 ]train loss : 0.365998 ,train acc: 0.845958 ,val loss : 0.391978 ,val acc : 0.824921\n",
      "[ ecpho : 5  iter :256 ]train loss : 0.264970 ,train acc: 0.871409 ,val loss : 0.383439 ,val acc : 0.826172\n",
      "[ ecpho : 5  iter :257 ]train loss : 0.276123 ,train acc: 0.868368 ,val loss : 0.386151 ,val acc : 0.822876\n",
      "[ ecpho : 5  iter :258 ]train loss : 0.319530 ,train acc: 0.855784 ,val loss : 0.381798 ,val acc : 0.828552\n",
      "[ ecpho : 5  iter :259 ]train loss : 0.306908 ,train acc: 0.841868 ,val loss : 0.387412 ,val acc : 0.822144\n",
      "[ ecpho : 5  iter :260 ]train loss : 0.341486 ,train acc: 0.849437 ,val loss : 0.387043 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :261 ]train loss : 0.253295 ,train acc: 0.878947 ,val loss : 0.388653 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :262 ]train loss : 0.312272 ,train acc: 0.864736 ,val loss : 0.388553 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :263 ]train loss : 0.300427 ,train acc: 0.854380 ,val loss : 0.390090 ,val acc : 0.822388\n",
      "[ ecpho : 5  iter :264 ]train loss : 0.311822 ,train acc: 0.863739 ,val loss : 0.386223 ,val acc : 0.823120\n",
      "[ ecpho : 5  iter :265 ]train loss : 0.248014 ,train acc: 0.877726 ,val loss : 0.387830 ,val acc : 0.823944\n",
      "[ ecpho : 5  iter :266 ]train loss : 0.314094 ,train acc: 0.851135 ,val loss : 0.388938 ,val acc : 0.824432\n",
      "[ ecpho : 5  iter :267 ]train loss : 0.245697 ,train acc: 0.885111 ,val loss : 0.389347 ,val acc : 0.822815\n",
      "[ ecpho : 5  iter :268 ]train loss : 0.258308 ,train acc: 0.876058 ,val loss : 0.387071 ,val acc : 0.825348\n",
      "[ ecpho : 5  iter :269 ]train loss : 0.297981 ,train acc: 0.863637 ,val loss : 0.389295 ,val acc : 0.823608\n",
      "[ ecpho : 5  iter :270 ]train loss : 0.252286 ,train acc: 0.877757 ,val loss : 0.382091 ,val acc : 0.825867\n",
      "[ ecpho : 5  iter :271 ]train loss : 0.315942 ,train acc: 0.857686 ,val loss : 0.384399 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :272 ]train loss : 0.329667 ,train acc: 0.850820 ,val loss : 0.388605 ,val acc : 0.823456\n",
      "[ ecpho : 5  iter :273 ]train loss : 0.310845 ,train acc: 0.851410 ,val loss : 0.386424 ,val acc : 0.826874\n",
      "[ ecpho : 5  iter :274 ]train loss : 0.307375 ,train acc: 0.860067 ,val loss : 0.385276 ,val acc : 0.827942\n",
      "[ ecpho : 5  iter :275 ]train loss : 0.275030 ,train acc: 0.862579 ,val loss : 0.388224 ,val acc : 0.823273\n",
      "[ ecpho : 5  iter :276 ]train loss : 0.245270 ,train acc: 0.879608 ,val loss : 0.389364 ,val acc : 0.823608\n",
      "[ ecpho : 5  iter :277 ]train loss : 0.399603 ,train acc: 0.809296 ,val loss : 0.387510 ,val acc : 0.827454\n",
      "[ ecpho : 5  iter :278 ]train loss : 0.302508 ,train acc: 0.865163 ,val loss : 0.394525 ,val acc : 0.824127\n",
      "[ ecpho : 5  iter :279 ]train loss : 0.321831 ,train acc: 0.858490 ,val loss : 0.389900 ,val acc : 0.823639\n",
      "[ ecpho : 5  iter :280 ]train loss : 0.295372 ,train acc: 0.857442 ,val loss : 0.392644 ,val acc : 0.822693\n",
      "[ ecpho : 5  iter :281 ]train loss : 0.242075 ,train acc: 0.879812 ,val loss : 0.388902 ,val acc : 0.828735\n",
      "[ ecpho : 5  iter :282 ]train loss : 0.299133 ,train acc: 0.861949 ,val loss : 0.389027 ,val acc : 0.824249\n",
      "[ ecpho : 5  iter :283 ]train loss : 0.295325 ,train acc: 0.859904 ,val loss : 0.383242 ,val acc : 0.822571\n",
      "[ ecpho : 5  iter :284 ]train loss : 0.263730 ,train acc: 0.874929 ,val loss : 0.390228 ,val acc : 0.823334\n",
      "[ ecpho : 5  iter :285 ]train loss : 0.280576 ,train acc: 0.864349 ,val loss : 0.391629 ,val acc : 0.822266\n",
      "[ ecpho : 5  iter :286 ]train loss : 0.246900 ,train acc: 0.878947 ,val loss : 0.382553 ,val acc : 0.829407\n",
      "[ ecpho : 5  iter :287 ]train loss : 0.279817 ,train acc: 0.867503 ,val loss : 0.390531 ,val acc : 0.821625\n",
      "[ ecpho : 5  iter :288 ]train loss : 0.290416 ,train acc: 0.866964 ,val loss : 0.394717 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :289 ]train loss : 0.261751 ,train acc: 0.876668 ,val loss : 0.388123 ,val acc : 0.821655\n",
      "[ ecpho : 5  iter :290 ]train loss : 0.352818 ,train acc: 0.831309 ,val loss : 0.386748 ,val acc : 0.825256\n",
      "[ ecpho : 5  iter :291 ]train loss : 0.374696 ,train acc: 0.823914 ,val loss : 0.388205 ,val acc : 0.824615\n",
      "[ ecpho : 5  iter :292 ]train loss : 0.261291 ,train acc: 0.876200 ,val loss : 0.385300 ,val acc : 0.824188\n",
      "[ ecpho : 5  iter :293 ]train loss : 0.246734 ,train acc: 0.881531 ,val loss : 0.386436 ,val acc : 0.822693\n",
      "[ ecpho : 5  iter :294 ]train loss : 0.334728 ,train acc: 0.843181 ,val loss : 0.393271 ,val acc : 0.823425\n",
      "[ ecpho : 5  iter :295 ]train loss : 0.297077 ,train acc: 0.854828 ,val loss : 0.385172 ,val acc : 0.825745\n",
      "[ ecpho : 5  iter :296 ]train loss : 0.265911 ,train acc: 0.871694 ,val loss : 0.387195 ,val acc : 0.827545\n",
      "[ ecpho : 5  iter :297 ]train loss : 0.324920 ,train acc: 0.833120 ,val loss : 0.392112 ,val acc : 0.824371\n",
      "[ ecpho : 5  iter :298 ]train loss : 0.309934 ,train acc: 0.855622 ,val loss : 0.384856 ,val acc : 0.826782\n",
      "[ ecpho : 5  iter :299 ]train loss : 0.270228 ,train acc: 0.868602 ,val loss : 0.391151 ,val acc : 0.823547\n",
      "[ ecpho : 5  iter :300 ]train loss : 0.281868 ,train acc: 0.860657 ,val loss : 0.387171 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :301 ]train loss : 0.406840 ,train acc: 0.802277 ,val loss : 0.381855 ,val acc : 0.826996\n",
      "[ ecpho : 5  iter :302 ]train loss : 0.418309 ,train acc: 0.834381 ,val loss : 0.394033 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :303 ]train loss : 0.306957 ,train acc: 0.859670 ,val loss : 0.386816 ,val acc : 0.827179\n",
      "[ ecpho : 5  iter :304 ]train loss : 0.336597 ,train acc: 0.852570 ,val loss : 0.391421 ,val acc : 0.824799\n",
      "[ ecpho : 5  iter :305 ]train loss : 0.294407 ,train acc: 0.867544 ,val loss : 0.386890 ,val acc : 0.827576\n",
      "[ ecpho : 5  iter :306 ]train loss : 0.328045 ,train acc: 0.853333 ,val loss : 0.383694 ,val acc : 0.826477\n",
      "[ ecpho : 5  iter :307 ]train loss : 0.361117 ,train acc: 0.804016 ,val loss : 0.389212 ,val acc : 0.822540\n",
      "[ ecpho : 5  iter :308 ]train loss : 0.314041 ,train acc: 0.856344 ,val loss : 0.391621 ,val acc : 0.820770\n",
      "[ ecpho : 5  iter :309 ]train loss : 0.362103 ,train acc: 0.821432 ,val loss : 0.391609 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :310 ]train loss : 0.340533 ,train acc: 0.821696 ,val loss : 0.390755 ,val acc : 0.823517\n",
      "[ ecpho : 5  iter :311 ]train loss : 0.282789 ,train acc: 0.872498 ,val loss : 0.384831 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :312 ]train loss : 0.290931 ,train acc: 0.869751 ,val loss : 0.387112 ,val acc : 0.823853\n",
      "[ ecpho : 5  iter :313 ]train loss : 0.310106 ,train acc: 0.857300 ,val loss : 0.384080 ,val acc : 0.827637\n",
      "[ ecpho : 5  iter :314 ]train loss : 0.325622 ,train acc: 0.853007 ,val loss : 0.381650 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :315 ]train loss : 0.273403 ,train acc: 0.864655 ,val loss : 0.390102 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :316 ]train loss : 0.338369 ,train acc: 0.830668 ,val loss : 0.391074 ,val acc : 0.823608\n",
      "[ ecpho : 5  iter :317 ]train loss : 0.327957 ,train acc: 0.832194 ,val loss : 0.382523 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :318 ]train loss : 0.244869 ,train acc: 0.881724 ,val loss : 0.394018 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :319 ]train loss : 0.265227 ,train acc: 0.870392 ,val loss : 0.383304 ,val acc : 0.825714\n",
      "[ ecpho : 5  iter :320 ]train loss : 0.281320 ,train acc: 0.857564 ,val loss : 0.385709 ,val acc : 0.825836\n",
      "[ ecpho : 5  iter :321 ]train loss : 0.476531 ,train acc: 0.833283 ,val loss : 0.386648 ,val acc : 0.827332\n",
      "[ ecpho : 5  iter :322 ]train loss : 0.248755 ,train acc: 0.878520 ,val loss : 0.390009 ,val acc : 0.823151\n",
      "[ ecpho : 5  iter :323 ]train loss : 0.360068 ,train acc: 0.844422 ,val loss : 0.389737 ,val acc : 0.826782\n",
      "[ ecpho : 5  iter :324 ]train loss : 0.260537 ,train acc: 0.877340 ,val loss : 0.386430 ,val acc : 0.823792\n",
      "[ ecpho : 5  iter :325 ]train loss : 0.352140 ,train acc: 0.827850 ,val loss : 0.388388 ,val acc : 0.825745\n",
      "[ ecpho : 5  iter :326 ]train loss : 0.384529 ,train acc: 0.838644 ,val loss : 0.388398 ,val acc : 0.822723\n",
      "[ ecpho : 5  iter :327 ]train loss : 0.270225 ,train acc: 0.871724 ,val loss : 0.386432 ,val acc : 0.826782\n",
      "[ ecpho : 5  iter :328 ]train loss : 0.284534 ,train acc: 0.866506 ,val loss : 0.385119 ,val acc : 0.826813\n",
      "[ ecpho : 5  iter :329 ]train loss : 0.254064 ,train acc: 0.878357 ,val loss : 0.390570 ,val acc : 0.824371\n",
      "[ ecpho : 5  iter :330 ]train loss : 0.292715 ,train acc: 0.865804 ,val loss : 0.388945 ,val acc : 0.827515\n",
      "[ ecpho : 5  iter :331 ]train loss : 0.344181 ,train acc: 0.852142 ,val loss : 0.382354 ,val acc : 0.825592\n",
      "[ ecpho : 5  iter :332 ]train loss : 0.251047 ,train acc: 0.877014 ,val loss : 0.387048 ,val acc : 0.825867\n",
      "[ ecpho : 5  iter :333 ]train loss : 0.249309 ,train acc: 0.880096 ,val loss : 0.386645 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :334 ]train loss : 0.258217 ,train acc: 0.874522 ,val loss : 0.387860 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :335 ]train loss : 0.325861 ,train acc: 0.852336 ,val loss : 0.387326 ,val acc : 0.826385\n",
      "[ ecpho : 5  iter :336 ]train loss : 0.316968 ,train acc: 0.842204 ,val loss : 0.391499 ,val acc : 0.824951\n",
      "[ ecpho : 5  iter :337 ]train loss : 0.308758 ,train acc: 0.866292 ,val loss : 0.387256 ,val acc : 0.828369\n",
      "[ ecpho : 5  iter :338 ]train loss : 0.261457 ,train acc: 0.873759 ,val loss : 0.389745 ,val acc : 0.823547\n",
      "[ ecpho : 5  iter :339 ]train loss : 0.276521 ,train acc: 0.863068 ,val loss : 0.389766 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :340 ]train loss : 0.365792 ,train acc: 0.854116 ,val loss : 0.387763 ,val acc : 0.823303\n",
      "[ ecpho : 5  iter :341 ]train loss : 0.266762 ,train acc: 0.877462 ,val loss : 0.388837 ,val acc : 0.824127\n",
      "[ ecpho : 5  iter :342 ]train loss : 0.311112 ,train acc: 0.853099 ,val loss : 0.390409 ,val acc : 0.822235\n",
      "[ ecpho : 5  iter :343 ]train loss : 0.311272 ,train acc: 0.851929 ,val loss : 0.389553 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :344 ]train loss : 0.261556 ,train acc: 0.874349 ,val loss : 0.393919 ,val acc : 0.822845\n",
      "[ ecpho : 5  iter :345 ]train loss : 0.327165 ,train acc: 0.832916 ,val loss : 0.388986 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :346 ]train loss : 0.401672 ,train acc: 0.818197 ,val loss : 0.392854 ,val acc : 0.824554\n",
      "[ ecpho : 5  iter :347 ]train loss : 0.299916 ,train acc: 0.862244 ,val loss : 0.386159 ,val acc : 0.826691\n",
      "[ ecpho : 5  iter :348 ]train loss : 0.312679 ,train acc: 0.867116 ,val loss : 0.387464 ,val acc : 0.828125\n",
      "[ ecpho : 5  iter :349 ]train loss : 0.279936 ,train acc: 0.866394 ,val loss : 0.385961 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :350 ]train loss : 0.315607 ,train acc: 0.842326 ,val loss : 0.381783 ,val acc : 0.828033\n",
      "[ ecpho : 5  iter :351 ]train loss : 0.402384 ,train acc: 0.829621 ,val loss : 0.388733 ,val acc : 0.823944\n",
      "[ ecpho : 5  iter :352 ]train loss : 0.292967 ,train acc: 0.850057 ,val loss : 0.382083 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :353 ]train loss : 0.262631 ,train acc: 0.872152 ,val loss : 0.389641 ,val acc : 0.823273\n",
      "[ ecpho : 5  iter :354 ]train loss : 0.369259 ,train acc: 0.838003 ,val loss : 0.395896 ,val acc : 0.822815\n",
      "[ ecpho : 5  iter :355 ]train loss : 0.354525 ,train acc: 0.860138 ,val loss : 0.390124 ,val acc : 0.828369\n",
      "[ ecpho : 5  iter :356 ]train loss : 0.298603 ,train acc: 0.851115 ,val loss : 0.388283 ,val acc : 0.824371\n",
      "[ ecpho : 5  iter :357 ]train loss : 0.411160 ,train acc: 0.825155 ,val loss : 0.391680 ,val acc : 0.822510\n",
      "[ ecpho : 5  iter :358 ]train loss : 0.546081 ,train acc: 0.711324 ,val loss : 0.396665 ,val acc : 0.822205\n",
      "[ ecpho : 5  iter :359 ]train loss : 0.360063 ,train acc: 0.806926 ,val loss : 0.389815 ,val acc : 0.823090\n",
      "[ ecpho : 5  iter :360 ]train loss : 0.246632 ,train acc: 0.878377 ,val loss : 0.392182 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :361 ]train loss : 0.287743 ,train acc: 0.858032 ,val loss : 0.392097 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :362 ]train loss : 0.288439 ,train acc: 0.870941 ,val loss : 0.391044 ,val acc : 0.821899\n",
      "[ ecpho : 5  iter :363 ]train loss : 0.284964 ,train acc: 0.864278 ,val loss : 0.386205 ,val acc : 0.822418\n",
      "[ ecpho : 5  iter :364 ]train loss : 0.283823 ,train acc: 0.861176 ,val loss : 0.385444 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :365 ]train loss : 0.245966 ,train acc: 0.878937 ,val loss : 0.386394 ,val acc : 0.822754\n",
      "[ ecpho : 5  iter :366 ]train loss : 0.288253 ,train acc: 0.863617 ,val loss : 0.387509 ,val acc : 0.827606\n",
      "[ ecpho : 5  iter :367 ]train loss : 0.360194 ,train acc: 0.809326 ,val loss : 0.385993 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :368 ]train loss : 0.249550 ,train acc: 0.878245 ,val loss : 0.391949 ,val acc : 0.825867\n",
      "[ ecpho : 5  iter :369 ]train loss : 0.286918 ,train acc: 0.867666 ,val loss : 0.390080 ,val acc : 0.820679\n",
      "[ ecpho : 5  iter :370 ]train loss : 0.290407 ,train acc: 0.871531 ,val loss : 0.390964 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :371 ]train loss : 0.266490 ,train acc: 0.874013 ,val loss : 0.384757 ,val acc : 0.827271\n",
      "[ ecpho : 5  iter :372 ]train loss : 0.354216 ,train acc: 0.852000 ,val loss : 0.385424 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :373 ]train loss : 0.314624 ,train acc: 0.849721 ,val loss : 0.385718 ,val acc : 0.824982\n",
      "[ ecpho : 5  iter :374 ]train loss : 0.314064 ,train acc: 0.858449 ,val loss : 0.388083 ,val acc : 0.827454\n",
      "[ ecpho : 5  iter :375 ]train loss : 0.317346 ,train acc: 0.860331 ,val loss : 0.383761 ,val acc : 0.827057\n",
      "[ ecpho : 5  iter :376 ]train loss : 0.385950 ,train acc: 0.807048 ,val loss : 0.394473 ,val acc : 0.821655\n",
      "[ ecpho : 5  iter :377 ]train loss : 0.350335 ,train acc: 0.850566 ,val loss : 0.386393 ,val acc : 0.825928\n",
      "[ ecpho : 5  iter :378 ]train loss : 0.309894 ,train acc: 0.868256 ,val loss : 0.386153 ,val acc : 0.827332\n",
      "[ ecpho : 5  iter :379 ]train loss : 0.408870 ,train acc: 0.832408 ,val loss : 0.387492 ,val acc : 0.823059\n",
      "[ ecpho : 5  iter :380 ]train loss : 0.257690 ,train acc: 0.876058 ,val loss : 0.385562 ,val acc : 0.822815\n",
      "[ ecpho : 5  iter :381 ]train loss : 0.366117 ,train acc: 0.849955 ,val loss : 0.394074 ,val acc : 0.820740\n",
      "[ ecpho : 5  iter :382 ]train loss : 0.300759 ,train acc: 0.858256 ,val loss : 0.386383 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :383 ]train loss : 0.384357 ,train acc: 0.808828 ,val loss : 0.383651 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :384 ]train loss : 0.287102 ,train acc: 0.865479 ,val loss : 0.381916 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :385 ]train loss : 0.269628 ,train acc: 0.874532 ,val loss : 0.386836 ,val acc : 0.822571\n",
      "[ ecpho : 5  iter :386 ]train loss : 0.244896 ,train acc: 0.878164 ,val loss : 0.383127 ,val acc : 0.825928\n",
      "[ ecpho : 5  iter :387 ]train loss : 0.261236 ,train acc: 0.871796 ,val loss : 0.382103 ,val acc : 0.824554\n",
      "[ ecpho : 5  iter :388 ]train loss : 0.297451 ,train acc: 0.865123 ,val loss : 0.384531 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :389 ]train loss : 0.327727 ,train acc: 0.856761 ,val loss : 0.388100 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :390 ]train loss : 0.291444 ,train acc: 0.861186 ,val loss : 0.387428 ,val acc : 0.824097\n",
      "[ ecpho : 5  iter :391 ]train loss : 0.263584 ,train acc: 0.878337 ,val loss : 0.381593 ,val acc : 0.825714\n",
      "[ ecpho : 5  iter :392 ]train loss : 0.354124 ,train acc: 0.856039 ,val loss : 0.379683 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :393 ]train loss : 0.287040 ,train acc: 0.845144 ,val loss : 0.386011 ,val acc : 0.826385\n",
      "[ ecpho : 5  iter :394 ]train loss : 0.282177 ,train acc: 0.866028 ,val loss : 0.386542 ,val acc : 0.826385\n",
      "[ ecpho : 5  iter :395 ]train loss : 0.291670 ,train acc: 0.863495 ,val loss : 0.390134 ,val acc : 0.828583\n",
      "[ ecpho : 5  iter :396 ]train loss : 0.324280 ,train acc: 0.860311 ,val loss : 0.385762 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :397 ]train loss : 0.299757 ,train acc: 0.861288 ,val loss : 0.390920 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :398 ]train loss : 0.352494 ,train acc: 0.856700 ,val loss : 0.392486 ,val acc : 0.820557\n",
      "[ ecpho : 5  iter :399 ]train loss : 0.248739 ,train acc: 0.878540 ,val loss : 0.385760 ,val acc : 0.822540\n",
      "[ ecpho : 5  iter :400 ]train loss : 0.364042 ,train acc: 0.836192 ,val loss : 0.388328 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :401 ]train loss : 0.294316 ,train acc: 0.866760 ,val loss : 0.391598 ,val acc : 0.823669\n",
      "[ ecpho : 5  iter :402 ]train loss : 0.422288 ,train acc: 0.830221 ,val loss : 0.385072 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :403 ]train loss : 0.322955 ,train acc: 0.852346 ,val loss : 0.387769 ,val acc : 0.824097\n",
      "[ ecpho : 5  iter :404 ]train loss : 0.298927 ,train acc: 0.865072 ,val loss : 0.388952 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :405 ]train loss : 0.350620 ,train acc: 0.851359 ,val loss : 0.388777 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :406 ]train loss : 0.255035 ,train acc: 0.878347 ,val loss : 0.388581 ,val acc : 0.826294\n",
      "[ ecpho : 5  iter :407 ]train loss : 0.365855 ,train acc: 0.809448 ,val loss : 0.386933 ,val acc : 0.827637\n",
      "[ ecpho : 5  iter :408 ]train loss : 0.295301 ,train acc: 0.858999 ,val loss : 0.388031 ,val acc : 0.823883\n",
      "[ ecpho : 5  iter :409 ]train loss : 0.325726 ,train acc: 0.828990 ,val loss : 0.387274 ,val acc : 0.828339\n",
      "[ ecpho : 5  iter :410 ]train loss : 0.304516 ,train acc: 0.861593 ,val loss : 0.381443 ,val acc : 0.823730\n",
      "[ ecpho : 5  iter :411 ]train loss : 0.315574 ,train acc: 0.853770 ,val loss : 0.384159 ,val acc : 0.824432\n",
      "[ ecpho : 5  iter :412 ]train loss : 0.277756 ,train acc: 0.871307 ,val loss : 0.391534 ,val acc : 0.822296\n",
      "[ ecpho : 5  iter :413 ]train loss : 0.254980 ,train acc: 0.866577 ,val loss : 0.387862 ,val acc : 0.822571\n",
      "[ ecpho : 5  iter :414 ]train loss : 0.338986 ,train acc: 0.850016 ,val loss : 0.390501 ,val acc : 0.822784\n",
      "[ ecpho : 5  iter :415 ]train loss : 0.322491 ,train acc: 0.861471 ,val loss : 0.387566 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :416 ]train loss : 0.329396 ,train acc: 0.830414 ,val loss : 0.383456 ,val acc : 0.827423\n",
      "[ ecpho : 5  iter :417 ]train loss : 0.371001 ,train acc: 0.838786 ,val loss : 0.384523 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :418 ]train loss : 0.432378 ,train acc: 0.815796 ,val loss : 0.384804 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :419 ]train loss : 0.257687 ,train acc: 0.874400 ,val loss : 0.389866 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :420 ]train loss : 0.261253 ,train acc: 0.873301 ,val loss : 0.385018 ,val acc : 0.826385\n",
      "[ ecpho : 5  iter :421 ]train loss : 0.392161 ,train acc: 0.810140 ,val loss : 0.385965 ,val acc : 0.824310\n",
      "[ ecpho : 5  iter :422 ]train loss : 0.296796 ,train acc: 0.866425 ,val loss : 0.387634 ,val acc : 0.825562\n",
      "[ ecpho : 5  iter :423 ]train loss : 0.285389 ,train acc: 0.870239 ,val loss : 0.386112 ,val acc : 0.828674\n",
      "[ ecpho : 5  iter :424 ]train loss : 0.367963 ,train acc: 0.826142 ,val loss : 0.389030 ,val acc : 0.827576\n",
      "[ ecpho : 5  iter :425 ]train loss : 0.284137 ,train acc: 0.867615 ,val loss : 0.390096 ,val acc : 0.822723\n",
      "[ ecpho : 5  iter :426 ]train loss : 0.317462 ,train acc: 0.848531 ,val loss : 0.383962 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :427 ]train loss : 0.339770 ,train acc: 0.855794 ,val loss : 0.384825 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :428 ]train loss : 0.326289 ,train acc: 0.827779 ,val loss : 0.385167 ,val acc : 0.826965\n",
      "[ ecpho : 5  iter :429 ]train loss : 0.312342 ,train acc: 0.862508 ,val loss : 0.392212 ,val acc : 0.820587\n",
      "[ ecpho : 5  iter :430 ]train loss : 0.433090 ,train acc: 0.828318 ,val loss : 0.390595 ,val acc : 0.819855\n",
      "[ ecpho : 5  iter :431 ]train loss : 0.382436 ,train acc: 0.821788 ,val loss : 0.388569 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :432 ]train loss : 0.354319 ,train acc: 0.835124 ,val loss : 0.393196 ,val acc : 0.822601\n",
      "[ ecpho : 5  iter :433 ]train loss : 0.292087 ,train acc: 0.852458 ,val loss : 0.382587 ,val acc : 0.827240\n",
      "[ ecpho : 5  iter :434 ]train loss : 0.315548 ,train acc: 0.836263 ,val loss : 0.386521 ,val acc : 0.822021\n",
      "[ ecpho : 5  iter :435 ]train loss : 0.277657 ,train acc: 0.869985 ,val loss : 0.390504 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :436 ]train loss : 0.249447 ,train acc: 0.882426 ,val loss : 0.382764 ,val acc : 0.825562\n",
      "[ ecpho : 5  iter :437 ]train loss : 0.239105 ,train acc: 0.882660 ,val loss : 0.386949 ,val acc : 0.825409\n",
      "[ ecpho : 5  iter :438 ]train loss : 0.241688 ,train acc: 0.882212 ,val loss : 0.387002 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :439 ]train loss : 0.399719 ,train acc: 0.853129 ,val loss : 0.383434 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :440 ]train loss : 0.310610 ,train acc: 0.862091 ,val loss : 0.390811 ,val acc : 0.823090\n",
      "[ ecpho : 5  iter :441 ]train loss : 0.268967 ,train acc: 0.862905 ,val loss : 0.390298 ,val acc : 0.823029\n",
      "[ ecpho : 5  iter :442 ]train loss : 0.274789 ,train acc: 0.871247 ,val loss : 0.381923 ,val acc : 0.826599\n",
      "[ ecpho : 5  iter :443 ]train loss : 0.279157 ,train acc: 0.869263 ,val loss : 0.388715 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :444 ]train loss : 0.277867 ,train acc: 0.873311 ,val loss : 0.383435 ,val acc : 0.825897\n",
      "[ ecpho : 5  iter :445 ]train loss : 0.256655 ,train acc: 0.876231 ,val loss : 0.384123 ,val acc : 0.826599\n",
      "[ ecpho : 5  iter :446 ]train loss : 0.312425 ,train acc: 0.857778 ,val loss : 0.389266 ,val acc : 0.822998\n",
      "[ ecpho : 5  iter :447 ]train loss : 0.313327 ,train acc: 0.866903 ,val loss : 0.381881 ,val acc : 0.826904\n",
      "[ ecpho : 5  iter :448 ]train loss : 0.312674 ,train acc: 0.839498 ,val loss : 0.383957 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :449 ]train loss : 0.249768 ,train acc: 0.881917 ,val loss : 0.390114 ,val acc : 0.822784\n",
      "[ ecpho : 5  iter :450 ]train loss : 0.316679 ,train acc: 0.845815 ,val loss : 0.388246 ,val acc : 0.823547\n",
      "[ ecpho : 5  iter :451 ]train loss : 0.256329 ,train acc: 0.878255 ,val loss : 0.383333 ,val acc : 0.824005\n",
      "[ ecpho : 5  iter :452 ]train loss : 0.228804 ,train acc: 0.892395 ,val loss : 0.376836 ,val acc : 0.829285\n",
      "[ ecpho : 5  iter :453 ]train loss : 0.319489 ,train acc: 0.855703 ,val loss : 0.390068 ,val acc : 0.824402\n",
      "[ ecpho : 5  iter :454 ]train loss : 0.429907 ,train acc: 0.820781 ,val loss : 0.383008 ,val acc : 0.826660\n",
      "[ ecpho : 5  iter :455 ]train loss : 0.314820 ,train acc: 0.839437 ,val loss : 0.388013 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :456 ]train loss : 0.258724 ,train acc: 0.868510 ,val loss : 0.387794 ,val acc : 0.824249\n",
      "[ ecpho : 5  iter :457 ]train loss : 0.246660 ,train acc: 0.879496 ,val loss : 0.387290 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :458 ]train loss : 0.337368 ,train acc: 0.841960 ,val loss : 0.387039 ,val acc : 0.824188\n",
      "[ ecpho : 5  iter :459 ]train loss : 0.382108 ,train acc: 0.834147 ,val loss : 0.389498 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :460 ]train loss : 0.244884 ,train acc: 0.881368 ,val loss : 0.387076 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :461 ]train loss : 0.276445 ,train acc: 0.876841 ,val loss : 0.388453 ,val acc : 0.826233\n",
      "[ ecpho : 5  iter :462 ]train loss : 0.275312 ,train acc: 0.869314 ,val loss : 0.381774 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :463 ]train loss : 0.334564 ,train acc: 0.852448 ,val loss : 0.388186 ,val acc : 0.824707\n",
      "[ ecpho : 5  iter :464 ]train loss : 0.546852 ,train acc: 0.822032 ,val loss : 0.392871 ,val acc : 0.826874\n",
      "[ ecpho : 5  iter :465 ]train loss : 0.251044 ,train acc: 0.876851 ,val loss : 0.385543 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :466 ]train loss : 0.364199 ,train acc: 0.827281 ,val loss : 0.381989 ,val acc : 0.826660\n",
      "[ ecpho : 5  iter :467 ]train loss : 0.329908 ,train acc: 0.859131 ,val loss : 0.386044 ,val acc : 0.824615\n",
      "[ ecpho : 5  iter :468 ]train loss : 0.303652 ,train acc: 0.865540 ,val loss : 0.383707 ,val acc : 0.826935\n",
      "[ ecpho : 5  iter :469 ]train loss : 0.363249 ,train acc: 0.827871 ,val loss : 0.386313 ,val acc : 0.822815\n",
      "[ ecpho : 5  iter :470 ]train loss : 0.331531 ,train acc: 0.853719 ,val loss : 0.379294 ,val acc : 0.829773\n",
      "[ ecpho : 5  iter :471 ]train loss : 0.341902 ,train acc: 0.830821 ,val loss : 0.385690 ,val acc : 0.824493\n",
      "[ ecpho : 5  iter :472 ]train loss : 0.273084 ,train acc: 0.870148 ,val loss : 0.388226 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :473 ]train loss : 0.326422 ,train acc: 0.840678 ,val loss : 0.385548 ,val acc : 0.828613\n",
      "[ ecpho : 5  iter :474 ]train loss : 0.285277 ,train acc: 0.851797 ,val loss : 0.388783 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :475 ]train loss : 0.351603 ,train acc: 0.850291 ,val loss : 0.384539 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :476 ]train loss : 0.327542 ,train acc: 0.858592 ,val loss : 0.384570 ,val acc : 0.823914\n",
      "[ ecpho : 5  iter :477 ]train loss : 0.316263 ,train acc: 0.847646 ,val loss : 0.389550 ,val acc : 0.823029\n",
      "[ ecpho : 5  iter :478 ]train loss : 0.438163 ,train acc: 0.786052 ,val loss : 0.386328 ,val acc : 0.826721\n",
      "[ ecpho : 5  iter :479 ]train loss : 0.295079 ,train acc: 0.864370 ,val loss : 0.384177 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :480 ]train loss : 0.230196 ,train acc: 0.887736 ,val loss : 0.389788 ,val acc : 0.822998\n",
      "[ ecpho : 5  iter :481 ]train loss : 0.261432 ,train acc: 0.875966 ,val loss : 0.384933 ,val acc : 0.824493\n",
      "[ ecpho : 5  iter :482 ]train loss : 0.396146 ,train acc: 0.787181 ,val loss : 0.387991 ,val acc : 0.822540\n",
      "[ ecpho : 5  iter :483 ]train loss : 0.355292 ,train acc: 0.842702 ,val loss : 0.391243 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :484 ]train loss : 0.295868 ,train acc: 0.868662 ,val loss : 0.389784 ,val acc : 0.827454\n",
      "[ ecpho : 5  iter :485 ]train loss : 0.252872 ,train acc: 0.878520 ,val loss : 0.385788 ,val acc : 0.828003\n",
      "[ ecpho : 5  iter :486 ]train loss : 0.379552 ,train acc: 0.837026 ,val loss : 0.385075 ,val acc : 0.826782\n",
      "[ ecpho : 5  iter :487 ]train loss : 0.314140 ,train acc: 0.839162 ,val loss : 0.390967 ,val acc : 0.822693\n",
      "[ ecpho : 5  iter :488 ]train loss : 0.341498 ,train acc: 0.844310 ,val loss : 0.385511 ,val acc : 0.826233\n",
      "[ ecpho : 5  iter :489 ]train loss : 0.317074 ,train acc: 0.857544 ,val loss : 0.386355 ,val acc : 0.824921\n",
      "[ ecpho : 5  iter :490 ]train loss : 0.271954 ,train acc: 0.869487 ,val loss : 0.384942 ,val acc : 0.825928\n",
      "[ ecpho : 5  iter :491 ]train loss : 0.320152 ,train acc: 0.854472 ,val loss : 0.386918 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :492 ]train loss : 0.431322 ,train acc: 0.806153 ,val loss : 0.389474 ,val acc : 0.824280\n",
      "[ ecpho : 5  iter :493 ]train loss : 0.266817 ,train acc: 0.872772 ,val loss : 0.386415 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :494 ]train loss : 0.306125 ,train acc: 0.855560 ,val loss : 0.387614 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :495 ]train loss : 0.300940 ,train acc: 0.862976 ,val loss : 0.388629 ,val acc : 0.826904\n",
      "[ ecpho : 5  iter :496 ]train loss : 0.397477 ,train acc: 0.818685 ,val loss : 0.382944 ,val acc : 0.823944\n",
      "[ ecpho : 5  iter :497 ]train loss : 0.259746 ,train acc: 0.875753 ,val loss : 0.382763 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :498 ]train loss : 0.254488 ,train acc: 0.875905 ,val loss : 0.385735 ,val acc : 0.824280\n",
      "[ ecpho : 5  iter :499 ]train loss : 0.292511 ,train acc: 0.864411 ,val loss : 0.381696 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :500 ]train loss : 0.270222 ,train acc: 0.877523 ,val loss : 0.391805 ,val acc : 0.821228\n",
      "[ ecpho : 5  iter :501 ]train loss : 0.270017 ,train acc: 0.871307 ,val loss : 0.387436 ,val acc : 0.822937\n",
      "[ ecpho : 5  iter :502 ]train loss : 0.284204 ,train acc: 0.866394 ,val loss : 0.389523 ,val acc : 0.825348\n",
      "[ ecpho : 5  iter :503 ]train loss : 0.360468 ,train acc: 0.819102 ,val loss : 0.387724 ,val acc : 0.824158\n",
      "[ ecpho : 5  iter :504 ]train loss : 0.238274 ,train acc: 0.880371 ,val loss : 0.385991 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :505 ]train loss : 0.298166 ,train acc: 0.860179 ,val loss : 0.390232 ,val acc : 0.825073\n",
      "[ ecpho : 5  iter :506 ]train loss : 0.277444 ,train acc: 0.869018 ,val loss : 0.383087 ,val acc : 0.825806\n",
      "[ ecpho : 5  iter :507 ]train loss : 0.443363 ,train acc: 0.828969 ,val loss : 0.384457 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :508 ]train loss : 0.341061 ,train acc: 0.834117 ,val loss : 0.386949 ,val acc : 0.824951\n",
      "[ ecpho : 5  iter :509 ]train loss : 0.395999 ,train acc: 0.843211 ,val loss : 0.387396 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :510 ]train loss : 0.280620 ,train acc: 0.861491 ,val loss : 0.384459 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :511 ]train loss : 0.330850 ,train acc: 0.833832 ,val loss : 0.391960 ,val acc : 0.824463\n",
      "[ ecpho : 5  iter :512 ]train loss : 0.253019 ,train acc: 0.879354 ,val loss : 0.383154 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :513 ]train loss : 0.234425 ,train acc: 0.881856 ,val loss : 0.389466 ,val acc : 0.824799\n",
      "[ ecpho : 5  iter :514 ]train loss : 0.280370 ,train acc: 0.869924 ,val loss : 0.382464 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :515 ]train loss : 0.387108 ,train acc: 0.840261 ,val loss : 0.388962 ,val acc : 0.822449\n",
      "[ ecpho : 5  iter :516 ]train loss : 0.431645 ,train acc: 0.837036 ,val loss : 0.386612 ,val acc : 0.827454\n",
      "[ ecpho : 5  iter :517 ]train loss : 0.265029 ,train acc: 0.873423 ,val loss : 0.385927 ,val acc : 0.824005\n",
      "[ ecpho : 5  iter :518 ]train loss : 0.258266 ,train acc: 0.873505 ,val loss : 0.385585 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :519 ]train loss : 0.286219 ,train acc: 0.862356 ,val loss : 0.386523 ,val acc : 0.823578\n",
      "[ ecpho : 5  iter :520 ]train loss : 0.369203 ,train acc: 0.842499 ,val loss : 0.383649 ,val acc : 0.824554\n",
      "[ ecpho : 5  iter :521 ]train loss : 0.335378 ,train acc: 0.831401 ,val loss : 0.388254 ,val acc : 0.826965\n",
      "[ ecpho : 5  iter :522 ]train loss : 0.314140 ,train acc: 0.849203 ,val loss : 0.376329 ,val acc : 0.829346\n",
      "[ ecpho : 5  iter :523 ]train loss : 0.373299 ,train acc: 0.845703 ,val loss : 0.384195 ,val acc : 0.827820\n",
      "[ ecpho : 5  iter :524 ]train loss : 0.330502 ,train acc: 0.862874 ,val loss : 0.390412 ,val acc : 0.823242\n",
      "[ ecpho : 5  iter :525 ]train loss : 0.335014 ,train acc: 0.833191 ,val loss : 0.382158 ,val acc : 0.828247\n",
      "[ ecpho : 5  iter :526 ]train loss : 0.341752 ,train acc: 0.853943 ,val loss : 0.383986 ,val acc : 0.824219\n",
      "[ ecpho : 5  iter :527 ]train loss : 0.368219 ,train acc: 0.842936 ,val loss : 0.388056 ,val acc : 0.825562\n",
      "[ ecpho : 5  iter :528 ]train loss : 0.424312 ,train acc: 0.798788 ,val loss : 0.386011 ,val acc : 0.823456\n",
      "[ ecpho : 5  iter :529 ]train loss : 0.289568 ,train acc: 0.859935 ,val loss : 0.383397 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :530 ]train loss : 0.370485 ,train acc: 0.846578 ,val loss : 0.388330 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :531 ]train loss : 0.308335 ,train acc: 0.838023 ,val loss : 0.386599 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :532 ]train loss : 0.335778 ,train acc: 0.846853 ,val loss : 0.387109 ,val acc : 0.823944\n",
      "[ ecpho : 5  iter :533 ]train loss : 0.315385 ,train acc: 0.852458 ,val loss : 0.382224 ,val acc : 0.827698\n",
      "[ ecpho : 5  iter :534 ]train loss : 0.318983 ,train acc: 0.846080 ,val loss : 0.386539 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :535 ]train loss : 0.300349 ,train acc: 0.863414 ,val loss : 0.382257 ,val acc : 0.827942\n",
      "[ ecpho : 5  iter :536 ]train loss : 0.332172 ,train acc: 0.855215 ,val loss : 0.388149 ,val acc : 0.823547\n",
      "[ ecpho : 5  iter :537 ]train loss : 0.263704 ,train acc: 0.871674 ,val loss : 0.384491 ,val acc : 0.824188\n",
      "[ ecpho : 5  iter :538 ]train loss : 0.365237 ,train acc: 0.845154 ,val loss : 0.385158 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :539 ]train loss : 0.320821 ,train acc: 0.856313 ,val loss : 0.383320 ,val acc : 0.827026\n",
      "[ ecpho : 5  iter :540 ]train loss : 0.302921 ,train acc: 0.839854 ,val loss : 0.385722 ,val acc : 0.826813\n",
      "[ ecpho : 5  iter :541 ]train loss : 0.376461 ,train acc: 0.808797 ,val loss : 0.384613 ,val acc : 0.826172\n",
      "[ ecpho : 5  iter :542 ]train loss : 0.250696 ,train acc: 0.880300 ,val loss : 0.382590 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :543 ]train loss : 0.364872 ,train acc: 0.843720 ,val loss : 0.384006 ,val acc : 0.826813\n",
      "[ ecpho : 5  iter :544 ]train loss : 0.375389 ,train acc: 0.799357 ,val loss : 0.388383 ,val acc : 0.826416\n",
      "[ ecpho : 5  iter :545 ]train loss : 0.258016 ,train acc: 0.873332 ,val loss : 0.390502 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :546 ]train loss : 0.326001 ,train acc: 0.862824 ,val loss : 0.384951 ,val acc : 0.828796\n",
      "[ ecpho : 5  iter :547 ]train loss : 0.346077 ,train acc: 0.847087 ,val loss : 0.388653 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :548 ]train loss : 0.345822 ,train acc: 0.814534 ,val loss : 0.387385 ,val acc : 0.825592\n",
      "[ ecpho : 5  iter :549 ]train loss : 0.304555 ,train acc: 0.859579 ,val loss : 0.383028 ,val acc : 0.827362\n",
      "[ ecpho : 5  iter :550 ]train loss : 0.299805 ,train acc: 0.853221 ,val loss : 0.386911 ,val acc : 0.821106\n",
      "[ ecpho : 5  iter :551 ]train loss : 0.255264 ,train acc: 0.878825 ,val loss : 0.381379 ,val acc : 0.828064\n",
      "[ ecpho : 5  iter :552 ]train loss : 0.281048 ,train acc: 0.863790 ,val loss : 0.384534 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :553 ]train loss : 0.261980 ,train acc: 0.877808 ,val loss : 0.386447 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :554 ]train loss : 0.338989 ,train acc: 0.828797 ,val loss : 0.388418 ,val acc : 0.827911\n",
      "[ ecpho : 5  iter :555 ]train loss : 0.284027 ,train acc: 0.870606 ,val loss : 0.384736 ,val acc : 0.826477\n",
      "[ ecpho : 5  iter :556 ]train loss : 0.278379 ,train acc: 0.864868 ,val loss : 0.388253 ,val acc : 0.829224\n",
      "[ ecpho : 5  iter :557 ]train loss : 0.275788 ,train acc: 0.872599 ,val loss : 0.381698 ,val acc : 0.830933\n",
      "[ ecpho : 5  iter :558 ]train loss : 0.372164 ,train acc: 0.820770 ,val loss : 0.386894 ,val acc : 0.826996\n",
      "[ ecpho : 5  iter :559 ]train loss : 0.322163 ,train acc: 0.869141 ,val loss : 0.382068 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :560 ]train loss : 0.369095 ,train acc: 0.825012 ,val loss : 0.381921 ,val acc : 0.827515\n",
      "[ ecpho : 5  iter :561 ]train loss : 0.332856 ,train acc: 0.854452 ,val loss : 0.392304 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :562 ]train loss : 0.332971 ,train acc: 0.854391 ,val loss : 0.389994 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :563 ]train loss : 0.293650 ,train acc: 0.864522 ,val loss : 0.386235 ,val acc : 0.823639\n",
      "[ ecpho : 5  iter :564 ]train loss : 0.306569 ,train acc: 0.855896 ,val loss : 0.379670 ,val acc : 0.827332\n",
      "[ ecpho : 5  iter :565 ]train loss : 0.270205 ,train acc: 0.872793 ,val loss : 0.388068 ,val acc : 0.824005\n",
      "[ ecpho : 5  iter :566 ]train loss : 0.296971 ,train acc: 0.857615 ,val loss : 0.383954 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :567 ]train loss : 0.283064 ,train acc: 0.863841 ,val loss : 0.383177 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :568 ]train loss : 0.260356 ,train acc: 0.877136 ,val loss : 0.393821 ,val acc : 0.823700\n",
      "[ ecpho : 5  iter :569 ]train loss : 0.288165 ,train acc: 0.866831 ,val loss : 0.388026 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :570 ]train loss : 0.507181 ,train acc: 0.797455 ,val loss : 0.389446 ,val acc : 0.827240\n",
      "[ ecpho : 5  iter :571 ]train loss : 0.275550 ,train acc: 0.871338 ,val loss : 0.382256 ,val acc : 0.825470\n",
      "[ ecpho : 5  iter :572 ]train loss : 0.343343 ,train acc: 0.844666 ,val loss : 0.385474 ,val acc : 0.825562\n",
      "[ ecpho : 5  iter :573 ]train loss : 0.276507 ,train acc: 0.872803 ,val loss : 0.386468 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :574 ]train loss : 0.269422 ,train acc: 0.867462 ,val loss : 0.380953 ,val acc : 0.829132\n",
      "[ ecpho : 5  iter :575 ]train loss : 0.250318 ,train acc: 0.878540 ,val loss : 0.387832 ,val acc : 0.827026\n",
      "[ ecpho : 5  iter :576 ]train loss : 0.461338 ,train acc: 0.793630 ,val loss : 0.386634 ,val acc : 0.825684\n",
      "[ ecpho : 5  iter :577 ]train loss : 0.261596 ,train acc: 0.877533 ,val loss : 0.384301 ,val acc : 0.823669\n",
      "[ ecpho : 5  iter :578 ]train loss : 0.297997 ,train acc: 0.855215 ,val loss : 0.384826 ,val acc : 0.827026\n",
      "[ ecpho : 5  iter :579 ]train loss : 0.316608 ,train acc: 0.848440 ,val loss : 0.380147 ,val acc : 0.831360\n",
      "[ ecpho : 5  iter :580 ]train loss : 0.292436 ,train acc: 0.866394 ,val loss : 0.386744 ,val acc : 0.826843\n",
      "[ ecpho : 5  iter :581 ]train loss : 0.249897 ,train acc: 0.878784 ,val loss : 0.384261 ,val acc : 0.828491\n",
      "[ ecpho : 5  iter :582 ]train loss : 0.308862 ,train acc: 0.862640 ,val loss : 0.387167 ,val acc : 0.826599\n",
      "[ ecpho : 5  iter :583 ]train loss : 0.370632 ,train acc: 0.847056 ,val loss : 0.383995 ,val acc : 0.828369\n",
      "[ ecpho : 5  iter :584 ]train loss : 0.282290 ,train acc: 0.865774 ,val loss : 0.389137 ,val acc : 0.822388\n",
      "[ ecpho : 5  iter :585 ]train loss : 0.353595 ,train acc: 0.827881 ,val loss : 0.388788 ,val acc : 0.820099\n",
      "[ ecpho : 5  iter :586 ]train loss : 0.405328 ,train acc: 0.817017 ,val loss : 0.386276 ,val acc : 0.825073\n",
      "[ ecpho : 5  iter :587 ]train loss : 0.296580 ,train acc: 0.854655 ,val loss : 0.383228 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :588 ]train loss : 0.319684 ,train acc: 0.846985 ,val loss : 0.385074 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :589 ]train loss : 0.265145 ,train acc: 0.878367 ,val loss : 0.388848 ,val acc : 0.821869\n",
      "[ ecpho : 5  iter :590 ]train loss : 0.368527 ,train acc: 0.809489 ,val loss : 0.385518 ,val acc : 0.822815\n",
      "[ ecpho : 5  iter :591 ]train loss : 0.295656 ,train acc: 0.850647 ,val loss : 0.380977 ,val acc : 0.832123\n",
      "[ ecpho : 5  iter :592 ]train loss : 0.264864 ,train acc: 0.873322 ,val loss : 0.386243 ,val acc : 0.823395\n",
      "[ ecpho : 5  iter :593 ]train loss : 0.441159 ,train acc: 0.775472 ,val loss : 0.390870 ,val acc : 0.823181\n",
      "[ ecpho : 5  iter :594 ]train loss : 0.334588 ,train acc: 0.854624 ,val loss : 0.389031 ,val acc : 0.823975\n",
      "[ ecpho : 5  iter :595 ]train loss : 0.332634 ,train acc: 0.850301 ,val loss : 0.388387 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :596 ]train loss : 0.258636 ,train acc: 0.877462 ,val loss : 0.385372 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :597 ]train loss : 0.279284 ,train acc: 0.861623 ,val loss : 0.384417 ,val acc : 0.825348\n",
      "[ ecpho : 5  iter :598 ]train loss : 0.266580 ,train acc: 0.870260 ,val loss : 0.391784 ,val acc : 0.821442\n",
      "[ ecpho : 5  iter :599 ]train loss : 0.264239 ,train acc: 0.872732 ,val loss : 0.384068 ,val acc : 0.826080\n",
      "[ ecpho : 5  iter :600 ]train loss : 0.313154 ,train acc: 0.837789 ,val loss : 0.387549 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :601 ]train loss : 0.301910 ,train acc: 0.862081 ,val loss : 0.394123 ,val acc : 0.820801\n",
      "[ ecpho : 5  iter :602 ]train loss : 0.320879 ,train acc: 0.851624 ,val loss : 0.387467 ,val acc : 0.823517\n",
      "[ ecpho : 5  iter :603 ]train loss : 0.445952 ,train acc: 0.779470 ,val loss : 0.386214 ,val acc : 0.824463\n",
      "[ ecpho : 5  iter :604 ]train loss : 0.357270 ,train acc: 0.792481 ,val loss : 0.380163 ,val acc : 0.826599\n",
      "[ ecpho : 5  iter :605 ]train loss : 0.271628 ,train acc: 0.872477 ,val loss : 0.385243 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :606 ]train loss : 0.337278 ,train acc: 0.856079 ,val loss : 0.386987 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :607 ]train loss : 0.271090 ,train acc: 0.872915 ,val loss : 0.386858 ,val acc : 0.824707\n",
      "[ ecpho : 5  iter :608 ]train loss : 0.251725 ,train acc: 0.878642 ,val loss : 0.383561 ,val acc : 0.829193\n",
      "[ ecpho : 5  iter :609 ]train loss : 0.258386 ,train acc: 0.875692 ,val loss : 0.387534 ,val acc : 0.822144\n",
      "[ ecpho : 5  iter :610 ]train loss : 0.442109 ,train acc: 0.783549 ,val loss : 0.386568 ,val acc : 0.827759\n",
      "[ ecpho : 5  iter :611 ]train loss : 0.238485 ,train acc: 0.884135 ,val loss : 0.386935 ,val acc : 0.828461\n",
      "[ ecpho : 5  iter :612 ]train loss : 0.377352 ,train acc: 0.779114 ,val loss : 0.386465 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :613 ]train loss : 0.408716 ,train acc: 0.843720 ,val loss : 0.387379 ,val acc : 0.824341\n",
      "[ ecpho : 5  iter :614 ]train loss : 0.335762 ,train acc: 0.844574 ,val loss : 0.391604 ,val acc : 0.824829\n",
      "[ ecpho : 5  iter :615 ]train loss : 0.282118 ,train acc: 0.869934 ,val loss : 0.391698 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :616 ]train loss : 0.349394 ,train acc: 0.810171 ,val loss : 0.381584 ,val acc : 0.824371\n",
      "[ ecpho : 5  iter :617 ]train loss : 0.359875 ,train acc: 0.840057 ,val loss : 0.386859 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :618 ]train loss : 0.488710 ,train acc: 0.795309 ,val loss : 0.388958 ,val acc : 0.823425\n",
      "[ ecpho : 5  iter :619 ]train loss : 0.347470 ,train acc: 0.837443 ,val loss : 0.383313 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :620 ]train loss : 0.248268 ,train acc: 0.878326 ,val loss : 0.384950 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :621 ]train loss : 0.303208 ,train acc: 0.859365 ,val loss : 0.383213 ,val acc : 0.827362\n",
      "[ ecpho : 5  iter :622 ]train loss : 0.232773 ,train acc: 0.886007 ,val loss : 0.388391 ,val acc : 0.821625\n",
      "[ ecpho : 5  iter :623 ]train loss : 0.296601 ,train acc: 0.850627 ,val loss : 0.388167 ,val acc : 0.822723\n",
      "[ ecpho : 5  iter :624 ]train loss : 0.321618 ,train acc: 0.848724 ,val loss : 0.384721 ,val acc : 0.823792\n",
      "[ ecpho : 5  iter :625 ]train loss : 0.272722 ,train acc: 0.872894 ,val loss : 0.384297 ,val acc : 0.827942\n",
      "[ ecpho : 5  iter :626 ]train loss : 0.284628 ,train acc: 0.863851 ,val loss : 0.387444 ,val acc : 0.822693\n",
      "[ ecpho : 5  iter :627 ]train loss : 0.356818 ,train acc: 0.849203 ,val loss : 0.391066 ,val acc : 0.825745\n",
      "[ ecpho : 5  iter :628 ]train loss : 0.332433 ,train acc: 0.828156 ,val loss : 0.388498 ,val acc : 0.822815\n",
      "[ ecpho : 5  iter :629 ]train loss : 0.291166 ,train acc: 0.863770 ,val loss : 0.381002 ,val acc : 0.826172\n",
      "[ ecpho : 5  iter :630 ]train loss : 0.427641 ,train acc: 0.753642 ,val loss : 0.378050 ,val acc : 0.826660\n",
      "[ ecpho : 5  iter :631 ]train loss : 0.260580 ,train acc: 0.874227 ,val loss : 0.379031 ,val acc : 0.828491\n",
      "[ ecpho : 5  iter :632 ]train loss : 0.334903 ,train acc: 0.856374 ,val loss : 0.388724 ,val acc : 0.824677\n",
      "[ ecpho : 5  iter :633 ]train loss : 0.432193 ,train acc: 0.743937 ,val loss : 0.389072 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :634 ]train loss : 0.315554 ,train acc: 0.857290 ,val loss : 0.381390 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :635 ]train loss : 0.269159 ,train acc: 0.872986 ,val loss : 0.390580 ,val acc : 0.824188\n",
      "[ ecpho : 5  iter :636 ]train loss : 0.336268 ,train acc: 0.851685 ,val loss : 0.384743 ,val acc : 0.827637\n",
      "[ ecpho : 5  iter :637 ]train loss : 0.275794 ,train acc: 0.856690 ,val loss : 0.388830 ,val acc : 0.824158\n",
      "[ ecpho : 5  iter :638 ]train loss : 0.259357 ,train acc: 0.878245 ,val loss : 0.385238 ,val acc : 0.827271\n",
      "[ ecpho : 5  iter :639 ]train loss : 0.282761 ,train acc: 0.866953 ,val loss : 0.392801 ,val acc : 0.825073\n",
      "[ ecpho : 5  iter :640 ]train loss : 0.324796 ,train acc: 0.852061 ,val loss : 0.384518 ,val acc : 0.826752\n",
      "[ ecpho : 5  iter :641 ]train loss : 0.315450 ,train acc: 0.854960 ,val loss : 0.381526 ,val acc : 0.829620\n",
      "[ ecpho : 5  iter :642 ]train loss : 0.284368 ,train acc: 0.860565 ,val loss : 0.378718 ,val acc : 0.826416\n",
      "[ ecpho : 5  iter :643 ]train loss : 0.274901 ,train acc: 0.873169 ,val loss : 0.387278 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :644 ]train loss : 0.280255 ,train acc: 0.863963 ,val loss : 0.390338 ,val acc : 0.824799\n",
      "[ ecpho : 5  iter :645 ]train loss : 0.317515 ,train acc: 0.843160 ,val loss : 0.379211 ,val acc : 0.827881\n",
      "[ ecpho : 5  iter :646 ]train loss : 0.242483 ,train acc: 0.882711 ,val loss : 0.389249 ,val acc : 0.824219\n",
      "[ ecpho : 5  iter :647 ]train loss : 0.402782 ,train acc: 0.832683 ,val loss : 0.386365 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :648 ]train loss : 0.324095 ,train acc: 0.836650 ,val loss : 0.384643 ,val acc : 0.823792\n",
      "[ ecpho : 5  iter :649 ]train loss : 0.299950 ,train acc: 0.860677 ,val loss : 0.384474 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :650 ]train loss : 0.327614 ,train acc: 0.833689 ,val loss : 0.390697 ,val acc : 0.828308\n",
      "[ ecpho : 5  iter :651 ]train loss : 0.415396 ,train acc: 0.824738 ,val loss : 0.386152 ,val acc : 0.824921\n",
      "[ ecpho : 5  iter :652 ]train loss : 0.347071 ,train acc: 0.835653 ,val loss : 0.390546 ,val acc : 0.821838\n",
      "[ ecpho : 5  iter :653 ]train loss : 0.414030 ,train acc: 0.774557 ,val loss : 0.385916 ,val acc : 0.825745\n",
      "[ ecpho : 5  iter :654 ]train loss : 0.338816 ,train acc: 0.850952 ,val loss : 0.389516 ,val acc : 0.823181\n",
      "[ ecpho : 5  iter :655 ]train loss : 0.271252 ,train acc: 0.873505 ,val loss : 0.385015 ,val acc : 0.827667\n",
      "[ ecpho : 5  iter :656 ]train loss : 0.511629 ,train acc: 0.799724 ,val loss : 0.384395 ,val acc : 0.828094\n",
      "[ ecpho : 5  iter :657 ]train loss : 0.344454 ,train acc: 0.844055 ,val loss : 0.381817 ,val acc : 0.826080\n",
      "[ ecpho : 5  iter :658 ]train loss : 0.310998 ,train acc: 0.853709 ,val loss : 0.384290 ,val acc : 0.826721\n",
      "[ ecpho : 5  iter :659 ]train loss : 0.314813 ,train acc: 0.843404 ,val loss : 0.385611 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :660 ]train loss : 0.315166 ,train acc: 0.851583 ,val loss : 0.383498 ,val acc : 0.823364\n",
      "[ ecpho : 5  iter :661 ]train loss : 0.404096 ,train acc: 0.808167 ,val loss : 0.386822 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :662 ]train loss : 0.376802 ,train acc: 0.823110 ,val loss : 0.384364 ,val acc : 0.824982\n",
      "[ ecpho : 5  iter :663 ]train loss : 0.322737 ,train acc: 0.850667 ,val loss : 0.380452 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :664 ]train loss : 0.336077 ,train acc: 0.849009 ,val loss : 0.381895 ,val acc : 0.828156\n",
      "[ ecpho : 5  iter :665 ]train loss : 0.251246 ,train acc: 0.878133 ,val loss : 0.385094 ,val acc : 0.825012\n",
      "[ ecpho : 5  iter :666 ]train loss : 0.419002 ,train acc: 0.804901 ,val loss : 0.382062 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :667 ]train loss : 0.352456 ,train acc: 0.821075 ,val loss : 0.382460 ,val acc : 0.826752\n",
      "[ ecpho : 5  iter :668 ]train loss : 0.459279 ,train acc: 0.812999 ,val loss : 0.387989 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :669 ]train loss : 0.276213 ,train acc: 0.866150 ,val loss : 0.388901 ,val acc : 0.821960\n",
      "[ ecpho : 5  iter :670 ]train loss : 0.334925 ,train acc: 0.807139 ,val loss : 0.387808 ,val acc : 0.822723\n",
      "[ ecpho : 5  iter :671 ]train loss : 0.483981 ,train acc: 0.779846 ,val loss : 0.386264 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :672 ]train loss : 0.271843 ,train acc: 0.866323 ,val loss : 0.387697 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :673 ]train loss : 0.258577 ,train acc: 0.880147 ,val loss : 0.382226 ,val acc : 0.827301\n",
      "[ ecpho : 5  iter :674 ]train loss : 0.351020 ,train acc: 0.843333 ,val loss : 0.386869 ,val acc : 0.827087\n",
      "[ ecpho : 5  iter :675 ]train loss : 0.326548 ,train acc: 0.856934 ,val loss : 0.394901 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :676 ]train loss : 0.323107 ,train acc: 0.839589 ,val loss : 0.386159 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :677 ]train loss : 0.275838 ,train acc: 0.868744 ,val loss : 0.386652 ,val acc : 0.824951\n",
      "[ ecpho : 5  iter :678 ]train loss : 0.297538 ,train acc: 0.848918 ,val loss : 0.386876 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :679 ]train loss : 0.258179 ,train acc: 0.879608 ,val loss : 0.381723 ,val acc : 0.825989\n",
      "[ ecpho : 5  iter :680 ]train loss : 0.280039 ,train acc: 0.866364 ,val loss : 0.382418 ,val acc : 0.824707\n",
      "[ ecpho : 5  iter :681 ]train loss : 0.421292 ,train acc: 0.770966 ,val loss : 0.384522 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :682 ]train loss : 0.333905 ,train acc: 0.833262 ,val loss : 0.387691 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :683 ]train loss : 0.263403 ,train acc: 0.877106 ,val loss : 0.382996 ,val acc : 0.829041\n",
      "[ ecpho : 5  iter :684 ]train loss : 0.418900 ,train acc: 0.780640 ,val loss : 0.386059 ,val acc : 0.825989\n",
      "[ ecpho : 5  iter :685 ]train loss : 0.253640 ,train acc: 0.879679 ,val loss : 0.388933 ,val acc : 0.822968\n",
      "[ ecpho : 5  iter :686 ]train loss : 0.286774 ,train acc: 0.861572 ,val loss : 0.382187 ,val acc : 0.826904\n",
      "[ ecpho : 5  iter :687 ]train loss : 0.248898 ,train acc: 0.880687 ,val loss : 0.383532 ,val acc : 0.826538\n",
      "[ ecpho : 5  iter :688 ]train loss : 0.238972 ,train acc: 0.883006 ,val loss : 0.384439 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :689 ]train loss : 0.278312 ,train acc: 0.865479 ,val loss : 0.390614 ,val acc : 0.826355\n",
      "[ ecpho : 5  iter :690 ]train loss : 0.237855 ,train acc: 0.886027 ,val loss : 0.389024 ,val acc : 0.826477\n",
      "[ ecpho : 5  iter :691 ]train loss : 0.327558 ,train acc: 0.863017 ,val loss : 0.385710 ,val acc : 0.828552\n",
      "[ ecpho : 5  iter :692 ]train loss : 0.291119 ,train acc: 0.863566 ,val loss : 0.382435 ,val acc : 0.825989\n",
      "[ ecpho : 5  iter :693 ]train loss : 0.353952 ,train acc: 0.846904 ,val loss : 0.384976 ,val acc : 0.827728\n",
      "[ ecpho : 5  iter :694 ]train loss : 0.323325 ,train acc: 0.807953 ,val loss : 0.381334 ,val acc : 0.825745\n",
      "[ ecpho : 5  iter :695 ]train loss : 0.337544 ,train acc: 0.844432 ,val loss : 0.383297 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :696 ]train loss : 0.290477 ,train acc: 0.870870 ,val loss : 0.388851 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :697 ]train loss : 0.572198 ,train acc: 0.734741 ,val loss : 0.389151 ,val acc : 0.824860\n",
      "[ ecpho : 5  iter :698 ]train loss : 0.293255 ,train acc: 0.868307 ,val loss : 0.384064 ,val acc : 0.827393\n",
      "[ ecpho : 5  iter :699 ]train loss : 0.302507 ,train acc: 0.853048 ,val loss : 0.388446 ,val acc : 0.827148\n",
      "[ ecpho : 5  iter :700 ]train loss : 0.399599 ,train acc: 0.817352 ,val loss : 0.385132 ,val acc : 0.824677\n",
      "[ ecpho : 5  iter :701 ]train loss : 0.326049 ,train acc: 0.847585 ,val loss : 0.383172 ,val acc : 0.826630\n",
      "[ ecpho : 5  iter :702 ]train loss : 0.335457 ,train acc: 0.741028 ,val loss : 0.386303 ,val acc : 0.827881\n",
      "[ ecpho : 5  iter :703 ]train loss : 0.337791 ,train acc: 0.834920 ,val loss : 0.380566 ,val acc : 0.828339\n",
      "[ ecpho : 5  iter :704 ]train loss : 0.408647 ,train acc: 0.788941 ,val loss : 0.382294 ,val acc : 0.827759\n",
      "[ ecpho : 5  iter :705 ]train loss : 0.266512 ,train acc: 0.869843 ,val loss : 0.386769 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :706 ]train loss : 0.255423 ,train acc: 0.877309 ,val loss : 0.394394 ,val acc : 0.826233\n",
      "[ ecpho : 5  iter :707 ]train loss : 0.289520 ,train acc: 0.856140 ,val loss : 0.386197 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :708 ]train loss : 0.265128 ,train acc: 0.870504 ,val loss : 0.381965 ,val acc : 0.828552\n",
      "[ ecpho : 5  iter :709 ]train loss : 0.302946 ,train acc: 0.866262 ,val loss : 0.386526 ,val acc : 0.824371\n",
      "[ ecpho : 5  iter :710 ]train loss : 0.290795 ,train acc: 0.854980 ,val loss : 0.391738 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :711 ]train loss : 0.265747 ,train acc: 0.875814 ,val loss : 0.386091 ,val acc : 0.825958\n",
      "[ ecpho : 5  iter :712 ]train loss : 0.354366 ,train acc: 0.848155 ,val loss : 0.386136 ,val acc : 0.827271\n",
      "[ ecpho : 5  iter :713 ]train loss : 0.271695 ,train acc: 0.873077 ,val loss : 0.383019 ,val acc : 0.825623\n",
      "[ ecpho : 5  iter :714 ]train loss : 0.247447 ,train acc: 0.881602 ,val loss : 0.385145 ,val acc : 0.827881\n",
      "[ ecpho : 5  iter :715 ]train loss : 0.274524 ,train acc: 0.872742 ,val loss : 0.391114 ,val acc : 0.824097\n",
      "[ ecpho : 5  iter :716 ]train loss : 0.267573 ,train acc: 0.868419 ,val loss : 0.384108 ,val acc : 0.824646\n",
      "[ ecpho : 5  iter :717 ]train loss : 0.284979 ,train acc: 0.856476 ,val loss : 0.391555 ,val acc : 0.823486\n",
      "[ ecpho : 5  iter :718 ]train loss : 0.293759 ,train acc: 0.865214 ,val loss : 0.390451 ,val acc : 0.821411\n",
      "[ ecpho : 5  iter :719 ]train loss : 0.314823 ,train acc: 0.845317 ,val loss : 0.388972 ,val acc : 0.824677\n",
      "[ ecpho : 5  iter :720 ]train loss : 0.289425 ,train acc: 0.860891 ,val loss : 0.389385 ,val acc : 0.824799\n",
      "[ ecpho : 5  iter :721 ]train loss : 0.283294 ,train acc: 0.875163 ,val loss : 0.387666 ,val acc : 0.824738\n",
      "[ ecpho : 5  iter :722 ]train loss : 0.252750 ,train acc: 0.880320 ,val loss : 0.385906 ,val acc : 0.825836\n",
      "[ ecpho : 5  iter :723 ]train loss : 0.286035 ,train acc: 0.870453 ,val loss : 0.387201 ,val acc : 0.824036\n",
      "[ ecpho : 5  iter :724 ]train loss : 0.494954 ,train acc: 0.791341 ,val loss : 0.384775 ,val acc : 0.825592\n",
      "[ ecpho : 5  iter :725 ]train loss : 0.351713 ,train acc: 0.823761 ,val loss : 0.379126 ,val acc : 0.829620\n",
      "[ ecpho : 5  iter :726 ]train loss : 0.325587 ,train acc: 0.856293 ,val loss : 0.380964 ,val acc : 0.829468\n",
      "[ ecpho : 5  iter :727 ]train loss : 0.295477 ,train acc: 0.864472 ,val loss : 0.385263 ,val acc : 0.825348\n",
      "[ ecpho : 5  iter :728 ]train loss : 0.423769 ,train acc: 0.840444 ,val loss : 0.393306 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :729 ]train loss : 0.302689 ,train acc: 0.855479 ,val loss : 0.384257 ,val acc : 0.825226\n",
      "[ ecpho : 5  iter :730 ]train loss : 0.443559 ,train acc: 0.832906 ,val loss : 0.388771 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :731 ]train loss : 0.331218 ,train acc: 0.856740 ,val loss : 0.382387 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :732 ]train loss : 0.319490 ,train acc: 0.856100 ,val loss : 0.386860 ,val acc : 0.822937\n",
      "[ ecpho : 5  iter :733 ]train loss : 0.485117 ,train acc: 0.760010 ,val loss : 0.390092 ,val acc : 0.824615\n",
      "[ ecpho : 5  iter :734 ]train loss : 0.263790 ,train acc: 0.876577 ,val loss : 0.384237 ,val acc : 0.827606\n",
      "[ ecpho : 5  iter :735 ]train loss : 0.359204 ,train acc: 0.838806 ,val loss : 0.388177 ,val acc : 0.820526\n",
      "[ ecpho : 5  iter :736 ]train loss : 0.268298 ,train acc: 0.864858 ,val loss : 0.385365 ,val acc : 0.827545\n",
      "[ ecpho : 5  iter :737 ]train loss : 0.348253 ,train acc: 0.817403 ,val loss : 0.384187 ,val acc : 0.826233\n",
      "[ ecpho : 5  iter :738 ]train loss : 0.288907 ,train acc: 0.865021 ,val loss : 0.390822 ,val acc : 0.825714\n",
      "[ ecpho : 5  iter :739 ]train loss : 0.256588 ,train acc: 0.874135 ,val loss : 0.384151 ,val acc : 0.823334\n",
      "[ ecpho : 5  iter :740 ]train loss : 0.283866 ,train acc: 0.866547 ,val loss : 0.384811 ,val acc : 0.824646\n",
      "[ ecpho : 5  iter :741 ]train loss : 0.307868 ,train acc: 0.846232 ,val loss : 0.385934 ,val acc : 0.826569\n",
      "[ ecpho : 5  iter :742 ]train loss : 0.258891 ,train acc: 0.876617 ,val loss : 0.383915 ,val acc : 0.827332\n",
      "[ ecpho : 5  iter :743 ]train loss : 0.434652 ,train acc: 0.801392 ,val loss : 0.383210 ,val acc : 0.824829\n",
      "[ ecpho : 5  iter :744 ]train loss : 0.255661 ,train acc: 0.875376 ,val loss : 0.385249 ,val acc : 0.825256\n",
      "[ ecpho : 5  iter :745 ]train loss : 0.249624 ,train acc: 0.880992 ,val loss : 0.384683 ,val acc : 0.826080\n",
      "[ ecpho : 5  iter :746 ]train loss : 0.371510 ,train acc: 0.820832 ,val loss : 0.386493 ,val acc : 0.823944\n",
      "[ ecpho : 5  iter :747 ]train loss : 0.261582 ,train acc: 0.873098 ,val loss : 0.382649 ,val acc : 0.826355\n",
      "[ ecpho : 5  iter :748 ]train loss : 0.290949 ,train acc: 0.860992 ,val loss : 0.383915 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :749 ]train loss : 0.292816 ,train acc: 0.861603 ,val loss : 0.384674 ,val acc : 0.824158\n",
      "[ ecpho : 5  iter :750 ]train loss : 0.374904 ,train acc: 0.824626 ,val loss : 0.378243 ,val acc : 0.829559\n",
      "[ ecpho : 5  iter :751 ]train loss : 0.414802 ,train acc: 0.831960 ,val loss : 0.384781 ,val acc : 0.825623\n",
      "[ ecpho : 5  iter :752 ]train loss : 0.287447 ,train acc: 0.862681 ,val loss : 0.388126 ,val acc : 0.824982\n",
      "[ ecpho : 5  iter :753 ]train loss : 0.397184 ,train acc: 0.801422 ,val loss : 0.382185 ,val acc : 0.824219\n",
      "[ ecpho : 5  iter :754 ]train loss : 0.313064 ,train acc: 0.841004 ,val loss : 0.388047 ,val acc : 0.826111\n",
      "[ ecpho : 5  iter :755 ]train loss : 0.354403 ,train acc: 0.850159 ,val loss : 0.382125 ,val acc : 0.828705\n",
      "[ ecpho : 5  iter :756 ]train loss : 0.418430 ,train acc: 0.749603 ,val loss : 0.385022 ,val acc : 0.826721\n",
      "[ ecpho : 5  iter :757 ]train loss : 0.335496 ,train acc: 0.825613 ,val loss : 0.388037 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :758 ]train loss : 0.271412 ,train acc: 0.868632 ,val loss : 0.379781 ,val acc : 0.827362\n",
      "[ ecpho : 5  iter :759 ]train loss : 0.250872 ,train acc: 0.875997 ,val loss : 0.389914 ,val acc : 0.825592\n",
      "[ ecpho : 5  iter :760 ]train loss : 0.334228 ,train acc: 0.855906 ,val loss : 0.383635 ,val acc : 0.827972\n",
      "[ ecpho : 5  iter :761 ]train loss : 0.288366 ,train acc: 0.859965 ,val loss : 0.378903 ,val acc : 0.831451\n",
      "[ ecpho : 5  iter :762 ]train loss : 0.293430 ,train acc: 0.868357 ,val loss : 0.391416 ,val acc : 0.822021\n",
      "[ ecpho : 5  iter :763 ]train loss : 0.331203 ,train acc: 0.858073 ,val loss : 0.382178 ,val acc : 0.827850\n",
      "[ ecpho : 5  iter :764 ]train loss : 0.263173 ,train acc: 0.873108 ,val loss : 0.388705 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :765 ]train loss : 0.254061 ,train acc: 0.879913 ,val loss : 0.382307 ,val acc : 0.827393\n",
      "[ ecpho : 5  iter :766 ]train loss : 0.253459 ,train acc: 0.876434 ,val loss : 0.386276 ,val acc : 0.827972\n",
      "[ ecpho : 5  iter :767 ]train loss : 0.330669 ,train acc: 0.858358 ,val loss : 0.384410 ,val acc : 0.827209\n",
      "[ ecpho : 5  iter :768 ]train loss : 0.300013 ,train acc: 0.861674 ,val loss : 0.388282 ,val acc : 0.824646\n",
      "[ ecpho : 5  iter :769 ]train loss : 0.273458 ,train acc: 0.858256 ,val loss : 0.384042 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :770 ]train loss : 0.290603 ,train acc: 0.856832 ,val loss : 0.379891 ,val acc : 0.826904\n",
      "[ ecpho : 5  iter :771 ]train loss : 0.275875 ,train acc: 0.870239 ,val loss : 0.382559 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :772 ]train loss : 0.347017 ,train acc: 0.841807 ,val loss : 0.387938 ,val acc : 0.822845\n",
      "[ ecpho : 5  iter :773 ]train loss : 0.244901 ,train acc: 0.880747 ,val loss : 0.387330 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :774 ]train loss : 0.328494 ,train acc: 0.845805 ,val loss : 0.386774 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :775 ]train loss : 0.301865 ,train acc: 0.853567 ,val loss : 0.383911 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :776 ]train loss : 0.260851 ,train acc: 0.872213 ,val loss : 0.385698 ,val acc : 0.828400\n",
      "[ ecpho : 5  iter :777 ]train loss : 0.265970 ,train acc: 0.871338 ,val loss : 0.387010 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :778 ]train loss : 0.241298 ,train acc: 0.884176 ,val loss : 0.383014 ,val acc : 0.828949\n",
      "[ ecpho : 5  iter :779 ]train loss : 0.434394 ,train acc: 0.746552 ,val loss : 0.386186 ,val acc : 0.826447\n",
      "[ ecpho : 5  iter :780 ]train loss : 0.321871 ,train acc: 0.841411 ,val loss : 0.387926 ,val acc : 0.823669\n",
      "[ ecpho : 5  iter :781 ]train loss : 0.377015 ,train acc: 0.841655 ,val loss : 0.383495 ,val acc : 0.825989\n",
      "[ ecpho : 5  iter :782 ]train loss : 0.270420 ,train acc: 0.875478 ,val loss : 0.383496 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :783 ]train loss : 0.373821 ,train acc: 0.840322 ,val loss : 0.381145 ,val acc : 0.827026\n",
      "[ ecpho : 5  iter :784 ]train loss : 0.364967 ,train acc: 0.824972 ,val loss : 0.387204 ,val acc : 0.826294\n",
      "[ ecpho : 5  iter :785 ]train loss : 0.332819 ,train acc: 0.846375 ,val loss : 0.387383 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :786 ]train loss : 0.316888 ,train acc: 0.841207 ,val loss : 0.384015 ,val acc : 0.827209\n",
      "[ ecpho : 5  iter :787 ]train loss : 0.282566 ,train acc: 0.868591 ,val loss : 0.382722 ,val acc : 0.830536\n",
      "[ ecpho : 5  iter :788 ]train loss : 0.290174 ,train acc: 0.862030 ,val loss : 0.382393 ,val acc : 0.823120\n",
      "[ ecpho : 5  iter :789 ]train loss : 0.281138 ,train acc: 0.869405 ,val loss : 0.382255 ,val acc : 0.827972\n",
      "[ ecpho : 5  iter :790 ]train loss : 0.244748 ,train acc: 0.881266 ,val loss : 0.382095 ,val acc : 0.828857\n",
      "[ ecpho : 5  iter :791 ]train loss : 0.304173 ,train acc: 0.860413 ,val loss : 0.386239 ,val acc : 0.823334\n",
      "[ ecpho : 5  iter :792 ]train loss : 0.290209 ,train acc: 0.870178 ,val loss : 0.383239 ,val acc : 0.826233\n",
      "[ ecpho : 5  iter :793 ]train loss : 0.249274 ,train acc: 0.880524 ,val loss : 0.385166 ,val acc : 0.824097\n",
      "[ ecpho : 5  iter :794 ]train loss : 0.305124 ,train acc: 0.829437 ,val loss : 0.385209 ,val acc : 0.829193\n",
      "[ ecpho : 5  iter :795 ]train loss : 0.247752 ,train acc: 0.880086 ,val loss : 0.381489 ,val acc : 0.827271\n",
      "[ ecpho : 5  iter :796 ]train loss : 0.358667 ,train acc: 0.840851 ,val loss : 0.382032 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :797 ]train loss : 0.321463 ,train acc: 0.841878 ,val loss : 0.385211 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :798 ]train loss : 0.267869 ,train acc: 0.872528 ,val loss : 0.387357 ,val acc : 0.824646\n",
      "[ ecpho : 5  iter :799 ]train loss : 0.247538 ,train acc: 0.886932 ,val loss : 0.384596 ,val acc : 0.827118\n",
      "[ ecpho : 5  iter :800 ]train loss : 0.401401 ,train acc: 0.794230 ,val loss : 0.391163 ,val acc : 0.826935\n",
      "[ ecpho : 5  iter :801 ]train loss : 0.294380 ,train acc: 0.865753 ,val loss : 0.382806 ,val acc : 0.828369\n",
      "[ ecpho : 5  iter :802 ]train loss : 0.257029 ,train acc: 0.878896 ,val loss : 0.391944 ,val acc : 0.824829\n",
      "[ ecpho : 5  iter :803 ]train loss : 0.393451 ,train acc: 0.786041 ,val loss : 0.384848 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :804 ]train loss : 0.268014 ,train acc: 0.870138 ,val loss : 0.387280 ,val acc : 0.822662\n",
      "[ ecpho : 5  iter :805 ]train loss : 0.286620 ,train acc: 0.869639 ,val loss : 0.389172 ,val acc : 0.823975\n",
      "[ ecpho : 5  iter :806 ]train loss : 0.285881 ,train acc: 0.862010 ,val loss : 0.384845 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :807 ]train loss : 0.322270 ,train acc: 0.828766 ,val loss : 0.387760 ,val acc : 0.828094\n",
      "[ ecpho : 5  iter :808 ]train loss : 0.267061 ,train acc: 0.870748 ,val loss : 0.387000 ,val acc : 0.825867\n",
      "[ ecpho : 5  iter :809 ]train loss : 0.254333 ,train acc: 0.875122 ,val loss : 0.381951 ,val acc : 0.827759\n",
      "[ ecpho : 5  iter :810 ]train loss : 0.298472 ,train acc: 0.861481 ,val loss : 0.384687 ,val acc : 0.825256\n",
      "[ ecpho : 5  iter :811 ]train loss : 0.249092 ,train acc: 0.879588 ,val loss : 0.379783 ,val acc : 0.825775\n",
      "[ ecpho : 5  iter :812 ]train loss : 0.302901 ,train acc: 0.857859 ,val loss : 0.377983 ,val acc : 0.828522\n",
      "[ ecpho : 5  iter :813 ]train loss : 0.396979 ,train acc: 0.834290 ,val loss : 0.385548 ,val acc : 0.825562\n",
      "[ ecpho : 5  iter :814 ]train loss : 0.332771 ,train acc: 0.852214 ,val loss : 0.380459 ,val acc : 0.825623\n",
      "[ ecpho : 5  iter :815 ]train loss : 0.279659 ,train acc: 0.873037 ,val loss : 0.386798 ,val acc : 0.823517\n",
      "[ ecpho : 5  iter :816 ]train loss : 0.467397 ,train acc: 0.826355 ,val loss : 0.384739 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :817 ]train loss : 0.393778 ,train acc: 0.809743 ,val loss : 0.388453 ,val acc : 0.825256\n",
      "[ ecpho : 5  iter :818 ]train loss : 0.276305 ,train acc: 0.869965 ,val loss : 0.386398 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :819 ]train loss : 0.282362 ,train acc: 0.864665 ,val loss : 0.383802 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :820 ]train loss : 0.330003 ,train acc: 0.858643 ,val loss : 0.384746 ,val acc : 0.826111\n",
      "[ ecpho : 5  iter :821 ]train loss : 0.320531 ,train acc: 0.853180 ,val loss : 0.386500 ,val acc : 0.825256\n",
      "[ ecpho : 5  iter :822 ]train loss : 0.288717 ,train acc: 0.867767 ,val loss : 0.383335 ,val acc : 0.827393\n",
      "[ ecpho : 5  iter :823 ]train loss : 0.291023 ,train acc: 0.868622 ,val loss : 0.387049 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :824 ]train loss : 0.352601 ,train acc: 0.846894 ,val loss : 0.385920 ,val acc : 0.825134\n",
      "[ ecpho : 5  iter :825 ]train loss : 0.266323 ,train acc: 0.869863 ,val loss : 0.382992 ,val acc : 0.828888\n",
      "[ ecpho : 5  iter :826 ]train loss : 0.273849 ,train acc: 0.870850 ,val loss : 0.387772 ,val acc : 0.827148\n",
      "[ ecpho : 5  iter :827 ]train loss : 0.279706 ,train acc: 0.868225 ,val loss : 0.383561 ,val acc : 0.824860\n",
      "[ ecpho : 5  iter :828 ]train loss : 0.319564 ,train acc: 0.855418 ,val loss : 0.384169 ,val acc : 0.827026\n",
      "[ ecpho : 5  iter :829 ]train loss : 0.361641 ,train acc: 0.848246 ,val loss : 0.383260 ,val acc : 0.828125\n",
      "[ ecpho : 5  iter :830 ]train loss : 0.327278 ,train acc: 0.860820 ,val loss : 0.384691 ,val acc : 0.826477\n",
      "[ ecpho : 5  iter :831 ]train loss : 0.280331 ,train acc: 0.870504 ,val loss : 0.387784 ,val acc : 0.828339\n",
      "[ ecpho : 5  iter :832 ]train loss : 0.263751 ,train acc: 0.875549 ,val loss : 0.381700 ,val acc : 0.827271\n",
      "[ ecpho : 5  iter :833 ]train loss : 0.417275 ,train acc: 0.841675 ,val loss : 0.378250 ,val acc : 0.828888\n",
      "[ ecpho : 5  iter :834 ]train loss : 0.257820 ,train acc: 0.878713 ,val loss : 0.387277 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :835 ]train loss : 0.304121 ,train acc: 0.835897 ,val loss : 0.387053 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :836 ]train loss : 0.300269 ,train acc: 0.859151 ,val loss : 0.387528 ,val acc : 0.825684\n",
      "[ ecpho : 5  iter :837 ]train loss : 0.280594 ,train acc: 0.867849 ,val loss : 0.382135 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :838 ]train loss : 0.283204 ,train acc: 0.863546 ,val loss : 0.380227 ,val acc : 0.827942\n",
      "[ ecpho : 5  iter :839 ]train loss : 0.271451 ,train acc: 0.868296 ,val loss : 0.390417 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :840 ]train loss : 0.253131 ,train acc: 0.882436 ,val loss : 0.379152 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :841 ]train loss : 0.323740 ,train acc: 0.857554 ,val loss : 0.385219 ,val acc : 0.826843\n",
      "[ ecpho : 5  iter :842 ]train loss : 0.668857 ,train acc: 0.805349 ,val loss : 0.384380 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :843 ]train loss : 0.251511 ,train acc: 0.880208 ,val loss : 0.387191 ,val acc : 0.821198\n",
      "[ ecpho : 5  iter :844 ]train loss : 0.231141 ,train acc: 0.886180 ,val loss : 0.390011 ,val acc : 0.823975\n",
      "[ ecpho : 5  iter :845 ]train loss : 0.289006 ,train acc: 0.849955 ,val loss : 0.382134 ,val acc : 0.829071\n",
      "[ ecpho : 5  iter :846 ]train loss : 0.238393 ,train acc: 0.885254 ,val loss : 0.383233 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :847 ]train loss : 0.344284 ,train acc: 0.841644 ,val loss : 0.382786 ,val acc : 0.826630\n",
      "[ ecpho : 5  iter :848 ]train loss : 0.335329 ,train acc: 0.849060 ,val loss : 0.388815 ,val acc : 0.824860\n",
      "[ ecpho : 5  iter :849 ]train loss : 0.279422 ,train acc: 0.867788 ,val loss : 0.386627 ,val acc : 0.827637\n",
      "[ ecpho : 5  iter :850 ]train loss : 0.309483 ,train acc: 0.859487 ,val loss : 0.386921 ,val acc : 0.822510\n",
      "[ ecpho : 5  iter :851 ]train loss : 0.369632 ,train acc: 0.790670 ,val loss : 0.385756 ,val acc : 0.824371\n",
      "[ ecpho : 5  iter :852 ]train loss : 0.249440 ,train acc: 0.880351 ,val loss : 0.383677 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :853 ]train loss : 0.271219 ,train acc: 0.869151 ,val loss : 0.387295 ,val acc : 0.827118\n",
      "[ ecpho : 5  iter :854 ]train loss : 0.284236 ,train acc: 0.863424 ,val loss : 0.384658 ,val acc : 0.827057\n",
      "[ ecpho : 5  iter :855 ]train loss : 0.315874 ,train acc: 0.839529 ,val loss : 0.381988 ,val acc : 0.827576\n",
      "[ ecpho : 5  iter :856 ]train loss : 0.401745 ,train acc: 0.832621 ,val loss : 0.383717 ,val acc : 0.826294\n",
      "[ ecpho : 5  iter :857 ]train loss : 0.259641 ,train acc: 0.874359 ,val loss : 0.384039 ,val acc : 0.825470\n",
      "[ ecpho : 5  iter :858 ]train loss : 0.409357 ,train acc: 0.784994 ,val loss : 0.385065 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :859 ]train loss : 0.313210 ,train acc: 0.845368 ,val loss : 0.385964 ,val acc : 0.825409\n",
      "[ ecpho : 5  iter :860 ]train loss : 0.303831 ,train acc: 0.856669 ,val loss : 0.382786 ,val acc : 0.827606\n",
      "[ ecpho : 5  iter :861 ]train loss : 0.256187 ,train acc: 0.878265 ,val loss : 0.386819 ,val acc : 0.828613\n",
      "[ ecpho : 5  iter :862 ]train loss : 0.364678 ,train acc: 0.808065 ,val loss : 0.389259 ,val acc : 0.822723\n",
      "[ ecpho : 5  iter :863 ]train loss : 0.310432 ,train acc: 0.860352 ,val loss : 0.381985 ,val acc : 0.824921\n",
      "[ ecpho : 5  iter :864 ]train loss : 0.307477 ,train acc: 0.857198 ,val loss : 0.389995 ,val acc : 0.827484\n",
      "[ ecpho : 5  iter :865 ]train loss : 0.267773 ,train acc: 0.868693 ,val loss : 0.384464 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :866 ]train loss : 0.301353 ,train acc: 0.858704 ,val loss : 0.382645 ,val acc : 0.828766\n",
      "[ ecpho : 5  iter :867 ]train loss : 0.258555 ,train acc: 0.880503 ,val loss : 0.385109 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :868 ]train loss : 0.248027 ,train acc: 0.881887 ,val loss : 0.385822 ,val acc : 0.824860\n",
      "[ ecpho : 5  iter :869 ]train loss : 0.322861 ,train acc: 0.861583 ,val loss : 0.388010 ,val acc : 0.826813\n",
      "[ ecpho : 5  iter :870 ]train loss : 0.488882 ,train acc: 0.819214 ,val loss : 0.381736 ,val acc : 0.829041\n",
      "[ ecpho : 5  iter :871 ]train loss : 0.318133 ,train acc: 0.841899 ,val loss : 0.383276 ,val acc : 0.826385\n",
      "[ ecpho : 5  iter :872 ]train loss : 0.319653 ,train acc: 0.839437 ,val loss : 0.385950 ,val acc : 0.827087\n",
      "[ ecpho : 5  iter :873 ]train loss : 0.273692 ,train acc: 0.874135 ,val loss : 0.383110 ,val acc : 0.823639\n",
      "[ ecpho : 5  iter :874 ]train loss : 0.314578 ,train acc: 0.849243 ,val loss : 0.383606 ,val acc : 0.829224\n",
      "[ ecpho : 5  iter :875 ]train loss : 0.381980 ,train acc: 0.843567 ,val loss : 0.388556 ,val acc : 0.824066\n",
      "[ ecpho : 5  iter :876 ]train loss : 0.410206 ,train acc: 0.845205 ,val loss : 0.386673 ,val acc : 0.826935\n",
      "[ ecpho : 5  iter :877 ]train loss : 0.320765 ,train acc: 0.858938 ,val loss : 0.381814 ,val acc : 0.828339\n",
      "[ ecpho : 5  iter :878 ]train loss : 0.298232 ,train acc: 0.866974 ,val loss : 0.388420 ,val acc : 0.827881\n",
      "[ ecpho : 5  iter :879 ]train loss : 0.301336 ,train acc: 0.840485 ,val loss : 0.386192 ,val acc : 0.823517\n",
      "[ ecpho : 5  iter :880 ]train loss : 0.362997 ,train acc: 0.819509 ,val loss : 0.388685 ,val acc : 0.827576\n",
      "[ ecpho : 5  iter :881 ]train loss : 0.323276 ,train acc: 0.857422 ,val loss : 0.383939 ,val acc : 0.828217\n",
      "[ ecpho : 5  iter :882 ]train loss : 0.297617 ,train acc: 0.857666 ,val loss : 0.383593 ,val acc : 0.826294\n",
      "[ ecpho : 5  iter :883 ]train loss : 0.421472 ,train acc: 0.822642 ,val loss : 0.384423 ,val acc : 0.827057\n",
      "[ ecpho : 5  iter :884 ]train loss : 0.350193 ,train acc: 0.845174 ,val loss : 0.389943 ,val acc : 0.824341\n",
      "[ ecpho : 5  iter :885 ]train loss : 0.303394 ,train acc: 0.854492 ,val loss : 0.382622 ,val acc : 0.830231\n",
      "[ ecpho : 5  iter :886 ]train loss : 0.274828 ,train acc: 0.865316 ,val loss : 0.382614 ,val acc : 0.825195\n",
      "[ ecpho : 5  iter :887 ]train loss : 0.297606 ,train acc: 0.867045 ,val loss : 0.389690 ,val acc : 0.824463\n",
      "[ ecpho : 5  iter :888 ]train loss : 0.425305 ,train acc: 0.809204 ,val loss : 0.386721 ,val acc : 0.828064\n",
      "[ ecpho : 5  iter :889 ]train loss : 0.347827 ,train acc: 0.852122 ,val loss : 0.385327 ,val acc : 0.826202\n",
      "[ ecpho : 5  iter :890 ]train loss : 0.286404 ,train acc: 0.865458 ,val loss : 0.387373 ,val acc : 0.823425\n",
      "[ ecpho : 5  iter :891 ]train loss : 0.320176 ,train acc: 0.852529 ,val loss : 0.389947 ,val acc : 0.827240\n",
      "[ ecpho : 5  iter :892 ]train loss : 0.281993 ,train acc: 0.867991 ,val loss : 0.388451 ,val acc : 0.826416\n",
      "[ ecpho : 5  iter :893 ]train loss : 0.250921 ,train acc: 0.878794 ,val loss : 0.385518 ,val acc : 0.826843\n",
      "[ ecpho : 5  iter :894 ]train loss : 0.278726 ,train acc: 0.865825 ,val loss : 0.385203 ,val acc : 0.827087\n",
      "[ ecpho : 5  iter :895 ]train loss : 0.335608 ,train acc: 0.835297 ,val loss : 0.379936 ,val acc : 0.828186\n",
      "[ ecpho : 5  iter :896 ]train loss : 0.318040 ,train acc: 0.861359 ,val loss : 0.385775 ,val acc : 0.825348\n",
      "[ ecpho : 5  iter :897 ]train loss : 0.340942 ,train acc: 0.850800 ,val loss : 0.387077 ,val acc : 0.825439\n",
      "[ ecpho : 5  iter :898 ]train loss : 0.317072 ,train acc: 0.857524 ,val loss : 0.376933 ,val acc : 0.829071\n",
      "[ ecpho : 5  iter :899 ]train loss : 0.430419 ,train acc: 0.777588 ,val loss : 0.390075 ,val acc : 0.826569\n",
      "[ ecpho : 5  iter :900 ]train loss : 0.318998 ,train acc: 0.854147 ,val loss : 0.384312 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :901 ]train loss : 0.347410 ,train acc: 0.850098 ,val loss : 0.384155 ,val acc : 0.827637\n",
      "[ ecpho : 5  iter :902 ]train loss : 0.313587 ,train acc: 0.859813 ,val loss : 0.391751 ,val acc : 0.824890\n",
      "[ ecpho : 5  iter :903 ]train loss : 0.315492 ,train acc: 0.853536 ,val loss : 0.383908 ,val acc : 0.825470\n",
      "[ ecpho : 5  iter :904 ]train loss : 0.289065 ,train acc: 0.863210 ,val loss : 0.387438 ,val acc : 0.825806\n",
      "[ ecpho : 5  iter :905 ]train loss : 0.445625 ,train acc: 0.787069 ,val loss : 0.380678 ,val acc : 0.827698\n",
      "[ ecpho : 5  iter :906 ]train loss : 0.417223 ,train acc: 0.795207 ,val loss : 0.385532 ,val acc : 0.827606\n",
      "[ ecpho : 5  iter :907 ]train loss : 0.305636 ,train acc: 0.863668 ,val loss : 0.383511 ,val acc : 0.827240\n",
      "[ ecpho : 5  iter :908 ]train loss : 0.250914 ,train acc: 0.878733 ,val loss : 0.387331 ,val acc : 0.827698\n",
      "[ ecpho : 5  iter :909 ]train loss : 0.268226 ,train acc: 0.867157 ,val loss : 0.383380 ,val acc : 0.826355\n",
      "[ ecpho : 5  iter :910 ]train loss : 0.277028 ,train acc: 0.871775 ,val loss : 0.389309 ,val acc : 0.824249\n",
      "[ ecpho : 5  iter :911 ]train loss : 0.284648 ,train acc: 0.855357 ,val loss : 0.382318 ,val acc : 0.825714\n",
      "[ ecpho : 5  iter :912 ]train loss : 0.317986 ,train acc: 0.853068 ,val loss : 0.389497 ,val acc : 0.825104\n",
      "[ ecpho : 5  iter :913 ]train loss : 0.319778 ,train acc: 0.852600 ,val loss : 0.388412 ,val acc : 0.823212\n",
      "[ ecpho : 5  iter :914 ]train loss : 0.289215 ,train acc: 0.870504 ,val loss : 0.383176 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :915 ]train loss : 0.258530 ,train acc: 0.875549 ,val loss : 0.385219 ,val acc : 0.825378\n",
      "[ ecpho : 5  iter :916 ]train loss : 0.246790 ,train acc: 0.878367 ,val loss : 0.383662 ,val acc : 0.827423\n",
      "[ ecpho : 5  iter :917 ]train loss : 0.398364 ,train acc: 0.820333 ,val loss : 0.377490 ,val acc : 0.830017\n",
      "[ ecpho : 5  iter :918 ]train loss : 0.410790 ,train acc: 0.844065 ,val loss : 0.384647 ,val acc : 0.826233\n",
      "[ ecpho : 5  iter :919 ]train loss : 0.342183 ,train acc: 0.816325 ,val loss : 0.380872 ,val acc : 0.828888\n",
      "[ ecpho : 5  iter :920 ]train loss : 0.574658 ,train acc: 0.801249 ,val loss : 0.379068 ,val acc : 0.828735\n",
      "[ ecpho : 5  iter :921 ]train loss : 0.289520 ,train acc: 0.855804 ,val loss : 0.376270 ,val acc : 0.830627\n",
      "[ ecpho : 5  iter :922 ]train loss : 0.386935 ,train acc: 0.835836 ,val loss : 0.380562 ,val acc : 0.828308\n",
      "[ ecpho : 5  iter :923 ]train loss : 0.333779 ,train acc: 0.852559 ,val loss : 0.386341 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :924 ]train loss : 0.375065 ,train acc: 0.777649 ,val loss : 0.388024 ,val acc : 0.826141\n",
      "[ ecpho : 5  iter :925 ]train loss : 0.261787 ,train acc: 0.871318 ,val loss : 0.388247 ,val acc : 0.826294\n",
      "[ ecpho : 5  iter :926 ]train loss : 0.327321 ,train acc: 0.856954 ,val loss : 0.383881 ,val acc : 0.829163\n",
      "[ ecpho : 5  iter :927 ]train loss : 0.273244 ,train acc: 0.869293 ,val loss : 0.385449 ,val acc : 0.827148\n",
      "[ ecpho : 5  iter :928 ]train loss : 0.298604 ,train acc: 0.864309 ,val loss : 0.383674 ,val acc : 0.826508\n",
      "[ ecpho : 5  iter :929 ]train loss : 0.368435 ,train acc: 0.853404 ,val loss : 0.378978 ,val acc : 0.825653\n",
      "[ ecpho : 5  iter :930 ]train loss : 0.278787 ,train acc: 0.851766 ,val loss : 0.384034 ,val acc : 0.827972\n",
      "[ ecpho : 5  iter :931 ]train loss : 0.371973 ,train acc: 0.832296 ,val loss : 0.388196 ,val acc : 0.825836\n",
      "[ ecpho : 5  iter :932 ]train loss : 0.260216 ,train acc: 0.877340 ,val loss : 0.387418 ,val acc : 0.826324\n",
      "[ ecpho : 5  iter :933 ]train loss : 0.241531 ,train acc: 0.884145 ,val loss : 0.386129 ,val acc : 0.828430\n",
      "[ ecpho : 5  iter :934 ]train loss : 0.358596 ,train acc: 0.844371 ,val loss : 0.384881 ,val acc : 0.825500\n",
      "[ ecpho : 5  iter :935 ]train loss : 0.232915 ,train acc: 0.890635 ,val loss : 0.382345 ,val acc : 0.826996\n",
      "[ ecpho : 5  iter :936 ]train loss : 0.366450 ,train acc: 0.822123 ,val loss : 0.386028 ,val acc : 0.824463\n",
      "[ ecpho : 5  iter :937 ]train loss : 0.247503 ,train acc: 0.878947 ,val loss : 0.382909 ,val acc : 0.828766\n",
      "[ ecpho : 5  iter :938 ]train loss : 0.388660 ,train acc: 0.791911 ,val loss : 0.380734 ,val acc : 0.830322\n",
      "[ ecpho : 5  iter :939 ]train loss : 0.237652 ,train acc: 0.887767 ,val loss : 0.381795 ,val acc : 0.826996\n",
      "[ ecpho : 5  iter :940 ]train loss : 0.321087 ,train acc: 0.858093 ,val loss : 0.386460 ,val acc : 0.826050\n",
      "[ ecpho : 5  iter :941 ]train loss : 0.248316 ,train acc: 0.882365 ,val loss : 0.393647 ,val acc : 0.824127\n",
      "[ ecpho : 5  iter :942 ]train loss : 0.273541 ,train acc: 0.874207 ,val loss : 0.380716 ,val acc : 0.828796\n",
      "[ ecpho : 5  iter :943 ]train loss : 0.274142 ,train acc: 0.868357 ,val loss : 0.381288 ,val acc : 0.830811\n",
      "[ ecpho : 5  iter :944 ]train loss : 0.444587 ,train acc: 0.815572 ,val loss : 0.381439 ,val acc : 0.825256\n",
      "[ ecpho : 5  iter :945 ]train loss : 0.433853 ,train acc: 0.797424 ,val loss : 0.387592 ,val acc : 0.827881\n",
      "[ ecpho : 5  iter :946 ]train loss : 0.259523 ,train acc: 0.873962 ,val loss : 0.386678 ,val acc : 0.825928\n",
      "[ ecpho : 5  iter :947 ]train loss : 0.266200 ,train acc: 0.877248 ,val loss : 0.380917 ,val acc : 0.829742\n",
      "[ ecpho : 5  iter :948 ]train loss : 0.407600 ,train acc: 0.794739 ,val loss : 0.384650 ,val acc : 0.823303\n",
      "[ ecpho : 5  iter :949 ]train loss : 0.246075 ,train acc: 0.881276 ,val loss : 0.381026 ,val acc : 0.825317\n",
      "[ ecpho : 5  iter :950 ]train loss : 0.259775 ,train acc: 0.878632 ,val loss : 0.384091 ,val acc : 0.822174\n",
      "[ ecpho : 5  iter :951 ]train loss : 0.347412 ,train acc: 0.835470 ,val loss : 0.380161 ,val acc : 0.829468\n",
      "[ ecpho : 5  iter :952 ]train loss : 0.339503 ,train acc: 0.845764 ,val loss : 0.380975 ,val acc : 0.828217\n",
      "[ ecpho : 5  iter :953 ]train loss : 0.357586 ,train acc: 0.846761 ,val loss : 0.384041 ,val acc : 0.823303\n",
      "[ ecpho : 5  iter :954 ]train loss : 0.352493 ,train acc: 0.854350 ,val loss : 0.381739 ,val acc : 0.828369\n",
      "[ ecpho : 5  iter :955 ]train loss : 0.339845 ,train acc: 0.816366 ,val loss : 0.388473 ,val acc : 0.826660\n",
      "[ ecpho : 5  iter :956 ]train loss : 0.307216 ,train acc: 0.858002 ,val loss : 0.390249 ,val acc : 0.823029\n",
      "[ ecpho : 5  iter :957 ]train loss : 0.281179 ,train acc: 0.867594 ,val loss : 0.384657 ,val acc : 0.828552\n",
      "[ ecpho : 5  iter :958 ]train loss : 0.392491 ,train acc: 0.798269 ,val loss : 0.384918 ,val acc : 0.825531\n",
      "[ ecpho : 5  iter :959 ]train loss : 0.263384 ,train acc: 0.875641 ,val loss : 0.384423 ,val acc : 0.824585\n",
      "[ ecpho : 5  iter :960 ]train loss : 0.249731 ,train acc: 0.877055 ,val loss : 0.386578 ,val acc : 0.823822\n",
      "[ ecpho : 5  iter :961 ]train loss : 0.303642 ,train acc: 0.866079 ,val loss : 0.385058 ,val acc : 0.829346\n",
      "[ ecpho : 5  iter :962 ]train loss : 0.349639 ,train acc: 0.852265 ,val loss : 0.381404 ,val acc : 0.827759\n",
      "[ ecpho : 5  iter :963 ]train loss : 0.299664 ,train acc: 0.864522 ,val loss : 0.387152 ,val acc : 0.826111\n",
      "[ ecpho : 5  iter :964 ]train loss : 0.346984 ,train acc: 0.854086 ,val loss : 0.384014 ,val acc : 0.821991\n",
      "[ ecpho : 5  iter :965 ]train loss : 0.329547 ,train acc: 0.856435 ,val loss : 0.385118 ,val acc : 0.824646\n",
      "[ ecpho : 5  iter :966 ]train loss : 0.369827 ,train acc: 0.847178 ,val loss : 0.380228 ,val acc : 0.828186\n",
      "[ ecpho : 5  iter :967 ]train loss : 0.277272 ,train acc: 0.866404 ,val loss : 0.381125 ,val acc : 0.827942\n",
      "[ ecpho : 5  iter :968 ]train loss : 0.372592 ,train acc: 0.826101 ,val loss : 0.383631 ,val acc : 0.824005\n",
      "[ ecpho : 5  iter :969 ]train loss : 0.379038 ,train acc: 0.846090 ,val loss : 0.380451 ,val acc : 0.827240\n",
      "[ ecpho : 5  iter :970 ]train loss : 0.245935 ,train acc: 0.879384 ,val loss : 0.388387 ,val acc : 0.823303\n",
      "[ ecpho : 5  iter :971 ]train loss : 0.270069 ,train acc: 0.867289 ,val loss : 0.387022 ,val acc : 0.825043\n",
      "[ ecpho : 5  iter :972 ]train loss : 0.380138 ,train acc: 0.840871 ,val loss : 0.384817 ,val acc : 0.826385\n",
      "[ ecpho : 5  iter :973 ]train loss : 0.251814 ,train acc: 0.878662 ,val loss : 0.378794 ,val acc : 0.826416\n",
      "[ ecpho : 5  iter :974 ]train loss : 0.363465 ,train acc: 0.834127 ,val loss : 0.383048 ,val acc : 0.825287\n",
      "[ ecpho : 5  iter :975 ]train loss : 0.261985 ,train acc: 0.879598 ,val loss : 0.387760 ,val acc : 0.825684\n",
      "[ ecpho : 5  iter :976 ]train loss : 0.308009 ,train acc: 0.856608 ,val loss : 0.385578 ,val acc : 0.823761\n",
      "[ ecpho : 5  iter :977 ]train loss : 0.297866 ,train acc: 0.848938 ,val loss : 0.388268 ,val acc : 0.826691\n",
      "[ ecpho : 5  iter :978 ]train loss : 0.275036 ,train acc: 0.866638 ,val loss : 0.383026 ,val acc : 0.827728\n",
      "[ ecpho : 5  iter :979 ]train loss : 0.256372 ,train acc: 0.876414 ,val loss : 0.387089 ,val acc : 0.826569\n",
      "[ ecpho : 5  iter :980 ]train loss : 0.257233 ,train acc: 0.875549 ,val loss : 0.386709 ,val acc : 0.825409\n",
      "[ ecpho : 5  iter :981 ]train loss : 0.342277 ,train acc: 0.854726 ,val loss : 0.379729 ,val acc : 0.827972\n",
      "[ ecpho : 5  iter :982 ]train loss : 0.430150 ,train acc: 0.799327 ,val loss : 0.386929 ,val acc : 0.826172\n",
      "[ ecpho : 5  iter :983 ]train loss : 0.283482 ,train acc: 0.868388 ,val loss : 0.383912 ,val acc : 0.828125\n",
      "[ ecpho : 5  iter :984 ]train loss : 0.319099 ,train acc: 0.854187 ,val loss : 0.385335 ,val acc : 0.828766\n",
      "[ ecpho : 5  iter :985 ]train loss : 0.286272 ,train acc: 0.864675 ,val loss : 0.383486 ,val acc : 0.826843\n",
      "[ ecpho : 5  iter :986 ]train loss : 0.251369 ,train acc: 0.878611 ,val loss : 0.388728 ,val acc : 0.826019\n",
      "[ ecpho : 5  iter :987 ]train loss : 0.280721 ,train acc: 0.871979 ,val loss : 0.384263 ,val acc : 0.828400\n",
      "[ ecpho : 5  iter :988 ]train loss : 0.282294 ,train acc: 0.874237 ,val loss : 0.382768 ,val acc : 0.826569\n",
      "[ ecpho : 5  iter :989 ]train loss : 0.414318 ,train acc: 0.799958 ,val loss : 0.385762 ,val acc : 0.827667\n",
      "[ ecpho : 5  iter :990 ]train loss : 0.309995 ,train acc: 0.860677 ,val loss : 0.383253 ,val acc : 0.824951\n",
      "[ ecpho : 5  iter :991 ]train loss : 0.331528 ,train acc: 0.864451 ,val loss : 0.388417 ,val acc : 0.824219\n",
      "[ ecpho : 5  iter :992 ]train loss : 0.297202 ,train acc: 0.862172 ,val loss : 0.385198 ,val acc : 0.824768\n",
      "[ ecpho : 5  iter :993 ]train loss : 0.375716 ,train acc: 0.833069 ,val loss : 0.390515 ,val acc : 0.824188\n",
      "[ ecpho : 5  iter :994 ]train loss : 0.363285 ,train acc: 0.844940 ,val loss : 0.379567 ,val acc : 0.825165\n",
      "[ ecpho : 5  iter :995 ]train loss : 0.259585 ,train acc: 0.873830 ,val loss : 0.380130 ,val acc : 0.828888\n",
      "[ ecpho : 5  iter :996 ]train loss : 0.290502 ,train acc: 0.861054 ,val loss : 0.384026 ,val acc : 0.828979\n",
      "[ ecpho : 5  iter :997 ]train loss : 0.411728 ,train acc: 0.771179 ,val loss : 0.383524 ,val acc : 0.825684\n",
      "[ ecpho : 5  iter :998 ]train loss : 0.342913 ,train acc: 0.848674 ,val loss : 0.390055 ,val acc : 0.826874\n",
      "[ ecpho : 5  iter :999 ]train loss : 0.251033 ,train acc: 0.878133 ,val loss : 0.379919 ,val acc : 0.827301\n",
      "[ ecpho : 5  iter :1000 ]train loss : 0.304541 ,train acc: 0.860932 ,val loss : 0.383727 ,val acc : 0.825409\n",
      "=============================================\n",
      "[ 5 ] average train loss : 0.315547 train acc : 0.852664\n",
      "[ ecpho : 6  iter :1 ]train loss : 0.228491 ,train acc: 0.893168 ,val loss : 0.386129 ,val acc : 0.827698\n",
      "[ ecpho : 6  iter :2 ]train loss : 0.353056 ,train acc: 0.839000 ,val loss : 0.389450 ,val acc : 0.825684\n",
      "[ ecpho : 6  iter :3 ]train loss : 0.284737 ,train acc: 0.870463 ,val loss : 0.385938 ,val acc : 0.828003\n",
      "[ ecpho : 6  iter :4 ]train loss : 0.442399 ,train acc: 0.800649 ,val loss : 0.388182 ,val acc : 0.824493\n",
      "[ ecpho : 6  iter :5 ]train loss : 0.284454 ,train acc: 0.865591 ,val loss : 0.385542 ,val acc : 0.823730\n",
      "[ ecpho : 6  iter :6 ]train loss : 0.372058 ,train acc: 0.837158 ,val loss : 0.386170 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :7 ]train loss : 0.288406 ,train acc: 0.867727 ,val loss : 0.385097 ,val acc : 0.828796\n",
      "[ ecpho : 6  iter :8 ]train loss : 0.346030 ,train acc: 0.853750 ,val loss : 0.383764 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :9 ]train loss : 0.387171 ,train acc: 0.846263 ,val loss : 0.386791 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :10 ]train loss : 0.378992 ,train acc: 0.844371 ,val loss : 0.387673 ,val acc : 0.825439\n",
      "[ ecpho : 6  iter :11 ]train loss : 0.383090 ,train acc: 0.809703 ,val loss : 0.381616 ,val acc : 0.825470\n",
      "[ ecpho : 6  iter :12 ]train loss : 0.263948 ,train acc: 0.874308 ,val loss : 0.382928 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :13 ]train loss : 0.317002 ,train acc: 0.857483 ,val loss : 0.380910 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :14 ]train loss : 0.263725 ,train acc: 0.866893 ,val loss : 0.383416 ,val acc : 0.826080\n",
      "[ ecpho : 6  iter :15 ]train loss : 0.478478 ,train acc: 0.811869 ,val loss : 0.384224 ,val acc : 0.828522\n",
      "[ ecpho : 6  iter :16 ]train loss : 0.270424 ,train acc: 0.869537 ,val loss : 0.390446 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :17 ]train loss : 0.351564 ,train acc: 0.856069 ,val loss : 0.388481 ,val acc : 0.823364\n",
      "[ ecpho : 6  iter :18 ]train loss : 0.290357 ,train acc: 0.866445 ,val loss : 0.383326 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :19 ]train loss : 0.290580 ,train acc: 0.844544 ,val loss : 0.381227 ,val acc : 0.829010\n",
      "[ ecpho : 6  iter :20 ]train loss : 0.326471 ,train acc: 0.855510 ,val loss : 0.384065 ,val acc : 0.823517\n",
      "[ ecpho : 6  iter :21 ]train loss : 0.284348 ,train acc: 0.864512 ,val loss : 0.385662 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :22 ]train loss : 0.309375 ,train acc: 0.865672 ,val loss : 0.386277 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :23 ]train loss : 0.249358 ,train acc: 0.877452 ,val loss : 0.383078 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :24 ]train loss : 0.268355 ,train acc: 0.869893 ,val loss : 0.381850 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :25 ]train loss : 0.263424 ,train acc: 0.877269 ,val loss : 0.382266 ,val acc : 0.828705\n",
      "[ ecpho : 6  iter :26 ]train loss : 0.254971 ,train acc: 0.878123 ,val loss : 0.383353 ,val acc : 0.823181\n",
      "[ ecpho : 6  iter :27 ]train loss : 0.318196 ,train acc: 0.849314 ,val loss : 0.389043 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :28 ]train loss : 0.284232 ,train acc: 0.862803 ,val loss : 0.386537 ,val acc : 0.824615\n",
      "[ ecpho : 6  iter :29 ]train loss : 0.270229 ,train acc: 0.867829 ,val loss : 0.383288 ,val acc : 0.822876\n",
      "[ ecpho : 6  iter :30 ]train loss : 0.382190 ,train acc: 0.850240 ,val loss : 0.385669 ,val acc : 0.827148\n",
      "[ ecpho : 6  iter :31 ]train loss : 0.432415 ,train acc: 0.796234 ,val loss : 0.380492 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :32 ]train loss : 0.328420 ,train acc: 0.863393 ,val loss : 0.383769 ,val acc : 0.826599\n",
      "[ ecpho : 6  iter :33 ]train loss : 0.267412 ,train acc: 0.879028 ,val loss : 0.383479 ,val acc : 0.827667\n",
      "[ ecpho : 6  iter :34 ]train loss : 0.346830 ,train acc: 0.845113 ,val loss : 0.388222 ,val acc : 0.827698\n",
      "[ ecpho : 6  iter :35 ]train loss : 0.336182 ,train acc: 0.857300 ,val loss : 0.382003 ,val acc : 0.827484\n",
      "[ ecpho : 6  iter :36 ]train loss : 0.308122 ,train acc: 0.861003 ,val loss : 0.383238 ,val acc : 0.824768\n",
      "[ ecpho : 6  iter :37 ]train loss : 0.327316 ,train acc: 0.851725 ,val loss : 0.387307 ,val acc : 0.825897\n",
      "[ ecpho : 6  iter :38 ]train loss : 0.247037 ,train acc: 0.881083 ,val loss : 0.385604 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :39 ]train loss : 0.297953 ,train acc: 0.855855 ,val loss : 0.382705 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :40 ]train loss : 0.383553 ,train acc: 0.826355 ,val loss : 0.382382 ,val acc : 0.829956\n",
      "[ ecpho : 6  iter :41 ]train loss : 0.418182 ,train acc: 0.797374 ,val loss : 0.389913 ,val acc : 0.825043\n",
      "[ ecpho : 6  iter :42 ]train loss : 0.275093 ,train acc: 0.864197 ,val loss : 0.381923 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :43 ]train loss : 0.313505 ,train acc: 0.858419 ,val loss : 0.385252 ,val acc : 0.825623\n",
      "[ ecpho : 6  iter :44 ]train loss : 0.268516 ,train acc: 0.871033 ,val loss : 0.385263 ,val acc : 0.824219\n",
      "[ ecpho : 6  iter :45 ]train loss : 0.314558 ,train acc: 0.856720 ,val loss : 0.386136 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :46 ]train loss : 0.294996 ,train acc: 0.862000 ,val loss : 0.384317 ,val acc : 0.824280\n",
      "[ ecpho : 6  iter :47 ]train loss : 0.280394 ,train acc: 0.869873 ,val loss : 0.383981 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :48 ]train loss : 0.250574 ,train acc: 0.885803 ,val loss : 0.380577 ,val acc : 0.824463\n",
      "[ ecpho : 6  iter :49 ]train loss : 0.330362 ,train acc: 0.856252 ,val loss : 0.389074 ,val acc : 0.824097\n",
      "[ ecpho : 6  iter :50 ]train loss : 0.305082 ,train acc: 0.861043 ,val loss : 0.387348 ,val acc : 0.827728\n",
      "[ ecpho : 6  iter :51 ]train loss : 0.351753 ,train acc: 0.851603 ,val loss : 0.384397 ,val acc : 0.824554\n",
      "[ ecpho : 6  iter :52 ]train loss : 0.309280 ,train acc: 0.857921 ,val loss : 0.387368 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :53 ]train loss : 0.321584 ,train acc: 0.841706 ,val loss : 0.382084 ,val acc : 0.830902\n",
      "[ ecpho : 6  iter :54 ]train loss : 0.280202 ,train acc: 0.868398 ,val loss : 0.384815 ,val acc : 0.826111\n",
      "[ ecpho : 6  iter :55 ]train loss : 0.312835 ,train acc: 0.859294 ,val loss : 0.384002 ,val acc : 0.827850\n",
      "[ ecpho : 6  iter :56 ]train loss : 0.352757 ,train acc: 0.853445 ,val loss : 0.383240 ,val acc : 0.828552\n",
      "[ ecpho : 6  iter :57 ]train loss : 0.360981 ,train acc: 0.842662 ,val loss : 0.383389 ,val acc : 0.824860\n",
      "[ ecpho : 6  iter :58 ]train loss : 0.293378 ,train acc: 0.868490 ,val loss : 0.381942 ,val acc : 0.825623\n",
      "[ ecpho : 6  iter :59 ]train loss : 0.314992 ,train acc: 0.859436 ,val loss : 0.385773 ,val acc : 0.826172\n",
      "[ ecpho : 6  iter :60 ]train loss : 0.381749 ,train acc: 0.824575 ,val loss : 0.387968 ,val acc : 0.824341\n",
      "[ ecpho : 6  iter :61 ]train loss : 0.326231 ,train acc: 0.856344 ,val loss : 0.384799 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :62 ]train loss : 0.400122 ,train acc: 0.802552 ,val loss : 0.383474 ,val acc : 0.829620\n",
      "[ ecpho : 6  iter :63 ]train loss : 0.306478 ,train acc: 0.865651 ,val loss : 0.384443 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :64 ]train loss : 0.249649 ,train acc: 0.880015 ,val loss : 0.385363 ,val acc : 0.823517\n",
      "[ ecpho : 6  iter :65 ]train loss : 0.391197 ,train acc: 0.832815 ,val loss : 0.380941 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :66 ]train loss : 0.265892 ,train acc: 0.874023 ,val loss : 0.380055 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :67 ]train loss : 0.311682 ,train acc: 0.857208 ,val loss : 0.382023 ,val acc : 0.824585\n",
      "[ ecpho : 6  iter :68 ]train loss : 0.289166 ,train acc: 0.862386 ,val loss : 0.379810 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :69 ]train loss : 0.306099 ,train acc: 0.860514 ,val loss : 0.382773 ,val acc : 0.827667\n",
      "[ ecpho : 6  iter :70 ]train loss : 0.277121 ,train acc: 0.869090 ,val loss : 0.389132 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :71 ]train loss : 0.350031 ,train acc: 0.850963 ,val loss : 0.381437 ,val acc : 0.827026\n",
      "[ ecpho : 6  iter :72 ]train loss : 0.318830 ,train acc: 0.862457 ,val loss : 0.384570 ,val acc : 0.824432\n",
      "[ ecpho : 6  iter :73 ]train loss : 0.366585 ,train acc: 0.833059 ,val loss : 0.381918 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :74 ]train loss : 0.348375 ,train acc: 0.846548 ,val loss : 0.389629 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :75 ]train loss : 0.356373 ,train acc: 0.835399 ,val loss : 0.383821 ,val acc : 0.824249\n",
      "[ ecpho : 6  iter :76 ]train loss : 0.346049 ,train acc: 0.857707 ,val loss : 0.379418 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :77 ]train loss : 0.332229 ,train acc: 0.834595 ,val loss : 0.377709 ,val acc : 0.828552\n",
      "[ ecpho : 6  iter :78 ]train loss : 0.267905 ,train acc: 0.869965 ,val loss : 0.382835 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :79 ]train loss : 0.331174 ,train acc: 0.831991 ,val loss : 0.385062 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :80 ]train loss : 0.275263 ,train acc: 0.870829 ,val loss : 0.388913 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :81 ]train loss : 0.309082 ,train acc: 0.850413 ,val loss : 0.382855 ,val acc : 0.828186\n",
      "[ ecpho : 6  iter :82 ]train loss : 0.288909 ,train acc: 0.867086 ,val loss : 0.381567 ,val acc : 0.829407\n",
      "[ ecpho : 6  iter :83 ]train loss : 0.262985 ,train acc: 0.872447 ,val loss : 0.382737 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :84 ]train loss : 0.280671 ,train acc: 0.874685 ,val loss : 0.383931 ,val acc : 0.826141\n",
      "[ ecpho : 6  iter :85 ]train loss : 0.268302 ,train acc: 0.861176 ,val loss : 0.387068 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :86 ]train loss : 0.306801 ,train acc: 0.863983 ,val loss : 0.381838 ,val acc : 0.830688\n",
      "[ ecpho : 6  iter :87 ]train loss : 0.310565 ,train acc: 0.851837 ,val loss : 0.385246 ,val acc : 0.826141\n",
      "[ ecpho : 6  iter :88 ]train loss : 0.361352 ,train acc: 0.852305 ,val loss : 0.383054 ,val acc : 0.825073\n",
      "[ ecpho : 6  iter :89 ]train loss : 0.258136 ,train acc: 0.878510 ,val loss : 0.382609 ,val acc : 0.826691\n",
      "[ ecpho : 6  iter :90 ]train loss : 0.282072 ,train acc: 0.867360 ,val loss : 0.385322 ,val acc : 0.823517\n",
      "[ ecpho : 6  iter :91 ]train loss : 0.293626 ,train acc: 0.859151 ,val loss : 0.385865 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :92 ]train loss : 0.379311 ,train acc: 0.819438 ,val loss : 0.385274 ,val acc : 0.825623\n",
      "[ ecpho : 6  iter :93 ]train loss : 0.275119 ,train acc: 0.867615 ,val loss : 0.386495 ,val acc : 0.823242\n",
      "[ ecpho : 6  iter :94 ]train loss : 0.254787 ,train acc: 0.878499 ,val loss : 0.385799 ,val acc : 0.823853\n",
      "[ ecpho : 6  iter :95 ]train loss : 0.353463 ,train acc: 0.846659 ,val loss : 0.381076 ,val acc : 0.828339\n",
      "[ ecpho : 6  iter :96 ]train loss : 0.258431 ,train acc: 0.876170 ,val loss : 0.387426 ,val acc : 0.825714\n",
      "[ ecpho : 6  iter :97 ]train loss : 0.373070 ,train acc: 0.827515 ,val loss : 0.386333 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :98 ]train loss : 0.327646 ,train acc: 0.850271 ,val loss : 0.383034 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :99 ]train loss : 0.276194 ,train acc: 0.874624 ,val loss : 0.380810 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :100 ]train loss : 0.370668 ,train acc: 0.842825 ,val loss : 0.389421 ,val acc : 0.824493\n",
      "[ ecpho : 6  iter :101 ]train loss : 0.239746 ,train acc: 0.881256 ,val loss : 0.389386 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :102 ]train loss : 0.306193 ,train acc: 0.862122 ,val loss : 0.384229 ,val acc : 0.828918\n",
      "[ ecpho : 6  iter :103 ]train loss : 0.266153 ,train acc: 0.882304 ,val loss : 0.381016 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :104 ]train loss : 0.243519 ,train acc: 0.884796 ,val loss : 0.380335 ,val acc : 0.828156\n",
      "[ ecpho : 6  iter :105 ]train loss : 0.439848 ,train acc: 0.845540 ,val loss : 0.384419 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :106 ]train loss : 0.258289 ,train acc: 0.872254 ,val loss : 0.382413 ,val acc : 0.824799\n",
      "[ ecpho : 6  iter :107 ]train loss : 0.300974 ,train acc: 0.859426 ,val loss : 0.380771 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :108 ]train loss : 0.413700 ,train acc: 0.842163 ,val loss : 0.385253 ,val acc : 0.825806\n",
      "[ ecpho : 6  iter :109 ]train loss : 0.260166 ,train acc: 0.877584 ,val loss : 0.382717 ,val acc : 0.826965\n",
      "[ ecpho : 6  iter :110 ]train loss : 0.363182 ,train acc: 0.841573 ,val loss : 0.385989 ,val acc : 0.825745\n",
      "[ ecpho : 6  iter :111 ]train loss : 0.248043 ,train acc: 0.881826 ,val loss : 0.384709 ,val acc : 0.824524\n",
      "[ ecpho : 6  iter :112 ]train loss : 0.478665 ,train acc: 0.815806 ,val loss : 0.385786 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :113 ]train loss : 0.330901 ,train acc: 0.831085 ,val loss : 0.390916 ,val acc : 0.823883\n",
      "[ ecpho : 6  iter :114 ]train loss : 0.392800 ,train acc: 0.844055 ,val loss : 0.384569 ,val acc : 0.825684\n",
      "[ ecpho : 6  iter :115 ]train loss : 0.398359 ,train acc: 0.836589 ,val loss : 0.385767 ,val acc : 0.829041\n",
      "[ ecpho : 6  iter :116 ]train loss : 0.278605 ,train acc: 0.865316 ,val loss : 0.384759 ,val acc : 0.825592\n",
      "[ ecpho : 6  iter :117 ]train loss : 0.346781 ,train acc: 0.827454 ,val loss : 0.385851 ,val acc : 0.826233\n",
      "[ ecpho : 6  iter :118 ]train loss : 0.288283 ,train acc: 0.852804 ,val loss : 0.384275 ,val acc : 0.824707\n",
      "[ ecpho : 6  iter :119 ]train loss : 0.260542 ,train acc: 0.880829 ,val loss : 0.383413 ,val acc : 0.826752\n",
      "[ ecpho : 6  iter :120 ]train loss : 0.367259 ,train acc: 0.854228 ,val loss : 0.385711 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :121 ]train loss : 0.278453 ,train acc: 0.858917 ,val loss : 0.389623 ,val acc : 0.824066\n",
      "[ ecpho : 6  iter :122 ]train loss : 0.356251 ,train acc: 0.847310 ,val loss : 0.382057 ,val acc : 0.825134\n",
      "[ ecpho : 6  iter :123 ]train loss : 0.278245 ,train acc: 0.870077 ,val loss : 0.382843 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :124 ]train loss : 0.375543 ,train acc: 0.825846 ,val loss : 0.388564 ,val acc : 0.829956\n",
      "[ ecpho : 6  iter :125 ]train loss : 0.322510 ,train acc: 0.858195 ,val loss : 0.386304 ,val acc : 0.822937\n",
      "[ ecpho : 6  iter :126 ]train loss : 0.370995 ,train acc: 0.830658 ,val loss : 0.387027 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :127 ]train loss : 0.335415 ,train acc: 0.763692 ,val loss : 0.388206 ,val acc : 0.824646\n",
      "[ ecpho : 6  iter :128 ]train loss : 0.344480 ,train acc: 0.825897 ,val loss : 0.387953 ,val acc : 0.824280\n",
      "[ ecpho : 6  iter :129 ]train loss : 0.257047 ,train acc: 0.878581 ,val loss : 0.383178 ,val acc : 0.824951\n",
      "[ ecpho : 6  iter :130 ]train loss : 0.434460 ,train acc: 0.842591 ,val loss : 0.383135 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :131 ]train loss : 0.289149 ,train acc: 0.859365 ,val loss : 0.383068 ,val acc : 0.825195\n",
      "[ ecpho : 6  iter :132 ]train loss : 0.303499 ,train acc: 0.850260 ,val loss : 0.386517 ,val acc : 0.825195\n",
      "[ ecpho : 6  iter :133 ]train loss : 0.463403 ,train acc: 0.828064 ,val loss : 0.376923 ,val acc : 0.830048\n",
      "[ ecpho : 6  iter :134 ]train loss : 0.419365 ,train acc: 0.816691 ,val loss : 0.392933 ,val acc : 0.826660\n",
      "[ ecpho : 6  iter :135 ]train loss : 0.261916 ,train acc: 0.877126 ,val loss : 0.384258 ,val acc : 0.826752\n",
      "[ ecpho : 6  iter :136 ]train loss : 0.289625 ,train acc: 0.861827 ,val loss : 0.386550 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :137 ]train loss : 0.382234 ,train acc: 0.810028 ,val loss : 0.389618 ,val acc : 0.822998\n",
      "[ ecpho : 6  iter :138 ]train loss : 0.338662 ,train acc: 0.848694 ,val loss : 0.379962 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :139 ]train loss : 0.266269 ,train acc: 0.869181 ,val loss : 0.378885 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :140 ]train loss : 0.299203 ,train acc: 0.860901 ,val loss : 0.381980 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :141 ]train loss : 0.382027 ,train acc: 0.842387 ,val loss : 0.383794 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :142 ]train loss : 0.243159 ,train acc: 0.881012 ,val loss : 0.387962 ,val acc : 0.824799\n",
      "[ ecpho : 6  iter :143 ]train loss : 0.282273 ,train acc: 0.869141 ,val loss : 0.387277 ,val acc : 0.825775\n",
      "[ ecpho : 6  iter :144 ]train loss : 0.273370 ,train acc: 0.865428 ,val loss : 0.382359 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :145 ]train loss : 0.334528 ,train acc: 0.865163 ,val loss : 0.382277 ,val acc : 0.823517\n",
      "[ ecpho : 6  iter :146 ]train loss : 0.366738 ,train acc: 0.840027 ,val loss : 0.378886 ,val acc : 0.831146\n",
      "[ ecpho : 6  iter :147 ]train loss : 0.273576 ,train acc: 0.871491 ,val loss : 0.381783 ,val acc : 0.828735\n",
      "[ ecpho : 6  iter :148 ]train loss : 0.250951 ,train acc: 0.881114 ,val loss : 0.381750 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :149 ]train loss : 0.258369 ,train acc: 0.876648 ,val loss : 0.391998 ,val acc : 0.823395\n",
      "[ ecpho : 6  iter :150 ]train loss : 0.323790 ,train acc: 0.860260 ,val loss : 0.382375 ,val acc : 0.828461\n",
      "[ ecpho : 6  iter :151 ]train loss : 0.305297 ,train acc: 0.860647 ,val loss : 0.380503 ,val acc : 0.827942\n",
      "[ ecpho : 6  iter :152 ]train loss : 0.443398 ,train acc: 0.832540 ,val loss : 0.384457 ,val acc : 0.826660\n",
      "[ ecpho : 6  iter :153 ]train loss : 0.277645 ,train acc: 0.871999 ,val loss : 0.383618 ,val acc : 0.825806\n",
      "[ ecpho : 6  iter :154 ]train loss : 0.420169 ,train acc: 0.848501 ,val loss : 0.380883 ,val acc : 0.826752\n",
      "[ ecpho : 6  iter :155 ]train loss : 0.244550 ,train acc: 0.881185 ,val loss : 0.380856 ,val acc : 0.830139\n",
      "[ ecpho : 6  iter :156 ]train loss : 0.308554 ,train acc: 0.859141 ,val loss : 0.384491 ,val acc : 0.826904\n",
      "[ ecpho : 6  iter :157 ]train loss : 0.251896 ,train acc: 0.880320 ,val loss : 0.381371 ,val acc : 0.826172\n",
      "[ ecpho : 6  iter :158 ]train loss : 0.380356 ,train acc: 0.844533 ,val loss : 0.383309 ,val acc : 0.826202\n",
      "[ ecpho : 6  iter :159 ]train loss : 0.276451 ,train acc: 0.868795 ,val loss : 0.385838 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :160 ]train loss : 0.417175 ,train acc: 0.804250 ,val loss : 0.386135 ,val acc : 0.823547\n",
      "[ ecpho : 6  iter :161 ]train loss : 0.388888 ,train acc: 0.833700 ,val loss : 0.386126 ,val acc : 0.827545\n",
      "[ ecpho : 6  iter :162 ]train loss : 0.327164 ,train acc: 0.832357 ,val loss : 0.384846 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :163 ]train loss : 0.462996 ,train acc: 0.834513 ,val loss : 0.383395 ,val acc : 0.829315\n",
      "[ ecpho : 6  iter :164 ]train loss : 0.324155 ,train acc: 0.826223 ,val loss : 0.384872 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :165 ]train loss : 0.422405 ,train acc: 0.815145 ,val loss : 0.387122 ,val acc : 0.823853\n",
      "[ ecpho : 6  iter :166 ]train loss : 0.286787 ,train acc: 0.857788 ,val loss : 0.386211 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :167 ]train loss : 0.261573 ,train acc: 0.879873 ,val loss : 0.380809 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :168 ]train loss : 0.326241 ,train acc: 0.843353 ,val loss : 0.380086 ,val acc : 0.827759\n",
      "[ ecpho : 6  iter :169 ]train loss : 0.269174 ,train acc: 0.869619 ,val loss : 0.383654 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :170 ]train loss : 0.362231 ,train acc: 0.843943 ,val loss : 0.387054 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :171 ]train loss : 0.304974 ,train acc: 0.859579 ,val loss : 0.377367 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :172 ]train loss : 0.299929 ,train acc: 0.852905 ,val loss : 0.384552 ,val acc : 0.827728\n",
      "[ ecpho : 6  iter :173 ]train loss : 0.271983 ,train acc: 0.866730 ,val loss : 0.384792 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :174 ]train loss : 0.316468 ,train acc: 0.857666 ,val loss : 0.384693 ,val acc : 0.825623\n",
      "[ ecpho : 6  iter :175 ]train loss : 0.257355 ,train acc: 0.875824 ,val loss : 0.392138 ,val acc : 0.821991\n",
      "[ ecpho : 6  iter :176 ]train loss : 0.285914 ,train acc: 0.873088 ,val loss : 0.389450 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :177 ]train loss : 0.379477 ,train acc: 0.848491 ,val loss : 0.389311 ,val acc : 0.824554\n",
      "[ ecpho : 6  iter :178 ]train loss : 0.296398 ,train acc: 0.853190 ,val loss : 0.379651 ,val acc : 0.827881\n",
      "[ ecpho : 6  iter :179 ]train loss : 0.387501 ,train acc: 0.806223 ,val loss : 0.382635 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :180 ]train loss : 0.296833 ,train acc: 0.846466 ,val loss : 0.385362 ,val acc : 0.821594\n",
      "[ ecpho : 6  iter :181 ]train loss : 0.318250 ,train acc: 0.847809 ,val loss : 0.388869 ,val acc : 0.825745\n",
      "[ ecpho : 6  iter :182 ]train loss : 0.262768 ,train acc: 0.882914 ,val loss : 0.385021 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :183 ]train loss : 0.377618 ,train acc: 0.843913 ,val loss : 0.381940 ,val acc : 0.827209\n",
      "[ ecpho : 6  iter :184 ]train loss : 0.252381 ,train acc: 0.881439 ,val loss : 0.383094 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :185 ]train loss : 0.349557 ,train acc: 0.836345 ,val loss : 0.387344 ,val acc : 0.825348\n",
      "[ ecpho : 6  iter :186 ]train loss : 0.274377 ,train acc: 0.875010 ,val loss : 0.386410 ,val acc : 0.826660\n",
      "[ ecpho : 6  iter :187 ]train loss : 0.267307 ,train acc: 0.871023 ,val loss : 0.382825 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :188 ]train loss : 0.275138 ,train acc: 0.872182 ,val loss : 0.381845 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :189 ]train loss : 0.321413 ,train acc: 0.864736 ,val loss : 0.379387 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :190 ]train loss : 0.296148 ,train acc: 0.862630 ,val loss : 0.388229 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :191 ]train loss : 0.275393 ,train acc: 0.860870 ,val loss : 0.376369 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :192 ]train loss : 0.270747 ,train acc: 0.874990 ,val loss : 0.388992 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :193 ]train loss : 0.258376 ,train acc: 0.875977 ,val loss : 0.381344 ,val acc : 0.824768\n",
      "[ ecpho : 6  iter :194 ]train loss : 0.332719 ,train acc: 0.851603 ,val loss : 0.381668 ,val acc : 0.827667\n",
      "[ ecpho : 6  iter :195 ]train loss : 0.433716 ,train acc: 0.837402 ,val loss : 0.385866 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :196 ]train loss : 0.294930 ,train acc: 0.858480 ,val loss : 0.384676 ,val acc : 0.824951\n",
      "[ ecpho : 6  iter :197 ]train loss : 0.323886 ,train acc: 0.841471 ,val loss : 0.382442 ,val acc : 0.824341\n",
      "[ ecpho : 6  iter :198 ]train loss : 0.330312 ,train acc: 0.851237 ,val loss : 0.384266 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :199 ]train loss : 0.320487 ,train acc: 0.841390 ,val loss : 0.387258 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :200 ]train loss : 0.316108 ,train acc: 0.863546 ,val loss : 0.382165 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :201 ]train loss : 0.292094 ,train acc: 0.869873 ,val loss : 0.381608 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :202 ]train loss : 0.332427 ,train acc: 0.855428 ,val loss : 0.383793 ,val acc : 0.824829\n",
      "[ ecpho : 6  iter :203 ]train loss : 0.331032 ,train acc: 0.831390 ,val loss : 0.387899 ,val acc : 0.823639\n",
      "[ ecpho : 6  iter :204 ]train loss : 0.290922 ,train acc: 0.859477 ,val loss : 0.387073 ,val acc : 0.829010\n",
      "[ ecpho : 6  iter :205 ]train loss : 0.337913 ,train acc: 0.846293 ,val loss : 0.386884 ,val acc : 0.825073\n",
      "[ ecpho : 6  iter :206 ]train loss : 0.281872 ,train acc: 0.869507 ,val loss : 0.383539 ,val acc : 0.826752\n",
      "[ ecpho : 6  iter :207 ]train loss : 0.393354 ,train acc: 0.812256 ,val loss : 0.387539 ,val acc : 0.827759\n",
      "[ ecpho : 6  iter :208 ]train loss : 0.535585 ,train acc: 0.745433 ,val loss : 0.388807 ,val acc : 0.824219\n",
      "[ ecpho : 6  iter :209 ]train loss : 0.328066 ,train acc: 0.847636 ,val loss : 0.384909 ,val acc : 0.824951\n",
      "[ ecpho : 6  iter :210 ]train loss : 0.268230 ,train acc: 0.870850 ,val loss : 0.383898 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :211 ]train loss : 0.314643 ,train acc: 0.841878 ,val loss : 0.385461 ,val acc : 0.827057\n",
      "[ ecpho : 6  iter :212 ]train loss : 0.377874 ,train acc: 0.821676 ,val loss : 0.384886 ,val acc : 0.824615\n",
      "[ ecpho : 6  iter :213 ]train loss : 0.307469 ,train acc: 0.844238 ,val loss : 0.380305 ,val acc : 0.829437\n",
      "[ ecpho : 6  iter :214 ]train loss : 0.264606 ,train acc: 0.872264 ,val loss : 0.382703 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :215 ]train loss : 0.273371 ,train acc: 0.865662 ,val loss : 0.387429 ,val acc : 0.828278\n",
      "[ ecpho : 6  iter :216 ]train loss : 0.492085 ,train acc: 0.785116 ,val loss : 0.384916 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :217 ]train loss : 0.342780 ,train acc: 0.850861 ,val loss : 0.383229 ,val acc : 0.824646\n",
      "[ ecpho : 6  iter :218 ]train loss : 0.369195 ,train acc: 0.837982 ,val loss : 0.377537 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :219 ]train loss : 0.284814 ,train acc: 0.866862 ,val loss : 0.384618 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :220 ]train loss : 0.312461 ,train acc: 0.836690 ,val loss : 0.384567 ,val acc : 0.826752\n",
      "[ ecpho : 6  iter :221 ]train loss : 0.297964 ,train acc: 0.862712 ,val loss : 0.384834 ,val acc : 0.824707\n",
      "[ ecpho : 6  iter :222 ]train loss : 0.258061 ,train acc: 0.877543 ,val loss : 0.380734 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :223 ]train loss : 0.463583 ,train acc: 0.827678 ,val loss : 0.386842 ,val acc : 0.824982\n",
      "[ ecpho : 6  iter :224 ]train loss : 0.310192 ,train acc: 0.831777 ,val loss : 0.385081 ,val acc : 0.823792\n",
      "[ ecpho : 6  iter :225 ]train loss : 0.330288 ,train acc: 0.857096 ,val loss : 0.378585 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :226 ]train loss : 0.302171 ,train acc: 0.864390 ,val loss : 0.387340 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :227 ]train loss : 0.383758 ,train acc: 0.830292 ,val loss : 0.383503 ,val acc : 0.827026\n",
      "[ ecpho : 6  iter :228 ]train loss : 0.432036 ,train acc: 0.802297 ,val loss : 0.387606 ,val acc : 0.823853\n",
      "[ ecpho : 6  iter :229 ]train loss : 0.228447 ,train acc: 0.888570 ,val loss : 0.382613 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :230 ]train loss : 0.271116 ,train acc: 0.871104 ,val loss : 0.389951 ,val acc : 0.824829\n",
      "[ ecpho : 6  iter :231 ]train loss : 0.320666 ,train acc: 0.839010 ,val loss : 0.390830 ,val acc : 0.824158\n",
      "[ ecpho : 6  iter :232 ]train loss : 0.238234 ,train acc: 0.883799 ,val loss : 0.383088 ,val acc : 0.825592\n",
      "[ ecpho : 6  iter :233 ]train loss : 0.283442 ,train acc: 0.868286 ,val loss : 0.382353 ,val acc : 0.824554\n",
      "[ ecpho : 6  iter :234 ]train loss : 0.298961 ,train acc: 0.861237 ,val loss : 0.377905 ,val acc : 0.830292\n",
      "[ ecpho : 6  iter :235 ]train loss : 0.302046 ,train acc: 0.850647 ,val loss : 0.380305 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :236 ]train loss : 0.274160 ,train acc: 0.870077 ,val loss : 0.381939 ,val acc : 0.825134\n",
      "[ ecpho : 6  iter :237 ]train loss : 0.300076 ,train acc: 0.863647 ,val loss : 0.383470 ,val acc : 0.827759\n",
      "[ ecpho : 6  iter :238 ]train loss : 0.293518 ,train acc: 0.869792 ,val loss : 0.380603 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :239 ]train loss : 0.342096 ,train acc: 0.807526 ,val loss : 0.386935 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :240 ]train loss : 0.300759 ,train acc: 0.869344 ,val loss : 0.378830 ,val acc : 0.828888\n",
      "[ ecpho : 6  iter :241 ]train loss : 0.323377 ,train acc: 0.852641 ,val loss : 0.384267 ,val acc : 0.823395\n",
      "[ ecpho : 6  iter :242 ]train loss : 0.499919 ,train acc: 0.751516 ,val loss : 0.378099 ,val acc : 0.826019\n",
      "[ ecpho : 6  iter :243 ]train loss : 0.232836 ,train acc: 0.885325 ,val loss : 0.386874 ,val acc : 0.824707\n",
      "[ ecpho : 6  iter :244 ]train loss : 0.295233 ,train acc: 0.862417 ,val loss : 0.385562 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :245 ]train loss : 0.278519 ,train acc: 0.874400 ,val loss : 0.383019 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :246 ]train loss : 0.358692 ,train acc: 0.811015 ,val loss : 0.381804 ,val acc : 0.825409\n",
      "[ ecpho : 6  iter :247 ]train loss : 0.275156 ,train acc: 0.863515 ,val loss : 0.383529 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :248 ]train loss : 0.256028 ,train acc: 0.878387 ,val loss : 0.376355 ,val acc : 0.828430\n",
      "[ ecpho : 6  iter :249 ]train loss : 0.281170 ,train acc: 0.864441 ,val loss : 0.386411 ,val acc : 0.824310\n",
      "[ ecpho : 6  iter :250 ]train loss : 0.553059 ,train acc: 0.772390 ,val loss : 0.385085 ,val acc : 0.824066\n",
      "[ ecpho : 6  iter :251 ]train loss : 0.326847 ,train acc: 0.859446 ,val loss : 0.380743 ,val acc : 0.829498\n",
      "[ ecpho : 6  iter :252 ]train loss : 0.334750 ,train acc: 0.861287 ,val loss : 0.382817 ,val acc : 0.828064\n",
      "[ ecpho : 6  iter :253 ]train loss : 0.357893 ,train acc: 0.848033 ,val loss : 0.386442 ,val acc : 0.825684\n",
      "[ ecpho : 6  iter :254 ]train loss : 0.275384 ,train acc: 0.867483 ,val loss : 0.388649 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :255 ]train loss : 0.281676 ,train acc: 0.868235 ,val loss : 0.383251 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :256 ]train loss : 0.257975 ,train acc: 0.876088 ,val loss : 0.382022 ,val acc : 0.828308\n",
      "[ ecpho : 6  iter :257 ]train loss : 0.318968 ,train acc: 0.858276 ,val loss : 0.383591 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :258 ]train loss : 0.256431 ,train acc: 0.878754 ,val loss : 0.386231 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :259 ]train loss : 0.382180 ,train acc: 0.822886 ,val loss : 0.384952 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :260 ]train loss : 0.411971 ,train acc: 0.839325 ,val loss : 0.387769 ,val acc : 0.824066\n",
      "[ ecpho : 6  iter :261 ]train loss : 0.293960 ,train acc: 0.864665 ,val loss : 0.386769 ,val acc : 0.827972\n",
      "[ ecpho : 6  iter :262 ]train loss : 0.250612 ,train acc: 0.876536 ,val loss : 0.379497 ,val acc : 0.827942\n",
      "[ ecpho : 6  iter :263 ]train loss : 0.347825 ,train acc: 0.847595 ,val loss : 0.382210 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :264 ]train loss : 0.275413 ,train acc: 0.869598 ,val loss : 0.378984 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :265 ]train loss : 0.331971 ,train acc: 0.856903 ,val loss : 0.384779 ,val acc : 0.824341\n",
      "[ ecpho : 6  iter :266 ]train loss : 0.284432 ,train acc: 0.867157 ,val loss : 0.382176 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :267 ]train loss : 0.236923 ,train acc: 0.883474 ,val loss : 0.380207 ,val acc : 0.824371\n",
      "[ ecpho : 6  iter :268 ]train loss : 0.420092 ,train acc: 0.842499 ,val loss : 0.390505 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :269 ]train loss : 0.361980 ,train acc: 0.833089 ,val loss : 0.385433 ,val acc : 0.824219\n",
      "[ ecpho : 6  iter :270 ]train loss : 0.266869 ,train acc: 0.877218 ,val loss : 0.380820 ,val acc : 0.828461\n",
      "[ ecpho : 6  iter :271 ]train loss : 0.356349 ,train acc: 0.845479 ,val loss : 0.388717 ,val acc : 0.824219\n",
      "[ ecpho : 6  iter :272 ]train loss : 0.239462 ,train acc: 0.884359 ,val loss : 0.387445 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :273 ]train loss : 0.356549 ,train acc: 0.842407 ,val loss : 0.384247 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :274 ]train loss : 0.290277 ,train acc: 0.855723 ,val loss : 0.385082 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :275 ]train loss : 0.374962 ,train acc: 0.830068 ,val loss : 0.383473 ,val acc : 0.826782\n",
      "[ ecpho : 6  iter :276 ]train loss : 0.282849 ,train acc: 0.867747 ,val loss : 0.383966 ,val acc : 0.825287\n",
      "[ ecpho : 6  iter :277 ]train loss : 0.308161 ,train acc: 0.858917 ,val loss : 0.383624 ,val acc : 0.826111\n",
      "[ ecpho : 6  iter :278 ]train loss : 0.280805 ,train acc: 0.871165 ,val loss : 0.385961 ,val acc : 0.825409\n",
      "[ ecpho : 6  iter :279 ]train loss : 0.430254 ,train acc: 0.772105 ,val loss : 0.382011 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :280 ]train loss : 0.401759 ,train acc: 0.826447 ,val loss : 0.389338 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :281 ]train loss : 0.342073 ,train acc: 0.827667 ,val loss : 0.379847 ,val acc : 0.827484\n",
      "[ ecpho : 6  iter :282 ]train loss : 0.309610 ,train acc: 0.830902 ,val loss : 0.381636 ,val acc : 0.826538\n",
      "[ ecpho : 6  iter :283 ]train loss : 0.272281 ,train acc: 0.863617 ,val loss : 0.380378 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :284 ]train loss : 0.353589 ,train acc: 0.838115 ,val loss : 0.382308 ,val acc : 0.827881\n",
      "[ ecpho : 6  iter :285 ]train loss : 0.295122 ,train acc: 0.862793 ,val loss : 0.380736 ,val acc : 0.828583\n",
      "[ ecpho : 6  iter :286 ]train loss : 0.254649 ,train acc: 0.876516 ,val loss : 0.382074 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :287 ]train loss : 0.262384 ,train acc: 0.875346 ,val loss : 0.386255 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :288 ]train loss : 0.317811 ,train acc: 0.848979 ,val loss : 0.387845 ,val acc : 0.825470\n",
      "[ ecpho : 6  iter :289 ]train loss : 0.493803 ,train acc: 0.779846 ,val loss : 0.381228 ,val acc : 0.826202\n",
      "[ ecpho : 6  iter :290 ]train loss : 0.312664 ,train acc: 0.860291 ,val loss : 0.381875 ,val acc : 0.824860\n",
      "[ ecpho : 6  iter :291 ]train loss : 0.326020 ,train acc: 0.835744 ,val loss : 0.386737 ,val acc : 0.825195\n",
      "[ ecpho : 6  iter :292 ]train loss : 0.287597 ,train acc: 0.871409 ,val loss : 0.380851 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :293 ]train loss : 0.298295 ,train acc: 0.864655 ,val loss : 0.388246 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :294 ]train loss : 0.295974 ,train acc: 0.863403 ,val loss : 0.380361 ,val acc : 0.828094\n",
      "[ ecpho : 6  iter :295 ]train loss : 0.275677 ,train acc: 0.873830 ,val loss : 0.382156 ,val acc : 0.826904\n",
      "[ ecpho : 6  iter :296 ]train loss : 0.425741 ,train acc: 0.819275 ,val loss : 0.386009 ,val acc : 0.823181\n",
      "[ ecpho : 6  iter :297 ]train loss : 0.289475 ,train acc: 0.865774 ,val loss : 0.383830 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :298 ]train loss : 0.275507 ,train acc: 0.867045 ,val loss : 0.377920 ,val acc : 0.826782\n",
      "[ ecpho : 6  iter :299 ]train loss : 0.440039 ,train acc: 0.803406 ,val loss : 0.384518 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :300 ]train loss : 0.387245 ,train acc: 0.818970 ,val loss : 0.382605 ,val acc : 0.824646\n",
      "[ ecpho : 6  iter :301 ]train loss : 0.287623 ,train acc: 0.861593 ,val loss : 0.382538 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :302 ]train loss : 0.472555 ,train acc: 0.795624 ,val loss : 0.386747 ,val acc : 0.825623\n",
      "[ ecpho : 6  iter :303 ]train loss : 0.250799 ,train acc: 0.877553 ,val loss : 0.383353 ,val acc : 0.828735\n",
      "[ ecpho : 6  iter :304 ]train loss : 0.253790 ,train acc: 0.878235 ,val loss : 0.382758 ,val acc : 0.825775\n",
      "[ ecpho : 6  iter :305 ]train loss : 0.273605 ,train acc: 0.870931 ,val loss : 0.383627 ,val acc : 0.823334\n",
      "[ ecpho : 6  iter :306 ]train loss : 0.555643 ,train acc: 0.756592 ,val loss : 0.382365 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :307 ]train loss : 0.305799 ,train acc: 0.864797 ,val loss : 0.383838 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :308 ]train loss : 0.412556 ,train acc: 0.827759 ,val loss : 0.383538 ,val acc : 0.828278\n",
      "[ ecpho : 6  iter :309 ]train loss : 0.289338 ,train acc: 0.859884 ,val loss : 0.387213 ,val acc : 0.824799\n",
      "[ ecpho : 6  iter :310 ]train loss : 0.375157 ,train acc: 0.824341 ,val loss : 0.379199 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :311 ]train loss : 0.293613 ,train acc: 0.855754 ,val loss : 0.391105 ,val acc : 0.822998\n",
      "[ ecpho : 6  iter :312 ]train loss : 0.390379 ,train acc: 0.820272 ,val loss : 0.380158 ,val acc : 0.830414\n",
      "[ ecpho : 6  iter :313 ]train loss : 0.264529 ,train acc: 0.874064 ,val loss : 0.383677 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :314 ]train loss : 0.302968 ,train acc: 0.870433 ,val loss : 0.380372 ,val acc : 0.825348\n",
      "[ ecpho : 6  iter :315 ]train loss : 0.313074 ,train acc: 0.845520 ,val loss : 0.383671 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :316 ]train loss : 0.305148 ,train acc: 0.869130 ,val loss : 0.382854 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :317 ]train loss : 0.291145 ,train acc: 0.862854 ,val loss : 0.388158 ,val acc : 0.821808\n",
      "[ ecpho : 6  iter :318 ]train loss : 0.294280 ,train acc: 0.861908 ,val loss : 0.386045 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :319 ]train loss : 0.310458 ,train acc: 0.858490 ,val loss : 0.387968 ,val acc : 0.824097\n",
      "[ ecpho : 6  iter :320 ]train loss : 0.386991 ,train acc: 0.841950 ,val loss : 0.383932 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :321 ]train loss : 0.250282 ,train acc: 0.878082 ,val loss : 0.386827 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :322 ]train loss : 0.264704 ,train acc: 0.867737 ,val loss : 0.381588 ,val acc : 0.826752\n",
      "[ ecpho : 6  iter :323 ]train loss : 0.261521 ,train acc: 0.876312 ,val loss : 0.385678 ,val acc : 0.822845\n",
      "[ ecpho : 6  iter :324 ]train loss : 0.287989 ,train acc: 0.871826 ,val loss : 0.386440 ,val acc : 0.825775\n",
      "[ ecpho : 6  iter :325 ]train loss : 0.306732 ,train acc: 0.861410 ,val loss : 0.384550 ,val acc : 0.826202\n",
      "[ ecpho : 6  iter :326 ]train loss : 0.308140 ,train acc: 0.865814 ,val loss : 0.382781 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :327 ]train loss : 0.358559 ,train acc: 0.842397 ,val loss : 0.383161 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :328 ]train loss : 0.255410 ,train acc: 0.875671 ,val loss : 0.386890 ,val acc : 0.822998\n",
      "[ ecpho : 6  iter :329 ]train loss : 0.235503 ,train acc: 0.883352 ,val loss : 0.388337 ,val acc : 0.823914\n",
      "[ ecpho : 6  iter :330 ]train loss : 0.261196 ,train acc: 0.873260 ,val loss : 0.381084 ,val acc : 0.825653\n",
      "[ ecpho : 6  iter :331 ]train loss : 0.273732 ,train acc: 0.867350 ,val loss : 0.384752 ,val acc : 0.823578\n",
      "[ ecpho : 6  iter :332 ]train loss : 0.273516 ,train acc: 0.869690 ,val loss : 0.384864 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :333 ]train loss : 0.240420 ,train acc: 0.882518 ,val loss : 0.387597 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :334 ]train loss : 0.358570 ,train acc: 0.811300 ,val loss : 0.389236 ,val acc : 0.823181\n",
      "[ ecpho : 6  iter :335 ]train loss : 0.475520 ,train acc: 0.826101 ,val loss : 0.382285 ,val acc : 0.828552\n",
      "[ ecpho : 6  iter :336 ]train loss : 0.324338 ,train acc: 0.836660 ,val loss : 0.381418 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :337 ]train loss : 0.350571 ,train acc: 0.848531 ,val loss : 0.390126 ,val acc : 0.823090\n",
      "[ ecpho : 6  iter :338 ]train loss : 0.377872 ,train acc: 0.784902 ,val loss : 0.386536 ,val acc : 0.824005\n",
      "[ ecpho : 6  iter :339 ]train loss : 0.371423 ,train acc: 0.846802 ,val loss : 0.384980 ,val acc : 0.824341\n",
      "[ ecpho : 6  iter :340 ]train loss : 0.273208 ,train acc: 0.865224 ,val loss : 0.388487 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :341 ]train loss : 0.247967 ,train acc: 0.878428 ,val loss : 0.386555 ,val acc : 0.827057\n",
      "[ ecpho : 6  iter :342 ]train loss : 0.331235 ,train acc: 0.856537 ,val loss : 0.383184 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :343 ]train loss : 0.337022 ,train acc: 0.840464 ,val loss : 0.388883 ,val acc : 0.824341\n",
      "[ ecpho : 6  iter :344 ]train loss : 0.293209 ,train acc: 0.861755 ,val loss : 0.384577 ,val acc : 0.823944\n",
      "[ ecpho : 6  iter :345 ]train loss : 0.276486 ,train acc: 0.872396 ,val loss : 0.378143 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :346 ]train loss : 0.325562 ,train acc: 0.823100 ,val loss : 0.381133 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :347 ]train loss : 0.238502 ,train acc: 0.884399 ,val loss : 0.379342 ,val acc : 0.830292\n",
      "[ ecpho : 6  iter :348 ]train loss : 0.276172 ,train acc: 0.869680 ,val loss : 0.385488 ,val acc : 0.825195\n",
      "[ ecpho : 6  iter :349 ]train loss : 0.305140 ,train acc: 0.848958 ,val loss : 0.383738 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :350 ]train loss : 0.303132 ,train acc: 0.866109 ,val loss : 0.383795 ,val acc : 0.827240\n",
      "[ ecpho : 6  iter :351 ]train loss : 0.267261 ,train acc: 0.869710 ,val loss : 0.383565 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :352 ]train loss : 0.404549 ,train acc: 0.809306 ,val loss : 0.382612 ,val acc : 0.828308\n",
      "[ ecpho : 6  iter :353 ]train loss : 0.290316 ,train acc: 0.864492 ,val loss : 0.385488 ,val acc : 0.826111\n",
      "[ ecpho : 6  iter :354 ]train loss : 0.336681 ,train acc: 0.830109 ,val loss : 0.382409 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :355 ]train loss : 0.240952 ,train acc: 0.884135 ,val loss : 0.387095 ,val acc : 0.826782\n",
      "[ ecpho : 6  iter :356 ]train loss : 0.331285 ,train acc: 0.829081 ,val loss : 0.387681 ,val acc : 0.822449\n",
      "[ ecpho : 6  iter :357 ]train loss : 0.242532 ,train acc: 0.882833 ,val loss : 0.382785 ,val acc : 0.823303\n",
      "[ ecpho : 6  iter :358 ]train loss : 0.272073 ,train acc: 0.873566 ,val loss : 0.386728 ,val acc : 0.825073\n",
      "[ ecpho : 6  iter :359 ]train loss : 0.283687 ,train acc: 0.864797 ,val loss : 0.380332 ,val acc : 0.828522\n",
      "[ ecpho : 6  iter :360 ]train loss : 0.285345 ,train acc: 0.867828 ,val loss : 0.383553 ,val acc : 0.827484\n",
      "[ ecpho : 6  iter :361 ]train loss : 0.290107 ,train acc: 0.855093 ,val loss : 0.386334 ,val acc : 0.823761\n",
      "[ ecpho : 6  iter :362 ]train loss : 0.256968 ,train acc: 0.878398 ,val loss : 0.377964 ,val acc : 0.828918\n",
      "[ ecpho : 6  iter :363 ]train loss : 0.231683 ,train acc: 0.888458 ,val loss : 0.386094 ,val acc : 0.827545\n",
      "[ ecpho : 6  iter :364 ]train loss : 0.286040 ,train acc: 0.860047 ,val loss : 0.377588 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :365 ]train loss : 0.254164 ,train acc: 0.882935 ,val loss : 0.382876 ,val acc : 0.824371\n",
      "[ ecpho : 6  iter :366 ]train loss : 0.296588 ,train acc: 0.865316 ,val loss : 0.376619 ,val acc : 0.829010\n",
      "[ ecpho : 6  iter :367 ]train loss : 0.288068 ,train acc: 0.866180 ,val loss : 0.386158 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :368 ]train loss : 0.312035 ,train acc: 0.836741 ,val loss : 0.381597 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :369 ]train loss : 0.329690 ,train acc: 0.856618 ,val loss : 0.388295 ,val acc : 0.822510\n",
      "[ ecpho : 6  iter :370 ]train loss : 0.241585 ,train acc: 0.882538 ,val loss : 0.381374 ,val acc : 0.826660\n",
      "[ ecpho : 6  iter :371 ]train loss : 0.369245 ,train acc: 0.837443 ,val loss : 0.382453 ,val acc : 0.828094\n",
      "[ ecpho : 6  iter :372 ]train loss : 0.276546 ,train acc: 0.870260 ,val loss : 0.385834 ,val acc : 0.825439\n",
      "[ ecpho : 6  iter :373 ]train loss : 0.293215 ,train acc: 0.863159 ,val loss : 0.383059 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :374 ]train loss : 0.246168 ,train acc: 0.880758 ,val loss : 0.384836 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :375 ]train loss : 0.286128 ,train acc: 0.856720 ,val loss : 0.384251 ,val acc : 0.824860\n",
      "[ ecpho : 6  iter :376 ]train loss : 0.229665 ,train acc: 0.889384 ,val loss : 0.385824 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :377 ]train loss : 0.311119 ,train acc: 0.860911 ,val loss : 0.385961 ,val acc : 0.825195\n",
      "[ ecpho : 6  iter :378 ]train loss : 0.433448 ,train acc: 0.833242 ,val loss : 0.384599 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :379 ]train loss : 0.298406 ,train acc: 0.842702 ,val loss : 0.380976 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :380 ]train loss : 0.310537 ,train acc: 0.843506 ,val loss : 0.384150 ,val acc : 0.826172\n",
      "[ ecpho : 6  iter :381 ]train loss : 0.275961 ,train acc: 0.868836 ,val loss : 0.379467 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :382 ]train loss : 0.312613 ,train acc: 0.845693 ,val loss : 0.386295 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :383 ]train loss : 0.257929 ,train acc: 0.876740 ,val loss : 0.382798 ,val acc : 0.828827\n",
      "[ ecpho : 6  iter :384 ]train loss : 0.247420 ,train acc: 0.882670 ,val loss : 0.378879 ,val acc : 0.825470\n",
      "[ ecpho : 6  iter :385 ]train loss : 0.431681 ,train acc: 0.823039 ,val loss : 0.390353 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :386 ]train loss : 0.376676 ,train acc: 0.835826 ,val loss : 0.385645 ,val acc : 0.827850\n",
      "[ ecpho : 6  iter :387 ]train loss : 0.267840 ,train acc: 0.875631 ,val loss : 0.385807 ,val acc : 0.827423\n",
      "[ ecpho : 6  iter :388 ]train loss : 0.375240 ,train acc: 0.846883 ,val loss : 0.382710 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :389 ]train loss : 0.309725 ,train acc: 0.868490 ,val loss : 0.384303 ,val acc : 0.824524\n",
      "[ ecpho : 6  iter :390 ]train loss : 0.462174 ,train acc: 0.806417 ,val loss : 0.382273 ,val acc : 0.827240\n",
      "[ ecpho : 6  iter :391 ]train loss : 0.271080 ,train acc: 0.868215 ,val loss : 0.382080 ,val acc : 0.826965\n",
      "[ ecpho : 6  iter :392 ]train loss : 0.249411 ,train acc: 0.881846 ,val loss : 0.385379 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :393 ]train loss : 0.255435 ,train acc: 0.876689 ,val loss : 0.377993 ,val acc : 0.830994\n",
      "[ ecpho : 6  iter :394 ]train loss : 0.293018 ,train acc: 0.845134 ,val loss : 0.389085 ,val acc : 0.824738\n",
      "[ ecpho : 6  iter :395 ]train loss : 0.253252 ,train acc: 0.883219 ,val loss : 0.381258 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :396 ]train loss : 0.315870 ,train acc: 0.850037 ,val loss : 0.385898 ,val acc : 0.827362\n",
      "[ ecpho : 6  iter :397 ]train loss : 0.385212 ,train acc: 0.823812 ,val loss : 0.388762 ,val acc : 0.824371\n",
      "[ ecpho : 6  iter :398 ]train loss : 0.442287 ,train acc: 0.796651 ,val loss : 0.379720 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :399 ]train loss : 0.278742 ,train acc: 0.852946 ,val loss : 0.384341 ,val acc : 0.823151\n",
      "[ ecpho : 6  iter :400 ]train loss : 0.280121 ,train acc: 0.866496 ,val loss : 0.380327 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :401 ]train loss : 0.303345 ,train acc: 0.836934 ,val loss : 0.380508 ,val acc : 0.829987\n",
      "[ ecpho : 6  iter :402 ]train loss : 0.293809 ,train acc: 0.853241 ,val loss : 0.386082 ,val acc : 0.824341\n",
      "[ ecpho : 6  iter :403 ]train loss : 0.220623 ,train acc: 0.891907 ,val loss : 0.380890 ,val acc : 0.830597\n",
      "[ ecpho : 6  iter :404 ]train loss : 0.295319 ,train acc: 0.865946 ,val loss : 0.387984 ,val acc : 0.823456\n",
      "[ ecpho : 6  iter :405 ]train loss : 0.297272 ,train acc: 0.858785 ,val loss : 0.388303 ,val acc : 0.823608\n",
      "[ ecpho : 6  iter :406 ]train loss : 0.345968 ,train acc: 0.825551 ,val loss : 0.381511 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :407 ]train loss : 0.247898 ,train acc: 0.879110 ,val loss : 0.384526 ,val acc : 0.824371\n",
      "[ ecpho : 6  iter :408 ]train loss : 0.259633 ,train acc: 0.873413 ,val loss : 0.379301 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :409 ]train loss : 0.308860 ,train acc: 0.856405 ,val loss : 0.386774 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :410 ]train loss : 0.333713 ,train acc: 0.854329 ,val loss : 0.386037 ,val acc : 0.827484\n",
      "[ ecpho : 6  iter :411 ]train loss : 0.249390 ,train acc: 0.881205 ,val loss : 0.387645 ,val acc : 0.822113\n",
      "[ ecpho : 6  iter :412 ]train loss : 0.261437 ,train acc: 0.873800 ,val loss : 0.383031 ,val acc : 0.831116\n",
      "[ ecpho : 6  iter :413 ]train loss : 0.279038 ,train acc: 0.854380 ,val loss : 0.384690 ,val acc : 0.824829\n",
      "[ ecpho : 6  iter :414 ]train loss : 0.402046 ,train acc: 0.812968 ,val loss : 0.387806 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :415 ]train loss : 0.341237 ,train acc: 0.825958 ,val loss : 0.389535 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :416 ]train loss : 0.245723 ,train acc: 0.882802 ,val loss : 0.378404 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :417 ]train loss : 0.284238 ,train acc: 0.865468 ,val loss : 0.377346 ,val acc : 0.832123\n",
      "[ ecpho : 6  iter :418 ]train loss : 0.281123 ,train acc: 0.864471 ,val loss : 0.378969 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :419 ]train loss : 0.384334 ,train acc: 0.808563 ,val loss : 0.378104 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :420 ]train loss : 0.306970 ,train acc: 0.857330 ,val loss : 0.378471 ,val acc : 0.827148\n",
      "[ ecpho : 6  iter :421 ]train loss : 0.271161 ,train acc: 0.874196 ,val loss : 0.384949 ,val acc : 0.824921\n",
      "[ ecpho : 6  iter :422 ]train loss : 0.385796 ,train acc: 0.814311 ,val loss : 0.384278 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :423 ]train loss : 0.330753 ,train acc: 0.854808 ,val loss : 0.383530 ,val acc : 0.831543\n",
      "[ ecpho : 6  iter :424 ]train loss : 0.271803 ,train acc: 0.872559 ,val loss : 0.385442 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :425 ]train loss : 0.303188 ,train acc: 0.864675 ,val loss : 0.382444 ,val acc : 0.825592\n",
      "[ ecpho : 6  iter :426 ]train loss : 0.287685 ,train acc: 0.863434 ,val loss : 0.383278 ,val acc : 0.826965\n",
      "[ ecpho : 6  iter :427 ]train loss : 0.259945 ,train acc: 0.869843 ,val loss : 0.378442 ,val acc : 0.826172\n",
      "[ ecpho : 6  iter :428 ]train loss : 0.344702 ,train acc: 0.849691 ,val loss : 0.384964 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :429 ]train loss : 0.321726 ,train acc: 0.837006 ,val loss : 0.378285 ,val acc : 0.827911\n",
      "[ ecpho : 6  iter :430 ]train loss : 0.498343 ,train acc: 0.767558 ,val loss : 0.380809 ,val acc : 0.825287\n",
      "[ ecpho : 6  iter :431 ]train loss : 0.303571 ,train acc: 0.867330 ,val loss : 0.384185 ,val acc : 0.825043\n",
      "[ ecpho : 6  iter :432 ]train loss : 0.377344 ,train acc: 0.802419 ,val loss : 0.380496 ,val acc : 0.827942\n",
      "[ ecpho : 6  iter :433 ]train loss : 0.326290 ,train acc: 0.864248 ,val loss : 0.378580 ,val acc : 0.829834\n",
      "[ ecpho : 6  iter :434 ]train loss : 0.443374 ,train acc: 0.704305 ,val loss : 0.378507 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :435 ]train loss : 0.290402 ,train acc: 0.864492 ,val loss : 0.386137 ,val acc : 0.829956\n",
      "[ ecpho : 6  iter :436 ]train loss : 0.342508 ,train acc: 0.794739 ,val loss : 0.381019 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :437 ]train loss : 0.315333 ,train acc: 0.865285 ,val loss : 0.381445 ,val acc : 0.828339\n",
      "[ ecpho : 6  iter :438 ]train loss : 0.332852 ,train acc: 0.861033 ,val loss : 0.382086 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :439 ]train loss : 0.407858 ,train acc: 0.774007 ,val loss : 0.387920 ,val acc : 0.825439\n",
      "[ ecpho : 6  iter :440 ]train loss : 0.268876 ,train acc: 0.874227 ,val loss : 0.386417 ,val acc : 0.827881\n",
      "[ ecpho : 6  iter :441 ]train loss : 0.254839 ,train acc: 0.882467 ,val loss : 0.381434 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :442 ]train loss : 0.347449 ,train acc: 0.833242 ,val loss : 0.382655 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :443 ]train loss : 0.260332 ,train acc: 0.874176 ,val loss : 0.386929 ,val acc : 0.824158\n",
      "[ ecpho : 6  iter :444 ]train loss : 0.265516 ,train acc: 0.869985 ,val loss : 0.378391 ,val acc : 0.827057\n",
      "[ ecpho : 6  iter :445 ]train loss : 0.292525 ,train acc: 0.864502 ,val loss : 0.385240 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :446 ]train loss : 0.290564 ,train acc: 0.872884 ,val loss : 0.384952 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :447 ]train loss : 0.323396 ,train acc: 0.858480 ,val loss : 0.379343 ,val acc : 0.826172\n",
      "[ ecpho : 6  iter :448 ]train loss : 0.251635 ,train acc: 0.879110 ,val loss : 0.382173 ,val acc : 0.828979\n",
      "[ ecpho : 6  iter :449 ]train loss : 0.292168 ,train acc: 0.868256 ,val loss : 0.390586 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :450 ]train loss : 0.298511 ,train acc: 0.863668 ,val loss : 0.378939 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :451 ]train loss : 0.260646 ,train acc: 0.877502 ,val loss : 0.385194 ,val acc : 0.824249\n",
      "[ ecpho : 6  iter :452 ]train loss : 0.361748 ,train acc: 0.834320 ,val loss : 0.384807 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :453 ]train loss : 0.245298 ,train acc: 0.879761 ,val loss : 0.386619 ,val acc : 0.827759\n",
      "[ ecpho : 6  iter :454 ]train loss : 0.256717 ,train acc: 0.875885 ,val loss : 0.381306 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :455 ]train loss : 0.246285 ,train acc: 0.882060 ,val loss : 0.384760 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :456 ]train loss : 0.375329 ,train acc: 0.844422 ,val loss : 0.390296 ,val acc : 0.824615\n",
      "[ ecpho : 6  iter :457 ]train loss : 0.316122 ,train acc: 0.859528 ,val loss : 0.383037 ,val acc : 0.829041\n",
      "[ ecpho : 6  iter :458 ]train loss : 0.471482 ,train acc: 0.798889 ,val loss : 0.383283 ,val acc : 0.825195\n",
      "[ ecpho : 6  iter :459 ]train loss : 0.240363 ,train acc: 0.883942 ,val loss : 0.386802 ,val acc : 0.824524\n",
      "[ ecpho : 6  iter :460 ]train loss : 0.370854 ,train acc: 0.833995 ,val loss : 0.385382 ,val acc : 0.822662\n",
      "[ ecpho : 6  iter :461 ]train loss : 0.276372 ,train acc: 0.871246 ,val loss : 0.383950 ,val acc : 0.823303\n",
      "[ ecpho : 6  iter :462 ]train loss : 0.329536 ,train acc: 0.858612 ,val loss : 0.381222 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :463 ]train loss : 0.306732 ,train acc: 0.867269 ,val loss : 0.380891 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :464 ]train loss : 0.285699 ,train acc: 0.872396 ,val loss : 0.384995 ,val acc : 0.825928\n",
      "[ ecpho : 6  iter :465 ]train loss : 0.488397 ,train acc: 0.785370 ,val loss : 0.381948 ,val acc : 0.827667\n",
      "[ ecpho : 6  iter :466 ]train loss : 0.314815 ,train acc: 0.853007 ,val loss : 0.384653 ,val acc : 0.826935\n",
      "[ ecpho : 6  iter :467 ]train loss : 0.287536 ,train acc: 0.871928 ,val loss : 0.382510 ,val acc : 0.827759\n",
      "[ ecpho : 6  iter :468 ]train loss : 0.275391 ,train acc: 0.874410 ,val loss : 0.386395 ,val acc : 0.824677\n",
      "[ ecpho : 6  iter :469 ]train loss : 0.340269 ,train acc: 0.856567 ,val loss : 0.386642 ,val acc : 0.826019\n",
      "[ ecpho : 6  iter :470 ]train loss : 0.246396 ,train acc: 0.879730 ,val loss : 0.387817 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :471 ]train loss : 0.291823 ,train acc: 0.854238 ,val loss : 0.386357 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :472 ]train loss : 0.267658 ,train acc: 0.868012 ,val loss : 0.378907 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :473 ]train loss : 0.279879 ,train acc: 0.857371 ,val loss : 0.383412 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :474 ]train loss : 0.258069 ,train acc: 0.875020 ,val loss : 0.383296 ,val acc : 0.826080\n",
      "[ ecpho : 6  iter :475 ]train loss : 0.404260 ,train acc: 0.800446 ,val loss : 0.384107 ,val acc : 0.827484\n",
      "[ ecpho : 6  iter :476 ]train loss : 0.281104 ,train acc: 0.869710 ,val loss : 0.382625 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :477 ]train loss : 0.353877 ,train acc: 0.859507 ,val loss : 0.384656 ,val acc : 0.827057\n",
      "[ ecpho : 6  iter :478 ]train loss : 0.295752 ,train acc: 0.857666 ,val loss : 0.382803 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :479 ]train loss : 0.318698 ,train acc: 0.860199 ,val loss : 0.382396 ,val acc : 0.825348\n",
      "[ ecpho : 6  iter :480 ]train loss : 0.277149 ,train acc: 0.869629 ,val loss : 0.380886 ,val acc : 0.828522\n",
      "[ ecpho : 6  iter :481 ]train loss : 0.380412 ,train acc: 0.824880 ,val loss : 0.386849 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :482 ]train loss : 0.303445 ,train acc: 0.857860 ,val loss : 0.381813 ,val acc : 0.827362\n",
      "[ ecpho : 6  iter :483 ]train loss : 0.302170 ,train acc: 0.849854 ,val loss : 0.382585 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :484 ]train loss : 0.274629 ,train acc: 0.862803 ,val loss : 0.379610 ,val acc : 0.828949\n",
      "[ ecpho : 6  iter :485 ]train loss : 0.273964 ,train acc: 0.870412 ,val loss : 0.379015 ,val acc : 0.829010\n",
      "[ ecpho : 6  iter :486 ]train loss : 0.298815 ,train acc: 0.844655 ,val loss : 0.377741 ,val acc : 0.828583\n",
      "[ ecpho : 6  iter :487 ]train loss : 0.412881 ,train acc: 0.817983 ,val loss : 0.385661 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :488 ]train loss : 0.230508 ,train acc: 0.888387 ,val loss : 0.384007 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :489 ]train loss : 0.292397 ,train acc: 0.869110 ,val loss : 0.388299 ,val acc : 0.824707\n",
      "[ ecpho : 6  iter :490 ]train loss : 0.341868 ,train acc: 0.848246 ,val loss : 0.379477 ,val acc : 0.826202\n",
      "[ ecpho : 6  iter :491 ]train loss : 0.266697 ,train acc: 0.876119 ,val loss : 0.380635 ,val acc : 0.828796\n",
      "[ ecpho : 6  iter :492 ]train loss : 0.322264 ,train acc: 0.866302 ,val loss : 0.388929 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :493 ]train loss : 0.322392 ,train acc: 0.858917 ,val loss : 0.384911 ,val acc : 0.826019\n",
      "[ ecpho : 6  iter :494 ]train loss : 0.380094 ,train acc: 0.790039 ,val loss : 0.386652 ,val acc : 0.827972\n",
      "[ ecpho : 6  iter :495 ]train loss : 0.251077 ,train acc: 0.877726 ,val loss : 0.384950 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :496 ]train loss : 0.254318 ,train acc: 0.875142 ,val loss : 0.386165 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :497 ]train loss : 0.278651 ,train acc: 0.862254 ,val loss : 0.387596 ,val acc : 0.826691\n",
      "[ ecpho : 6  iter :498 ]train loss : 0.306504 ,train acc: 0.856262 ,val loss : 0.381990 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :499 ]train loss : 0.290915 ,train acc: 0.865387 ,val loss : 0.380744 ,val acc : 0.827881\n",
      "[ ecpho : 6  iter :500 ]train loss : 0.266607 ,train acc: 0.877197 ,val loss : 0.384841 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :501 ]train loss : 0.299580 ,train acc: 0.859996 ,val loss : 0.377183 ,val acc : 0.829346\n",
      "[ ecpho : 6  iter :502 ]train loss : 0.341736 ,train acc: 0.853099 ,val loss : 0.387824 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :503 ]train loss : 0.359220 ,train acc: 0.821849 ,val loss : 0.380588 ,val acc : 0.828674\n",
      "[ ecpho : 6  iter :504 ]train loss : 0.406189 ,train acc: 0.832265 ,val loss : 0.383441 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :505 ]train loss : 0.235979 ,train acc: 0.887451 ,val loss : 0.379291 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :506 ]train loss : 0.311268 ,train acc: 0.866170 ,val loss : 0.384178 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :507 ]train loss : 0.296552 ,train acc: 0.860179 ,val loss : 0.381184 ,val acc : 0.828461\n",
      "[ ecpho : 6  iter :508 ]train loss : 0.312578 ,train acc: 0.860392 ,val loss : 0.390651 ,val acc : 0.825745\n",
      "[ ecpho : 6  iter :509 ]train loss : 0.249583 ,train acc: 0.880849 ,val loss : 0.385164 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :510 ]train loss : 0.269324 ,train acc: 0.877096 ,val loss : 0.382963 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :511 ]train loss : 0.382626 ,train acc: 0.832296 ,val loss : 0.385000 ,val acc : 0.824280\n",
      "[ ecpho : 6  iter :512 ]train loss : 0.301403 ,train acc: 0.853740 ,val loss : 0.382281 ,val acc : 0.826782\n",
      "[ ecpho : 6  iter :513 ]train loss : 0.272018 ,train acc: 0.871541 ,val loss : 0.388230 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :514 ]train loss : 0.241769 ,train acc: 0.882263 ,val loss : 0.386754 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :515 ]train loss : 0.275926 ,train acc: 0.862162 ,val loss : 0.379064 ,val acc : 0.828003\n",
      "[ ecpho : 6  iter :516 ]train loss : 0.326281 ,train acc: 0.853516 ,val loss : 0.386022 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :517 ]train loss : 0.375281 ,train acc: 0.833628 ,val loss : 0.384910 ,val acc : 0.827789\n",
      "[ ecpho : 6  iter :518 ]train loss : 0.314573 ,train acc: 0.852580 ,val loss : 0.386705 ,val acc : 0.827484\n",
      "[ ecpho : 6  iter :519 ]train loss : 0.330059 ,train acc: 0.851186 ,val loss : 0.384145 ,val acc : 0.824615\n",
      "[ ecpho : 6  iter :520 ]train loss : 0.260421 ,train acc: 0.876617 ,val loss : 0.380717 ,val acc : 0.828674\n",
      "[ ecpho : 6  iter :521 ]train loss : 0.260917 ,train acc: 0.875010 ,val loss : 0.377553 ,val acc : 0.828949\n",
      "[ ecpho : 6  iter :522 ]train loss : 0.234039 ,train acc: 0.886983 ,val loss : 0.383637 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :523 ]train loss : 0.289627 ,train acc: 0.865652 ,val loss : 0.377440 ,val acc : 0.828644\n",
      "[ ecpho : 6  iter :524 ]train loss : 0.305186 ,train acc: 0.855611 ,val loss : 0.381573 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :525 ]train loss : 0.260692 ,train acc: 0.875651 ,val loss : 0.389116 ,val acc : 0.824615\n",
      "[ ecpho : 6  iter :526 ]train loss : 0.268406 ,train acc: 0.878448 ,val loss : 0.382886 ,val acc : 0.826202\n",
      "[ ecpho : 6  iter :527 ]train loss : 0.280924 ,train acc: 0.869690 ,val loss : 0.381280 ,val acc : 0.828644\n",
      "[ ecpho : 6  iter :528 ]train loss : 0.305675 ,train acc: 0.858622 ,val loss : 0.379858 ,val acc : 0.831177\n",
      "[ ecpho : 6  iter :529 ]train loss : 0.234426 ,train acc: 0.883443 ,val loss : 0.381130 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :530 ]train loss : 0.319224 ,train acc: 0.855103 ,val loss : 0.387155 ,val acc : 0.824768\n",
      "[ ecpho : 6  iter :531 ]train loss : 0.327942 ,train acc: 0.826701 ,val loss : 0.386887 ,val acc : 0.825256\n",
      "[ ecpho : 6  iter :532 ]train loss : 0.636332 ,train acc: 0.754751 ,val loss : 0.380901 ,val acc : 0.829651\n",
      "[ ecpho : 6  iter :533 ]train loss : 0.310016 ,train acc: 0.860392 ,val loss : 0.383865 ,val acc : 0.823792\n",
      "[ ecpho : 6  iter :534 ]train loss : 0.322293 ,train acc: 0.860789 ,val loss : 0.386849 ,val acc : 0.827423\n",
      "[ ecpho : 6  iter :535 ]train loss : 0.352177 ,train acc: 0.831187 ,val loss : 0.381958 ,val acc : 0.827209\n",
      "[ ecpho : 6  iter :536 ]train loss : 0.398011 ,train acc: 0.820964 ,val loss : 0.386339 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :537 ]train loss : 0.274813 ,train acc: 0.869008 ,val loss : 0.383364 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :538 ]train loss : 0.259200 ,train acc: 0.877533 ,val loss : 0.381318 ,val acc : 0.829895\n",
      "[ ecpho : 6  iter :539 ]train loss : 0.352839 ,train acc: 0.823558 ,val loss : 0.380963 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :540 ]train loss : 0.317988 ,train acc: 0.865997 ,val loss : 0.383896 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :541 ]train loss : 0.259816 ,train acc: 0.876516 ,val loss : 0.385311 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :542 ]train loss : 0.248020 ,train acc: 0.879364 ,val loss : 0.386848 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :543 ]train loss : 0.309999 ,train acc: 0.868307 ,val loss : 0.384958 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :544 ]train loss : 0.318251 ,train acc: 0.859273 ,val loss : 0.384604 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :545 ]train loss : 0.244087 ,train acc: 0.883077 ,val loss : 0.381831 ,val acc : 0.830078\n",
      "[ ecpho : 6  iter :546 ]train loss : 0.273373 ,train acc: 0.865743 ,val loss : 0.382902 ,val acc : 0.826660\n",
      "[ ecpho : 6  iter :547 ]train loss : 0.244513 ,train acc: 0.879191 ,val loss : 0.383095 ,val acc : 0.824463\n",
      "[ ecpho : 6  iter :548 ]train loss : 0.262946 ,train acc: 0.875214 ,val loss : 0.380428 ,val acc : 0.825897\n",
      "[ ecpho : 6  iter :549 ]train loss : 0.230171 ,train acc: 0.887736 ,val loss : 0.380615 ,val acc : 0.823883\n",
      "[ ecpho : 6  iter :550 ]train loss : 0.276156 ,train acc: 0.870422 ,val loss : 0.380642 ,val acc : 0.826294\n",
      "[ ecpho : 6  iter :551 ]train loss : 0.321119 ,train acc: 0.847565 ,val loss : 0.390622 ,val acc : 0.824219\n",
      "[ ecpho : 6  iter :552 ]train loss : 0.289030 ,train acc: 0.871277 ,val loss : 0.380873 ,val acc : 0.829620\n",
      "[ ecpho : 6  iter :553 ]train loss : 0.406430 ,train acc: 0.823680 ,val loss : 0.389396 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :554 ]train loss : 0.220673 ,train acc: 0.895935 ,val loss : 0.380478 ,val acc : 0.828003\n",
      "[ ecpho : 6  iter :555 ]train loss : 0.266879 ,train acc: 0.874807 ,val loss : 0.385868 ,val acc : 0.823944\n",
      "[ ecpho : 6  iter :556 ]train loss : 0.279469 ,train acc: 0.869008 ,val loss : 0.381182 ,val acc : 0.823303\n",
      "[ ecpho : 6  iter :557 ]train loss : 0.259317 ,train acc: 0.876139 ,val loss : 0.384249 ,val acc : 0.827393\n",
      "[ ecpho : 6  iter :558 ]train loss : 0.284258 ,train acc: 0.870606 ,val loss : 0.386680 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :559 ]train loss : 0.285850 ,train acc: 0.865062 ,val loss : 0.382589 ,val acc : 0.827850\n",
      "[ ecpho : 6  iter :560 ]train loss : 0.371012 ,train acc: 0.806753 ,val loss : 0.376881 ,val acc : 0.831207\n",
      "[ ecpho : 6  iter :561 ]train loss : 0.402329 ,train acc: 0.823191 ,val loss : 0.378198 ,val acc : 0.831879\n",
      "[ ecpho : 6  iter :562 ]train loss : 0.285630 ,train acc: 0.861226 ,val loss : 0.383793 ,val acc : 0.824799\n",
      "[ ecpho : 6  iter :563 ]train loss : 0.215351 ,train acc: 0.895111 ,val loss : 0.380408 ,val acc : 0.828735\n",
      "[ ecpho : 6  iter :564 ]train loss : 0.304387 ,train acc: 0.860362 ,val loss : 0.380628 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :565 ]train loss : 0.359388 ,train acc: 0.818604 ,val loss : 0.384498 ,val acc : 0.829956\n",
      "[ ecpho : 6  iter :566 ]train loss : 0.371935 ,train acc: 0.816386 ,val loss : 0.381660 ,val acc : 0.828918\n",
      "[ ecpho : 6  iter :567 ]train loss : 0.417213 ,train acc: 0.809886 ,val loss : 0.389413 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :568 ]train loss : 0.276921 ,train acc: 0.870168 ,val loss : 0.388849 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :569 ]train loss : 0.304424 ,train acc: 0.865794 ,val loss : 0.380866 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :570 ]train loss : 0.325534 ,train acc: 0.835765 ,val loss : 0.386717 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :571 ]train loss : 0.317516 ,train acc: 0.856059 ,val loss : 0.389168 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :572 ]train loss : 0.287021 ,train acc: 0.860647 ,val loss : 0.381034 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :573 ]train loss : 0.250838 ,train acc: 0.884216 ,val loss : 0.375630 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :574 ]train loss : 0.283921 ,train acc: 0.868724 ,val loss : 0.384916 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :575 ]train loss : 0.336010 ,train acc: 0.855103 ,val loss : 0.385630 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :576 ]train loss : 0.226741 ,train acc: 0.890859 ,val loss : 0.387089 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :577 ]train loss : 0.243501 ,train acc: 0.887044 ,val loss : 0.382036 ,val acc : 0.828400\n",
      "[ ecpho : 6  iter :578 ]train loss : 0.278078 ,train acc: 0.869781 ,val loss : 0.383319 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :579 ]train loss : 0.342873 ,train acc: 0.836904 ,val loss : 0.385380 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :580 ]train loss : 0.244436 ,train acc: 0.880503 ,val loss : 0.382077 ,val acc : 0.823822\n",
      "[ ecpho : 6  iter :581 ]train loss : 0.342780 ,train acc: 0.825714 ,val loss : 0.386094 ,val acc : 0.826660\n",
      "[ ecpho : 6  iter :582 ]train loss : 0.322644 ,train acc: 0.860006 ,val loss : 0.385108 ,val acc : 0.828461\n",
      "[ ecpho : 6  iter :583 ]train loss : 0.250786 ,train acc: 0.882965 ,val loss : 0.380948 ,val acc : 0.826935\n",
      "[ ecpho : 6  iter :584 ]train loss : 0.246705 ,train acc: 0.884237 ,val loss : 0.377293 ,val acc : 0.830750\n",
      "[ ecpho : 6  iter :585 ]train loss : 0.276778 ,train acc: 0.867554 ,val loss : 0.378368 ,val acc : 0.829224\n",
      "[ ecpho : 6  iter :586 ]train loss : 0.315068 ,train acc: 0.859884 ,val loss : 0.385324 ,val acc : 0.823944\n",
      "[ ecpho : 6  iter :587 ]train loss : 0.267004 ,train acc: 0.872213 ,val loss : 0.382280 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :588 ]train loss : 0.306957 ,train acc: 0.864197 ,val loss : 0.379978 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :589 ]train loss : 0.529255 ,train acc: 0.823334 ,val loss : 0.383209 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :590 ]train loss : 0.285107 ,train acc: 0.869487 ,val loss : 0.382154 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :591 ]train loss : 0.284569 ,train acc: 0.864136 ,val loss : 0.387039 ,val acc : 0.825897\n",
      "[ ecpho : 6  iter :592 ]train loss : 0.332409 ,train acc: 0.834066 ,val loss : 0.386630 ,val acc : 0.824402\n",
      "[ ecpho : 6  iter :593 ]train loss : 0.346369 ,train acc: 0.855794 ,val loss : 0.383800 ,val acc : 0.825928\n",
      "[ ecpho : 6  iter :594 ]train loss : 0.241390 ,train acc: 0.883433 ,val loss : 0.385828 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :595 ]train loss : 0.384118 ,train acc: 0.836558 ,val loss : 0.387177 ,val acc : 0.824646\n",
      "[ ecpho : 6  iter :596 ]train loss : 0.299821 ,train acc: 0.856445 ,val loss : 0.381072 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :597 ]train loss : 0.252078 ,train acc: 0.881042 ,val loss : 0.376979 ,val acc : 0.829559\n",
      "[ ecpho : 6  iter :598 ]train loss : 0.270611 ,train acc: 0.875732 ,val loss : 0.383080 ,val acc : 0.829742\n",
      "[ ecpho : 6  iter :599 ]train loss : 0.353697 ,train acc: 0.819560 ,val loss : 0.385149 ,val acc : 0.825592\n",
      "[ ecpho : 6  iter :600 ]train loss : 0.281516 ,train acc: 0.869344 ,val loss : 0.378049 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :601 ]train loss : 0.278771 ,train acc: 0.860474 ,val loss : 0.386901 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :602 ]train loss : 0.349443 ,train acc: 0.854106 ,val loss : 0.385099 ,val acc : 0.824371\n",
      "[ ecpho : 6  iter :603 ]train loss : 0.270417 ,train acc: 0.861816 ,val loss : 0.390812 ,val acc : 0.824402\n",
      "[ ecpho : 6  iter :604 ]train loss : 0.326694 ,train acc: 0.857442 ,val loss : 0.378619 ,val acc : 0.829895\n",
      "[ ecpho : 6  iter :605 ]train loss : 0.331643 ,train acc: 0.861552 ,val loss : 0.383042 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :606 ]train loss : 0.382037 ,train acc: 0.804800 ,val loss : 0.382823 ,val acc : 0.826904\n",
      "[ ecpho : 6  iter :607 ]train loss : 0.246801 ,train acc: 0.877370 ,val loss : 0.383917 ,val acc : 0.825043\n",
      "[ ecpho : 6  iter :608 ]train loss : 0.242749 ,train acc: 0.882385 ,val loss : 0.379746 ,val acc : 0.827576\n",
      "[ ecpho : 6  iter :609 ]train loss : 0.257438 ,train acc: 0.878398 ,val loss : 0.378913 ,val acc : 0.827850\n",
      "[ ecpho : 6  iter :610 ]train loss : 0.313415 ,train acc: 0.854747 ,val loss : 0.381340 ,val acc : 0.830872\n",
      "[ ecpho : 6  iter :611 ]train loss : 0.235574 ,train acc: 0.884349 ,val loss : 0.382748 ,val acc : 0.827942\n",
      "[ ecpho : 6  iter :612 ]train loss : 0.287236 ,train acc: 0.867676 ,val loss : 0.382308 ,val acc : 0.827148\n",
      "[ ecpho : 6  iter :613 ]train loss : 0.302252 ,train acc: 0.854340 ,val loss : 0.391123 ,val acc : 0.821625\n",
      "[ ecpho : 6  iter :614 ]train loss : 0.248598 ,train acc: 0.877309 ,val loss : 0.374779 ,val acc : 0.829834\n",
      "[ ecpho : 6  iter :615 ]train loss : 0.257730 ,train acc: 0.879476 ,val loss : 0.381832 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :616 ]train loss : 0.341781 ,train acc: 0.795197 ,val loss : 0.388119 ,val acc : 0.823761\n",
      "[ ecpho : 6  iter :617 ]train loss : 0.305487 ,train acc: 0.857717 ,val loss : 0.384305 ,val acc : 0.825348\n",
      "[ ecpho : 6  iter :618 ]train loss : 0.330893 ,train acc: 0.862315 ,val loss : 0.379572 ,val acc : 0.828430\n",
      "[ ecpho : 6  iter :619 ]train loss : 0.314357 ,train acc: 0.855855 ,val loss : 0.379707 ,val acc : 0.828644\n",
      "[ ecpho : 6  iter :620 ]train loss : 0.380523 ,train acc: 0.814128 ,val loss : 0.384522 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :621 ]train loss : 0.325612 ,train acc: 0.840749 ,val loss : 0.385633 ,val acc : 0.825226\n",
      "[ ecpho : 6  iter :622 ]train loss : 0.333480 ,train acc: 0.857157 ,val loss : 0.381565 ,val acc : 0.828430\n",
      "[ ecpho : 6  iter :623 ]train loss : 0.342249 ,train acc: 0.850657 ,val loss : 0.384434 ,val acc : 0.827881\n",
      "[ ecpho : 6  iter :624 ]train loss : 0.342211 ,train acc: 0.788696 ,val loss : 0.382516 ,val acc : 0.827728\n",
      "[ ecpho : 6  iter :625 ]train loss : 0.406550 ,train acc: 0.813538 ,val loss : 0.383999 ,val acc : 0.830078\n",
      "[ ecpho : 6  iter :626 ]train loss : 0.242300 ,train acc: 0.882233 ,val loss : 0.379595 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :627 ]train loss : 0.285333 ,train acc: 0.867391 ,val loss : 0.388026 ,val acc : 0.824585\n",
      "[ ecpho : 6  iter :628 ]train loss : 0.308480 ,train acc: 0.852936 ,val loss : 0.384125 ,val acc : 0.825531\n",
      "[ ecpho : 6  iter :629 ]train loss : 0.247766 ,train acc: 0.881480 ,val loss : 0.377716 ,val acc : 0.829590\n",
      "[ ecpho : 6  iter :630 ]train loss : 0.354876 ,train acc: 0.823670 ,val loss : 0.384987 ,val acc : 0.827545\n",
      "[ ecpho : 6  iter :631 ]train loss : 0.579868 ,train acc: 0.789286 ,val loss : 0.379796 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :632 ]train loss : 0.325212 ,train acc: 0.850047 ,val loss : 0.381898 ,val acc : 0.829071\n",
      "[ ecpho : 6  iter :633 ]train loss : 0.301363 ,train acc: 0.861369 ,val loss : 0.385681 ,val acc : 0.820526\n",
      "[ ecpho : 6  iter :634 ]train loss : 0.261450 ,train acc: 0.872406 ,val loss : 0.380453 ,val acc : 0.824310\n",
      "[ ecpho : 6  iter :635 ]train loss : 0.285025 ,train acc: 0.870361 ,val loss : 0.381361 ,val acc : 0.828430\n",
      "[ ecpho : 6  iter :636 ]train loss : 0.375744 ,train acc: 0.851756 ,val loss : 0.377680 ,val acc : 0.830902\n",
      "[ ecpho : 6  iter :637 ]train loss : 0.275773 ,train acc: 0.866536 ,val loss : 0.386568 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :638 ]train loss : 0.297073 ,train acc: 0.857615 ,val loss : 0.381613 ,val acc : 0.827545\n",
      "[ ecpho : 6  iter :639 ]train loss : 0.291366 ,train acc: 0.866526 ,val loss : 0.383744 ,val acc : 0.826447\n",
      "[ ecpho : 6  iter :640 ]train loss : 0.245678 ,train acc: 0.881226 ,val loss : 0.385534 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :641 ]train loss : 0.329317 ,train acc: 0.855428 ,val loss : 0.382564 ,val acc : 0.828613\n",
      "[ ecpho : 6  iter :642 ]train loss : 0.319458 ,train acc: 0.854655 ,val loss : 0.379886 ,val acc : 0.825470\n",
      "[ ecpho : 6  iter :643 ]train loss : 0.321790 ,train acc: 0.860524 ,val loss : 0.386674 ,val acc : 0.824890\n",
      "[ ecpho : 6  iter :644 ]train loss : 0.239815 ,train acc: 0.883077 ,val loss : 0.383415 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :645 ]train loss : 0.310551 ,train acc: 0.834880 ,val loss : 0.382279 ,val acc : 0.824432\n",
      "[ ecpho : 6  iter :646 ]train loss : 0.311396 ,train acc: 0.840912 ,val loss : 0.382557 ,val acc : 0.825073\n",
      "[ ecpho : 6  iter :647 ]train loss : 0.303584 ,train acc: 0.866913 ,val loss : 0.385566 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :648 ]train loss : 0.321909 ,train acc: 0.851939 ,val loss : 0.383712 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :649 ]train loss : 0.366578 ,train acc: 0.843516 ,val loss : 0.380002 ,val acc : 0.826782\n",
      "[ ecpho : 6  iter :650 ]train loss : 0.263431 ,train acc: 0.873708 ,val loss : 0.378677 ,val acc : 0.827148\n",
      "[ ecpho : 6  iter :651 ]train loss : 0.272864 ,train acc: 0.877604 ,val loss : 0.378120 ,val acc : 0.828796\n",
      "[ ecpho : 6  iter :652 ]train loss : 0.221982 ,train acc: 0.891022 ,val loss : 0.383138 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :653 ]train loss : 0.358239 ,train acc: 0.812714 ,val loss : 0.379779 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :654 ]train loss : 0.275003 ,train acc: 0.870860 ,val loss : 0.387547 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :655 ]train loss : 0.337725 ,train acc: 0.823425 ,val loss : 0.385162 ,val acc : 0.826935\n",
      "[ ecpho : 6  iter :656 ]train loss : 0.304483 ,train acc: 0.856221 ,val loss : 0.386806 ,val acc : 0.826538\n",
      "[ ecpho : 6  iter :657 ]train loss : 0.304559 ,train acc: 0.855784 ,val loss : 0.378684 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :658 ]train loss : 0.263534 ,train acc: 0.876811 ,val loss : 0.385667 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :659 ]train loss : 0.275693 ,train acc: 0.869629 ,val loss : 0.383367 ,val acc : 0.824097\n",
      "[ ecpho : 6  iter :660 ]train loss : 0.249491 ,train acc: 0.878520 ,val loss : 0.382399 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :661 ]train loss : 0.356663 ,train acc: 0.807241 ,val loss : 0.383429 ,val acc : 0.828094\n",
      "[ ecpho : 6  iter :662 ]train loss : 0.241037 ,train acc: 0.881927 ,val loss : 0.379801 ,val acc : 0.829041\n",
      "[ ecpho : 6  iter :663 ]train loss : 0.278331 ,train acc: 0.872121 ,val loss : 0.386674 ,val acc : 0.824554\n",
      "[ ecpho : 6  iter :664 ]train loss : 0.310622 ,train acc: 0.854635 ,val loss : 0.383397 ,val acc : 0.827972\n",
      "[ ecpho : 6  iter :665 ]train loss : 0.234011 ,train acc: 0.888509 ,val loss : 0.376457 ,val acc : 0.828705\n",
      "[ ecpho : 6  iter :666 ]train loss : 0.311806 ,train acc: 0.859874 ,val loss : 0.385316 ,val acc : 0.827240\n",
      "[ ecpho : 6  iter :667 ]train loss : 0.362248 ,train acc: 0.801107 ,val loss : 0.390002 ,val acc : 0.823639\n",
      "[ ecpho : 6  iter :668 ]train loss : 0.456452 ,train acc: 0.755310 ,val loss : 0.382144 ,val acc : 0.829285\n",
      "[ ecpho : 6  iter :669 ]train loss : 0.309876 ,train acc: 0.853160 ,val loss : 0.382848 ,val acc : 0.827942\n",
      "[ ecpho : 6  iter :670 ]train loss : 0.436556 ,train acc: 0.812775 ,val loss : 0.382519 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :671 ]train loss : 0.307727 ,train acc: 0.850861 ,val loss : 0.381708 ,val acc : 0.826141\n",
      "[ ecpho : 6  iter :672 ]train loss : 0.294632 ,train acc: 0.847107 ,val loss : 0.382728 ,val acc : 0.824310\n",
      "[ ecpho : 6  iter :673 ]train loss : 0.374013 ,train acc: 0.804454 ,val loss : 0.380042 ,val acc : 0.829041\n",
      "[ ecpho : 6  iter :674 ]train loss : 0.321569 ,train acc: 0.859640 ,val loss : 0.380214 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :675 ]train loss : 0.297905 ,train acc: 0.869222 ,val loss : 0.376022 ,val acc : 0.829712\n",
      "[ ecpho : 6  iter :676 ]train loss : 0.281170 ,train acc: 0.872599 ,val loss : 0.384138 ,val acc : 0.826599\n",
      "[ ecpho : 6  iter :677 ]train loss : 0.257279 ,train acc: 0.875244 ,val loss : 0.383148 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :678 ]train loss : 0.262192 ,train acc: 0.875204 ,val loss : 0.384592 ,val acc : 0.827209\n",
      "[ ecpho : 6  iter :679 ]train loss : 0.380462 ,train acc: 0.823446 ,val loss : 0.383198 ,val acc : 0.827576\n",
      "[ ecpho : 6  iter :680 ]train loss : 0.280842 ,train acc: 0.869578 ,val loss : 0.387183 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :681 ]train loss : 0.301942 ,train acc: 0.867127 ,val loss : 0.384855 ,val acc : 0.824768\n",
      "[ ecpho : 6  iter :682 ]train loss : 0.295759 ,train acc: 0.861155 ,val loss : 0.383412 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :683 ]train loss : 0.232319 ,train acc: 0.884766 ,val loss : 0.384320 ,val acc : 0.831329\n",
      "[ ecpho : 6  iter :684 ]train loss : 0.328823 ,train acc: 0.853271 ,val loss : 0.381987 ,val acc : 0.827576\n",
      "[ ecpho : 6  iter :685 ]train loss : 0.289452 ,train acc: 0.869365 ,val loss : 0.380886 ,val acc : 0.826111\n",
      "[ ecpho : 6  iter :686 ]train loss : 0.297752 ,train acc: 0.862681 ,val loss : 0.383654 ,val acc : 0.827026\n",
      "[ ecpho : 6  iter :687 ]train loss : 0.331522 ,train acc: 0.854706 ,val loss : 0.381449 ,val acc : 0.829132\n",
      "[ ecpho : 6  iter :688 ]train loss : 0.344165 ,train acc: 0.822602 ,val loss : 0.387658 ,val acc : 0.825623\n",
      "[ ecpho : 6  iter :689 ]train loss : 0.262552 ,train acc: 0.877442 ,val loss : 0.376009 ,val acc : 0.828491\n",
      "[ ecpho : 6  iter :690 ]train loss : 0.365114 ,train acc: 0.837372 ,val loss : 0.381299 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :691 ]train loss : 0.402353 ,train acc: 0.845266 ,val loss : 0.387652 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :692 ]train loss : 0.335476 ,train acc: 0.824544 ,val loss : 0.379298 ,val acc : 0.828003\n",
      "[ ecpho : 6  iter :693 ]train loss : 0.342293 ,train acc: 0.827108 ,val loss : 0.379517 ,val acc : 0.829834\n",
      "[ ecpho : 6  iter :694 ]train loss : 0.251292 ,train acc: 0.880920 ,val loss : 0.383122 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :695 ]train loss : 0.381414 ,train acc: 0.810242 ,val loss : 0.383388 ,val acc : 0.826813\n",
      "[ ecpho : 6  iter :696 ]train loss : 0.409470 ,train acc: 0.799001 ,val loss : 0.378195 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :697 ]train loss : 0.267436 ,train acc: 0.866648 ,val loss : 0.384625 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :698 ]train loss : 0.251311 ,train acc: 0.881602 ,val loss : 0.376187 ,val acc : 0.829010\n",
      "[ ecpho : 6  iter :699 ]train loss : 0.242550 ,train acc: 0.881795 ,val loss : 0.380809 ,val acc : 0.826019\n",
      "[ ecpho : 6  iter :700 ]train loss : 0.276804 ,train acc: 0.870748 ,val loss : 0.387008 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :701 ]train loss : 0.280526 ,train acc: 0.858755 ,val loss : 0.390078 ,val acc : 0.825226\n",
      "[ ecpho : 6  iter :702 ]train loss : 0.247886 ,train acc: 0.879466 ,val loss : 0.383095 ,val acc : 0.825226\n",
      "[ ecpho : 6  iter :703 ]train loss : 0.269660 ,train acc: 0.877482 ,val loss : 0.379731 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :704 ]train loss : 0.411241 ,train acc: 0.827464 ,val loss : 0.383385 ,val acc : 0.825653\n",
      "[ ecpho : 6  iter :705 ]train loss : 0.319868 ,train acc: 0.843689 ,val loss : 0.383576 ,val acc : 0.823761\n",
      "[ ecpho : 6  iter :706 ]train loss : 0.256120 ,train acc: 0.876699 ,val loss : 0.380735 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :707 ]train loss : 0.383959 ,train acc: 0.811503 ,val loss : 0.383500 ,val acc : 0.824921\n",
      "[ ecpho : 6  iter :708 ]train loss : 0.512281 ,train acc: 0.811218 ,val loss : 0.383803 ,val acc : 0.827423\n",
      "[ ecpho : 6  iter :709 ]train loss : 0.252997 ,train acc: 0.877960 ,val loss : 0.382834 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :710 ]train loss : 0.251427 ,train acc: 0.877004 ,val loss : 0.383705 ,val acc : 0.829559\n",
      "[ ecpho : 6  iter :711 ]train loss : 0.381765 ,train acc: 0.767568 ,val loss : 0.385779 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :712 ]train loss : 0.304781 ,train acc: 0.852905 ,val loss : 0.378440 ,val acc : 0.828613\n",
      "[ ecpho : 6  iter :713 ]train loss : 0.289106 ,train acc: 0.848155 ,val loss : 0.381834 ,val acc : 0.828918\n",
      "[ ecpho : 6  iter :714 ]train loss : 0.280113 ,train acc: 0.873088 ,val loss : 0.381681 ,val acc : 0.825439\n",
      "[ ecpho : 6  iter :715 ]train loss : 0.403011 ,train acc: 0.811635 ,val loss : 0.381526 ,val acc : 0.825745\n",
      "[ ecpho : 6  iter :716 ]train loss : 0.276517 ,train acc: 0.867025 ,val loss : 0.385714 ,val acc : 0.825684\n",
      "[ ecpho : 6  iter :717 ]train loss : 0.321978 ,train acc: 0.831757 ,val loss : 0.387587 ,val acc : 0.828796\n",
      "[ ecpho : 6  iter :718 ]train loss : 0.362630 ,train acc: 0.849905 ,val loss : 0.385877 ,val acc : 0.823517\n",
      "[ ecpho : 6  iter :719 ]train loss : 0.239281 ,train acc: 0.881927 ,val loss : 0.379951 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :720 ]train loss : 0.252005 ,train acc: 0.877563 ,val loss : 0.383187 ,val acc : 0.823212\n",
      "[ ecpho : 6  iter :721 ]train loss : 0.312844 ,train acc: 0.830709 ,val loss : 0.389047 ,val acc : 0.826324\n",
      "[ ecpho : 6  iter :722 ]train loss : 0.334816 ,train acc: 0.847422 ,val loss : 0.382647 ,val acc : 0.828918\n",
      "[ ecpho : 6  iter :723 ]train loss : 0.243392 ,train acc: 0.883148 ,val loss : 0.382743 ,val acc : 0.824890\n",
      "[ ecpho : 6  iter :724 ]train loss : 0.287205 ,train acc: 0.866252 ,val loss : 0.380195 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :725 ]train loss : 0.442121 ,train acc: 0.835999 ,val loss : 0.385340 ,val acc : 0.825012\n",
      "[ ecpho : 6  iter :726 ]train loss : 0.260079 ,train acc: 0.877024 ,val loss : 0.380626 ,val acc : 0.828339\n",
      "[ ecpho : 6  iter :727 ]train loss : 0.241099 ,train acc: 0.882507 ,val loss : 0.378891 ,val acc : 0.829590\n",
      "[ ecpho : 6  iter :728 ]train loss : 0.519986 ,train acc: 0.809754 ,val loss : 0.386298 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :729 ]train loss : 0.368472 ,train acc: 0.851176 ,val loss : 0.379416 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :730 ]train loss : 0.413502 ,train acc: 0.788340 ,val loss : 0.378643 ,val acc : 0.828064\n",
      "[ ecpho : 6  iter :731 ]train loss : 0.329849 ,train acc: 0.857503 ,val loss : 0.379197 ,val acc : 0.829224\n",
      "[ ecpho : 6  iter :732 ]train loss : 0.313926 ,train acc: 0.861460 ,val loss : 0.388971 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :733 ]train loss : 0.247218 ,train acc: 0.882589 ,val loss : 0.382290 ,val acc : 0.827698\n",
      "[ ecpho : 6  iter :734 ]train loss : 0.308030 ,train acc: 0.836283 ,val loss : 0.378043 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :735 ]train loss : 0.298890 ,train acc: 0.854096 ,val loss : 0.387994 ,val acc : 0.824371\n",
      "[ ecpho : 6  iter :736 ]train loss : 0.299151 ,train acc: 0.863983 ,val loss : 0.385439 ,val acc : 0.824402\n",
      "[ ecpho : 6  iter :737 ]train loss : 0.285015 ,train acc: 0.870433 ,val loss : 0.383609 ,val acc : 0.827698\n",
      "[ ecpho : 6  iter :738 ]train loss : 0.253155 ,train acc: 0.884227 ,val loss : 0.383975 ,val acc : 0.823761\n",
      "[ ecpho : 6  iter :739 ]train loss : 0.238854 ,train acc: 0.884349 ,val loss : 0.391232 ,val acc : 0.824158\n",
      "[ ecpho : 6  iter :740 ]train loss : 0.247356 ,train acc: 0.880442 ,val loss : 0.384234 ,val acc : 0.824982\n",
      "[ ecpho : 6  iter :741 ]train loss : 0.324544 ,train acc: 0.826040 ,val loss : 0.384082 ,val acc : 0.826538\n",
      "[ ecpho : 6  iter :742 ]train loss : 0.279514 ,train acc: 0.868825 ,val loss : 0.379997 ,val acc : 0.831146\n",
      "[ ecpho : 6  iter :743 ]train loss : 0.303650 ,train acc: 0.863220 ,val loss : 0.388449 ,val acc : 0.825714\n",
      "[ ecpho : 6  iter :744 ]train loss : 0.253629 ,train acc: 0.875193 ,val loss : 0.388558 ,val acc : 0.827393\n",
      "[ ecpho : 6  iter :745 ]train loss : 0.265600 ,train acc: 0.874542 ,val loss : 0.376843 ,val acc : 0.830200\n",
      "[ ecpho : 6  iter :746 ]train loss : 0.266146 ,train acc: 0.871470 ,val loss : 0.382276 ,val acc : 0.831421\n",
      "[ ecpho : 6  iter :747 ]train loss : 0.262935 ,train acc: 0.874563 ,val loss : 0.383975 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :748 ]train loss : 0.259127 ,train acc: 0.876628 ,val loss : 0.379228 ,val acc : 0.828735\n",
      "[ ecpho : 6  iter :749 ]train loss : 0.280023 ,train acc: 0.869914 ,val loss : 0.383613 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :750 ]train loss : 0.290000 ,train acc: 0.864349 ,val loss : 0.380687 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :751 ]train loss : 0.301229 ,train acc: 0.863464 ,val loss : 0.375540 ,val acc : 0.827881\n",
      "[ ecpho : 6  iter :752 ]train loss : 0.287965 ,train acc: 0.868571 ,val loss : 0.377125 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :753 ]train loss : 0.233680 ,train acc: 0.884481 ,val loss : 0.384738 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :754 ]train loss : 0.286978 ,train acc: 0.863169 ,val loss : 0.384507 ,val acc : 0.828430\n",
      "[ ecpho : 6  iter :755 ]train loss : 0.357978 ,train acc: 0.811056 ,val loss : 0.382889 ,val acc : 0.830872\n",
      "[ ecpho : 6  iter :756 ]train loss : 0.257557 ,train acc: 0.880198 ,val loss : 0.384306 ,val acc : 0.824738\n",
      "[ ecpho : 6  iter :757 ]train loss : 0.280864 ,train acc: 0.867676 ,val loss : 0.380033 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :758 ]train loss : 0.331607 ,train acc: 0.850556 ,val loss : 0.384437 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :759 ]train loss : 0.437225 ,train acc: 0.795980 ,val loss : 0.383860 ,val acc : 0.829590\n",
      "[ ecpho : 6  iter :760 ]train loss : 0.329871 ,train acc: 0.859406 ,val loss : 0.383866 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :761 ]train loss : 0.264747 ,train acc: 0.872315 ,val loss : 0.385957 ,val acc : 0.829681\n",
      "[ ecpho : 6  iter :762 ]train loss : 0.321494 ,train acc: 0.861247 ,val loss : 0.385426 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :763 ]train loss : 0.304600 ,train acc: 0.861125 ,val loss : 0.380476 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :764 ]train loss : 0.292887 ,train acc: 0.865031 ,val loss : 0.382824 ,val acc : 0.827148\n",
      "[ ecpho : 6  iter :765 ]train loss : 0.281950 ,train acc: 0.857219 ,val loss : 0.384914 ,val acc : 0.827393\n",
      "[ ecpho : 6  iter :766 ]train loss : 0.292400 ,train acc: 0.861898 ,val loss : 0.383976 ,val acc : 0.824493\n",
      "[ ecpho : 6  iter :767 ]train loss : 0.325860 ,train acc: 0.849986 ,val loss : 0.390290 ,val acc : 0.824493\n",
      "[ ecpho : 6  iter :768 ]train loss : 0.280599 ,train acc: 0.867737 ,val loss : 0.374350 ,val acc : 0.828583\n",
      "[ ecpho : 6  iter :769 ]train loss : 0.326019 ,train acc: 0.860453 ,val loss : 0.383811 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :770 ]train loss : 0.296028 ,train acc: 0.856557 ,val loss : 0.383830 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :771 ]train loss : 0.296098 ,train acc: 0.860738 ,val loss : 0.382049 ,val acc : 0.829773\n",
      "[ ecpho : 6  iter :772 ]train loss : 0.291325 ,train acc: 0.869395 ,val loss : 0.385753 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :773 ]train loss : 0.313573 ,train acc: 0.860982 ,val loss : 0.382373 ,val acc : 0.828613\n",
      "[ ecpho : 6  iter :774 ]train loss : 0.275649 ,train acc: 0.871765 ,val loss : 0.381094 ,val acc : 0.823608\n",
      "[ ecpho : 6  iter :775 ]train loss : 0.288521 ,train acc: 0.865306 ,val loss : 0.382779 ,val acc : 0.824493\n",
      "[ ecpho : 6  iter :776 ]train loss : 0.327419 ,train acc: 0.850861 ,val loss : 0.386300 ,val acc : 0.826904\n",
      "[ ecpho : 6  iter :777 ]train loss : 0.396181 ,train acc: 0.840892 ,val loss : 0.387307 ,val acc : 0.828308\n",
      "[ ecpho : 6  iter :778 ]train loss : 0.287446 ,train acc: 0.868500 ,val loss : 0.383657 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :779 ]train loss : 0.400856 ,train acc: 0.838043 ,val loss : 0.381408 ,val acc : 0.828949\n",
      "[ ecpho : 6  iter :780 ]train loss : 0.329312 ,train acc: 0.854452 ,val loss : 0.383676 ,val acc : 0.826965\n",
      "[ ecpho : 6  iter :781 ]train loss : 0.352508 ,train acc: 0.799937 ,val loss : 0.384042 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :782 ]train loss : 0.314823 ,train acc: 0.861694 ,val loss : 0.382589 ,val acc : 0.828705\n",
      "[ ecpho : 6  iter :783 ]train loss : 0.285482 ,train acc: 0.871836 ,val loss : 0.380608 ,val acc : 0.826904\n",
      "[ ecpho : 6  iter :784 ]train loss : 0.315452 ,train acc: 0.866130 ,val loss : 0.387053 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :785 ]train loss : 0.249765 ,train acc: 0.883057 ,val loss : 0.382777 ,val acc : 0.827972\n",
      "[ ecpho : 6  iter :786 ]train loss : 0.271519 ,train acc: 0.871877 ,val loss : 0.379673 ,val acc : 0.828430\n",
      "[ ecpho : 6  iter :787 ]train loss : 0.261302 ,train acc: 0.870484 ,val loss : 0.385223 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :788 ]train loss : 0.285585 ,train acc: 0.860443 ,val loss : 0.387402 ,val acc : 0.827057\n",
      "[ ecpho : 6  iter :789 ]train loss : 0.333083 ,train acc: 0.862386 ,val loss : 0.380862 ,val acc : 0.828400\n",
      "[ ecpho : 6  iter :790 ]train loss : 0.308642 ,train acc: 0.857442 ,val loss : 0.383971 ,val acc : 0.824219\n",
      "[ ecpho : 6  iter :791 ]train loss : 0.248958 ,train acc: 0.885122 ,val loss : 0.383784 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :792 ]train loss : 0.291207 ,train acc: 0.851664 ,val loss : 0.382553 ,val acc : 0.827698\n",
      "[ ecpho : 6  iter :793 ]train loss : 0.277512 ,train acc: 0.865936 ,val loss : 0.382497 ,val acc : 0.827637\n",
      "[ ecpho : 6  iter :794 ]train loss : 0.300693 ,train acc: 0.868103 ,val loss : 0.380760 ,val acc : 0.829407\n",
      "[ ecpho : 6  iter :795 ]train loss : 0.372079 ,train acc: 0.846283 ,val loss : 0.385232 ,val acc : 0.823730\n",
      "[ ecpho : 6  iter :796 ]train loss : 0.292091 ,train acc: 0.862661 ,val loss : 0.381907 ,val acc : 0.828522\n",
      "[ ecpho : 6  iter :797 ]train loss : 0.346634 ,train acc: 0.847422 ,val loss : 0.381638 ,val acc : 0.826019\n",
      "[ ecpho : 6  iter :798 ]train loss : 0.269251 ,train acc: 0.873077 ,val loss : 0.381456 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :799 ]train loss : 0.254653 ,train acc: 0.875315 ,val loss : 0.386222 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :800 ]train loss : 0.298743 ,train acc: 0.866913 ,val loss : 0.379366 ,val acc : 0.831909\n",
      "[ ecpho : 6  iter :801 ]train loss : 0.343815 ,train acc: 0.813823 ,val loss : 0.380120 ,val acc : 0.829163\n",
      "[ ecpho : 6  iter :802 ]train loss : 0.239184 ,train acc: 0.884033 ,val loss : 0.382616 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :803 ]train loss : 0.287422 ,train acc: 0.870453 ,val loss : 0.385252 ,val acc : 0.826935\n",
      "[ ecpho : 6  iter :804 ]train loss : 0.249664 ,train acc: 0.878510 ,val loss : 0.386826 ,val acc : 0.827942\n",
      "[ ecpho : 6  iter :805 ]train loss : 0.380513 ,train acc: 0.841645 ,val loss : 0.387608 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :806 ]train loss : 0.293362 ,train acc: 0.862193 ,val loss : 0.382453 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :807 ]train loss : 0.226184 ,train acc: 0.889984 ,val loss : 0.389301 ,val acc : 0.824463\n",
      "[ ecpho : 6  iter :808 ]train loss : 0.314203 ,train acc: 0.857056 ,val loss : 0.379680 ,val acc : 0.829193\n",
      "[ ecpho : 6  iter :809 ]train loss : 0.262816 ,train acc: 0.877828 ,val loss : 0.388295 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :810 ]train loss : 0.288675 ,train acc: 0.862366 ,val loss : 0.383722 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :811 ]train loss : 0.265955 ,train acc: 0.870178 ,val loss : 0.378172 ,val acc : 0.830048\n",
      "[ ecpho : 6  iter :812 ]train loss : 0.422508 ,train acc: 0.752197 ,val loss : 0.383085 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :813 ]train loss : 0.253313 ,train acc: 0.877899 ,val loss : 0.382492 ,val acc : 0.828064\n",
      "[ ecpho : 6  iter :814 ]train loss : 0.289255 ,train acc: 0.864268 ,val loss : 0.387068 ,val acc : 0.827026\n",
      "[ ecpho : 6  iter :815 ]train loss : 0.300905 ,train acc: 0.864187 ,val loss : 0.387379 ,val acc : 0.826599\n",
      "[ ecpho : 6  iter :816 ]train loss : 0.342269 ,train acc: 0.847056 ,val loss : 0.384438 ,val acc : 0.826172\n",
      "[ ecpho : 6  iter :817 ]train loss : 0.337382 ,train acc: 0.822876 ,val loss : 0.384453 ,val acc : 0.825104\n",
      "[ ecpho : 6  iter :818 ]train loss : 0.514131 ,train acc: 0.800527 ,val loss : 0.383448 ,val acc : 0.829529\n",
      "[ ecpho : 6  iter :819 ]train loss : 0.331152 ,train acc: 0.858409 ,val loss : 0.387209 ,val acc : 0.825958\n",
      "[ ecpho : 6  iter :820 ]train loss : 0.304614 ,train acc: 0.863210 ,val loss : 0.379593 ,val acc : 0.830658\n",
      "[ ecpho : 6  iter :821 ]train loss : 0.318922 ,train acc: 0.850973 ,val loss : 0.384958 ,val acc : 0.826080\n",
      "[ ecpho : 6  iter :822 ]train loss : 0.261321 ,train acc: 0.884186 ,val loss : 0.382044 ,val acc : 0.830231\n",
      "[ ecpho : 6  iter :823 ]train loss : 0.311347 ,train acc: 0.857564 ,val loss : 0.386104 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :824 ]train loss : 0.280778 ,train acc: 0.870199 ,val loss : 0.382544 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :825 ]train loss : 0.324960 ,train acc: 0.843903 ,val loss : 0.384700 ,val acc : 0.822357\n",
      "[ ecpho : 6  iter :826 ]train loss : 0.329172 ,train acc: 0.843842 ,val loss : 0.379848 ,val acc : 0.828461\n",
      "[ ecpho : 6  iter :827 ]train loss : 0.262992 ,train acc: 0.876373 ,val loss : 0.380528 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :828 ]train loss : 0.356507 ,train acc: 0.810689 ,val loss : 0.381783 ,val acc : 0.825897\n",
      "[ ecpho : 6  iter :829 ]train loss : 0.355192 ,train acc: 0.812347 ,val loss : 0.378955 ,val acc : 0.827362\n",
      "[ ecpho : 6  iter :830 ]train loss : 0.463091 ,train acc: 0.822154 ,val loss : 0.373882 ,val acc : 0.829834\n",
      "[ ecpho : 6  iter :831 ]train loss : 0.337986 ,train acc: 0.835785 ,val loss : 0.382734 ,val acc : 0.823212\n",
      "[ ecpho : 6  iter :832 ]train loss : 0.341298 ,train acc: 0.813914 ,val loss : 0.384988 ,val acc : 0.825134\n",
      "[ ecpho : 6  iter :833 ]train loss : 0.259496 ,train acc: 0.875865 ,val loss : 0.379074 ,val acc : 0.826630\n",
      "[ ecpho : 6  iter :834 ]train loss : 0.289836 ,train acc: 0.866943 ,val loss : 0.383850 ,val acc : 0.824829\n",
      "[ ecpho : 6  iter :835 ]train loss : 0.323344 ,train acc: 0.844452 ,val loss : 0.387057 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :836 ]train loss : 0.271149 ,train acc: 0.875407 ,val loss : 0.382317 ,val acc : 0.827911\n",
      "[ ecpho : 6  iter :837 ]train loss : 0.290174 ,train acc: 0.854004 ,val loss : 0.383605 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :838 ]train loss : 0.286611 ,train acc: 0.869975 ,val loss : 0.388716 ,val acc : 0.823792\n",
      "[ ecpho : 6  iter :839 ]train loss : 0.358440 ,train acc: 0.847636 ,val loss : 0.381799 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :840 ]train loss : 0.267084 ,train acc: 0.878011 ,val loss : 0.383465 ,val acc : 0.826416\n",
      "[ ecpho : 6  iter :841 ]train loss : 0.335027 ,train acc: 0.862122 ,val loss : 0.383817 ,val acc : 0.827606\n",
      "[ ecpho : 6  iter :842 ]train loss : 0.527691 ,train acc: 0.770315 ,val loss : 0.380670 ,val acc : 0.825500\n",
      "[ ecpho : 6  iter :843 ]train loss : 0.309636 ,train acc: 0.860403 ,val loss : 0.379606 ,val acc : 0.828400\n",
      "[ ecpho : 6  iter :844 ]train loss : 0.283611 ,train acc: 0.857951 ,val loss : 0.378395 ,val acc : 0.828583\n",
      "[ ecpho : 6  iter :845 ]train loss : 0.449857 ,train acc: 0.801229 ,val loss : 0.388175 ,val acc : 0.828064\n",
      "[ ecpho : 6  iter :846 ]train loss : 0.281667 ,train acc: 0.863831 ,val loss : 0.383009 ,val acc : 0.826202\n",
      "[ ecpho : 6  iter :847 ]train loss : 0.314309 ,train acc: 0.833496 ,val loss : 0.384815 ,val acc : 0.828522\n",
      "[ ecpho : 6  iter :848 ]train loss : 0.320654 ,train acc: 0.839600 ,val loss : 0.384203 ,val acc : 0.828949\n",
      "[ ecpho : 6  iter :849 ]train loss : 0.344026 ,train acc: 0.863739 ,val loss : 0.380960 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :850 ]train loss : 0.379303 ,train acc: 0.832052 ,val loss : 0.382800 ,val acc : 0.825348\n",
      "[ ecpho : 6  iter :851 ]train loss : 0.357009 ,train acc: 0.847056 ,val loss : 0.384940 ,val acc : 0.827087\n",
      "[ ecpho : 6  iter :852 ]train loss : 0.261111 ,train acc: 0.873973 ,val loss : 0.381361 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :853 ]train loss : 0.377153 ,train acc: 0.833405 ,val loss : 0.384974 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :854 ]train loss : 0.289467 ,train acc: 0.868398 ,val loss : 0.383852 ,val acc : 0.823517\n",
      "[ ecpho : 6  iter :855 ]train loss : 0.296103 ,train acc: 0.852966 ,val loss : 0.386321 ,val acc : 0.825287\n",
      "[ ecpho : 6  iter :856 ]train loss : 0.352859 ,train acc: 0.805410 ,val loss : 0.382841 ,val acc : 0.828003\n",
      "[ ecpho : 6  iter :857 ]train loss : 0.230970 ,train acc: 0.885620 ,val loss : 0.381810 ,val acc : 0.824463\n",
      "[ ecpho : 6  iter :858 ]train loss : 0.271762 ,train acc: 0.876831 ,val loss : 0.381013 ,val acc : 0.830627\n",
      "[ ecpho : 6  iter :859 ]train loss : 0.268084 ,train acc: 0.872487 ,val loss : 0.381034 ,val acc : 0.825043\n",
      "[ ecpho : 6  iter :860 ]train loss : 0.258499 ,train acc: 0.874634 ,val loss : 0.382836 ,val acc : 0.827332\n",
      "[ ecpho : 6  iter :861 ]train loss : 0.275800 ,train acc: 0.870270 ,val loss : 0.378804 ,val acc : 0.830109\n",
      "[ ecpho : 6  iter :862 ]train loss : 0.314402 ,train acc: 0.858500 ,val loss : 0.383205 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :863 ]train loss : 0.261841 ,train acc: 0.876027 ,val loss : 0.377949 ,val acc : 0.826263\n",
      "[ ecpho : 6  iter :864 ]train loss : 0.273687 ,train acc: 0.867859 ,val loss : 0.382372 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :865 ]train loss : 0.362728 ,train acc: 0.826894 ,val loss : 0.382445 ,val acc : 0.825928\n",
      "[ ecpho : 6  iter :866 ]train loss : 0.242819 ,train acc: 0.881409 ,val loss : 0.386708 ,val acc : 0.826599\n",
      "[ ecpho : 6  iter :867 ]train loss : 0.260817 ,train acc: 0.875203 ,val loss : 0.388423 ,val acc : 0.825989\n",
      "[ ecpho : 6  iter :868 ]train loss : 0.291728 ,train acc: 0.863658 ,val loss : 0.379651 ,val acc : 0.829041\n",
      "[ ecpho : 6  iter :869 ]train loss : 0.350427 ,train acc: 0.852783 ,val loss : 0.380841 ,val acc : 0.829468\n",
      "[ ecpho : 6  iter :870 ]train loss : 0.249232 ,train acc: 0.884216 ,val loss : 0.381579 ,val acc : 0.828094\n",
      "[ ecpho : 6  iter :871 ]train loss : 0.332913 ,train acc: 0.839803 ,val loss : 0.381422 ,val acc : 0.825928\n",
      "[ ecpho : 6  iter :872 ]train loss : 0.396498 ,train acc: 0.801860 ,val loss : 0.388221 ,val acc : 0.822845\n",
      "[ ecpho : 6  iter :873 ]train loss : 0.253383 ,train acc: 0.877909 ,val loss : 0.378780 ,val acc : 0.828613\n",
      "[ ecpho : 6  iter :874 ]train loss : 0.325119 ,train acc: 0.854513 ,val loss : 0.389315 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :875 ]train loss : 0.533663 ,train acc: 0.680684 ,val loss : 0.377727 ,val acc : 0.830963\n",
      "[ ecpho : 6  iter :876 ]train loss : 0.266724 ,train acc: 0.862885 ,val loss : 0.377150 ,val acc : 0.829041\n",
      "[ ecpho : 6  iter :877 ]train loss : 0.232240 ,train acc: 0.887929 ,val loss : 0.382973 ,val acc : 0.825226\n",
      "[ ecpho : 6  iter :878 ]train loss : 0.376935 ,train acc: 0.844167 ,val loss : 0.387758 ,val acc : 0.825775\n",
      "[ ecpho : 6  iter :879 ]train loss : 0.291726 ,train acc: 0.865825 ,val loss : 0.379224 ,val acc : 0.829285\n",
      "[ ecpho : 6  iter :880 ]train loss : 0.263252 ,train acc: 0.876261 ,val loss : 0.385794 ,val acc : 0.828217\n",
      "[ ecpho : 6  iter :881 ]train loss : 0.378114 ,train acc: 0.787191 ,val loss : 0.379580 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :882 ]train loss : 0.339481 ,train acc: 0.822785 ,val loss : 0.381310 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :883 ]train loss : 0.262719 ,train acc: 0.874980 ,val loss : 0.381328 ,val acc : 0.828369\n",
      "[ ecpho : 6  iter :884 ]train loss : 0.238096 ,train acc: 0.882680 ,val loss : 0.379562 ,val acc : 0.823700\n",
      "[ ecpho : 6  iter :885 ]train loss : 0.352468 ,train acc: 0.857402 ,val loss : 0.384476 ,val acc : 0.823944\n",
      "[ ecpho : 6  iter :886 ]train loss : 0.324542 ,train acc: 0.844421 ,val loss : 0.391040 ,val acc : 0.822144\n",
      "[ ecpho : 6  iter :887 ]train loss : 0.390727 ,train acc: 0.796529 ,val loss : 0.378405 ,val acc : 0.830139\n",
      "[ ecpho : 6  iter :888 ]train loss : 0.378943 ,train acc: 0.830332 ,val loss : 0.378430 ,val acc : 0.826508\n",
      "[ ecpho : 6  iter :889 ]train loss : 0.479529 ,train acc: 0.802989 ,val loss : 0.377126 ,val acc : 0.828278\n",
      "[ ecpho : 6  iter :890 ]train loss : 0.252157 ,train acc: 0.878865 ,val loss : 0.382857 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :891 ]train loss : 0.330860 ,train acc: 0.863068 ,val loss : 0.378018 ,val acc : 0.827789\n",
      "[ ecpho : 6  iter :892 ]train loss : 0.277682 ,train acc: 0.872467 ,val loss : 0.382881 ,val acc : 0.825897\n",
      "[ ecpho : 6  iter :893 ]train loss : 0.364532 ,train acc: 0.780935 ,val loss : 0.381503 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :894 ]train loss : 0.256979 ,train acc: 0.874003 ,val loss : 0.380502 ,val acc : 0.828644\n",
      "[ ecpho : 6  iter :895 ]train loss : 0.240147 ,train acc: 0.884257 ,val loss : 0.388489 ,val acc : 0.825409\n",
      "[ ecpho : 6  iter :896 ]train loss : 0.356782 ,train acc: 0.848104 ,val loss : 0.380550 ,val acc : 0.827820\n",
      "[ ecpho : 6  iter :897 ]train loss : 0.299368 ,train acc: 0.858500 ,val loss : 0.383497 ,val acc : 0.827240\n",
      "[ ecpho : 6  iter :898 ]train loss : 0.268380 ,train acc: 0.878103 ,val loss : 0.386276 ,val acc : 0.826355\n",
      "[ ecpho : 6  iter :899 ]train loss : 0.314840 ,train acc: 0.861054 ,val loss : 0.385083 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :900 ]train loss : 0.285358 ,train acc: 0.861409 ,val loss : 0.376865 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :901 ]train loss : 0.274312 ,train acc: 0.865153 ,val loss : 0.383813 ,val acc : 0.826019\n",
      "[ ecpho : 6  iter :902 ]train loss : 0.333678 ,train acc: 0.853231 ,val loss : 0.383680 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :903 ]train loss : 0.233885 ,train acc: 0.885712 ,val loss : 0.381771 ,val acc : 0.829498\n",
      "[ ecpho : 6  iter :904 ]train loss : 0.282572 ,train acc: 0.873118 ,val loss : 0.379443 ,val acc : 0.826843\n",
      "[ ecpho : 6  iter :905 ]train loss : 0.346094 ,train acc: 0.843933 ,val loss : 0.376864 ,val acc : 0.828888\n",
      "[ ecpho : 6  iter :906 ]train loss : 0.407051 ,train acc: 0.798014 ,val loss : 0.378043 ,val acc : 0.827118\n",
      "[ ecpho : 6  iter :907 ]train loss : 0.349450 ,train acc: 0.812347 ,val loss : 0.383781 ,val acc : 0.827393\n",
      "[ ecpho : 6  iter :908 ]train loss : 0.280937 ,train acc: 0.865621 ,val loss : 0.386232 ,val acc : 0.825806\n",
      "[ ecpho : 6  iter :909 ]train loss : 0.393956 ,train acc: 0.799632 ,val loss : 0.378666 ,val acc : 0.830444\n",
      "[ ecpho : 6  iter :910 ]train loss : 0.310801 ,train acc: 0.841583 ,val loss : 0.381928 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :911 ]train loss : 0.320843 ,train acc: 0.852478 ,val loss : 0.382688 ,val acc : 0.826538\n",
      "[ ecpho : 6  iter :912 ]train loss : 0.397503 ,train acc: 0.840861 ,val loss : 0.378406 ,val acc : 0.828247\n",
      "[ ecpho : 6  iter :913 ]train loss : 0.406628 ,train acc: 0.841909 ,val loss : 0.382330 ,val acc : 0.826385\n",
      "[ ecpho : 6  iter :914 ]train loss : 0.265359 ,train acc: 0.871531 ,val loss : 0.381172 ,val acc : 0.828033\n",
      "[ ecpho : 6  iter :915 ]train loss : 0.334572 ,train acc: 0.854604 ,val loss : 0.381517 ,val acc : 0.830597\n",
      "[ ecpho : 6  iter :916 ]train loss : 0.282766 ,train acc: 0.871369 ,val loss : 0.384472 ,val acc : 0.825073\n",
      "[ ecpho : 6  iter :917 ]train loss : 0.319208 ,train acc: 0.830109 ,val loss : 0.382228 ,val acc : 0.828674\n",
      "[ ecpho : 6  iter :918 ]train loss : 0.277093 ,train acc: 0.874542 ,val loss : 0.384630 ,val acc : 0.828461\n",
      "[ ecpho : 6  iter :919 ]train loss : 0.309834 ,train acc: 0.844951 ,val loss : 0.384614 ,val acc : 0.826599\n",
      "[ ecpho : 6  iter :920 ]train loss : 0.334870 ,train acc: 0.851268 ,val loss : 0.390363 ,val acc : 0.823578\n",
      "[ ecpho : 6  iter :921 ]train loss : 0.262181 ,train acc: 0.874705 ,val loss : 0.382973 ,val acc : 0.829498\n",
      "[ ecpho : 6  iter :922 ]train loss : 0.322521 ,train acc: 0.857636 ,val loss : 0.382236 ,val acc : 0.828583\n",
      "[ ecpho : 6  iter :923 ]train loss : 0.303532 ,train acc: 0.857259 ,val loss : 0.389120 ,val acc : 0.828278\n",
      "[ ecpho : 6  iter :924 ]train loss : 0.382395 ,train acc: 0.848318 ,val loss : 0.380350 ,val acc : 0.828094\n",
      "[ ecpho : 6  iter :925 ]train loss : 0.284296 ,train acc: 0.865000 ,val loss : 0.376640 ,val acc : 0.829010\n",
      "[ ecpho : 6  iter :926 ]train loss : 0.247432 ,train acc: 0.879944 ,val loss : 0.384322 ,val acc : 0.827301\n",
      "[ ecpho : 6  iter :927 ]train loss : 0.355980 ,train acc: 0.852102 ,val loss : 0.385383 ,val acc : 0.828400\n",
      "[ ecpho : 6  iter :928 ]train loss : 0.280011 ,train acc: 0.866069 ,val loss : 0.378195 ,val acc : 0.828491\n",
      "[ ecpho : 6  iter :929 ]train loss : 0.262392 ,train acc: 0.878917 ,val loss : 0.381404 ,val acc : 0.825836\n",
      "[ ecpho : 6  iter :930 ]train loss : 0.275007 ,train acc: 0.863210 ,val loss : 0.373905 ,val acc : 0.828766\n",
      "[ ecpho : 6  iter :931 ]train loss : 0.315352 ,train acc: 0.858175 ,val loss : 0.381132 ,val acc : 0.823669\n",
      "[ ecpho : 6  iter :932 ]train loss : 0.269049 ,train acc: 0.869934 ,val loss : 0.384714 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :933 ]train loss : 0.283135 ,train acc: 0.870443 ,val loss : 0.385025 ,val acc : 0.829651\n",
      "[ ecpho : 6  iter :934 ]train loss : 0.276481 ,train acc: 0.879252 ,val loss : 0.383546 ,val acc : 0.826477\n",
      "[ ecpho : 6  iter :935 ]train loss : 0.366959 ,train acc: 0.811361 ,val loss : 0.379790 ,val acc : 0.827515\n",
      "[ ecpho : 6  iter :936 ]train loss : 0.283398 ,train acc: 0.865438 ,val loss : 0.384780 ,val acc : 0.826569\n",
      "[ ecpho : 6  iter :937 ]train loss : 0.250237 ,train acc: 0.880564 ,val loss : 0.378248 ,val acc : 0.828125\n",
      "[ ecpho : 6  iter :938 ]train loss : 0.253604 ,train acc: 0.877055 ,val loss : 0.381959 ,val acc : 0.829681\n",
      "[ ecpho : 6  iter :939 ]train loss : 0.267389 ,train acc: 0.879669 ,val loss : 0.381673 ,val acc : 0.828094\n",
      "[ ecpho : 6  iter :940 ]train loss : 0.302401 ,train acc: 0.863790 ,val loss : 0.382216 ,val acc : 0.828064\n",
      "[ ecpho : 6  iter :941 ]train loss : 0.353503 ,train acc: 0.850077 ,val loss : 0.382766 ,val acc : 0.828156\n",
      "[ ecpho : 6  iter :942 ]train loss : 0.283856 ,train acc: 0.872833 ,val loss : 0.377863 ,val acc : 0.830383\n",
      "[ ecpho : 6  iter :943 ]train loss : 0.284099 ,train acc: 0.868042 ,val loss : 0.383606 ,val acc : 0.827271\n",
      "[ ecpho : 6  iter :944 ]train loss : 0.341857 ,train acc: 0.809652 ,val loss : 0.382503 ,val acc : 0.823608\n",
      "[ ecpho : 6  iter :945 ]train loss : 0.253480 ,train acc: 0.878337 ,val loss : 0.381997 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :946 ]train loss : 0.357052 ,train acc: 0.822744 ,val loss : 0.383978 ,val acc : 0.828705\n",
      "[ ecpho : 6  iter :947 ]train loss : 0.339435 ,train acc: 0.857544 ,val loss : 0.379970 ,val acc : 0.830109\n",
      "[ ecpho : 6  iter :948 ]train loss : 0.264809 ,train acc: 0.878845 ,val loss : 0.377073 ,val acc : 0.834503\n",
      "[ ecpho : 6  iter :949 ]train loss : 0.318705 ,train acc: 0.848582 ,val loss : 0.384311 ,val acc : 0.828888\n",
      "[ ecpho : 6  iter :950 ]train loss : 0.277332 ,train acc: 0.869883 ,val loss : 0.381443 ,val acc : 0.824829\n",
      "[ ecpho : 6  iter :951 ]train loss : 0.387867 ,train acc: 0.795370 ,val loss : 0.380768 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :952 ]train loss : 0.292896 ,train acc: 0.877869 ,val loss : 0.379613 ,val acc : 0.829163\n",
      "[ ecpho : 6  iter :953 ]train loss : 0.308268 ,train acc: 0.863800 ,val loss : 0.384477 ,val acc : 0.825562\n",
      "[ ecpho : 6  iter :954 ]train loss : 0.264013 ,train acc: 0.877564 ,val loss : 0.379846 ,val acc : 0.827362\n",
      "[ ecpho : 6  iter :955 ]train loss : 0.274124 ,train acc: 0.870768 ,val loss : 0.381562 ,val acc : 0.829102\n",
      "[ ecpho : 6  iter :956 ]train loss : 0.294962 ,train acc: 0.854981 ,val loss : 0.385532 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :957 ]train loss : 0.435607 ,train acc: 0.800517 ,val loss : 0.384665 ,val acc : 0.826996\n",
      "[ ecpho : 6  iter :958 ]train loss : 0.265699 ,train acc: 0.869965 ,val loss : 0.375746 ,val acc : 0.829285\n",
      "[ ecpho : 6  iter :959 ]train loss : 0.289450 ,train acc: 0.869955 ,val loss : 0.384239 ,val acc : 0.829620\n",
      "[ ecpho : 6  iter :960 ]train loss : 0.281457 ,train acc: 0.865753 ,val loss : 0.382670 ,val acc : 0.826050\n",
      "[ ecpho : 6  iter :961 ]train loss : 0.360193 ,train acc: 0.816712 ,val loss : 0.383404 ,val acc : 0.824860\n",
      "[ ecpho : 6  iter :962 ]train loss : 0.261980 ,train acc: 0.873464 ,val loss : 0.385152 ,val acc : 0.824158\n",
      "[ ecpho : 6  iter :963 ]train loss : 0.296718 ,train acc: 0.860931 ,val loss : 0.383240 ,val acc : 0.827362\n",
      "[ ecpho : 6  iter :964 ]train loss : 0.251016 ,train acc: 0.880819 ,val loss : 0.384044 ,val acc : 0.824768\n",
      "[ ecpho : 6  iter :965 ]train loss : 0.332969 ,train acc: 0.856557 ,val loss : 0.389987 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :966 ]train loss : 0.357452 ,train acc: 0.809632 ,val loss : 0.379816 ,val acc : 0.831940\n",
      "[ ecpho : 6  iter :967 ]train loss : 0.245736 ,train acc: 0.886444 ,val loss : 0.375181 ,val acc : 0.827179\n",
      "[ ecpho : 6  iter :968 ]train loss : 0.260173 ,train acc: 0.877289 ,val loss : 0.382036 ,val acc : 0.824249\n",
      "[ ecpho : 6  iter :969 ]train loss : 0.262839 ,train acc: 0.873617 ,val loss : 0.383267 ,val acc : 0.826721\n",
      "[ ecpho : 6  iter :970 ]train loss : 0.291338 ,train acc: 0.855733 ,val loss : 0.384241 ,val acc : 0.828583\n",
      "[ ecpho : 6  iter :971 ]train loss : 0.373880 ,train acc: 0.845357 ,val loss : 0.379889 ,val acc : 0.827026\n",
      "[ ecpho : 6  iter :972 ]train loss : 0.359846 ,train acc: 0.818502 ,val loss : 0.384243 ,val acc : 0.829376\n",
      "[ ecpho : 6  iter :973 ]train loss : 0.277720 ,train acc: 0.867401 ,val loss : 0.376868 ,val acc : 0.825165\n",
      "[ ecpho : 6  iter :974 ]train loss : 0.292819 ,train acc: 0.864522 ,val loss : 0.386805 ,val acc : 0.824860\n",
      "[ ecpho : 6  iter :975 ]train loss : 0.270431 ,train acc: 0.876943 ,val loss : 0.381383 ,val acc : 0.830322\n",
      "[ ecpho : 6  iter :976 ]train loss : 0.332082 ,train acc: 0.856903 ,val loss : 0.386300 ,val acc : 0.824890\n",
      "[ ecpho : 6  iter :977 ]train loss : 0.256035 ,train acc: 0.876475 ,val loss : 0.382064 ,val acc : 0.828705\n",
      "[ ecpho : 6  iter :978 ]train loss : 0.308876 ,train acc: 0.862020 ,val loss : 0.384343 ,val acc : 0.824677\n",
      "[ ecpho : 6  iter :979 ]train loss : 0.264574 ,train acc: 0.872548 ,val loss : 0.383970 ,val acc : 0.826874\n",
      "[ ecpho : 6  iter :980 ]train loss : 0.283875 ,train acc: 0.855255 ,val loss : 0.388139 ,val acc : 0.825867\n",
      "[ ecpho : 6  iter :981 ]train loss : 0.261877 ,train acc: 0.873088 ,val loss : 0.388427 ,val acc : 0.825317\n",
      "[ ecpho : 6  iter :982 ]train loss : 0.250709 ,train acc: 0.884603 ,val loss : 0.381679 ,val acc : 0.828278\n",
      "[ ecpho : 6  iter :983 ]train loss : 0.312453 ,train acc: 0.828695 ,val loss : 0.382755 ,val acc : 0.828278\n",
      "[ ecpho : 6  iter :984 ]train loss : 0.287789 ,train acc: 0.867584 ,val loss : 0.383302 ,val acc : 0.828949\n",
      "[ ecpho : 6  iter :985 ]train loss : 0.337829 ,train acc: 0.851522 ,val loss : 0.375133 ,val acc : 0.830292\n",
      "[ ecpho : 6  iter :986 ]train loss : 0.279051 ,train acc: 0.872325 ,val loss : 0.378731 ,val acc : 0.828918\n",
      "[ ecpho : 6  iter :987 ]train loss : 0.257325 ,train acc: 0.877248 ,val loss : 0.378473 ,val acc : 0.826111\n",
      "[ ecpho : 6  iter :988 ]train loss : 0.321523 ,train acc: 0.851552 ,val loss : 0.382672 ,val acc : 0.827789\n",
      "[ ecpho : 6  iter :989 ]train loss : 0.338406 ,train acc: 0.853892 ,val loss : 0.379798 ,val acc : 0.828400\n",
      "[ ecpho : 6  iter :990 ]train loss : 0.242181 ,train acc: 0.883423 ,val loss : 0.385531 ,val acc : 0.825470\n",
      "[ ecpho : 6  iter :991 ]train loss : 0.380646 ,train acc: 0.825257 ,val loss : 0.378528 ,val acc : 0.827362\n",
      "[ ecpho : 6  iter :992 ]train loss : 0.323905 ,train acc: 0.853943 ,val loss : 0.379569 ,val acc : 0.828156\n",
      "[ ecpho : 6  iter :993 ]train loss : 0.293235 ,train acc: 0.862956 ,val loss : 0.383709 ,val acc : 0.829681\n",
      "[ ecpho : 6  iter :994 ]train loss : 0.320006 ,train acc: 0.837057 ,val loss : 0.384106 ,val acc : 0.825378\n",
      "[ ecpho : 6  iter :995 ]train loss : 0.324202 ,train acc: 0.855754 ,val loss : 0.382599 ,val acc : 0.828308\n",
      "[ ecpho : 6  iter :996 ]train loss : 0.262796 ,train acc: 0.877096 ,val loss : 0.384057 ,val acc : 0.822693\n",
      "[ ecpho : 6  iter :997 ]train loss : 0.340106 ,train acc: 0.832510 ,val loss : 0.383315 ,val acc : 0.828522\n",
      "[ ecpho : 6  iter :998 ]train loss : 0.330132 ,train acc: 0.860382 ,val loss : 0.383162 ,val acc : 0.829285\n",
      "[ ecpho : 6  iter :999 ]train loss : 0.331100 ,train acc: 0.852183 ,val loss : 0.385941 ,val acc : 0.826233\n",
      "[ ecpho : 6  iter :1000 ]train loss : 0.231920 ,train acc: 0.888407 ,val loss : 0.386429 ,val acc : 0.828918\n",
      "=============================================\n",
      "[ 6 ] average train loss : 0.311784 train acc : 0.854848\n",
      "[ ecpho : 7  iter :1 ]train loss : 0.297725 ,train acc: 0.848206 ,val loss : 0.378719 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :2 ]train loss : 0.451011 ,train acc: 0.832245 ,val loss : 0.386114 ,val acc : 0.825684\n",
      "[ ecpho : 7  iter :3 ]train loss : 0.243614 ,train acc: 0.883026 ,val loss : 0.381354 ,val acc : 0.830109\n",
      "[ ecpho : 7  iter :4 ]train loss : 0.283338 ,train acc: 0.875956 ,val loss : 0.379919 ,val acc : 0.828918\n",
      "[ ecpho : 7  iter :5 ]train loss : 0.386109 ,train acc: 0.789937 ,val loss : 0.380680 ,val acc : 0.828674\n",
      "[ ecpho : 7  iter :6 ]train loss : 0.305039 ,train acc: 0.860769 ,val loss : 0.378932 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :7 ]train loss : 0.330469 ,train acc: 0.864014 ,val loss : 0.385785 ,val acc : 0.825043\n",
      "[ ecpho : 7  iter :8 ]train loss : 0.254116 ,train acc: 0.876170 ,val loss : 0.377164 ,val acc : 0.831116\n",
      "[ ecpho : 7  iter :9 ]train loss : 0.514454 ,train acc: 0.815338 ,val loss : 0.379845 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :10 ]train loss : 0.260132 ,train acc: 0.871185 ,val loss : 0.380910 ,val acc : 0.829041\n",
      "[ ecpho : 7  iter :11 ]train loss : 0.326382 ,train acc: 0.832509 ,val loss : 0.381820 ,val acc : 0.823456\n",
      "[ ecpho : 7  iter :12 ]train loss : 0.239354 ,train acc: 0.884633 ,val loss : 0.382112 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :13 ]train loss : 0.272399 ,train acc: 0.870239 ,val loss : 0.387667 ,val acc : 0.821899\n",
      "[ ecpho : 7  iter :14 ]train loss : 0.308760 ,train acc: 0.845235 ,val loss : 0.383110 ,val acc : 0.826111\n",
      "[ ecpho : 7  iter :15 ]train loss : 0.436966 ,train acc: 0.814901 ,val loss : 0.378992 ,val acc : 0.826691\n",
      "[ ecpho : 7  iter :16 ]train loss : 0.308512 ,train acc: 0.848552 ,val loss : 0.378257 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :17 ]train loss : 0.424649 ,train acc: 0.829214 ,val loss : 0.380747 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :18 ]train loss : 0.255592 ,train acc: 0.873952 ,val loss : 0.382994 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :19 ]train loss : 0.289160 ,train acc: 0.865285 ,val loss : 0.378732 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :20 ]train loss : 0.307684 ,train acc: 0.861511 ,val loss : 0.388103 ,val acc : 0.826141\n",
      "[ ecpho : 7  iter :21 ]train loss : 0.292580 ,train acc: 0.864553 ,val loss : 0.386074 ,val acc : 0.825226\n",
      "[ ecpho : 7  iter :22 ]train loss : 0.360267 ,train acc: 0.807790 ,val loss : 0.382415 ,val acc : 0.826202\n",
      "[ ecpho : 7  iter :23 ]train loss : 0.272693 ,train acc: 0.864950 ,val loss : 0.382525 ,val acc : 0.825134\n",
      "[ ecpho : 7  iter :24 ]train loss : 0.241700 ,train acc: 0.884715 ,val loss : 0.385135 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :25 ]train loss : 0.270815 ,train acc: 0.880086 ,val loss : 0.384000 ,val acc : 0.826843\n",
      "[ ecpho : 7  iter :26 ]train loss : 0.358974 ,train acc: 0.851847 ,val loss : 0.381303 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :27 ]train loss : 0.294984 ,train acc: 0.860830 ,val loss : 0.382434 ,val acc : 0.831299\n",
      "[ ecpho : 7  iter :28 ]train loss : 0.331819 ,train acc: 0.856801 ,val loss : 0.385654 ,val acc : 0.822906\n",
      "[ ecpho : 7  iter :29 ]train loss : 0.333135 ,train acc: 0.850088 ,val loss : 0.382144 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :30 ]train loss : 0.442252 ,train acc: 0.803721 ,val loss : 0.385860 ,val acc : 0.828064\n",
      "[ ecpho : 7  iter :31 ]train loss : 0.260386 ,train acc: 0.871887 ,val loss : 0.377809 ,val acc : 0.829254\n",
      "[ ecpho : 7  iter :32 ]train loss : 0.315650 ,train acc: 0.840546 ,val loss : 0.383995 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :33 ]train loss : 0.292354 ,train acc: 0.866404 ,val loss : 0.382504 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :34 ]train loss : 0.307086 ,train acc: 0.854391 ,val loss : 0.381682 ,val acc : 0.826202\n",
      "[ ecpho : 7  iter :35 ]train loss : 0.304112 ,train acc: 0.862010 ,val loss : 0.378008 ,val acc : 0.826050\n",
      "[ ecpho : 7  iter :36 ]train loss : 0.299544 ,train acc: 0.871104 ,val loss : 0.380266 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :37 ]train loss : 0.283617 ,train acc: 0.879283 ,val loss : 0.377604 ,val acc : 0.828918\n",
      "[ ecpho : 7  iter :38 ]train loss : 0.351298 ,train acc: 0.851471 ,val loss : 0.379593 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :39 ]train loss : 0.293443 ,train acc: 0.854319 ,val loss : 0.376915 ,val acc : 0.832458\n",
      "[ ecpho : 7  iter :40 ]train loss : 0.323776 ,train acc: 0.855998 ,val loss : 0.382892 ,val acc : 0.823639\n",
      "[ ecpho : 7  iter :41 ]train loss : 0.249150 ,train acc: 0.880341 ,val loss : 0.379833 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :42 ]train loss : 0.285196 ,train acc: 0.869202 ,val loss : 0.384226 ,val acc : 0.826233\n",
      "[ ecpho : 7  iter :43 ]train loss : 0.315034 ,train acc: 0.863668 ,val loss : 0.382706 ,val acc : 0.827179\n",
      "[ ecpho : 7  iter :44 ]train loss : 0.289715 ,train acc: 0.857951 ,val loss : 0.378787 ,val acc : 0.827942\n",
      "[ ecpho : 7  iter :45 ]train loss : 0.257516 ,train acc: 0.879812 ,val loss : 0.384461 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :46 ]train loss : 0.248393 ,train acc: 0.878194 ,val loss : 0.376789 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :47 ]train loss : 0.248628 ,train acc: 0.879629 ,val loss : 0.383876 ,val acc : 0.824005\n",
      "[ ecpho : 7  iter :48 ]train loss : 0.233770 ,train acc: 0.886180 ,val loss : 0.384719 ,val acc : 0.825500\n",
      "[ ecpho : 7  iter :49 ]train loss : 0.236673 ,train acc: 0.886668 ,val loss : 0.380805 ,val acc : 0.824829\n",
      "[ ecpho : 7  iter :50 ]train loss : 0.312149 ,train acc: 0.856120 ,val loss : 0.386917 ,val acc : 0.821106\n",
      "[ ecpho : 7  iter :51 ]train loss : 0.289005 ,train acc: 0.863037 ,val loss : 0.384265 ,val acc : 0.828827\n",
      "[ ecpho : 7  iter :52 ]train loss : 0.360492 ,train acc: 0.801921 ,val loss : 0.377304 ,val acc : 0.831696\n",
      "[ ecpho : 7  iter :53 ]train loss : 0.242670 ,train acc: 0.883047 ,val loss : 0.381273 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :54 ]train loss : 0.367347 ,train acc: 0.850464 ,val loss : 0.378552 ,val acc : 0.829834\n",
      "[ ecpho : 7  iter :55 ]train loss : 0.259323 ,train acc: 0.874034 ,val loss : 0.378394 ,val acc : 0.826874\n",
      "[ ecpho : 7  iter :56 ]train loss : 0.305653 ,train acc: 0.853912 ,val loss : 0.383437 ,val acc : 0.828094\n",
      "[ ecpho : 7  iter :57 ]train loss : 0.348837 ,train acc: 0.830973 ,val loss : 0.381571 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :58 ]train loss : 0.297541 ,train acc: 0.858602 ,val loss : 0.379760 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :59 ]train loss : 0.361165 ,train acc: 0.828257 ,val loss : 0.385973 ,val acc : 0.826141\n",
      "[ ecpho : 7  iter :60 ]train loss : 0.252616 ,train acc: 0.877319 ,val loss : 0.383091 ,val acc : 0.827667\n",
      "[ ecpho : 7  iter :61 ]train loss : 0.420780 ,train acc: 0.801432 ,val loss : 0.384193 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :62 ]train loss : 0.275965 ,train acc: 0.875671 ,val loss : 0.381545 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :63 ]train loss : 0.330125 ,train acc: 0.845917 ,val loss : 0.383744 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :64 ]train loss : 0.558574 ,train acc: 0.806448 ,val loss : 0.382792 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :65 ]train loss : 0.332672 ,train acc: 0.846019 ,val loss : 0.385504 ,val acc : 0.827057\n",
      "[ ecpho : 7  iter :66 ]train loss : 0.275472 ,train acc: 0.867269 ,val loss : 0.381160 ,val acc : 0.829285\n",
      "[ ecpho : 7  iter :67 ]train loss : 0.272514 ,train acc: 0.870514 ,val loss : 0.381249 ,val acc : 0.824707\n",
      "[ ecpho : 7  iter :68 ]train loss : 0.360201 ,train acc: 0.809245 ,val loss : 0.379533 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :69 ]train loss : 0.347381 ,train acc: 0.821716 ,val loss : 0.382996 ,val acc : 0.825073\n",
      "[ ecpho : 7  iter :70 ]train loss : 0.501214 ,train acc: 0.824453 ,val loss : 0.381502 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :71 ]train loss : 0.273796 ,train acc: 0.868652 ,val loss : 0.381896 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :72 ]train loss : 0.339120 ,train acc: 0.838532 ,val loss : 0.384007 ,val acc : 0.826355\n",
      "[ ecpho : 7  iter :73 ]train loss : 0.361349 ,train acc: 0.822032 ,val loss : 0.381880 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :74 ]train loss : 0.256858 ,train acc: 0.878255 ,val loss : 0.385416 ,val acc : 0.825592\n",
      "[ ecpho : 7  iter :75 ]train loss : 0.333426 ,train acc: 0.836782 ,val loss : 0.381600 ,val acc : 0.827728\n",
      "[ ecpho : 7  iter :76 ]train loss : 0.326315 ,train acc: 0.842021 ,val loss : 0.380792 ,val acc : 0.829590\n",
      "[ ecpho : 7  iter :77 ]train loss : 0.347601 ,train acc: 0.840068 ,val loss : 0.386058 ,val acc : 0.825500\n",
      "[ ecpho : 7  iter :78 ]train loss : 0.310160 ,train acc: 0.858378 ,val loss : 0.381008 ,val acc : 0.827667\n",
      "[ ecpho : 7  iter :79 ]train loss : 0.296638 ,train acc: 0.854747 ,val loss : 0.376780 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :80 ]train loss : 0.294225 ,train acc: 0.857402 ,val loss : 0.384769 ,val acc : 0.826355\n",
      "[ ecpho : 7  iter :81 ]train loss : 0.349603 ,train acc: 0.839539 ,val loss : 0.385949 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :82 ]train loss : 0.427783 ,train acc: 0.818838 ,val loss : 0.383243 ,val acc : 0.825775\n",
      "[ ecpho : 7  iter :83 ]train loss : 0.263138 ,train acc: 0.880249 ,val loss : 0.384816 ,val acc : 0.826630\n",
      "[ ecpho : 7  iter :84 ]train loss : 0.255011 ,train acc: 0.879049 ,val loss : 0.390071 ,val acc : 0.825836\n",
      "[ ecpho : 7  iter :85 ]train loss : 0.304971 ,train acc: 0.865417 ,val loss : 0.386723 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :86 ]train loss : 0.291425 ,train acc: 0.867137 ,val loss : 0.383896 ,val acc : 0.826385\n",
      "[ ecpho : 7  iter :87 ]train loss : 0.347143 ,train acc: 0.842092 ,val loss : 0.385146 ,val acc : 0.827637\n",
      "[ ecpho : 7  iter :88 ]train loss : 0.310377 ,train acc: 0.855215 ,val loss : 0.390143 ,val acc : 0.830017\n",
      "[ ecpho : 7  iter :89 ]train loss : 0.412957 ,train acc: 0.838481 ,val loss : 0.385638 ,val acc : 0.826355\n",
      "[ ecpho : 7  iter :90 ]train loss : 0.267880 ,train acc: 0.873566 ,val loss : 0.381358 ,val acc : 0.826935\n",
      "[ ecpho : 7  iter :91 ]train loss : 0.330302 ,train acc: 0.841217 ,val loss : 0.381572 ,val acc : 0.828522\n",
      "[ ecpho : 7  iter :92 ]train loss : 0.501343 ,train acc: 0.748606 ,val loss : 0.386020 ,val acc : 0.824097\n",
      "[ ecpho : 7  iter :93 ]train loss : 0.260510 ,train acc: 0.874898 ,val loss : 0.383576 ,val acc : 0.826843\n",
      "[ ecpho : 7  iter :94 ]train loss : 0.263511 ,train acc: 0.875295 ,val loss : 0.381151 ,val acc : 0.826813\n",
      "[ ecpho : 7  iter :95 ]train loss : 0.263536 ,train acc: 0.871094 ,val loss : 0.382840 ,val acc : 0.825134\n",
      "[ ecpho : 7  iter :96 ]train loss : 0.275962 ,train acc: 0.871887 ,val loss : 0.377343 ,val acc : 0.827942\n",
      "[ ecpho : 7  iter :97 ]train loss : 0.247665 ,train acc: 0.882385 ,val loss : 0.380180 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :98 ]train loss : 0.305091 ,train acc: 0.845123 ,val loss : 0.387044 ,val acc : 0.824554\n",
      "[ ecpho : 7  iter :99 ]train loss : 0.255560 ,train acc: 0.878347 ,val loss : 0.386408 ,val acc : 0.823761\n",
      "[ ecpho : 7  iter :100 ]train loss : 0.442571 ,train acc: 0.823252 ,val loss : 0.380840 ,val acc : 0.829895\n",
      "[ ecpho : 7  iter :101 ]train loss : 0.293301 ,train acc: 0.858124 ,val loss : 0.386273 ,val acc : 0.824463\n",
      "[ ecpho : 7  iter :102 ]train loss : 0.279389 ,train acc: 0.870799 ,val loss : 0.381347 ,val acc : 0.826874\n",
      "[ ecpho : 7  iter :103 ]train loss : 0.425735 ,train acc: 0.800558 ,val loss : 0.379080 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :104 ]train loss : 0.367642 ,train acc: 0.827932 ,val loss : 0.377441 ,val acc : 0.827667\n",
      "[ ecpho : 7  iter :105 ]train loss : 0.276062 ,train acc: 0.871989 ,val loss : 0.379794 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :106 ]train loss : 0.258940 ,train acc: 0.874624 ,val loss : 0.384005 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :107 ]train loss : 0.388578 ,train acc: 0.807790 ,val loss : 0.379468 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :108 ]train loss : 0.525233 ,train acc: 0.806346 ,val loss : 0.381069 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :109 ]train loss : 0.400454 ,train acc: 0.820303 ,val loss : 0.380032 ,val acc : 0.825348\n",
      "[ ecpho : 7  iter :110 ]train loss : 0.314723 ,train acc: 0.859792 ,val loss : 0.389149 ,val acc : 0.826263\n",
      "[ ecpho : 7  iter :111 ]train loss : 0.276164 ,train acc: 0.867177 ,val loss : 0.382748 ,val acc : 0.828766\n",
      "[ ecpho : 7  iter :112 ]train loss : 0.276259 ,train acc: 0.869436 ,val loss : 0.390768 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :113 ]train loss : 0.231108 ,train acc: 0.888509 ,val loss : 0.382724 ,val acc : 0.828094\n",
      "[ ecpho : 7  iter :114 ]train loss : 0.793689 ,train acc: 0.733328 ,val loss : 0.385667 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :115 ]train loss : 0.265528 ,train acc: 0.876862 ,val loss : 0.383882 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :116 ]train loss : 0.264010 ,train acc: 0.873871 ,val loss : 0.377421 ,val acc : 0.829193\n",
      "[ ecpho : 7  iter :117 ]train loss : 0.262655 ,train acc: 0.875234 ,val loss : 0.378983 ,val acc : 0.823792\n",
      "[ ecpho : 7  iter :118 ]train loss : 0.419290 ,train acc: 0.838450 ,val loss : 0.385402 ,val acc : 0.823456\n",
      "[ ecpho : 7  iter :119 ]train loss : 0.237752 ,train acc: 0.883586 ,val loss : 0.374543 ,val acc : 0.834015\n",
      "[ ecpho : 7  iter :120 ]train loss : 0.233819 ,train acc: 0.889903 ,val loss : 0.377308 ,val acc : 0.827057\n",
      "[ ecpho : 7  iter :121 ]train loss : 0.408948 ,train acc: 0.802531 ,val loss : 0.376654 ,val acc : 0.830048\n",
      "[ ecpho : 7  iter :122 ]train loss : 0.240927 ,train acc: 0.883199 ,val loss : 0.378319 ,val acc : 0.827026\n",
      "[ ecpho : 7  iter :123 ]train loss : 0.336860 ,train acc: 0.862315 ,val loss : 0.375601 ,val acc : 0.829742\n",
      "[ ecpho : 7  iter :124 ]train loss : 0.305840 ,train acc: 0.866435 ,val loss : 0.384921 ,val acc : 0.824738\n",
      "[ ecpho : 7  iter :125 ]train loss : 0.363530 ,train acc: 0.814830 ,val loss : 0.387921 ,val acc : 0.822510\n",
      "[ ecpho : 7  iter :126 ]train loss : 0.265989 ,train acc: 0.874308 ,val loss : 0.379973 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :127 ]train loss : 0.294403 ,train acc: 0.858327 ,val loss : 0.380657 ,val acc : 0.829834\n",
      "[ ecpho : 7  iter :128 ]train loss : 0.285772 ,train acc: 0.867686 ,val loss : 0.382150 ,val acc : 0.829498\n",
      "[ ecpho : 7  iter :129 ]train loss : 0.297384 ,train acc: 0.849294 ,val loss : 0.386668 ,val acc : 0.827759\n",
      "[ ecpho : 7  iter :130 ]train loss : 0.311840 ,train acc: 0.863088 ,val loss : 0.378653 ,val acc : 0.827728\n",
      "[ ecpho : 7  iter :131 ]train loss : 0.373340 ,train acc: 0.848969 ,val loss : 0.383438 ,val acc : 0.826294\n",
      "[ ecpho : 7  iter :132 ]train loss : 0.272319 ,train acc: 0.872213 ,val loss : 0.379281 ,val acc : 0.828857\n",
      "[ ecpho : 7  iter :133 ]train loss : 0.319193 ,train acc: 0.844055 ,val loss : 0.382832 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :134 ]train loss : 0.274735 ,train acc: 0.868276 ,val loss : 0.378109 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :135 ]train loss : 0.268819 ,train acc: 0.871887 ,val loss : 0.388713 ,val acc : 0.825684\n",
      "[ ecpho : 7  iter :136 ]train loss : 0.267163 ,train acc: 0.875773 ,val loss : 0.382230 ,val acc : 0.825531\n",
      "[ ecpho : 7  iter :137 ]train loss : 0.351450 ,train acc: 0.851583 ,val loss : 0.382705 ,val acc : 0.829468\n",
      "[ ecpho : 7  iter :138 ]train loss : 0.356958 ,train acc: 0.836121 ,val loss : 0.385807 ,val acc : 0.824615\n",
      "[ ecpho : 7  iter :139 ]train loss : 0.358924 ,train acc: 0.853048 ,val loss : 0.376947 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :140 ]train loss : 0.357702 ,train acc: 0.813731 ,val loss : 0.379668 ,val acc : 0.829559\n",
      "[ ecpho : 7  iter :141 ]train loss : 0.306594 ,train acc: 0.862091 ,val loss : 0.375676 ,val acc : 0.830444\n",
      "[ ecpho : 7  iter :142 ]train loss : 0.277151 ,train acc: 0.870300 ,val loss : 0.379195 ,val acc : 0.828430\n",
      "[ ecpho : 7  iter :143 ]train loss : 0.263995 ,train acc: 0.881083 ,val loss : 0.383101 ,val acc : 0.824646\n",
      "[ ecpho : 7  iter :144 ]train loss : 0.332406 ,train acc: 0.843720 ,val loss : 0.377303 ,val acc : 0.828979\n",
      "[ ecpho : 7  iter :145 ]train loss : 0.323322 ,train acc: 0.846293 ,val loss : 0.380422 ,val acc : 0.829468\n",
      "[ ecpho : 7  iter :146 ]train loss : 0.253054 ,train acc: 0.878682 ,val loss : 0.384688 ,val acc : 0.824799\n",
      "[ ecpho : 7  iter :147 ]train loss : 0.341036 ,train acc: 0.858348 ,val loss : 0.384282 ,val acc : 0.826843\n",
      "[ ecpho : 7  iter :148 ]train loss : 0.356924 ,train acc: 0.816813 ,val loss : 0.386477 ,val acc : 0.827393\n",
      "[ ecpho : 7  iter :149 ]train loss : 0.258233 ,train acc: 0.873912 ,val loss : 0.383694 ,val acc : 0.825195\n",
      "[ ecpho : 7  iter :150 ]train loss : 0.330455 ,train acc: 0.834249 ,val loss : 0.381153 ,val acc : 0.826447\n",
      "[ ecpho : 7  iter :151 ]train loss : 0.365018 ,train acc: 0.854858 ,val loss : 0.384812 ,val acc : 0.826538\n",
      "[ ecpho : 7  iter :152 ]train loss : 0.355776 ,train acc: 0.845408 ,val loss : 0.382808 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :153 ]train loss : 0.309336 ,train acc: 0.865265 ,val loss : 0.386470 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :154 ]train loss : 0.289714 ,train acc: 0.869395 ,val loss : 0.377915 ,val acc : 0.828461\n",
      "[ ecpho : 7  iter :155 ]train loss : 0.347855 ,train acc: 0.812724 ,val loss : 0.378069 ,val acc : 0.829132\n",
      "[ ecpho : 7  iter :156 ]train loss : 0.418689 ,train acc: 0.818573 ,val loss : 0.383414 ,val acc : 0.824585\n",
      "[ ecpho : 7  iter :157 ]train loss : 0.303434 ,train acc: 0.857605 ,val loss : 0.385070 ,val acc : 0.828705\n",
      "[ ecpho : 7  iter :158 ]train loss : 0.273788 ,train acc: 0.871348 ,val loss : 0.384426 ,val acc : 0.825500\n",
      "[ ecpho : 7  iter :159 ]train loss : 0.333230 ,train acc: 0.847372 ,val loss : 0.377084 ,val acc : 0.831360\n",
      "[ ecpho : 7  iter :160 ]train loss : 0.272585 ,train acc: 0.867818 ,val loss : 0.385937 ,val acc : 0.825836\n",
      "[ ecpho : 7  iter :161 ]train loss : 0.420828 ,train acc: 0.812989 ,val loss : 0.382692 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :162 ]train loss : 0.305163 ,train acc: 0.862468 ,val loss : 0.381874 ,val acc : 0.830780\n",
      "[ ecpho : 7  iter :163 ]train loss : 0.332610 ,train acc: 0.847880 ,val loss : 0.377436 ,val acc : 0.827026\n",
      "[ ecpho : 7  iter :164 ]train loss : 0.237439 ,train acc: 0.881683 ,val loss : 0.380061 ,val acc : 0.825165\n",
      "[ ecpho : 7  iter :165 ]train loss : 0.308951 ,train acc: 0.861816 ,val loss : 0.379055 ,val acc : 0.828918\n",
      "[ ecpho : 7  iter :166 ]train loss : 0.284817 ,train acc: 0.870453 ,val loss : 0.378650 ,val acc : 0.825836\n",
      "[ ecpho : 7  iter :167 ]train loss : 0.299672 ,train acc: 0.858765 ,val loss : 0.384677 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :168 ]train loss : 0.316215 ,train acc: 0.849447 ,val loss : 0.383423 ,val acc : 0.826660\n",
      "[ ecpho : 7  iter :169 ]train loss : 0.277229 ,train acc: 0.859029 ,val loss : 0.380220 ,val acc : 0.829651\n",
      "[ ecpho : 7  iter :170 ]train loss : 0.372911 ,train acc: 0.815877 ,val loss : 0.383087 ,val acc : 0.828125\n",
      "[ ecpho : 7  iter :171 ]train loss : 0.245718 ,train acc: 0.879740 ,val loss : 0.387511 ,val acc : 0.828491\n",
      "[ ecpho : 7  iter :172 ]train loss : 0.275464 ,train acc: 0.870270 ,val loss : 0.377323 ,val acc : 0.829956\n",
      "[ ecpho : 7  iter :173 ]train loss : 0.278485 ,train acc: 0.867523 ,val loss : 0.381987 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :174 ]train loss : 0.348398 ,train acc: 0.853312 ,val loss : 0.380882 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :175 ]train loss : 0.638537 ,train acc: 0.779002 ,val loss : 0.385546 ,val acc : 0.826050\n",
      "[ ecpho : 7  iter :176 ]train loss : 0.309084 ,train acc: 0.867137 ,val loss : 0.380549 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :177 ]train loss : 0.401814 ,train acc: 0.842977 ,val loss : 0.373458 ,val acc : 0.831482\n",
      "[ ecpho : 7  iter :178 ]train loss : 0.255174 ,train acc: 0.877462 ,val loss : 0.382416 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :179 ]train loss : 0.355531 ,train acc: 0.840169 ,val loss : 0.384785 ,val acc : 0.823212\n",
      "[ ecpho : 7  iter :180 ]train loss : 0.238527 ,train acc: 0.883433 ,val loss : 0.385458 ,val acc : 0.824371\n",
      "[ ecpho : 7  iter :181 ]train loss : 0.245483 ,train acc: 0.881327 ,val loss : 0.384946 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :182 ]train loss : 0.308761 ,train acc: 0.862172 ,val loss : 0.383186 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :183 ]train loss : 0.347195 ,train acc: 0.780060 ,val loss : 0.381644 ,val acc : 0.824677\n",
      "[ ecpho : 7  iter :184 ]train loss : 0.216739 ,train acc: 0.895986 ,val loss : 0.382452 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :185 ]train loss : 0.463452 ,train acc: 0.819234 ,val loss : 0.380975 ,val acc : 0.825836\n",
      "[ ecpho : 7  iter :186 ]train loss : 0.234847 ,train acc: 0.888336 ,val loss : 0.379338 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :187 ]train loss : 0.270312 ,train acc: 0.870229 ,val loss : 0.386999 ,val acc : 0.826813\n",
      "[ ecpho : 7  iter :188 ]train loss : 0.292668 ,train acc: 0.858164 ,val loss : 0.384812 ,val acc : 0.828735\n",
      "[ ecpho : 7  iter :189 ]train loss : 0.296653 ,train acc: 0.864136 ,val loss : 0.377379 ,val acc : 0.826080\n",
      "[ ecpho : 7  iter :190 ]train loss : 0.271216 ,train acc: 0.870117 ,val loss : 0.384981 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :191 ]train loss : 0.390714 ,train acc: 0.851166 ,val loss : 0.380522 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :192 ]train loss : 0.341722 ,train acc: 0.857992 ,val loss : 0.381030 ,val acc : 0.829987\n",
      "[ ecpho : 7  iter :193 ]train loss : 0.299516 ,train acc: 0.849904 ,val loss : 0.379395 ,val acc : 0.824982\n",
      "[ ecpho : 7  iter :194 ]train loss : 0.259831 ,train acc: 0.875102 ,val loss : 0.380147 ,val acc : 0.826599\n",
      "[ ecpho : 7  iter :195 ]train loss : 0.347178 ,train acc: 0.855540 ,val loss : 0.382082 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :196 ]train loss : 0.226252 ,train acc: 0.890432 ,val loss : 0.383608 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :197 ]train loss : 0.298896 ,train acc: 0.863230 ,val loss : 0.380077 ,val acc : 0.826263\n",
      "[ ecpho : 7  iter :198 ]train loss : 0.258974 ,train acc: 0.876699 ,val loss : 0.385405 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :199 ]train loss : 0.336610 ,train acc: 0.853353 ,val loss : 0.382859 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :200 ]train loss : 0.281058 ,train acc: 0.865499 ,val loss : 0.381941 ,val acc : 0.827301\n",
      "[ ecpho : 7  iter :201 ]train loss : 0.404641 ,train acc: 0.805430 ,val loss : 0.376210 ,val acc : 0.828979\n",
      "[ ecpho : 7  iter :202 ]train loss : 0.274467 ,train acc: 0.878286 ,val loss : 0.378901 ,val acc : 0.826111\n",
      "[ ecpho : 7  iter :203 ]train loss : 0.272132 ,train acc: 0.872732 ,val loss : 0.382611 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :204 ]train loss : 0.334440 ,train acc: 0.853618 ,val loss : 0.380958 ,val acc : 0.828583\n",
      "[ ecpho : 7  iter :205 ]train loss : 0.268903 ,train acc: 0.868642 ,val loss : 0.380519 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :206 ]train loss : 0.301438 ,train acc: 0.862559 ,val loss : 0.378998 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :207 ]train loss : 0.246626 ,train acc: 0.884949 ,val loss : 0.383656 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :208 ]train loss : 0.360016 ,train acc: 0.818604 ,val loss : 0.382638 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :209 ]train loss : 0.305860 ,train acc: 0.861542 ,val loss : 0.385099 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :210 ]train loss : 0.364187 ,train acc: 0.845734 ,val loss : 0.379291 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :211 ]train loss : 0.315225 ,train acc: 0.858765 ,val loss : 0.382735 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :212 ]train loss : 0.317222 ,train acc: 0.853353 ,val loss : 0.384093 ,val acc : 0.824524\n",
      "[ ecpho : 7  iter :213 ]train loss : 0.272693 ,train acc: 0.877492 ,val loss : 0.382417 ,val acc : 0.824982\n",
      "[ ecpho : 7  iter :214 ]train loss : 0.260251 ,train acc: 0.875387 ,val loss : 0.379046 ,val acc : 0.830444\n",
      "[ ecpho : 7  iter :215 ]train loss : 0.320380 ,train acc: 0.822255 ,val loss : 0.386412 ,val acc : 0.825409\n",
      "[ ecpho : 7  iter :216 ]train loss : 0.290181 ,train acc: 0.874685 ,val loss : 0.381608 ,val acc : 0.829956\n",
      "[ ecpho : 7  iter :217 ]train loss : 0.238104 ,train acc: 0.888357 ,val loss : 0.381038 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :218 ]train loss : 0.250338 ,train acc: 0.880158 ,val loss : 0.385837 ,val acc : 0.825409\n",
      "[ ecpho : 7  iter :219 ]train loss : 0.254229 ,train acc: 0.878204 ,val loss : 0.383040 ,val acc : 0.828491\n",
      "[ ecpho : 7  iter :220 ]train loss : 0.269452 ,train acc: 0.873840 ,val loss : 0.382521 ,val acc : 0.826447\n",
      "[ ecpho : 7  iter :221 ]train loss : 0.232932 ,train acc: 0.887095 ,val loss : 0.387773 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :222 ]train loss : 0.229766 ,train acc: 0.890462 ,val loss : 0.387069 ,val acc : 0.825867\n",
      "[ ecpho : 7  iter :223 ]train loss : 0.287191 ,train acc: 0.873372 ,val loss : 0.384394 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :224 ]train loss : 0.407742 ,train acc: 0.775462 ,val loss : 0.379679 ,val acc : 0.829803\n",
      "[ ecpho : 7  iter :225 ]train loss : 0.297318 ,train acc: 0.855652 ,val loss : 0.379882 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :226 ]train loss : 0.265051 ,train acc: 0.866475 ,val loss : 0.378426 ,val acc : 0.831024\n",
      "[ ecpho : 7  iter :227 ]train loss : 0.340100 ,train acc: 0.857981 ,val loss : 0.382033 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :228 ]train loss : 0.296600 ,train acc: 0.868652 ,val loss : 0.381040 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :229 ]train loss : 0.401490 ,train acc: 0.827800 ,val loss : 0.384220 ,val acc : 0.828308\n",
      "[ ecpho : 7  iter :230 ]train loss : 0.311351 ,train acc: 0.864299 ,val loss : 0.379197 ,val acc : 0.829773\n",
      "[ ecpho : 7  iter :231 ]train loss : 0.419356 ,train acc: 0.792196 ,val loss : 0.379958 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :232 ]train loss : 0.406469 ,train acc: 0.704305 ,val loss : 0.382847 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :233 ]train loss : 0.324321 ,train acc: 0.852570 ,val loss : 0.387327 ,val acc : 0.825348\n",
      "[ ecpho : 7  iter :234 ]train loss : 0.281315 ,train acc: 0.870799 ,val loss : 0.382183 ,val acc : 0.825623\n",
      "[ ecpho : 7  iter :235 ]train loss : 0.265787 ,train acc: 0.874176 ,val loss : 0.385247 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :236 ]train loss : 0.446042 ,train acc: 0.828939 ,val loss : 0.380056 ,val acc : 0.828339\n",
      "[ ecpho : 7  iter :237 ]train loss : 0.248699 ,train acc: 0.881948 ,val loss : 0.387063 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :238 ]train loss : 0.238091 ,train acc: 0.884257 ,val loss : 0.385067 ,val acc : 0.823853\n",
      "[ ecpho : 7  iter :239 ]train loss : 0.253424 ,train acc: 0.881714 ,val loss : 0.381724 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :240 ]train loss : 0.274004 ,train acc: 0.865448 ,val loss : 0.382322 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :241 ]train loss : 0.411502 ,train acc: 0.817424 ,val loss : 0.384398 ,val acc : 0.821472\n",
      "[ ecpho : 7  iter :242 ]train loss : 0.311858 ,train acc: 0.869293 ,val loss : 0.383414 ,val acc : 0.825470\n",
      "[ ecpho : 7  iter :243 ]train loss : 0.300794 ,train acc: 0.861450 ,val loss : 0.382123 ,val acc : 0.825806\n",
      "[ ecpho : 7  iter :244 ]train loss : 0.283310 ,train acc: 0.866801 ,val loss : 0.381658 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :245 ]train loss : 0.271756 ,train acc: 0.871653 ,val loss : 0.379705 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :246 ]train loss : 0.369543 ,train acc: 0.845520 ,val loss : 0.379059 ,val acc : 0.826691\n",
      "[ ecpho : 7  iter :247 ]train loss : 0.314151 ,train acc: 0.861176 ,val loss : 0.379203 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :248 ]train loss : 0.296707 ,train acc: 0.863566 ,val loss : 0.379545 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :249 ]train loss : 0.258788 ,train acc: 0.877909 ,val loss : 0.386035 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :250 ]train loss : 0.447446 ,train acc: 0.809265 ,val loss : 0.383564 ,val acc : 0.828339\n",
      "[ ecpho : 7  iter :251 ]train loss : 0.309269 ,train acc: 0.864878 ,val loss : 0.378898 ,val acc : 0.826691\n",
      "[ ecpho : 7  iter :252 ]train loss : 0.242727 ,train acc: 0.881917 ,val loss : 0.386810 ,val acc : 0.825775\n",
      "[ ecpho : 7  iter :253 ]train loss : 0.361200 ,train acc: 0.852519 ,val loss : 0.378630 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :254 ]train loss : 0.320529 ,train acc: 0.855347 ,val loss : 0.382651 ,val acc : 0.826599\n",
      "[ ecpho : 7  iter :255 ]train loss : 0.282051 ,train acc: 0.865875 ,val loss : 0.381088 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :256 ]train loss : 0.259679 ,train acc: 0.876801 ,val loss : 0.386710 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :257 ]train loss : 0.454431 ,train acc: 0.774333 ,val loss : 0.381606 ,val acc : 0.825684\n",
      "[ ecpho : 7  iter :258 ]train loss : 0.282838 ,train acc: 0.862376 ,val loss : 0.378087 ,val acc : 0.828827\n",
      "[ ecpho : 7  iter :259 ]train loss : 0.309293 ,train acc: 0.859192 ,val loss : 0.385522 ,val acc : 0.825653\n",
      "[ ecpho : 7  iter :260 ]train loss : 0.308711 ,train acc: 0.845001 ,val loss : 0.385737 ,val acc : 0.826447\n",
      "[ ecpho : 7  iter :261 ]train loss : 0.236989 ,train acc: 0.883820 ,val loss : 0.380410 ,val acc : 0.826385\n",
      "[ ecpho : 7  iter :262 ]train loss : 0.326615 ,train acc: 0.844055 ,val loss : 0.381544 ,val acc : 0.828918\n",
      "[ ecpho : 7  iter :263 ]train loss : 0.313263 ,train acc: 0.850210 ,val loss : 0.375621 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :264 ]train loss : 0.401008 ,train acc: 0.840668 ,val loss : 0.379324 ,val acc : 0.829102\n",
      "[ ecpho : 7  iter :265 ]train loss : 0.244636 ,train acc: 0.884857 ,val loss : 0.382461 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :266 ]train loss : 0.271939 ,train acc: 0.874654 ,val loss : 0.384507 ,val acc : 0.825409\n",
      "[ ecpho : 7  iter :267 ]train loss : 0.232900 ,train acc: 0.888804 ,val loss : 0.385594 ,val acc : 0.824860\n",
      "[ ecpho : 7  iter :268 ]train loss : 0.280190 ,train acc: 0.868276 ,val loss : 0.379980 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :269 ]train loss : 0.287399 ,train acc: 0.860189 ,val loss : 0.379837 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :270 ]train loss : 0.286782 ,train acc: 0.870016 ,val loss : 0.387083 ,val acc : 0.829254\n",
      "[ ecpho : 7  iter :271 ]train loss : 0.273967 ,train acc: 0.869456 ,val loss : 0.379394 ,val acc : 0.826385\n",
      "[ ecpho : 7  iter :272 ]train loss : 0.300041 ,train acc: 0.854736 ,val loss : 0.379009 ,val acc : 0.830780\n",
      "[ ecpho : 7  iter :273 ]train loss : 0.424661 ,train acc: 0.774903 ,val loss : 0.382308 ,val acc : 0.827026\n",
      "[ ecpho : 7  iter :274 ]train loss : 0.236077 ,train acc: 0.888936 ,val loss : 0.377066 ,val acc : 0.828369\n",
      "[ ecpho : 7  iter :275 ]train loss : 0.395585 ,train acc: 0.844167 ,val loss : 0.381644 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :276 ]train loss : 0.282383 ,train acc: 0.868113 ,val loss : 0.382180 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :277 ]train loss : 0.265614 ,train acc: 0.875977 ,val loss : 0.383266 ,val acc : 0.825531\n",
      "[ ecpho : 7  iter :278 ]train loss : 0.266518 ,train acc: 0.872620 ,val loss : 0.384563 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :279 ]train loss : 0.234741 ,train acc: 0.885325 ,val loss : 0.379032 ,val acc : 0.826569\n",
      "[ ecpho : 7  iter :280 ]train loss : 0.275180 ,train acc: 0.868673 ,val loss : 0.383498 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :281 ]train loss : 0.267953 ,train acc: 0.870951 ,val loss : 0.376485 ,val acc : 0.830719\n",
      "[ ecpho : 7  iter :282 ]train loss : 0.291265 ,train acc: 0.862803 ,val loss : 0.379822 ,val acc : 0.829041\n",
      "[ ecpho : 7  iter :283 ]train loss : 0.352655 ,train acc: 0.826020 ,val loss : 0.380489 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :284 ]train loss : 0.312141 ,train acc: 0.843007 ,val loss : 0.384187 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :285 ]train loss : 0.269647 ,train acc: 0.867493 ,val loss : 0.389021 ,val acc : 0.822418\n",
      "[ ecpho : 7  iter :286 ]train loss : 0.363377 ,train acc: 0.817780 ,val loss : 0.383203 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :287 ]train loss : 0.313627 ,train acc: 0.859477 ,val loss : 0.383162 ,val acc : 0.825867\n",
      "[ ecpho : 7  iter :288 ]train loss : 0.382890 ,train acc: 0.832896 ,val loss : 0.382536 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :289 ]train loss : 0.370452 ,train acc: 0.830648 ,val loss : 0.376392 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :290 ]train loss : 0.301393 ,train acc: 0.848002 ,val loss : 0.380156 ,val acc : 0.825165\n",
      "[ ecpho : 7  iter :291 ]train loss : 0.303151 ,train acc: 0.850535 ,val loss : 0.378685 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :292 ]train loss : 0.276495 ,train acc: 0.870768 ,val loss : 0.385944 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :293 ]train loss : 0.239798 ,train acc: 0.887390 ,val loss : 0.380080 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :294 ]train loss : 0.391580 ,train acc: 0.812368 ,val loss : 0.379931 ,val acc : 0.826935\n",
      "[ ecpho : 7  iter :295 ]train loss : 0.335938 ,train acc: 0.855591 ,val loss : 0.390325 ,val acc : 0.824280\n",
      "[ ecpho : 7  iter :296 ]train loss : 0.278843 ,train acc: 0.875020 ,val loss : 0.381959 ,val acc : 0.824280\n",
      "[ ecpho : 7  iter :297 ]train loss : 0.286728 ,train acc: 0.870270 ,val loss : 0.382265 ,val acc : 0.826447\n",
      "[ ecpho : 7  iter :298 ]train loss : 0.321245 ,train acc: 0.842356 ,val loss : 0.378859 ,val acc : 0.825836\n",
      "[ ecpho : 7  iter :299 ]train loss : 0.327908 ,train acc: 0.852448 ,val loss : 0.383840 ,val acc : 0.826416\n",
      "[ ecpho : 7  iter :300 ]train loss : 0.275562 ,train acc: 0.862040 ,val loss : 0.382479 ,val acc : 0.824677\n",
      "[ ecpho : 7  iter :301 ]train loss : 0.292525 ,train acc: 0.862040 ,val loss : 0.381543 ,val acc : 0.825592\n",
      "[ ecpho : 7  iter :302 ]train loss : 0.267183 ,train acc: 0.874522 ,val loss : 0.384292 ,val acc : 0.828583\n",
      "[ ecpho : 7  iter :303 ]train loss : 0.277156 ,train acc: 0.870270 ,val loss : 0.386557 ,val acc : 0.824921\n",
      "[ ecpho : 7  iter :304 ]train loss : 0.247333 ,train acc: 0.882446 ,val loss : 0.380482 ,val acc : 0.828522\n",
      "[ ecpho : 7  iter :305 ]train loss : 0.276223 ,train acc: 0.870758 ,val loss : 0.386495 ,val acc : 0.826447\n",
      "[ ecpho : 7  iter :306 ]train loss : 0.350529 ,train acc: 0.859365 ,val loss : 0.380090 ,val acc : 0.827667\n",
      "[ ecpho : 7  iter :307 ]train loss : 0.265943 ,train acc: 0.873128 ,val loss : 0.379705 ,val acc : 0.827728\n",
      "[ ecpho : 7  iter :308 ]train loss : 0.327838 ,train acc: 0.846619 ,val loss : 0.389243 ,val acc : 0.823578\n",
      "[ ecpho : 7  iter :309 ]train loss : 0.436122 ,train acc: 0.830495 ,val loss : 0.388796 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :310 ]train loss : 0.331414 ,train acc: 0.856751 ,val loss : 0.388000 ,val acc : 0.824951\n",
      "[ ecpho : 7  iter :311 ]train loss : 0.364544 ,train acc: 0.830200 ,val loss : 0.388034 ,val acc : 0.824982\n",
      "[ ecpho : 7  iter :312 ]train loss : 0.309819 ,train acc: 0.863363 ,val loss : 0.386625 ,val acc : 0.825409\n",
      "[ ecpho : 7  iter :313 ]train loss : 0.323605 ,train acc: 0.851064 ,val loss : 0.380919 ,val acc : 0.830170\n",
      "[ ecpho : 7  iter :314 ]train loss : 0.480587 ,train acc: 0.787293 ,val loss : 0.383994 ,val acc : 0.829529\n",
      "[ ecpho : 7  iter :315 ]train loss : 0.354621 ,train acc: 0.822805 ,val loss : 0.376821 ,val acc : 0.830109\n",
      "[ ecpho : 7  iter :316 ]train loss : 0.524802 ,train acc: 0.803833 ,val loss : 0.378165 ,val acc : 0.828522\n",
      "[ ecpho : 7  iter :317 ]train loss : 0.292139 ,train acc: 0.857310 ,val loss : 0.381392 ,val acc : 0.828888\n",
      "[ ecpho : 7  iter :318 ]train loss : 0.267494 ,train acc: 0.870321 ,val loss : 0.377913 ,val acc : 0.830566\n",
      "[ ecpho : 7  iter :319 ]train loss : 0.338547 ,train acc: 0.824290 ,val loss : 0.375968 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :320 ]train loss : 0.294114 ,train acc: 0.859202 ,val loss : 0.378094 ,val acc : 0.829041\n",
      "[ ecpho : 7  iter :321 ]train loss : 0.417102 ,train acc: 0.830923 ,val loss : 0.382196 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :322 ]train loss : 0.484752 ,train acc: 0.794607 ,val loss : 0.386922 ,val acc : 0.829193\n",
      "[ ecpho : 7  iter :323 ]train loss : 0.254457 ,train acc: 0.875885 ,val loss : 0.382922 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :324 ]train loss : 0.232788 ,train acc: 0.886505 ,val loss : 0.379439 ,val acc : 0.830536\n",
      "[ ecpho : 7  iter :325 ]train loss : 0.408724 ,train acc: 0.824392 ,val loss : 0.382696 ,val acc : 0.829254\n",
      "[ ecpho : 7  iter :326 ]train loss : 0.329363 ,train acc: 0.809692 ,val loss : 0.382966 ,val acc : 0.829498\n",
      "[ ecpho : 7  iter :327 ]train loss : 0.319452 ,train acc: 0.839966 ,val loss : 0.377127 ,val acc : 0.829224\n",
      "[ ecpho : 7  iter :328 ]train loss : 0.247976 ,train acc: 0.879649 ,val loss : 0.387395 ,val acc : 0.823608\n",
      "[ ecpho : 7  iter :329 ]train loss : 0.325916 ,train acc: 0.835653 ,val loss : 0.382652 ,val acc : 0.824585\n",
      "[ ecpho : 7  iter :330 ]train loss : 0.236705 ,train acc: 0.887156 ,val loss : 0.382744 ,val acc : 0.829407\n",
      "[ ecpho : 7  iter :331 ]train loss : 0.243765 ,train acc: 0.886088 ,val loss : 0.375097 ,val acc : 0.828339\n",
      "[ ecpho : 7  iter :332 ]train loss : 0.283525 ,train acc: 0.868591 ,val loss : 0.381114 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :333 ]train loss : 0.342133 ,train acc: 0.840505 ,val loss : 0.376845 ,val acc : 0.826569\n",
      "[ ecpho : 7  iter :334 ]train loss : 0.301605 ,train acc: 0.866262 ,val loss : 0.385285 ,val acc : 0.825043\n",
      "[ ecpho : 7  iter :335 ]train loss : 0.303704 ,train acc: 0.860799 ,val loss : 0.382252 ,val acc : 0.826569\n",
      "[ ecpho : 7  iter :336 ]train loss : 0.372626 ,train acc: 0.841400 ,val loss : 0.376555 ,val acc : 0.825562\n",
      "[ ecpho : 7  iter :337 ]train loss : 0.295626 ,train acc: 0.861827 ,val loss : 0.380858 ,val acc : 0.823120\n",
      "[ ecpho : 7  iter :338 ]train loss : 0.314120 ,train acc: 0.853678 ,val loss : 0.381309 ,val acc : 0.826630\n",
      "[ ecpho : 7  iter :339 ]train loss : 0.335736 ,train acc: 0.824361 ,val loss : 0.377231 ,val acc : 0.830048\n",
      "[ ecpho : 7  iter :340 ]train loss : 0.345017 ,train acc: 0.846934 ,val loss : 0.386920 ,val acc : 0.825287\n",
      "[ ecpho : 7  iter :341 ]train loss : 0.249888 ,train acc: 0.882477 ,val loss : 0.381636 ,val acc : 0.825500\n",
      "[ ecpho : 7  iter :342 ]train loss : 0.311408 ,train acc: 0.852651 ,val loss : 0.381460 ,val acc : 0.826569\n",
      "[ ecpho : 7  iter :343 ]train loss : 0.424648 ,train acc: 0.823944 ,val loss : 0.382203 ,val acc : 0.831573\n",
      "[ ecpho : 7  iter :344 ]train loss : 0.433008 ,train acc: 0.836578 ,val loss : 0.380829 ,val acc : 0.832703\n",
      "[ ecpho : 7  iter :345 ]train loss : 0.242806 ,train acc: 0.882446 ,val loss : 0.381860 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :346 ]train loss : 0.311113 ,train acc: 0.840119 ,val loss : 0.383469 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :347 ]train loss : 0.285307 ,train acc: 0.868022 ,val loss : 0.379848 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :348 ]train loss : 0.485674 ,train acc: 0.784495 ,val loss : 0.385029 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :349 ]train loss : 0.303471 ,train acc: 0.849050 ,val loss : 0.380132 ,val acc : 0.826752\n",
      "[ ecpho : 7  iter :350 ]train loss : 0.319489 ,train acc: 0.852356 ,val loss : 0.384772 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :351 ]train loss : 0.287030 ,train acc: 0.864360 ,val loss : 0.381503 ,val acc : 0.828735\n",
      "[ ecpho : 7  iter :352 ]train loss : 0.400171 ,train acc: 0.838033 ,val loss : 0.373496 ,val acc : 0.828522\n",
      "[ ecpho : 7  iter :353 ]train loss : 0.336018 ,train acc: 0.854889 ,val loss : 0.376316 ,val acc : 0.829956\n",
      "[ ecpho : 7  iter :354 ]train loss : 0.245680 ,train acc: 0.884043 ,val loss : 0.381214 ,val acc : 0.825195\n",
      "[ ecpho : 7  iter :355 ]train loss : 0.272071 ,train acc: 0.869985 ,val loss : 0.375551 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :356 ]train loss : 0.241960 ,train acc: 0.885183 ,val loss : 0.382570 ,val acc : 0.829987\n",
      "[ ecpho : 7  iter :357 ]train loss : 0.262962 ,train acc: 0.875987 ,val loss : 0.377357 ,val acc : 0.825104\n",
      "[ ecpho : 7  iter :358 ]train loss : 0.381690 ,train acc: 0.845734 ,val loss : 0.378512 ,val acc : 0.830109\n",
      "[ ecpho : 7  iter :359 ]train loss : 0.287824 ,train acc: 0.861277 ,val loss : 0.380518 ,val acc : 0.826447\n",
      "[ ecpho : 7  iter :360 ]train loss : 0.295510 ,train acc: 0.864645 ,val loss : 0.382059 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :361 ]train loss : 0.235694 ,train acc: 0.888153 ,val loss : 0.386720 ,val acc : 0.824249\n",
      "[ ecpho : 7  iter :362 ]train loss : 0.309466 ,train acc: 0.859355 ,val loss : 0.383005 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :363 ]train loss : 0.420467 ,train acc: 0.840027 ,val loss : 0.381502 ,val acc : 0.825867\n",
      "[ ecpho : 7  iter :364 ]train loss : 0.382369 ,train acc: 0.828145 ,val loss : 0.379675 ,val acc : 0.826080\n",
      "[ ecpho : 7  iter :365 ]train loss : 0.254913 ,train acc: 0.881805 ,val loss : 0.380982 ,val acc : 0.825043\n",
      "[ ecpho : 7  iter :366 ]train loss : 0.263033 ,train acc: 0.869100 ,val loss : 0.381519 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :367 ]train loss : 0.293049 ,train acc: 0.853506 ,val loss : 0.383469 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :368 ]train loss : 0.232942 ,train acc: 0.890584 ,val loss : 0.382139 ,val acc : 0.827942\n",
      "[ ecpho : 7  iter :369 ]train loss : 0.339714 ,train acc: 0.852142 ,val loss : 0.379821 ,val acc : 0.828583\n",
      "[ ecpho : 7  iter :370 ]train loss : 0.280907 ,train acc: 0.863047 ,val loss : 0.381576 ,val acc : 0.825439\n",
      "[ ecpho : 7  iter :371 ]train loss : 0.389817 ,train acc: 0.807719 ,val loss : 0.383800 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :372 ]train loss : 0.265149 ,train acc: 0.873667 ,val loss : 0.380216 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :373 ]train loss : 0.317339 ,train acc: 0.855855 ,val loss : 0.383501 ,val acc : 0.825104\n",
      "[ ecpho : 7  iter :374 ]train loss : 0.430755 ,train acc: 0.787537 ,val loss : 0.383371 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :375 ]train loss : 0.523445 ,train acc: 0.747762 ,val loss : 0.382640 ,val acc : 0.824829\n",
      "[ ecpho : 7  iter :376 ]train loss : 0.415926 ,train acc: 0.827535 ,val loss : 0.382940 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :377 ]train loss : 0.247517 ,train acc: 0.879608 ,val loss : 0.380298 ,val acc : 0.829132\n",
      "[ ecpho : 7  iter :378 ]train loss : 0.295627 ,train acc: 0.852325 ,val loss : 0.378332 ,val acc : 0.830109\n",
      "[ ecpho : 7  iter :379 ]train loss : 0.421608 ,train acc: 0.784261 ,val loss : 0.377350 ,val acc : 0.829254\n",
      "[ ecpho : 7  iter :380 ]train loss : 0.257012 ,train acc: 0.873495 ,val loss : 0.384542 ,val acc : 0.827759\n",
      "[ ecpho : 7  iter :381 ]train loss : 0.286182 ,train acc: 0.862091 ,val loss : 0.380846 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :382 ]train loss : 0.368866 ,train acc: 0.829020 ,val loss : 0.379108 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :383 ]train loss : 0.253960 ,train acc: 0.873159 ,val loss : 0.385330 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :384 ]train loss : 0.304988 ,train acc: 0.850179 ,val loss : 0.380266 ,val acc : 0.830597\n",
      "[ ecpho : 7  iter :385 ]train loss : 0.267826 ,train acc: 0.867686 ,val loss : 0.382682 ,val acc : 0.824982\n",
      "[ ecpho : 7  iter :386 ]train loss : 0.237817 ,train acc: 0.886729 ,val loss : 0.377863 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :387 ]train loss : 0.387995 ,train acc: 0.830231 ,val loss : 0.377820 ,val acc : 0.830292\n",
      "[ ecpho : 7  iter :388 ]train loss : 0.383541 ,train acc: 0.810018 ,val loss : 0.379550 ,val acc : 0.825684\n",
      "[ ecpho : 7  iter :389 ]train loss : 0.365404 ,train acc: 0.826772 ,val loss : 0.379216 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :390 ]train loss : 0.269857 ,train acc: 0.878581 ,val loss : 0.379446 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :391 ]train loss : 0.256892 ,train acc: 0.874654 ,val loss : 0.382831 ,val acc : 0.828857\n",
      "[ ecpho : 7  iter :392 ]train loss : 0.295801 ,train acc: 0.862681 ,val loss : 0.388243 ,val acc : 0.824493\n",
      "[ ecpho : 7  iter :393 ]train loss : 0.302554 ,train acc: 0.873057 ,val loss : 0.377921 ,val acc : 0.830597\n",
      "[ ecpho : 7  iter :394 ]train loss : 0.306216 ,train acc: 0.859070 ,val loss : 0.376069 ,val acc : 0.830017\n",
      "[ ecpho : 7  iter :395 ]train loss : 0.410713 ,train acc: 0.846924 ,val loss : 0.382904 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :396 ]train loss : 0.270174 ,train acc: 0.866231 ,val loss : 0.381275 ,val acc : 0.828644\n",
      "[ ecpho : 7  iter :397 ]train loss : 0.263180 ,train acc: 0.871948 ,val loss : 0.379468 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :398 ]train loss : 0.245011 ,train acc: 0.880636 ,val loss : 0.387247 ,val acc : 0.825623\n",
      "[ ecpho : 7  iter :399 ]train loss : 0.346411 ,train acc: 0.836345 ,val loss : 0.381021 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :400 ]train loss : 0.406520 ,train acc: 0.826284 ,val loss : 0.380823 ,val acc : 0.826263\n",
      "[ ecpho : 7  iter :401 ]train loss : 0.339789 ,train acc: 0.859731 ,val loss : 0.377823 ,val acc : 0.830994\n",
      "[ ecpho : 7  iter :402 ]train loss : 0.502231 ,train acc: 0.821340 ,val loss : 0.379684 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :403 ]train loss : 0.263740 ,train acc: 0.871440 ,val loss : 0.382453 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :404 ]train loss : 0.304468 ,train acc: 0.858409 ,val loss : 0.386132 ,val acc : 0.825867\n",
      "[ ecpho : 7  iter :405 ]train loss : 0.253894 ,train acc: 0.871623 ,val loss : 0.379221 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :406 ]train loss : 0.238549 ,train acc: 0.883464 ,val loss : 0.389041 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :407 ]train loss : 0.305971 ,train acc: 0.857605 ,val loss : 0.378136 ,val acc : 0.826874\n",
      "[ ecpho : 7  iter :408 ]train loss : 0.277049 ,train acc: 0.865346 ,val loss : 0.383747 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :409 ]train loss : 0.250364 ,train acc: 0.879873 ,val loss : 0.377318 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :410 ]train loss : 0.302721 ,train acc: 0.859548 ,val loss : 0.379219 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :411 ]train loss : 0.319922 ,train acc: 0.858917 ,val loss : 0.382012 ,val acc : 0.825562\n",
      "[ ecpho : 7  iter :412 ]train loss : 0.371314 ,train acc: 0.816834 ,val loss : 0.377373 ,val acc : 0.831848\n",
      "[ ecpho : 7  iter :413 ]train loss : 0.284182 ,train acc: 0.866852 ,val loss : 0.380270 ,val acc : 0.831512\n",
      "[ ecpho : 7  iter :414 ]train loss : 0.262097 ,train acc: 0.875193 ,val loss : 0.378680 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :415 ]train loss : 0.400789 ,train acc: 0.819163 ,val loss : 0.380194 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :416 ]train loss : 0.269988 ,train acc: 0.870392 ,val loss : 0.377989 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :417 ]train loss : 0.425103 ,train acc: 0.773387 ,val loss : 0.379685 ,val acc : 0.827637\n",
      "[ ecpho : 7  iter :418 ]train loss : 0.371955 ,train acc: 0.845754 ,val loss : 0.385549 ,val acc : 0.828888\n",
      "[ ecpho : 7  iter :419 ]train loss : 0.314772 ,train acc: 0.854655 ,val loss : 0.379137 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :420 ]train loss : 0.312970 ,train acc: 0.855540 ,val loss : 0.378512 ,val acc : 0.829926\n",
      "[ ecpho : 7  iter :421 ]train loss : 0.335218 ,train acc: 0.830363 ,val loss : 0.380355 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :422 ]train loss : 0.294229 ,train acc: 0.864278 ,val loss : 0.376494 ,val acc : 0.828918\n",
      "[ ecpho : 7  iter :423 ]train loss : 0.325515 ,train acc: 0.852732 ,val loss : 0.377709 ,val acc : 0.828308\n",
      "[ ecpho : 7  iter :424 ]train loss : 0.254011 ,train acc: 0.880147 ,val loss : 0.383466 ,val acc : 0.829102\n",
      "[ ecpho : 7  iter :425 ]train loss : 0.268115 ,train acc: 0.873678 ,val loss : 0.378368 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :426 ]train loss : 0.319835 ,train acc: 0.857188 ,val loss : 0.383999 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :427 ]train loss : 0.370219 ,train acc: 0.845897 ,val loss : 0.379612 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :428 ]train loss : 0.368534 ,train acc: 0.855225 ,val loss : 0.385029 ,val acc : 0.825958\n",
      "[ ecpho : 7  iter :429 ]train loss : 0.271150 ,train acc: 0.864878 ,val loss : 0.384479 ,val acc : 0.828827\n",
      "[ ecpho : 7  iter :430 ]train loss : 0.335784 ,train acc: 0.839722 ,val loss : 0.384770 ,val acc : 0.826141\n",
      "[ ecpho : 7  iter :431 ]train loss : 0.284087 ,train acc: 0.871826 ,val loss : 0.381585 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :432 ]train loss : 0.266692 ,train acc: 0.872742 ,val loss : 0.381752 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :433 ]train loss : 0.343624 ,train acc: 0.832967 ,val loss : 0.380854 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :434 ]train loss : 0.394965 ,train acc: 0.823242 ,val loss : 0.382937 ,val acc : 0.828369\n",
      "[ ecpho : 7  iter :435 ]train loss : 0.276083 ,train acc: 0.877726 ,val loss : 0.383178 ,val acc : 0.829865\n",
      "[ ecpho : 7  iter :436 ]train loss : 0.293899 ,train acc: 0.867340 ,val loss : 0.378842 ,val acc : 0.831024\n",
      "[ ecpho : 7  iter :437 ]train loss : 0.365070 ,train acc: 0.844269 ,val loss : 0.392368 ,val acc : 0.823212\n",
      "[ ecpho : 7  iter :438 ]train loss : 0.240729 ,train acc: 0.885193 ,val loss : 0.377360 ,val acc : 0.829132\n",
      "[ ecpho : 7  iter :439 ]train loss : 0.241418 ,train acc: 0.882823 ,val loss : 0.375919 ,val acc : 0.830231\n",
      "[ ecpho : 7  iter :440 ]train loss : 0.368646 ,train acc: 0.840464 ,val loss : 0.383156 ,val acc : 0.826660\n",
      "[ ecpho : 7  iter :441 ]train loss : 0.274660 ,train acc: 0.867828 ,val loss : 0.380901 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :442 ]train loss : 0.245960 ,train acc: 0.879751 ,val loss : 0.380856 ,val acc : 0.825470\n",
      "[ ecpho : 7  iter :443 ]train loss : 0.372622 ,train acc: 0.838939 ,val loss : 0.381103 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :444 ]train loss : 0.265080 ,train acc: 0.878703 ,val loss : 0.385011 ,val acc : 0.826843\n",
      "[ ecpho : 7  iter :445 ]train loss : 0.408724 ,train acc: 0.839417 ,val loss : 0.374713 ,val acc : 0.830322\n",
      "[ ecpho : 7  iter :446 ]train loss : 0.278588 ,train acc: 0.876058 ,val loss : 0.383012 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :447 ]train loss : 0.252522 ,train acc: 0.879964 ,val loss : 0.381232 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :448 ]train loss : 0.273907 ,train acc: 0.875631 ,val loss : 0.383468 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :449 ]train loss : 0.278474 ,train acc: 0.868164 ,val loss : 0.381618 ,val acc : 0.828064\n",
      "[ ecpho : 7  iter :450 ]train loss : 0.261591 ,train acc: 0.872182 ,val loss : 0.379205 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :451 ]train loss : 0.248997 ,train acc: 0.881897 ,val loss : 0.385697 ,val acc : 0.823883\n",
      "[ ecpho : 7  iter :452 ]train loss : 0.276880 ,train acc: 0.875051 ,val loss : 0.380456 ,val acc : 0.826752\n",
      "[ ecpho : 7  iter :453 ]train loss : 0.313461 ,train acc: 0.849264 ,val loss : 0.380788 ,val acc : 0.831604\n",
      "[ ecpho : 7  iter :454 ]train loss : 0.340208 ,train acc: 0.830516 ,val loss : 0.382975 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :455 ]train loss : 0.391845 ,train acc: 0.795766 ,val loss : 0.378506 ,val acc : 0.825287\n",
      "[ ecpho : 7  iter :456 ]train loss : 0.244206 ,train acc: 0.883565 ,val loss : 0.383673 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :457 ]train loss : 0.363015 ,train acc: 0.830648 ,val loss : 0.377605 ,val acc : 0.831848\n",
      "[ ecpho : 7  iter :458 ]train loss : 0.278188 ,train acc: 0.871287 ,val loss : 0.383473 ,val acc : 0.824158\n",
      "[ ecpho : 7  iter :459 ]train loss : 0.243075 ,train acc: 0.881480 ,val loss : 0.386404 ,val acc : 0.826813\n",
      "[ ecpho : 7  iter :460 ]train loss : 0.348745 ,train acc: 0.853587 ,val loss : 0.380834 ,val acc : 0.825104\n",
      "[ ecpho : 7  iter :461 ]train loss : 0.266112 ,train acc: 0.870209 ,val loss : 0.388637 ,val acc : 0.828644\n",
      "[ ecpho : 7  iter :462 ]train loss : 0.285551 ,train acc: 0.850545 ,val loss : 0.387338 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :463 ]train loss : 0.266631 ,train acc: 0.873708 ,val loss : 0.382983 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :464 ]train loss : 0.268958 ,train acc: 0.868947 ,val loss : 0.377804 ,val acc : 0.829254\n",
      "[ ecpho : 7  iter :465 ]train loss : 0.420328 ,train acc: 0.737356 ,val loss : 0.383808 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :466 ]train loss : 0.352449 ,train acc: 0.851532 ,val loss : 0.380162 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :467 ]train loss : 0.247345 ,train acc: 0.880605 ,val loss : 0.378893 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :468 ]train loss : 0.288999 ,train acc: 0.870911 ,val loss : 0.381431 ,val acc : 0.825928\n",
      "[ ecpho : 7  iter :469 ]train loss : 0.297005 ,train acc: 0.850505 ,val loss : 0.389285 ,val acc : 0.825439\n",
      "[ ecpho : 7  iter :470 ]train loss : 0.268357 ,train acc: 0.872101 ,val loss : 0.379292 ,val acc : 0.830841\n",
      "[ ecpho : 7  iter :471 ]train loss : 0.330603 ,train acc: 0.855265 ,val loss : 0.379375 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :472 ]train loss : 0.275319 ,train acc: 0.871877 ,val loss : 0.378724 ,val acc : 0.828522\n",
      "[ ecpho : 7  iter :473 ]train loss : 0.295796 ,train acc: 0.851542 ,val loss : 0.384038 ,val acc : 0.827179\n",
      "[ ecpho : 7  iter :474 ]train loss : 0.289586 ,train acc: 0.864451 ,val loss : 0.381497 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :475 ]train loss : 0.315771 ,train acc: 0.869792 ,val loss : 0.385376 ,val acc : 0.827057\n",
      "[ ecpho : 7  iter :476 ]train loss : 0.310198 ,train acc: 0.839813 ,val loss : 0.382455 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :477 ]train loss : 0.366125 ,train acc: 0.828440 ,val loss : 0.383177 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :478 ]train loss : 0.266127 ,train acc: 0.872040 ,val loss : 0.380635 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :479 ]train loss : 0.287593 ,train acc: 0.872467 ,val loss : 0.382739 ,val acc : 0.825531\n",
      "[ ecpho : 7  iter :480 ]train loss : 0.269288 ,train acc: 0.875407 ,val loss : 0.379356 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :481 ]train loss : 0.457619 ,train acc: 0.771505 ,val loss : 0.378849 ,val acc : 0.828125\n",
      "[ ecpho : 7  iter :482 ]train loss : 0.354354 ,train acc: 0.828634 ,val loss : 0.382744 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :483 ]train loss : 0.278268 ,train acc: 0.871450 ,val loss : 0.381119 ,val acc : 0.830139\n",
      "[ ecpho : 7  iter :484 ]train loss : 0.266778 ,train acc: 0.877797 ,val loss : 0.383437 ,val acc : 0.826385\n",
      "[ ecpho : 7  iter :485 ]train loss : 0.375143 ,train acc: 0.859741 ,val loss : 0.381351 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :486 ]train loss : 0.285754 ,train acc: 0.868215 ,val loss : 0.378821 ,val acc : 0.830353\n",
      "[ ecpho : 7  iter :487 ]train loss : 0.298210 ,train acc: 0.856924 ,val loss : 0.373348 ,val acc : 0.829620\n",
      "[ ecpho : 7  iter :488 ]train loss : 0.453182 ,train acc: 0.807851 ,val loss : 0.379797 ,val acc : 0.829803\n",
      "[ ecpho : 7  iter :489 ]train loss : 0.289532 ,train acc: 0.858368 ,val loss : 0.381878 ,val acc : 0.828735\n",
      "[ ecpho : 7  iter :490 ]train loss : 0.290184 ,train acc: 0.861796 ,val loss : 0.383789 ,val acc : 0.829224\n",
      "[ ecpho : 7  iter :491 ]train loss : 0.360108 ,train acc: 0.821208 ,val loss : 0.384924 ,val acc : 0.825470\n",
      "[ ecpho : 7  iter :492 ]train loss : 0.457542 ,train acc: 0.800527 ,val loss : 0.387847 ,val acc : 0.824219\n",
      "[ ecpho : 7  iter :493 ]train loss : 0.297685 ,train acc: 0.867737 ,val loss : 0.381474 ,val acc : 0.830414\n",
      "[ ecpho : 7  iter :494 ]train loss : 0.300713 ,train acc: 0.859741 ,val loss : 0.379873 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :495 ]train loss : 0.301609 ,train acc: 0.869568 ,val loss : 0.377813 ,val acc : 0.828766\n",
      "[ ecpho : 7  iter :496 ]train loss : 0.293356 ,train acc: 0.855306 ,val loss : 0.383452 ,val acc : 0.824188\n",
      "[ ecpho : 7  iter :497 ]train loss : 0.394773 ,train acc: 0.816223 ,val loss : 0.383054 ,val acc : 0.828979\n",
      "[ ecpho : 7  iter :498 ]train loss : 0.269765 ,train acc: 0.873047 ,val loss : 0.386398 ,val acc : 0.822968\n",
      "[ ecpho : 7  iter :499 ]train loss : 0.260531 ,train acc: 0.872803 ,val loss : 0.383863 ,val acc : 0.824951\n",
      "[ ecpho : 7  iter :500 ]train loss : 0.346653 ,train acc: 0.834463 ,val loss : 0.384551 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :501 ]train loss : 0.338589 ,train acc: 0.857625 ,val loss : 0.382170 ,val acc : 0.824829\n",
      "[ ecpho : 7  iter :502 ]train loss : 0.333630 ,train acc: 0.841532 ,val loss : 0.381443 ,val acc : 0.829102\n",
      "[ ecpho : 7  iter :503 ]train loss : 0.235202 ,train acc: 0.889109 ,val loss : 0.385033 ,val acc : 0.826050\n",
      "[ ecpho : 7  iter :504 ]train loss : 0.269850 ,train acc: 0.864268 ,val loss : 0.379788 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :505 ]train loss : 0.316366 ,train acc: 0.856039 ,val loss : 0.386837 ,val acc : 0.825836\n",
      "[ ecpho : 7  iter :506 ]train loss : 0.314823 ,train acc: 0.865784 ,val loss : 0.382945 ,val acc : 0.825958\n",
      "[ ecpho : 7  iter :507 ]train loss : 0.249459 ,train acc: 0.883016 ,val loss : 0.390549 ,val acc : 0.822571\n",
      "[ ecpho : 7  iter :508 ]train loss : 0.364925 ,train acc: 0.800374 ,val loss : 0.383362 ,val acc : 0.825256\n",
      "[ ecpho : 7  iter :509 ]train loss : 0.330400 ,train acc: 0.859446 ,val loss : 0.381316 ,val acc : 0.826752\n",
      "[ ecpho : 7  iter :510 ]train loss : 0.278060 ,train acc: 0.871735 ,val loss : 0.380269 ,val acc : 0.827759\n",
      "[ ecpho : 7  iter :511 ]train loss : 0.291006 ,train acc: 0.866099 ,val loss : 0.379657 ,val acc : 0.829651\n",
      "[ ecpho : 7  iter :512 ]train loss : 0.336283 ,train acc: 0.853882 ,val loss : 0.380094 ,val acc : 0.825653\n",
      "[ ecpho : 7  iter :513 ]train loss : 0.265819 ,train acc: 0.874685 ,val loss : 0.379842 ,val acc : 0.829987\n",
      "[ ecpho : 7  iter :514 ]train loss : 0.265050 ,train acc: 0.872894 ,val loss : 0.384404 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :515 ]train loss : 0.310854 ,train acc: 0.865133 ,val loss : 0.384368 ,val acc : 0.829895\n",
      "[ ecpho : 7  iter :516 ]train loss : 0.317035 ,train acc: 0.856496 ,val loss : 0.378918 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :517 ]train loss : 0.371959 ,train acc: 0.828644 ,val loss : 0.374816 ,val acc : 0.830017\n",
      "[ ecpho : 7  iter :518 ]train loss : 0.319931 ,train acc: 0.850220 ,val loss : 0.382868 ,val acc : 0.828888\n",
      "[ ecpho : 7  iter :519 ]train loss : 0.312524 ,train acc: 0.863363 ,val loss : 0.381751 ,val acc : 0.829376\n",
      "[ ecpho : 7  iter :520 ]train loss : 0.353851 ,train acc: 0.806783 ,val loss : 0.381963 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :521 ]train loss : 0.263253 ,train acc: 0.876862 ,val loss : 0.380396 ,val acc : 0.829285\n",
      "[ ecpho : 7  iter :522 ]train loss : 0.314402 ,train acc: 0.847565 ,val loss : 0.379237 ,val acc : 0.829895\n",
      "[ ecpho : 7  iter :523 ]train loss : 0.340280 ,train acc: 0.847127 ,val loss : 0.379066 ,val acc : 0.830048\n",
      "[ ecpho : 7  iter :524 ]train loss : 0.282270 ,train acc: 0.862366 ,val loss : 0.377922 ,val acc : 0.828430\n",
      "[ ecpho : 7  iter :525 ]train loss : 0.310214 ,train acc: 0.859243 ,val loss : 0.386741 ,val acc : 0.825989\n",
      "[ ecpho : 7  iter :526 ]train loss : 0.274118 ,train acc: 0.871694 ,val loss : 0.383499 ,val acc : 0.826752\n",
      "[ ecpho : 7  iter :527 ]train loss : 0.324094 ,train acc: 0.845459 ,val loss : 0.378931 ,val acc : 0.828308\n",
      "[ ecpho : 7  iter :528 ]train loss : 0.234677 ,train acc: 0.887777 ,val loss : 0.383026 ,val acc : 0.826538\n",
      "[ ecpho : 7  iter :529 ]train loss : 0.353107 ,train acc: 0.857107 ,val loss : 0.380940 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :530 ]train loss : 0.408709 ,train acc: 0.847921 ,val loss : 0.383723 ,val acc : 0.830566\n",
      "[ ecpho : 7  iter :531 ]train loss : 0.245738 ,train acc: 0.885264 ,val loss : 0.388203 ,val acc : 0.826538\n",
      "[ ecpho : 7  iter :532 ]train loss : 0.335947 ,train acc: 0.837433 ,val loss : 0.378196 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :533 ]train loss : 0.253385 ,train acc: 0.882690 ,val loss : 0.383850 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :534 ]train loss : 0.271982 ,train acc: 0.872884 ,val loss : 0.386303 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :535 ]train loss : 0.284568 ,train acc: 0.866242 ,val loss : 0.377648 ,val acc : 0.828064\n",
      "[ ecpho : 7  iter :536 ]train loss : 0.414885 ,train acc: 0.797720 ,val loss : 0.377400 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :537 ]train loss : 0.278743 ,train acc: 0.872426 ,val loss : 0.381607 ,val acc : 0.829285\n",
      "[ ecpho : 7  iter :538 ]train loss : 0.531699 ,train acc: 0.770457 ,val loss : 0.383573 ,val acc : 0.823517\n",
      "[ ecpho : 7  iter :539 ]train loss : 0.260679 ,train acc: 0.872589 ,val loss : 0.378837 ,val acc : 0.829285\n",
      "[ ecpho : 7  iter :540 ]train loss : 0.306615 ,train acc: 0.857778 ,val loss : 0.378774 ,val acc : 0.831543\n",
      "[ ecpho : 7  iter :541 ]train loss : 0.273384 ,train acc: 0.869120 ,val loss : 0.384702 ,val acc : 0.826874\n",
      "[ ecpho : 7  iter :542 ]train loss : 0.352180 ,train acc: 0.848073 ,val loss : 0.386500 ,val acc : 0.826080\n",
      "[ ecpho : 7  iter :543 ]train loss : 0.288703 ,train acc: 0.864889 ,val loss : 0.385728 ,val acc : 0.827271\n",
      "[ ecpho : 7  iter :544 ]train loss : 0.293570 ,train acc: 0.860911 ,val loss : 0.382357 ,val acc : 0.828308\n",
      "[ ecpho : 7  iter :545 ]train loss : 0.241670 ,train acc: 0.881775 ,val loss : 0.384098 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :546 ]train loss : 0.307428 ,train acc: 0.858917 ,val loss : 0.375660 ,val acc : 0.830688\n",
      "[ ecpho : 7  iter :547 ]train loss : 0.306075 ,train acc: 0.858714 ,val loss : 0.381387 ,val acc : 0.825653\n",
      "[ ecpho : 7  iter :548 ]train loss : 0.311953 ,train acc: 0.859690 ,val loss : 0.380476 ,val acc : 0.831757\n",
      "[ ecpho : 7  iter :549 ]train loss : 0.272439 ,train acc: 0.864126 ,val loss : 0.385962 ,val acc : 0.823883\n",
      "[ ecpho : 7  iter :550 ]train loss : 0.278621 ,train acc: 0.872284 ,val loss : 0.383253 ,val acc : 0.827667\n",
      "[ ecpho : 7  iter :551 ]train loss : 0.275107 ,train acc: 0.867198 ,val loss : 0.376065 ,val acc : 0.830811\n",
      "[ ecpho : 7  iter :552 ]train loss : 0.348506 ,train acc: 0.812714 ,val loss : 0.378745 ,val acc : 0.826782\n",
      "[ ecpho : 7  iter :553 ]train loss : 0.335992 ,train acc: 0.851654 ,val loss : 0.378258 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :554 ]train loss : 0.277493 ,train acc: 0.858612 ,val loss : 0.381642 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :555 ]train loss : 0.370800 ,train acc: 0.806163 ,val loss : 0.385764 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :556 ]train loss : 0.336609 ,train acc: 0.842336 ,val loss : 0.389085 ,val acc : 0.826111\n",
      "[ ecpho : 7  iter :557 ]train loss : 0.282496 ,train acc: 0.864075 ,val loss : 0.382828 ,val acc : 0.825226\n",
      "[ ecpho : 7  iter :558 ]train loss : 0.263981 ,train acc: 0.872793 ,val loss : 0.378615 ,val acc : 0.828125\n",
      "[ ecpho : 7  iter :559 ]train loss : 0.247279 ,train acc: 0.880900 ,val loss : 0.376040 ,val acc : 0.830902\n",
      "[ ecpho : 7  iter :560 ]train loss : 0.269847 ,train acc: 0.873149 ,val loss : 0.382070 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :561 ]train loss : 0.336713 ,train acc: 0.827851 ,val loss : 0.382907 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :562 ]train loss : 0.406975 ,train acc: 0.836853 ,val loss : 0.382006 ,val acc : 0.828430\n",
      "[ ecpho : 7  iter :563 ]train loss : 0.352679 ,train acc: 0.849426 ,val loss : 0.383866 ,val acc : 0.824921\n",
      "[ ecpho : 7  iter :564 ]train loss : 0.248571 ,train acc: 0.882497 ,val loss : 0.376952 ,val acc : 0.829437\n",
      "[ ecpho : 7  iter :565 ]train loss : 0.285715 ,train acc: 0.862132 ,val loss : 0.388606 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :566 ]train loss : 0.315521 ,train acc: 0.865438 ,val loss : 0.383219 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :567 ]train loss : 0.388004 ,train acc: 0.825165 ,val loss : 0.379012 ,val acc : 0.831665\n",
      "[ ecpho : 7  iter :568 ]train loss : 0.244294 ,train acc: 0.881378 ,val loss : 0.383630 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :569 ]train loss : 0.398770 ,train acc: 0.781779 ,val loss : 0.381208 ,val acc : 0.829193\n",
      "[ ecpho : 7  iter :570 ]train loss : 0.291361 ,train acc: 0.853963 ,val loss : 0.385669 ,val acc : 0.824493\n",
      "[ ecpho : 7  iter :571 ]train loss : 0.284932 ,train acc: 0.865621 ,val loss : 0.379127 ,val acc : 0.830078\n",
      "[ ecpho : 7  iter :572 ]train loss : 0.298054 ,train acc: 0.865773 ,val loss : 0.379402 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :573 ]train loss : 0.330597 ,train acc: 0.864075 ,val loss : 0.386183 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :574 ]train loss : 0.279493 ,train acc: 0.853139 ,val loss : 0.384790 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :575 ]train loss : 0.268298 ,train acc: 0.872233 ,val loss : 0.383462 ,val acc : 0.827637\n",
      "[ ecpho : 7  iter :576 ]train loss : 0.352367 ,train acc: 0.854787 ,val loss : 0.378619 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :577 ]train loss : 0.244411 ,train acc: 0.883586 ,val loss : 0.387651 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :578 ]train loss : 0.360685 ,train acc: 0.848196 ,val loss : 0.383481 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :579 ]train loss : 0.406668 ,train acc: 0.806692 ,val loss : 0.381569 ,val acc : 0.824554\n",
      "[ ecpho : 7  iter :580 ]train loss : 0.321145 ,train acc: 0.840892 ,val loss : 0.381708 ,val acc : 0.825256\n",
      "[ ecpho : 7  iter :581 ]train loss : 0.281522 ,train acc: 0.867757 ,val loss : 0.381862 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :582 ]train loss : 0.285901 ,train acc: 0.863576 ,val loss : 0.376735 ,val acc : 0.830933\n",
      "[ ecpho : 7  iter :583 ]train loss : 0.337989 ,train acc: 0.850322 ,val loss : 0.379056 ,val acc : 0.830078\n",
      "[ ecpho : 7  iter :584 ]train loss : 0.265379 ,train acc: 0.869649 ,val loss : 0.376124 ,val acc : 0.829956\n",
      "[ ecpho : 7  iter :585 ]train loss : 0.233858 ,train acc: 0.886220 ,val loss : 0.381370 ,val acc : 0.830322\n",
      "[ ecpho : 7  iter :586 ]train loss : 0.355103 ,train acc: 0.841400 ,val loss : 0.378775 ,val acc : 0.829681\n",
      "[ ecpho : 7  iter :587 ]train loss : 0.244909 ,train acc: 0.887004 ,val loss : 0.384849 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :588 ]train loss : 0.282845 ,train acc: 0.861654 ,val loss : 0.379950 ,val acc : 0.827057\n",
      "[ ecpho : 7  iter :589 ]train loss : 0.390184 ,train acc: 0.786672 ,val loss : 0.383697 ,val acc : 0.826355\n",
      "[ ecpho : 7  iter :590 ]train loss : 0.459641 ,train acc: 0.810028 ,val loss : 0.378193 ,val acc : 0.825897\n",
      "[ ecpho : 7  iter :591 ]train loss : 0.330968 ,train acc: 0.847901 ,val loss : 0.381999 ,val acc : 0.825775\n",
      "[ ecpho : 7  iter :592 ]train loss : 0.277901 ,train acc: 0.869446 ,val loss : 0.376775 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :593 ]train loss : 0.230285 ,train acc: 0.889831 ,val loss : 0.383033 ,val acc : 0.826080\n",
      "[ ecpho : 7  iter :594 ]train loss : 0.320496 ,train acc: 0.867188 ,val loss : 0.388884 ,val acc : 0.825928\n",
      "[ ecpho : 7  iter :595 ]train loss : 0.265964 ,train acc: 0.877981 ,val loss : 0.387460 ,val acc : 0.824799\n",
      "[ ecpho : 7  iter :596 ]train loss : 0.244353 ,train acc: 0.886302 ,val loss : 0.384383 ,val acc : 0.826691\n",
      "[ ecpho : 7  iter :597 ]train loss : 0.280137 ,train acc: 0.875773 ,val loss : 0.383937 ,val acc : 0.827301\n",
      "[ ecpho : 7  iter :598 ]train loss : 0.272576 ,train acc: 0.877899 ,val loss : 0.381267 ,val acc : 0.825470\n",
      "[ ecpho : 7  iter :599 ]train loss : 0.322222 ,train acc: 0.827260 ,val loss : 0.380338 ,val acc : 0.828430\n",
      "[ ecpho : 7  iter :600 ]train loss : 0.325074 ,train acc: 0.847646 ,val loss : 0.376425 ,val acc : 0.829926\n",
      "[ ecpho : 7  iter :601 ]train loss : 0.257340 ,train acc: 0.875305 ,val loss : 0.382893 ,val acc : 0.825226\n",
      "[ ecpho : 7  iter :602 ]train loss : 0.257189 ,train acc: 0.877411 ,val loss : 0.379015 ,val acc : 0.829865\n",
      "[ ecpho : 7  iter :603 ]train loss : 0.325537 ,train acc: 0.851776 ,val loss : 0.379011 ,val acc : 0.829681\n",
      "[ ecpho : 7  iter :604 ]train loss : 0.302119 ,train acc: 0.846110 ,val loss : 0.383080 ,val acc : 0.823792\n",
      "[ ecpho : 7  iter :605 ]train loss : 0.369625 ,train acc: 0.824931 ,val loss : 0.380518 ,val acc : 0.830627\n",
      "[ ecpho : 7  iter :606 ]train loss : 0.301660 ,train acc: 0.852977 ,val loss : 0.384642 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :607 ]train loss : 0.290945 ,train acc: 0.860321 ,val loss : 0.383592 ,val acc : 0.827942\n",
      "[ ecpho : 7  iter :608 ]train loss : 0.264835 ,train acc: 0.876485 ,val loss : 0.383898 ,val acc : 0.826050\n",
      "[ ecpho : 7  iter :609 ]train loss : 0.289799 ,train acc: 0.870494 ,val loss : 0.374986 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :610 ]train loss : 0.450715 ,train acc: 0.781952 ,val loss : 0.379944 ,val acc : 0.826996\n",
      "[ ecpho : 7  iter :611 ]train loss : 0.260613 ,train acc: 0.876556 ,val loss : 0.385426 ,val acc : 0.825195\n",
      "[ ecpho : 7  iter :612 ]train loss : 0.357978 ,train acc: 0.843618 ,val loss : 0.377147 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :613 ]train loss : 0.310839 ,train acc: 0.840770 ,val loss : 0.382528 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :614 ]train loss : 0.301000 ,train acc: 0.863546 ,val loss : 0.380137 ,val acc : 0.826080\n",
      "[ ecpho : 7  iter :615 ]train loss : 0.302464 ,train acc: 0.841044 ,val loss : 0.377152 ,val acc : 0.830750\n",
      "[ ecpho : 7  iter :616 ]train loss : 0.260970 ,train acc: 0.872711 ,val loss : 0.380187 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :617 ]train loss : 0.296861 ,train acc: 0.863790 ,val loss : 0.385295 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :618 ]train loss : 0.305051 ,train acc: 0.856771 ,val loss : 0.376683 ,val acc : 0.828369\n",
      "[ ecpho : 7  iter :619 ]train loss : 0.298248 ,train acc: 0.863739 ,val loss : 0.380659 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :620 ]train loss : 0.292815 ,train acc: 0.851135 ,val loss : 0.384196 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :621 ]train loss : 0.330567 ,train acc: 0.838572 ,val loss : 0.382356 ,val acc : 0.825745\n",
      "[ ecpho : 7  iter :622 ]train loss : 0.345079 ,train acc: 0.829397 ,val loss : 0.377543 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :623 ]train loss : 0.266157 ,train acc: 0.868998 ,val loss : 0.379435 ,val acc : 0.829041\n",
      "[ ecpho : 7  iter :624 ]train loss : 0.339823 ,train acc: 0.829956 ,val loss : 0.382072 ,val acc : 0.825592\n",
      "[ ecpho : 7  iter :625 ]train loss : 0.351732 ,train acc: 0.842611 ,val loss : 0.381637 ,val acc : 0.826813\n",
      "[ ecpho : 7  iter :626 ]train loss : 0.387783 ,train acc: 0.847270 ,val loss : 0.379422 ,val acc : 0.829803\n",
      "[ ecpho : 7  iter :627 ]train loss : 0.292819 ,train acc: 0.863271 ,val loss : 0.380995 ,val acc : 0.827179\n",
      "[ ecpho : 7  iter :628 ]train loss : 0.264890 ,train acc: 0.871826 ,val loss : 0.378000 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :629 ]train loss : 0.282646 ,train acc: 0.863505 ,val loss : 0.376859 ,val acc : 0.829468\n",
      "[ ecpho : 7  iter :630 ]train loss : 0.393301 ,train acc: 0.791697 ,val loss : 0.381444 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :631 ]train loss : 0.313283 ,train acc: 0.850800 ,val loss : 0.380432 ,val acc : 0.830383\n",
      "[ ecpho : 7  iter :632 ]train loss : 0.337143 ,train acc: 0.840780 ,val loss : 0.380324 ,val acc : 0.825897\n",
      "[ ecpho : 7  iter :633 ]train loss : 0.329731 ,train acc: 0.857849 ,val loss : 0.379533 ,val acc : 0.828369\n",
      "[ ecpho : 7  iter :634 ]train loss : 0.349070 ,train acc: 0.853353 ,val loss : 0.380268 ,val acc : 0.825897\n",
      "[ ecpho : 7  iter :635 ]train loss : 0.260103 ,train acc: 0.879405 ,val loss : 0.379504 ,val acc : 0.830231\n",
      "[ ecpho : 7  iter :636 ]train loss : 0.375098 ,train acc: 0.834188 ,val loss : 0.380080 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :637 ]train loss : 0.291966 ,train acc: 0.868022 ,val loss : 0.382633 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :638 ]train loss : 0.478104 ,train acc: 0.828512 ,val loss : 0.379099 ,val acc : 0.829865\n",
      "[ ecpho : 7  iter :639 ]train loss : 0.446478 ,train acc: 0.838755 ,val loss : 0.379002 ,val acc : 0.829437\n",
      "[ ecpho : 7  iter :640 ]train loss : 0.299583 ,train acc: 0.847595 ,val loss : 0.377362 ,val acc : 0.829315\n",
      "[ ecpho : 7  iter :641 ]train loss : 0.300532 ,train acc: 0.859701 ,val loss : 0.376259 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :642 ]train loss : 0.213352 ,train acc: 0.897909 ,val loss : 0.381691 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :643 ]train loss : 0.307427 ,train acc: 0.842021 ,val loss : 0.383523 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :644 ]train loss : 0.263683 ,train acc: 0.872589 ,val loss : 0.377562 ,val acc : 0.829865\n",
      "[ ecpho : 7  iter :645 ]train loss : 0.260080 ,train acc: 0.872284 ,val loss : 0.376876 ,val acc : 0.829193\n",
      "[ ecpho : 7  iter :646 ]train loss : 0.371645 ,train acc: 0.830089 ,val loss : 0.375616 ,val acc : 0.827179\n",
      "[ ecpho : 7  iter :647 ]train loss : 0.325419 ,train acc: 0.848480 ,val loss : 0.383759 ,val acc : 0.826202\n",
      "[ ecpho : 7  iter :648 ]train loss : 0.251805 ,train acc: 0.880432 ,val loss : 0.380921 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :649 ]train loss : 0.330568 ,train acc: 0.820302 ,val loss : 0.380030 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :650 ]train loss : 0.375878 ,train acc: 0.814942 ,val loss : 0.384212 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :651 ]train loss : 0.374246 ,train acc: 0.847310 ,val loss : 0.373684 ,val acc : 0.830902\n",
      "[ ecpho : 7  iter :652 ]train loss : 0.310707 ,train acc: 0.848216 ,val loss : 0.374825 ,val acc : 0.829132\n",
      "[ ecpho : 7  iter :653 ]train loss : 0.432086 ,train acc: 0.807475 ,val loss : 0.377123 ,val acc : 0.828735\n",
      "[ ecpho : 7  iter :654 ]train loss : 0.446710 ,train acc: 0.804606 ,val loss : 0.377558 ,val acc : 0.829529\n",
      "[ ecpho : 7  iter :655 ]train loss : 0.334500 ,train acc: 0.836345 ,val loss : 0.376657 ,val acc : 0.829834\n",
      "[ ecpho : 7  iter :656 ]train loss : 0.341573 ,train acc: 0.842489 ,val loss : 0.378933 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :657 ]train loss : 0.334623 ,train acc: 0.849976 ,val loss : 0.382524 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :658 ]train loss : 0.294433 ,train acc: 0.861471 ,val loss : 0.386368 ,val acc : 0.828613\n",
      "[ ecpho : 7  iter :659 ]train loss : 0.372651 ,train acc: 0.849101 ,val loss : 0.379094 ,val acc : 0.826080\n",
      "[ ecpho : 7  iter :660 ]train loss : 0.363160 ,train acc: 0.849487 ,val loss : 0.379515 ,val acc : 0.826233\n",
      "[ ecpho : 7  iter :661 ]train loss : 0.263492 ,train acc: 0.878072 ,val loss : 0.377122 ,val acc : 0.829346\n",
      "[ ecpho : 7  iter :662 ]train loss : 0.365527 ,train acc: 0.841278 ,val loss : 0.380163 ,val acc : 0.826202\n",
      "[ ecpho : 7  iter :663 ]train loss : 0.316807 ,train acc: 0.848012 ,val loss : 0.378506 ,val acc : 0.830536\n",
      "[ ecpho : 7  iter :664 ]train loss : 0.360939 ,train acc: 0.847107 ,val loss : 0.373823 ,val acc : 0.829498\n",
      "[ ecpho : 7  iter :665 ]train loss : 0.430753 ,train acc: 0.820760 ,val loss : 0.378658 ,val acc : 0.828430\n",
      "[ ecpho : 7  iter :666 ]train loss : 0.362035 ,train acc: 0.835999 ,val loss : 0.380509 ,val acc : 0.828857\n",
      "[ ecpho : 7  iter :667 ]train loss : 0.371026 ,train acc: 0.850016 ,val loss : 0.383129 ,val acc : 0.829376\n",
      "[ ecpho : 7  iter :668 ]train loss : 0.314847 ,train acc: 0.860535 ,val loss : 0.386710 ,val acc : 0.823090\n",
      "[ ecpho : 7  iter :669 ]train loss : 0.323919 ,train acc: 0.823141 ,val loss : 0.377165 ,val acc : 0.828644\n",
      "[ ecpho : 7  iter :670 ]train loss : 0.288889 ,train acc: 0.860504 ,val loss : 0.376732 ,val acc : 0.826691\n",
      "[ ecpho : 7  iter :671 ]train loss : 0.285751 ,train acc: 0.872467 ,val loss : 0.382639 ,val acc : 0.828674\n",
      "[ ecpho : 7  iter :672 ]train loss : 0.262572 ,train acc: 0.874593 ,val loss : 0.387739 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :673 ]train loss : 0.277458 ,train acc: 0.870138 ,val loss : 0.378053 ,val acc : 0.829834\n",
      "[ ecpho : 7  iter :674 ]train loss : 0.270782 ,train acc: 0.873372 ,val loss : 0.384575 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :675 ]train loss : 0.313917 ,train acc: 0.867411 ,val loss : 0.380962 ,val acc : 0.829834\n",
      "[ ecpho : 7  iter :676 ]train loss : 0.259750 ,train acc: 0.870026 ,val loss : 0.380441 ,val acc : 0.829956\n",
      "[ ecpho : 7  iter :677 ]train loss : 0.274901 ,train acc: 0.868947 ,val loss : 0.381343 ,val acc : 0.829407\n",
      "[ ecpho : 7  iter :678 ]train loss : 0.218579 ,train acc: 0.893921 ,val loss : 0.384439 ,val acc : 0.826202\n",
      "[ ecpho : 7  iter :679 ]train loss : 0.298728 ,train acc: 0.861674 ,val loss : 0.383268 ,val acc : 0.831573\n",
      "[ ecpho : 7  iter :680 ]train loss : 0.319116 ,train acc: 0.865428 ,val loss : 0.383181 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :681 ]train loss : 0.272467 ,train acc: 0.876994 ,val loss : 0.379708 ,val acc : 0.826721\n",
      "[ ecpho : 7  iter :682 ]train loss : 0.261064 ,train acc: 0.876790 ,val loss : 0.380928 ,val acc : 0.826355\n",
      "[ ecpho : 7  iter :683 ]train loss : 0.281320 ,train acc: 0.868917 ,val loss : 0.384511 ,val acc : 0.826263\n",
      "[ ecpho : 7  iter :684 ]train loss : 0.294447 ,train acc: 0.862478 ,val loss : 0.379660 ,val acc : 0.826263\n",
      "[ ecpho : 7  iter :685 ]train loss : 0.366605 ,train acc: 0.847412 ,val loss : 0.380093 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :686 ]train loss : 0.424172 ,train acc: 0.787181 ,val loss : 0.384459 ,val acc : 0.824890\n",
      "[ ecpho : 7  iter :687 ]train loss : 0.284752 ,train acc: 0.866496 ,val loss : 0.377938 ,val acc : 0.827271\n",
      "[ ecpho : 7  iter :688 ]train loss : 0.352248 ,train acc: 0.823964 ,val loss : 0.378112 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :689 ]train loss : 0.315008 ,train acc: 0.856415 ,val loss : 0.386432 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :690 ]train loss : 0.311867 ,train acc: 0.867381 ,val loss : 0.381616 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :691 ]train loss : 0.398802 ,train acc: 0.841166 ,val loss : 0.375556 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :692 ]train loss : 0.242274 ,train acc: 0.881144 ,val loss : 0.381027 ,val acc : 0.826111\n",
      "[ ecpho : 7  iter :693 ]train loss : 0.258175 ,train acc: 0.875499 ,val loss : 0.376007 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :694 ]train loss : 0.332748 ,train acc: 0.856862 ,val loss : 0.383123 ,val acc : 0.828827\n",
      "[ ecpho : 7  iter :695 ]train loss : 0.257583 ,train acc: 0.880971 ,val loss : 0.383634 ,val acc : 0.830505\n",
      "[ ecpho : 7  iter :696 ]train loss : 0.269213 ,train acc: 0.871480 ,val loss : 0.378504 ,val acc : 0.832001\n",
      "[ ecpho : 7  iter :697 ]train loss : 0.251724 ,train acc: 0.886403 ,val loss : 0.381668 ,val acc : 0.830292\n",
      "[ ecpho : 7  iter :698 ]train loss : 0.350082 ,train acc: 0.826487 ,val loss : 0.379849 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :699 ]train loss : 0.336217 ,train acc: 0.847127 ,val loss : 0.377390 ,val acc : 0.829498\n",
      "[ ecpho : 7  iter :700 ]train loss : 0.411228 ,train acc: 0.833201 ,val loss : 0.380380 ,val acc : 0.824219\n",
      "[ ecpho : 7  iter :701 ]train loss : 0.412289 ,train acc: 0.816600 ,val loss : 0.381231 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :702 ]train loss : 0.267722 ,train acc: 0.872925 ,val loss : 0.383994 ,val acc : 0.823334\n",
      "[ ecpho : 7  iter :703 ]train loss : 0.266873 ,train acc: 0.875173 ,val loss : 0.377550 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :704 ]train loss : 0.303198 ,train acc: 0.855927 ,val loss : 0.380617 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :705 ]train loss : 0.265686 ,train acc: 0.878672 ,val loss : 0.379656 ,val acc : 0.828644\n",
      "[ ecpho : 7  iter :706 ]train loss : 0.338275 ,train acc: 0.835754 ,val loss : 0.377275 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :707 ]train loss : 0.308775 ,train acc: 0.839702 ,val loss : 0.378074 ,val acc : 0.826874\n",
      "[ ecpho : 7  iter :708 ]train loss : 0.263169 ,train acc: 0.873739 ,val loss : 0.384020 ,val acc : 0.829102\n",
      "[ ecpho : 7  iter :709 ]train loss : 0.434682 ,train acc: 0.810588 ,val loss : 0.384094 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :710 ]train loss : 0.312719 ,train acc: 0.866038 ,val loss : 0.377476 ,val acc : 0.824127\n",
      "[ ecpho : 7  iter :711 ]train loss : 0.233142 ,train acc: 0.887807 ,val loss : 0.381643 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :712 ]train loss : 0.447158 ,train acc: 0.745351 ,val loss : 0.381079 ,val acc : 0.826660\n",
      "[ ecpho : 7  iter :713 ]train loss : 0.263181 ,train acc: 0.875498 ,val loss : 0.383054 ,val acc : 0.828125\n",
      "[ ecpho : 7  iter :714 ]train loss : 0.282044 ,train acc: 0.869415 ,val loss : 0.378315 ,val acc : 0.826660\n",
      "[ ecpho : 7  iter :715 ]train loss : 0.276545 ,train acc: 0.869436 ,val loss : 0.378124 ,val acc : 0.829803\n",
      "[ ecpho : 7  iter :716 ]train loss : 0.420193 ,train acc: 0.772054 ,val loss : 0.385801 ,val acc : 0.826416\n",
      "[ ecpho : 7  iter :717 ]train loss : 0.256859 ,train acc: 0.875783 ,val loss : 0.382868 ,val acc : 0.828583\n",
      "[ ecpho : 7  iter :718 ]train loss : 0.400264 ,train acc: 0.816996 ,val loss : 0.376510 ,val acc : 0.826843\n",
      "[ ecpho : 7  iter :719 ]train loss : 0.274447 ,train acc: 0.869466 ,val loss : 0.380167 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :720 ]train loss : 0.280564 ,train acc: 0.863648 ,val loss : 0.383415 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :721 ]train loss : 0.390992 ,train acc: 0.840353 ,val loss : 0.382307 ,val acc : 0.826904\n",
      "[ ecpho : 7  iter :722 ]train loss : 0.326360 ,train acc: 0.854594 ,val loss : 0.382062 ,val acc : 0.825592\n",
      "[ ecpho : 7  iter :723 ]train loss : 0.400162 ,train acc: 0.818329 ,val loss : 0.383025 ,val acc : 0.827637\n",
      "[ ecpho : 7  iter :724 ]train loss : 0.395655 ,train acc: 0.849131 ,val loss : 0.385753 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :725 ]train loss : 0.276516 ,train acc: 0.870911 ,val loss : 0.382703 ,val acc : 0.829163\n",
      "[ ecpho : 7  iter :726 ]train loss : 0.248901 ,train acc: 0.881490 ,val loss : 0.386007 ,val acc : 0.827026\n",
      "[ ecpho : 7  iter :727 ]train loss : 0.317520 ,train acc: 0.846161 ,val loss : 0.380588 ,val acc : 0.829651\n",
      "[ ecpho : 7  iter :728 ]train loss : 0.338679 ,train acc: 0.820119 ,val loss : 0.384655 ,val acc : 0.827301\n",
      "[ ecpho : 7  iter :729 ]train loss : 0.303594 ,train acc: 0.857290 ,val loss : 0.380431 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :730 ]train loss : 0.358015 ,train acc: 0.814840 ,val loss : 0.379415 ,val acc : 0.828827\n",
      "[ ecpho : 7  iter :731 ]train loss : 0.301671 ,train acc: 0.856517 ,val loss : 0.379690 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :732 ]train loss : 0.313782 ,train acc: 0.863831 ,val loss : 0.381941 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :733 ]train loss : 0.342341 ,train acc: 0.849904 ,val loss : 0.379371 ,val acc : 0.829529\n",
      "[ ecpho : 7  iter :734 ]train loss : 0.265766 ,train acc: 0.871043 ,val loss : 0.380671 ,val acc : 0.830841\n",
      "[ ecpho : 7  iter :735 ]train loss : 0.350542 ,train acc: 0.847667 ,val loss : 0.386681 ,val acc : 0.826355\n",
      "[ ecpho : 7  iter :736 ]train loss : 0.258272 ,train acc: 0.880890 ,val loss : 0.379632 ,val acc : 0.833405\n",
      "[ ecpho : 7  iter :737 ]train loss : 0.269720 ,train acc: 0.875356 ,val loss : 0.379983 ,val acc : 0.828461\n",
      "[ ecpho : 7  iter :738 ]train loss : 0.321397 ,train acc: 0.839539 ,val loss : 0.383397 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :739 ]train loss : 0.345037 ,train acc: 0.853973 ,val loss : 0.379824 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :740 ]train loss : 0.281719 ,train acc: 0.866191 ,val loss : 0.384310 ,val acc : 0.826599\n",
      "[ ecpho : 7  iter :741 ]train loss : 0.416450 ,train acc: 0.829977 ,val loss : 0.382564 ,val acc : 0.827728\n",
      "[ ecpho : 7  iter :742 ]train loss : 0.299310 ,train acc: 0.862020 ,val loss : 0.386801 ,val acc : 0.829163\n",
      "[ ecpho : 7  iter :743 ]train loss : 0.319355 ,train acc: 0.851868 ,val loss : 0.386924 ,val acc : 0.824432\n",
      "[ ecpho : 7  iter :744 ]train loss : 0.246903 ,train acc: 0.879659 ,val loss : 0.384112 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :745 ]train loss : 0.254298 ,train acc: 0.881388 ,val loss : 0.386164 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :746 ]train loss : 0.272567 ,train acc: 0.866262 ,val loss : 0.381010 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :747 ]train loss : 0.352719 ,train acc: 0.811361 ,val loss : 0.378599 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :748 ]train loss : 0.239386 ,train acc: 0.884623 ,val loss : 0.383498 ,val acc : 0.827942\n",
      "[ ecpho : 7  iter :749 ]train loss : 0.335395 ,train acc: 0.859212 ,val loss : 0.377046 ,val acc : 0.829407\n",
      "[ ecpho : 7  iter :750 ]train loss : 0.292195 ,train acc: 0.859660 ,val loss : 0.379586 ,val acc : 0.827637\n",
      "[ ecpho : 7  iter :751 ]train loss : 0.299275 ,train acc: 0.864929 ,val loss : 0.381970 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :752 ]train loss : 0.347644 ,train acc: 0.811564 ,val loss : 0.374402 ,val acc : 0.832031\n",
      "[ ecpho : 7  iter :753 ]train loss : 0.268991 ,train acc: 0.876282 ,val loss : 0.379861 ,val acc : 0.827179\n",
      "[ ecpho : 7  iter :754 ]train loss : 0.218201 ,train acc: 0.892924 ,val loss : 0.386211 ,val acc : 0.824463\n",
      "[ ecpho : 7  iter :755 ]train loss : 0.309294 ,train acc: 0.861796 ,val loss : 0.384085 ,val acc : 0.824036\n",
      "[ ecpho : 7  iter :756 ]train loss : 0.319485 ,train acc: 0.852600 ,val loss : 0.382733 ,val acc : 0.828827\n",
      "[ ecpho : 7  iter :757 ]train loss : 0.462381 ,train acc: 0.770315 ,val loss : 0.380903 ,val acc : 0.827271\n",
      "[ ecpho : 7  iter :758 ]train loss : 0.300682 ,train acc: 0.866974 ,val loss : 0.382979 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :759 ]train loss : 0.302277 ,train acc: 0.864644 ,val loss : 0.377857 ,val acc : 0.829468\n",
      "[ ecpho : 7  iter :760 ]train loss : 0.358000 ,train acc: 0.815776 ,val loss : 0.383605 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :761 ]train loss : 0.423136 ,train acc: 0.804616 ,val loss : 0.378770 ,val acc : 0.829376\n",
      "[ ecpho : 7  iter :762 ]train loss : 0.253324 ,train acc: 0.877218 ,val loss : 0.388969 ,val acc : 0.825012\n",
      "[ ecpho : 7  iter :763 ]train loss : 0.265757 ,train acc: 0.879761 ,val loss : 0.385072 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :764 ]train loss : 0.289218 ,train acc: 0.871684 ,val loss : 0.381800 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :765 ]train loss : 0.388987 ,train acc: 0.811310 ,val loss : 0.377022 ,val acc : 0.828796\n",
      "[ ecpho : 7  iter :766 ]train loss : 0.295284 ,train acc: 0.865519 ,val loss : 0.381506 ,val acc : 0.828796\n",
      "[ ecpho : 7  iter :767 ]train loss : 0.271606 ,train acc: 0.874502 ,val loss : 0.381272 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :768 ]train loss : 0.323887 ,train acc: 0.855743 ,val loss : 0.379720 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :769 ]train loss : 0.298954 ,train acc: 0.865977 ,val loss : 0.382740 ,val acc : 0.825623\n",
      "[ ecpho : 7  iter :770 ]train loss : 0.289302 ,train acc: 0.857198 ,val loss : 0.380998 ,val acc : 0.829681\n",
      "[ ecpho : 7  iter :771 ]train loss : 0.346293 ,train acc: 0.824148 ,val loss : 0.381067 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :772 ]train loss : 0.339984 ,train acc: 0.834564 ,val loss : 0.381820 ,val acc : 0.828094\n",
      "[ ecpho : 7  iter :773 ]train loss : 0.362912 ,train acc: 0.862000 ,val loss : 0.380863 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :774 ]train loss : 0.310310 ,train acc: 0.854869 ,val loss : 0.384485 ,val acc : 0.824738\n",
      "[ ecpho : 7  iter :775 ]train loss : 0.282707 ,train acc: 0.865641 ,val loss : 0.384369 ,val acc : 0.826630\n",
      "[ ecpho : 7  iter :776 ]train loss : 0.237123 ,train acc: 0.884898 ,val loss : 0.375574 ,val acc : 0.829926\n",
      "[ ecpho : 7  iter :777 ]train loss : 0.292851 ,train acc: 0.858571 ,val loss : 0.386479 ,val acc : 0.823608\n",
      "[ ecpho : 7  iter :778 ]train loss : 0.375246 ,train acc: 0.837443 ,val loss : 0.385701 ,val acc : 0.823090\n",
      "[ ecpho : 7  iter :779 ]train loss : 0.312976 ,train acc: 0.871084 ,val loss : 0.384440 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :780 ]train loss : 0.255511 ,train acc: 0.876139 ,val loss : 0.377794 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :781 ]train loss : 0.416367 ,train acc: 0.826213 ,val loss : 0.381821 ,val acc : 0.826385\n",
      "[ ecpho : 7  iter :782 ]train loss : 0.348733 ,train acc: 0.824015 ,val loss : 0.378444 ,val acc : 0.828064\n",
      "[ ecpho : 7  iter :783 ]train loss : 0.284831 ,train acc: 0.867645 ,val loss : 0.376963 ,val acc : 0.827393\n",
      "[ ecpho : 7  iter :784 ]train loss : 0.222905 ,train acc: 0.891256 ,val loss : 0.381137 ,val acc : 0.828674\n",
      "[ ecpho : 7  iter :785 ]train loss : 0.258055 ,train acc: 0.877380 ,val loss : 0.382153 ,val acc : 0.824738\n",
      "[ ecpho : 7  iter :786 ]train loss : 0.395766 ,train acc: 0.839834 ,val loss : 0.380641 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :787 ]train loss : 0.246084 ,train acc: 0.877726 ,val loss : 0.379190 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :788 ]train loss : 0.368218 ,train acc: 0.827118 ,val loss : 0.382950 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :789 ]train loss : 0.562307 ,train acc: 0.738902 ,val loss : 0.380355 ,val acc : 0.830078\n",
      "[ ecpho : 7  iter :790 ]train loss : 0.295038 ,train acc: 0.862620 ,val loss : 0.382895 ,val acc : 0.829681\n",
      "[ ecpho : 7  iter :791 ]train loss : 0.354047 ,train acc: 0.847107 ,val loss : 0.382626 ,val acc : 0.827637\n",
      "[ ecpho : 7  iter :792 ]train loss : 0.365648 ,train acc: 0.849538 ,val loss : 0.381204 ,val acc : 0.824982\n",
      "[ ecpho : 7  iter :793 ]train loss : 0.253452 ,train acc: 0.881165 ,val loss : 0.382849 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :794 ]train loss : 0.257191 ,train acc: 0.875478 ,val loss : 0.381388 ,val acc : 0.829285\n",
      "[ ecpho : 7  iter :795 ]train loss : 0.239530 ,train acc: 0.885915 ,val loss : 0.381818 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :796 ]train loss : 0.456465 ,train acc: 0.828522 ,val loss : 0.385126 ,val acc : 0.826813\n",
      "[ ecpho : 7  iter :797 ]train loss : 0.306287 ,train acc: 0.855225 ,val loss : 0.378112 ,val acc : 0.831909\n",
      "[ ecpho : 7  iter :798 ]train loss : 0.346181 ,train acc: 0.839000 ,val loss : 0.382917 ,val acc : 0.826141\n",
      "[ ecpho : 7  iter :799 ]train loss : 0.263850 ,train acc: 0.874288 ,val loss : 0.384345 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :800 ]train loss : 0.254630 ,train acc: 0.879496 ,val loss : 0.380798 ,val acc : 0.827881\n",
      "[ ecpho : 7  iter :801 ]train loss : 0.301943 ,train acc: 0.857524 ,val loss : 0.379998 ,val acc : 0.828400\n",
      "[ ecpho : 7  iter :802 ]train loss : 0.392617 ,train acc: 0.835012 ,val loss : 0.380273 ,val acc : 0.828674\n",
      "[ ecpho : 7  iter :803 ]train loss : 0.258679 ,train acc: 0.880483 ,val loss : 0.381841 ,val acc : 0.825500\n",
      "[ ecpho : 7  iter :804 ]train loss : 0.424485 ,train acc: 0.817403 ,val loss : 0.383530 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :805 ]train loss : 0.333370 ,train acc: 0.854421 ,val loss : 0.377757 ,val acc : 0.832397\n",
      "[ ecpho : 7  iter :806 ]train loss : 0.409918 ,train acc: 0.814026 ,val loss : 0.381181 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :807 ]train loss : 0.305525 ,train acc: 0.858266 ,val loss : 0.383361 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :808 ]train loss : 0.322341 ,train acc: 0.863668 ,val loss : 0.380007 ,val acc : 0.829132\n",
      "[ ecpho : 7  iter :809 ]train loss : 0.268667 ,train acc: 0.870250 ,val loss : 0.381118 ,val acc : 0.831299\n",
      "[ ecpho : 7  iter :810 ]train loss : 0.269653 ,train acc: 0.875244 ,val loss : 0.387263 ,val acc : 0.825684\n",
      "[ ecpho : 7  iter :811 ]train loss : 0.256853 ,train acc: 0.878845 ,val loss : 0.387450 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :812 ]train loss : 0.259945 ,train acc: 0.872335 ,val loss : 0.381255 ,val acc : 0.829620\n",
      "[ ecpho : 7  iter :813 ]train loss : 0.317671 ,train acc: 0.853923 ,val loss : 0.378193 ,val acc : 0.826965\n",
      "[ ecpho : 7  iter :814 ]train loss : 0.280156 ,train acc: 0.874176 ,val loss : 0.377692 ,val acc : 0.829712\n",
      "[ ecpho : 7  iter :815 ]train loss : 0.301135 ,train acc: 0.855245 ,val loss : 0.378791 ,val acc : 0.828369\n",
      "[ ecpho : 7  iter :816 ]train loss : 0.302035 ,train acc: 0.863932 ,val loss : 0.382383 ,val acc : 0.826538\n",
      "[ ecpho : 7  iter :817 ]train loss : 0.372767 ,train acc: 0.834147 ,val loss : 0.380789 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :818 ]train loss : 0.251421 ,train acc: 0.875153 ,val loss : 0.377267 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :819 ]train loss : 0.540312 ,train acc: 0.806214 ,val loss : 0.385957 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :820 ]train loss : 0.280463 ,train acc: 0.868958 ,val loss : 0.379913 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :821 ]train loss : 0.303479 ,train acc: 0.868632 ,val loss : 0.378367 ,val acc : 0.827728\n",
      "[ ecpho : 7  iter :822 ]train loss : 0.265828 ,train acc: 0.871450 ,val loss : 0.382890 ,val acc : 0.826172\n",
      "[ ecpho : 7  iter :823 ]train loss : 0.277460 ,train acc: 0.868510 ,val loss : 0.377712 ,val acc : 0.829315\n",
      "[ ecpho : 7  iter :824 ]train loss : 0.312180 ,train acc: 0.862193 ,val loss : 0.383432 ,val acc : 0.827606\n",
      "[ ecpho : 7  iter :825 ]train loss : 0.346041 ,train acc: 0.834961 ,val loss : 0.382858 ,val acc : 0.828094\n",
      "[ ecpho : 7  iter :826 ]train loss : 0.303357 ,train acc: 0.859131 ,val loss : 0.381304 ,val acc : 0.826141\n",
      "[ ecpho : 7  iter :827 ]train loss : 0.262083 ,train acc: 0.871134 ,val loss : 0.375478 ,val acc : 0.831818\n",
      "[ ecpho : 7  iter :828 ]train loss : 0.250903 ,train acc: 0.883128 ,val loss : 0.383245 ,val acc : 0.826843\n",
      "[ ecpho : 7  iter :829 ]train loss : 0.299037 ,train acc: 0.871135 ,val loss : 0.377494 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :830 ]train loss : 0.229532 ,train acc: 0.888224 ,val loss : 0.379388 ,val acc : 0.829559\n",
      "[ ecpho : 7  iter :831 ]train loss : 0.387264 ,train acc: 0.840403 ,val loss : 0.390854 ,val acc : 0.824738\n",
      "[ ecpho : 7  iter :832 ]train loss : 0.312087 ,train acc: 0.858073 ,val loss : 0.384236 ,val acc : 0.827576\n",
      "[ ecpho : 7  iter :833 ]train loss : 0.300021 ,train acc: 0.862081 ,val loss : 0.380965 ,val acc : 0.828674\n",
      "[ ecpho : 7  iter :834 ]train loss : 0.293057 ,train acc: 0.859762 ,val loss : 0.381805 ,val acc : 0.828400\n",
      "[ ecpho : 7  iter :835 ]train loss : 0.373683 ,train acc: 0.830638 ,val loss : 0.379685 ,val acc : 0.829132\n",
      "[ ecpho : 7  iter :836 ]train loss : 0.268487 ,train acc: 0.878062 ,val loss : 0.376870 ,val acc : 0.826508\n",
      "[ ecpho : 7  iter :837 ]train loss : 0.247521 ,train acc: 0.880931 ,val loss : 0.381151 ,val acc : 0.828156\n",
      "[ ecpho : 7  iter :838 ]train loss : 0.294684 ,train acc: 0.850179 ,val loss : 0.383923 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :839 ]train loss : 0.305250 ,train acc: 0.861654 ,val loss : 0.385800 ,val acc : 0.828766\n",
      "[ ecpho : 7  iter :840 ]train loss : 0.241178 ,train acc: 0.885406 ,val loss : 0.378171 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :841 ]train loss : 0.250282 ,train acc: 0.881307 ,val loss : 0.380756 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :842 ]train loss : 0.256548 ,train acc: 0.874929 ,val loss : 0.379987 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :843 ]train loss : 0.344224 ,train acc: 0.833466 ,val loss : 0.379275 ,val acc : 0.827454\n",
      "[ ecpho : 7  iter :844 ]train loss : 0.289996 ,train acc: 0.865601 ,val loss : 0.387723 ,val acc : 0.825592\n",
      "[ ecpho : 7  iter :845 ]train loss : 0.288573 ,train acc: 0.860698 ,val loss : 0.386146 ,val acc : 0.826782\n",
      "[ ecpho : 7  iter :846 ]train loss : 0.247606 ,train acc: 0.882233 ,val loss : 0.381887 ,val acc : 0.828735\n",
      "[ ecpho : 7  iter :847 ]train loss : 0.232708 ,train acc: 0.887706 ,val loss : 0.379790 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :848 ]train loss : 0.264147 ,train acc: 0.872162 ,val loss : 0.379463 ,val acc : 0.825714\n",
      "[ ecpho : 7  iter :849 ]train loss : 0.343965 ,train acc: 0.855581 ,val loss : 0.386069 ,val acc : 0.827271\n",
      "[ ecpho : 7  iter :850 ]train loss : 0.286108 ,train acc: 0.867035 ,val loss : 0.387364 ,val acc : 0.826660\n",
      "[ ecpho : 7  iter :851 ]train loss : 0.266416 ,train acc: 0.875885 ,val loss : 0.382031 ,val acc : 0.828766\n",
      "[ ecpho : 7  iter :852 ]train loss : 0.281660 ,train acc: 0.861369 ,val loss : 0.376612 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :853 ]train loss : 0.222663 ,train acc: 0.891256 ,val loss : 0.384306 ,val acc : 0.828888\n",
      "[ ecpho : 7  iter :854 ]train loss : 0.239031 ,train acc: 0.884165 ,val loss : 0.384215 ,val acc : 0.827332\n",
      "[ ecpho : 7  iter :855 ]train loss : 0.283748 ,train acc: 0.854543 ,val loss : 0.378510 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :856 ]train loss : 0.264030 ,train acc: 0.869578 ,val loss : 0.381519 ,val acc : 0.829102\n",
      "[ ecpho : 7  iter :857 ]train loss : 0.285008 ,train acc: 0.858246 ,val loss : 0.378676 ,val acc : 0.828003\n",
      "[ ecpho : 7  iter :858 ]train loss : 0.260782 ,train acc: 0.871358 ,val loss : 0.384013 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :859 ]train loss : 0.274775 ,train acc: 0.875509 ,val loss : 0.379983 ,val acc : 0.826599\n",
      "[ ecpho : 7  iter :860 ]train loss : 0.294623 ,train acc: 0.859019 ,val loss : 0.379732 ,val acc : 0.831177\n",
      "[ ecpho : 7  iter :861 ]train loss : 0.274409 ,train acc: 0.874695 ,val loss : 0.382961 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :862 ]train loss : 0.271836 ,train acc: 0.869487 ,val loss : 0.384145 ,val acc : 0.825989\n",
      "[ ecpho : 7  iter :863 ]train loss : 0.237060 ,train acc: 0.885091 ,val loss : 0.382727 ,val acc : 0.829346\n",
      "[ ecpho : 7  iter :864 ]train loss : 0.306070 ,train acc: 0.851522 ,val loss : 0.377048 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :865 ]train loss : 0.336405 ,train acc: 0.831858 ,val loss : 0.377317 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :866 ]train loss : 0.237543 ,train acc: 0.887156 ,val loss : 0.379658 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :867 ]train loss : 0.291526 ,train acc: 0.864095 ,val loss : 0.382099 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :868 ]train loss : 0.259493 ,train acc: 0.873962 ,val loss : 0.383758 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :869 ]train loss : 0.285998 ,train acc: 0.867086 ,val loss : 0.381501 ,val acc : 0.828674\n",
      "[ ecpho : 7  iter :870 ]train loss : 0.351784 ,train acc: 0.840800 ,val loss : 0.382959 ,val acc : 0.822632\n",
      "[ ecpho : 7  iter :871 ]train loss : 0.388423 ,train acc: 0.820282 ,val loss : 0.378525 ,val acc : 0.827515\n",
      "[ ecpho : 7  iter :872 ]train loss : 0.291547 ,train acc: 0.867778 ,val loss : 0.381440 ,val acc : 0.828369\n",
      "[ ecpho : 7  iter :873 ]train loss : 0.276711 ,train acc: 0.871297 ,val loss : 0.380481 ,val acc : 0.826630\n",
      "[ ecpho : 7  iter :874 ]train loss : 0.331129 ,train acc: 0.866211 ,val loss : 0.377796 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :875 ]train loss : 0.330421 ,train acc: 0.837321 ,val loss : 0.381046 ,val acc : 0.827911\n",
      "[ ecpho : 7  iter :876 ]train loss : 0.338858 ,train acc: 0.859589 ,val loss : 0.374688 ,val acc : 0.830231\n",
      "[ ecpho : 7  iter :877 ]train loss : 0.319851 ,train acc: 0.861572 ,val loss : 0.380512 ,val acc : 0.826019\n",
      "[ ecpho : 7  iter :878 ]train loss : 0.353979 ,train acc: 0.843374 ,val loss : 0.382495 ,val acc : 0.829498\n",
      "[ ecpho : 7  iter :879 ]train loss : 0.272555 ,train acc: 0.872874 ,val loss : 0.378085 ,val acc : 0.829559\n",
      "[ ecpho : 7  iter :880 ]train loss : 0.252789 ,train acc: 0.879334 ,val loss : 0.381634 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :881 ]train loss : 0.332526 ,train acc: 0.851451 ,val loss : 0.380275 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :882 ]train loss : 0.275580 ,train acc: 0.868886 ,val loss : 0.381757 ,val acc : 0.826782\n",
      "[ ecpho : 7  iter :883 ]train loss : 0.391291 ,train acc: 0.785919 ,val loss : 0.377611 ,val acc : 0.829803\n",
      "[ ecpho : 7  iter :884 ]train loss : 0.253146 ,train acc: 0.877523 ,val loss : 0.383171 ,val acc : 0.828644\n",
      "[ ecpho : 7  iter :885 ]train loss : 0.392559 ,train acc: 0.844198 ,val loss : 0.382696 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :886 ]train loss : 0.459072 ,train acc: 0.761933 ,val loss : 0.379814 ,val acc : 0.828430\n",
      "[ ecpho : 7  iter :887 ]train loss : 0.282417 ,train acc: 0.867503 ,val loss : 0.382348 ,val acc : 0.824585\n",
      "[ ecpho : 7  iter :888 ]train loss : 0.293609 ,train acc: 0.864777 ,val loss : 0.390696 ,val acc : 0.825165\n",
      "[ ecpho : 7  iter :889 ]train loss : 0.287187 ,train acc: 0.863749 ,val loss : 0.379074 ,val acc : 0.828979\n",
      "[ ecpho : 7  iter :890 ]train loss : 0.382859 ,train acc: 0.849294 ,val loss : 0.381412 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :891 ]train loss : 0.256452 ,train acc: 0.874105 ,val loss : 0.378368 ,val acc : 0.829773\n",
      "[ ecpho : 7  iter :892 ]train loss : 0.286579 ,train acc: 0.868347 ,val loss : 0.380884 ,val acc : 0.829895\n",
      "[ ecpho : 7  iter :893 ]train loss : 0.268760 ,train acc: 0.870707 ,val loss : 0.379433 ,val acc : 0.827484\n",
      "[ ecpho : 7  iter :894 ]train loss : 0.314422 ,train acc: 0.863770 ,val loss : 0.377641 ,val acc : 0.828918\n",
      "[ ecpho : 7  iter :895 ]train loss : 0.312860 ,train acc: 0.856425 ,val loss : 0.376360 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :896 ]train loss : 0.296224 ,train acc: 0.870056 ,val loss : 0.379394 ,val acc : 0.830048\n",
      "[ ecpho : 7  iter :897 ]train loss : 0.333453 ,train acc: 0.851512 ,val loss : 0.380121 ,val acc : 0.830444\n",
      "[ ecpho : 7  iter :898 ]train loss : 0.272317 ,train acc: 0.869985 ,val loss : 0.387386 ,val acc : 0.827087\n",
      "[ ecpho : 7  iter :899 ]train loss : 0.290732 ,train acc: 0.862295 ,val loss : 0.384068 ,val acc : 0.824188\n",
      "[ ecpho : 7  iter :900 ]train loss : 0.318660 ,train acc: 0.853343 ,val loss : 0.379729 ,val acc : 0.827148\n",
      "[ ecpho : 7  iter :901 ]train loss : 0.489139 ,train acc: 0.789571 ,val loss : 0.379459 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :902 ]train loss : 0.244808 ,train acc: 0.884135 ,val loss : 0.377098 ,val acc : 0.826752\n",
      "[ ecpho : 7  iter :903 ]train loss : 0.389406 ,train acc: 0.814026 ,val loss : 0.378902 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :904 ]train loss : 0.300591 ,train acc: 0.863271 ,val loss : 0.379647 ,val acc : 0.827118\n",
      "[ ecpho : 7  iter :905 ]train loss : 0.239448 ,train acc: 0.884145 ,val loss : 0.381362 ,val acc : 0.824799\n",
      "[ ecpho : 7  iter :906 ]train loss : 0.322765 ,train acc: 0.852356 ,val loss : 0.374659 ,val acc : 0.829590\n",
      "[ ecpho : 7  iter :907 ]train loss : 0.276779 ,train acc: 0.864746 ,val loss : 0.379981 ,val acc : 0.828461\n",
      "[ ecpho : 7  iter :908 ]train loss : 0.440258 ,train acc: 0.813690 ,val loss : 0.381042 ,val acc : 0.831360\n",
      "[ ecpho : 7  iter :909 ]train loss : 0.278010 ,train acc: 0.858460 ,val loss : 0.372748 ,val acc : 0.830902\n",
      "[ ecpho : 7  iter :910 ]train loss : 0.268009 ,train acc: 0.879588 ,val loss : 0.387148 ,val acc : 0.823730\n",
      "[ ecpho : 7  iter :911 ]train loss : 0.379062 ,train acc: 0.847595 ,val loss : 0.381192 ,val acc : 0.829376\n",
      "[ ecpho : 7  iter :912 ]train loss : 0.244573 ,train acc: 0.881673 ,val loss : 0.388026 ,val acc : 0.827393\n",
      "[ ecpho : 7  iter :913 ]train loss : 0.364203 ,train acc: 0.844340 ,val loss : 0.380506 ,val acc : 0.828766\n",
      "[ ecpho : 7  iter :914 ]train loss : 0.329180 ,train acc: 0.850586 ,val loss : 0.379263 ,val acc : 0.831879\n",
      "[ ecpho : 7  iter :915 ]train loss : 0.291539 ,train acc: 0.864909 ,val loss : 0.385802 ,val acc : 0.830994\n",
      "[ ecpho : 7  iter :916 ]train loss : 0.291638 ,train acc: 0.866954 ,val loss : 0.377545 ,val acc : 0.829742\n",
      "[ ecpho : 7  iter :917 ]train loss : 0.302020 ,train acc: 0.860972 ,val loss : 0.375412 ,val acc : 0.830200\n",
      "[ ecpho : 7  iter :918 ]train loss : 0.404290 ,train acc: 0.845123 ,val loss : 0.382154 ,val acc : 0.827209\n",
      "[ ecpho : 7  iter :919 ]train loss : 0.319198 ,train acc: 0.854075 ,val loss : 0.386216 ,val acc : 0.826385\n",
      "[ ecpho : 7  iter :920 ]train loss : 0.273379 ,train acc: 0.870290 ,val loss : 0.385400 ,val acc : 0.828278\n",
      "[ ecpho : 7  iter :921 ]train loss : 0.344480 ,train acc: 0.822276 ,val loss : 0.383978 ,val acc : 0.828644\n",
      "[ ecpho : 7  iter :922 ]train loss : 0.359167 ,train acc: 0.840027 ,val loss : 0.384969 ,val acc : 0.823792\n",
      "[ ecpho : 7  iter :923 ]train loss : 0.237329 ,train acc: 0.887339 ,val loss : 0.383287 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :924 ]train loss : 0.318472 ,train acc: 0.860280 ,val loss : 0.383343 ,val acc : 0.828033\n",
      "[ ecpho : 7  iter :925 ]train loss : 0.312893 ,train acc: 0.844859 ,val loss : 0.376582 ,val acc : 0.830872\n",
      "[ ecpho : 7  iter :926 ]train loss : 0.287598 ,train acc: 0.854594 ,val loss : 0.384421 ,val acc : 0.825134\n",
      "[ ecpho : 7  iter :927 ]train loss : 0.303781 ,train acc: 0.841543 ,val loss : 0.375231 ,val acc : 0.829651\n",
      "[ ecpho : 7  iter :928 ]train loss : 0.273612 ,train acc: 0.873586 ,val loss : 0.378678 ,val acc : 0.832153\n",
      "[ ecpho : 7  iter :929 ]train loss : 0.272604 ,train acc: 0.871531 ,val loss : 0.382059 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :930 ]train loss : 0.284887 ,train acc: 0.868032 ,val loss : 0.381473 ,val acc : 0.826477\n",
      "[ ecpho : 7  iter :931 ]train loss : 0.295352 ,train acc: 0.865967 ,val loss : 0.379653 ,val acc : 0.827393\n",
      "[ ecpho : 7  iter :932 ]train loss : 0.319150 ,train acc: 0.860321 ,val loss : 0.384056 ,val acc : 0.828705\n",
      "[ ecpho : 7  iter :933 ]train loss : 0.272126 ,train acc: 0.873596 ,val loss : 0.383451 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :934 ]train loss : 0.326006 ,train acc: 0.848725 ,val loss : 0.381396 ,val acc : 0.827271\n",
      "[ ecpho : 7  iter :935 ]train loss : 0.332544 ,train acc: 0.856100 ,val loss : 0.371934 ,val acc : 0.830292\n",
      "[ ecpho : 7  iter :936 ]train loss : 0.358229 ,train acc: 0.838644 ,val loss : 0.382844 ,val acc : 0.826599\n",
      "[ ecpho : 7  iter :937 ]train loss : 0.290105 ,train acc: 0.861379 ,val loss : 0.385375 ,val acc : 0.822998\n",
      "[ ecpho : 7  iter :938 ]train loss : 0.246626 ,train acc: 0.881144 ,val loss : 0.381323 ,val acc : 0.827698\n",
      "[ ecpho : 7  iter :939 ]train loss : 0.377598 ,train acc: 0.830302 ,val loss : 0.379912 ,val acc : 0.825287\n",
      "[ ecpho : 7  iter :940 ]train loss : 0.268721 ,train acc: 0.881836 ,val loss : 0.380047 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :941 ]train loss : 0.253841 ,train acc: 0.877177 ,val loss : 0.373970 ,val acc : 0.828796\n",
      "[ ecpho : 7  iter :942 ]train loss : 0.310752 ,train acc: 0.853861 ,val loss : 0.376397 ,val acc : 0.827301\n",
      "[ ecpho : 7  iter :943 ]train loss : 0.249686 ,train acc: 0.880290 ,val loss : 0.377702 ,val acc : 0.828857\n",
      "[ ecpho : 7  iter :944 ]train loss : 0.312260 ,train acc: 0.863749 ,val loss : 0.382909 ,val acc : 0.828766\n",
      "[ ecpho : 7  iter :945 ]train loss : 0.268661 ,train acc: 0.873545 ,val loss : 0.376288 ,val acc : 0.830292\n",
      "[ ecpho : 7  iter :946 ]train loss : 0.358775 ,train acc: 0.851166 ,val loss : 0.375813 ,val acc : 0.830811\n",
      "[ ecpho : 7  iter :947 ]train loss : 0.330399 ,train acc: 0.856110 ,val loss : 0.378749 ,val acc : 0.829956\n",
      "[ ecpho : 7  iter :948 ]train loss : 0.250140 ,train acc: 0.880666 ,val loss : 0.385108 ,val acc : 0.827393\n",
      "[ ecpho : 7  iter :949 ]train loss : 0.316164 ,train acc: 0.857147 ,val loss : 0.384205 ,val acc : 0.827545\n",
      "[ ecpho : 7  iter :950 ]train loss : 0.337041 ,train acc: 0.838013 ,val loss : 0.385911 ,val acc : 0.828217\n",
      "[ ecpho : 7  iter :951 ]train loss : 0.303991 ,train acc: 0.866648 ,val loss : 0.372494 ,val acc : 0.832397\n",
      "[ ecpho : 7  iter :952 ]train loss : 0.246787 ,train acc: 0.881724 ,val loss : 0.379977 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :953 ]train loss : 0.354235 ,train acc: 0.847473 ,val loss : 0.376629 ,val acc : 0.831665\n",
      "[ ecpho : 7  iter :954 ]train loss : 0.267077 ,train acc: 0.875651 ,val loss : 0.381569 ,val acc : 0.825775\n",
      "[ ecpho : 7  iter :955 ]train loss : 0.236974 ,train acc: 0.885050 ,val loss : 0.374199 ,val acc : 0.832428\n",
      "[ ecpho : 7  iter :956 ]train loss : 0.322914 ,train acc: 0.852743 ,val loss : 0.385651 ,val acc : 0.826324\n",
      "[ ecpho : 7  iter :957 ]train loss : 0.337665 ,train acc: 0.859558 ,val loss : 0.380133 ,val acc : 0.832001\n",
      "[ ecpho : 7  iter :958 ]train loss : 0.310631 ,train acc: 0.832896 ,val loss : 0.385050 ,val acc : 0.824951\n",
      "[ ecpho : 7  iter :959 ]train loss : 0.337705 ,train acc: 0.818594 ,val loss : 0.374229 ,val acc : 0.828247\n",
      "[ ecpho : 7  iter :960 ]train loss : 0.418171 ,train acc: 0.807923 ,val loss : 0.386393 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :961 ]train loss : 0.333681 ,train acc: 0.833913 ,val loss : 0.386427 ,val acc : 0.829224\n",
      "[ ecpho : 7  iter :962 ]train loss : 0.288867 ,train acc: 0.872935 ,val loss : 0.377069 ,val acc : 0.832611\n",
      "[ ecpho : 7  iter :963 ]train loss : 0.447550 ,train acc: 0.776164 ,val loss : 0.377175 ,val acc : 0.831818\n",
      "[ ecpho : 7  iter :964 ]train loss : 0.381848 ,train acc: 0.856293 ,val loss : 0.374827 ,val acc : 0.832031\n",
      "[ ecpho : 7  iter :965 ]train loss : 0.332013 ,train acc: 0.855581 ,val loss : 0.381293 ,val acc : 0.827026\n",
      "[ ecpho : 7  iter :966 ]train loss : 0.315032 ,train acc: 0.849487 ,val loss : 0.378288 ,val acc : 0.829407\n",
      "[ ecpho : 7  iter :967 ]train loss : 0.249671 ,train acc: 0.879812 ,val loss : 0.380519 ,val acc : 0.827667\n",
      "[ ecpho : 7  iter :968 ]train loss : 0.331585 ,train acc: 0.841553 ,val loss : 0.382011 ,val acc : 0.825897\n",
      "[ ecpho : 7  iter :969 ]train loss : 0.285244 ,train acc: 0.868663 ,val loss : 0.382566 ,val acc : 0.828949\n",
      "[ ecpho : 7  iter :970 ]train loss : 0.317019 ,train acc: 0.863383 ,val loss : 0.374676 ,val acc : 0.831177\n",
      "[ ecpho : 7  iter :971 ]train loss : 0.372310 ,train acc: 0.806925 ,val loss : 0.381001 ,val acc : 0.827820\n",
      "[ ecpho : 7  iter :972 ]train loss : 0.249608 ,train acc: 0.877126 ,val loss : 0.379571 ,val acc : 0.828552\n",
      "[ ecpho : 7  iter :973 ]train loss : 0.298931 ,train acc: 0.866821 ,val loss : 0.379397 ,val acc : 0.831604\n",
      "[ ecpho : 7  iter :974 ]train loss : 0.327448 ,train acc: 0.847575 ,val loss : 0.378307 ,val acc : 0.830261\n",
      "[ ecpho : 7  iter :975 ]train loss : 0.349427 ,train acc: 0.815298 ,val loss : 0.375066 ,val acc : 0.830536\n",
      "[ ecpho : 7  iter :976 ]train loss : 0.321803 ,train acc: 0.841929 ,val loss : 0.381659 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :977 ]train loss : 0.328381 ,train acc: 0.858378 ,val loss : 0.374904 ,val acc : 0.830383\n",
      "[ ecpho : 7  iter :978 ]train loss : 0.315958 ,train acc: 0.857595 ,val loss : 0.382948 ,val acc : 0.826263\n",
      "[ ecpho : 7  iter :979 ]train loss : 0.254785 ,train acc: 0.879466 ,val loss : 0.383431 ,val acc : 0.828857\n",
      "[ ecpho : 7  iter :980 ]train loss : 0.277139 ,train acc: 0.861776 ,val loss : 0.375445 ,val acc : 0.830566\n",
      "[ ecpho : 7  iter :981 ]train loss : 0.318062 ,train acc: 0.854675 ,val loss : 0.379646 ,val acc : 0.829010\n",
      "[ ecpho : 7  iter :982 ]train loss : 0.249475 ,train acc: 0.878154 ,val loss : 0.384496 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :983 ]train loss : 0.326545 ,train acc: 0.853892 ,val loss : 0.381160 ,val acc : 0.826141\n",
      "[ ecpho : 7  iter :984 ]train loss : 0.259057 ,train acc: 0.874532 ,val loss : 0.378457 ,val acc : 0.826813\n",
      "[ ecpho : 7  iter :985 ]train loss : 0.384123 ,train acc: 0.825328 ,val loss : 0.385607 ,val acc : 0.829071\n",
      "[ ecpho : 7  iter :986 ]train loss : 0.356946 ,train acc: 0.842336 ,val loss : 0.383292 ,val acc : 0.827362\n",
      "[ ecpho : 7  iter :987 ]train loss : 0.442942 ,train acc: 0.841665 ,val loss : 0.382539 ,val acc : 0.827972\n",
      "[ ecpho : 7  iter :988 ]train loss : 0.360204 ,train acc: 0.829539 ,val loss : 0.380952 ,val acc : 0.827271\n",
      "[ ecpho : 7  iter :989 ]train loss : 0.284103 ,train acc: 0.860423 ,val loss : 0.377052 ,val acc : 0.832458\n",
      "[ ecpho : 7  iter :990 ]train loss : 0.238100 ,train acc: 0.883535 ,val loss : 0.381412 ,val acc : 0.826752\n",
      "[ ecpho : 7  iter :991 ]train loss : 0.293940 ,train acc: 0.862600 ,val loss : 0.381457 ,val acc : 0.828186\n",
      "[ ecpho : 7  iter :992 ]train loss : 0.339070 ,train acc: 0.823832 ,val loss : 0.379364 ,val acc : 0.828308\n",
      "[ ecpho : 7  iter :993 ]train loss : 0.290809 ,train acc: 0.870616 ,val loss : 0.382513 ,val acc : 0.827423\n",
      "[ ecpho : 7  iter :994 ]train loss : 0.381795 ,train acc: 0.848836 ,val loss : 0.381353 ,val acc : 0.827850\n",
      "[ ecpho : 7  iter :995 ]train loss : 0.300242 ,train acc: 0.862142 ,val loss : 0.379637 ,val acc : 0.827789\n",
      "[ ecpho : 7  iter :996 ]train loss : 0.271705 ,train acc: 0.862722 ,val loss : 0.381437 ,val acc : 0.830170\n",
      "[ ecpho : 7  iter :997 ]train loss : 0.238671 ,train acc: 0.884033 ,val loss : 0.383494 ,val acc : 0.827240\n",
      "[ ecpho : 7  iter :998 ]train loss : 0.372870 ,train acc: 0.818085 ,val loss : 0.379221 ,val acc : 0.825470\n",
      "[ ecpho : 7  iter :999 ]train loss : 0.292930 ,train acc: 0.870046 ,val loss : 0.385241 ,val acc : 0.825073\n",
      "[ ecpho : 7  iter :1000 ]train loss : 0.371930 ,train acc: 0.851715 ,val loss : 0.386391 ,val acc : 0.827545\n",
      "=============================================\n",
      "[ 7 ] average train loss : 0.313444 train acc : 0.854922\n",
      "[ ecpho : 8  iter :1 ]train loss : 0.402627 ,train acc: 0.848704 ,val loss : 0.383204 ,val acc : 0.825104\n",
      "[ ecpho : 8  iter :2 ]train loss : 0.286072 ,train acc: 0.871480 ,val loss : 0.377749 ,val acc : 0.830231\n",
      "[ ecpho : 8  iter :3 ]train loss : 0.263468 ,train acc: 0.866964 ,val loss : 0.376427 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :4 ]train loss : 0.278612 ,train acc: 0.879964 ,val loss : 0.382056 ,val acc : 0.830872\n",
      "[ ecpho : 8  iter :5 ]train loss : 0.473558 ,train acc: 0.822866 ,val loss : 0.376235 ,val acc : 0.830505\n",
      "[ ecpho : 8  iter :6 ]train loss : 0.264858 ,train acc: 0.875214 ,val loss : 0.380449 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :7 ]train loss : 0.274214 ,train acc: 0.867116 ,val loss : 0.379309 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :8 ]train loss : 0.271657 ,train acc: 0.868286 ,val loss : 0.374254 ,val acc : 0.830627\n",
      "[ ecpho : 8  iter :9 ]train loss : 0.222992 ,train acc: 0.890991 ,val loss : 0.380572 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :10 ]train loss : 0.320909 ,train acc: 0.850973 ,val loss : 0.383167 ,val acc : 0.825745\n",
      "[ ecpho : 8  iter :11 ]train loss : 0.261383 ,train acc: 0.871562 ,val loss : 0.381730 ,val acc : 0.826508\n",
      "[ ecpho : 8  iter :12 ]train loss : 0.335473 ,train acc: 0.852000 ,val loss : 0.377162 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :13 ]train loss : 0.280734 ,train acc: 0.878011 ,val loss : 0.383749 ,val acc : 0.830994\n",
      "[ ecpho : 8  iter :14 ]train loss : 0.292289 ,train acc: 0.858795 ,val loss : 0.387508 ,val acc : 0.826080\n",
      "[ ecpho : 8  iter :15 ]train loss : 0.291686 ,train acc: 0.858063 ,val loss : 0.376483 ,val acc : 0.832458\n",
      "[ ecpho : 8  iter :16 ]train loss : 0.405949 ,train acc: 0.829855 ,val loss : 0.382436 ,val acc : 0.827148\n",
      "[ ecpho : 8  iter :17 ]train loss : 0.337878 ,train acc: 0.853078 ,val loss : 0.383563 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :18 ]train loss : 0.370956 ,train acc: 0.830801 ,val loss : 0.383974 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :19 ]train loss : 0.367021 ,train acc: 0.844320 ,val loss : 0.377775 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :20 ]train loss : 0.297796 ,train acc: 0.862000 ,val loss : 0.380444 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :21 ]train loss : 0.308555 ,train acc: 0.847565 ,val loss : 0.381372 ,val acc : 0.830383\n",
      "[ ecpho : 8  iter :22 ]train loss : 0.398554 ,train acc: 0.837911 ,val loss : 0.375831 ,val acc : 0.828674\n",
      "[ ecpho : 8  iter :23 ]train loss : 0.337119 ,train acc: 0.851797 ,val loss : 0.384201 ,val acc : 0.828400\n",
      "[ ecpho : 8  iter :24 ]train loss : 0.276511 ,train acc: 0.866526 ,val loss : 0.379436 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :25 ]train loss : 0.343981 ,train acc: 0.851919 ,val loss : 0.381620 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :26 ]train loss : 0.309039 ,train acc: 0.857493 ,val loss : 0.379419 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :27 ]train loss : 0.241590 ,train acc: 0.881968 ,val loss : 0.381953 ,val acc : 0.828613\n",
      "[ ecpho : 8  iter :28 ]train loss : 0.377113 ,train acc: 0.819580 ,val loss : 0.384409 ,val acc : 0.826416\n",
      "[ ecpho : 8  iter :29 ]train loss : 0.367185 ,train acc: 0.831248 ,val loss : 0.379943 ,val acc : 0.824707\n",
      "[ ecpho : 8  iter :30 ]train loss : 0.294466 ,train acc: 0.870056 ,val loss : 0.380461 ,val acc : 0.828827\n",
      "[ ecpho : 8  iter :31 ]train loss : 0.281588 ,train acc: 0.869456 ,val loss : 0.382351 ,val acc : 0.829895\n",
      "[ ecpho : 8  iter :32 ]train loss : 0.432381 ,train acc: 0.841339 ,val loss : 0.381093 ,val acc : 0.826721\n",
      "[ ecpho : 8  iter :33 ]train loss : 0.276127 ,train acc: 0.865397 ,val loss : 0.385127 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :34 ]train loss : 0.271563 ,train acc: 0.872732 ,val loss : 0.379951 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :35 ]train loss : 0.299190 ,train acc: 0.853424 ,val loss : 0.385095 ,val acc : 0.825562\n",
      "[ ecpho : 8  iter :36 ]train loss : 0.278973 ,train acc: 0.872101 ,val loss : 0.380544 ,val acc : 0.825867\n",
      "[ ecpho : 8  iter :37 ]train loss : 0.307826 ,train acc: 0.865692 ,val loss : 0.380472 ,val acc : 0.824890\n",
      "[ ecpho : 8  iter :38 ]train loss : 0.278166 ,train acc: 0.864980 ,val loss : 0.376731 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :39 ]train loss : 0.249484 ,train acc: 0.883321 ,val loss : 0.373882 ,val acc : 0.827057\n",
      "[ ecpho : 8  iter :40 ]train loss : 0.302079 ,train acc: 0.867330 ,val loss : 0.383415 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :41 ]train loss : 0.255017 ,train acc: 0.872691 ,val loss : 0.380576 ,val acc : 0.827271\n",
      "[ ecpho : 8  iter :42 ]train loss : 0.308904 ,train acc: 0.859019 ,val loss : 0.376340 ,val acc : 0.829803\n",
      "[ ecpho : 8  iter :43 ]train loss : 0.307530 ,train acc: 0.864868 ,val loss : 0.380060 ,val acc : 0.828979\n",
      "[ ecpho : 8  iter :44 ]train loss : 0.395453 ,train acc: 0.839722 ,val loss : 0.379060 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :45 ]train loss : 0.263196 ,train acc: 0.872650 ,val loss : 0.380892 ,val acc : 0.825348\n",
      "[ ecpho : 8  iter :46 ]train loss : 0.266331 ,train acc: 0.870016 ,val loss : 0.382383 ,val acc : 0.827332\n",
      "[ ecpho : 8  iter :47 ]train loss : 0.300030 ,train acc: 0.869487 ,val loss : 0.385040 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :48 ]train loss : 0.259731 ,train acc: 0.873942 ,val loss : 0.387513 ,val acc : 0.825195\n",
      "[ ecpho : 8  iter :49 ]train loss : 0.306952 ,train acc: 0.862000 ,val loss : 0.377311 ,val acc : 0.831268\n",
      "[ ecpho : 8  iter :50 ]train loss : 0.252553 ,train acc: 0.879669 ,val loss : 0.381195 ,val acc : 0.825836\n",
      "[ ecpho : 8  iter :51 ]train loss : 0.339371 ,train acc: 0.856862 ,val loss : 0.381194 ,val acc : 0.827362\n",
      "[ ecpho : 8  iter :52 ]train loss : 0.249037 ,train acc: 0.881541 ,val loss : 0.374921 ,val acc : 0.830597\n",
      "[ ecpho : 8  iter :53 ]train loss : 0.280222 ,train acc: 0.870707 ,val loss : 0.380638 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :54 ]train loss : 0.252577 ,train acc: 0.876963 ,val loss : 0.380602 ,val acc : 0.826752\n",
      "[ ecpho : 8  iter :55 ]train loss : 0.293604 ,train acc: 0.866486 ,val loss : 0.381094 ,val acc : 0.826538\n",
      "[ ecpho : 8  iter :56 ]train loss : 0.334355 ,train acc: 0.855703 ,val loss : 0.377805 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :57 ]train loss : 0.328644 ,train acc: 0.853841 ,val loss : 0.381937 ,val acc : 0.829224\n",
      "[ ecpho : 8  iter :58 ]train loss : 0.443271 ,train acc: 0.764109 ,val loss : 0.380753 ,val acc : 0.830353\n",
      "[ ecpho : 8  iter :59 ]train loss : 0.261371 ,train acc: 0.880249 ,val loss : 0.381613 ,val acc : 0.827301\n",
      "[ ecpho : 8  iter :60 ]train loss : 0.401229 ,train acc: 0.791708 ,val loss : 0.379722 ,val acc : 0.828339\n",
      "[ ecpho : 8  iter :61 ]train loss : 0.334018 ,train acc: 0.856629 ,val loss : 0.384994 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :62 ]train loss : 0.287595 ,train acc: 0.876231 ,val loss : 0.379037 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :63 ]train loss : 0.510598 ,train acc: 0.715546 ,val loss : 0.383913 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :64 ]train loss : 0.337764 ,train acc: 0.844208 ,val loss : 0.383389 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :65 ]train loss : 0.225208 ,train acc: 0.892436 ,val loss : 0.381904 ,val acc : 0.824982\n",
      "[ ecpho : 8  iter :66 ]train loss : 0.238390 ,train acc: 0.885061 ,val loss : 0.376809 ,val acc : 0.831909\n",
      "[ ecpho : 8  iter :67 ]train loss : 0.266932 ,train acc: 0.868398 ,val loss : 0.396061 ,val acc : 0.824921\n",
      "[ ecpho : 8  iter :68 ]train loss : 0.294434 ,train acc: 0.855632 ,val loss : 0.383456 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :69 ]train loss : 0.343260 ,train acc: 0.834249 ,val loss : 0.377362 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :70 ]train loss : 0.327158 ,train acc: 0.852519 ,val loss : 0.384048 ,val acc : 0.825531\n",
      "[ ecpho : 8  iter :71 ]train loss : 0.249537 ,train acc: 0.877625 ,val loss : 0.381344 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :72 ]train loss : 0.251978 ,train acc: 0.874990 ,val loss : 0.383023 ,val acc : 0.826752\n",
      "[ ecpho : 8  iter :73 ]train loss : 0.338340 ,train acc: 0.831431 ,val loss : 0.379723 ,val acc : 0.826599\n",
      "[ ecpho : 8  iter :74 ]train loss : 0.296837 ,train acc: 0.852895 ,val loss : 0.376502 ,val acc : 0.830719\n",
      "[ ecpho : 8  iter :75 ]train loss : 0.227338 ,train acc: 0.888448 ,val loss : 0.378526 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :76 ]train loss : 0.330245 ,train acc: 0.852020 ,val loss : 0.379346 ,val acc : 0.825226\n",
      "[ ecpho : 8  iter :77 ]train loss : 0.304362 ,train acc: 0.852163 ,val loss : 0.378662 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :78 ]train loss : 0.277623 ,train acc: 0.868693 ,val loss : 0.376493 ,val acc : 0.828674\n",
      "[ ecpho : 8  iter :79 ]train loss : 0.261707 ,train acc: 0.875987 ,val loss : 0.377453 ,val acc : 0.832062\n",
      "[ ecpho : 8  iter :80 ]train loss : 0.255320 ,train acc: 0.878031 ,val loss : 0.380741 ,val acc : 0.825958\n",
      "[ ecpho : 8  iter :81 ]train loss : 0.297059 ,train acc: 0.852610 ,val loss : 0.379541 ,val acc : 0.829071\n",
      "[ ecpho : 8  iter :82 ]train loss : 0.358651 ,train acc: 0.811940 ,val loss : 0.383446 ,val acc : 0.829041\n",
      "[ ecpho : 8  iter :83 ]train loss : 0.342798 ,train acc: 0.855937 ,val loss : 0.377877 ,val acc : 0.830780\n",
      "[ ecpho : 8  iter :84 ]train loss : 0.338774 ,train acc: 0.800812 ,val loss : 0.379681 ,val acc : 0.825989\n",
      "[ ecpho : 8  iter :85 ]train loss : 0.362230 ,train acc: 0.840464 ,val loss : 0.380084 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :86 ]train loss : 0.262138 ,train acc: 0.876251 ,val loss : 0.378370 ,val acc : 0.826721\n",
      "[ ecpho : 8  iter :87 ]train loss : 0.291969 ,train acc: 0.844310 ,val loss : 0.384103 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :88 ]train loss : 0.265590 ,train acc: 0.875661 ,val loss : 0.385766 ,val acc : 0.827942\n",
      "[ ecpho : 8  iter :89 ]train loss : 0.368437 ,train acc: 0.756683 ,val loss : 0.381524 ,val acc : 0.826141\n",
      "[ ecpho : 8  iter :90 ]train loss : 0.298344 ,train acc: 0.868195 ,val loss : 0.388826 ,val acc : 0.825989\n",
      "[ ecpho : 8  iter :91 ]train loss : 0.245683 ,train acc: 0.880625 ,val loss : 0.382057 ,val acc : 0.826538\n",
      "[ ecpho : 8  iter :92 ]train loss : 0.343708 ,train acc: 0.857025 ,val loss : 0.378179 ,val acc : 0.825195\n",
      "[ ecpho : 8  iter :93 ]train loss : 0.247787 ,train acc: 0.880168 ,val loss : 0.382381 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :94 ]train loss : 0.313799 ,train acc: 0.856293 ,val loss : 0.381981 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :95 ]train loss : 0.362269 ,train acc: 0.844645 ,val loss : 0.379033 ,val acc : 0.825653\n",
      "[ ecpho : 8  iter :96 ]train loss : 0.279768 ,train acc: 0.867055 ,val loss : 0.376337 ,val acc : 0.828979\n",
      "[ ecpho : 8  iter :97 ]train loss : 0.299338 ,train acc: 0.864838 ,val loss : 0.382926 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :98 ]train loss : 0.267587 ,train acc: 0.876343 ,val loss : 0.384374 ,val acc : 0.826111\n",
      "[ ecpho : 8  iter :99 ]train loss : 0.311923 ,train acc: 0.863536 ,val loss : 0.377997 ,val acc : 0.829590\n",
      "[ ecpho : 8  iter :100 ]train loss : 0.251468 ,train acc: 0.882833 ,val loss : 0.378908 ,val acc : 0.831451\n",
      "[ ecpho : 8  iter :101 ]train loss : 0.396314 ,train acc: 0.836599 ,val loss : 0.378842 ,val acc : 0.833221\n",
      "[ ecpho : 8  iter :102 ]train loss : 0.257936 ,train acc: 0.879974 ,val loss : 0.377312 ,val acc : 0.827332\n",
      "[ ecpho : 8  iter :103 ]train loss : 0.273609 ,train acc: 0.867248 ,val loss : 0.381450 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :104 ]train loss : 0.282808 ,train acc: 0.870544 ,val loss : 0.381965 ,val acc : 0.828857\n",
      "[ ecpho : 8  iter :105 ]train loss : 0.254776 ,train acc: 0.879954 ,val loss : 0.380238 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :106 ]train loss : 0.260123 ,train acc: 0.875702 ,val loss : 0.375637 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :107 ]train loss : 0.229679 ,train acc: 0.888489 ,val loss : 0.378156 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :108 ]train loss : 0.282552 ,train acc: 0.861501 ,val loss : 0.379083 ,val acc : 0.828918\n",
      "[ ecpho : 8  iter :109 ]train loss : 0.397966 ,train acc: 0.826844 ,val loss : 0.380433 ,val acc : 0.828766\n",
      "[ ecpho : 8  iter :110 ]train loss : 0.371098 ,train acc: 0.852448 ,val loss : 0.375767 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :111 ]train loss : 0.362726 ,train acc: 0.836629 ,val loss : 0.387281 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :112 ]train loss : 0.265959 ,train acc: 0.872620 ,val loss : 0.381849 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :113 ]train loss : 0.397695 ,train acc: 0.844910 ,val loss : 0.379716 ,val acc : 0.825043\n",
      "[ ecpho : 8  iter :114 ]train loss : 0.335489 ,train acc: 0.859111 ,val loss : 0.369915 ,val acc : 0.834534\n",
      "[ ecpho : 8  iter :115 ]train loss : 0.298359 ,train acc: 0.862722 ,val loss : 0.382242 ,val acc : 0.829010\n",
      "[ ecpho : 8  iter :116 ]train loss : 0.256467 ,train acc: 0.877869 ,val loss : 0.384085 ,val acc : 0.825439\n",
      "[ ecpho : 8  iter :117 ]train loss : 0.271927 ,train acc: 0.868225 ,val loss : 0.377848 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :118 ]train loss : 0.254197 ,train acc: 0.879822 ,val loss : 0.378060 ,val acc : 0.828400\n",
      "[ ecpho : 8  iter :119 ]train loss : 0.391341 ,train acc: 0.819224 ,val loss : 0.383621 ,val acc : 0.826721\n",
      "[ ecpho : 8  iter :120 ]train loss : 0.278755 ,train acc: 0.861094 ,val loss : 0.381374 ,val acc : 0.829376\n",
      "[ ecpho : 8  iter :121 ]train loss : 0.337863 ,train acc: 0.848419 ,val loss : 0.379937 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :122 ]train loss : 0.321307 ,train acc: 0.858419 ,val loss : 0.381830 ,val acc : 0.829376\n",
      "[ ecpho : 8  iter :123 ]train loss : 0.501986 ,train acc: 0.811503 ,val loss : 0.379058 ,val acc : 0.829498\n",
      "[ ecpho : 8  iter :124 ]train loss : 0.375846 ,train acc: 0.832184 ,val loss : 0.382232 ,val acc : 0.825653\n",
      "[ ecpho : 8  iter :125 ]train loss : 0.334392 ,train acc: 0.854645 ,val loss : 0.374831 ,val acc : 0.832672\n",
      "[ ecpho : 8  iter :126 ]train loss : 0.282277 ,train acc: 0.863770 ,val loss : 0.383229 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :127 ]train loss : 0.267719 ,train acc: 0.873169 ,val loss : 0.384014 ,val acc : 0.826965\n",
      "[ ecpho : 8  iter :128 ]train loss : 0.348352 ,train acc: 0.816071 ,val loss : 0.377891 ,val acc : 0.830078\n",
      "[ ecpho : 8  iter :129 ]train loss : 0.303577 ,train acc: 0.855337 ,val loss : 0.377758 ,val acc : 0.829437\n",
      "[ ecpho : 8  iter :130 ]train loss : 0.294891 ,train acc: 0.838145 ,val loss : 0.381174 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :131 ]train loss : 0.243159 ,train acc: 0.883199 ,val loss : 0.379685 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :132 ]train loss : 0.343525 ,train acc: 0.861593 ,val loss : 0.381073 ,val acc : 0.828217\n",
      "[ ecpho : 8  iter :133 ]train loss : 0.249946 ,train acc: 0.879506 ,val loss : 0.386294 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :134 ]train loss : 0.337889 ,train acc: 0.829641 ,val loss : 0.375371 ,val acc : 0.829437\n",
      "[ ecpho : 8  iter :135 ]train loss : 0.330994 ,train acc: 0.860342 ,val loss : 0.380780 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :136 ]train loss : 0.265097 ,train acc: 0.871358 ,val loss : 0.386489 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :137 ]train loss : 0.330974 ,train acc: 0.850932 ,val loss : 0.380038 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :138 ]train loss : 0.272235 ,train acc: 0.879181 ,val loss : 0.374454 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :139 ]train loss : 0.336242 ,train acc: 0.841868 ,val loss : 0.380255 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :140 ]train loss : 0.311103 ,train acc: 0.834992 ,val loss : 0.381519 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :141 ]train loss : 0.309951 ,train acc: 0.847555 ,val loss : 0.382920 ,val acc : 0.828339\n",
      "[ ecpho : 8  iter :142 ]train loss : 0.374643 ,train acc: 0.852763 ,val loss : 0.381938 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :143 ]train loss : 0.289738 ,train acc: 0.869446 ,val loss : 0.377014 ,val acc : 0.827271\n",
      "[ ecpho : 8  iter :144 ]train loss : 0.298161 ,train acc: 0.852010 ,val loss : 0.380345 ,val acc : 0.827606\n",
      "[ ecpho : 8  iter :145 ]train loss : 0.287124 ,train acc: 0.863342 ,val loss : 0.377370 ,val acc : 0.826782\n",
      "[ ecpho : 8  iter :146 ]train loss : 0.330754 ,train acc: 0.853912 ,val loss : 0.376540 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :147 ]train loss : 0.328488 ,train acc: 0.827433 ,val loss : 0.375499 ,val acc : 0.830688\n",
      "[ ecpho : 8  iter :148 ]train loss : 0.448524 ,train acc: 0.831187 ,val loss : 0.378325 ,val acc : 0.829895\n",
      "[ ecpho : 8  iter :149 ]train loss : 0.336981 ,train acc: 0.853343 ,val loss : 0.380497 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :150 ]train loss : 0.231717 ,train acc: 0.887075 ,val loss : 0.378535 ,val acc : 0.829590\n",
      "[ ecpho : 8  iter :151 ]train loss : 0.242843 ,train acc: 0.882050 ,val loss : 0.387193 ,val acc : 0.826111\n",
      "[ ecpho : 8  iter :152 ]train loss : 0.351837 ,train acc: 0.821645 ,val loss : 0.380677 ,val acc : 0.826996\n",
      "[ ecpho : 8  iter :153 ]train loss : 0.370729 ,train acc: 0.859060 ,val loss : 0.381420 ,val acc : 0.827911\n",
      "[ ecpho : 8  iter :154 ]train loss : 0.261210 ,train acc: 0.867757 ,val loss : 0.376831 ,val acc : 0.832336\n",
      "[ ecpho : 8  iter :155 ]train loss : 0.234351 ,train acc: 0.886780 ,val loss : 0.379248 ,val acc : 0.825348\n",
      "[ ecpho : 8  iter :156 ]train loss : 0.299461 ,train acc: 0.852478 ,val loss : 0.378601 ,val acc : 0.827271\n",
      "[ ecpho : 8  iter :157 ]train loss : 0.267968 ,train acc: 0.862366 ,val loss : 0.383718 ,val acc : 0.830811\n",
      "[ ecpho : 8  iter :158 ]train loss : 0.270154 ,train acc: 0.873932 ,val loss : 0.386843 ,val acc : 0.826111\n",
      "[ ecpho : 8  iter :159 ]train loss : 0.340409 ,train acc: 0.839620 ,val loss : 0.376195 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :160 ]train loss : 0.282597 ,train acc: 0.860860 ,val loss : 0.383404 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :161 ]train loss : 0.235057 ,train acc: 0.886709 ,val loss : 0.377201 ,val acc : 0.825867\n",
      "[ ecpho : 8  iter :162 ]train loss : 0.338791 ,train acc: 0.839864 ,val loss : 0.379657 ,val acc : 0.828369\n",
      "[ ecpho : 8  iter :163 ]train loss : 0.298737 ,train acc: 0.864716 ,val loss : 0.381790 ,val acc : 0.828613\n",
      "[ ecpho : 8  iter :164 ]train loss : 0.365505 ,train acc: 0.839549 ,val loss : 0.380292 ,val acc : 0.828369\n",
      "[ ecpho : 8  iter :165 ]train loss : 0.246298 ,train acc: 0.885051 ,val loss : 0.375657 ,val acc : 0.831665\n",
      "[ ecpho : 8  iter :166 ]train loss : 0.243909 ,train acc: 0.883219 ,val loss : 0.377596 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :167 ]train loss : 0.240545 ,train acc: 0.885701 ,val loss : 0.379657 ,val acc : 0.830933\n",
      "[ ecpho : 8  iter :168 ]train loss : 0.402039 ,train acc: 0.833211 ,val loss : 0.382589 ,val acc : 0.828613\n",
      "[ ecpho : 8  iter :169 ]train loss : 0.321836 ,train acc: 0.859426 ,val loss : 0.377891 ,val acc : 0.830261\n",
      "[ ecpho : 8  iter :170 ]train loss : 0.323678 ,train acc: 0.851746 ,val loss : 0.385441 ,val acc : 0.828094\n",
      "[ ecpho : 8  iter :171 ]train loss : 0.301651 ,train acc: 0.860758 ,val loss : 0.382112 ,val acc : 0.826874\n",
      "[ ecpho : 8  iter :172 ]train loss : 0.372459 ,train acc: 0.847036 ,val loss : 0.379399 ,val acc : 0.830017\n",
      "[ ecpho : 8  iter :173 ]train loss : 0.264606 ,train acc: 0.872274 ,val loss : 0.384187 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :174 ]train loss : 0.226092 ,train acc: 0.889262 ,val loss : 0.382246 ,val acc : 0.829437\n",
      "[ ecpho : 8  iter :175 ]train loss : 0.407889 ,train acc: 0.795360 ,val loss : 0.382870 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :176 ]train loss : 0.327150 ,train acc: 0.854635 ,val loss : 0.375246 ,val acc : 0.830414\n",
      "[ ecpho : 8  iter :177 ]train loss : 0.396125 ,train acc: 0.837687 ,val loss : 0.383358 ,val acc : 0.824738\n",
      "[ ecpho : 8  iter :178 ]train loss : 0.382062 ,train acc: 0.840363 ,val loss : 0.383923 ,val acc : 0.826599\n",
      "[ ecpho : 8  iter :179 ]train loss : 0.299562 ,train acc: 0.864471 ,val loss : 0.376018 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :180 ]train loss : 0.270461 ,train acc: 0.871053 ,val loss : 0.378802 ,val acc : 0.831390\n",
      "[ ecpho : 8  iter :181 ]train loss : 0.291580 ,train acc: 0.861237 ,val loss : 0.384657 ,val acc : 0.826721\n",
      "[ ecpho : 8  iter :182 ]train loss : 0.276295 ,train acc: 0.869242 ,val loss : 0.376895 ,val acc : 0.831268\n",
      "[ ecpho : 8  iter :183 ]train loss : 0.251393 ,train acc: 0.884603 ,val loss : 0.380484 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :184 ]train loss : 0.334103 ,train acc: 0.853567 ,val loss : 0.380014 ,val acc : 0.828217\n",
      "[ ecpho : 8  iter :185 ]train loss : 0.254291 ,train acc: 0.878591 ,val loss : 0.382564 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :186 ]train loss : 0.406110 ,train acc: 0.826681 ,val loss : 0.381508 ,val acc : 0.825562\n",
      "[ ecpho : 8  iter :187 ]train loss : 0.285334 ,train acc: 0.866160 ,val loss : 0.381685 ,val acc : 0.826538\n",
      "[ ecpho : 8  iter :188 ]train loss : 0.313611 ,train acc: 0.850098 ,val loss : 0.384340 ,val acc : 0.825470\n",
      "[ ecpho : 8  iter :189 ]train loss : 0.287470 ,train acc: 0.861806 ,val loss : 0.378364 ,val acc : 0.829803\n",
      "[ ecpho : 8  iter :190 ]train loss : 0.352304 ,train acc: 0.838623 ,val loss : 0.378919 ,val acc : 0.827362\n",
      "[ ecpho : 8  iter :191 ]train loss : 0.297822 ,train acc: 0.872701 ,val loss : 0.380118 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :192 ]train loss : 0.360561 ,train acc: 0.835042 ,val loss : 0.384224 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :193 ]train loss : 0.291327 ,train acc: 0.866374 ,val loss : 0.381323 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :194 ]train loss : 0.286520 ,train acc: 0.865448 ,val loss : 0.379054 ,val acc : 0.825226\n",
      "[ ecpho : 8  iter :195 ]train loss : 0.252746 ,train acc: 0.879791 ,val loss : 0.384677 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :196 ]train loss : 0.253575 ,train acc: 0.879934 ,val loss : 0.386174 ,val acc : 0.825867\n",
      "[ ecpho : 8  iter :197 ]train loss : 0.296702 ,train acc: 0.853546 ,val loss : 0.377048 ,val acc : 0.828949\n",
      "[ ecpho : 8  iter :198 ]train loss : 0.287111 ,train acc: 0.866394 ,val loss : 0.378946 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :199 ]train loss : 0.314271 ,train acc: 0.862976 ,val loss : 0.382210 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :200 ]train loss : 0.286911 ,train acc: 0.859873 ,val loss : 0.380152 ,val acc : 0.826416\n",
      "[ ecpho : 8  iter :201 ]train loss : 0.389808 ,train acc: 0.824178 ,val loss : 0.382917 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :202 ]train loss : 0.255675 ,train acc: 0.877451 ,val loss : 0.380144 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :203 ]train loss : 0.254120 ,train acc: 0.879364 ,val loss : 0.378316 ,val acc : 0.829834\n",
      "[ ecpho : 8  iter :204 ]train loss : 0.243924 ,train acc: 0.886037 ,val loss : 0.374046 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :205 ]train loss : 0.262511 ,train acc: 0.875854 ,val loss : 0.384079 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :206 ]train loss : 0.294476 ,train acc: 0.865804 ,val loss : 0.381828 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :207 ]train loss : 0.350221 ,train acc: 0.816803 ,val loss : 0.384405 ,val acc : 0.824982\n",
      "[ ecpho : 8  iter :208 ]train loss : 0.270719 ,train acc: 0.876384 ,val loss : 0.376437 ,val acc : 0.829742\n",
      "[ ecpho : 8  iter :209 ]train loss : 0.268117 ,train acc: 0.868907 ,val loss : 0.378647 ,val acc : 0.830902\n",
      "[ ecpho : 8  iter :210 ]train loss : 0.385427 ,train acc: 0.804291 ,val loss : 0.382221 ,val acc : 0.828827\n",
      "[ ecpho : 8  iter :211 ]train loss : 0.337204 ,train acc: 0.850515 ,val loss : 0.383010 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :212 ]train loss : 0.343902 ,train acc: 0.855316 ,val loss : 0.377491 ,val acc : 0.830048\n",
      "[ ecpho : 8  iter :213 ]train loss : 0.376482 ,train acc: 0.844656 ,val loss : 0.383189 ,val acc : 0.825439\n",
      "[ ecpho : 8  iter :214 ]train loss : 0.262960 ,train acc: 0.876526 ,val loss : 0.384897 ,val acc : 0.825439\n",
      "[ ecpho : 8  iter :215 ]train loss : 0.267205 ,train acc: 0.871562 ,val loss : 0.382941 ,val acc : 0.829498\n",
      "[ ecpho : 8  iter :216 ]train loss : 0.304338 ,train acc: 0.864563 ,val loss : 0.375873 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :217 ]train loss : 0.325442 ,train acc: 0.859812 ,val loss : 0.383950 ,val acc : 0.824677\n",
      "[ ecpho : 8  iter :218 ]train loss : 0.315892 ,train acc: 0.833221 ,val loss : 0.381500 ,val acc : 0.830627\n",
      "[ ecpho : 8  iter :219 ]train loss : 0.281631 ,train acc: 0.868490 ,val loss : 0.380530 ,val acc : 0.827332\n",
      "[ ecpho : 8  iter :220 ]train loss : 0.254046 ,train acc: 0.877238 ,val loss : 0.382695 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :221 ]train loss : 0.244218 ,train acc: 0.884206 ,val loss : 0.380871 ,val acc : 0.825562\n",
      "[ ecpho : 8  iter :222 ]train loss : 0.272241 ,train acc: 0.872182 ,val loss : 0.382300 ,val acc : 0.827301\n",
      "[ ecpho : 8  iter :223 ]train loss : 0.326973 ,train acc: 0.861796 ,val loss : 0.376553 ,val acc : 0.829315\n",
      "[ ecpho : 8  iter :224 ]train loss : 0.390009 ,train acc: 0.766307 ,val loss : 0.379555 ,val acc : 0.829559\n",
      "[ ecpho : 8  iter :225 ]train loss : 0.364876 ,train acc: 0.860097 ,val loss : 0.382328 ,val acc : 0.824921\n",
      "[ ecpho : 8  iter :226 ]train loss : 0.270182 ,train acc: 0.868032 ,val loss : 0.381680 ,val acc : 0.825043\n",
      "[ ecpho : 8  iter :227 ]train loss : 0.313564 ,train acc: 0.857208 ,val loss : 0.386287 ,val acc : 0.829559\n",
      "[ ecpho : 8  iter :228 ]train loss : 0.241338 ,train acc: 0.879740 ,val loss : 0.382560 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :229 ]train loss : 0.493136 ,train acc: 0.751231 ,val loss : 0.381201 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :230 ]train loss : 0.308213 ,train acc: 0.860209 ,val loss : 0.382102 ,val acc : 0.828705\n",
      "[ ecpho : 8  iter :231 ]train loss : 0.362032 ,train acc: 0.846924 ,val loss : 0.377263 ,val acc : 0.830200\n",
      "[ ecpho : 8  iter :232 ]train loss : 0.325191 ,train acc: 0.867513 ,val loss : 0.385951 ,val acc : 0.824738\n",
      "[ ecpho : 8  iter :233 ]train loss : 0.314044 ,train acc: 0.838511 ,val loss : 0.383253 ,val acc : 0.825623\n",
      "[ ecpho : 8  iter :234 ]train loss : 0.263267 ,train acc: 0.877421 ,val loss : 0.377937 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :235 ]train loss : 0.262465 ,train acc: 0.875753 ,val loss : 0.383514 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :236 ]train loss : 0.283174 ,train acc: 0.869955 ,val loss : 0.377420 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :237 ]train loss : 0.296515 ,train acc: 0.851430 ,val loss : 0.379128 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :238 ]train loss : 0.322516 ,train acc: 0.856039 ,val loss : 0.381525 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :239 ]train loss : 0.324701 ,train acc: 0.853394 ,val loss : 0.382039 ,val acc : 0.826080\n",
      "[ ecpho : 8  iter :240 ]train loss : 0.328391 ,train acc: 0.854564 ,val loss : 0.389358 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :241 ]train loss : 0.311846 ,train acc: 0.857432 ,val loss : 0.378246 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :242 ]train loss : 0.283345 ,train acc: 0.859609 ,val loss : 0.382572 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :243 ]train loss : 0.299403 ,train acc: 0.866465 ,val loss : 0.378786 ,val acc : 0.827301\n",
      "[ ecpho : 8  iter :244 ]train loss : 0.274148 ,train acc: 0.869975 ,val loss : 0.382371 ,val acc : 0.831116\n",
      "[ ecpho : 8  iter :245 ]train loss : 0.337261 ,train acc: 0.845459 ,val loss : 0.383771 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :246 ]train loss : 0.343165 ,train acc: 0.851908 ,val loss : 0.379032 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :247 ]train loss : 0.256031 ,train acc: 0.877828 ,val loss : 0.379921 ,val acc : 0.828064\n",
      "[ ecpho : 8  iter :248 ]train loss : 0.242288 ,train acc: 0.883535 ,val loss : 0.386908 ,val acc : 0.826019\n",
      "[ ecpho : 8  iter :249 ]train loss : 0.321963 ,train acc: 0.852193 ,val loss : 0.373994 ,val acc : 0.831055\n",
      "[ ecpho : 8  iter :250 ]train loss : 0.470734 ,train acc: 0.824606 ,val loss : 0.377245 ,val acc : 0.829254\n",
      "[ ecpho : 8  iter :251 ]train loss : 0.466789 ,train acc: 0.794617 ,val loss : 0.381567 ,val acc : 0.829437\n",
      "[ ecpho : 8  iter :252 ]train loss : 0.346513 ,train acc: 0.832164 ,val loss : 0.381618 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :253 ]train loss : 0.282859 ,train acc: 0.857513 ,val loss : 0.376569 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :254 ]train loss : 0.252795 ,train acc: 0.878988 ,val loss : 0.378879 ,val acc : 0.828857\n",
      "[ ecpho : 8  iter :255 ]train loss : 0.283884 ,train acc: 0.865000 ,val loss : 0.378905 ,val acc : 0.830566\n",
      "[ ecpho : 8  iter :256 ]train loss : 0.272407 ,train acc: 0.876892 ,val loss : 0.380480 ,val acc : 0.830658\n",
      "[ ecpho : 8  iter :257 ]train loss : 0.448770 ,train acc: 0.841197 ,val loss : 0.377538 ,val acc : 0.831177\n",
      "[ ecpho : 8  iter :258 ]train loss : 0.304441 ,train acc: 0.861033 ,val loss : 0.385969 ,val acc : 0.827209\n",
      "[ ecpho : 8  iter :259 ]train loss : 0.245632 ,train acc: 0.880717 ,val loss : 0.381095 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :260 ]train loss : 0.244757 ,train acc: 0.882965 ,val loss : 0.383153 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :261 ]train loss : 0.387194 ,train acc: 0.851512 ,val loss : 0.376323 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :262 ]train loss : 0.255537 ,train acc: 0.876424 ,val loss : 0.376092 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :263 ]train loss : 0.338012 ,train acc: 0.847138 ,val loss : 0.383009 ,val acc : 0.831055\n",
      "[ ecpho : 8  iter :264 ]train loss : 0.339167 ,train acc: 0.852946 ,val loss : 0.380936 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :265 ]train loss : 0.323594 ,train acc: 0.827810 ,val loss : 0.376900 ,val acc : 0.831299\n",
      "[ ecpho : 8  iter :266 ]train loss : 0.287140 ,train acc: 0.872233 ,val loss : 0.381747 ,val acc : 0.829407\n",
      "[ ecpho : 8  iter :267 ]train loss : 0.250073 ,train acc: 0.883026 ,val loss : 0.382142 ,val acc : 0.830902\n",
      "[ ecpho : 8  iter :268 ]train loss : 0.259631 ,train acc: 0.876536 ,val loss : 0.382849 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :269 ]train loss : 0.289341 ,train acc: 0.859324 ,val loss : 0.382940 ,val acc : 0.830963\n",
      "[ ecpho : 8  iter :270 ]train loss : 0.301635 ,train acc: 0.859935 ,val loss : 0.381285 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :271 ]train loss : 0.248481 ,train acc: 0.877411 ,val loss : 0.380471 ,val acc : 0.827942\n",
      "[ ecpho : 8  iter :272 ]train loss : 0.233638 ,train acc: 0.886993 ,val loss : 0.380026 ,val acc : 0.827454\n",
      "[ ecpho : 8  iter :273 ]train loss : 0.471042 ,train acc: 0.832886 ,val loss : 0.380656 ,val acc : 0.828400\n",
      "[ ecpho : 8  iter :274 ]train loss : 0.253282 ,train acc: 0.880544 ,val loss : 0.383436 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :275 ]train loss : 0.287539 ,train acc: 0.870372 ,val loss : 0.373587 ,val acc : 0.832062\n",
      "[ ecpho : 8  iter :276 ]train loss : 0.332075 ,train acc: 0.845927 ,val loss : 0.376691 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :277 ]train loss : 0.277087 ,train acc: 0.865072 ,val loss : 0.381328 ,val acc : 0.826416\n",
      "[ ecpho : 8  iter :278 ]train loss : 0.326441 ,train acc: 0.830455 ,val loss : 0.377773 ,val acc : 0.829651\n",
      "[ ecpho : 8  iter :279 ]train loss : 0.266936 ,train acc: 0.868968 ,val loss : 0.377162 ,val acc : 0.830750\n",
      "[ ecpho : 8  iter :280 ]train loss : 0.305690 ,train acc: 0.864075 ,val loss : 0.382445 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :281 ]train loss : 0.267233 ,train acc: 0.876241 ,val loss : 0.380110 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :282 ]train loss : 0.322475 ,train acc: 0.861074 ,val loss : 0.386668 ,val acc : 0.826508\n",
      "[ ecpho : 8  iter :283 ]train loss : 0.239188 ,train acc: 0.886098 ,val loss : 0.379153 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :284 ]train loss : 0.254812 ,train acc: 0.878387 ,val loss : 0.386364 ,val acc : 0.826813\n",
      "[ ecpho : 8  iter :285 ]train loss : 0.531357 ,train acc: 0.783966 ,val loss : 0.382802 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :286 ]train loss : 0.300397 ,train acc: 0.858114 ,val loss : 0.382335 ,val acc : 0.828064\n",
      "[ ecpho : 8  iter :287 ]train loss : 0.301469 ,train acc: 0.860006 ,val loss : 0.385946 ,val acc : 0.825745\n",
      "[ ecpho : 8  iter :288 ]train loss : 0.284037 ,train acc: 0.852966 ,val loss : 0.385130 ,val acc : 0.825134\n",
      "[ ecpho : 8  iter :289 ]train loss : 0.290031 ,train acc: 0.866140 ,val loss : 0.377353 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :290 ]train loss : 0.262780 ,train acc: 0.877645 ,val loss : 0.382317 ,val acc : 0.827454\n",
      "[ ecpho : 8  iter :291 ]train loss : 0.321769 ,train acc: 0.854736 ,val loss : 0.382647 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :292 ]train loss : 0.287533 ,train acc: 0.866730 ,val loss : 0.382240 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :293 ]train loss : 0.264884 ,train acc: 0.876597 ,val loss : 0.377116 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :294 ]train loss : 0.285349 ,train acc: 0.860016 ,val loss : 0.376267 ,val acc : 0.831146\n",
      "[ ecpho : 8  iter :295 ]train loss : 0.307966 ,train acc: 0.868774 ,val loss : 0.380121 ,val acc : 0.824921\n",
      "[ ecpho : 8  iter :296 ]train loss : 0.390004 ,train acc: 0.829488 ,val loss : 0.376876 ,val acc : 0.829987\n",
      "[ ecpho : 8  iter :297 ]train loss : 0.263528 ,train acc: 0.881215 ,val loss : 0.381610 ,val acc : 0.826050\n",
      "[ ecpho : 8  iter :298 ]train loss : 0.274293 ,train acc: 0.874502 ,val loss : 0.380583 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :299 ]train loss : 0.387569 ,train acc: 0.835419 ,val loss : 0.389331 ,val acc : 0.824463\n",
      "[ ecpho : 8  iter :300 ]train loss : 0.317874 ,train acc: 0.862793 ,val loss : 0.377433 ,val acc : 0.831390\n",
      "[ ecpho : 8  iter :301 ]train loss : 0.332734 ,train acc: 0.853760 ,val loss : 0.381972 ,val acc : 0.826599\n",
      "[ ecpho : 8  iter :302 ]train loss : 0.350125 ,train acc: 0.855103 ,val loss : 0.378565 ,val acc : 0.828949\n",
      "[ ecpho : 8  iter :303 ]train loss : 0.312976 ,train acc: 0.858582 ,val loss : 0.380362 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :304 ]train loss : 0.269432 ,train acc: 0.878408 ,val loss : 0.379775 ,val acc : 0.829987\n",
      "[ ecpho : 8  iter :305 ]train loss : 0.250552 ,train acc: 0.880330 ,val loss : 0.386219 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :306 ]train loss : 0.235372 ,train acc: 0.886291 ,val loss : 0.378840 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :307 ]train loss : 0.371563 ,train acc: 0.839264 ,val loss : 0.386874 ,val acc : 0.824860\n",
      "[ ecpho : 8  iter :308 ]train loss : 0.245620 ,train acc: 0.881694 ,val loss : 0.379871 ,val acc : 0.826813\n",
      "[ ecpho : 8  iter :309 ]train loss : 0.229548 ,train acc: 0.890432 ,val loss : 0.375457 ,val acc : 0.829590\n",
      "[ ecpho : 8  iter :310 ]train loss : 0.338223 ,train acc: 0.837331 ,val loss : 0.381092 ,val acc : 0.825256\n",
      "[ ecpho : 8  iter :311 ]train loss : 0.371349 ,train acc: 0.829875 ,val loss : 0.376758 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :312 ]train loss : 0.294982 ,train acc: 0.872538 ,val loss : 0.385595 ,val acc : 0.828766\n",
      "[ ecpho : 8  iter :313 ]train loss : 0.233998 ,train acc: 0.888855 ,val loss : 0.383127 ,val acc : 0.828400\n",
      "[ ecpho : 8  iter :314 ]train loss : 0.262871 ,train acc: 0.872477 ,val loss : 0.378335 ,val acc : 0.829315\n",
      "[ ecpho : 8  iter :315 ]train loss : 0.372284 ,train acc: 0.856079 ,val loss : 0.374631 ,val acc : 0.829712\n",
      "[ ecpho : 8  iter :316 ]train loss : 0.313434 ,train acc: 0.861613 ,val loss : 0.380886 ,val acc : 0.824707\n",
      "[ ecpho : 8  iter :317 ]train loss : 0.293319 ,train acc: 0.863780 ,val loss : 0.383209 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :318 ]train loss : 0.398793 ,train acc: 0.833639 ,val loss : 0.388610 ,val acc : 0.827057\n",
      "[ ecpho : 8  iter :319 ]train loss : 0.237131 ,train acc: 0.887054 ,val loss : 0.380536 ,val acc : 0.828827\n",
      "[ ecpho : 8  iter :320 ]train loss : 0.348505 ,train acc: 0.854675 ,val loss : 0.384648 ,val acc : 0.826935\n",
      "[ ecpho : 8  iter :321 ]train loss : 0.361027 ,train acc: 0.821503 ,val loss : 0.383889 ,val acc : 0.824432\n",
      "[ ecpho : 8  iter :322 ]train loss : 0.423176 ,train acc: 0.818807 ,val loss : 0.380870 ,val acc : 0.829895\n",
      "[ ecpho : 8  iter :323 ]train loss : 0.298491 ,train acc: 0.849192 ,val loss : 0.375681 ,val acc : 0.831573\n",
      "[ ecpho : 8  iter :324 ]train loss : 0.266247 ,train acc: 0.877075 ,val loss : 0.382533 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :325 ]train loss : 0.353485 ,train acc: 0.834992 ,val loss : 0.385017 ,val acc : 0.829315\n",
      "[ ecpho : 8  iter :326 ]train loss : 0.456538 ,train acc: 0.808665 ,val loss : 0.379360 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :327 ]train loss : 0.374593 ,train acc: 0.849640 ,val loss : 0.381237 ,val acc : 0.829529\n",
      "[ ecpho : 8  iter :328 ]train loss : 0.285526 ,train acc: 0.853821 ,val loss : 0.381163 ,val acc : 0.826904\n",
      "[ ecpho : 8  iter :329 ]train loss : 0.311010 ,train acc: 0.857219 ,val loss : 0.379545 ,val acc : 0.829559\n",
      "[ ecpho : 8  iter :330 ]train loss : 0.359356 ,train acc: 0.854625 ,val loss : 0.378145 ,val acc : 0.826874\n",
      "[ ecpho : 8  iter :331 ]train loss : 0.474758 ,train acc: 0.829081 ,val loss : 0.379882 ,val acc : 0.826477\n",
      "[ ecpho : 8  iter :332 ]train loss : 0.272301 ,train acc: 0.868856 ,val loss : 0.380782 ,val acc : 0.828033\n",
      "[ ecpho : 8  iter :333 ]train loss : 0.598047 ,train acc: 0.814840 ,val loss : 0.379310 ,val acc : 0.829315\n",
      "[ ecpho : 8  iter :334 ]train loss : 0.309477 ,train acc: 0.863424 ,val loss : 0.382564 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :335 ]train loss : 0.307069 ,train acc: 0.851858 ,val loss : 0.383789 ,val acc : 0.826080\n",
      "[ ecpho : 8  iter :336 ]train loss : 0.372957 ,train acc: 0.842458 ,val loss : 0.379827 ,val acc : 0.830475\n",
      "[ ecpho : 8  iter :337 ]train loss : 0.337902 ,train acc: 0.863180 ,val loss : 0.383013 ,val acc : 0.829041\n",
      "[ ecpho : 8  iter :338 ]train loss : 0.356935 ,train acc: 0.853984 ,val loss : 0.385047 ,val acc : 0.827332\n",
      "[ ecpho : 8  iter :339 ]train loss : 0.318983 ,train acc: 0.859996 ,val loss : 0.378171 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :340 ]train loss : 0.268490 ,train acc: 0.868968 ,val loss : 0.377545 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :341 ]train loss : 0.310082 ,train acc: 0.842021 ,val loss : 0.380186 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :342 ]train loss : 0.268073 ,train acc: 0.877523 ,val loss : 0.383675 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :343 ]train loss : 0.337398 ,train acc: 0.857493 ,val loss : 0.379681 ,val acc : 0.830414\n",
      "[ ecpho : 8  iter :344 ]train loss : 0.256190 ,train acc: 0.879527 ,val loss : 0.384320 ,val acc : 0.826263\n",
      "[ ecpho : 8  iter :345 ]train loss : 0.301307 ,train acc: 0.859456 ,val loss : 0.376311 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :346 ]train loss : 0.251183 ,train acc: 0.878387 ,val loss : 0.386905 ,val acc : 0.826477\n",
      "[ ecpho : 8  iter :347 ]train loss : 0.241079 ,train acc: 0.880391 ,val loss : 0.375757 ,val acc : 0.827087\n",
      "[ ecpho : 8  iter :348 ]train loss : 0.320300 ,train acc: 0.816101 ,val loss : 0.378837 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :349 ]train loss : 0.322680 ,train acc: 0.854441 ,val loss : 0.383334 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :350 ]train loss : 0.299688 ,train acc: 0.855276 ,val loss : 0.376784 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :351 ]train loss : 0.276086 ,train acc: 0.871155 ,val loss : 0.378585 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :352 ]train loss : 0.377982 ,train acc: 0.837535 ,val loss : 0.380497 ,val acc : 0.826660\n",
      "[ ecpho : 8  iter :353 ]train loss : 0.310046 ,train acc: 0.862742 ,val loss : 0.384489 ,val acc : 0.826263\n",
      "[ ecpho : 8  iter :354 ]train loss : 0.347777 ,train acc: 0.842133 ,val loss : 0.388314 ,val acc : 0.824951\n",
      "[ ecpho : 8  iter :355 ]train loss : 0.242690 ,train acc: 0.885468 ,val loss : 0.378819 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :356 ]train loss : 0.479306 ,train acc: 0.813711 ,val loss : 0.382476 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :357 ]train loss : 0.338565 ,train acc: 0.850322 ,val loss : 0.387504 ,val acc : 0.826172\n",
      "[ ecpho : 8  iter :358 ]train loss : 0.379871 ,train acc: 0.849233 ,val loss : 0.386312 ,val acc : 0.825867\n",
      "[ ecpho : 8  iter :359 ]train loss : 0.359505 ,train acc: 0.860626 ,val loss : 0.388122 ,val acc : 0.824585\n",
      "[ ecpho : 8  iter :360 ]train loss : 0.271102 ,train acc: 0.871826 ,val loss : 0.385182 ,val acc : 0.825073\n",
      "[ ecpho : 8  iter :361 ]train loss : 0.264548 ,train acc: 0.875437 ,val loss : 0.381680 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :362 ]train loss : 0.239561 ,train acc: 0.884949 ,val loss : 0.377387 ,val acc : 0.830750\n",
      "[ ecpho : 8  iter :363 ]train loss : 0.273434 ,train acc: 0.870972 ,val loss : 0.375375 ,val acc : 0.830902\n",
      "[ ecpho : 8  iter :364 ]train loss : 0.328423 ,train acc: 0.855357 ,val loss : 0.381558 ,val acc : 0.826935\n",
      "[ ecpho : 8  iter :365 ]train loss : 0.341661 ,train acc: 0.842987 ,val loss : 0.382225 ,val acc : 0.829681\n",
      "[ ecpho : 8  iter :366 ]train loss : 0.321111 ,train acc: 0.861226 ,val loss : 0.378517 ,val acc : 0.830017\n",
      "[ ecpho : 8  iter :367 ]train loss : 0.299772 ,train acc: 0.861613 ,val loss : 0.380566 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :368 ]train loss : 0.272034 ,train acc: 0.872304 ,val loss : 0.381892 ,val acc : 0.825348\n",
      "[ ecpho : 8  iter :369 ]train loss : 0.252564 ,train acc: 0.883301 ,val loss : 0.382257 ,val acc : 0.827454\n",
      "[ ecpho : 8  iter :370 ]train loss : 0.269015 ,train acc: 0.872864 ,val loss : 0.383770 ,val acc : 0.827759\n",
      "[ ecpho : 8  iter :371 ]train loss : 0.373651 ,train acc: 0.818421 ,val loss : 0.374036 ,val acc : 0.829895\n",
      "[ ecpho : 8  iter :372 ]train loss : 0.291096 ,train acc: 0.863800 ,val loss : 0.374757 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :373 ]train loss : 0.345368 ,train acc: 0.853455 ,val loss : 0.380531 ,val acc : 0.827515\n",
      "[ ecpho : 8  iter :374 ]train loss : 0.286675 ,train acc: 0.870829 ,val loss : 0.380813 ,val acc : 0.830505\n",
      "[ ecpho : 8  iter :375 ]train loss : 0.281836 ,train acc: 0.871256 ,val loss : 0.384061 ,val acc : 0.825500\n",
      "[ ecpho : 8  iter :376 ]train loss : 0.322182 ,train acc: 0.845042 ,val loss : 0.381857 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :377 ]train loss : 0.405097 ,train acc: 0.814840 ,val loss : 0.384063 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :378 ]train loss : 0.332391 ,train acc: 0.843689 ,val loss : 0.381599 ,val acc : 0.826813\n",
      "[ ecpho : 8  iter :379 ]train loss : 0.275772 ,train acc: 0.870667 ,val loss : 0.377276 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :380 ]train loss : 0.271344 ,train acc: 0.876882 ,val loss : 0.377126 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :381 ]train loss : 0.405926 ,train acc: 0.766886 ,val loss : 0.381333 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :382 ]train loss : 0.268790 ,train acc: 0.873088 ,val loss : 0.376976 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :383 ]train loss : 0.283827 ,train acc: 0.868652 ,val loss : 0.386767 ,val acc : 0.825165\n",
      "[ ecpho : 8  iter :384 ]train loss : 0.363486 ,train acc: 0.847545 ,val loss : 0.381297 ,val acc : 0.828064\n",
      "[ ecpho : 8  iter :385 ]train loss : 0.247059 ,train acc: 0.883107 ,val loss : 0.380175 ,val acc : 0.827942\n",
      "[ ecpho : 8  iter :386 ]train loss : 0.344605 ,train acc: 0.861247 ,val loss : 0.377755 ,val acc : 0.831848\n",
      "[ ecpho : 8  iter :387 ]train loss : 0.259828 ,train acc: 0.879771 ,val loss : 0.377485 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :388 ]train loss : 0.263081 ,train acc: 0.875692 ,val loss : 0.379545 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :389 ]train loss : 0.240491 ,train acc: 0.888072 ,val loss : 0.377085 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :390 ]train loss : 0.288272 ,train acc: 0.867798 ,val loss : 0.380685 ,val acc : 0.828033\n",
      "[ ecpho : 8  iter :391 ]train loss : 0.274676 ,train acc: 0.869242 ,val loss : 0.380393 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :392 ]train loss : 0.258520 ,train acc: 0.881571 ,val loss : 0.379482 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :393 ]train loss : 0.356889 ,train acc: 0.850240 ,val loss : 0.386751 ,val acc : 0.825531\n",
      "[ ecpho : 8  iter :394 ]train loss : 0.313555 ,train acc: 0.860331 ,val loss : 0.377728 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :395 ]train loss : 0.249318 ,train acc: 0.880086 ,val loss : 0.379806 ,val acc : 0.825378\n",
      "[ ecpho : 8  iter :396 ]train loss : 0.350225 ,train acc: 0.810415 ,val loss : 0.377125 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :397 ]train loss : 0.470453 ,train acc: 0.841899 ,val loss : 0.381353 ,val acc : 0.828491\n",
      "[ ecpho : 8  iter :398 ]train loss : 0.264689 ,train acc: 0.873159 ,val loss : 0.379954 ,val acc : 0.832092\n",
      "[ ecpho : 8  iter :399 ]train loss : 0.266427 ,train acc: 0.870880 ,val loss : 0.383503 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :400 ]train loss : 0.360682 ,train acc: 0.847646 ,val loss : 0.376580 ,val acc : 0.827576\n",
      "[ ecpho : 8  iter :401 ]train loss : 0.300201 ,train acc: 0.861725 ,val loss : 0.380098 ,val acc : 0.828827\n",
      "[ ecpho : 8  iter :402 ]train loss : 0.279699 ,train acc: 0.866903 ,val loss : 0.377269 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :403 ]train loss : 0.262412 ,train acc: 0.869151 ,val loss : 0.383254 ,val acc : 0.826263\n",
      "[ ecpho : 8  iter :404 ]train loss : 0.356673 ,train acc: 0.845195 ,val loss : 0.378298 ,val acc : 0.831848\n",
      "[ ecpho : 8  iter :405 ]train loss : 0.271437 ,train acc: 0.871379 ,val loss : 0.378215 ,val acc : 0.827759\n",
      "[ ecpho : 8  iter :406 ]train loss : 0.578852 ,train acc: 0.717367 ,val loss : 0.380912 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :407 ]train loss : 0.345440 ,train acc: 0.843170 ,val loss : 0.377260 ,val acc : 0.829529\n",
      "[ ecpho : 8  iter :408 ]train loss : 0.285085 ,train acc: 0.857931 ,val loss : 0.381408 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :409 ]train loss : 0.284329 ,train acc: 0.863444 ,val loss : 0.383550 ,val acc : 0.825409\n",
      "[ ecpho : 8  iter :410 ]train loss : 0.278696 ,train acc: 0.858856 ,val loss : 0.378298 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :411 ]train loss : 0.227698 ,train acc: 0.891134 ,val loss : 0.381321 ,val acc : 0.824768\n",
      "[ ecpho : 8  iter :412 ]train loss : 0.302524 ,train acc: 0.852305 ,val loss : 0.382420 ,val acc : 0.826263\n",
      "[ ecpho : 8  iter :413 ]train loss : 0.344371 ,train acc: 0.820272 ,val loss : 0.382564 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :414 ]train loss : 0.244365 ,train acc: 0.881043 ,val loss : 0.378067 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :415 ]train loss : 0.251435 ,train acc: 0.877106 ,val loss : 0.377335 ,val acc : 0.833099\n",
      "[ ecpho : 8  iter :416 ]train loss : 0.324496 ,train acc: 0.837840 ,val loss : 0.383832 ,val acc : 0.830536\n",
      "[ ecpho : 8  iter :417 ]train loss : 0.281303 ,train acc: 0.865529 ,val loss : 0.383194 ,val acc : 0.828979\n",
      "[ ecpho : 8  iter :418 ]train loss : 0.282847 ,train acc: 0.863780 ,val loss : 0.382220 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :419 ]train loss : 0.277030 ,train acc: 0.868581 ,val loss : 0.381158 ,val acc : 0.828705\n",
      "[ ecpho : 8  iter :420 ]train loss : 0.314457 ,train acc: 0.841716 ,val loss : 0.384004 ,val acc : 0.827393\n",
      "[ ecpho : 8  iter :421 ]train loss : 0.304927 ,train acc: 0.857798 ,val loss : 0.382303 ,val acc : 0.826080\n",
      "[ ecpho : 8  iter :422 ]train loss : 0.301907 ,train acc: 0.849609 ,val loss : 0.375866 ,val acc : 0.830597\n",
      "[ ecpho : 8  iter :423 ]train loss : 0.318137 ,train acc: 0.856944 ,val loss : 0.380040 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :424 ]train loss : 0.261084 ,train acc: 0.876618 ,val loss : 0.381591 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :425 ]train loss : 0.257084 ,train acc: 0.875936 ,val loss : 0.380532 ,val acc : 0.828491\n",
      "[ ecpho : 8  iter :426 ]train loss : 0.348698 ,train acc: 0.853790 ,val loss : 0.380471 ,val acc : 0.832123\n",
      "[ ecpho : 8  iter :427 ]train loss : 0.309633 ,train acc: 0.858683 ,val loss : 0.381931 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :428 ]train loss : 0.304347 ,train acc: 0.835317 ,val loss : 0.381102 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :429 ]train loss : 0.276902 ,train acc: 0.869507 ,val loss : 0.379577 ,val acc : 0.827362\n",
      "[ ecpho : 8  iter :430 ]train loss : 0.323503 ,train acc: 0.863302 ,val loss : 0.383196 ,val acc : 0.832336\n",
      "[ ecpho : 8  iter :431 ]train loss : 0.280481 ,train acc: 0.866893 ,val loss : 0.387661 ,val acc : 0.826782\n",
      "[ ecpho : 8  iter :432 ]train loss : 0.309596 ,train acc: 0.838460 ,val loss : 0.379865 ,val acc : 0.825653\n",
      "[ ecpho : 8  iter :433 ]train loss : 0.313192 ,train acc: 0.852560 ,val loss : 0.376438 ,val acc : 0.826904\n",
      "[ ecpho : 8  iter :434 ]train loss : 0.318717 ,train acc: 0.854828 ,val loss : 0.378468 ,val acc : 0.825897\n",
      "[ ecpho : 8  iter :435 ]train loss : 0.311182 ,train acc: 0.859314 ,val loss : 0.382907 ,val acc : 0.824493\n",
      "[ ecpho : 8  iter :436 ]train loss : 0.262203 ,train acc: 0.873830 ,val loss : 0.378153 ,val acc : 0.827148\n",
      "[ ecpho : 8  iter :437 ]train loss : 0.302529 ,train acc: 0.864268 ,val loss : 0.383005 ,val acc : 0.828979\n",
      "[ ecpho : 8  iter :438 ]train loss : 0.313971 ,train acc: 0.854065 ,val loss : 0.379997 ,val acc : 0.829926\n",
      "[ ecpho : 8  iter :439 ]train loss : 0.247484 ,train acc: 0.882629 ,val loss : 0.385903 ,val acc : 0.826477\n",
      "[ ecpho : 8  iter :440 ]train loss : 0.253756 ,train acc: 0.886454 ,val loss : 0.384437 ,val acc : 0.824554\n",
      "[ ecpho : 8  iter :441 ]train loss : 0.271526 ,train acc: 0.867564 ,val loss : 0.381373 ,val acc : 0.826996\n",
      "[ ecpho : 8  iter :442 ]train loss : 0.285966 ,train acc: 0.871175 ,val loss : 0.384428 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :443 ]train loss : 0.308965 ,train acc: 0.848704 ,val loss : 0.380109 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :444 ]train loss : 0.321088 ,train acc: 0.864380 ,val loss : 0.373442 ,val acc : 0.826935\n",
      "[ ecpho : 8  iter :445 ]train loss : 0.337602 ,train acc: 0.835917 ,val loss : 0.384003 ,val acc : 0.828339\n",
      "[ ecpho : 8  iter :446 ]train loss : 0.456127 ,train acc: 0.815064 ,val loss : 0.378428 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :447 ]train loss : 0.304300 ,train acc: 0.849477 ,val loss : 0.385799 ,val acc : 0.830475\n",
      "[ ecpho : 8  iter :448 ]train loss : 0.320643 ,train acc: 0.850637 ,val loss : 0.383536 ,val acc : 0.826935\n",
      "[ ecpho : 8  iter :449 ]train loss : 0.266345 ,train acc: 0.875987 ,val loss : 0.381800 ,val acc : 0.828613\n",
      "[ ecpho : 8  iter :450 ]train loss : 0.293311 ,train acc: 0.865255 ,val loss : 0.377701 ,val acc : 0.828949\n",
      "[ ecpho : 8  iter :451 ]train loss : 0.373626 ,train acc: 0.799683 ,val loss : 0.382423 ,val acc : 0.825256\n",
      "[ ecpho : 8  iter :452 ]train loss : 0.287108 ,train acc: 0.863281 ,val loss : 0.383617 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :453 ]train loss : 0.285630 ,train acc: 0.875132 ,val loss : 0.381215 ,val acc : 0.827209\n",
      "[ ecpho : 8  iter :454 ]train loss : 0.344867 ,train acc: 0.851044 ,val loss : 0.381865 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :455 ]train loss : 0.389763 ,train acc: 0.842896 ,val loss : 0.385315 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :456 ]train loss : 0.258538 ,train acc: 0.882701 ,val loss : 0.380466 ,val acc : 0.825745\n",
      "[ ecpho : 8  iter :457 ]train loss : 0.268158 ,train acc: 0.876485 ,val loss : 0.381603 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :458 ]train loss : 0.333783 ,train acc: 0.853028 ,val loss : 0.379476 ,val acc : 0.827606\n",
      "[ ecpho : 8  iter :459 ]train loss : 0.342271 ,train acc: 0.852224 ,val loss : 0.376689 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :460 ]train loss : 0.298866 ,train acc: 0.870626 ,val loss : 0.377126 ,val acc : 0.827576\n",
      "[ ecpho : 8  iter :461 ]train loss : 0.361974 ,train acc: 0.824778 ,val loss : 0.372651 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :462 ]train loss : 0.252880 ,train acc: 0.877838 ,val loss : 0.381316 ,val acc : 0.826263\n",
      "[ ecpho : 8  iter :463 ]train loss : 0.260577 ,train acc: 0.876414 ,val loss : 0.380949 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :464 ]train loss : 0.285588 ,train acc: 0.867503 ,val loss : 0.377996 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :465 ]train loss : 0.343040 ,train acc: 0.845256 ,val loss : 0.371980 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :466 ]train loss : 0.264137 ,train acc: 0.868897 ,val loss : 0.375536 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :467 ]train loss : 0.256248 ,train acc: 0.873983 ,val loss : 0.379328 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :468 ]train loss : 0.332899 ,train acc: 0.861735 ,val loss : 0.381916 ,val acc : 0.827576\n",
      "[ ecpho : 8  iter :469 ]train loss : 0.289992 ,train acc: 0.865163 ,val loss : 0.375518 ,val acc : 0.831177\n",
      "[ ecpho : 8  iter :470 ]train loss : 0.275649 ,train acc: 0.860575 ,val loss : 0.379182 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :471 ]train loss : 0.307436 ,train acc: 0.858989 ,val loss : 0.384503 ,val acc : 0.826965\n",
      "[ ecpho : 8  iter :472 ]train loss : 0.282693 ,train acc: 0.869649 ,val loss : 0.380255 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :473 ]train loss : 0.237305 ,train acc: 0.882752 ,val loss : 0.381572 ,val acc : 0.828033\n",
      "[ ecpho : 8  iter :474 ]train loss : 0.382891 ,train acc: 0.828176 ,val loss : 0.381578 ,val acc : 0.828430\n",
      "[ ecpho : 8  iter :475 ]train loss : 0.411212 ,train acc: 0.833700 ,val loss : 0.388284 ,val acc : 0.825500\n",
      "[ ecpho : 8  iter :476 ]train loss : 0.329288 ,train acc: 0.847951 ,val loss : 0.382790 ,val acc : 0.824524\n",
      "[ ecpho : 8  iter :477 ]train loss : 0.271788 ,train acc: 0.872182 ,val loss : 0.380960 ,val acc : 0.824402\n",
      "[ ecpho : 8  iter :478 ]train loss : 0.337712 ,train acc: 0.852682 ,val loss : 0.377343 ,val acc : 0.830353\n",
      "[ ecpho : 8  iter :479 ]train loss : 0.331679 ,train acc: 0.849945 ,val loss : 0.385665 ,val acc : 0.824005\n",
      "[ ecpho : 8  iter :480 ]train loss : 0.353403 ,train acc: 0.847331 ,val loss : 0.377262 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :481 ]train loss : 0.271520 ,train acc: 0.875407 ,val loss : 0.383700 ,val acc : 0.827209\n",
      "[ ecpho : 8  iter :482 ]train loss : 0.367415 ,train acc: 0.849487 ,val loss : 0.378989 ,val acc : 0.829620\n",
      "[ ecpho : 8  iter :483 ]train loss : 0.369195 ,train acc: 0.836426 ,val loss : 0.379460 ,val acc : 0.828094\n",
      "[ ecpho : 8  iter :484 ]train loss : 0.307402 ,train acc: 0.853038 ,val loss : 0.385312 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :485 ]train loss : 0.277434 ,train acc: 0.869466 ,val loss : 0.382976 ,val acc : 0.826752\n",
      "[ ecpho : 8  iter :486 ]train loss : 0.308108 ,train acc: 0.849966 ,val loss : 0.380040 ,val acc : 0.826447\n",
      "[ ecpho : 8  iter :487 ]train loss : 0.321107 ,train acc: 0.844503 ,val loss : 0.384755 ,val acc : 0.830292\n",
      "[ ecpho : 8  iter :488 ]train loss : 0.241170 ,train acc: 0.886342 ,val loss : 0.383145 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :489 ]train loss : 0.452423 ,train acc: 0.833537 ,val loss : 0.382284 ,val acc : 0.829498\n",
      "[ ecpho : 8  iter :490 ]train loss : 0.244261 ,train acc: 0.882436 ,val loss : 0.380263 ,val acc : 0.831329\n",
      "[ ecpho : 8  iter :491 ]train loss : 0.311140 ,train acc: 0.863119 ,val loss : 0.382932 ,val acc : 0.826508\n",
      "[ ecpho : 8  iter :492 ]train loss : 0.234547 ,train acc: 0.889048 ,val loss : 0.381293 ,val acc : 0.826813\n",
      "[ ecpho : 8  iter :493 ]train loss : 0.343320 ,train acc: 0.817393 ,val loss : 0.384825 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :494 ]train loss : 0.382188 ,train acc: 0.837209 ,val loss : 0.383378 ,val acc : 0.826355\n",
      "[ ecpho : 8  iter :495 ]train loss : 0.358498 ,train acc: 0.829427 ,val loss : 0.378624 ,val acc : 0.831116\n",
      "[ ecpho : 8  iter :496 ]train loss : 0.276947 ,train acc: 0.876760 ,val loss : 0.377276 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :497 ]train loss : 0.354967 ,train acc: 0.838369 ,val loss : 0.375642 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :498 ]train loss : 0.272474 ,train acc: 0.864644 ,val loss : 0.378553 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :499 ]train loss : 0.326842 ,train acc: 0.850993 ,val loss : 0.383090 ,val acc : 0.828735\n",
      "[ ecpho : 8  iter :500 ]train loss : 0.330669 ,train acc: 0.842947 ,val loss : 0.379925 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :501 ]train loss : 0.301983 ,train acc: 0.845307 ,val loss : 0.381585 ,val acc : 0.829041\n",
      "[ ecpho : 8  iter :502 ]train loss : 0.313676 ,train acc: 0.861766 ,val loss : 0.377989 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :503 ]train loss : 0.290287 ,train acc: 0.858734 ,val loss : 0.381243 ,val acc : 0.827515\n",
      "[ ecpho : 8  iter :504 ]train loss : 0.320446 ,train acc: 0.860006 ,val loss : 0.373446 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :505 ]train loss : 0.260124 ,train acc: 0.877970 ,val loss : 0.385496 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :506 ]train loss : 0.247144 ,train acc: 0.887075 ,val loss : 0.380527 ,val acc : 0.829437\n",
      "[ ecpho : 8  iter :507 ]train loss : 0.326055 ,train acc: 0.860698 ,val loss : 0.384333 ,val acc : 0.825592\n",
      "[ ecpho : 8  iter :508 ]train loss : 0.233721 ,train acc: 0.886841 ,val loss : 0.385645 ,val acc : 0.826324\n",
      "[ ecpho : 8  iter :509 ]train loss : 0.235419 ,train acc: 0.887573 ,val loss : 0.379994 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :510 ]train loss : 0.325508 ,train acc: 0.849792 ,val loss : 0.374987 ,val acc : 0.829590\n",
      "[ ecpho : 8  iter :511 ]train loss : 0.267590 ,train acc: 0.870453 ,val loss : 0.387602 ,val acc : 0.827942\n",
      "[ ecpho : 8  iter :512 ]train loss : 0.265234 ,train acc: 0.877065 ,val loss : 0.382157 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :513 ]train loss : 0.274486 ,train acc: 0.859436 ,val loss : 0.379999 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :514 ]train loss : 0.317574 ,train acc: 0.847809 ,val loss : 0.378617 ,val acc : 0.828217\n",
      "[ ecpho : 8  iter :515 ]train loss : 0.332128 ,train acc: 0.860748 ,val loss : 0.382851 ,val acc : 0.826050\n",
      "[ ecpho : 8  iter :516 ]train loss : 0.338923 ,train acc: 0.820933 ,val loss : 0.380798 ,val acc : 0.828400\n",
      "[ ecpho : 8  iter :517 ]train loss : 0.257223 ,train acc: 0.879852 ,val loss : 0.380295 ,val acc : 0.828491\n",
      "[ ecpho : 8  iter :518 ]train loss : 0.300700 ,train acc: 0.852376 ,val loss : 0.374970 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :519 ]train loss : 0.301375 ,train acc: 0.871419 ,val loss : 0.382686 ,val acc : 0.826202\n",
      "[ ecpho : 8  iter :520 ]train loss : 0.322094 ,train acc: 0.850555 ,val loss : 0.383790 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :521 ]train loss : 0.313364 ,train acc: 0.844727 ,val loss : 0.380067 ,val acc : 0.832458\n",
      "[ ecpho : 8  iter :522 ]train loss : 0.259604 ,train acc: 0.876495 ,val loss : 0.384790 ,val acc : 0.825714\n",
      "[ ecpho : 8  iter :523 ]train loss : 0.288833 ,train acc: 0.869761 ,val loss : 0.380074 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :524 ]train loss : 0.337538 ,train acc: 0.857300 ,val loss : 0.380133 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :525 ]train loss : 0.279382 ,train acc: 0.860687 ,val loss : 0.376137 ,val acc : 0.829926\n",
      "[ ecpho : 8  iter :526 ]train loss : 0.279607 ,train acc: 0.870209 ,val loss : 0.383338 ,val acc : 0.823486\n",
      "[ ecpho : 8  iter :527 ]train loss : 0.260032 ,train acc: 0.873372 ,val loss : 0.377878 ,val acc : 0.826904\n",
      "[ ecpho : 8  iter :528 ]train loss : 0.315241 ,train acc: 0.840902 ,val loss : 0.375694 ,val acc : 0.832733\n",
      "[ ecpho : 8  iter :529 ]train loss : 0.423615 ,train acc: 0.804474 ,val loss : 0.379044 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :530 ]train loss : 0.262130 ,train acc: 0.875366 ,val loss : 0.376142 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :531 ]train loss : 0.264250 ,train acc: 0.874593 ,val loss : 0.379934 ,val acc : 0.828857\n",
      "[ ecpho : 8  iter :532 ]train loss : 0.314264 ,train acc: 0.840709 ,val loss : 0.377411 ,val acc : 0.828857\n",
      "[ ecpho : 8  iter :533 ]train loss : 0.474721 ,train acc: 0.786001 ,val loss : 0.373651 ,val acc : 0.830963\n",
      "[ ecpho : 8  iter :534 ]train loss : 0.338129 ,train acc: 0.848592 ,val loss : 0.381431 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :535 ]train loss : 0.289315 ,train acc: 0.857595 ,val loss : 0.379802 ,val acc : 0.827911\n",
      "[ ecpho : 8  iter :536 ]train loss : 0.353753 ,train acc: 0.820058 ,val loss : 0.380030 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :537 ]train loss : 0.305200 ,train acc: 0.855815 ,val loss : 0.381475 ,val acc : 0.828613\n",
      "[ ecpho : 8  iter :538 ]train loss : 0.288480 ,train acc: 0.862590 ,val loss : 0.380017 ,val acc : 0.828949\n",
      "[ ecpho : 8  iter :539 ]train loss : 0.344753 ,train acc: 0.850901 ,val loss : 0.385621 ,val acc : 0.825806\n",
      "[ ecpho : 8  iter :540 ]train loss : 0.353362 ,train acc: 0.846558 ,val loss : 0.380515 ,val acc : 0.830017\n",
      "[ ecpho : 8  iter :541 ]train loss : 0.255417 ,train acc: 0.880147 ,val loss : 0.385623 ,val acc : 0.825104\n",
      "[ ecpho : 8  iter :542 ]train loss : 0.248728 ,train acc: 0.878408 ,val loss : 0.376682 ,val acc : 0.831940\n",
      "[ ecpho : 8  iter :543 ]train loss : 0.335897 ,train acc: 0.833669 ,val loss : 0.379672 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :544 ]train loss : 0.260280 ,train acc: 0.879954 ,val loss : 0.373615 ,val acc : 0.831635\n",
      "[ ecpho : 8  iter :545 ]train loss : 0.472382 ,train acc: 0.777578 ,val loss : 0.379940 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :546 ]train loss : 0.336111 ,train acc: 0.861155 ,val loss : 0.379592 ,val acc : 0.827606\n",
      "[ ecpho : 8  iter :547 ]train loss : 0.270600 ,train acc: 0.868174 ,val loss : 0.382134 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :548 ]train loss : 0.438879 ,train acc: 0.723216 ,val loss : 0.381176 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :549 ]train loss : 0.279211 ,train acc: 0.871094 ,val loss : 0.379235 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :550 ]train loss : 0.251785 ,train acc: 0.878937 ,val loss : 0.383588 ,val acc : 0.830292\n",
      "[ ecpho : 8  iter :551 ]train loss : 0.345076 ,train acc: 0.861389 ,val loss : 0.379844 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :552 ]train loss : 0.305436 ,train acc: 0.861908 ,val loss : 0.382038 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :553 ]train loss : 0.357412 ,train acc: 0.842407 ,val loss : 0.382096 ,val acc : 0.829834\n",
      "[ ecpho : 8  iter :554 ]train loss : 0.400809 ,train acc: 0.782298 ,val loss : 0.385346 ,val acc : 0.827209\n",
      "[ ecpho : 8  iter :555 ]train loss : 0.239474 ,train acc: 0.883464 ,val loss : 0.376816 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :556 ]train loss : 0.349487 ,train acc: 0.851502 ,val loss : 0.382346 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :557 ]train loss : 0.254609 ,train acc: 0.878621 ,val loss : 0.384167 ,val acc : 0.829224\n",
      "[ ecpho : 8  iter :558 ]train loss : 0.297562 ,train acc: 0.857259 ,val loss : 0.383356 ,val acc : 0.826019\n",
      "[ ecpho : 8  iter :559 ]train loss : 0.397400 ,train acc: 0.795166 ,val loss : 0.380710 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :560 ]train loss : 0.267345 ,train acc: 0.874502 ,val loss : 0.374959 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :561 ]train loss : 0.397910 ,train acc: 0.846965 ,val loss : 0.379559 ,val acc : 0.829803\n",
      "[ ecpho : 8  iter :562 ]train loss : 0.423174 ,train acc: 0.820638 ,val loss : 0.384223 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :563 ]train loss : 0.318107 ,train acc: 0.853017 ,val loss : 0.377731 ,val acc : 0.830261\n",
      "[ ecpho : 8  iter :564 ]train loss : 0.278860 ,train acc: 0.869995 ,val loss : 0.380712 ,val acc : 0.828339\n",
      "[ ecpho : 8  iter :565 ]train loss : 0.336033 ,train acc: 0.860413 ,val loss : 0.381298 ,val acc : 0.826263\n",
      "[ ecpho : 8  iter :566 ]train loss : 0.347465 ,train acc: 0.849070 ,val loss : 0.379333 ,val acc : 0.830536\n",
      "[ ecpho : 8  iter :567 ]train loss : 0.277825 ,train acc: 0.871643 ,val loss : 0.378821 ,val acc : 0.828766\n",
      "[ ecpho : 8  iter :568 ]train loss : 0.254104 ,train acc: 0.880483 ,val loss : 0.380355 ,val acc : 0.828491\n",
      "[ ecpho : 8  iter :569 ]train loss : 0.396683 ,train acc: 0.813660 ,val loss : 0.382062 ,val acc : 0.823822\n",
      "[ ecpho : 8  iter :570 ]train loss : 0.324602 ,train acc: 0.853831 ,val loss : 0.387145 ,val acc : 0.826599\n",
      "[ ecpho : 8  iter :571 ]train loss : 0.329726 ,train acc: 0.849213 ,val loss : 0.379293 ,val acc : 0.829590\n",
      "[ ecpho : 8  iter :572 ]train loss : 0.407333 ,train acc: 0.783722 ,val loss : 0.378308 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :573 ]train loss : 0.289769 ,train acc: 0.874135 ,val loss : 0.383400 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :574 ]train loss : 0.263074 ,train acc: 0.875763 ,val loss : 0.382260 ,val acc : 0.826508\n",
      "[ ecpho : 8  iter :575 ]train loss : 0.268042 ,train acc: 0.872711 ,val loss : 0.379604 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :576 ]train loss : 0.248136 ,train acc: 0.886149 ,val loss : 0.383329 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :577 ]train loss : 0.310729 ,train acc: 0.846853 ,val loss : 0.378360 ,val acc : 0.830719\n",
      "[ ecpho : 8  iter :578 ]train loss : 0.404517 ,train acc: 0.835358 ,val loss : 0.379972 ,val acc : 0.826294\n",
      "[ ecpho : 8  iter :579 ]train loss : 0.306806 ,train acc: 0.869873 ,val loss : 0.381094 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :580 ]train loss : 0.309407 ,train acc: 0.840953 ,val loss : 0.380445 ,val acc : 0.828552\n",
      "[ ecpho : 8  iter :581 ]train loss : 0.290172 ,train acc: 0.845775 ,val loss : 0.379879 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :582 ]train loss : 0.227374 ,train acc: 0.888947 ,val loss : 0.384319 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :583 ]train loss : 0.288718 ,train acc: 0.866476 ,val loss : 0.375790 ,val acc : 0.830048\n",
      "[ ecpho : 8  iter :584 ]train loss : 0.268803 ,train acc: 0.872508 ,val loss : 0.381200 ,val acc : 0.828430\n",
      "[ ecpho : 8  iter :585 ]train loss : 0.289595 ,train acc: 0.869385 ,val loss : 0.377571 ,val acc : 0.828918\n",
      "[ ecpho : 8  iter :586 ]train loss : 0.241600 ,train acc: 0.883820 ,val loss : 0.381866 ,val acc : 0.826447\n",
      "[ ecpho : 8  iter :587 ]train loss : 0.338059 ,train acc: 0.847829 ,val loss : 0.379566 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :588 ]train loss : 0.257421 ,train acc: 0.876058 ,val loss : 0.380714 ,val acc : 0.830994\n",
      "[ ecpho : 8  iter :589 ]train loss : 0.250602 ,train acc: 0.879150 ,val loss : 0.377261 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :590 ]train loss : 0.393479 ,train acc: 0.835734 ,val loss : 0.384253 ,val acc : 0.826965\n",
      "[ ecpho : 8  iter :591 ]train loss : 0.281921 ,train acc: 0.871623 ,val loss : 0.376354 ,val acc : 0.830139\n",
      "[ ecpho : 8  iter :592 ]train loss : 0.382262 ,train acc: 0.803792 ,val loss : 0.379009 ,val acc : 0.830475\n",
      "[ ecpho : 8  iter :593 ]train loss : 0.371394 ,train acc: 0.816773 ,val loss : 0.375024 ,val acc : 0.828369\n",
      "[ ecpho : 8  iter :594 ]train loss : 0.312225 ,train acc: 0.865397 ,val loss : 0.381931 ,val acc : 0.823700\n",
      "[ ecpho : 8  iter :595 ]train loss : 0.288919 ,train acc: 0.854024 ,val loss : 0.384100 ,val acc : 0.829315\n",
      "[ ecpho : 8  iter :596 ]train loss : 0.231325 ,train acc: 0.888062 ,val loss : 0.379153 ,val acc : 0.830383\n",
      "[ ecpho : 8  iter :597 ]train loss : 0.313253 ,train acc: 0.814606 ,val loss : 0.384711 ,val acc : 0.825439\n",
      "[ ecpho : 8  iter :598 ]train loss : 0.296532 ,train acc: 0.863251 ,val loss : 0.382415 ,val acc : 0.827148\n",
      "[ ecpho : 8  iter :599 ]train loss : 0.364517 ,train acc: 0.815501 ,val loss : 0.376689 ,val acc : 0.829620\n",
      "[ ecpho : 8  iter :600 ]train loss : 0.313516 ,train acc: 0.867055 ,val loss : 0.383187 ,val acc : 0.825745\n",
      "[ ecpho : 8  iter :601 ]train loss : 0.377795 ,train acc: 0.778605 ,val loss : 0.376528 ,val acc : 0.828857\n",
      "[ ecpho : 8  iter :602 ]train loss : 0.246254 ,train acc: 0.881968 ,val loss : 0.380097 ,val acc : 0.824921\n",
      "[ ecpho : 8  iter :603 ]train loss : 0.346072 ,train acc: 0.857076 ,val loss : 0.380342 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :604 ]train loss : 0.423421 ,train acc: 0.797730 ,val loss : 0.383012 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :605 ]train loss : 0.261029 ,train acc: 0.876495 ,val loss : 0.374480 ,val acc : 0.831024\n",
      "[ ecpho : 8  iter :606 ]train loss : 0.303383 ,train acc: 0.853984 ,val loss : 0.383020 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :607 ]train loss : 0.234047 ,train acc: 0.886119 ,val loss : 0.374298 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :608 ]train loss : 0.238471 ,train acc: 0.889099 ,val loss : 0.374571 ,val acc : 0.830292\n",
      "[ ecpho : 8  iter :609 ]train loss : 0.367723 ,train acc: 0.818899 ,val loss : 0.376894 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :610 ]train loss : 0.282244 ,train acc: 0.870972 ,val loss : 0.379283 ,val acc : 0.829559\n",
      "[ ecpho : 8  iter :611 ]train loss : 0.274704 ,train acc: 0.869863 ,val loss : 0.383881 ,val acc : 0.831085\n",
      "[ ecpho : 8  iter :612 ]train loss : 0.290730 ,train acc: 0.870433 ,val loss : 0.378447 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :613 ]train loss : 0.300089 ,train acc: 0.867483 ,val loss : 0.379455 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :614 ]train loss : 0.273068 ,train acc: 0.865174 ,val loss : 0.384007 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :615 ]train loss : 0.435792 ,train acc: 0.815959 ,val loss : 0.380869 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :616 ]train loss : 0.245644 ,train acc: 0.881521 ,val loss : 0.379742 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :617 ]train loss : 0.285521 ,train acc: 0.873362 ,val loss : 0.379063 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :618 ]train loss : 0.268825 ,train acc: 0.870331 ,val loss : 0.384876 ,val acc : 0.825958\n",
      "[ ecpho : 8  iter :619 ]train loss : 0.333924 ,train acc: 0.841238 ,val loss : 0.379530 ,val acc : 0.830963\n",
      "[ ecpho : 8  iter :620 ]train loss : 0.302927 ,train acc: 0.861969 ,val loss : 0.384456 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :621 ]train loss : 0.470817 ,train acc: 0.779897 ,val loss : 0.375895 ,val acc : 0.830658\n",
      "[ ecpho : 8  iter :622 ]train loss : 0.317104 ,train acc: 0.862824 ,val loss : 0.381048 ,val acc : 0.829742\n",
      "[ ecpho : 8  iter :623 ]train loss : 0.301013 ,train acc: 0.860535 ,val loss : 0.381509 ,val acc : 0.829620\n",
      "[ ecpho : 8  iter :624 ]train loss : 0.273688 ,train acc: 0.868652 ,val loss : 0.376378 ,val acc : 0.831238\n",
      "[ ecpho : 8  iter :625 ]train loss : 0.258244 ,train acc: 0.873678 ,val loss : 0.382577 ,val acc : 0.828430\n",
      "[ ecpho : 8  iter :626 ]train loss : 0.287091 ,train acc: 0.866445 ,val loss : 0.379766 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :627 ]train loss : 0.269510 ,train acc: 0.875560 ,val loss : 0.379743 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :628 ]train loss : 0.373022 ,train acc: 0.839417 ,val loss : 0.386541 ,val acc : 0.826935\n",
      "[ ecpho : 8  iter :629 ]train loss : 0.443124 ,train acc: 0.834208 ,val loss : 0.382517 ,val acc : 0.825806\n",
      "[ ecpho : 8  iter :630 ]train loss : 0.258964 ,train acc: 0.872609 ,val loss : 0.386317 ,val acc : 0.826660\n",
      "[ ecpho : 8  iter :631 ]train loss : 0.354852 ,train acc: 0.848053 ,val loss : 0.380718 ,val acc : 0.827362\n",
      "[ ecpho : 8  iter :632 ]train loss : 0.395211 ,train acc: 0.805237 ,val loss : 0.381880 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :633 ]train loss : 0.302388 ,train acc: 0.858429 ,val loss : 0.379868 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :634 ]train loss : 0.317868 ,train acc: 0.858460 ,val loss : 0.384509 ,val acc : 0.830750\n",
      "[ ecpho : 8  iter :635 ]train loss : 0.314515 ,train acc: 0.849782 ,val loss : 0.380327 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :636 ]train loss : 0.277155 ,train acc: 0.868144 ,val loss : 0.374260 ,val acc : 0.831024\n",
      "[ ecpho : 8  iter :637 ]train loss : 0.327020 ,train acc: 0.843811 ,val loss : 0.387077 ,val acc : 0.827759\n",
      "[ ecpho : 8  iter :638 ]train loss : 0.334036 ,train acc: 0.847992 ,val loss : 0.371942 ,val acc : 0.829681\n",
      "[ ecpho : 8  iter :639 ]train loss : 0.240637 ,train acc: 0.885295 ,val loss : 0.378906 ,val acc : 0.826782\n",
      "[ ecpho : 8  iter :640 ]train loss : 0.267888 ,train acc: 0.870422 ,val loss : 0.387709 ,val acc : 0.826996\n",
      "[ ecpho : 8  iter :641 ]train loss : 0.264265 ,train acc: 0.879405 ,val loss : 0.382758 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :642 ]train loss : 0.263453 ,train acc: 0.874898 ,val loss : 0.383773 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :643 ]train loss : 0.258432 ,train acc: 0.880595 ,val loss : 0.386379 ,val acc : 0.825195\n",
      "[ ecpho : 8  iter :644 ]train loss : 0.332610 ,train acc: 0.850698 ,val loss : 0.379997 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :645 ]train loss : 0.268094 ,train acc: 0.866852 ,val loss : 0.380691 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :646 ]train loss : 0.273858 ,train acc: 0.867279 ,val loss : 0.384603 ,val acc : 0.825134\n",
      "[ ecpho : 8  iter :647 ]train loss : 0.284786 ,train acc: 0.864766 ,val loss : 0.384791 ,val acc : 0.826874\n",
      "[ ecpho : 8  iter :648 ]train loss : 0.345733 ,train acc: 0.821757 ,val loss : 0.379661 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :649 ]train loss : 0.272724 ,train acc: 0.873017 ,val loss : 0.372057 ,val acc : 0.830597\n",
      "[ ecpho : 8  iter :650 ]train loss : 0.247546 ,train acc: 0.883596 ,val loss : 0.377003 ,val acc : 0.825806\n",
      "[ ecpho : 8  iter :651 ]train loss : 0.603984 ,train acc: 0.747488 ,val loss : 0.375661 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :652 ]train loss : 0.287168 ,train acc: 0.867849 ,val loss : 0.374698 ,val acc : 0.831482\n",
      "[ ecpho : 8  iter :653 ]train loss : 0.256110 ,train acc: 0.879618 ,val loss : 0.379126 ,val acc : 0.827362\n",
      "[ ecpho : 8  iter :654 ]train loss : 0.248054 ,train acc: 0.879903 ,val loss : 0.375344 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :655 ]train loss : 0.344063 ,train acc: 0.849426 ,val loss : 0.378883 ,val acc : 0.827209\n",
      "[ ecpho : 8  iter :656 ]train loss : 0.350459 ,train acc: 0.833201 ,val loss : 0.378907 ,val acc : 0.829681\n",
      "[ ecpho : 8  iter :657 ]train loss : 0.303034 ,train acc: 0.864472 ,val loss : 0.378452 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :658 ]train loss : 0.317996 ,train acc: 0.852977 ,val loss : 0.376468 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :659 ]train loss : 0.360127 ,train acc: 0.848094 ,val loss : 0.377421 ,val acc : 0.830658\n",
      "[ ecpho : 8  iter :660 ]train loss : 0.338071 ,train acc: 0.819987 ,val loss : 0.375577 ,val acc : 0.825867\n",
      "[ ecpho : 8  iter :661 ]train loss : 0.254595 ,train acc: 0.875916 ,val loss : 0.377719 ,val acc : 0.826477\n",
      "[ ecpho : 8  iter :662 ]train loss : 0.506475 ,train acc: 0.827912 ,val loss : 0.373503 ,val acc : 0.831726\n",
      "[ ecpho : 8  iter :663 ]train loss : 0.260655 ,train acc: 0.875163 ,val loss : 0.380854 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :664 ]train loss : 0.388819 ,train acc: 0.820028 ,val loss : 0.379786 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :665 ]train loss : 0.444854 ,train acc: 0.827891 ,val loss : 0.373423 ,val acc : 0.829498\n",
      "[ ecpho : 8  iter :666 ]train loss : 0.256504 ,train acc: 0.878123 ,val loss : 0.378560 ,val acc : 0.830658\n",
      "[ ecpho : 8  iter :667 ]train loss : 0.232251 ,train acc: 0.888906 ,val loss : 0.380428 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :668 ]train loss : 0.366562 ,train acc: 0.812938 ,val loss : 0.383682 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :669 ]train loss : 0.263623 ,train acc: 0.874003 ,val loss : 0.373179 ,val acc : 0.830902\n",
      "[ ecpho : 8  iter :670 ]train loss : 0.335169 ,train acc: 0.857015 ,val loss : 0.378826 ,val acc : 0.827942\n",
      "[ ecpho : 8  iter :671 ]train loss : 0.281701 ,train acc: 0.858866 ,val loss : 0.378828 ,val acc : 0.826172\n",
      "[ ecpho : 8  iter :672 ]train loss : 0.266855 ,train acc: 0.880320 ,val loss : 0.379607 ,val acc : 0.829163\n",
      "[ ecpho : 8  iter :673 ]train loss : 0.248220 ,train acc: 0.878632 ,val loss : 0.373232 ,val acc : 0.830688\n",
      "[ ecpho : 8  iter :674 ]train loss : 0.324034 ,train acc: 0.829061 ,val loss : 0.380092 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :675 ]train loss : 0.270863 ,train acc: 0.874736 ,val loss : 0.379021 ,val acc : 0.829041\n",
      "[ ecpho : 8  iter :676 ]train loss : 0.248669 ,train acc: 0.880269 ,val loss : 0.379530 ,val acc : 0.830200\n",
      "[ ecpho : 8  iter :677 ]train loss : 0.354489 ,train acc: 0.827494 ,val loss : 0.380863 ,val acc : 0.824768\n",
      "[ ecpho : 8  iter :678 ]train loss : 0.308897 ,train acc: 0.858856 ,val loss : 0.380689 ,val acc : 0.826538\n",
      "[ ecpho : 8  iter :679 ]train loss : 0.250681 ,train acc: 0.876414 ,val loss : 0.379732 ,val acc : 0.828674\n",
      "[ ecpho : 8  iter :680 ]train loss : 0.235983 ,train acc: 0.888509 ,val loss : 0.378933 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :681 ]train loss : 0.352736 ,train acc: 0.841705 ,val loss : 0.374018 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :682 ]train loss : 0.257697 ,train acc: 0.880341 ,val loss : 0.375809 ,val acc : 0.826782\n",
      "[ ecpho : 8  iter :683 ]train loss : 0.319340 ,train acc: 0.855540 ,val loss : 0.375351 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :684 ]train loss : 0.249293 ,train acc: 0.882406 ,val loss : 0.380257 ,val acc : 0.827881\n",
      "[ ecpho : 8  iter :685 ]train loss : 0.235109 ,train acc: 0.886190 ,val loss : 0.378783 ,val acc : 0.827576\n",
      "[ ecpho : 8  iter :686 ]train loss : 0.259084 ,train acc: 0.874380 ,val loss : 0.377010 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :687 ]train loss : 0.255173 ,train acc: 0.878601 ,val loss : 0.376332 ,val acc : 0.830139\n",
      "[ ecpho : 8  iter :688 ]train loss : 0.280093 ,train acc: 0.870127 ,val loss : 0.379231 ,val acc : 0.827911\n",
      "[ ecpho : 8  iter :689 ]train loss : 0.274145 ,train acc: 0.875895 ,val loss : 0.388684 ,val acc : 0.825562\n",
      "[ ecpho : 8  iter :690 ]train loss : 0.237085 ,train acc: 0.884247 ,val loss : 0.380523 ,val acc : 0.828369\n",
      "[ ecpho : 8  iter :691 ]train loss : 0.317430 ,train acc: 0.848877 ,val loss : 0.379126 ,val acc : 0.829407\n",
      "[ ecpho : 8  iter :692 ]train loss : 0.256200 ,train acc: 0.877055 ,val loss : 0.384391 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :693 ]train loss : 0.378368 ,train acc: 0.812877 ,val loss : 0.377924 ,val acc : 0.826752\n",
      "[ ecpho : 8  iter :694 ]train loss : 0.282778 ,train acc: 0.866079 ,val loss : 0.384396 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :695 ]train loss : 0.345114 ,train acc: 0.855876 ,val loss : 0.385082 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :696 ]train loss : 0.239135 ,train acc: 0.883270 ,val loss : 0.380013 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :697 ]train loss : 0.263811 ,train acc: 0.873260 ,val loss : 0.383217 ,val acc : 0.828033\n",
      "[ ecpho : 8  iter :698 ]train loss : 0.273780 ,train acc: 0.875203 ,val loss : 0.383092 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :699 ]train loss : 0.291431 ,train acc: 0.861349 ,val loss : 0.376612 ,val acc : 0.830933\n",
      "[ ecpho : 8  iter :700 ]train loss : 0.261963 ,train acc: 0.881297 ,val loss : 0.374290 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :701 ]train loss : 0.317078 ,train acc: 0.857432 ,val loss : 0.379000 ,val acc : 0.830505\n",
      "[ ecpho : 8  iter :702 ]train loss : 0.244292 ,train acc: 0.884338 ,val loss : 0.376986 ,val acc : 0.830597\n",
      "[ ecpho : 8  iter :703 ]train loss : 0.306094 ,train acc: 0.846863 ,val loss : 0.375131 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :704 ]train loss : 0.273528 ,train acc: 0.872172 ,val loss : 0.379638 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :705 ]train loss : 0.306892 ,train acc: 0.859874 ,val loss : 0.381693 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :706 ]train loss : 0.245995 ,train acc: 0.881195 ,val loss : 0.383894 ,val acc : 0.823822\n",
      "[ ecpho : 8  iter :707 ]train loss : 0.258522 ,train acc: 0.878530 ,val loss : 0.383555 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :708 ]train loss : 0.306335 ,train acc: 0.841227 ,val loss : 0.376724 ,val acc : 0.830353\n",
      "[ ecpho : 8  iter :709 ]train loss : 0.332009 ,train acc: 0.841614 ,val loss : 0.382221 ,val acc : 0.827759\n",
      "[ ecpho : 8  iter :710 ]train loss : 0.308131 ,train acc: 0.863678 ,val loss : 0.381417 ,val acc : 0.826111\n",
      "[ ecpho : 8  iter :711 ]train loss : 0.326714 ,train acc: 0.832448 ,val loss : 0.376132 ,val acc : 0.830597\n",
      "[ ecpho : 8  iter :712 ]train loss : 0.301894 ,train acc: 0.858917 ,val loss : 0.386517 ,val acc : 0.826538\n",
      "[ ecpho : 8  iter :713 ]train loss : 0.383059 ,train acc: 0.743490 ,val loss : 0.376398 ,val acc : 0.830811\n",
      "[ ecpho : 8  iter :714 ]train loss : 0.235095 ,train acc: 0.887878 ,val loss : 0.379387 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :715 ]train loss : 0.534950 ,train acc: 0.807037 ,val loss : 0.382442 ,val acc : 0.829071\n",
      "[ ecpho : 8  iter :716 ]train loss : 0.280442 ,train acc: 0.876414 ,val loss : 0.382760 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :717 ]train loss : 0.288638 ,train acc: 0.869985 ,val loss : 0.384111 ,val acc : 0.827515\n",
      "[ ecpho : 8  iter :718 ]train loss : 0.354912 ,train acc: 0.836568 ,val loss : 0.378716 ,val acc : 0.827789\n",
      "[ ecpho : 8  iter :719 ]train loss : 0.260363 ,train acc: 0.875478 ,val loss : 0.387361 ,val acc : 0.825958\n",
      "[ ecpho : 8  iter :720 ]train loss : 0.295412 ,train acc: 0.866943 ,val loss : 0.376444 ,val acc : 0.828857\n",
      "[ ecpho : 8  iter :721 ]train loss : 0.275069 ,train acc: 0.867005 ,val loss : 0.380517 ,val acc : 0.831055\n",
      "[ ecpho : 8  iter :722 ]train loss : 0.315697 ,train acc: 0.843974 ,val loss : 0.379342 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :723 ]train loss : 0.283064 ,train acc: 0.859141 ,val loss : 0.385549 ,val acc : 0.823975\n",
      "[ ecpho : 8  iter :724 ]train loss : 0.332119 ,train acc: 0.853078 ,val loss : 0.377159 ,val acc : 0.828583\n",
      "[ ecpho : 8  iter :725 ]train loss : 0.306462 ,train acc: 0.867696 ,val loss : 0.381011 ,val acc : 0.828430\n",
      "[ ecpho : 8  iter :726 ]train loss : 0.357118 ,train acc: 0.819702 ,val loss : 0.378554 ,val acc : 0.826111\n",
      "[ ecpho : 8  iter :727 ]train loss : 0.412469 ,train acc: 0.843211 ,val loss : 0.382111 ,val acc : 0.830414\n",
      "[ ecpho : 8  iter :728 ]train loss : 0.337712 ,train acc: 0.852265 ,val loss : 0.384667 ,val acc : 0.831696\n",
      "[ ecpho : 8  iter :729 ]train loss : 0.236466 ,train acc: 0.883616 ,val loss : 0.378910 ,val acc : 0.826721\n",
      "[ ecpho : 8  iter :730 ]train loss : 0.342820 ,train acc: 0.850871 ,val loss : 0.381233 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :731 ]train loss : 0.362621 ,train acc: 0.828003 ,val loss : 0.378825 ,val acc : 0.831879\n",
      "[ ecpho : 8  iter :732 ]train loss : 0.282489 ,train acc: 0.873393 ,val loss : 0.377672 ,val acc : 0.827759\n",
      "[ ecpho : 8  iter :733 ]train loss : 0.341497 ,train acc: 0.831075 ,val loss : 0.374739 ,val acc : 0.829712\n",
      "[ ecpho : 8  iter :734 ]train loss : 0.298101 ,train acc: 0.865051 ,val loss : 0.381138 ,val acc : 0.828979\n",
      "[ ecpho : 8  iter :735 ]train loss : 0.379386 ,train acc: 0.829448 ,val loss : 0.384377 ,val acc : 0.826141\n",
      "[ ecpho : 8  iter :736 ]train loss : 0.259024 ,train acc: 0.877299 ,val loss : 0.379049 ,val acc : 0.827911\n",
      "[ ecpho : 8  iter :737 ]train loss : 0.350064 ,train acc: 0.858948 ,val loss : 0.381442 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :738 ]train loss : 0.341501 ,train acc: 0.844737 ,val loss : 0.379020 ,val acc : 0.829651\n",
      "[ ecpho : 8  iter :739 ]train loss : 0.238620 ,train acc: 0.885132 ,val loss : 0.372777 ,val acc : 0.826050\n",
      "[ ecpho : 8  iter :740 ]train loss : 0.339612 ,train acc: 0.852061 ,val loss : 0.378847 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :741 ]train loss : 0.327419 ,train acc: 0.854736 ,val loss : 0.378762 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :742 ]train loss : 0.309311 ,train acc: 0.871318 ,val loss : 0.381374 ,val acc : 0.827209\n",
      "[ ecpho : 8  iter :743 ]train loss : 0.335480 ,train acc: 0.849040 ,val loss : 0.379542 ,val acc : 0.826202\n",
      "[ ecpho : 8  iter :744 ]train loss : 0.359476 ,train acc: 0.857717 ,val loss : 0.377425 ,val acc : 0.826904\n",
      "[ ecpho : 8  iter :745 ]train loss : 0.344865 ,train acc: 0.848989 ,val loss : 0.378920 ,val acc : 0.829254\n",
      "[ ecpho : 8  iter :746 ]train loss : 0.270375 ,train acc: 0.873301 ,val loss : 0.379033 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :747 ]train loss : 0.357296 ,train acc: 0.848195 ,val loss : 0.376553 ,val acc : 0.831787\n",
      "[ ecpho : 8  iter :748 ]train loss : 0.330701 ,train acc: 0.848918 ,val loss : 0.381659 ,val acc : 0.828400\n",
      "[ ecpho : 8  iter :749 ]train loss : 0.298256 ,train acc: 0.841716 ,val loss : 0.388158 ,val acc : 0.827087\n",
      "[ ecpho : 8  iter :750 ]train loss : 0.316690 ,train acc: 0.867401 ,val loss : 0.381641 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :751 ]train loss : 0.296866 ,train acc: 0.850169 ,val loss : 0.384522 ,val acc : 0.826172\n",
      "[ ecpho : 8  iter :752 ]train loss : 0.299405 ,train acc: 0.849925 ,val loss : 0.376437 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :753 ]train loss : 0.251965 ,train acc: 0.883504 ,val loss : 0.381853 ,val acc : 0.826202\n",
      "[ ecpho : 8  iter :754 ]train loss : 0.358135 ,train acc: 0.830333 ,val loss : 0.380306 ,val acc : 0.828705\n",
      "[ ecpho : 8  iter :755 ]train loss : 0.284422 ,train acc: 0.869995 ,val loss : 0.382500 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :756 ]train loss : 0.326461 ,train acc: 0.851186 ,val loss : 0.379640 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :757 ]train loss : 0.247887 ,train acc: 0.879598 ,val loss : 0.384537 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :758 ]train loss : 0.325573 ,train acc: 0.856923 ,val loss : 0.383074 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :759 ]train loss : 0.287253 ,train acc: 0.853658 ,val loss : 0.376964 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :760 ]train loss : 0.344334 ,train acc: 0.856588 ,val loss : 0.385423 ,val acc : 0.824249\n",
      "[ ecpho : 8  iter :761 ]train loss : 0.240198 ,train acc: 0.883311 ,val loss : 0.382428 ,val acc : 0.829132\n",
      "[ ecpho : 8  iter :762 ]train loss : 0.378987 ,train acc: 0.831208 ,val loss : 0.379609 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :763 ]train loss : 0.254048 ,train acc: 0.879273 ,val loss : 0.379392 ,val acc : 0.830505\n",
      "[ ecpho : 8  iter :764 ]train loss : 0.311177 ,train acc: 0.840627 ,val loss : 0.379887 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :765 ]train loss : 0.375228 ,train acc: 0.825297 ,val loss : 0.381943 ,val acc : 0.828949\n",
      "[ ecpho : 8  iter :766 ]train loss : 0.352148 ,train acc: 0.844422 ,val loss : 0.382868 ,val acc : 0.831146\n",
      "[ ecpho : 8  iter :767 ]train loss : 0.276079 ,train acc: 0.854981 ,val loss : 0.381922 ,val acc : 0.826813\n",
      "[ ecpho : 8  iter :768 ]train loss : 0.295244 ,train acc: 0.867920 ,val loss : 0.374485 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :769 ]train loss : 0.262750 ,train acc: 0.874420 ,val loss : 0.379330 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :770 ]train loss : 0.472705 ,train acc: 0.841400 ,val loss : 0.377620 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :771 ]train loss : 0.247038 ,train acc: 0.880717 ,val loss : 0.376484 ,val acc : 0.829529\n",
      "[ ecpho : 8  iter :772 ]train loss : 0.240644 ,train acc: 0.884735 ,val loss : 0.378999 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :773 ]train loss : 0.348554 ,train acc: 0.820191 ,val loss : 0.378019 ,val acc : 0.827423\n",
      "[ ecpho : 8  iter :774 ]train loss : 0.379432 ,train acc: 0.847646 ,val loss : 0.388499 ,val acc : 0.828522\n",
      "[ ecpho : 8  iter :775 ]train loss : 0.386716 ,train acc: 0.841594 ,val loss : 0.381665 ,val acc : 0.829224\n",
      "[ ecpho : 8  iter :776 ]train loss : 0.490980 ,train acc: 0.772502 ,val loss : 0.377715 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :777 ]train loss : 0.348540 ,train acc: 0.853912 ,val loss : 0.381219 ,val acc : 0.826202\n",
      "[ ecpho : 8  iter :778 ]train loss : 0.389600 ,train acc: 0.841939 ,val loss : 0.383810 ,val acc : 0.827179\n",
      "[ ecpho : 8  iter :779 ]train loss : 0.435413 ,train acc: 0.842000 ,val loss : 0.384492 ,val acc : 0.827423\n",
      "[ ecpho : 8  iter :780 ]train loss : 0.288992 ,train acc: 0.859426 ,val loss : 0.380987 ,val acc : 0.828583\n",
      "[ ecpho : 8  iter :781 ]train loss : 0.271029 ,train acc: 0.869436 ,val loss : 0.380040 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :782 ]train loss : 0.284529 ,train acc: 0.864451 ,val loss : 0.385035 ,val acc : 0.827393\n",
      "[ ecpho : 8  iter :783 ]train loss : 0.304137 ,train acc: 0.837006 ,val loss : 0.378684 ,val acc : 0.828217\n",
      "[ ecpho : 8  iter :784 ]train loss : 0.263406 ,train acc: 0.880870 ,val loss : 0.377629 ,val acc : 0.829529\n",
      "[ ecpho : 8  iter :785 ]train loss : 0.348867 ,train acc: 0.845408 ,val loss : 0.386277 ,val acc : 0.823944\n",
      "[ ecpho : 8  iter :786 ]train loss : 0.253069 ,train acc: 0.880219 ,val loss : 0.377364 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :787 ]train loss : 0.311742 ,train acc: 0.832052 ,val loss : 0.377374 ,val acc : 0.829773\n",
      "[ ecpho : 8  iter :788 ]train loss : 0.366915 ,train acc: 0.822540 ,val loss : 0.379089 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :789 ]train loss : 0.269570 ,train acc: 0.877991 ,val loss : 0.377641 ,val acc : 0.831512\n",
      "[ ecpho : 8  iter :790 ]train loss : 0.336002 ,train acc: 0.841146 ,val loss : 0.378304 ,val acc : 0.827667\n",
      "[ ecpho : 8  iter :791 ]train loss : 0.253630 ,train acc: 0.878906 ,val loss : 0.379558 ,val acc : 0.830200\n",
      "[ ecpho : 8  iter :792 ]train loss : 0.229816 ,train acc: 0.890249 ,val loss : 0.380220 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :793 ]train loss : 0.322145 ,train acc: 0.830994 ,val loss : 0.378144 ,val acc : 0.826019\n",
      "[ ecpho : 8  iter :794 ]train loss : 0.275630 ,train acc: 0.871867 ,val loss : 0.380382 ,val acc : 0.823914\n",
      "[ ecpho : 8  iter :795 ]train loss : 0.274227 ,train acc: 0.868825 ,val loss : 0.376709 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :796 ]train loss : 0.319991 ,train acc: 0.861359 ,val loss : 0.381119 ,val acc : 0.825958\n",
      "[ ecpho : 8  iter :797 ]train loss : 0.273261 ,train acc: 0.870483 ,val loss : 0.378846 ,val acc : 0.826782\n",
      "[ ecpho : 8  iter :798 ]train loss : 0.346154 ,train acc: 0.834401 ,val loss : 0.380483 ,val acc : 0.830261\n",
      "[ ecpho : 8  iter :799 ]train loss : 0.252769 ,train acc: 0.878876 ,val loss : 0.379241 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :800 ]train loss : 0.258952 ,train acc: 0.878072 ,val loss : 0.377558 ,val acc : 0.829712\n",
      "[ ecpho : 8  iter :801 ]train loss : 0.387749 ,train acc: 0.703145 ,val loss : 0.385325 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :802 ]train loss : 0.330767 ,train acc: 0.853587 ,val loss : 0.382482 ,val acc : 0.826965\n",
      "[ ecpho : 8  iter :803 ]train loss : 0.310941 ,train acc: 0.843455 ,val loss : 0.379246 ,val acc : 0.828918\n",
      "[ ecpho : 8  iter :804 ]train loss : 0.465493 ,train acc: 0.826315 ,val loss : 0.382046 ,val acc : 0.826355\n",
      "[ ecpho : 8  iter :805 ]train loss : 0.367541 ,train acc: 0.807444 ,val loss : 0.375768 ,val acc : 0.828613\n",
      "[ ecpho : 8  iter :806 ]train loss : 0.327173 ,train acc: 0.845652 ,val loss : 0.383435 ,val acc : 0.828094\n",
      "[ ecpho : 8  iter :807 ]train loss : 0.306344 ,train acc: 0.845785 ,val loss : 0.382064 ,val acc : 0.826660\n",
      "[ ecpho : 8  iter :808 ]train loss : 0.249350 ,train acc: 0.881053 ,val loss : 0.373879 ,val acc : 0.832153\n",
      "[ ecpho : 8  iter :809 ]train loss : 0.319819 ,train acc: 0.856649 ,val loss : 0.376410 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :810 ]train loss : 0.256432 ,train acc: 0.882426 ,val loss : 0.380269 ,val acc : 0.831940\n",
      "[ ecpho : 8  iter :811 ]train loss : 0.247028 ,train acc: 0.882904 ,val loss : 0.381437 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :812 ]train loss : 0.357062 ,train acc: 0.827149 ,val loss : 0.380858 ,val acc : 0.828156\n",
      "[ ecpho : 8  iter :813 ]train loss : 0.316585 ,train acc: 0.857005 ,val loss : 0.379865 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :814 ]train loss : 0.336363 ,train acc: 0.828532 ,val loss : 0.375138 ,val acc : 0.831390\n",
      "[ ecpho : 8  iter :815 ]train loss : 0.488257 ,train acc: 0.828359 ,val loss : 0.380597 ,val acc : 0.825958\n",
      "[ ecpho : 8  iter :816 ]train loss : 0.376267 ,train acc: 0.822113 ,val loss : 0.381082 ,val acc : 0.825989\n",
      "[ ecpho : 8  iter :817 ]train loss : 0.311100 ,train acc: 0.839895 ,val loss : 0.378252 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :818 ]train loss : 0.247006 ,train acc: 0.880127 ,val loss : 0.378859 ,val acc : 0.831055\n",
      "[ ecpho : 8  iter :819 ]train loss : 0.263405 ,train acc: 0.873545 ,val loss : 0.378462 ,val acc : 0.826172\n",
      "[ ecpho : 8  iter :820 ]train loss : 0.256199 ,train acc: 0.879832 ,val loss : 0.381167 ,val acc : 0.825378\n",
      "[ ecpho : 8  iter :821 ]train loss : 0.347480 ,train acc: 0.839824 ,val loss : 0.375963 ,val acc : 0.830109\n",
      "[ ecpho : 8  iter :822 ]train loss : 0.359278 ,train acc: 0.836782 ,val loss : 0.381060 ,val acc : 0.828033\n",
      "[ ecpho : 8  iter :823 ]train loss : 0.342520 ,train acc: 0.821930 ,val loss : 0.383545 ,val acc : 0.825226\n",
      "[ ecpho : 8  iter :824 ]train loss : 0.301386 ,train acc: 0.865499 ,val loss : 0.381412 ,val acc : 0.824768\n",
      "[ ecpho : 8  iter :825 ]train loss : 0.304539 ,train acc: 0.856801 ,val loss : 0.381270 ,val acc : 0.827087\n",
      "[ ecpho : 8  iter :826 ]train loss : 0.304976 ,train acc: 0.859039 ,val loss : 0.380084 ,val acc : 0.830841\n",
      "[ ecpho : 8  iter :827 ]train loss : 0.351446 ,train acc: 0.847595 ,val loss : 0.383107 ,val acc : 0.827240\n",
      "[ ecpho : 8  iter :828 ]train loss : 0.241212 ,train acc: 0.882080 ,val loss : 0.377925 ,val acc : 0.829712\n",
      "[ ecpho : 8  iter :829 ]train loss : 0.315798 ,train acc: 0.846324 ,val loss : 0.381233 ,val acc : 0.829651\n",
      "[ ecpho : 8  iter :830 ]train loss : 0.276165 ,train acc: 0.870799 ,val loss : 0.383728 ,val acc : 0.824799\n",
      "[ ecpho : 8  iter :831 ]train loss : 0.348173 ,train acc: 0.820282 ,val loss : 0.382663 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :832 ]train loss : 0.265004 ,train acc: 0.876546 ,val loss : 0.382535 ,val acc : 0.826630\n",
      "[ ecpho : 8  iter :833 ]train loss : 0.274864 ,train acc: 0.870697 ,val loss : 0.383823 ,val acc : 0.827698\n",
      "[ ecpho : 8  iter :834 ]train loss : 0.273486 ,train acc: 0.870127 ,val loss : 0.379140 ,val acc : 0.832001\n",
      "[ ecpho : 8  iter :835 ]train loss : 0.269581 ,train acc: 0.877991 ,val loss : 0.384125 ,val acc : 0.824097\n",
      "[ ecpho : 8  iter :836 ]train loss : 0.258108 ,train acc: 0.878001 ,val loss : 0.379030 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :837 ]train loss : 0.236382 ,train acc: 0.885447 ,val loss : 0.372458 ,val acc : 0.833527\n",
      "[ ecpho : 8  iter :838 ]train loss : 0.334324 ,train acc: 0.847778 ,val loss : 0.376373 ,val acc : 0.828125\n",
      "[ ecpho : 8  iter :839 ]train loss : 0.315970 ,train acc: 0.861654 ,val loss : 0.380299 ,val acc : 0.826782\n",
      "[ ecpho : 8  iter :840 ]train loss : 0.294026 ,train acc: 0.870667 ,val loss : 0.380643 ,val acc : 0.828369\n",
      "[ ecpho : 8  iter :841 ]train loss : 0.299540 ,train acc: 0.856486 ,val loss : 0.370625 ,val acc : 0.831757\n",
      "[ ecpho : 8  iter :842 ]train loss : 0.544049 ,train acc: 0.670431 ,val loss : 0.380990 ,val acc : 0.828278\n",
      "[ ecpho : 8  iter :843 ]train loss : 0.281392 ,train acc: 0.870656 ,val loss : 0.377347 ,val acc : 0.825897\n",
      "[ ecpho : 8  iter :844 ]train loss : 0.282684 ,train acc: 0.860962 ,val loss : 0.382688 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :845 ]train loss : 0.254484 ,train acc: 0.884643 ,val loss : 0.375721 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :846 ]train loss : 0.309319 ,train acc: 0.861084 ,val loss : 0.376681 ,val acc : 0.828644\n",
      "[ ecpho : 8  iter :847 ]train loss : 0.279101 ,train acc: 0.871664 ,val loss : 0.377038 ,val acc : 0.831146\n",
      "[ ecpho : 8  iter :848 ]train loss : 0.263025 ,train acc: 0.876678 ,val loss : 0.380525 ,val acc : 0.826080\n",
      "[ ecpho : 8  iter :849 ]train loss : 0.308721 ,train acc: 0.854920 ,val loss : 0.383151 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :850 ]train loss : 0.303696 ,train acc: 0.863719 ,val loss : 0.378077 ,val acc : 0.827118\n",
      "[ ecpho : 8  iter :851 ]train loss : 0.282199 ,train acc: 0.870199 ,val loss : 0.387636 ,val acc : 0.825073\n",
      "[ ecpho : 8  iter :852 ]train loss : 0.339595 ,train acc: 0.854289 ,val loss : 0.373093 ,val acc : 0.830719\n",
      "[ ecpho : 8  iter :853 ]train loss : 0.277478 ,train acc: 0.868276 ,val loss : 0.384422 ,val acc : 0.824097\n",
      "[ ecpho : 8  iter :854 ]train loss : 0.237073 ,train acc: 0.885590 ,val loss : 0.381834 ,val acc : 0.827972\n",
      "[ ecpho : 8  iter :855 ]train loss : 0.352574 ,train acc: 0.831004 ,val loss : 0.379560 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :856 ]train loss : 0.282814 ,train acc: 0.873362 ,val loss : 0.380013 ,val acc : 0.826508\n",
      "[ ecpho : 8  iter :857 ]train loss : 0.247121 ,train acc: 0.879110 ,val loss : 0.382570 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :858 ]train loss : 0.335786 ,train acc: 0.869171 ,val loss : 0.374514 ,val acc : 0.831329\n",
      "[ ecpho : 8  iter :859 ]train loss : 0.247157 ,train acc: 0.878021 ,val loss : 0.376444 ,val acc : 0.828979\n",
      "[ ecpho : 8  iter :860 ]train loss : 0.278014 ,train acc: 0.865682 ,val loss : 0.372096 ,val acc : 0.832794\n",
      "[ ecpho : 8  iter :861 ]train loss : 0.297307 ,train acc: 0.862569 ,val loss : 0.383016 ,val acc : 0.825623\n",
      "[ ecpho : 8  iter :862 ]train loss : 0.267862 ,train acc: 0.870219 ,val loss : 0.382367 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :863 ]train loss : 0.282998 ,train acc: 0.868907 ,val loss : 0.382245 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :864 ]train loss : 0.447589 ,train acc: 0.846537 ,val loss : 0.377551 ,val acc : 0.829773\n",
      "[ ecpho : 8  iter :865 ]train loss : 0.260712 ,train acc: 0.875041 ,val loss : 0.378603 ,val acc : 0.827911\n",
      "[ ecpho : 8  iter :866 ]train loss : 0.420312 ,train acc: 0.835571 ,val loss : 0.380070 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :867 ]train loss : 0.249749 ,train acc: 0.884206 ,val loss : 0.380243 ,val acc : 0.826996\n",
      "[ ecpho : 8  iter :868 ]train loss : 0.275865 ,train acc: 0.871460 ,val loss : 0.375925 ,val acc : 0.830048\n",
      "[ ecpho : 8  iter :869 ]train loss : 0.257965 ,train acc: 0.877604 ,val loss : 0.377692 ,val acc : 0.830444\n",
      "[ ecpho : 8  iter :870 ]train loss : 0.284728 ,train acc: 0.869263 ,val loss : 0.383217 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :871 ]train loss : 0.315759 ,train acc: 0.865652 ,val loss : 0.379138 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :872 ]train loss : 0.306792 ,train acc: 0.835073 ,val loss : 0.381622 ,val acc : 0.823944\n",
      "[ ecpho : 8  iter :873 ]train loss : 0.288793 ,train acc: 0.868327 ,val loss : 0.384669 ,val acc : 0.829742\n",
      "[ ecpho : 8  iter :874 ]train loss : 0.257773 ,train acc: 0.876811 ,val loss : 0.378823 ,val acc : 0.829987\n",
      "[ ecpho : 8  iter :875 ]train loss : 0.281197 ,train acc: 0.853099 ,val loss : 0.379608 ,val acc : 0.826874\n",
      "[ ecpho : 8  iter :876 ]train loss : 0.245507 ,train acc: 0.882528 ,val loss : 0.376563 ,val acc : 0.827637\n",
      "[ ecpho : 8  iter :877 ]train loss : 0.303775 ,train acc: 0.851318 ,val loss : 0.382462 ,val acc : 0.827759\n",
      "[ ecpho : 8  iter :878 ]train loss : 0.239955 ,train acc: 0.882772 ,val loss : 0.388205 ,val acc : 0.823608\n",
      "[ ecpho : 8  iter :879 ]train loss : 0.238537 ,train acc: 0.884918 ,val loss : 0.376997 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :880 ]train loss : 0.375599 ,train acc: 0.841909 ,val loss : 0.378242 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :881 ]train loss : 0.314339 ,train acc: 0.839498 ,val loss : 0.379183 ,val acc : 0.831299\n",
      "[ ecpho : 8  iter :882 ]train loss : 0.350203 ,train acc: 0.860433 ,val loss : 0.380440 ,val acc : 0.830292\n",
      "[ ecpho : 8  iter :883 ]train loss : 0.272854 ,train acc: 0.867930 ,val loss : 0.384985 ,val acc : 0.826599\n",
      "[ ecpho : 8  iter :884 ]train loss : 0.311451 ,train acc: 0.857422 ,val loss : 0.379524 ,val acc : 0.827393\n",
      "[ ecpho : 8  iter :885 ]train loss : 0.361244 ,train acc: 0.845876 ,val loss : 0.383834 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :886 ]train loss : 0.298445 ,train acc: 0.864380 ,val loss : 0.377222 ,val acc : 0.827515\n",
      "[ ecpho : 8  iter :887 ]train loss : 0.295107 ,train acc: 0.864024 ,val loss : 0.381478 ,val acc : 0.828888\n",
      "[ ecpho : 8  iter :888 ]train loss : 0.321191 ,train acc: 0.856568 ,val loss : 0.379424 ,val acc : 0.825775\n",
      "[ ecpho : 8  iter :889 ]train loss : 0.248720 ,train acc: 0.884593 ,val loss : 0.377682 ,val acc : 0.828094\n",
      "[ ecpho : 8  iter :890 ]train loss : 0.334306 ,train acc: 0.832408 ,val loss : 0.385668 ,val acc : 0.825745\n",
      "[ ecpho : 8  iter :891 ]train loss : 0.265388 ,train acc: 0.875356 ,val loss : 0.381157 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :892 ]train loss : 0.288368 ,train acc: 0.867432 ,val loss : 0.378726 ,val acc : 0.830627\n",
      "[ ecpho : 8  iter :893 ]train loss : 0.403420 ,train acc: 0.851980 ,val loss : 0.385056 ,val acc : 0.826416\n",
      "[ ecpho : 8  iter :894 ]train loss : 0.309765 ,train acc: 0.865356 ,val loss : 0.385099 ,val acc : 0.827606\n",
      "[ ecpho : 8  iter :895 ]train loss : 0.250212 ,train acc: 0.878611 ,val loss : 0.385460 ,val acc : 0.829620\n",
      "[ ecpho : 8  iter :896 ]train loss : 0.294751 ,train acc: 0.866506 ,val loss : 0.375024 ,val acc : 0.831970\n",
      "[ ecpho : 8  iter :897 ]train loss : 0.342446 ,train acc: 0.823548 ,val loss : 0.380198 ,val acc : 0.826691\n",
      "[ ecpho : 8  iter :898 ]train loss : 0.280187 ,train acc: 0.875183 ,val loss : 0.382847 ,val acc : 0.829376\n",
      "[ ecpho : 8  iter :899 ]train loss : 0.291838 ,train acc: 0.863729 ,val loss : 0.383635 ,val acc : 0.825531\n",
      "[ ecpho : 8  iter :900 ]train loss : 0.252963 ,train acc: 0.879964 ,val loss : 0.380880 ,val acc : 0.829651\n",
      "[ ecpho : 8  iter :901 ]train loss : 0.300557 ,train acc: 0.860128 ,val loss : 0.377104 ,val acc : 0.826141\n",
      "[ ecpho : 8  iter :902 ]train loss : 0.275770 ,train acc: 0.870880 ,val loss : 0.375315 ,val acc : 0.829498\n",
      "[ ecpho : 8  iter :903 ]train loss : 0.415572 ,train acc: 0.849213 ,val loss : 0.382413 ,val acc : 0.826019\n",
      "[ ecpho : 8  iter :904 ]train loss : 0.367000 ,train acc: 0.813772 ,val loss : 0.381058 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :905 ]train loss : 0.322751 ,train acc: 0.855143 ,val loss : 0.374037 ,val acc : 0.829193\n",
      "[ ecpho : 8  iter :906 ]train loss : 0.238833 ,train acc: 0.883871 ,val loss : 0.377585 ,val acc : 0.829620\n",
      "[ ecpho : 8  iter :907 ]train loss : 0.411895 ,train acc: 0.846090 ,val loss : 0.380512 ,val acc : 0.825989\n",
      "[ ecpho : 8  iter :908 ]train loss : 0.309271 ,train acc: 0.862590 ,val loss : 0.380009 ,val acc : 0.828461\n",
      "[ ecpho : 8  iter :909 ]train loss : 0.251577 ,train acc: 0.878418 ,val loss : 0.373592 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :910 ]train loss : 0.336232 ,train acc: 0.856303 ,val loss : 0.377978 ,val acc : 0.830719\n",
      "[ ecpho : 8  iter :911 ]train loss : 0.547476 ,train acc: 0.780660 ,val loss : 0.382659 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :912 ]train loss : 0.386997 ,train acc: 0.804057 ,val loss : 0.378437 ,val acc : 0.829254\n",
      "[ ecpho : 8  iter :913 ]train loss : 0.298557 ,train acc: 0.860596 ,val loss : 0.374972 ,val acc : 0.829803\n",
      "[ ecpho : 8  iter :914 ]train loss : 0.230247 ,train acc: 0.890045 ,val loss : 0.380705 ,val acc : 0.830353\n",
      "[ ecpho : 8  iter :915 ]train loss : 0.333148 ,train acc: 0.855143 ,val loss : 0.381299 ,val acc : 0.830261\n",
      "[ ecpho : 8  iter :916 ]train loss : 0.290843 ,train acc: 0.851349 ,val loss : 0.380243 ,val acc : 0.829346\n",
      "[ ecpho : 8  iter :917 ]train loss : 0.231775 ,train acc: 0.891327 ,val loss : 0.378447 ,val acc : 0.832489\n",
      "[ ecpho : 8  iter :918 ]train loss : 0.489206 ,train acc: 0.791036 ,val loss : 0.380295 ,val acc : 0.830261\n",
      "[ ecpho : 8  iter :919 ]train loss : 0.323342 ,train acc: 0.853444 ,val loss : 0.378960 ,val acc : 0.832611\n",
      "[ ecpho : 8  iter :920 ]train loss : 0.317050 ,train acc: 0.859507 ,val loss : 0.380270 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :921 ]train loss : 0.428484 ,train acc: 0.808014 ,val loss : 0.377920 ,val acc : 0.827576\n",
      "[ ecpho : 8  iter :922 ]train loss : 0.496640 ,train acc: 0.836457 ,val loss : 0.379707 ,val acc : 0.829285\n",
      "[ ecpho : 8  iter :923 ]train loss : 0.313549 ,train acc: 0.845886 ,val loss : 0.381578 ,val acc : 0.826111\n",
      "[ ecpho : 8  iter :924 ]train loss : 0.300749 ,train acc: 0.859629 ,val loss : 0.382818 ,val acc : 0.827728\n",
      "[ ecpho : 8  iter :925 ]train loss : 0.259695 ,train acc: 0.876902 ,val loss : 0.383042 ,val acc : 0.828094\n",
      "[ ecpho : 8  iter :926 ]train loss : 0.351950 ,train acc: 0.851827 ,val loss : 0.380416 ,val acc : 0.827362\n",
      "[ ecpho : 8  iter :927 ]train loss : 0.260468 ,train acc: 0.879944 ,val loss : 0.379848 ,val acc : 0.830963\n",
      "[ ecpho : 8  iter :928 ]train loss : 0.417858 ,train acc: 0.838064 ,val loss : 0.386074 ,val acc : 0.824219\n",
      "[ ecpho : 8  iter :929 ]train loss : 0.250511 ,train acc: 0.881917 ,val loss : 0.380053 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :930 ]train loss : 0.303230 ,train acc: 0.859334 ,val loss : 0.378907 ,val acc : 0.829681\n",
      "[ ecpho : 8  iter :931 ]train loss : 0.315726 ,train acc: 0.843984 ,val loss : 0.388466 ,val acc : 0.825378\n",
      "[ ecpho : 8  iter :932 ]train loss : 0.261236 ,train acc: 0.876414 ,val loss : 0.383626 ,val acc : 0.827271\n",
      "[ ecpho : 8  iter :933 ]train loss : 0.255994 ,train acc: 0.879252 ,val loss : 0.383493 ,val acc : 0.829041\n",
      "[ ecpho : 8  iter :934 ]train loss : 0.413494 ,train acc: 0.757039 ,val loss : 0.375658 ,val acc : 0.829620\n",
      "[ ecpho : 8  iter :935 ]train loss : 0.290678 ,train acc: 0.871602 ,val loss : 0.379689 ,val acc : 0.828064\n",
      "[ ecpho : 8  iter :936 ]train loss : 0.289335 ,train acc: 0.861878 ,val loss : 0.377126 ,val acc : 0.830811\n",
      "[ ecpho : 8  iter :937 ]train loss : 0.308434 ,train acc: 0.861898 ,val loss : 0.382168 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :938 ]train loss : 0.246599 ,train acc: 0.881460 ,val loss : 0.386820 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :939 ]train loss : 0.326176 ,train acc: 0.856415 ,val loss : 0.378753 ,val acc : 0.830261\n",
      "[ ecpho : 8  iter :940 ]train loss : 0.354056 ,train acc: 0.845276 ,val loss : 0.381171 ,val acc : 0.827393\n",
      "[ ecpho : 8  iter :941 ]train loss : 0.324210 ,train acc: 0.858205 ,val loss : 0.372186 ,val acc : 0.830688\n",
      "[ ecpho : 8  iter :942 ]train loss : 0.304621 ,train acc: 0.860799 ,val loss : 0.381239 ,val acc : 0.829041\n",
      "[ ecpho : 8  iter :943 ]train loss : 0.325827 ,train acc: 0.857473 ,val loss : 0.376413 ,val acc : 0.829742\n",
      "[ ecpho : 8  iter :944 ]train loss : 0.393333 ,train acc: 0.819519 ,val loss : 0.383250 ,val acc : 0.826813\n",
      "[ ecpho : 8  iter :945 ]train loss : 0.243038 ,train acc: 0.884725 ,val loss : 0.382073 ,val acc : 0.826324\n",
      "[ ecpho : 8  iter :946 ]train loss : 0.259081 ,train acc: 0.874909 ,val loss : 0.373035 ,val acc : 0.830750\n",
      "[ ecpho : 8  iter :947 ]train loss : 0.307917 ,train acc: 0.854116 ,val loss : 0.380337 ,val acc : 0.826752\n",
      "[ ecpho : 8  iter :948 ]train loss : 0.401432 ,train acc: 0.808238 ,val loss : 0.379657 ,val acc : 0.827820\n",
      "[ ecpho : 8  iter :949 ]train loss : 0.352360 ,train acc: 0.835419 ,val loss : 0.382265 ,val acc : 0.829102\n",
      "[ ecpho : 8  iter :950 ]train loss : 0.353792 ,train acc: 0.849549 ,val loss : 0.378878 ,val acc : 0.827484\n",
      "[ ecpho : 8  iter :951 ]train loss : 0.338922 ,train acc: 0.858337 ,val loss : 0.382811 ,val acc : 0.828217\n",
      "[ ecpho : 8  iter :952 ]train loss : 0.285691 ,train acc: 0.861379 ,val loss : 0.380576 ,val acc : 0.827026\n",
      "[ ecpho : 8  iter :953 ]train loss : 0.234620 ,train acc: 0.884959 ,val loss : 0.376553 ,val acc : 0.829254\n",
      "[ ecpho : 8  iter :954 ]train loss : 0.275803 ,train acc: 0.860016 ,val loss : 0.373215 ,val acc : 0.830109\n",
      "[ ecpho : 8  iter :955 ]train loss : 0.330272 ,train acc: 0.855448 ,val loss : 0.389447 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :956 ]train loss : 0.258322 ,train acc: 0.874542 ,val loss : 0.388272 ,val acc : 0.825836\n",
      "[ ecpho : 8  iter :957 ]train loss : 0.299846 ,train acc: 0.861054 ,val loss : 0.376538 ,val acc : 0.832489\n",
      "[ ecpho : 8  iter :958 ]train loss : 0.332402 ,train acc: 0.866415 ,val loss : 0.378855 ,val acc : 0.829712\n",
      "[ ecpho : 8  iter :959 ]train loss : 0.365662 ,train acc: 0.831045 ,val loss : 0.380434 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :960 ]train loss : 0.352320 ,train acc: 0.846497 ,val loss : 0.379470 ,val acc : 0.826447\n",
      "[ ecpho : 8  iter :961 ]train loss : 0.262856 ,train acc: 0.874827 ,val loss : 0.384661 ,val acc : 0.826294\n",
      "[ ecpho : 8  iter :962 ]train loss : 0.323459 ,train acc: 0.861328 ,val loss : 0.384381 ,val acc : 0.825989\n",
      "[ ecpho : 8  iter :963 ]train loss : 0.301270 ,train acc: 0.856374 ,val loss : 0.378217 ,val acc : 0.824921\n",
      "[ ecpho : 8  iter :964 ]train loss : 0.306643 ,train acc: 0.854950 ,val loss : 0.380307 ,val acc : 0.828583\n",
      "[ ecpho : 8  iter :965 ]train loss : 0.301856 ,train acc: 0.851786 ,val loss : 0.389101 ,val acc : 0.822479\n",
      "[ ecpho : 8  iter :966 ]train loss : 0.398690 ,train acc: 0.834280 ,val loss : 0.375499 ,val acc : 0.832214\n",
      "[ ecpho : 8  iter :967 ]train loss : 0.284234 ,train acc: 0.870148 ,val loss : 0.379588 ,val acc : 0.829529\n",
      "[ ecpho : 8  iter :968 ]train loss : 0.266555 ,train acc: 0.874695 ,val loss : 0.382097 ,val acc : 0.827545\n",
      "[ ecpho : 8  iter :969 ]train loss : 0.353057 ,train acc: 0.834015 ,val loss : 0.385134 ,val acc : 0.827271\n",
      "[ ecpho : 8  iter :970 ]train loss : 0.292216 ,train acc: 0.862966 ,val loss : 0.376858 ,val acc : 0.829956\n",
      "[ ecpho : 8  iter :971 ]train loss : 0.376561 ,train acc: 0.843109 ,val loss : 0.379351 ,val acc : 0.826660\n",
      "[ ecpho : 8  iter :972 ]train loss : 0.378912 ,train acc: 0.846090 ,val loss : 0.379268 ,val acc : 0.828308\n",
      "[ ecpho : 8  iter :973 ]train loss : 0.302179 ,train acc: 0.872955 ,val loss : 0.380037 ,val acc : 0.826935\n",
      "[ ecpho : 8  iter :974 ]train loss : 0.307588 ,train acc: 0.839081 ,val loss : 0.379130 ,val acc : 0.829010\n",
      "[ ecpho : 8  iter :975 ]train loss : 0.237490 ,train acc: 0.885783 ,val loss : 0.379635 ,val acc : 0.829834\n",
      "[ ecpho : 8  iter :976 ]train loss : 0.245292 ,train acc: 0.880931 ,val loss : 0.379424 ,val acc : 0.828766\n",
      "[ ecpho : 8  iter :977 ]train loss : 0.316753 ,train acc: 0.859690 ,val loss : 0.382605 ,val acc : 0.825928\n",
      "[ ecpho : 8  iter :978 ]train loss : 0.312287 ,train acc: 0.859711 ,val loss : 0.378681 ,val acc : 0.829865\n",
      "[ ecpho : 8  iter :979 ]train loss : 0.247709 ,train acc: 0.881683 ,val loss : 0.381285 ,val acc : 0.829407\n",
      "[ ecpho : 8  iter :980 ]train loss : 0.320065 ,train acc: 0.853719 ,val loss : 0.382483 ,val acc : 0.826569\n",
      "[ ecpho : 8  iter :981 ]train loss : 0.283901 ,train acc: 0.868378 ,val loss : 0.375816 ,val acc : 0.826996\n",
      "[ ecpho : 8  iter :982 ]train loss : 0.231265 ,train acc: 0.886749 ,val loss : 0.383317 ,val acc : 0.828003\n",
      "[ ecpho : 8  iter :983 ]train loss : 0.295220 ,train acc: 0.871043 ,val loss : 0.378837 ,val acc : 0.828186\n",
      "[ ecpho : 8  iter :984 ]train loss : 0.310373 ,train acc: 0.843872 ,val loss : 0.383521 ,val acc : 0.826385\n",
      "[ ecpho : 8  iter :985 ]train loss : 0.237938 ,train acc: 0.885376 ,val loss : 0.376137 ,val acc : 0.828705\n",
      "[ ecpho : 8  iter :986 ]train loss : 0.343182 ,train acc: 0.848674 ,val loss : 0.382169 ,val acc : 0.827576\n",
      "[ ecpho : 8  iter :987 ]train loss : 0.242066 ,train acc: 0.884745 ,val loss : 0.382389 ,val acc : 0.826874\n",
      "[ ecpho : 8  iter :988 ]train loss : 0.225161 ,train acc: 0.890686 ,val loss : 0.384229 ,val acc : 0.826538\n",
      "[ ecpho : 8  iter :989 ]train loss : 0.384733 ,train acc: 0.819244 ,val loss : 0.380006 ,val acc : 0.827850\n",
      "[ ecpho : 8  iter :990 ]train loss : 0.304319 ,train acc: 0.870199 ,val loss : 0.381429 ,val acc : 0.828766\n",
      "[ ecpho : 8  iter :991 ]train loss : 0.249405 ,train acc: 0.878784 ,val loss : 0.377380 ,val acc : 0.831329\n",
      "[ ecpho : 8  iter :992 ]train loss : 0.315523 ,train acc: 0.852712 ,val loss : 0.377379 ,val acc : 0.829376\n",
      "[ ecpho : 8  iter :993 ]train loss : 0.337173 ,train acc: 0.852132 ,val loss : 0.388264 ,val acc : 0.826874\n",
      "[ ecpho : 8  iter :994 ]train loss : 0.289459 ,train acc: 0.852183 ,val loss : 0.380069 ,val acc : 0.827515\n",
      "[ ecpho : 8  iter :995 ]train loss : 0.257893 ,train acc: 0.880768 ,val loss : 0.380068 ,val acc : 0.829468\n",
      "[ ecpho : 8  iter :996 ]train loss : 0.250964 ,train acc: 0.879038 ,val loss : 0.381837 ,val acc : 0.828796\n",
      "[ ecpho : 8  iter :997 ]train loss : 0.312544 ,train acc: 0.840474 ,val loss : 0.377430 ,val acc : 0.829742\n",
      "[ ecpho : 8  iter :998 ]train loss : 0.237544 ,train acc: 0.885732 ,val loss : 0.378692 ,val acc : 0.830688\n",
      "[ ecpho : 8  iter :999 ]train loss : 0.267921 ,train acc: 0.870738 ,val loss : 0.381954 ,val acc : 0.828674\n",
      "[ ecpho : 8  iter :1000 ]train loss : 0.280065 ,train acc: 0.866781 ,val loss : 0.381387 ,val acc : 0.827148\n",
      "=============================================\n",
      "[ 8 ] average train loss : 0.309616 train acc : 0.856983\n",
      "[ ecpho : 9  iter :1 ]train loss : 0.280958 ,train acc: 0.867930 ,val loss : 0.382825 ,val acc : 0.825165\n",
      "[ ecpho : 9  iter :2 ]train loss : 0.396852 ,train acc: 0.809418 ,val loss : 0.380907 ,val acc : 0.826385\n",
      "[ ecpho : 9  iter :3 ]train loss : 0.326538 ,train acc: 0.828390 ,val loss : 0.381173 ,val acc : 0.825134\n",
      "[ ecpho : 9  iter :4 ]train loss : 0.353641 ,train acc: 0.814952 ,val loss : 0.379834 ,val acc : 0.830109\n",
      "[ ecpho : 9  iter :5 ]train loss : 0.237716 ,train acc: 0.887695 ,val loss : 0.384767 ,val acc : 0.826538\n",
      "[ ecpho : 9  iter :6 ]train loss : 0.394694 ,train acc: 0.816101 ,val loss : 0.377021 ,val acc : 0.831390\n",
      "[ ecpho : 9  iter :7 ]train loss : 0.332467 ,train acc: 0.847138 ,val loss : 0.381771 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :8 ]train loss : 0.283690 ,train acc: 0.863464 ,val loss : 0.385124 ,val acc : 0.824158\n",
      "[ ecpho : 9  iter :9 ]train loss : 0.284748 ,train acc: 0.869914 ,val loss : 0.381116 ,val acc : 0.826874\n",
      "[ ecpho : 9  iter :10 ]train loss : 0.434811 ,train acc: 0.813019 ,val loss : 0.383754 ,val acc : 0.825714\n",
      "[ ecpho : 9  iter :11 ]train loss : 0.256834 ,train acc: 0.877523 ,val loss : 0.385163 ,val acc : 0.825928\n",
      "[ ecpho : 9  iter :12 ]train loss : 0.337973 ,train acc: 0.852173 ,val loss : 0.382068 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :13 ]train loss : 0.289674 ,train acc: 0.860097 ,val loss : 0.385342 ,val acc : 0.827606\n",
      "[ ecpho : 9  iter :14 ]train loss : 0.231911 ,train acc: 0.887512 ,val loss : 0.385377 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :15 ]train loss : 0.338135 ,train acc: 0.828858 ,val loss : 0.378681 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :16 ]train loss : 0.335670 ,train acc: 0.856506 ,val loss : 0.378458 ,val acc : 0.830078\n",
      "[ ecpho : 9  iter :17 ]train loss : 0.279013 ,train acc: 0.861033 ,val loss : 0.379550 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :18 ]train loss : 0.262713 ,train acc: 0.876190 ,val loss : 0.384255 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :19 ]train loss : 0.260833 ,train acc: 0.874166 ,val loss : 0.383781 ,val acc : 0.826508\n",
      "[ ecpho : 9  iter :20 ]train loss : 0.255413 ,train acc: 0.880534 ,val loss : 0.375905 ,val acc : 0.829712\n",
      "[ ecpho : 9  iter :21 ]train loss : 0.333906 ,train acc: 0.853475 ,val loss : 0.374983 ,val acc : 0.831116\n",
      "[ ecpho : 9  iter :22 ]train loss : 0.255138 ,train acc: 0.878204 ,val loss : 0.384719 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :23 ]train loss : 0.388402 ,train acc: 0.855957 ,val loss : 0.387488 ,val acc : 0.826538\n",
      "[ ecpho : 9  iter :24 ]train loss : 0.294881 ,train acc: 0.862824 ,val loss : 0.378081 ,val acc : 0.830139\n",
      "[ ecpho : 9  iter :25 ]train loss : 0.243116 ,train acc: 0.882701 ,val loss : 0.377552 ,val acc : 0.827362\n",
      "[ ecpho : 9  iter :26 ]train loss : 0.314577 ,train acc: 0.861501 ,val loss : 0.382016 ,val acc : 0.830322\n",
      "[ ecpho : 9  iter :27 ]train loss : 0.262810 ,train acc: 0.872630 ,val loss : 0.386807 ,val acc : 0.826050\n",
      "[ ecpho : 9  iter :28 ]train loss : 0.285268 ,train acc: 0.864553 ,val loss : 0.381162 ,val acc : 0.825287\n",
      "[ ecpho : 9  iter :29 ]train loss : 0.232836 ,train acc: 0.886892 ,val loss : 0.382544 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :30 ]train loss : 0.425141 ,train acc: 0.797007 ,val loss : 0.375981 ,val acc : 0.831696\n",
      "[ ecpho : 9  iter :31 ]train loss : 0.282024 ,train acc: 0.862122 ,val loss : 0.380809 ,val acc : 0.826813\n",
      "[ ecpho : 9  iter :32 ]train loss : 0.272379 ,train acc: 0.868032 ,val loss : 0.378769 ,val acc : 0.830170\n",
      "[ ecpho : 9  iter :33 ]train loss : 0.398752 ,train acc: 0.789602 ,val loss : 0.377790 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :34 ]train loss : 0.272073 ,train acc: 0.869649 ,val loss : 0.381764 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :35 ]train loss : 0.229750 ,train acc: 0.891246 ,val loss : 0.382055 ,val acc : 0.826599\n",
      "[ ecpho : 9  iter :36 ]train loss : 0.272528 ,train acc: 0.872498 ,val loss : 0.379876 ,val acc : 0.829498\n",
      "[ ecpho : 9  iter :37 ]train loss : 0.257892 ,train acc: 0.873271 ,val loss : 0.377457 ,val acc : 0.829987\n",
      "[ ecpho : 9  iter :38 ]train loss : 0.327362 ,train acc: 0.851766 ,val loss : 0.378835 ,val acc : 0.831390\n",
      "[ ecpho : 9  iter :39 ]train loss : 0.233561 ,train acc: 0.888031 ,val loss : 0.378114 ,val acc : 0.829468\n",
      "[ ecpho : 9  iter :40 ]train loss : 0.278393 ,train acc: 0.865306 ,val loss : 0.375472 ,val acc : 0.831573\n",
      "[ ecpho : 9  iter :41 ]train loss : 0.356762 ,train acc: 0.849467 ,val loss : 0.379432 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :42 ]train loss : 0.345208 ,train acc: 0.839946 ,val loss : 0.379716 ,val acc : 0.826630\n",
      "[ ecpho : 9  iter :43 ]train loss : 0.363723 ,train acc: 0.856598 ,val loss : 0.382516 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :44 ]train loss : 0.419290 ,train acc: 0.816864 ,val loss : 0.379510 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :45 ]train loss : 0.237586 ,train acc: 0.886586 ,val loss : 0.377971 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :46 ]train loss : 0.288694 ,train acc: 0.866669 ,val loss : 0.384410 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :47 ]train loss : 0.344924 ,train acc: 0.844777 ,val loss : 0.382127 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :48 ]train loss : 0.303343 ,train acc: 0.864950 ,val loss : 0.378557 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :49 ]train loss : 0.319267 ,train acc: 0.825500 ,val loss : 0.378519 ,val acc : 0.826294\n",
      "[ ecpho : 9  iter :50 ]train loss : 0.300919 ,train acc: 0.870992 ,val loss : 0.381885 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :51 ]train loss : 0.320661 ,train acc: 0.859945 ,val loss : 0.381858 ,val acc : 0.829651\n",
      "[ ecpho : 9  iter :52 ]train loss : 0.329735 ,train acc: 0.824422 ,val loss : 0.381890 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :53 ]train loss : 0.314761 ,train acc: 0.860586 ,val loss : 0.380633 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :54 ]train loss : 0.353220 ,train acc: 0.854146 ,val loss : 0.384109 ,val acc : 0.824860\n",
      "[ ecpho : 9  iter :55 ]train loss : 0.315492 ,train acc: 0.859355 ,val loss : 0.384470 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :56 ]train loss : 0.231527 ,train acc: 0.888387 ,val loss : 0.379730 ,val acc : 0.831512\n",
      "[ ecpho : 9  iter :57 ]train loss : 0.295044 ,train acc: 0.861491 ,val loss : 0.380378 ,val acc : 0.829102\n",
      "[ ecpho : 9  iter :58 ]train loss : 0.330299 ,train acc: 0.855062 ,val loss : 0.380270 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :59 ]train loss : 0.368994 ,train acc: 0.851247 ,val loss : 0.380686 ,val acc : 0.826538\n",
      "[ ecpho : 9  iter :60 ]train loss : 0.346798 ,train acc: 0.853679 ,val loss : 0.378694 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :61 ]train loss : 0.408975 ,train acc: 0.818197 ,val loss : 0.377955 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :62 ]train loss : 0.250233 ,train acc: 0.881246 ,val loss : 0.379196 ,val acc : 0.830841\n",
      "[ ecpho : 9  iter :63 ]train loss : 0.251517 ,train acc: 0.881022 ,val loss : 0.375586 ,val acc : 0.831390\n",
      "[ ecpho : 9  iter :64 ]train loss : 0.270620 ,train acc: 0.872660 ,val loss : 0.381926 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :65 ]train loss : 0.295676 ,train acc: 0.865896 ,val loss : 0.380700 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :66 ]train loss : 0.254520 ,train acc: 0.879038 ,val loss : 0.376136 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :67 ]train loss : 0.375287 ,train acc: 0.818075 ,val loss : 0.382140 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :68 ]train loss : 0.304510 ,train acc: 0.843302 ,val loss : 0.378554 ,val acc : 0.824554\n",
      "[ ecpho : 9  iter :69 ]train loss : 0.340368 ,train acc: 0.818298 ,val loss : 0.376698 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :70 ]train loss : 0.325500 ,train acc: 0.847046 ,val loss : 0.378315 ,val acc : 0.828094\n",
      "[ ecpho : 9  iter :71 ]train loss : 0.311803 ,train acc: 0.859334 ,val loss : 0.379223 ,val acc : 0.827362\n",
      "[ ecpho : 9  iter :72 ]train loss : 0.226931 ,train acc: 0.888346 ,val loss : 0.376534 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :73 ]train loss : 0.259889 ,train acc: 0.877299 ,val loss : 0.383731 ,val acc : 0.829712\n",
      "[ ecpho : 9  iter :74 ]train loss : 0.322964 ,train acc: 0.844757 ,val loss : 0.375848 ,val acc : 0.828522\n",
      "[ ecpho : 9  iter :75 ]train loss : 0.275176 ,train acc: 0.871786 ,val loss : 0.376300 ,val acc : 0.827362\n",
      "[ ecpho : 9  iter :76 ]train loss : 0.288564 ,train acc: 0.865977 ,val loss : 0.381563 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :77 ]train loss : 0.240797 ,train acc: 0.885559 ,val loss : 0.386035 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :78 ]train loss : 0.288261 ,train acc: 0.873952 ,val loss : 0.381963 ,val acc : 0.826355\n",
      "[ ecpho : 9  iter :79 ]train loss : 0.313694 ,train acc: 0.860555 ,val loss : 0.384032 ,val acc : 0.830200\n",
      "[ ecpho : 9  iter :80 ]train loss : 0.328347 ,train acc: 0.855947 ,val loss : 0.387270 ,val acc : 0.824921\n",
      "[ ecpho : 9  iter :81 ]train loss : 0.363416 ,train acc: 0.850891 ,val loss : 0.377894 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :82 ]train loss : 0.319764 ,train acc: 0.813507 ,val loss : 0.376157 ,val acc : 0.828735\n",
      "[ ecpho : 9  iter :83 ]train loss : 0.348506 ,train acc: 0.822164 ,val loss : 0.383716 ,val acc : 0.826660\n",
      "[ ecpho : 9  iter :84 ]train loss : 0.285385 ,train acc: 0.867106 ,val loss : 0.378622 ,val acc : 0.828766\n",
      "[ ecpho : 9  iter :85 ]train loss : 0.293247 ,train acc: 0.866465 ,val loss : 0.379340 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :86 ]train loss : 0.333196 ,train acc: 0.824341 ,val loss : 0.378144 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :87 ]train loss : 0.314197 ,train acc: 0.850790 ,val loss : 0.380158 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :88 ]train loss : 0.488954 ,train acc: 0.750377 ,val loss : 0.384700 ,val acc : 0.826355\n",
      "[ ecpho : 9  iter :89 ]train loss : 0.243560 ,train acc: 0.879100 ,val loss : 0.377498 ,val acc : 0.829590\n",
      "[ ecpho : 9  iter :90 ]train loss : 0.261759 ,train acc: 0.871826 ,val loss : 0.382688 ,val acc : 0.826904\n",
      "[ ecpho : 9  iter :91 ]train loss : 0.334861 ,train acc: 0.857900 ,val loss : 0.388071 ,val acc : 0.825500\n",
      "[ ecpho : 9  iter :92 ]train loss : 0.224755 ,train acc: 0.889903 ,val loss : 0.374907 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :93 ]train loss : 0.280603 ,train acc: 0.871023 ,val loss : 0.380935 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :94 ]train loss : 0.482642 ,train acc: 0.797506 ,val loss : 0.377988 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :95 ]train loss : 0.417929 ,train acc: 0.840525 ,val loss : 0.382654 ,val acc : 0.825378\n",
      "[ ecpho : 9  iter :96 ]train loss : 0.296627 ,train acc: 0.847778 ,val loss : 0.377894 ,val acc : 0.829773\n",
      "[ ecpho : 9  iter :97 ]train loss : 0.366157 ,train acc: 0.839488 ,val loss : 0.379695 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :98 ]train loss : 0.376929 ,train acc: 0.851593 ,val loss : 0.384196 ,val acc : 0.828949\n",
      "[ ecpho : 9  iter :99 ]train loss : 0.255477 ,train acc: 0.880971 ,val loss : 0.376481 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :100 ]train loss : 0.321721 ,train acc: 0.857371 ,val loss : 0.382875 ,val acc : 0.830597\n",
      "[ ecpho : 9  iter :101 ]train loss : 0.257569 ,train acc: 0.877665 ,val loss : 0.377361 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :102 ]train loss : 0.321711 ,train acc: 0.863169 ,val loss : 0.378497 ,val acc : 0.829254\n",
      "[ ecpho : 9  iter :103 ]train loss : 0.286842 ,train acc: 0.870931 ,val loss : 0.378072 ,val acc : 0.827545\n",
      "[ ecpho : 9  iter :104 ]train loss : 0.286712 ,train acc: 0.868663 ,val loss : 0.380600 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :105 ]train loss : 0.241803 ,train acc: 0.886464 ,val loss : 0.376841 ,val acc : 0.832672\n",
      "[ ecpho : 9  iter :106 ]train loss : 0.252264 ,train acc: 0.879110 ,val loss : 0.381194 ,val acc : 0.829285\n",
      "[ ecpho : 9  iter :107 ]train loss : 0.367693 ,train acc: 0.846171 ,val loss : 0.387394 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :108 ]train loss : 0.316710 ,train acc: 0.866323 ,val loss : 0.378814 ,val acc : 0.832245\n",
      "[ ecpho : 9  iter :109 ]train loss : 0.291216 ,train acc: 0.850261 ,val loss : 0.382646 ,val acc : 0.827118\n",
      "[ ecpho : 9  iter :110 ]train loss : 0.286801 ,train acc: 0.862630 ,val loss : 0.380052 ,val acc : 0.826935\n",
      "[ ecpho : 9  iter :111 ]train loss : 0.335697 ,train acc: 0.850952 ,val loss : 0.382597 ,val acc : 0.825623\n",
      "[ ecpho : 9  iter :112 ]train loss : 0.250229 ,train acc: 0.882416 ,val loss : 0.380513 ,val acc : 0.830902\n",
      "[ ecpho : 9  iter :113 ]train loss : 0.236775 ,train acc: 0.886342 ,val loss : 0.374430 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :114 ]train loss : 0.249151 ,train acc: 0.881846 ,val loss : 0.377659 ,val acc : 0.826874\n",
      "[ ecpho : 9  iter :115 ]train loss : 0.260375 ,train acc: 0.874288 ,val loss : 0.383843 ,val acc : 0.825378\n",
      "[ ecpho : 9  iter :116 ]train loss : 0.289914 ,train acc: 0.863332 ,val loss : 0.383810 ,val acc : 0.825775\n",
      "[ ecpho : 9  iter :117 ]train loss : 0.432616 ,train acc: 0.828949 ,val loss : 0.383532 ,val acc : 0.828278\n",
      "[ ecpho : 9  iter :118 ]train loss : 0.356728 ,train acc: 0.812836 ,val loss : 0.377133 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :119 ]train loss : 0.311273 ,train acc: 0.861593 ,val loss : 0.378486 ,val acc : 0.831207\n",
      "[ ecpho : 9  iter :120 ]train loss : 0.267165 ,train acc: 0.879659 ,val loss : 0.381523 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :121 ]train loss : 0.322940 ,train acc: 0.853851 ,val loss : 0.376986 ,val acc : 0.830658\n",
      "[ ecpho : 9  iter :122 ]train loss : 0.279597 ,train acc: 0.862061 ,val loss : 0.376453 ,val acc : 0.828522\n",
      "[ ecpho : 9  iter :123 ]train loss : 0.354916 ,train acc: 0.845724 ,val loss : 0.380088 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :124 ]train loss : 0.234370 ,train acc: 0.888428 ,val loss : 0.380569 ,val acc : 0.829987\n",
      "[ ecpho : 9  iter :125 ]train loss : 0.289980 ,train acc: 0.855306 ,val loss : 0.381413 ,val acc : 0.826904\n",
      "[ ecpho : 9  iter :126 ]train loss : 0.400130 ,train acc: 0.828502 ,val loss : 0.379043 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :127 ]train loss : 0.397666 ,train acc: 0.814128 ,val loss : 0.376763 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :128 ]train loss : 0.283995 ,train acc: 0.866882 ,val loss : 0.378475 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :129 ]train loss : 0.302782 ,train acc: 0.862712 ,val loss : 0.382031 ,val acc : 0.828857\n",
      "[ ecpho : 9  iter :130 ]train loss : 0.304654 ,train acc: 0.851278 ,val loss : 0.381664 ,val acc : 0.827942\n",
      "[ ecpho : 9  iter :131 ]train loss : 0.314061 ,train acc: 0.864115 ,val loss : 0.377514 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :132 ]train loss : 0.237455 ,train acc: 0.884461 ,val loss : 0.376437 ,val acc : 0.830109\n",
      "[ ecpho : 9  iter :133 ]train loss : 0.326357 ,train acc: 0.853292 ,val loss : 0.378007 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :134 ]train loss : 0.256398 ,train acc: 0.877502 ,val loss : 0.375800 ,val acc : 0.831268\n",
      "[ ecpho : 9  iter :135 ]train loss : 0.302415 ,train acc: 0.868429 ,val loss : 0.374758 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :136 ]train loss : 0.359555 ,train acc: 0.817068 ,val loss : 0.381817 ,val acc : 0.826630\n",
      "[ ecpho : 9  iter :137 ]train loss : 0.341506 ,train acc: 0.859009 ,val loss : 0.380565 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :138 ]train loss : 0.274219 ,train acc: 0.870860 ,val loss : 0.383809 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :139 ]train loss : 0.265337 ,train acc: 0.876414 ,val loss : 0.382481 ,val acc : 0.829529\n",
      "[ ecpho : 9  iter :140 ]train loss : 0.279344 ,train acc: 0.866598 ,val loss : 0.379070 ,val acc : 0.827118\n",
      "[ ecpho : 9  iter :141 ]train loss : 0.295962 ,train acc: 0.868124 ,val loss : 0.381179 ,val acc : 0.826904\n",
      "[ ecpho : 9  iter :142 ]train loss : 0.272415 ,train acc: 0.871928 ,val loss : 0.390377 ,val acc : 0.824402\n",
      "[ ecpho : 9  iter :143 ]train loss : 0.271984 ,train acc: 0.874786 ,val loss : 0.381738 ,val acc : 0.825409\n",
      "[ ecpho : 9  iter :144 ]train loss : 0.359550 ,train acc: 0.847412 ,val loss : 0.378574 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :145 ]train loss : 0.319028 ,train acc: 0.842753 ,val loss : 0.382066 ,val acc : 0.827087\n",
      "[ ecpho : 9  iter :146 ]train loss : 0.401892 ,train acc: 0.833018 ,val loss : 0.373466 ,val acc : 0.833862\n",
      "[ ecpho : 9  iter :147 ]train loss : 0.401825 ,train acc: 0.802267 ,val loss : 0.384397 ,val acc : 0.825562\n",
      "[ ecpho : 9  iter :148 ]train loss : 0.340137 ,train acc: 0.859528 ,val loss : 0.377158 ,val acc : 0.829590\n",
      "[ ecpho : 9  iter :149 ]train loss : 0.340999 ,train acc: 0.828359 ,val loss : 0.381692 ,val acc : 0.826416\n",
      "[ ecpho : 9  iter :150 ]train loss : 0.270665 ,train acc: 0.868622 ,val loss : 0.381179 ,val acc : 0.824707\n",
      "[ ecpho : 9  iter :151 ]train loss : 0.278528 ,train acc: 0.863464 ,val loss : 0.380663 ,val acc : 0.825348\n",
      "[ ecpho : 9  iter :152 ]train loss : 0.258631 ,train acc: 0.876190 ,val loss : 0.380187 ,val acc : 0.827118\n",
      "[ ecpho : 9  iter :153 ]train loss : 0.279838 ,train acc: 0.871470 ,val loss : 0.377085 ,val acc : 0.829041\n",
      "[ ecpho : 9  iter :154 ]train loss : 0.262558 ,train acc: 0.874664 ,val loss : 0.379086 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :155 ]train loss : 0.244474 ,train acc: 0.879964 ,val loss : 0.377971 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :156 ]train loss : 0.269882 ,train acc: 0.870677 ,val loss : 0.380486 ,val acc : 0.827362\n",
      "[ ecpho : 9  iter :157 ]train loss : 0.250131 ,train acc: 0.883240 ,val loss : 0.380257 ,val acc : 0.829926\n",
      "[ ecpho : 9  iter :158 ]train loss : 0.375047 ,train acc: 0.848602 ,val loss : 0.379224 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :159 ]train loss : 0.246585 ,train acc: 0.881114 ,val loss : 0.379049 ,val acc : 0.826202\n",
      "[ ecpho : 9  iter :160 ]train loss : 0.339337 ,train acc: 0.846344 ,val loss : 0.381318 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :161 ]train loss : 0.387496 ,train acc: 0.839335 ,val loss : 0.377339 ,val acc : 0.829071\n",
      "[ ecpho : 9  iter :162 ]train loss : 0.326992 ,train acc: 0.857513 ,val loss : 0.380147 ,val acc : 0.830841\n",
      "[ ecpho : 9  iter :163 ]train loss : 0.246149 ,train acc: 0.883362 ,val loss : 0.379462 ,val acc : 0.830353\n",
      "[ ecpho : 9  iter :164 ]train loss : 0.287075 ,train acc: 0.862549 ,val loss : 0.379400 ,val acc : 0.829376\n",
      "[ ecpho : 9  iter :165 ]train loss : 0.262652 ,train acc: 0.873474 ,val loss : 0.380523 ,val acc : 0.825958\n",
      "[ ecpho : 9  iter :166 ]train loss : 0.271610 ,train acc: 0.872945 ,val loss : 0.382807 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :167 ]train loss : 0.246569 ,train acc: 0.886729 ,val loss : 0.377255 ,val acc : 0.831116\n",
      "[ ecpho : 9  iter :168 ]train loss : 0.389927 ,train acc: 0.819438 ,val loss : 0.379936 ,val acc : 0.827148\n",
      "[ ecpho : 9  iter :169 ]train loss : 0.303187 ,train acc: 0.867391 ,val loss : 0.380615 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :170 ]train loss : 0.310896 ,train acc: 0.858297 ,val loss : 0.382372 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :171 ]train loss : 0.406792 ,train acc: 0.811127 ,val loss : 0.377670 ,val acc : 0.829437\n",
      "[ ecpho : 9  iter :172 ]train loss : 0.383313 ,train acc: 0.834330 ,val loss : 0.380225 ,val acc : 0.826599\n",
      "[ ecpho : 9  iter :173 ]train loss : 0.558331 ,train acc: 0.824595 ,val loss : 0.386610 ,val acc : 0.826385\n",
      "[ ecpho : 9  iter :174 ]train loss : 0.275797 ,train acc: 0.873891 ,val loss : 0.381835 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :175 ]train loss : 0.338332 ,train acc: 0.822561 ,val loss : 0.380380 ,val acc : 0.829102\n",
      "[ ecpho : 9  iter :176 ]train loss : 0.372189 ,train acc: 0.799835 ,val loss : 0.377382 ,val acc : 0.832336\n",
      "[ ecpho : 9  iter :177 ]train loss : 0.335536 ,train acc: 0.815369 ,val loss : 0.378154 ,val acc : 0.829376\n",
      "[ ecpho : 9  iter :178 ]train loss : 0.273506 ,train acc: 0.877869 ,val loss : 0.378176 ,val acc : 0.829651\n",
      "[ ecpho : 9  iter :179 ]train loss : 0.273687 ,train acc: 0.869700 ,val loss : 0.378627 ,val acc : 0.830902\n",
      "[ ecpho : 9  iter :180 ]train loss : 0.249253 ,train acc: 0.877696 ,val loss : 0.378431 ,val acc : 0.826080\n",
      "[ ecpho : 9  iter :181 ]train loss : 0.305847 ,train acc: 0.856130 ,val loss : 0.378564 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :182 ]train loss : 0.409302 ,train acc: 0.842214 ,val loss : 0.379274 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :183 ]train loss : 0.406965 ,train acc: 0.826569 ,val loss : 0.385004 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :184 ]train loss : 0.320852 ,train acc: 0.833486 ,val loss : 0.379164 ,val acc : 0.826202\n",
      "[ ecpho : 9  iter :185 ]train loss : 0.261818 ,train acc: 0.869008 ,val loss : 0.378922 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :186 ]train loss : 0.313086 ,train acc: 0.856812 ,val loss : 0.377157 ,val acc : 0.828033\n",
      "[ ecpho : 9  iter :187 ]train loss : 0.403452 ,train acc: 0.833323 ,val loss : 0.379561 ,val acc : 0.825256\n",
      "[ ecpho : 9  iter :188 ]train loss : 0.287431 ,train acc: 0.864644 ,val loss : 0.380533 ,val acc : 0.830933\n",
      "[ ecpho : 9  iter :189 ]train loss : 0.351369 ,train acc: 0.830800 ,val loss : 0.378311 ,val acc : 0.831116\n",
      "[ ecpho : 9  iter :190 ]train loss : 0.343443 ,train acc: 0.855906 ,val loss : 0.379493 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :191 ]train loss : 0.275507 ,train acc: 0.860260 ,val loss : 0.378308 ,val acc : 0.829987\n",
      "[ ecpho : 9  iter :192 ]train loss : 0.263147 ,train acc: 0.874685 ,val loss : 0.381225 ,val acc : 0.829498\n",
      "[ ecpho : 9  iter :193 ]train loss : 0.249887 ,train acc: 0.881124 ,val loss : 0.382017 ,val acc : 0.831726\n",
      "[ ecpho : 9  iter :194 ]train loss : 0.277224 ,train acc: 0.861125 ,val loss : 0.379495 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :195 ]train loss : 0.277821 ,train acc: 0.864105 ,val loss : 0.385110 ,val acc : 0.829041\n",
      "[ ecpho : 9  iter :196 ]train loss : 0.321240 ,train acc: 0.862579 ,val loss : 0.380011 ,val acc : 0.830780\n",
      "[ ecpho : 9  iter :197 ]train loss : 0.271226 ,train acc: 0.874837 ,val loss : 0.381115 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :198 ]train loss : 0.279031 ,train acc: 0.867777 ,val loss : 0.381330 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :199 ]train loss : 0.271956 ,train acc: 0.874166 ,val loss : 0.385817 ,val acc : 0.826813\n",
      "[ ecpho : 9  iter :200 ]train loss : 0.372769 ,train acc: 0.827861 ,val loss : 0.379100 ,val acc : 0.829956\n",
      "[ ecpho : 9  iter :201 ]train loss : 0.487860 ,train acc: 0.795776 ,val loss : 0.374262 ,val acc : 0.826569\n",
      "[ ecpho : 9  iter :202 ]train loss : 0.312193 ,train acc: 0.850077 ,val loss : 0.382423 ,val acc : 0.832001\n",
      "[ ecpho : 9  iter :203 ]train loss : 0.237060 ,train acc: 0.887105 ,val loss : 0.379727 ,val acc : 0.831451\n",
      "[ ecpho : 9  iter :204 ]train loss : 0.416573 ,train acc: 0.847768 ,val loss : 0.374503 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :205 ]train loss : 0.338410 ,train acc: 0.839040 ,val loss : 0.379165 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :206 ]train loss : 0.301007 ,train acc: 0.863617 ,val loss : 0.376135 ,val acc : 0.828979\n",
      "[ ecpho : 9  iter :207 ]train loss : 0.385210 ,train acc: 0.840973 ,val loss : 0.384624 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :208 ]train loss : 0.261336 ,train acc: 0.876801 ,val loss : 0.384978 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :209 ]train loss : 0.290780 ,train acc: 0.863393 ,val loss : 0.380303 ,val acc : 0.825958\n",
      "[ ecpho : 9  iter :210 ]train loss : 0.336363 ,train acc: 0.850454 ,val loss : 0.380216 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :211 ]train loss : 0.393464 ,train acc: 0.827342 ,val loss : 0.380300 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :212 ]train loss : 0.236495 ,train acc: 0.884989 ,val loss : 0.375427 ,val acc : 0.830109\n",
      "[ ecpho : 9  iter :213 ]train loss : 0.320068 ,train acc: 0.859843 ,val loss : 0.375591 ,val acc : 0.829285\n",
      "[ ecpho : 9  iter :214 ]train loss : 0.305680 ,train acc: 0.847046 ,val loss : 0.380409 ,val acc : 0.830627\n",
      "[ ecpho : 9  iter :215 ]train loss : 0.311364 ,train acc: 0.845256 ,val loss : 0.378655 ,val acc : 0.829071\n",
      "[ ecpho : 9  iter :216 ]train loss : 0.391602 ,train acc: 0.849091 ,val loss : 0.378767 ,val acc : 0.824921\n",
      "[ ecpho : 9  iter :217 ]train loss : 0.297940 ,train acc: 0.849844 ,val loss : 0.376818 ,val acc : 0.830658\n",
      "[ ecpho : 9  iter :218 ]train loss : 0.293189 ,train acc: 0.858958 ,val loss : 0.375785 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :219 ]train loss : 0.346510 ,train acc: 0.853078 ,val loss : 0.380737 ,val acc : 0.829041\n",
      "[ ecpho : 9  iter :220 ]train loss : 0.292990 ,train acc: 0.857585 ,val loss : 0.382106 ,val acc : 0.823578\n",
      "[ ecpho : 9  iter :221 ]train loss : 0.383223 ,train acc: 0.846029 ,val loss : 0.381138 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :222 ]train loss : 0.275089 ,train acc: 0.863963 ,val loss : 0.374950 ,val acc : 0.829987\n",
      "[ ecpho : 9  iter :223 ]train loss : 0.253360 ,train acc: 0.880829 ,val loss : 0.376851 ,val acc : 0.830200\n",
      "[ ecpho : 9  iter :224 ]train loss : 0.257725 ,train acc: 0.879140 ,val loss : 0.378373 ,val acc : 0.830414\n",
      "[ ecpho : 9  iter :225 ]train loss : 0.355006 ,train acc: 0.818970 ,val loss : 0.384229 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :226 ]train loss : 0.213890 ,train acc: 0.898153 ,val loss : 0.378975 ,val acc : 0.826965\n",
      "[ ecpho : 9  iter :227 ]train loss : 0.247838 ,train acc: 0.878835 ,val loss : 0.382833 ,val acc : 0.827637\n",
      "[ ecpho : 9  iter :228 ]train loss : 0.268566 ,train acc: 0.870890 ,val loss : 0.381418 ,val acc : 0.827148\n",
      "[ ecpho : 9  iter :229 ]train loss : 0.379740 ,train acc: 0.823802 ,val loss : 0.379161 ,val acc : 0.829926\n",
      "[ ecpho : 9  iter :230 ]train loss : 0.240647 ,train acc: 0.883331 ,val loss : 0.384355 ,val acc : 0.825623\n",
      "[ ecpho : 9  iter :231 ]train loss : 0.332568 ,train acc: 0.842418 ,val loss : 0.368945 ,val acc : 0.831299\n",
      "[ ecpho : 9  iter :232 ]train loss : 0.482697 ,train acc: 0.746542 ,val loss : 0.379856 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :233 ]train loss : 0.282890 ,train acc: 0.868337 ,val loss : 0.381628 ,val acc : 0.830383\n",
      "[ ecpho : 9  iter :234 ]train loss : 0.292358 ,train acc: 0.864848 ,val loss : 0.381543 ,val acc : 0.829529\n",
      "[ ecpho : 9  iter :235 ]train loss : 0.233251 ,train acc: 0.887024 ,val loss : 0.380608 ,val acc : 0.825958\n",
      "[ ecpho : 9  iter :236 ]train loss : 0.383831 ,train acc: 0.832865 ,val loss : 0.381072 ,val acc : 0.826294\n",
      "[ ecpho : 9  iter :237 ]train loss : 0.357065 ,train acc: 0.843862 ,val loss : 0.378221 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :238 ]train loss : 0.388177 ,train acc: 0.847412 ,val loss : 0.374903 ,val acc : 0.826843\n",
      "[ ecpho : 9  iter :239 ]train loss : 0.438097 ,train acc: 0.782247 ,val loss : 0.377287 ,val acc : 0.829132\n",
      "[ ecpho : 9  iter :240 ]train loss : 0.249054 ,train acc: 0.879100 ,val loss : 0.383468 ,val acc : 0.830505\n",
      "[ ecpho : 9  iter :241 ]train loss : 0.407236 ,train acc: 0.809570 ,val loss : 0.376302 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :242 ]train loss : 0.251020 ,train acc: 0.881388 ,val loss : 0.387922 ,val acc : 0.826721\n",
      "[ ecpho : 9  iter :243 ]train loss : 0.264457 ,train acc: 0.865336 ,val loss : 0.377881 ,val acc : 0.832367\n",
      "[ ecpho : 9  iter :244 ]train loss : 0.328424 ,train acc: 0.864695 ,val loss : 0.378451 ,val acc : 0.828522\n",
      "[ ecpho : 9  iter :245 ]train loss : 0.337026 ,train acc: 0.849966 ,val loss : 0.384991 ,val acc : 0.825409\n",
      "[ ecpho : 9  iter :246 ]train loss : 0.327656 ,train acc: 0.829081 ,val loss : 0.376269 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :247 ]train loss : 0.327627 ,train acc: 0.831675 ,val loss : 0.379570 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :248 ]train loss : 0.339909 ,train acc: 0.854279 ,val loss : 0.384333 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :249 ]train loss : 0.288182 ,train acc: 0.865123 ,val loss : 0.381955 ,val acc : 0.831299\n",
      "[ ecpho : 9  iter :250 ]train loss : 0.233583 ,train acc: 0.887583 ,val loss : 0.382193 ,val acc : 0.826630\n",
      "[ ecpho : 9  iter :251 ]train loss : 0.290729 ,train acc: 0.863912 ,val loss : 0.379627 ,val acc : 0.830994\n",
      "[ ecpho : 9  iter :252 ]train loss : 0.260407 ,train acc: 0.879822 ,val loss : 0.379337 ,val acc : 0.829529\n",
      "[ ecpho : 9  iter :253 ]train loss : 0.313829 ,train acc: 0.856069 ,val loss : 0.381284 ,val acc : 0.827423\n",
      "[ ecpho : 9  iter :254 ]train loss : 0.337364 ,train acc: 0.859680 ,val loss : 0.378981 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :255 ]train loss : 0.299217 ,train acc: 0.863353 ,val loss : 0.383607 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :256 ]train loss : 0.288781 ,train acc: 0.864868 ,val loss : 0.382000 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :257 ]train loss : 0.279673 ,train acc: 0.858358 ,val loss : 0.379214 ,val acc : 0.830566\n",
      "[ ecpho : 9  iter :258 ]train loss : 0.393725 ,train acc: 0.803304 ,val loss : 0.383872 ,val acc : 0.825104\n",
      "[ ecpho : 9  iter :259 ]train loss : 0.312889 ,train acc: 0.861186 ,val loss : 0.375780 ,val acc : 0.831940\n",
      "[ ecpho : 9  iter :260 ]train loss : 0.272869 ,train acc: 0.874420 ,val loss : 0.373278 ,val acc : 0.832214\n",
      "[ ecpho : 9  iter :261 ]train loss : 0.298305 ,train acc: 0.855744 ,val loss : 0.379318 ,val acc : 0.826477\n",
      "[ ecpho : 9  iter :262 ]train loss : 0.390983 ,train acc: 0.831777 ,val loss : 0.383384 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :263 ]train loss : 0.258716 ,train acc: 0.869721 ,val loss : 0.378022 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :264 ]train loss : 0.420474 ,train acc: 0.831452 ,val loss : 0.382521 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :265 ]train loss : 0.289843 ,train acc: 0.860748 ,val loss : 0.375897 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :266 ]train loss : 0.284407 ,train acc: 0.866303 ,val loss : 0.377295 ,val acc : 0.832062\n",
      "[ ecpho : 9  iter :267 ]train loss : 0.452312 ,train acc: 0.821574 ,val loss : 0.376038 ,val acc : 0.831299\n",
      "[ ecpho : 9  iter :268 ]train loss : 0.360696 ,train acc: 0.753184 ,val loss : 0.388194 ,val acc : 0.824768\n",
      "[ ecpho : 9  iter :269 ]train loss : 0.274989 ,train acc: 0.870402 ,val loss : 0.375906 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :270 ]train loss : 0.578085 ,train acc: 0.731618 ,val loss : 0.380280 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :271 ]train loss : 0.405751 ,train acc: 0.841858 ,val loss : 0.374789 ,val acc : 0.831146\n",
      "[ ecpho : 9  iter :272 ]train loss : 0.319980 ,train acc: 0.854604 ,val loss : 0.380460 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :273 ]train loss : 0.332584 ,train acc: 0.830984 ,val loss : 0.374298 ,val acc : 0.831055\n",
      "[ ecpho : 9  iter :274 ]train loss : 0.327723 ,train acc: 0.845520 ,val loss : 0.377559 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :275 ]train loss : 0.298045 ,train acc: 0.859578 ,val loss : 0.382598 ,val acc : 0.826050\n",
      "[ ecpho : 9  iter :276 ]train loss : 0.383425 ,train acc: 0.853597 ,val loss : 0.382259 ,val acc : 0.827179\n",
      "[ ecpho : 9  iter :277 ]train loss : 0.252290 ,train acc: 0.878886 ,val loss : 0.375716 ,val acc : 0.829834\n",
      "[ ecpho : 9  iter :278 ]train loss : 0.381376 ,train acc: 0.844788 ,val loss : 0.377099 ,val acc : 0.829071\n",
      "[ ecpho : 9  iter :279 ]train loss : 0.344543 ,train acc: 0.847961 ,val loss : 0.378281 ,val acc : 0.831146\n",
      "[ ecpho : 9  iter :280 ]train loss : 0.268878 ,train acc: 0.874288 ,val loss : 0.381891 ,val acc : 0.830505\n",
      "[ ecpho : 9  iter :281 ]train loss : 0.239096 ,train acc: 0.886485 ,val loss : 0.383810 ,val acc : 0.826569\n",
      "[ ecpho : 9  iter :282 ]train loss : 0.259182 ,train acc: 0.882955 ,val loss : 0.376530 ,val acc : 0.829620\n",
      "[ ecpho : 9  iter :283 ]train loss : 0.287637 ,train acc: 0.861542 ,val loss : 0.379619 ,val acc : 0.827423\n",
      "[ ecpho : 9  iter :284 ]train loss : 0.247674 ,train acc: 0.885020 ,val loss : 0.383271 ,val acc : 0.827942\n",
      "[ ecpho : 9  iter :285 ]train loss : 0.251317 ,train acc: 0.879791 ,val loss : 0.384683 ,val acc : 0.826569\n",
      "[ ecpho : 9  iter :286 ]train loss : 0.294223 ,train acc: 0.861583 ,val loss : 0.380439 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :287 ]train loss : 0.243030 ,train acc: 0.881429 ,val loss : 0.387101 ,val acc : 0.825256\n",
      "[ ecpho : 9  iter :288 ]train loss : 0.313253 ,train acc: 0.853567 ,val loss : 0.385104 ,val acc : 0.824982\n",
      "[ ecpho : 9  iter :289 ]train loss : 0.339827 ,train acc: 0.855917 ,val loss : 0.381684 ,val acc : 0.826508\n",
      "[ ecpho : 9  iter :290 ]train loss : 0.249172 ,train acc: 0.876048 ,val loss : 0.380573 ,val acc : 0.828857\n",
      "[ ecpho : 9  iter :291 ]train loss : 0.365826 ,train acc: 0.835571 ,val loss : 0.374154 ,val acc : 0.828064\n",
      "[ ecpho : 9  iter :292 ]train loss : 0.268854 ,train acc: 0.870463 ,val loss : 0.380389 ,val acc : 0.826874\n",
      "[ ecpho : 9  iter :293 ]train loss : 0.268741 ,train acc: 0.873678 ,val loss : 0.375689 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :294 ]train loss : 0.309123 ,train acc: 0.865021 ,val loss : 0.377304 ,val acc : 0.829010\n",
      "[ ecpho : 9  iter :295 ]train loss : 0.393798 ,train acc: 0.827596 ,val loss : 0.380754 ,val acc : 0.827026\n",
      "[ ecpho : 9  iter :296 ]train loss : 0.268006 ,train acc: 0.881836 ,val loss : 0.379153 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :297 ]train loss : 0.414071 ,train acc: 0.811188 ,val loss : 0.377602 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :298 ]train loss : 0.266660 ,train acc: 0.874939 ,val loss : 0.378168 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :299 ]train loss : 0.269090 ,train acc: 0.868367 ,val loss : 0.381205 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :300 ]train loss : 0.258806 ,train acc: 0.879313 ,val loss : 0.385813 ,val acc : 0.823975\n",
      "[ ecpho : 9  iter :301 ]train loss : 0.299080 ,train acc: 0.867666 ,val loss : 0.375174 ,val acc : 0.832397\n",
      "[ ecpho : 9  iter :302 ]train loss : 0.271600 ,train acc: 0.866160 ,val loss : 0.380380 ,val acc : 0.830933\n",
      "[ ecpho : 9  iter :303 ]train loss : 0.312447 ,train acc: 0.864227 ,val loss : 0.386455 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :304 ]train loss : 0.292628 ,train acc: 0.867544 ,val loss : 0.387475 ,val acc : 0.830963\n",
      "[ ecpho : 9  iter :305 ]train loss : 0.257044 ,train acc: 0.881480 ,val loss : 0.384439 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :306 ]train loss : 0.300736 ,train acc: 0.851644 ,val loss : 0.379488 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :307 ]train loss : 0.304057 ,train acc: 0.862417 ,val loss : 0.375203 ,val acc : 0.828369\n",
      "[ ecpho : 9  iter :308 ]train loss : 0.260347 ,train acc: 0.873403 ,val loss : 0.375729 ,val acc : 0.829132\n",
      "[ ecpho : 9  iter :309 ]train loss : 0.319967 ,train acc: 0.863658 ,val loss : 0.380828 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :310 ]train loss : 0.288124 ,train acc: 0.854340 ,val loss : 0.375812 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :311 ]train loss : 0.235269 ,train acc: 0.886617 ,val loss : 0.383094 ,val acc : 0.830627\n",
      "[ ecpho : 9  iter :312 ]train loss : 0.373938 ,train acc: 0.844147 ,val loss : 0.378041 ,val acc : 0.829651\n",
      "[ ecpho : 9  iter :313 ]train loss : 0.310380 ,train acc: 0.838501 ,val loss : 0.372127 ,val acc : 0.830078\n",
      "[ ecpho : 9  iter :314 ]train loss : 0.292828 ,train acc: 0.852773 ,val loss : 0.386761 ,val acc : 0.830933\n",
      "[ ecpho : 9  iter :315 ]train loss : 0.361909 ,train acc: 0.835846 ,val loss : 0.383663 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :316 ]train loss : 0.320221 ,train acc: 0.859690 ,val loss : 0.379231 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :317 ]train loss : 0.347149 ,train acc: 0.843079 ,val loss : 0.382288 ,val acc : 0.823730\n",
      "[ ecpho : 9  iter :318 ]train loss : 0.454823 ,train acc: 0.809377 ,val loss : 0.381285 ,val acc : 0.828979\n",
      "[ ecpho : 9  iter :319 ]train loss : 0.302851 ,train acc: 0.863719 ,val loss : 0.383575 ,val acc : 0.824890\n",
      "[ ecpho : 9  iter :320 ]train loss : 0.332515 ,train acc: 0.856344 ,val loss : 0.378785 ,val acc : 0.827942\n",
      "[ ecpho : 9  iter :321 ]train loss : 0.348465 ,train acc: 0.842651 ,val loss : 0.382894 ,val acc : 0.826355\n",
      "[ ecpho : 9  iter :322 ]train loss : 0.292355 ,train acc: 0.867900 ,val loss : 0.380833 ,val acc : 0.827484\n",
      "[ ecpho : 9  iter :323 ]train loss : 0.253196 ,train acc: 0.881561 ,val loss : 0.374812 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :324 ]train loss : 0.276890 ,train acc: 0.874613 ,val loss : 0.379862 ,val acc : 0.826324\n",
      "[ ecpho : 9  iter :325 ]train loss : 0.244822 ,train acc: 0.885681 ,val loss : 0.378157 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :326 ]train loss : 0.270788 ,train acc: 0.872223 ,val loss : 0.378559 ,val acc : 0.830750\n",
      "[ ecpho : 9  iter :327 ]train loss : 0.309773 ,train acc: 0.866272 ,val loss : 0.381439 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :328 ]train loss : 0.238106 ,train acc: 0.889119 ,val loss : 0.380167 ,val acc : 0.828735\n",
      "[ ecpho : 9  iter :329 ]train loss : 0.231492 ,train acc: 0.887166 ,val loss : 0.379617 ,val acc : 0.830322\n",
      "[ ecpho : 9  iter :330 ]train loss : 0.381766 ,train acc: 0.838776 ,val loss : 0.381327 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :331 ]train loss : 0.271713 ,train acc: 0.868907 ,val loss : 0.374332 ,val acc : 0.829987\n",
      "[ ecpho : 9  iter :332 ]train loss : 0.316868 ,train acc: 0.843547 ,val loss : 0.382695 ,val acc : 0.826080\n",
      "[ ecpho : 9  iter :333 ]train loss : 0.252286 ,train acc: 0.881877 ,val loss : 0.377157 ,val acc : 0.831451\n",
      "[ ecpho : 9  iter :334 ]train loss : 0.270639 ,train acc: 0.869893 ,val loss : 0.376590 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :335 ]train loss : 0.233010 ,train acc: 0.888906 ,val loss : 0.376538 ,val acc : 0.831635\n",
      "[ ecpho : 9  iter :336 ]train loss : 0.425129 ,train acc: 0.834951 ,val loss : 0.377648 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :337 ]train loss : 0.240046 ,train acc: 0.885020 ,val loss : 0.381333 ,val acc : 0.827606\n",
      "[ ecpho : 9  iter :338 ]train loss : 0.317552 ,train acc: 0.853740 ,val loss : 0.381405 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :339 ]train loss : 0.226500 ,train acc: 0.893412 ,val loss : 0.386304 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :340 ]train loss : 0.244384 ,train acc: 0.882365 ,val loss : 0.380221 ,val acc : 0.829376\n",
      "[ ecpho : 9  iter :341 ]train loss : 0.437639 ,train acc: 0.776713 ,val loss : 0.380159 ,val acc : 0.829498\n",
      "[ ecpho : 9  iter :342 ]train loss : 0.338117 ,train acc: 0.840342 ,val loss : 0.381510 ,val acc : 0.830292\n",
      "[ ecpho : 9  iter :343 ]train loss : 0.284678 ,train acc: 0.867218 ,val loss : 0.378720 ,val acc : 0.833405\n",
      "[ ecpho : 9  iter :344 ]train loss : 0.256109 ,train acc: 0.879822 ,val loss : 0.379319 ,val acc : 0.829010\n",
      "[ ecpho : 9  iter :345 ]train loss : 0.274805 ,train acc: 0.877208 ,val loss : 0.383346 ,val acc : 0.824646\n",
      "[ ecpho : 9  iter :346 ]train loss : 0.334711 ,train acc: 0.847483 ,val loss : 0.381597 ,val acc : 0.829010\n",
      "[ ecpho : 9  iter :347 ]train loss : 0.468027 ,train acc: 0.812571 ,val loss : 0.381692 ,val acc : 0.831055\n",
      "[ ecpho : 9  iter :348 ]train loss : 0.241871 ,train acc: 0.885559 ,val loss : 0.383783 ,val acc : 0.825836\n",
      "[ ecpho : 9  iter :349 ]train loss : 0.352994 ,train acc: 0.859609 ,val loss : 0.376104 ,val acc : 0.832306\n",
      "[ ecpho : 9  iter :350 ]train loss : 0.301410 ,train acc: 0.865743 ,val loss : 0.383837 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :351 ]train loss : 0.292987 ,train acc: 0.853251 ,val loss : 0.387110 ,val acc : 0.826202\n",
      "[ ecpho : 9  iter :352 ]train loss : 0.331972 ,train acc: 0.858775 ,val loss : 0.377199 ,val acc : 0.832092\n",
      "[ ecpho : 9  iter :353 ]train loss : 0.376951 ,train acc: 0.844116 ,val loss : 0.383174 ,val acc : 0.825989\n",
      "[ ecpho : 9  iter :354 ]train loss : 0.253201 ,train acc: 0.877309 ,val loss : 0.378838 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :355 ]train loss : 0.279623 ,train acc: 0.869670 ,val loss : 0.375809 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :356 ]train loss : 0.373744 ,train acc: 0.798442 ,val loss : 0.380920 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :357 ]train loss : 0.317168 ,train acc: 0.835225 ,val loss : 0.380646 ,val acc : 0.825867\n",
      "[ ecpho : 9  iter :358 ]train loss : 0.298943 ,train acc: 0.865712 ,val loss : 0.377342 ,val acc : 0.832001\n",
      "[ ecpho : 9  iter :359 ]train loss : 0.299346 ,train acc: 0.853150 ,val loss : 0.380522 ,val acc : 0.826294\n",
      "[ ecpho : 9  iter :360 ]train loss : 0.289602 ,train acc: 0.872375 ,val loss : 0.383671 ,val acc : 0.830231\n",
      "[ ecpho : 9  iter :361 ]train loss : 0.352403 ,train acc: 0.819570 ,val loss : 0.377559 ,val acc : 0.830963\n",
      "[ ecpho : 9  iter :362 ]train loss : 0.319076 ,train acc: 0.838867 ,val loss : 0.379019 ,val acc : 0.830139\n",
      "[ ecpho : 9  iter :363 ]train loss : 0.272650 ,train acc: 0.866486 ,val loss : 0.376416 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :364 ]train loss : 0.269743 ,train acc: 0.874980 ,val loss : 0.377905 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :365 ]train loss : 0.392235 ,train acc: 0.832225 ,val loss : 0.377615 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :366 ]train loss : 0.324560 ,train acc: 0.836121 ,val loss : 0.379544 ,val acc : 0.826508\n",
      "[ ecpho : 9  iter :367 ]train loss : 0.304443 ,train acc: 0.846751 ,val loss : 0.381108 ,val acc : 0.831329\n",
      "[ ecpho : 9  iter :368 ]train loss : 0.387427 ,train acc: 0.830323 ,val loss : 0.376332 ,val acc : 0.830414\n",
      "[ ecpho : 9  iter :369 ]train loss : 0.283805 ,train acc: 0.869863 ,val loss : 0.375668 ,val acc : 0.830902\n",
      "[ ecpho : 9  iter :370 ]train loss : 0.251853 ,train acc: 0.876536 ,val loss : 0.380354 ,val acc : 0.825958\n",
      "[ ecpho : 9  iter :371 ]train loss : 0.297657 ,train acc: 0.862823 ,val loss : 0.377871 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :372 ]train loss : 0.276332 ,train acc: 0.869649 ,val loss : 0.379476 ,val acc : 0.829010\n",
      "[ ecpho : 9  iter :373 ]train loss : 0.259542 ,train acc: 0.879771 ,val loss : 0.381095 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :374 ]train loss : 0.392448 ,train acc: 0.853699 ,val loss : 0.383541 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :375 ]train loss : 0.241938 ,train acc: 0.883535 ,val loss : 0.377544 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :376 ]train loss : 0.366987 ,train acc: 0.830760 ,val loss : 0.384879 ,val acc : 0.823730\n",
      "[ ecpho : 9  iter :377 ]train loss : 0.347149 ,train acc: 0.833008 ,val loss : 0.376897 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :378 ]train loss : 0.278099 ,train acc: 0.861766 ,val loss : 0.379536 ,val acc : 0.825867\n",
      "[ ecpho : 9  iter :379 ]train loss : 0.240363 ,train acc: 0.887695 ,val loss : 0.379550 ,val acc : 0.828766\n",
      "[ ecpho : 9  iter :380 ]train loss : 0.242255 ,train acc: 0.884165 ,val loss : 0.383720 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :381 ]train loss : 0.310479 ,train acc: 0.870534 ,val loss : 0.381126 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :382 ]train loss : 0.364619 ,train acc: 0.845947 ,val loss : 0.380828 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :383 ]train loss : 0.379706 ,train acc: 0.826681 ,val loss : 0.377266 ,val acc : 0.832489\n",
      "[ ecpho : 9  iter :384 ]train loss : 0.244368 ,train acc: 0.882762 ,val loss : 0.373970 ,val acc : 0.831055\n",
      "[ ecpho : 9  iter :385 ]train loss : 0.419156 ,train acc: 0.830750 ,val loss : 0.374592 ,val acc : 0.831604\n",
      "[ ecpho : 9  iter :386 ]train loss : 0.437633 ,train acc: 0.779246 ,val loss : 0.381290 ,val acc : 0.824890\n",
      "[ ecpho : 9  iter :387 ]train loss : 0.290134 ,train acc: 0.866547 ,val loss : 0.377894 ,val acc : 0.832031\n",
      "[ ecpho : 9  iter :388 ]train loss : 0.338060 ,train acc: 0.831838 ,val loss : 0.380700 ,val acc : 0.830109\n",
      "[ ecpho : 9  iter :389 ]train loss : 0.363637 ,train acc: 0.843994 ,val loss : 0.378990 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :390 ]train loss : 0.233079 ,train acc: 0.887248 ,val loss : 0.372894 ,val acc : 0.832001\n",
      "[ ecpho : 9  iter :391 ]train loss : 0.223019 ,train acc: 0.893372 ,val loss : 0.380315 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :392 ]train loss : 0.409464 ,train acc: 0.813680 ,val loss : 0.377448 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :393 ]train loss : 0.248275 ,train acc: 0.879151 ,val loss : 0.380881 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :394 ]train loss : 0.400120 ,train acc: 0.783824 ,val loss : 0.377902 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :395 ]train loss : 0.284336 ,train acc: 0.873250 ,val loss : 0.378404 ,val acc : 0.826935\n",
      "[ ecpho : 9  iter :396 ]train loss : 0.318464 ,train acc: 0.867788 ,val loss : 0.381734 ,val acc : 0.832520\n",
      "[ ecpho : 9  iter :397 ]train loss : 0.284265 ,train acc: 0.866750 ,val loss : 0.375941 ,val acc : 0.828949\n",
      "[ ecpho : 9  iter :398 ]train loss : 0.332881 ,train acc: 0.850820 ,val loss : 0.382930 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :399 ]train loss : 0.362702 ,train acc: 0.836924 ,val loss : 0.382075 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :400 ]train loss : 0.405409 ,train acc: 0.799744 ,val loss : 0.377379 ,val acc : 0.830780\n",
      "[ ecpho : 9  iter :401 ]train loss : 0.352450 ,train acc: 0.849487 ,val loss : 0.376178 ,val acc : 0.829498\n",
      "[ ecpho : 9  iter :402 ]train loss : 0.398469 ,train acc: 0.846954 ,val loss : 0.381208 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :403 ]train loss : 0.290371 ,train acc: 0.866923 ,val loss : 0.383231 ,val acc : 0.826355\n",
      "[ ecpho : 9  iter :404 ]train loss : 0.328031 ,train acc: 0.864248 ,val loss : 0.377233 ,val acc : 0.826813\n",
      "[ ecpho : 9  iter :405 ]train loss : 0.356191 ,train acc: 0.816712 ,val loss : 0.380412 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :406 ]train loss : 0.523216 ,train acc: 0.826070 ,val loss : 0.381827 ,val acc : 0.826019\n",
      "[ ecpho : 9  iter :407 ]train loss : 0.336368 ,train acc: 0.847697 ,val loss : 0.375735 ,val acc : 0.829773\n",
      "[ ecpho : 9  iter :408 ]train loss : 0.355675 ,train acc: 0.819896 ,val loss : 0.383184 ,val acc : 0.826233\n",
      "[ ecpho : 9  iter :409 ]train loss : 0.303760 ,train acc: 0.855886 ,val loss : 0.378257 ,val acc : 0.827667\n",
      "[ ecpho : 9  iter :410 ]train loss : 0.284022 ,train acc: 0.869354 ,val loss : 0.386233 ,val acc : 0.825043\n",
      "[ ecpho : 9  iter :411 ]train loss : 0.312585 ,train acc: 0.865885 ,val loss : 0.374867 ,val acc : 0.831696\n",
      "[ ecpho : 9  iter :412 ]train loss : 0.265185 ,train acc: 0.876160 ,val loss : 0.377210 ,val acc : 0.825989\n",
      "[ ecpho : 9  iter :413 ]train loss : 0.237072 ,train acc: 0.885569 ,val loss : 0.383598 ,val acc : 0.826233\n",
      "[ ecpho : 9  iter :414 ]train loss : 0.309156 ,train acc: 0.836273 ,val loss : 0.375314 ,val acc : 0.830780\n",
      "[ ecpho : 9  iter :415 ]train loss : 0.285315 ,train acc: 0.861461 ,val loss : 0.378828 ,val acc : 0.831787\n",
      "[ ecpho : 9  iter :416 ]train loss : 0.282806 ,train acc: 0.865377 ,val loss : 0.379042 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :417 ]train loss : 0.302502 ,train acc: 0.862905 ,val loss : 0.380026 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :418 ]train loss : 0.412669 ,train acc: 0.853353 ,val loss : 0.377247 ,val acc : 0.830475\n",
      "[ ecpho : 9  iter :419 ]train loss : 0.377890 ,train acc: 0.833089 ,val loss : 0.379157 ,val acc : 0.830811\n",
      "[ ecpho : 9  iter :420 ]train loss : 0.297577 ,train acc: 0.871755 ,val loss : 0.377715 ,val acc : 0.828857\n",
      "[ ecpho : 9  iter :421 ]train loss : 0.241698 ,train acc: 0.885183 ,val loss : 0.383085 ,val acc : 0.827728\n",
      "[ ecpho : 9  iter :422 ]train loss : 0.242782 ,train acc: 0.884552 ,val loss : 0.384839 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :423 ]train loss : 0.304969 ,train acc: 0.858317 ,val loss : 0.380585 ,val acc : 0.829010\n",
      "[ ecpho : 9  iter :424 ]train loss : 0.322144 ,train acc: 0.830444 ,val loss : 0.380651 ,val acc : 0.827637\n",
      "[ ecpho : 9  iter :425 ]train loss : 0.456818 ,train acc: 0.828308 ,val loss : 0.380918 ,val acc : 0.828064\n",
      "[ ecpho : 9  iter :426 ]train loss : 0.294560 ,train acc: 0.850952 ,val loss : 0.373701 ,val acc : 0.828949\n",
      "[ ecpho : 9  iter :427 ]train loss : 0.343772 ,train acc: 0.851705 ,val loss : 0.380026 ,val acc : 0.826965\n",
      "[ ecpho : 9  iter :428 ]train loss : 0.262186 ,train acc: 0.877747 ,val loss : 0.381158 ,val acc : 0.833527\n",
      "[ ecpho : 9  iter :429 ]train loss : 0.463948 ,train acc: 0.739380 ,val loss : 0.379032 ,val acc : 0.831390\n",
      "[ ecpho : 9  iter :430 ]train loss : 0.267844 ,train acc: 0.873576 ,val loss : 0.386003 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :431 ]train loss : 0.359115 ,train acc: 0.819245 ,val loss : 0.379620 ,val acc : 0.828064\n",
      "[ ecpho : 9  iter :432 ]train loss : 0.262115 ,train acc: 0.878459 ,val loss : 0.389586 ,val acc : 0.824707\n",
      "[ ecpho : 9  iter :433 ]train loss : 0.261465 ,train acc: 0.873108 ,val loss : 0.376674 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :434 ]train loss : 0.227771 ,train acc: 0.890554 ,val loss : 0.376311 ,val acc : 0.831451\n",
      "[ ecpho : 9  iter :435 ]train loss : 0.262807 ,train acc: 0.872284 ,val loss : 0.379489 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :436 ]train loss : 0.376300 ,train acc: 0.849243 ,val loss : 0.384358 ,val acc : 0.827484\n",
      "[ ecpho : 9  iter :437 ]train loss : 0.281216 ,train acc: 0.863312 ,val loss : 0.378641 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :438 ]train loss : 0.342192 ,train acc: 0.851227 ,val loss : 0.380347 ,val acc : 0.828857\n",
      "[ ecpho : 9  iter :439 ]train loss : 0.234057 ,train acc: 0.888214 ,val loss : 0.379328 ,val acc : 0.828064\n",
      "[ ecpho : 9  iter :440 ]train loss : 0.239012 ,train acc: 0.883586 ,val loss : 0.376846 ,val acc : 0.830139\n",
      "[ ecpho : 9  iter :441 ]train loss : 0.357276 ,train acc: 0.855367 ,val loss : 0.376934 ,val acc : 0.828735\n",
      "[ ecpho : 9  iter :442 ]train loss : 0.508667 ,train acc: 0.826955 ,val loss : 0.378930 ,val acc : 0.828735\n",
      "[ ecpho : 9  iter :443 ]train loss : 0.327269 ,train acc: 0.854299 ,val loss : 0.374480 ,val acc : 0.828522\n",
      "[ ecpho : 9  iter :444 ]train loss : 0.272630 ,train acc: 0.866506 ,val loss : 0.378477 ,val acc : 0.830231\n",
      "[ ecpho : 9  iter :445 ]train loss : 0.292601 ,train acc: 0.863800 ,val loss : 0.382282 ,val acc : 0.831390\n",
      "[ ecpho : 9  iter :446 ]train loss : 0.265784 ,train acc: 0.879283 ,val loss : 0.382874 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :447 ]train loss : 0.345297 ,train acc: 0.854828 ,val loss : 0.383452 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :448 ]train loss : 0.332864 ,train acc: 0.833110 ,val loss : 0.379478 ,val acc : 0.826874\n",
      "[ ecpho : 9  iter :449 ]train loss : 0.256423 ,train acc: 0.878550 ,val loss : 0.377152 ,val acc : 0.830536\n",
      "[ ecpho : 9  iter :450 ]train loss : 0.320940 ,train acc: 0.850240 ,val loss : 0.381201 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :451 ]train loss : 0.435806 ,train acc: 0.819906 ,val loss : 0.375352 ,val acc : 0.829254\n",
      "[ ecpho : 9  iter :452 ]train loss : 0.253021 ,train acc: 0.880737 ,val loss : 0.380676 ,val acc : 0.830231\n",
      "[ ecpho : 9  iter :453 ]train loss : 0.265075 ,train acc: 0.876678 ,val loss : 0.378804 ,val acc : 0.829376\n",
      "[ ecpho : 9  iter :454 ]train loss : 0.426707 ,train acc: 0.797791 ,val loss : 0.382124 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :455 ]train loss : 0.379304 ,train acc: 0.804108 ,val loss : 0.376146 ,val acc : 0.832397\n",
      "[ ecpho : 9  iter :456 ]train loss : 0.299837 ,train acc: 0.847412 ,val loss : 0.378375 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :457 ]train loss : 0.299881 ,train acc: 0.856334 ,val loss : 0.383386 ,val acc : 0.825653\n",
      "[ ecpho : 9  iter :458 ]train loss : 0.357316 ,train acc: 0.820831 ,val loss : 0.382242 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :459 ]train loss : 0.298088 ,train acc: 0.851369 ,val loss : 0.379579 ,val acc : 0.832184\n",
      "[ ecpho : 9  iter :460 ]train loss : 0.288640 ,train acc: 0.864268 ,val loss : 0.379509 ,val acc : 0.830231\n",
      "[ ecpho : 9  iter :461 ]train loss : 0.337875 ,train acc: 0.856232 ,val loss : 0.383126 ,val acc : 0.827026\n",
      "[ ecpho : 9  iter :462 ]train loss : 0.257282 ,train acc: 0.876038 ,val loss : 0.378163 ,val acc : 0.831604\n",
      "[ ecpho : 9  iter :463 ]train loss : 0.367582 ,train acc: 0.826203 ,val loss : 0.383472 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :464 ]train loss : 0.360938 ,train acc: 0.841573 ,val loss : 0.379054 ,val acc : 0.827606\n",
      "[ ecpho : 9  iter :465 ]train loss : 0.516139 ,train acc: 0.814230 ,val loss : 0.380926 ,val acc : 0.826569\n",
      "[ ecpho : 9  iter :466 ]train loss : 0.276946 ,train acc: 0.871928 ,val loss : 0.381029 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :467 ]train loss : 0.273034 ,train acc: 0.868398 ,val loss : 0.386170 ,val acc : 0.829437\n",
      "[ ecpho : 9  iter :468 ]train loss : 0.287976 ,train acc: 0.865285 ,val loss : 0.379174 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :469 ]train loss : 0.260007 ,train acc: 0.874024 ,val loss : 0.375648 ,val acc : 0.828949\n",
      "[ ecpho : 9  iter :470 ]train loss : 0.243588 ,train acc: 0.883250 ,val loss : 0.376540 ,val acc : 0.829437\n",
      "[ ecpho : 9  iter :471 ]train loss : 0.297732 ,train acc: 0.869670 ,val loss : 0.376983 ,val acc : 0.829407\n",
      "[ ecpho : 9  iter :472 ]train loss : 0.341621 ,train acc: 0.833740 ,val loss : 0.381355 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :473 ]train loss : 0.274174 ,train acc: 0.867615 ,val loss : 0.381739 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :474 ]train loss : 0.426005 ,train acc: 0.802724 ,val loss : 0.382059 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :475 ]train loss : 0.262612 ,train acc: 0.873871 ,val loss : 0.385461 ,val acc : 0.827332\n",
      "[ ecpho : 9  iter :476 ]train loss : 0.429249 ,train acc: 0.841237 ,val loss : 0.379565 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :477 ]train loss : 0.318154 ,train acc: 0.856069 ,val loss : 0.378087 ,val acc : 0.831360\n",
      "[ ecpho : 9  iter :478 ]train loss : 0.341894 ,train acc: 0.854920 ,val loss : 0.375459 ,val acc : 0.832062\n",
      "[ ecpho : 9  iter :479 ]train loss : 0.290197 ,train acc: 0.869853 ,val loss : 0.381462 ,val acc : 0.828674\n",
      "[ ecpho : 9  iter :480 ]train loss : 0.307321 ,train acc: 0.853322 ,val loss : 0.382602 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :481 ]train loss : 0.293951 ,train acc: 0.853617 ,val loss : 0.379543 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :482 ]train loss : 0.273246 ,train acc: 0.876638 ,val loss : 0.375448 ,val acc : 0.830383\n",
      "[ ecpho : 9  iter :483 ]train loss : 0.290760 ,train acc: 0.864482 ,val loss : 0.382727 ,val acc : 0.827148\n",
      "[ ecpho : 9  iter :484 ]train loss : 0.365928 ,train acc: 0.845632 ,val loss : 0.376233 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :485 ]train loss : 0.336408 ,train acc: 0.852010 ,val loss : 0.378139 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :486 ]train loss : 0.345753 ,train acc: 0.849925 ,val loss : 0.381866 ,val acc : 0.826477\n",
      "[ ecpho : 9  iter :487 ]train loss : 0.266566 ,train acc: 0.872030 ,val loss : 0.378903 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :488 ]train loss : 0.267633 ,train acc: 0.870799 ,val loss : 0.379125 ,val acc : 0.832092\n",
      "[ ecpho : 9  iter :489 ]train loss : 0.325836 ,train acc: 0.822347 ,val loss : 0.376515 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :490 ]train loss : 0.380517 ,train acc: 0.807373 ,val loss : 0.379073 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :491 ]train loss : 0.343740 ,train acc: 0.849467 ,val loss : 0.378331 ,val acc : 0.830872\n",
      "[ ecpho : 9  iter :492 ]train loss : 0.266861 ,train acc: 0.873301 ,val loss : 0.380893 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :493 ]train loss : 0.247428 ,train acc: 0.880432 ,val loss : 0.382919 ,val acc : 0.826660\n",
      "[ ecpho : 9  iter :494 ]train loss : 0.265134 ,train acc: 0.873444 ,val loss : 0.374834 ,val acc : 0.831696\n",
      "[ ecpho : 9  iter :495 ]train loss : 0.236493 ,train acc: 0.883199 ,val loss : 0.378536 ,val acc : 0.830444\n",
      "[ ecpho : 9  iter :496 ]train loss : 0.255142 ,train acc: 0.879842 ,val loss : 0.380961 ,val acc : 0.829346\n",
      "[ ecpho : 9  iter :497 ]train loss : 0.366391 ,train acc: 0.847799 ,val loss : 0.378207 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :498 ]train loss : 0.256692 ,train acc: 0.874939 ,val loss : 0.375357 ,val acc : 0.831696\n",
      "[ ecpho : 9  iter :499 ]train loss : 0.278742 ,train acc: 0.872498 ,val loss : 0.378929 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :500 ]train loss : 0.307685 ,train acc: 0.865336 ,val loss : 0.379784 ,val acc : 0.825897\n",
      "[ ecpho : 9  iter :501 ]train loss : 0.319306 ,train acc: 0.842407 ,val loss : 0.380464 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :502 ]train loss : 0.362598 ,train acc: 0.813802 ,val loss : 0.379814 ,val acc : 0.830353\n",
      "[ ecpho : 9  iter :503 ]train loss : 0.243943 ,train acc: 0.884633 ,val loss : 0.384812 ,val acc : 0.826080\n",
      "[ ecpho : 9  iter :504 ]train loss : 0.265294 ,train acc: 0.874634 ,val loss : 0.376243 ,val acc : 0.828369\n",
      "[ ecpho : 9  iter :505 ]train loss : 0.327907 ,train acc: 0.853027 ,val loss : 0.375597 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :506 ]train loss : 0.305513 ,train acc: 0.858785 ,val loss : 0.380376 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :507 ]train loss : 0.253023 ,train acc: 0.877004 ,val loss : 0.381011 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :508 ]train loss : 0.242657 ,train acc: 0.886790 ,val loss : 0.377132 ,val acc : 0.827179\n",
      "[ ecpho : 9  iter :509 ]train loss : 0.233113 ,train acc: 0.887146 ,val loss : 0.380261 ,val acc : 0.830536\n",
      "[ ecpho : 9  iter :510 ]train loss : 0.458169 ,train acc: 0.807963 ,val loss : 0.377599 ,val acc : 0.828705\n",
      "[ ecpho : 9  iter :511 ]train loss : 0.415458 ,train acc: 0.825562 ,val loss : 0.377564 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :512 ]train loss : 0.253525 ,train acc: 0.876729 ,val loss : 0.378448 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :513 ]train loss : 0.248247 ,train acc: 0.881765 ,val loss : 0.378468 ,val acc : 0.824524\n",
      "[ ecpho : 9  iter :514 ]train loss : 0.290918 ,train acc: 0.868907 ,val loss : 0.374806 ,val acc : 0.828369\n",
      "[ ecpho : 9  iter :515 ]train loss : 0.290891 ,train acc: 0.863241 ,val loss : 0.385136 ,val acc : 0.827332\n",
      "[ ecpho : 9  iter :516 ]train loss : 0.272709 ,train acc: 0.871958 ,val loss : 0.380445 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :517 ]train loss : 0.336005 ,train acc: 0.843038 ,val loss : 0.380594 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :518 ]train loss : 0.272695 ,train acc: 0.874725 ,val loss : 0.375177 ,val acc : 0.830597\n",
      "[ ecpho : 9  iter :519 ]train loss : 0.348352 ,train acc: 0.834361 ,val loss : 0.380753 ,val acc : 0.827942\n",
      "[ ecpho : 9  iter :520 ]train loss : 0.251737 ,train acc: 0.881795 ,val loss : 0.374842 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :521 ]train loss : 0.508368 ,train acc: 0.835317 ,val loss : 0.381053 ,val acc : 0.826385\n",
      "[ ecpho : 9  iter :522 ]train loss : 0.256056 ,train acc: 0.878499 ,val loss : 0.380504 ,val acc : 0.826935\n",
      "[ ecpho : 9  iter :523 ]train loss : 0.327538 ,train acc: 0.833832 ,val loss : 0.382871 ,val acc : 0.827362\n",
      "[ ecpho : 9  iter :524 ]train loss : 0.311832 ,train acc: 0.841309 ,val loss : 0.380472 ,val acc : 0.829132\n",
      "[ ecpho : 9  iter :525 ]train loss : 0.301619 ,train acc: 0.868642 ,val loss : 0.382062 ,val acc : 0.828369\n",
      "[ ecpho : 9  iter :526 ]train loss : 0.383442 ,train acc: 0.806641 ,val loss : 0.372803 ,val acc : 0.831787\n",
      "[ ecpho : 9  iter :527 ]train loss : 0.286201 ,train acc: 0.861735 ,val loss : 0.383981 ,val acc : 0.827423\n",
      "[ ecpho : 9  iter :528 ]train loss : 0.331164 ,train acc: 0.852132 ,val loss : 0.381758 ,val acc : 0.825623\n",
      "[ ecpho : 9  iter :529 ]train loss : 0.285063 ,train acc: 0.868581 ,val loss : 0.378577 ,val acc : 0.829346\n",
      "[ ecpho : 9  iter :530 ]train loss : 0.334787 ,train acc: 0.857788 ,val loss : 0.378026 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :531 ]train loss : 0.349036 ,train acc: 0.855215 ,val loss : 0.378695 ,val acc : 0.829163\n",
      "[ ecpho : 9  iter :532 ]train loss : 0.255408 ,train acc: 0.881622 ,val loss : 0.377948 ,val acc : 0.829773\n",
      "[ ecpho : 9  iter :533 ]train loss : 0.352851 ,train acc: 0.846751 ,val loss : 0.384321 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :534 ]train loss : 0.229303 ,train acc: 0.891500 ,val loss : 0.374423 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :535 ]train loss : 0.271481 ,train acc: 0.876862 ,val loss : 0.382567 ,val acc : 0.830017\n",
      "[ ecpho : 9  iter :536 ]train loss : 0.255545 ,train acc: 0.873952 ,val loss : 0.380681 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :537 ]train loss : 0.298784 ,train acc: 0.867473 ,val loss : 0.378108 ,val acc : 0.829285\n",
      "[ ecpho : 9  iter :538 ]train loss : 0.244714 ,train acc: 0.884664 ,val loss : 0.376819 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :539 ]train loss : 0.294751 ,train acc: 0.866964 ,val loss : 0.380758 ,val acc : 0.826355\n",
      "[ ecpho : 9  iter :540 ]train loss : 0.240330 ,train acc: 0.887075 ,val loss : 0.377887 ,val acc : 0.829468\n",
      "[ ecpho : 9  iter :541 ]train loss : 0.394889 ,train acc: 0.751180 ,val loss : 0.380299 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :542 ]train loss : 0.244131 ,train acc: 0.882935 ,val loss : 0.374304 ,val acc : 0.831268\n",
      "[ ecpho : 9  iter :543 ]train loss : 0.287902 ,train acc: 0.854360 ,val loss : 0.379126 ,val acc : 0.828949\n",
      "[ ecpho : 9  iter :544 ]train loss : 0.348898 ,train acc: 0.827576 ,val loss : 0.379456 ,val acc : 0.831818\n",
      "[ ecpho : 9  iter :545 ]train loss : 0.288022 ,train acc: 0.870422 ,val loss : 0.372693 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :546 ]train loss : 0.278656 ,train acc: 0.872803 ,val loss : 0.379507 ,val acc : 0.827759\n",
      "[ ecpho : 9  iter :547 ]train loss : 0.371977 ,train acc: 0.858521 ,val loss : 0.374291 ,val acc : 0.829132\n",
      "[ ecpho : 9  iter :548 ]train loss : 0.287337 ,train acc: 0.869955 ,val loss : 0.376022 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :549 ]train loss : 0.287143 ,train acc: 0.869690 ,val loss : 0.382216 ,val acc : 0.830627\n",
      "[ ecpho : 9  iter :550 ]train loss : 0.267373 ,train acc: 0.872782 ,val loss : 0.379554 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :551 ]train loss : 0.266888 ,train acc: 0.870534 ,val loss : 0.377373 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :552 ]train loss : 0.361786 ,train acc: 0.824890 ,val loss : 0.380783 ,val acc : 0.826233\n",
      "[ ecpho : 9  iter :553 ]train loss : 0.331023 ,train acc: 0.825806 ,val loss : 0.376637 ,val acc : 0.829163\n",
      "[ ecpho : 9  iter :554 ]train loss : 0.249832 ,train acc: 0.882772 ,val loss : 0.382524 ,val acc : 0.829468\n",
      "[ ecpho : 9  iter :555 ]train loss : 0.361050 ,train acc: 0.794322 ,val loss : 0.378752 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :556 ]train loss : 0.264723 ,train acc: 0.874908 ,val loss : 0.376094 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :557 ]train loss : 0.359599 ,train acc: 0.832845 ,val loss : 0.380181 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :558 ]train loss : 0.261859 ,train acc: 0.879150 ,val loss : 0.371731 ,val acc : 0.833252\n",
      "[ ecpho : 9  iter :559 ]train loss : 0.302470 ,train acc: 0.868154 ,val loss : 0.381764 ,val acc : 0.827087\n",
      "[ ecpho : 9  iter :560 ]train loss : 0.274822 ,train acc: 0.867849 ,val loss : 0.378792 ,val acc : 0.831787\n",
      "[ ecpho : 9  iter :561 ]train loss : 0.265145 ,train acc: 0.877635 ,val loss : 0.385385 ,val acc : 0.827942\n",
      "[ ecpho : 9  iter :562 ]train loss : 0.284116 ,train acc: 0.863190 ,val loss : 0.381408 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :563 ]train loss : 0.248199 ,train acc: 0.882772 ,val loss : 0.381414 ,val acc : 0.827606\n",
      "[ ecpho : 9  iter :564 ]train loss : 0.299213 ,train acc: 0.862742 ,val loss : 0.379041 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :565 ]train loss : 0.304834 ,train acc: 0.862295 ,val loss : 0.377667 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :566 ]train loss : 0.264881 ,train acc: 0.880992 ,val loss : 0.376489 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :567 ]train loss : 0.235494 ,train acc: 0.886637 ,val loss : 0.379812 ,val acc : 0.826965\n",
      "[ ecpho : 9  iter :568 ]train loss : 0.277093 ,train acc: 0.873342 ,val loss : 0.380606 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :569 ]train loss : 0.290593 ,train acc: 0.843140 ,val loss : 0.376931 ,val acc : 0.830322\n",
      "[ ecpho : 9  iter :570 ]train loss : 0.395728 ,train acc: 0.788127 ,val loss : 0.376574 ,val acc : 0.826721\n",
      "[ ecpho : 9  iter :571 ]train loss : 0.227567 ,train acc: 0.891632 ,val loss : 0.380606 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :572 ]train loss : 0.309437 ,train acc: 0.857951 ,val loss : 0.377421 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :573 ]train loss : 0.308645 ,train acc: 0.863841 ,val loss : 0.380046 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :574 ]train loss : 0.279296 ,train acc: 0.871216 ,val loss : 0.379776 ,val acc : 0.828094\n",
      "[ ecpho : 9  iter :575 ]train loss : 0.404249 ,train acc: 0.805308 ,val loss : 0.377052 ,val acc : 0.830597\n",
      "[ ecpho : 9  iter :576 ]train loss : 0.224139 ,train acc: 0.891876 ,val loss : 0.377030 ,val acc : 0.829803\n",
      "[ ecpho : 9  iter :577 ]train loss : 0.265451 ,train acc: 0.877452 ,val loss : 0.375399 ,val acc : 0.829590\n",
      "[ ecpho : 9  iter :578 ]train loss : 0.314203 ,train acc: 0.855235 ,val loss : 0.378755 ,val acc : 0.832611\n",
      "[ ecpho : 9  iter :579 ]train loss : 0.312992 ,train acc: 0.863352 ,val loss : 0.382744 ,val acc : 0.830566\n",
      "[ ecpho : 9  iter :580 ]train loss : 0.244863 ,train acc: 0.885447 ,val loss : 0.374776 ,val acc : 0.833160\n",
      "[ ecpho : 9  iter :581 ]train loss : 0.253959 ,train acc: 0.876872 ,val loss : 0.385663 ,val acc : 0.826416\n",
      "[ ecpho : 9  iter :582 ]train loss : 0.266145 ,train acc: 0.876109 ,val loss : 0.381317 ,val acc : 0.829041\n",
      "[ ecpho : 9  iter :583 ]train loss : 0.277435 ,train acc: 0.870138 ,val loss : 0.374695 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :584 ]train loss : 0.264890 ,train acc: 0.870565 ,val loss : 0.384629 ,val acc : 0.823730\n",
      "[ ecpho : 9  iter :585 ]train loss : 0.253505 ,train acc: 0.881887 ,val loss : 0.377383 ,val acc : 0.832123\n",
      "[ ecpho : 9  iter :586 ]train loss : 0.309372 ,train acc: 0.838125 ,val loss : 0.374614 ,val acc : 0.829956\n",
      "[ ecpho : 9  iter :587 ]train loss : 0.270267 ,train acc: 0.868805 ,val loss : 0.383813 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :588 ]train loss : 0.258203 ,train acc: 0.876567 ,val loss : 0.377227 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :589 ]train loss : 0.297117 ,train acc: 0.857768 ,val loss : 0.377633 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :590 ]train loss : 0.349814 ,train acc: 0.847961 ,val loss : 0.382823 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :591 ]train loss : 0.416376 ,train acc: 0.810822 ,val loss : 0.375876 ,val acc : 0.833069\n",
      "[ ecpho : 9  iter :592 ]train loss : 0.336848 ,train acc: 0.860026 ,val loss : 0.380126 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :593 ]train loss : 0.241146 ,train acc: 0.883016 ,val loss : 0.377205 ,val acc : 0.828979\n",
      "[ ecpho : 9  iter :594 ]train loss : 0.265015 ,train acc: 0.873067 ,val loss : 0.380717 ,val acc : 0.829346\n",
      "[ ecpho : 9  iter :595 ]train loss : 0.358710 ,train acc: 0.853699 ,val loss : 0.378615 ,val acc : 0.828705\n",
      "[ ecpho : 9  iter :596 ]train loss : 0.288061 ,train acc: 0.862834 ,val loss : 0.380895 ,val acc : 0.827332\n",
      "[ ecpho : 9  iter :597 ]train loss : 0.343202 ,train acc: 0.844147 ,val loss : 0.376186 ,val acc : 0.830658\n",
      "[ ecpho : 9  iter :598 ]train loss : 0.300267 ,train acc: 0.859884 ,val loss : 0.384768 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :599 ]train loss : 0.292235 ,train acc: 0.866923 ,val loss : 0.382041 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :600 ]train loss : 0.399931 ,train acc: 0.785655 ,val loss : 0.378570 ,val acc : 0.826599\n",
      "[ ecpho : 9  iter :601 ]train loss : 0.352657 ,train acc: 0.846955 ,val loss : 0.378746 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :602 ]train loss : 0.313453 ,train acc: 0.861277 ,val loss : 0.375362 ,val acc : 0.832062\n",
      "[ ecpho : 9  iter :603 ]train loss : 0.332475 ,train acc: 0.832632 ,val loss : 0.377349 ,val acc : 0.826965\n",
      "[ ecpho : 9  iter :604 ]train loss : 0.262647 ,train acc: 0.873108 ,val loss : 0.381309 ,val acc : 0.825806\n",
      "[ ecpho : 9  iter :605 ]train loss : 0.296578 ,train acc: 0.861257 ,val loss : 0.380875 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :606 ]train loss : 0.220825 ,train acc: 0.893992 ,val loss : 0.383813 ,val acc : 0.826538\n",
      "[ ecpho : 9  iter :607 ]train loss : 0.333075 ,train acc: 0.835561 ,val loss : 0.383446 ,val acc : 0.828979\n",
      "[ ecpho : 9  iter :608 ]train loss : 0.230698 ,train acc: 0.888662 ,val loss : 0.381126 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :609 ]train loss : 0.312125 ,train acc: 0.842031 ,val loss : 0.382785 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :610 ]train loss : 0.278649 ,train acc: 0.870656 ,val loss : 0.379234 ,val acc : 0.830505\n",
      "[ ecpho : 9  iter :611 ]train loss : 0.324136 ,train acc: 0.847901 ,val loss : 0.374655 ,val acc : 0.830292\n",
      "[ ecpho : 9  iter :612 ]train loss : 0.271016 ,train acc: 0.870189 ,val loss : 0.379273 ,val acc : 0.830627\n",
      "[ ecpho : 9  iter :613 ]train loss : 0.238688 ,train acc: 0.887695 ,val loss : 0.380339 ,val acc : 0.826538\n",
      "[ ecpho : 9  iter :614 ]train loss : 0.273407 ,train acc: 0.873759 ,val loss : 0.381144 ,val acc : 0.827667\n",
      "[ ecpho : 9  iter :615 ]train loss : 0.293826 ,train acc: 0.859273 ,val loss : 0.376062 ,val acc : 0.831329\n",
      "[ ecpho : 9  iter :616 ]train loss : 0.226453 ,train acc: 0.890676 ,val loss : 0.374403 ,val acc : 0.831726\n",
      "[ ecpho : 9  iter :617 ]train loss : 0.253294 ,train acc: 0.878276 ,val loss : 0.380879 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :618 ]train loss : 0.373037 ,train acc: 0.786204 ,val loss : 0.381716 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :619 ]train loss : 0.243593 ,train acc: 0.885762 ,val loss : 0.380393 ,val acc : 0.829315\n",
      "[ ecpho : 9  iter :620 ]train loss : 0.331556 ,train acc: 0.857259 ,val loss : 0.383962 ,val acc : 0.829163\n",
      "[ ecpho : 9  iter :621 ]train loss : 0.462854 ,train acc: 0.816956 ,val loss : 0.380849 ,val acc : 0.832245\n",
      "[ ecpho : 9  iter :622 ]train loss : 0.278739 ,train acc: 0.873159 ,val loss : 0.378914 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :623 ]train loss : 0.307428 ,train acc: 0.863770 ,val loss : 0.378111 ,val acc : 0.829315\n",
      "[ ecpho : 9  iter :624 ]train loss : 0.351923 ,train acc: 0.859680 ,val loss : 0.378410 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :625 ]train loss : 0.345324 ,train acc: 0.841828 ,val loss : 0.378533 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :626 ]train loss : 0.282046 ,train acc: 0.871725 ,val loss : 0.378199 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :627 ]train loss : 0.334925 ,train acc: 0.859507 ,val loss : 0.384427 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :628 ]train loss : 0.332571 ,train acc: 0.858012 ,val loss : 0.389278 ,val acc : 0.824860\n",
      "[ ecpho : 9  iter :629 ]train loss : 0.446235 ,train acc: 0.736725 ,val loss : 0.376320 ,val acc : 0.828735\n",
      "[ ecpho : 9  iter :630 ]train loss : 0.279127 ,train acc: 0.857432 ,val loss : 0.378877 ,val acc : 0.832672\n",
      "[ ecpho : 9  iter :631 ]train loss : 0.389728 ,train acc: 0.846507 ,val loss : 0.380773 ,val acc : 0.827545\n",
      "[ ecpho : 9  iter :632 ]train loss : 0.259036 ,train acc: 0.875000 ,val loss : 0.374411 ,val acc : 0.830109\n",
      "[ ecpho : 9  iter :633 ]train loss : 0.270526 ,train acc: 0.867310 ,val loss : 0.380109 ,val acc : 0.830200\n",
      "[ ecpho : 9  iter :634 ]train loss : 0.240367 ,train acc: 0.885925 ,val loss : 0.376949 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :635 ]train loss : 0.298278 ,train acc: 0.864115 ,val loss : 0.378923 ,val acc : 0.827484\n",
      "[ ecpho : 9  iter :636 ]train loss : 0.316537 ,train acc: 0.867391 ,val loss : 0.372296 ,val acc : 0.830139\n",
      "[ ecpho : 9  iter :637 ]train loss : 0.301335 ,train acc: 0.864919 ,val loss : 0.385001 ,val acc : 0.824493\n",
      "[ ecpho : 9  iter :638 ]train loss : 0.299262 ,train acc: 0.857473 ,val loss : 0.378524 ,val acc : 0.828735\n",
      "[ ecpho : 9  iter :639 ]train loss : 0.303318 ,train acc: 0.861623 ,val loss : 0.384235 ,val acc : 0.826843\n",
      "[ ecpho : 9  iter :640 ]train loss : 0.323612 ,train acc: 0.864034 ,val loss : 0.381578 ,val acc : 0.826630\n",
      "[ ecpho : 9  iter :641 ]train loss : 0.417159 ,train acc: 0.846914 ,val loss : 0.378768 ,val acc : 0.829987\n",
      "[ ecpho : 9  iter :642 ]train loss : 0.265541 ,train acc: 0.881897 ,val loss : 0.377349 ,val acc : 0.825775\n",
      "[ ecpho : 9  iter :643 ]train loss : 0.320278 ,train acc: 0.857870 ,val loss : 0.379258 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :644 ]train loss : 0.253945 ,train acc: 0.878510 ,val loss : 0.376132 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :645 ]train loss : 0.267205 ,train acc: 0.868276 ,val loss : 0.378793 ,val acc : 0.826324\n",
      "[ ecpho : 9  iter :646 ]train loss : 0.334630 ,train acc: 0.847656 ,val loss : 0.378580 ,val acc : 0.826202\n",
      "[ ecpho : 9  iter :647 ]train loss : 0.282567 ,train acc: 0.875610 ,val loss : 0.384416 ,val acc : 0.829102\n",
      "[ ecpho : 9  iter :648 ]train loss : 0.371929 ,train acc: 0.790314 ,val loss : 0.383167 ,val acc : 0.827332\n",
      "[ ecpho : 9  iter :649 ]train loss : 0.357812 ,train acc: 0.849487 ,val loss : 0.383672 ,val acc : 0.825134\n",
      "[ ecpho : 9  iter :650 ]train loss : 0.320754 ,train acc: 0.844361 ,val loss : 0.374791 ,val acc : 0.829498\n",
      "[ ecpho : 9  iter :651 ]train loss : 0.298817 ,train acc: 0.852804 ,val loss : 0.379007 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :652 ]train loss : 0.274338 ,train acc: 0.872976 ,val loss : 0.378944 ,val acc : 0.826233\n",
      "[ ecpho : 9  iter :653 ]train loss : 0.318633 ,train acc: 0.857737 ,val loss : 0.380389 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :654 ]train loss : 0.468160 ,train acc: 0.688497 ,val loss : 0.382613 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :655 ]train loss : 0.334488 ,train acc: 0.832581 ,val loss : 0.380627 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :656 ]train loss : 0.326093 ,train acc: 0.838308 ,val loss : 0.379425 ,val acc : 0.828857\n",
      "[ ecpho : 9  iter :657 ]train loss : 0.265702 ,train acc: 0.871185 ,val loss : 0.380932 ,val acc : 0.826874\n",
      "[ ecpho : 9  iter :658 ]train loss : 0.428363 ,train acc: 0.834849 ,val loss : 0.374610 ,val acc : 0.832794\n",
      "[ ecpho : 9  iter :659 ]train loss : 0.400176 ,train acc: 0.841217 ,val loss : 0.380209 ,val acc : 0.826813\n",
      "[ ecpho : 9  iter :660 ]train loss : 0.326041 ,train acc: 0.861552 ,val loss : 0.378718 ,val acc : 0.825684\n",
      "[ ecpho : 9  iter :661 ]train loss : 0.316314 ,train acc: 0.858327 ,val loss : 0.380336 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :662 ]train loss : 0.409381 ,train acc: 0.748342 ,val loss : 0.375672 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :663 ]train loss : 0.268209 ,train acc: 0.869975 ,val loss : 0.377627 ,val acc : 0.827148\n",
      "[ ecpho : 9  iter :664 ]train loss : 0.358465 ,train acc: 0.857625 ,val loss : 0.380272 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :665 ]train loss : 0.324662 ,train acc: 0.843933 ,val loss : 0.378335 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :666 ]train loss : 0.353674 ,train acc: 0.846629 ,val loss : 0.379672 ,val acc : 0.830017\n",
      "[ ecpho : 9  iter :667 ]train loss : 0.403714 ,train acc: 0.813039 ,val loss : 0.379949 ,val acc : 0.830963\n",
      "[ ecpho : 9  iter :668 ]train loss : 0.311853 ,train acc: 0.856303 ,val loss : 0.378946 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :669 ]train loss : 0.276080 ,train acc: 0.860402 ,val loss : 0.376191 ,val acc : 0.832123\n",
      "[ ecpho : 9  iter :670 ]train loss : 0.296601 ,train acc: 0.866699 ,val loss : 0.376860 ,val acc : 0.831482\n",
      "[ ecpho : 9  iter :671 ]train loss : 0.303899 ,train acc: 0.862813 ,val loss : 0.386609 ,val acc : 0.826477\n",
      "[ ecpho : 9  iter :672 ]train loss : 0.334269 ,train acc: 0.853546 ,val loss : 0.380567 ,val acc : 0.830902\n",
      "[ ecpho : 9  iter :673 ]train loss : 0.237346 ,train acc: 0.883179 ,val loss : 0.382517 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :674 ]train loss : 0.253142 ,train acc: 0.873932 ,val loss : 0.373727 ,val acc : 0.829926\n",
      "[ ecpho : 9  iter :675 ]train loss : 0.341559 ,train acc: 0.839040 ,val loss : 0.379548 ,val acc : 0.825531\n",
      "[ ecpho : 9  iter :676 ]train loss : 0.324740 ,train acc: 0.834951 ,val loss : 0.378035 ,val acc : 0.827118\n",
      "[ ecpho : 9  iter :677 ]train loss : 0.251651 ,train acc: 0.880290 ,val loss : 0.377462 ,val acc : 0.830109\n",
      "[ ecpho : 9  iter :678 ]train loss : 0.406340 ,train acc: 0.724315 ,val loss : 0.385999 ,val acc : 0.826599\n",
      "[ ecpho : 9  iter :679 ]train loss : 0.303257 ,train acc: 0.852539 ,val loss : 0.376521 ,val acc : 0.828979\n",
      "[ ecpho : 9  iter :680 ]train loss : 0.380122 ,train acc: 0.845581 ,val loss : 0.378683 ,val acc : 0.832062\n",
      "[ ecpho : 9  iter :681 ]train loss : 0.402027 ,train acc: 0.836467 ,val loss : 0.381038 ,val acc : 0.830719\n",
      "[ ecpho : 9  iter :682 ]train loss : 0.354769 ,train acc: 0.846629 ,val loss : 0.377945 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :683 ]train loss : 0.355306 ,train acc: 0.823375 ,val loss : 0.379312 ,val acc : 0.829041\n",
      "[ ecpho : 9  iter :684 ]train loss : 0.284461 ,train acc: 0.864573 ,val loss : 0.383269 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :685 ]train loss : 0.248879 ,train acc: 0.877085 ,val loss : 0.379935 ,val acc : 0.830627\n",
      "[ ecpho : 9  iter :686 ]train loss : 0.480594 ,train acc: 0.812785 ,val loss : 0.370513 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :687 ]train loss : 0.361120 ,train acc: 0.847331 ,val loss : 0.376367 ,val acc : 0.828064\n",
      "[ ecpho : 9  iter :688 ]train loss : 0.387116 ,train acc: 0.847392 ,val loss : 0.378814 ,val acc : 0.824371\n",
      "[ ecpho : 9  iter :689 ]train loss : 0.583809 ,train acc: 0.723918 ,val loss : 0.381310 ,val acc : 0.826202\n",
      "[ ecpho : 9  iter :690 ]train loss : 0.377249 ,train acc: 0.843913 ,val loss : 0.380854 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :691 ]train loss : 0.252778 ,train acc: 0.879212 ,val loss : 0.379640 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :692 ]train loss : 0.297618 ,train acc: 0.856761 ,val loss : 0.379555 ,val acc : 0.825409\n",
      "[ ecpho : 9  iter :693 ]train loss : 0.320014 ,train acc: 0.867523 ,val loss : 0.383952 ,val acc : 0.826385\n",
      "[ ecpho : 9  iter :694 ]train loss : 0.257754 ,train acc: 0.880463 ,val loss : 0.380857 ,val acc : 0.829346\n",
      "[ ecpho : 9  iter :695 ]train loss : 0.251614 ,train acc: 0.880849 ,val loss : 0.372797 ,val acc : 0.831451\n",
      "[ ecpho : 9  iter :696 ]train loss : 0.271039 ,train acc: 0.874827 ,val loss : 0.378069 ,val acc : 0.829010\n",
      "[ ecpho : 9  iter :697 ]train loss : 0.277331 ,train acc: 0.862925 ,val loss : 0.379301 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :698 ]train loss : 0.348859 ,train acc: 0.838664 ,val loss : 0.377460 ,val acc : 0.831787\n",
      "[ ecpho : 9  iter :699 ]train loss : 0.341256 ,train acc: 0.846965 ,val loss : 0.380677 ,val acc : 0.826141\n",
      "[ ecpho : 9  iter :700 ]train loss : 0.243379 ,train acc: 0.886851 ,val loss : 0.379421 ,val acc : 0.829865\n",
      "[ ecpho : 9  iter :701 ]train loss : 0.355630 ,train acc: 0.856771 ,val loss : 0.376159 ,val acc : 0.829712\n",
      "[ ecpho : 9  iter :702 ]train loss : 0.409909 ,train acc: 0.820333 ,val loss : 0.381696 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :703 ]train loss : 0.260499 ,train acc: 0.875661 ,val loss : 0.373811 ,val acc : 0.830811\n",
      "[ ecpho : 9  iter :704 ]train loss : 0.375505 ,train acc: 0.807221 ,val loss : 0.385024 ,val acc : 0.825317\n",
      "[ ecpho : 9  iter :705 ]train loss : 0.254434 ,train acc: 0.875926 ,val loss : 0.380409 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :706 ]train loss : 0.347477 ,train acc: 0.842997 ,val loss : 0.374181 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :707 ]train loss : 0.348846 ,train acc: 0.854177 ,val loss : 0.379422 ,val acc : 0.827759\n",
      "[ ecpho : 9  iter :708 ]train loss : 0.326939 ,train acc: 0.832723 ,val loss : 0.383369 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :709 ]train loss : 0.289033 ,train acc: 0.851746 ,val loss : 0.378337 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :710 ]train loss : 0.250179 ,train acc: 0.877960 ,val loss : 0.383160 ,val acc : 0.826447\n",
      "[ ecpho : 9  iter :711 ]train loss : 0.305404 ,train acc: 0.852081 ,val loss : 0.378087 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :712 ]train loss : 0.285339 ,train acc: 0.869792 ,val loss : 0.381313 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :713 ]train loss : 0.399269 ,train acc: 0.818685 ,val loss : 0.382520 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :714 ]train loss : 0.388565 ,train acc: 0.825602 ,val loss : 0.375450 ,val acc : 0.831207\n",
      "[ ecpho : 9  iter :715 ]train loss : 0.263364 ,train acc: 0.876231 ,val loss : 0.380037 ,val acc : 0.828033\n",
      "[ ecpho : 9  iter :716 ]train loss : 0.300625 ,train acc: 0.853516 ,val loss : 0.383549 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :717 ]train loss : 0.350210 ,train acc: 0.805898 ,val loss : 0.382487 ,val acc : 0.830414\n",
      "[ ecpho : 9  iter :718 ]train loss : 0.338096 ,train acc: 0.846456 ,val loss : 0.374453 ,val acc : 0.829254\n",
      "[ ecpho : 9  iter :719 ]train loss : 0.246838 ,train acc: 0.879852 ,val loss : 0.375080 ,val acc : 0.830444\n",
      "[ ecpho : 9  iter :720 ]train loss : 0.336415 ,train acc: 0.829020 ,val loss : 0.380795 ,val acc : 0.825928\n",
      "[ ecpho : 9  iter :721 ]train loss : 0.261518 ,train acc: 0.875142 ,val loss : 0.386289 ,val acc : 0.825317\n",
      "[ ecpho : 9  iter :722 ]train loss : 0.288325 ,train acc: 0.868480 ,val loss : 0.380421 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :723 ]train loss : 0.294543 ,train acc: 0.863017 ,val loss : 0.380520 ,val acc : 0.826172\n",
      "[ ecpho : 9  iter :724 ]train loss : 0.433028 ,train acc: 0.806447 ,val loss : 0.380680 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :725 ]train loss : 0.289883 ,train acc: 0.869242 ,val loss : 0.372487 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :726 ]train loss : 0.275637 ,train acc: 0.875234 ,val loss : 0.378815 ,val acc : 0.830292\n",
      "[ ecpho : 9  iter :727 ]train loss : 0.306307 ,train acc: 0.862579 ,val loss : 0.379657 ,val acc : 0.827423\n",
      "[ ecpho : 9  iter :728 ]train loss : 0.349986 ,train acc: 0.824972 ,val loss : 0.377655 ,val acc : 0.830933\n",
      "[ ecpho : 9  iter :729 ]train loss : 0.299863 ,train acc: 0.860087 ,val loss : 0.378495 ,val acc : 0.829163\n",
      "[ ecpho : 9  iter :730 ]train loss : 0.254093 ,train acc: 0.877828 ,val loss : 0.381391 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :731 ]train loss : 0.360603 ,train acc: 0.832977 ,val loss : 0.381897 ,val acc : 0.827942\n",
      "[ ecpho : 9  iter :732 ]train loss : 0.283827 ,train acc: 0.871073 ,val loss : 0.376192 ,val acc : 0.830688\n",
      "[ ecpho : 9  iter :733 ]train loss : 0.272580 ,train acc: 0.873250 ,val loss : 0.382879 ,val acc : 0.829163\n",
      "[ ecpho : 9  iter :734 ]train loss : 0.251549 ,train acc: 0.883016 ,val loss : 0.377531 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :735 ]train loss : 0.278071 ,train acc: 0.861898 ,val loss : 0.382794 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :736 ]train loss : 0.335616 ,train acc: 0.857188 ,val loss : 0.382208 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :737 ]train loss : 0.376246 ,train acc: 0.730174 ,val loss : 0.378808 ,val acc : 0.829163\n",
      "[ ecpho : 9  iter :738 ]train loss : 0.311996 ,train acc: 0.861613 ,val loss : 0.376781 ,val acc : 0.832184\n",
      "[ ecpho : 9  iter :739 ]train loss : 0.358666 ,train acc: 0.856924 ,val loss : 0.382585 ,val acc : 0.826111\n",
      "[ ecpho : 9  iter :740 ]train loss : 0.287629 ,train acc: 0.863922 ,val loss : 0.383796 ,val acc : 0.824829\n",
      "[ ecpho : 9  iter :741 ]train loss : 0.352714 ,train acc: 0.848511 ,val loss : 0.380226 ,val acc : 0.826965\n",
      "[ ecpho : 9  iter :742 ]train loss : 0.259077 ,train acc: 0.872976 ,val loss : 0.379716 ,val acc : 0.826904\n",
      "[ ecpho : 9  iter :743 ]train loss : 0.293002 ,train acc: 0.865814 ,val loss : 0.379786 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :744 ]train loss : 0.330383 ,train acc: 0.828827 ,val loss : 0.384869 ,val acc : 0.826355\n",
      "[ ecpho : 9  iter :745 ]train loss : 0.219463 ,train acc: 0.895660 ,val loss : 0.386329 ,val acc : 0.824158\n",
      "[ ecpho : 9  iter :746 ]train loss : 0.431565 ,train acc: 0.802348 ,val loss : 0.377247 ,val acc : 0.829712\n",
      "[ ecpho : 9  iter :747 ]train loss : 0.334690 ,train acc: 0.848073 ,val loss : 0.379297 ,val acc : 0.827728\n",
      "[ ecpho : 9  iter :748 ]train loss : 0.316502 ,train acc: 0.861939 ,val loss : 0.377572 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :749 ]train loss : 0.277626 ,train acc: 0.859741 ,val loss : 0.384448 ,val acc : 0.827332\n",
      "[ ecpho : 9  iter :750 ]train loss : 0.285959 ,train acc: 0.872528 ,val loss : 0.379832 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :751 ]train loss : 0.461054 ,train acc: 0.804352 ,val loss : 0.380538 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :752 ]train loss : 0.319938 ,train acc: 0.855143 ,val loss : 0.376796 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :753 ]train loss : 0.228821 ,train acc: 0.890361 ,val loss : 0.375183 ,val acc : 0.829529\n",
      "[ ecpho : 9  iter :754 ]train loss : 0.370388 ,train acc: 0.827759 ,val loss : 0.384311 ,val acc : 0.826569\n",
      "[ ecpho : 9  iter :755 ]train loss : 0.302180 ,train acc: 0.852844 ,val loss : 0.379678 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :756 ]train loss : 0.385649 ,train acc: 0.831757 ,val loss : 0.385291 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :757 ]train loss : 0.242726 ,train acc: 0.883362 ,val loss : 0.382376 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :758 ]train loss : 0.426224 ,train acc: 0.839549 ,val loss : 0.378098 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :759 ]train loss : 0.415930 ,train acc: 0.840525 ,val loss : 0.378320 ,val acc : 0.831146\n",
      "[ ecpho : 9  iter :760 ]train loss : 0.391964 ,train acc: 0.800710 ,val loss : 0.375109 ,val acc : 0.829559\n",
      "[ ecpho : 9  iter :761 ]train loss : 0.279253 ,train acc: 0.868256 ,val loss : 0.382032 ,val acc : 0.829773\n",
      "[ ecpho : 9  iter :762 ]train loss : 0.260864 ,train acc: 0.875834 ,val loss : 0.377665 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :763 ]train loss : 0.456665 ,train acc: 0.812195 ,val loss : 0.379947 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :764 ]train loss : 0.364620 ,train acc: 0.836182 ,val loss : 0.383538 ,val acc : 0.824463\n",
      "[ ecpho : 9  iter :765 ]train loss : 0.243674 ,train acc: 0.882243 ,val loss : 0.373825 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :766 ]train loss : 0.345782 ,train acc: 0.856995 ,val loss : 0.373955 ,val acc : 0.829407\n",
      "[ ecpho : 9  iter :767 ]train loss : 0.381246 ,train acc: 0.818695 ,val loss : 0.381072 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :768 ]train loss : 0.351560 ,train acc: 0.839539 ,val loss : 0.384300 ,val acc : 0.829437\n",
      "[ ecpho : 9  iter :769 ]train loss : 0.264330 ,train acc: 0.864939 ,val loss : 0.379027 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :770 ]train loss : 0.269731 ,train acc: 0.874715 ,val loss : 0.377819 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :771 ]train loss : 0.423268 ,train acc: 0.821503 ,val loss : 0.380628 ,val acc : 0.829315\n",
      "[ ecpho : 9  iter :772 ]train loss : 0.456430 ,train acc: 0.765066 ,val loss : 0.384538 ,val acc : 0.827362\n",
      "[ ecpho : 9  iter :773 ]train loss : 0.279880 ,train acc: 0.875794 ,val loss : 0.380789 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :774 ]train loss : 0.307192 ,train acc: 0.857310 ,val loss : 0.378605 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :775 ]train loss : 0.279989 ,train acc: 0.874430 ,val loss : 0.377608 ,val acc : 0.825256\n",
      "[ ecpho : 9  iter :776 ]train loss : 0.234127 ,train acc: 0.886749 ,val loss : 0.381287 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :777 ]train loss : 0.423661 ,train acc: 0.821361 ,val loss : 0.378447 ,val acc : 0.830505\n",
      "[ ecpho : 9  iter :778 ]train loss : 0.369401 ,train acc: 0.826640 ,val loss : 0.378296 ,val acc : 0.824951\n",
      "[ ecpho : 9  iter :779 ]train loss : 0.314351 ,train acc: 0.860230 ,val loss : 0.382017 ,val acc : 0.827454\n",
      "[ ecpho : 9  iter :780 ]train loss : 0.294878 ,train acc: 0.860606 ,val loss : 0.384048 ,val acc : 0.829834\n",
      "[ ecpho : 9  iter :781 ]train loss : 0.289044 ,train acc: 0.863047 ,val loss : 0.378966 ,val acc : 0.830658\n",
      "[ ecpho : 9  iter :782 ]train loss : 0.375171 ,train acc: 0.854055 ,val loss : 0.374920 ,val acc : 0.827148\n",
      "[ ecpho : 9  iter :783 ]train loss : 0.324664 ,train acc: 0.852854 ,val loss : 0.375527 ,val acc : 0.830200\n",
      "[ ecpho : 9  iter :784 ]train loss : 0.300481 ,train acc: 0.860097 ,val loss : 0.378698 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :785 ]train loss : 0.270630 ,train acc: 0.868256 ,val loss : 0.377719 ,val acc : 0.825745\n",
      "[ ecpho : 9  iter :786 ]train loss : 0.333714 ,train acc: 0.858093 ,val loss : 0.378788 ,val acc : 0.830872\n",
      "[ ecpho : 9  iter :787 ]train loss : 0.288806 ,train acc: 0.850027 ,val loss : 0.379461 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :788 ]train loss : 0.320621 ,train acc: 0.854502 ,val loss : 0.381174 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :789 ]train loss : 0.349088 ,train acc: 0.848358 ,val loss : 0.380355 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :790 ]train loss : 0.324082 ,train acc: 0.851380 ,val loss : 0.382584 ,val acc : 0.829254\n",
      "[ ecpho : 9  iter :791 ]train loss : 0.459280 ,train acc: 0.780854 ,val loss : 0.379263 ,val acc : 0.829346\n",
      "[ ecpho : 9  iter :792 ]train loss : 0.365038 ,train acc: 0.817973 ,val loss : 0.378055 ,val acc : 0.828644\n",
      "[ ecpho : 9  iter :793 ]train loss : 0.358263 ,train acc: 0.839630 ,val loss : 0.373990 ,val acc : 0.830444\n",
      "[ ecpho : 9  iter :794 ]train loss : 0.279434 ,train acc: 0.871653 ,val loss : 0.378496 ,val acc : 0.826904\n",
      "[ ecpho : 9  iter :795 ]train loss : 0.305557 ,train acc: 0.861257 ,val loss : 0.381044 ,val acc : 0.826324\n",
      "[ ecpho : 9  iter :796 ]train loss : 0.262435 ,train acc: 0.871613 ,val loss : 0.372027 ,val acc : 0.831421\n",
      "[ ecpho : 9  iter :797 ]train loss : 0.702889 ,train acc: 0.765381 ,val loss : 0.380987 ,val acc : 0.831757\n",
      "[ ecpho : 9  iter :798 ]train loss : 0.293961 ,train acc: 0.865814 ,val loss : 0.379909 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :799 ]train loss : 0.267174 ,train acc: 0.874563 ,val loss : 0.380486 ,val acc : 0.827026\n",
      "[ ecpho : 9  iter :800 ]train loss : 0.267775 ,train acc: 0.872813 ,val loss : 0.379479 ,val acc : 0.829956\n",
      "[ ecpho : 9  iter :801 ]train loss : 0.322673 ,train acc: 0.853363 ,val loss : 0.387364 ,val acc : 0.826599\n",
      "[ ecpho : 9  iter :802 ]train loss : 0.306894 ,train acc: 0.847880 ,val loss : 0.380902 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :803 ]train loss : 0.265243 ,train acc: 0.875041 ,val loss : 0.384960 ,val acc : 0.830780\n",
      "[ ecpho : 9  iter :804 ]train loss : 0.306746 ,train acc: 0.870483 ,val loss : 0.376210 ,val acc : 0.830170\n",
      "[ ecpho : 9  iter :805 ]train loss : 0.253568 ,train acc: 0.874329 ,val loss : 0.382383 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :806 ]train loss : 0.283723 ,train acc: 0.861104 ,val loss : 0.381763 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :807 ]train loss : 0.359994 ,train acc: 0.825562 ,val loss : 0.380920 ,val acc : 0.826904\n",
      "[ ecpho : 9  iter :808 ]train loss : 0.298044 ,train acc: 0.849396 ,val loss : 0.376610 ,val acc : 0.829376\n",
      "[ ecpho : 9  iter :809 ]train loss : 0.223576 ,train acc: 0.893748 ,val loss : 0.381852 ,val acc : 0.828033\n",
      "[ ecpho : 9  iter :810 ]train loss : 0.291421 ,train acc: 0.857198 ,val loss : 0.376691 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :811 ]train loss : 0.245844 ,train acc: 0.881175 ,val loss : 0.381993 ,val acc : 0.827911\n",
      "[ ecpho : 9  iter :812 ]train loss : 0.270883 ,train acc: 0.873810 ,val loss : 0.380545 ,val acc : 0.830078\n",
      "[ ecpho : 9  iter :813 ]train loss : 0.433286 ,train acc: 0.735067 ,val loss : 0.382794 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :814 ]train loss : 0.278629 ,train acc: 0.863139 ,val loss : 0.377898 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :815 ]train loss : 0.360334 ,train acc: 0.805145 ,val loss : 0.378490 ,val acc : 0.826721\n",
      "[ ecpho : 9  iter :816 ]train loss : 0.268300 ,train acc: 0.870667 ,val loss : 0.382114 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :817 ]train loss : 0.378502 ,train acc: 0.849060 ,val loss : 0.380338 ,val acc : 0.829437\n",
      "[ ecpho : 9  iter :818 ]train loss : 0.298114 ,train acc: 0.858785 ,val loss : 0.379311 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :819 ]train loss : 0.279746 ,train acc: 0.870758 ,val loss : 0.378940 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :820 ]train loss : 0.443821 ,train acc: 0.836172 ,val loss : 0.380325 ,val acc : 0.827545\n",
      "[ ecpho : 9  iter :821 ]train loss : 0.271048 ,train acc: 0.871887 ,val loss : 0.380876 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :822 ]train loss : 0.257076 ,train acc: 0.877309 ,val loss : 0.381416 ,val acc : 0.829651\n",
      "[ ecpho : 9  iter :823 ]train loss : 0.437232 ,train acc: 0.802073 ,val loss : 0.378746 ,val acc : 0.827423\n",
      "[ ecpho : 9  iter :824 ]train loss : 0.337280 ,train acc: 0.830353 ,val loss : 0.376195 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :825 ]train loss : 0.366396 ,train acc: 0.805563 ,val loss : 0.382939 ,val acc : 0.827667\n",
      "[ ecpho : 9  iter :826 ]train loss : 0.378854 ,train acc: 0.856059 ,val loss : 0.379840 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :827 ]train loss : 0.422152 ,train acc: 0.808645 ,val loss : 0.376513 ,val acc : 0.824432\n",
      "[ ecpho : 9  iter :828 ]train loss : 0.316612 ,train acc: 0.864573 ,val loss : 0.377830 ,val acc : 0.829102\n",
      "[ ecpho : 9  iter :829 ]train loss : 0.287441 ,train acc: 0.864990 ,val loss : 0.379002 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :830 ]train loss : 0.280928 ,train acc: 0.876170 ,val loss : 0.383171 ,val acc : 0.825989\n",
      "[ ecpho : 9  iter :831 ]train loss : 0.352812 ,train acc: 0.823517 ,val loss : 0.375170 ,val acc : 0.833252\n",
      "[ ecpho : 9  iter :832 ]train loss : 0.303069 ,train acc: 0.871745 ,val loss : 0.378513 ,val acc : 0.827972\n",
      "[ ecpho : 9  iter :833 ]train loss : 0.280077 ,train acc: 0.877777 ,val loss : 0.373031 ,val acc : 0.832306\n",
      "[ ecpho : 9  iter :834 ]train loss : 0.289286 ,train acc: 0.871165 ,val loss : 0.378960 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :835 ]train loss : 0.259993 ,train acc: 0.875824 ,val loss : 0.375887 ,val acc : 0.829620\n",
      "[ ecpho : 9  iter :836 ]train loss : 0.507954 ,train acc: 0.825857 ,val loss : 0.376451 ,val acc : 0.830566\n",
      "[ ecpho : 9  iter :837 ]train loss : 0.252213 ,train acc: 0.885305 ,val loss : 0.382176 ,val acc : 0.829895\n",
      "[ ecpho : 9  iter :838 ]train loss : 0.341930 ,train acc: 0.834188 ,val loss : 0.381640 ,val acc : 0.828583\n",
      "[ ecpho : 9  iter :839 ]train loss : 0.382545 ,train acc: 0.848501 ,val loss : 0.383822 ,val acc : 0.825531\n",
      "[ ecpho : 9  iter :840 ]train loss : 0.357488 ,train acc: 0.795288 ,val loss : 0.379632 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :841 ]train loss : 0.305759 ,train acc: 0.860606 ,val loss : 0.373616 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :842 ]train loss : 0.366507 ,train acc: 0.810272 ,val loss : 0.380904 ,val acc : 0.827850\n",
      "[ ecpho : 9  iter :843 ]train loss : 0.266829 ,train acc: 0.872732 ,val loss : 0.379247 ,val acc : 0.825500\n",
      "[ ecpho : 9  iter :844 ]train loss : 0.230182 ,train acc: 0.889465 ,val loss : 0.374698 ,val acc : 0.829407\n",
      "[ ecpho : 9  iter :845 ]train loss : 0.302619 ,train acc: 0.866730 ,val loss : 0.377061 ,val acc : 0.828491\n",
      "[ ecpho : 9  iter :846 ]train loss : 0.294892 ,train acc: 0.844187 ,val loss : 0.376996 ,val acc : 0.828522\n",
      "[ ecpho : 9  iter :847 ]train loss : 0.293154 ,train acc: 0.869578 ,val loss : 0.380400 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :848 ]train loss : 0.295437 ,train acc: 0.871908 ,val loss : 0.383137 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :849 ]train loss : 0.306050 ,train acc: 0.848134 ,val loss : 0.376636 ,val acc : 0.828125\n",
      "[ ecpho : 9  iter :850 ]train loss : 0.322488 ,train acc: 0.838593 ,val loss : 0.387289 ,val acc : 0.826996\n",
      "[ ecpho : 9  iter :851 ]train loss : 0.456039 ,train acc: 0.797069 ,val loss : 0.379853 ,val acc : 0.829224\n",
      "[ ecpho : 9  iter :852 ]train loss : 0.368857 ,train acc: 0.831238 ,val loss : 0.379100 ,val acc : 0.829315\n",
      "[ ecpho : 9  iter :853 ]train loss : 0.342558 ,train acc: 0.851634 ,val loss : 0.385242 ,val acc : 0.828339\n",
      "[ ecpho : 9  iter :854 ]train loss : 0.391783 ,train acc: 0.829356 ,val loss : 0.374063 ,val acc : 0.830566\n",
      "[ ecpho : 9  iter :855 ]train loss : 0.412449 ,train acc: 0.832682 ,val loss : 0.382906 ,val acc : 0.827484\n",
      "[ ecpho : 9  iter :856 ]train loss : 0.232343 ,train acc: 0.890360 ,val loss : 0.380200 ,val acc : 0.828888\n",
      "[ ecpho : 9  iter :857 ]train loss : 0.286343 ,train acc: 0.863912 ,val loss : 0.383359 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :858 ]train loss : 0.310552 ,train acc: 0.858846 ,val loss : 0.377396 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :859 ]train loss : 0.318902 ,train acc: 0.855642 ,val loss : 0.385454 ,val acc : 0.826935\n",
      "[ ecpho : 9  iter :860 ]train loss : 0.250315 ,train acc: 0.884145 ,val loss : 0.387772 ,val acc : 0.826263\n",
      "[ ecpho : 9  iter :861 ]train loss : 0.266652 ,train acc: 0.874837 ,val loss : 0.382387 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :862 ]train loss : 0.321902 ,train acc: 0.861786 ,val loss : 0.383733 ,val acc : 0.828278\n",
      "[ ecpho : 9  iter :863 ]train loss : 0.251513 ,train acc: 0.884928 ,val loss : 0.382653 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :864 ]train loss : 0.313036 ,train acc: 0.862040 ,val loss : 0.380608 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :865 ]train loss : 0.237145 ,train acc: 0.884308 ,val loss : 0.382879 ,val acc : 0.830719\n",
      "[ ecpho : 9  iter :866 ]train loss : 0.292878 ,train acc: 0.868876 ,val loss : 0.385161 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :867 ]train loss : 0.248977 ,train acc: 0.880178 ,val loss : 0.382523 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :868 ]train loss : 0.308645 ,train acc: 0.862844 ,val loss : 0.379840 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :869 ]train loss : 0.264631 ,train acc: 0.878947 ,val loss : 0.379217 ,val acc : 0.828308\n",
      "[ ecpho : 9  iter :870 ]train loss : 0.245196 ,train acc: 0.881327 ,val loss : 0.378500 ,val acc : 0.825470\n",
      "[ ecpho : 9  iter :871 ]train loss : 0.319907 ,train acc: 0.859151 ,val loss : 0.379872 ,val acc : 0.825775\n",
      "[ ecpho : 9  iter :872 ]train loss : 0.301981 ,train acc: 0.858582 ,val loss : 0.379792 ,val acc : 0.827759\n",
      "[ ecpho : 9  iter :873 ]train loss : 0.281358 ,train acc: 0.865733 ,val loss : 0.379870 ,val acc : 0.827484\n",
      "[ ecpho : 9  iter :874 ]train loss : 0.303674 ,train acc: 0.858795 ,val loss : 0.379765 ,val acc : 0.828461\n",
      "[ ecpho : 9  iter :875 ]train loss : 0.277946 ,train acc: 0.871145 ,val loss : 0.381654 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :876 ]train loss : 0.267461 ,train acc: 0.881337 ,val loss : 0.376698 ,val acc : 0.827118\n",
      "[ ecpho : 9  iter :877 ]train loss : 0.346962 ,train acc: 0.815704 ,val loss : 0.375164 ,val acc : 0.828674\n",
      "[ ecpho : 9  iter :878 ]train loss : 0.279097 ,train acc: 0.877106 ,val loss : 0.386828 ,val acc : 0.829132\n",
      "[ ecpho : 9  iter :879 ]train loss : 0.236039 ,train acc: 0.887848 ,val loss : 0.380846 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :880 ]train loss : 0.324814 ,train acc: 0.834574 ,val loss : 0.377561 ,val acc : 0.832367\n",
      "[ ecpho : 9  iter :881 ]train loss : 0.259821 ,train acc: 0.879344 ,val loss : 0.377596 ,val acc : 0.825897\n",
      "[ ecpho : 9  iter :882 ]train loss : 0.442439 ,train acc: 0.837718 ,val loss : 0.381124 ,val acc : 0.824585\n",
      "[ ecpho : 9  iter :883 ]train loss : 0.291727 ,train acc: 0.866241 ,val loss : 0.374488 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :884 ]train loss : 0.274714 ,train acc: 0.866292 ,val loss : 0.378652 ,val acc : 0.826843\n",
      "[ ecpho : 9  iter :885 ]train loss : 0.263468 ,train acc: 0.870209 ,val loss : 0.380886 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :886 ]train loss : 0.373152 ,train acc: 0.844564 ,val loss : 0.376042 ,val acc : 0.830505\n",
      "[ ecpho : 9  iter :887 ]train loss : 0.405710 ,train acc: 0.787537 ,val loss : 0.377897 ,val acc : 0.830719\n",
      "[ ecpho : 9  iter :888 ]train loss : 0.364098 ,train acc: 0.843659 ,val loss : 0.381802 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :889 ]train loss : 0.258712 ,train acc: 0.885580 ,val loss : 0.376649 ,val acc : 0.830658\n",
      "[ ecpho : 9  iter :890 ]train loss : 0.390773 ,train acc: 0.824483 ,val loss : 0.382401 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :891 ]train loss : 0.395328 ,train acc: 0.812897 ,val loss : 0.376717 ,val acc : 0.832703\n",
      "[ ecpho : 9  iter :892 ]train loss : 0.358392 ,train acc: 0.830800 ,val loss : 0.380151 ,val acc : 0.829193\n",
      "[ ecpho : 9  iter :893 ]train loss : 0.317154 ,train acc: 0.858429 ,val loss : 0.377568 ,val acc : 0.830231\n",
      "[ ecpho : 9  iter :894 ]train loss : 0.311140 ,train acc: 0.855632 ,val loss : 0.372092 ,val acc : 0.832123\n",
      "[ ecpho : 9  iter :895 ]train loss : 0.326000 ,train acc: 0.824941 ,val loss : 0.377619 ,val acc : 0.830719\n",
      "[ ecpho : 9  iter :896 ]train loss : 0.346716 ,train acc: 0.830404 ,val loss : 0.384799 ,val acc : 0.827240\n",
      "[ ecpho : 9  iter :897 ]train loss : 0.310741 ,train acc: 0.854879 ,val loss : 0.375783 ,val acc : 0.828613\n",
      "[ ecpho : 9  iter :898 ]train loss : 0.286172 ,train acc: 0.863627 ,val loss : 0.380674 ,val acc : 0.828064\n",
      "[ ecpho : 9  iter :899 ]train loss : 0.342234 ,train acc: 0.847819 ,val loss : 0.375380 ,val acc : 0.830658\n",
      "[ ecpho : 9  iter :900 ]train loss : 0.326698 ,train acc: 0.847545 ,val loss : 0.378522 ,val acc : 0.829529\n",
      "[ ecpho : 9  iter :901 ]train loss : 0.236569 ,train acc: 0.886332 ,val loss : 0.385085 ,val acc : 0.832672\n",
      "[ ecpho : 9  iter :902 ]train loss : 0.236801 ,train acc: 0.887644 ,val loss : 0.375641 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :903 ]train loss : 0.275939 ,train acc: 0.868723 ,val loss : 0.378699 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :904 ]train loss : 0.319114 ,train acc: 0.858399 ,val loss : 0.382819 ,val acc : 0.829285\n",
      "[ ecpho : 9  iter :905 ]train loss : 0.230362 ,train acc: 0.889211 ,val loss : 0.374140 ,val acc : 0.832336\n",
      "[ ecpho : 9  iter :906 ]train loss : 0.270042 ,train acc: 0.874603 ,val loss : 0.378270 ,val acc : 0.827148\n",
      "[ ecpho : 9  iter :907 ]train loss : 0.230658 ,train acc: 0.888153 ,val loss : 0.384937 ,val acc : 0.830292\n",
      "[ ecpho : 9  iter :908 ]train loss : 0.408230 ,train acc: 0.832794 ,val loss : 0.382840 ,val acc : 0.830750\n",
      "[ ecpho : 9  iter :909 ]train loss : 0.275376 ,train acc: 0.863953 ,val loss : 0.381762 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :910 ]train loss : 0.317947 ,train acc: 0.851430 ,val loss : 0.383897 ,val acc : 0.827637\n",
      "[ ecpho : 9  iter :911 ]train loss : 0.307551 ,train acc: 0.857646 ,val loss : 0.377053 ,val acc : 0.829254\n",
      "[ ecpho : 9  iter :912 ]train loss : 0.419055 ,train acc: 0.825836 ,val loss : 0.375917 ,val acc : 0.831512\n",
      "[ ecpho : 9  iter :913 ]train loss : 0.315370 ,train acc: 0.854452 ,val loss : 0.380718 ,val acc : 0.827332\n",
      "[ ecpho : 9  iter :914 ]train loss : 0.385916 ,train acc: 0.825134 ,val loss : 0.380982 ,val acc : 0.827881\n",
      "[ ecpho : 9  iter :915 ]train loss : 0.262156 ,train acc: 0.877034 ,val loss : 0.385619 ,val acc : 0.828430\n",
      "[ ecpho : 9  iter :916 ]train loss : 0.297749 ,train acc: 0.853282 ,val loss : 0.382999 ,val acc : 0.829346\n",
      "[ ecpho : 9  iter :917 ]train loss : 0.348931 ,train acc: 0.855927 ,val loss : 0.382317 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :918 ]train loss : 0.358280 ,train acc: 0.858165 ,val loss : 0.381695 ,val acc : 0.827698\n",
      "[ ecpho : 9  iter :919 ]train loss : 0.230777 ,train acc: 0.888519 ,val loss : 0.379925 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :920 ]train loss : 0.313619 ,train acc: 0.841187 ,val loss : 0.377017 ,val acc : 0.828918\n",
      "[ ecpho : 9  iter :921 ]train loss : 0.326820 ,train acc: 0.859375 ,val loss : 0.377643 ,val acc : 0.830688\n",
      "[ ecpho : 9  iter :922 ]train loss : 0.371087 ,train acc: 0.842153 ,val loss : 0.381568 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :923 ]train loss : 0.300340 ,train acc: 0.871643 ,val loss : 0.378496 ,val acc : 0.831726\n",
      "[ ecpho : 9  iter :924 ]train loss : 0.408790 ,train acc: 0.765849 ,val loss : 0.383351 ,val acc : 0.824921\n",
      "[ ecpho : 9  iter :925 ]train loss : 0.336798 ,train acc: 0.847107 ,val loss : 0.379080 ,val acc : 0.828522\n",
      "[ ecpho : 9  iter :926 ]train loss : 0.374946 ,train acc: 0.850881 ,val loss : 0.373480 ,val acc : 0.830048\n",
      "[ ecpho : 9  iter :927 ]train loss : 0.281732 ,train acc: 0.865122 ,val loss : 0.379096 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :928 ]train loss : 0.301633 ,train acc: 0.853882 ,val loss : 0.384095 ,val acc : 0.825623\n",
      "[ ecpho : 9  iter :929 ]train loss : 0.265941 ,train acc: 0.878825 ,val loss : 0.377171 ,val acc : 0.831482\n",
      "[ ecpho : 9  iter :930 ]train loss : 0.280857 ,train acc: 0.876902 ,val loss : 0.382854 ,val acc : 0.825348\n",
      "[ ecpho : 9  iter :931 ]train loss : 0.293810 ,train acc: 0.859985 ,val loss : 0.382109 ,val acc : 0.827728\n",
      "[ ecpho : 9  iter :932 ]train loss : 0.288579 ,train acc: 0.852142 ,val loss : 0.377649 ,val acc : 0.828278\n",
      "[ ecpho : 9  iter :933 ]train loss : 0.344236 ,train acc: 0.851278 ,val loss : 0.385183 ,val acc : 0.827057\n",
      "[ ecpho : 9  iter :934 ]train loss : 0.319921 ,train acc: 0.856822 ,val loss : 0.371924 ,val acc : 0.831421\n",
      "[ ecpho : 9  iter :935 ]train loss : 0.246709 ,train acc: 0.880564 ,val loss : 0.372773 ,val acc : 0.830994\n",
      "[ ecpho : 9  iter :936 ]train loss : 0.384805 ,train acc: 0.829376 ,val loss : 0.371480 ,val acc : 0.832245\n",
      "[ ecpho : 9  iter :937 ]train loss : 0.341164 ,train acc: 0.851990 ,val loss : 0.378049 ,val acc : 0.829681\n",
      "[ ecpho : 9  iter :938 ]train loss : 0.320569 ,train acc: 0.859334 ,val loss : 0.378185 ,val acc : 0.830139\n",
      "[ ecpho : 9  iter :939 ]train loss : 0.269570 ,train acc: 0.879618 ,val loss : 0.379445 ,val acc : 0.830872\n",
      "[ ecpho : 9  iter :940 ]train loss : 0.306835 ,train acc: 0.850566 ,val loss : 0.383464 ,val acc : 0.828796\n",
      "[ ecpho : 9  iter :941 ]train loss : 0.308716 ,train acc: 0.856629 ,val loss : 0.380679 ,val acc : 0.826569\n",
      "[ ecpho : 9  iter :942 ]train loss : 0.424785 ,train acc: 0.780630 ,val loss : 0.379547 ,val acc : 0.829254\n",
      "[ ecpho : 9  iter :943 ]train loss : 0.324350 ,train acc: 0.843923 ,val loss : 0.376451 ,val acc : 0.828766\n",
      "[ ecpho : 9  iter :944 ]train loss : 0.318627 ,train acc: 0.854848 ,val loss : 0.377893 ,val acc : 0.828949\n",
      "[ ecpho : 9  iter :945 ]train loss : 0.311925 ,train acc: 0.866699 ,val loss : 0.372922 ,val acc : 0.829742\n",
      "[ ecpho : 9  iter :946 ]train loss : 0.259072 ,train acc: 0.878164 ,val loss : 0.380138 ,val acc : 0.828674\n",
      "[ ecpho : 9  iter :947 ]train loss : 0.285650 ,train acc: 0.867594 ,val loss : 0.384947 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :948 ]train loss : 0.245811 ,train acc: 0.881846 ,val loss : 0.379100 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :949 ]train loss : 0.268182 ,train acc: 0.873525 ,val loss : 0.373811 ,val acc : 0.831543\n",
      "[ ecpho : 9  iter :950 ]train loss : 0.394385 ,train acc: 0.844991 ,val loss : 0.383383 ,val acc : 0.827820\n",
      "[ ecpho : 9  iter :951 ]train loss : 0.244848 ,train acc: 0.881439 ,val loss : 0.376484 ,val acc : 0.828705\n",
      "[ ecpho : 9  iter :952 ]train loss : 0.338789 ,train acc: 0.847829 ,val loss : 0.377986 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :953 ]train loss : 0.252818 ,train acc: 0.878296 ,val loss : 0.375597 ,val acc : 0.827393\n",
      "[ ecpho : 9  iter :954 ]train loss : 0.361929 ,train acc: 0.791026 ,val loss : 0.381400 ,val acc : 0.827789\n",
      "[ ecpho : 9  iter :955 ]train loss : 0.245050 ,train acc: 0.882823 ,val loss : 0.376611 ,val acc : 0.831421\n",
      "[ ecpho : 9  iter :956 ]train loss : 0.296978 ,train acc: 0.862183 ,val loss : 0.376922 ,val acc : 0.828217\n",
      "[ ecpho : 9  iter :957 ]train loss : 0.317479 ,train acc: 0.863851 ,val loss : 0.377047 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :958 ]train loss : 0.254428 ,train acc: 0.881693 ,val loss : 0.376740 ,val acc : 0.829315\n",
      "[ ecpho : 9  iter :959 ]train loss : 0.289114 ,train acc: 0.865326 ,val loss : 0.378926 ,val acc : 0.828186\n",
      "[ ecpho : 9  iter :960 ]train loss : 0.294701 ,train acc: 0.867076 ,val loss : 0.380870 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :961 ]train loss : 0.470518 ,train acc: 0.834992 ,val loss : 0.380302 ,val acc : 0.827026\n",
      "[ ecpho : 9  iter :962 ]train loss : 0.310545 ,train acc: 0.863902 ,val loss : 0.376449 ,val acc : 0.832062\n",
      "[ ecpho : 9  iter :963 ]train loss : 0.618501 ,train acc: 0.814728 ,val loss : 0.383957 ,val acc : 0.825592\n",
      "[ ecpho : 9  iter :964 ]train loss : 0.396899 ,train acc: 0.844320 ,val loss : 0.375145 ,val acc : 0.829437\n",
      "[ ecpho : 9  iter :965 ]train loss : 0.300796 ,train acc: 0.863709 ,val loss : 0.382581 ,val acc : 0.828003\n",
      "[ ecpho : 9  iter :966 ]train loss : 0.369242 ,train acc: 0.838521 ,val loss : 0.383761 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :967 ]train loss : 0.319743 ,train acc: 0.853109 ,val loss : 0.380014 ,val acc : 0.828552\n",
      "[ ecpho : 9  iter :968 ]train loss : 0.265731 ,train acc: 0.877045 ,val loss : 0.376459 ,val acc : 0.829376\n",
      "[ ecpho : 9  iter :969 ]train loss : 0.286384 ,train acc: 0.866669 ,val loss : 0.378499 ,val acc : 0.830261\n",
      "[ ecpho : 9  iter :970 ]train loss : 0.236967 ,train acc: 0.884613 ,val loss : 0.381535 ,val acc : 0.828369\n",
      "[ ecpho : 9  iter :971 ]train loss : 0.308553 ,train acc: 0.869131 ,val loss : 0.383369 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :972 ]train loss : 0.263821 ,train acc: 0.874898 ,val loss : 0.380739 ,val acc : 0.826233\n",
      "[ ecpho : 9  iter :973 ]train loss : 0.266803 ,train acc: 0.872182 ,val loss : 0.379092 ,val acc : 0.828156\n",
      "[ ecpho : 9  iter :974 ]train loss : 0.336283 ,train acc: 0.831584 ,val loss : 0.378229 ,val acc : 0.828827\n",
      "[ ecpho : 9  iter :975 ]train loss : 0.297190 ,train acc: 0.864929 ,val loss : 0.379625 ,val acc : 0.829529\n",
      "[ ecpho : 9  iter :976 ]train loss : 0.244942 ,train acc: 0.881012 ,val loss : 0.387147 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :977 ]train loss : 0.306386 ,train acc: 0.859548 ,val loss : 0.377479 ,val acc : 0.827637\n",
      "[ ecpho : 9  iter :978 ]train loss : 0.284363 ,train acc: 0.864970 ,val loss : 0.385843 ,val acc : 0.826691\n",
      "[ ecpho : 9  iter :979 ]train loss : 0.240684 ,train acc: 0.884013 ,val loss : 0.376552 ,val acc : 0.829956\n",
      "[ ecpho : 9  iter :980 ]train loss : 0.236034 ,train acc: 0.885803 ,val loss : 0.377418 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :981 ]train loss : 0.279945 ,train acc: 0.869212 ,val loss : 0.380098 ,val acc : 0.827576\n",
      "[ ecpho : 9  iter :982 ]train loss : 0.325014 ,train acc: 0.861288 ,val loss : 0.385514 ,val acc : 0.825531\n",
      "[ ecpho : 9  iter :983 ]train loss : 0.327962 ,train acc: 0.844676 ,val loss : 0.378971 ,val acc : 0.828247\n",
      "[ ecpho : 9  iter :984 ]train loss : 0.443843 ,train acc: 0.834686 ,val loss : 0.382596 ,val acc : 0.827271\n",
      "[ ecpho : 9  iter :985 ]train loss : 0.379474 ,train acc: 0.807007 ,val loss : 0.381552 ,val acc : 0.826080\n",
      "[ ecpho : 9  iter :986 ]train loss : 0.339525 ,train acc: 0.854106 ,val loss : 0.380010 ,val acc : 0.827209\n",
      "[ ecpho : 9  iter :987 ]train loss : 0.344647 ,train acc: 0.804810 ,val loss : 0.383370 ,val acc : 0.827179\n",
      "[ ecpho : 9  iter :988 ]train loss : 0.330375 ,train acc: 0.851959 ,val loss : 0.376554 ,val acc : 0.828400\n",
      "[ ecpho : 9  iter :989 ]train loss : 0.298327 ,train acc: 0.858042 ,val loss : 0.378633 ,val acc : 0.826965\n",
      "[ ecpho : 9  iter :990 ]train loss : 0.314174 ,train acc: 0.854197 ,val loss : 0.375831 ,val acc : 0.832275\n",
      "[ ecpho : 9  iter :991 ]train loss : 0.308516 ,train acc: 0.869588 ,val loss : 0.381639 ,val acc : 0.825989\n",
      "[ ecpho : 9  iter :992 ]train loss : 0.399761 ,train acc: 0.809723 ,val loss : 0.380464 ,val acc : 0.830688\n",
      "[ ecpho : 9  iter :993 ]train loss : 0.296096 ,train acc: 0.868917 ,val loss : 0.379930 ,val acc : 0.829773\n",
      "[ ecpho : 9  iter :994 ]train loss : 0.302815 ,train acc: 0.867981 ,val loss : 0.385608 ,val acc : 0.827087\n",
      "[ ecpho : 9  iter :995 ]train loss : 0.267866 ,train acc: 0.871002 ,val loss : 0.381436 ,val acc : 0.827301\n",
      "[ ecpho : 9  iter :996 ]train loss : 0.273540 ,train acc: 0.871480 ,val loss : 0.383325 ,val acc : 0.827515\n",
      "[ ecpho : 9  iter :997 ]train loss : 0.268587 ,train acc: 0.864492 ,val loss : 0.375346 ,val acc : 0.831604\n",
      "[ ecpho : 9  iter :998 ]train loss : 0.282863 ,train acc: 0.863322 ,val loss : 0.380511 ,val acc : 0.825165\n",
      "[ ecpho : 9  iter :999 ]train loss : 0.391783 ,train acc: 0.843445 ,val loss : 0.375090 ,val acc : 0.829407\n",
      "[ ecpho : 9  iter :1000 ]train loss : 0.301293 ,train acc: 0.862234 ,val loss : 0.379027 ,val acc : 0.829224\n",
      "=============================================\n",
      "[ 9 ] average train loss : 0.313789 train acc : 0.855016\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "data_files = glob.glob('../unet_3d_traindata/*_data_*.npy')\n",
    "valdata_files = glob.glob('../unet_3d_valdata/*_data_*.npy')\n",
    "\n",
    "print(len(data_files))\n",
    "print(len(valdata_files))\n",
    "\n",
    "np.random.shuffle(data_files)\n",
    "np.random.shuffle(data_files)\n",
    "np.random.shuffle(valdata_files)\n",
    "train_datafiles = data_files[:]\n",
    "val_datafiles = valdata_files[:10]\n",
    "\n",
    "\n",
    "evaled_weights = []\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "val_costs = []\n",
    "val_accs = []\n",
    "for val_datafile in val_datafiles[:2]:\n",
    "    val_data = np.load(val_datafile)\n",
    "    val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "    val_norm[val_norm > 1] = 1\n",
    "    val_norm[val_norm < 0] = 0\n",
    "    val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "    val_label = np.load(val_datafiles[0].replace('_data_','_label_'))\n",
    "    val_label = np.reshape(val_label,[1,32,32,32,2])\n",
    "    \n",
    "    val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                       feed_dict={input_x:val_norm,input_y:val_label,keep_prob:0.5})\n",
    "    print('val loss: %f ,val acc : %f' % (val_cost,val_acc))\n",
    "    val_costs.append(val_cost)\n",
    "    val_accs.append(val_acc)\n",
    "print(np.mean(val_cost),np.mean(val_acc))\n",
    "\n",
    "for ecpho in range(10):\n",
    "    iteration = 0\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    #tmp_tranfiles = train_datafiles[ecpho*5000:(ecpho + 1)*5000]\n",
    "    tmp_tranfiles = np.random.choice(train_datafiles,5000)\n",
    "    for idx in np.arange(0,len(tmp_tranfiles),5):\n",
    "        iteration += 1\n",
    "        tmp_files = tmp_tranfiles[idx:idx+3]\n",
    "        train_datas = []\n",
    "        train_labels = []\n",
    "        for train_datafile in tmp_files:\n",
    "            train_data = np.load(train_datafile)\n",
    "            train_label = np.load(train_datafile.replace('_data_','_label_'))\n",
    "            train_norm = (train_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            train_norm[train_norm > 1] = 1\n",
    "            train_norm[train_norm < 0] = 0\n",
    "            train_datas.append(train_norm)\n",
    "            train_labels.append(train_label)\n",
    "        \n",
    "        train_datas = np.array(train_datas)\n",
    "        train_labels = np.array(train_labels)\n",
    "        _,train_cost,train_output_shape,train_acc,ws = sess.run([optimizer,cost,logits_shape,accuracy,weights],\n",
    "                                       feed_dict={input_x:train_datas,input_y:train_labels,keep_prob:0.5})\n",
    "        train_loss.append(train_cost)\n",
    "        train_accs.append(train_acc)\n",
    "        val_costs = []\n",
    "        val_accs = []\n",
    "        for val_datafile in val_datafiles[:10]:\n",
    "            val_data = np.load(val_datafile)\n",
    "            val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            val_norm[val_norm > 1] = 1\n",
    "            val_norm[val_norm < 0] = 0\n",
    "            val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "            val_label = np.load(val_datafiles[0].replace('_data_','_label_'))\n",
    "            val_label = np.reshape(val_label,[1,32,32,32,2])\n",
    "            val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                           feed_dict={input_x:val_norm,input_y:val_label,keep_prob:0.5})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accs.append(val_acc)\n",
    "        print('[ ecpho : %d  iter :%d ]train loss : %f ,train acc: %f ,val loss : %f ,val acc : %f' % (ecpho,iteration,train_cost,train_acc,np.mean(val_cost),np.mean(val_acc)))\n",
    "    print(\"=============================================\")\n",
    "    print(\"[ %d ] average train loss : %f train acc : %f\" % (ecpho,np.mean(train_loss),np.mean(train_accs)))\n",
    "    \n",
    "    modelpath = './unet3d_models_7/ecpho_'+str(ecpho)\n",
    "    if not os.path.exists(modelpath):\n",
    "        os.mkdir(modelpath)\n",
    "    saver.save(sess,modelpath+'/unet3d_model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16103\n",
      "17\n",
      "val loss: 0.607566 ,val acc : 0.650421\n",
      "val loss: 0.598150 ,val acc : 0.651123\n",
      "0.59815 0.651123\n",
      "[ ecpho : 0  iter :1 ]train loss : 0.607897 ,train acc: 0.652008 ,val loss : 0.591170 ,val acc : 0.651947\n",
      "[ ecpho : 0  iter :2 ]train loss : 0.631531 ,train acc: 0.637268 ,val loss : 0.575040 ,val acc : 0.659973\n",
      "[ ecpho : 0  iter :3 ]train loss : 0.571188 ,train acc: 0.661194 ,val loss : 0.550397 ,val acc : 0.668182\n",
      "[ ecpho : 0  iter :4 ]train loss : 0.580733 ,train acc: 0.657868 ,val loss : 0.538635 ,val acc : 0.784729\n",
      "[ ecpho : 0  iter :5 ]train loss : 0.522726 ,train acc: 0.796479 ,val loss : 0.516778 ,val acc : 0.789062\n",
      "[ ecpho : 0  iter :6 ]train loss : 0.500829 ,train acc: 0.798717 ,val loss : 0.489672 ,val acc : 0.790131\n",
      "[ ecpho : 0  iter :7 ]train loss : 0.517230 ,train acc: 0.766948 ,val loss : 0.462798 ,val acc : 0.796478\n",
      "[ ecpho : 0  iter :8 ]train loss : 0.464639 ,train acc: 0.800761 ,val loss : 0.444146 ,val acc : 0.808075\n",
      "[ ecpho : 0  iter :9 ]train loss : 0.471285 ,train acc: 0.766490 ,val loss : 0.425110 ,val acc : 0.818634\n",
      "[ ecpho : 0  iter :10 ]train loss : 0.425093 ,train acc: 0.814891 ,val loss : 0.399117 ,val acc : 0.831085\n",
      "[ ecpho : 0  iter :11 ]train loss : 0.371478 ,train acc: 0.838888 ,val loss : 0.381225 ,val acc : 0.837646\n",
      "[ ecpho : 0  iter :12 ]train loss : 0.362003 ,train acc: 0.829824 ,val loss : 0.364782 ,val acc : 0.841949\n",
      "[ ecpho : 0  iter :13 ]train loss : 0.354014 ,train acc: 0.843842 ,val loss : 0.356100 ,val acc : 0.840912\n",
      "[ ecpho : 0  iter :14 ]train loss : 0.310706 ,train acc: 0.840180 ,val loss : 0.338655 ,val acc : 0.847778\n",
      "[ ecpho : 0  iter :15 ]train loss : 0.316604 ,train acc: 0.841065 ,val loss : 0.337032 ,val acc : 0.856049\n",
      "[ ecpho : 0  iter :16 ]train loss : 0.305656 ,train acc: 0.852946 ,val loss : 0.334835 ,val acc : 0.862854\n",
      "[ ecpho : 0  iter :17 ]train loss : 0.283077 ,train acc: 0.864248 ,val loss : 0.328528 ,val acc : 0.862915\n",
      "[ ecpho : 0  iter :18 ]train loss : 0.300974 ,train acc: 0.863312 ,val loss : 0.322837 ,val acc : 0.864685\n",
      "[ ecpho : 0  iter :19 ]train loss : 0.245971 ,train acc: 0.871145 ,val loss : 0.310327 ,val acc : 0.870758\n",
      "[ ecpho : 0  iter :20 ]train loss : 0.234059 ,train acc: 0.866659 ,val loss : 0.316986 ,val acc : 0.880371\n",
      "[ ecpho : 0  iter :21 ]train loss : 0.249485 ,train acc: 0.891612 ,val loss : 0.301885 ,val acc : 0.874756\n",
      "[ ecpho : 0  iter :22 ]train loss : 0.211422 ,train acc: 0.893606 ,val loss : 0.307487 ,val acc : 0.873291\n",
      "[ ecpho : 0  iter :23 ]train loss : 0.305152 ,train acc: 0.813497 ,val loss : 0.301678 ,val acc : 0.888336\n",
      "[ ecpho : 0  iter :24 ]train loss : 0.228538 ,train acc: 0.904165 ,val loss : 0.290268 ,val acc : 0.893219\n",
      "[ ecpho : 0  iter :25 ]train loss : 0.301582 ,train acc: 0.868653 ,val loss : 0.285931 ,val acc : 0.886261\n",
      "[ ecpho : 0  iter :26 ]train loss : 0.210437 ,train acc: 0.890890 ,val loss : 0.280003 ,val acc : 0.893860\n",
      "[ ecpho : 0  iter :27 ]train loss : 0.192063 ,train acc: 0.908864 ,val loss : 0.276539 ,val acc : 0.902191\n",
      "[ ecpho : 0  iter :28 ]train loss : 0.200357 ,train acc: 0.892446 ,val loss : 0.278926 ,val acc : 0.911438\n",
      "[ ecpho : 0  iter :29 ]train loss : 0.226035 ,train acc: 0.920176 ,val loss : 0.262610 ,val acc : 0.893616\n",
      "[ ecpho : 0  iter :30 ]train loss : 0.208010 ,train acc: 0.898905 ,val loss : 0.258544 ,val acc : 0.912109\n",
      "[ ecpho : 0  iter :31 ]train loss : 0.206608 ,train acc: 0.907257 ,val loss : 0.260047 ,val acc : 0.924408\n",
      "[ ecpho : 0  iter :32 ]train loss : 0.343807 ,train acc: 0.866913 ,val loss : 0.252103 ,val acc : 0.916931\n",
      "[ ecpho : 0  iter :33 ]train loss : 0.200657 ,train acc: 0.905965 ,val loss : 0.242921 ,val acc : 0.923523\n",
      "[ ecpho : 0  iter :34 ]train loss : 0.226419 ,train acc: 0.896983 ,val loss : 0.243958 ,val acc : 0.931366\n",
      "[ ecpho : 0  iter :35 ]train loss : 0.190972 ,train acc: 0.913167 ,val loss : 0.233795 ,val acc : 0.937653\n",
      "[ ecpho : 0  iter :36 ]train loss : 0.194075 ,train acc: 0.935313 ,val loss : 0.230036 ,val acc : 0.934937\n",
      "[ ecpho : 0  iter :37 ]train loss : 0.205861 ,train acc: 0.924113 ,val loss : 0.225605 ,val acc : 0.932892\n",
      "[ ecpho : 0  iter :38 ]train loss : 0.176603 ,train acc: 0.925974 ,val loss : 0.226155 ,val acc : 0.943024\n",
      "[ ecpho : 0  iter :39 ]train loss : 0.203844 ,train acc: 0.944366 ,val loss : 0.221198 ,val acc : 0.946655\n",
      "[ ecpho : 0  iter :40 ]train loss : 0.137409 ,train acc: 0.969889 ,val loss : 0.216114 ,val acc : 0.948914\n",
      "[ ecpho : 0  iter :41 ]train loss : 0.250979 ,train acc: 0.918050 ,val loss : 0.207476 ,val acc : 0.950928\n",
      "[ ecpho : 0  iter :42 ]train loss : 0.172615 ,train acc: 0.951538 ,val loss : 0.206563 ,val acc : 0.952362\n",
      "[ ecpho : 0  iter :43 ]train loss : 0.284307 ,train acc: 0.901703 ,val loss : 0.196728 ,val acc : 0.955078\n",
      "[ ecpho : 0  iter :44 ]train loss : 0.142760 ,train acc: 0.972412 ,val loss : 0.194060 ,val acc : 0.955627\n",
      "[ ecpho : 0  iter :45 ]train loss : 0.132441 ,train acc: 0.972656 ,val loss : 0.188855 ,val acc : 0.959412\n",
      "[ ecpho : 0  iter :46 ]train loss : 0.187488 ,train acc: 0.951060 ,val loss : 0.189091 ,val acc : 0.957947\n",
      "[ ecpho : 0  iter :47 ]train loss : 0.170479 ,train acc: 0.958221 ,val loss : 0.179605 ,val acc : 0.963043\n",
      "[ ecpho : 0  iter :48 ]train loss : 0.164797 ,train acc: 0.962972 ,val loss : 0.178246 ,val acc : 0.962158\n",
      "[ ecpho : 0  iter :49 ]train loss : 0.197242 ,train acc: 0.949381 ,val loss : 0.175246 ,val acc : 0.963470\n",
      "[ ecpho : 0  iter :50 ]train loss : 0.151520 ,train acc: 0.966715 ,val loss : 0.170731 ,val acc : 0.962708\n",
      "[ ecpho : 0  iter :51 ]train loss : 0.181092 ,train acc: 0.946279 ,val loss : 0.172327 ,val acc : 0.962616\n",
      "[ ecpho : 0  iter :52 ]train loss : 0.223781 ,train acc: 0.907369 ,val loss : 0.176207 ,val acc : 0.961975\n",
      "[ ecpho : 0  iter :53 ]train loss : 0.151455 ,train acc: 0.965861 ,val loss : 0.177111 ,val acc : 0.971069\n",
      "[ ecpho : 0  iter :54 ]train loss : 0.166514 ,train acc: 0.959564 ,val loss : 0.176752 ,val acc : 0.967743\n",
      "[ ecpho : 0  iter :55 ]train loss : 0.111398 ,train acc: 0.984965 ,val loss : 0.178206 ,val acc : 0.965881\n",
      "[ ecpho : 0  iter :56 ]train loss : 0.171203 ,train acc: 0.959177 ,val loss : 0.177050 ,val acc : 0.970520\n",
      "[ ecpho : 0  iter :57 ]train loss : 0.125254 ,train acc: 0.978230 ,val loss : 0.180347 ,val acc : 0.970245\n",
      "[ ecpho : 0  iter :58 ]train loss : 0.145707 ,train acc: 0.978403 ,val loss : 0.172100 ,val acc : 0.967041\n",
      "[ ecpho : 0  iter :59 ]train loss : 0.241265 ,train acc: 0.878672 ,val loss : 0.180972 ,val acc : 0.958466\n",
      "[ ecpho : 0  iter :60 ]train loss : 0.158941 ,train acc: 0.960947 ,val loss : 0.173360 ,val acc : 0.973389\n",
      "[ ecpho : 0  iter :61 ]train loss : 0.203040 ,train acc: 0.946645 ,val loss : 0.176689 ,val acc : 0.972229\n",
      "[ ecpho : 0  iter :62 ]train loss : 0.170780 ,train acc: 0.959289 ,val loss : 0.177112 ,val acc : 0.960693\n",
      "[ ecpho : 0  iter :63 ]train loss : 0.120286 ,train acc: 0.972615 ,val loss : 0.174445 ,val acc : 0.969086\n",
      "[ ecpho : 0  iter :64 ]train loss : 0.111705 ,train acc: 0.986623 ,val loss : 0.166950 ,val acc : 0.972717\n",
      "[ ecpho : 0  iter :65 ]train loss : 0.165042 ,train acc: 0.927348 ,val loss : 0.168986 ,val acc : 0.967102\n",
      "[ ecpho : 0  iter :66 ]train loss : 0.138065 ,train acc: 0.974344 ,val loss : 0.172210 ,val acc : 0.969116\n",
      "[ ecpho : 0  iter :67 ]train loss : 0.224140 ,train acc: 0.950276 ,val loss : 0.165376 ,val acc : 0.973938\n",
      "[ ecpho : 0  iter :68 ]train loss : 0.112979 ,train acc: 0.984324 ,val loss : 0.158625 ,val acc : 0.971191\n",
      "[ ecpho : 0  iter :69 ]train loss : 0.211876 ,train acc: 0.901581 ,val loss : 0.178765 ,val acc : 0.955627\n",
      "[ ecpho : 0  iter :70 ]train loss : 0.127001 ,train acc: 0.970031 ,val loss : 0.168108 ,val acc : 0.972290\n",
      "[ ecpho : 0  iter :71 ]train loss : 0.165127 ,train acc: 0.959432 ,val loss : 0.167760 ,val acc : 0.973480\n",
      "[ ecpho : 0  iter :72 ]train loss : 0.109827 ,train acc: 0.980346 ,val loss : 0.169255 ,val acc : 0.967438\n",
      "[ ecpho : 0  iter :73 ]train loss : 0.105879 ,train acc: 0.981119 ,val loss : 0.176728 ,val acc : 0.968506\n",
      "[ ecpho : 0  iter :74 ]train loss : 0.164478 ,train acc: 0.966980 ,val loss : 0.171682 ,val acc : 0.973907\n",
      "[ ecpho : 0  iter :75 ]train loss : 0.088635 ,train acc: 0.992279 ,val loss : 0.170799 ,val acc : 0.974762\n",
      "[ ecpho : 0  iter :76 ]train loss : 0.092177 ,train acc: 0.989552 ,val loss : 0.172189 ,val acc : 0.974335\n",
      "[ ecpho : 0  iter :77 ]train loss : 0.107106 ,train acc: 0.981353 ,val loss : 0.175722 ,val acc : 0.971497\n",
      "[ ecpho : 0  iter :78 ]train loss : 0.096159 ,train acc: 0.989837 ,val loss : 0.172180 ,val acc : 0.973999\n",
      "[ ecpho : 0  iter :79 ]train loss : 0.116122 ,train acc: 0.984141 ,val loss : 0.171859 ,val acc : 0.973389\n",
      "[ ecpho : 0  iter :80 ]train loss : 0.141230 ,train acc: 0.981343 ,val loss : 0.167905 ,val acc : 0.973022\n",
      "[ ecpho : 0  iter :81 ]train loss : 0.144896 ,train acc: 0.980550 ,val loss : 0.164234 ,val acc : 0.974091\n",
      "[ ecpho : 0  iter :82 ]train loss : 0.109131 ,train acc: 0.989095 ,val loss : 0.155486 ,val acc : 0.976807\n",
      "[ ecpho : 0  iter :83 ]train loss : 0.146553 ,train acc: 0.953288 ,val loss : 0.158865 ,val acc : 0.976288\n",
      "[ ecpho : 0  iter :84 ]train loss : 0.197446 ,train acc: 0.928192 ,val loss : 0.162396 ,val acc : 0.971619\n",
      "[ ecpho : 0  iter :85 ]train loss : 0.118323 ,train acc: 0.971039 ,val loss : 0.162184 ,val acc : 0.971954\n",
      "[ ecpho : 0  iter :86 ]train loss : 0.104503 ,train acc: 0.986124 ,val loss : 0.161903 ,val acc : 0.977386\n",
      "[ ecpho : 0  iter :87 ]train loss : 0.105740 ,train acc: 0.993235 ,val loss : 0.159127 ,val acc : 0.975342\n",
      "[ ecpho : 0  iter :88 ]train loss : 0.104970 ,train acc: 0.989268 ,val loss : 0.160483 ,val acc : 0.974365\n",
      "[ ecpho : 0  iter :89 ]train loss : 0.126319 ,train acc: 0.963999 ,val loss : 0.158705 ,val acc : 0.975616\n",
      "[ ecpho : 0  iter :90 ]train loss : 0.118515 ,train acc: 0.978383 ,val loss : 0.159588 ,val acc : 0.977234\n",
      "[ ecpho : 0  iter :91 ]train loss : 0.095231 ,train acc: 0.991343 ,val loss : 0.157705 ,val acc : 0.978027\n",
      "[ ecpho : 0  iter :92 ]train loss : 0.220361 ,train acc: 0.959432 ,val loss : 0.148446 ,val acc : 0.977966\n",
      "[ ecpho : 0  iter :93 ]train loss : 0.166470 ,train acc: 0.943207 ,val loss : 0.145119 ,val acc : 0.973907\n",
      "[ ecpho : 0  iter :94 ]train loss : 0.194606 ,train acc: 0.963460 ,val loss : 0.137765 ,val acc : 0.977417\n",
      "[ ecpho : 0  iter :95 ]train loss : 0.099867 ,train acc: 0.988657 ,val loss : 0.133374 ,val acc : 0.978607\n",
      "[ ecpho : 0  iter :96 ]train loss : 0.186961 ,train acc: 0.953186 ,val loss : 0.135825 ,val acc : 0.973938\n",
      "[ ecpho : 0  iter :97 ]train loss : 0.161116 ,train acc: 0.958089 ,val loss : 0.141676 ,val acc : 0.972717\n",
      "[ ecpho : 0  iter :98 ]train loss : 0.285166 ,train acc: 0.877696 ,val loss : 0.156185 ,val acc : 0.970032\n",
      "[ ecpho : 0  iter :99 ]train loss : 0.128548 ,train acc: 0.976349 ,val loss : 0.159669 ,val acc : 0.977661\n",
      "[ ecpho : 0  iter :100 ]train loss : 0.093382 ,train acc: 0.994425 ,val loss : 0.159883 ,val acc : 0.978546\n",
      "[ ecpho : 0  iter :101 ]train loss : 0.132297 ,train acc: 0.983418 ,val loss : 0.164140 ,val acc : 0.974365\n",
      "[ ecpho : 0  iter :102 ]train loss : 0.122562 ,train acc: 0.964813 ,val loss : 0.166761 ,val acc : 0.969574\n",
      "[ ecpho : 0  iter :103 ]train loss : 0.117656 ,train acc: 0.963847 ,val loss : 0.163227 ,val acc : 0.973114\n",
      "[ ecpho : 0  iter :104 ]train loss : 0.115394 ,train acc: 0.977885 ,val loss : 0.165050 ,val acc : 0.978638\n",
      "[ ecpho : 0  iter :105 ]train loss : 0.237622 ,train acc: 0.883789 ,val loss : 0.167651 ,val acc : 0.978119\n",
      "[ ecpho : 0  iter :106 ]train loss : 0.166274 ,train acc: 0.970194 ,val loss : 0.167018 ,val acc : 0.974487\n",
      "[ ecpho : 0  iter :107 ]train loss : 0.105090 ,train acc: 0.987732 ,val loss : 0.163440 ,val acc : 0.975922\n",
      "[ ecpho : 0  iter :108 ]train loss : 0.136875 ,train acc: 0.975148 ,val loss : 0.163559 ,val acc : 0.978516\n",
      "[ ecpho : 0  iter :109 ]train loss : 0.152788 ,train acc: 0.955902 ,val loss : 0.162121 ,val acc : 0.977295\n",
      "[ ecpho : 0  iter :110 ]train loss : 0.116134 ,train acc: 0.984822 ,val loss : 0.155239 ,val acc : 0.976990\n",
      "[ ecpho : 0  iter :111 ]train loss : 0.112410 ,train acc: 0.975097 ,val loss : 0.158105 ,val acc : 0.978027\n",
      "[ ecpho : 0  iter :112 ]train loss : 0.075847 ,train acc: 0.994893 ,val loss : 0.157045 ,val acc : 0.978821\n",
      "[ ecpho : 0  iter :113 ]train loss : 0.076126 ,train acc: 0.993286 ,val loss : 0.156310 ,val acc : 0.978790\n",
      "[ ecpho : 0  iter :114 ]train loss : 0.085332 ,train acc: 0.989939 ,val loss : 0.156408 ,val acc : 0.979187\n",
      "[ ecpho : 0  iter :115 ]train loss : 0.123824 ,train acc: 0.989146 ,val loss : 0.157294 ,val acc : 0.974945\n",
      "[ ecpho : 0  iter :116 ]train loss : 0.131721 ,train acc: 0.982096 ,val loss : 0.150438 ,val acc : 0.976105\n",
      "[ ecpho : 0  iter :117 ]train loss : 0.130805 ,train acc: 0.981272 ,val loss : 0.141113 ,val acc : 0.978821\n",
      "[ ecpho : 0  iter :118 ]train loss : 0.092260 ,train acc: 0.984395 ,val loss : 0.141793 ,val acc : 0.979614\n",
      "[ ecpho : 0  iter :119 ]train loss : 0.116525 ,train acc: 0.991363 ,val loss : 0.139447 ,val acc : 0.978149\n",
      "[ ecpho : 0  iter :120 ]train loss : 0.098087 ,train acc: 0.986501 ,val loss : 0.134692 ,val acc : 0.976532\n",
      "[ ecpho : 0  iter :121 ]train loss : 0.072767 ,train acc: 0.994557 ,val loss : 0.134979 ,val acc : 0.977509\n",
      "[ ecpho : 0  iter :122 ]train loss : 0.198653 ,train acc: 0.952138 ,val loss : 0.133120 ,val acc : 0.978790\n",
      "[ ecpho : 0  iter :123 ]train loss : 0.071827 ,train acc: 0.996633 ,val loss : 0.133920 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :124 ]train loss : 0.230888 ,train acc: 0.913401 ,val loss : 0.141695 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :125 ]train loss : 0.090497 ,train acc: 0.989288 ,val loss : 0.147744 ,val acc : 0.978210\n",
      "[ ecpho : 0  iter :126 ]train loss : 0.133418 ,train acc: 0.965637 ,val loss : 0.150865 ,val acc : 0.977783\n",
      "[ ecpho : 0  iter :127 ]train loss : 0.140575 ,train acc: 0.959188 ,val loss : 0.156767 ,val acc : 0.978027\n",
      "[ ecpho : 0  iter :128 ]train loss : 0.166427 ,train acc: 0.930765 ,val loss : 0.158778 ,val acc : 0.978210\n",
      "[ ecpho : 0  iter :129 ]train loss : 0.114823 ,train acc: 0.980153 ,val loss : 0.161431 ,val acc : 0.978271\n",
      "[ ecpho : 0  iter :130 ]train loss : 0.234231 ,train acc: 0.950053 ,val loss : 0.157958 ,val acc : 0.979095\n",
      "[ ecpho : 0  iter :131 ]train loss : 0.173217 ,train acc: 0.955017 ,val loss : 0.154296 ,val acc : 0.976959\n",
      "[ ecpho : 0  iter :132 ]train loss : 0.194829 ,train acc: 0.918925 ,val loss : 0.154841 ,val acc : 0.975067\n",
      "[ ecpho : 0  iter :133 ]train loss : 0.235263 ,train acc: 0.895660 ,val loss : 0.158400 ,val acc : 0.972198\n",
      "[ ecpho : 0  iter :134 ]train loss : 0.136255 ,train acc: 0.962076 ,val loss : 0.165011 ,val acc : 0.976288\n",
      "[ ecpho : 0  iter :135 ]train loss : 0.106249 ,train acc: 0.989166 ,val loss : 0.159336 ,val acc : 0.979095\n",
      "[ ecpho : 0  iter :136 ]train loss : 0.163277 ,train acc: 0.962799 ,val loss : 0.158665 ,val acc : 0.978760\n",
      "[ ecpho : 0  iter :137 ]train loss : 0.128239 ,train acc: 0.967255 ,val loss : 0.157735 ,val acc : 0.977539\n",
      "[ ecpho : 0  iter :138 ]train loss : 0.184033 ,train acc: 0.935241 ,val loss : 0.158685 ,val acc : 0.976593\n",
      "[ ecpho : 0  iter :139 ]train loss : 0.088832 ,train acc: 0.984720 ,val loss : 0.161605 ,val acc : 0.977051\n",
      "[ ecpho : 0  iter :140 ]train loss : 0.116495 ,train acc: 0.971862 ,val loss : 0.162194 ,val acc : 0.977966\n",
      "[ ecpho : 0  iter :141 ]train loss : 0.123483 ,train acc: 0.969482 ,val loss : 0.161448 ,val acc : 0.978363\n",
      "[ ecpho : 0  iter :142 ]train loss : 0.194192 ,train acc: 0.945811 ,val loss : 0.162859 ,val acc : 0.977661\n",
      "[ ecpho : 0  iter :143 ]train loss : 0.105932 ,train acc: 0.989919 ,val loss : 0.160734 ,val acc : 0.977875\n",
      "[ ecpho : 0  iter :144 ]train loss : 0.105553 ,train acc: 0.990915 ,val loss : 0.154458 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :145 ]train loss : 0.098717 ,train acc: 0.978943 ,val loss : 0.154262 ,val acc : 0.978943\n",
      "[ ecpho : 0  iter :146 ]train loss : 0.095329 ,train acc: 0.993835 ,val loss : 0.148244 ,val acc : 0.977936\n",
      "[ ecpho : 0  iter :147 ]train loss : 0.186665 ,train acc: 0.940511 ,val loss : 0.145551 ,val acc : 0.977478\n",
      "[ ecpho : 0  iter :148 ]train loss : 0.116251 ,train acc: 0.987101 ,val loss : 0.140362 ,val acc : 0.978363\n",
      "[ ecpho : 0  iter :149 ]train loss : 0.080723 ,train acc: 0.991404 ,val loss : 0.138260 ,val acc : 0.978943\n",
      "[ ecpho : 0  iter :150 ]train loss : 0.280665 ,train acc: 0.873677 ,val loss : 0.144616 ,val acc : 0.978546\n",
      "[ ecpho : 0  iter :151 ]train loss : 0.079521 ,train acc: 0.991506 ,val loss : 0.145217 ,val acc : 0.977936\n",
      "[ ecpho : 0  iter :152 ]train loss : 0.093884 ,train acc: 0.985524 ,val loss : 0.150368 ,val acc : 0.978638\n",
      "[ ecpho : 0  iter :153 ]train loss : 0.090128 ,train acc: 0.984863 ,val loss : 0.148929 ,val acc : 0.978638\n",
      "[ ecpho : 0  iter :154 ]train loss : 0.226421 ,train acc: 0.919209 ,val loss : 0.151045 ,val acc : 0.978119\n",
      "[ ecpho : 0  iter :155 ]train loss : 0.190038 ,train acc: 0.915547 ,val loss : 0.156100 ,val acc : 0.976318\n",
      "[ ecpho : 0  iter :156 ]train loss : 0.116728 ,train acc: 0.976603 ,val loss : 0.159205 ,val acc : 0.977600\n",
      "[ ecpho : 0  iter :157 ]train loss : 0.116026 ,train acc: 0.982716 ,val loss : 0.161560 ,val acc : 0.978821\n",
      "[ ecpho : 0  iter :158 ]train loss : 0.089596 ,train acc: 0.988210 ,val loss : 0.158303 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :159 ]train loss : 0.107333 ,train acc: 0.977712 ,val loss : 0.158585 ,val acc : 0.979095\n",
      "[ ecpho : 0  iter :160 ]train loss : 0.114240 ,train acc: 0.973053 ,val loss : 0.157299 ,val acc : 0.978851\n",
      "[ ecpho : 0  iter :161 ]train loss : 0.168780 ,train acc: 0.958567 ,val loss : 0.154812 ,val acc : 0.978607\n",
      "[ ecpho : 0  iter :162 ]train loss : 0.189713 ,train acc: 0.931742 ,val loss : 0.155381 ,val acc : 0.978149\n",
      "[ ecpho : 0  iter :163 ]train loss : 0.117561 ,train acc: 0.977518 ,val loss : 0.154101 ,val acc : 0.978485\n",
      "[ ecpho : 0  iter :164 ]train loss : 0.107397 ,train acc: 0.981465 ,val loss : 0.152232 ,val acc : 0.978638\n",
      "[ ecpho : 0  iter :165 ]train loss : 0.196899 ,train acc: 0.922994 ,val loss : 0.155084 ,val acc : 0.978516\n",
      "[ ecpho : 0  iter :166 ]train loss : 0.072459 ,train acc: 0.992350 ,val loss : 0.156901 ,val acc : 0.978851\n",
      "[ ecpho : 0  iter :167 ]train loss : 0.122390 ,train acc: 0.986948 ,val loss : 0.151080 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :168 ]train loss : 0.171146 ,train acc: 0.938873 ,val loss : 0.153289 ,val acc : 0.978424\n",
      "[ ecpho : 0  iter :169 ]train loss : 0.109223 ,train acc: 0.981160 ,val loss : 0.152495 ,val acc : 0.978394\n",
      "[ ecpho : 0  iter :170 ]train loss : 0.106592 ,train acc: 0.981353 ,val loss : 0.151043 ,val acc : 0.978943\n",
      "[ ecpho : 0  iter :171 ]train loss : 0.131045 ,train acc: 0.979787 ,val loss : 0.146074 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :172 ]train loss : 0.223739 ,train acc: 0.920278 ,val loss : 0.140824 ,val acc : 0.978821\n",
      "[ ecpho : 0  iter :173 ]train loss : 0.107545 ,train acc: 0.982706 ,val loss : 0.140170 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :174 ]train loss : 0.167851 ,train acc: 0.959706 ,val loss : 0.138666 ,val acc : 0.978882\n",
      "[ ecpho : 0  iter :175 ]train loss : 0.111833 ,train acc: 0.981974 ,val loss : 0.136880 ,val acc : 0.978333\n",
      "[ ecpho : 0  iter :176 ]train loss : 0.096592 ,train acc: 0.986206 ,val loss : 0.133106 ,val acc : 0.978699\n",
      "[ ecpho : 0  iter :177 ]train loss : 0.119250 ,train acc: 0.983205 ,val loss : 0.129450 ,val acc : 0.978760\n",
      "[ ecpho : 0  iter :178 ]train loss : 0.091784 ,train acc: 0.987630 ,val loss : 0.129008 ,val acc : 0.978851\n",
      "[ ecpho : 0  iter :179 ]train loss : 0.088238 ,train acc: 0.991679 ,val loss : 0.128593 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :180 ]train loss : 0.082924 ,train acc: 0.993164 ,val loss : 0.128230 ,val acc : 0.978790\n",
      "[ ecpho : 0  iter :181 ]train loss : 0.071618 ,train acc: 0.994527 ,val loss : 0.128843 ,val acc : 0.979065\n",
      "[ ecpho : 0  iter :182 ]train loss : 0.141779 ,train acc: 0.964253 ,val loss : 0.132194 ,val acc : 0.979340\n",
      "[ ecpho : 0  iter :183 ]train loss : 0.096189 ,train acc: 0.981302 ,val loss : 0.139384 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :184 ]train loss : 0.079825 ,train acc: 0.992757 ,val loss : 0.142348 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :185 ]train loss : 0.121294 ,train acc: 0.976471 ,val loss : 0.145954 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :186 ]train loss : 0.075756 ,train acc: 0.995412 ,val loss : 0.144400 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :187 ]train loss : 0.075470 ,train acc: 0.993693 ,val loss : 0.141515 ,val acc : 0.979706\n",
      "[ ecpho : 0  iter :188 ]train loss : 0.174976 ,train acc: 0.939178 ,val loss : 0.146841 ,val acc : 0.979370\n",
      "[ ecpho : 0  iter :189 ]train loss : 0.148703 ,train acc: 0.976816 ,val loss : 0.144487 ,val acc : 0.978760\n",
      "[ ecpho : 0  iter :190 ]train loss : 0.060666 ,train acc: 0.996795 ,val loss : 0.145117 ,val acc : 0.978668\n",
      "[ ecpho : 0  iter :191 ]train loss : 0.084572 ,train acc: 0.989298 ,val loss : 0.145973 ,val acc : 0.979034\n",
      "[ ecpho : 0  iter :192 ]train loss : 0.094413 ,train acc: 0.981506 ,val loss : 0.144642 ,val acc : 0.979004\n",
      "[ ecpho : 0  iter :193 ]train loss : 0.109180 ,train acc: 0.987711 ,val loss : 0.145349 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :194 ]train loss : 0.200213 ,train acc: 0.918131 ,val loss : 0.145736 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :195 ]train loss : 0.117847 ,train acc: 0.980428 ,val loss : 0.143190 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :196 ]train loss : 0.054511 ,train acc: 0.996866 ,val loss : 0.149693 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :197 ]train loss : 0.172044 ,train acc: 0.966919 ,val loss : 0.142040 ,val acc : 0.979645\n",
      "[ ecpho : 0  iter :198 ]train loss : 0.079933 ,train acc: 0.989715 ,val loss : 0.139703 ,val acc : 0.979706\n",
      "[ ecpho : 0  iter :199 ]train loss : 0.067440 ,train acc: 0.996968 ,val loss : 0.134318 ,val acc : 0.979706\n",
      "[ ecpho : 0  iter :200 ]train loss : 0.209269 ,train acc: 0.929748 ,val loss : 0.134175 ,val acc : 0.978638\n",
      "[ ecpho : 0  iter :201 ]train loss : 0.080240 ,train acc: 0.993947 ,val loss : 0.133358 ,val acc : 0.977905\n",
      "[ ecpho : 0  iter :202 ]train loss : 0.083792 ,train acc: 0.991943 ,val loss : 0.128590 ,val acc : 0.979034\n",
      "[ ecpho : 0  iter :203 ]train loss : 0.218481 ,train acc: 0.920420 ,val loss : 0.132432 ,val acc : 0.978821\n",
      "[ ecpho : 0  iter :204 ]train loss : 0.073535 ,train acc: 0.991068 ,val loss : 0.133657 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :205 ]train loss : 0.149889 ,train acc: 0.972768 ,val loss : 0.130236 ,val acc : 0.979584\n",
      "[ ecpho : 0  iter :206 ]train loss : 0.080774 ,train acc: 0.990275 ,val loss : 0.129726 ,val acc : 0.979889\n",
      "[ ecpho : 0  iter :207 ]train loss : 0.173640 ,train acc: 0.949991 ,val loss : 0.121054 ,val acc : 0.979858\n",
      "[ ecpho : 0  iter :208 ]train loss : 0.100480 ,train acc: 0.981262 ,val loss : 0.119704 ,val acc : 0.979919\n",
      "[ ecpho : 0  iter :209 ]train loss : 0.098613 ,train acc: 0.984568 ,val loss : 0.120267 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :210 ]train loss : 0.086915 ,train acc: 0.990041 ,val loss : 0.120460 ,val acc : 0.979187\n",
      "[ ecpho : 0  iter :211 ]train loss : 0.082838 ,train acc: 0.992096 ,val loss : 0.120137 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :212 ]train loss : 0.108932 ,train acc: 0.979624 ,val loss : 0.124012 ,val acc : 0.978485\n",
      "[ ecpho : 0  iter :213 ]train loss : 0.271175 ,train acc: 0.899038 ,val loss : 0.139014 ,val acc : 0.978058\n",
      "[ ecpho : 0  iter :214 ]train loss : 0.075878 ,train acc: 0.994781 ,val loss : 0.147255 ,val acc : 0.978455\n",
      "[ ecpho : 0  iter :215 ]train loss : 0.178493 ,train acc: 0.929901 ,val loss : 0.153703 ,val acc : 0.978668\n",
      "[ ecpho : 0  iter :216 ]train loss : 0.160841 ,train acc: 0.928100 ,val loss : 0.157849 ,val acc : 0.978882\n",
      "[ ecpho : 0  iter :217 ]train loss : 0.125100 ,train acc: 0.992024 ,val loss : 0.159686 ,val acc : 0.979523\n",
      "[ ecpho : 0  iter :218 ]train loss : 0.105649 ,train acc: 0.991689 ,val loss : 0.167024 ,val acc : 0.979706\n",
      "[ ecpho : 0  iter :219 ]train loss : 0.105744 ,train acc: 0.981882 ,val loss : 0.159616 ,val acc : 0.979706\n",
      "[ ecpho : 0  iter :220 ]train loss : 0.137206 ,train acc: 0.979502 ,val loss : 0.153003 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :221 ]train loss : 0.119737 ,train acc: 0.986765 ,val loss : 0.148330 ,val acc : 0.978516\n",
      "[ ecpho : 0  iter :222 ]train loss : 0.143473 ,train acc: 0.976552 ,val loss : 0.137721 ,val acc : 0.979248\n",
      "[ ecpho : 0  iter :223 ]train loss : 0.149040 ,train acc: 0.966115 ,val loss : 0.129351 ,val acc : 0.979156\n",
      "[ ecpho : 0  iter :224 ]train loss : 0.093885 ,train acc: 0.982503 ,val loss : 0.126250 ,val acc : 0.979584\n",
      "[ ecpho : 0  iter :225 ]train loss : 0.197361 ,train acc: 0.928772 ,val loss : 0.130612 ,val acc : 0.979614\n",
      "[ ecpho : 0  iter :226 ]train loss : 0.106324 ,train acc: 0.977905 ,val loss : 0.132917 ,val acc : 0.979462\n",
      "[ ecpho : 0  iter :227 ]train loss : 0.130043 ,train acc: 0.970388 ,val loss : 0.130000 ,val acc : 0.979340\n",
      "[ ecpho : 0  iter :228 ]train loss : 0.103521 ,train acc: 0.980560 ,val loss : 0.130287 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :229 ]train loss : 0.063638 ,train acc: 0.996704 ,val loss : 0.129411 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :230 ]train loss : 0.150610 ,train acc: 0.955719 ,val loss : 0.124796 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :231 ]train loss : 0.081224 ,train acc: 0.989847 ,val loss : 0.127139 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :232 ]train loss : 0.088100 ,train acc: 0.983144 ,val loss : 0.129042 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :233 ]train loss : 0.088639 ,train acc: 0.987253 ,val loss : 0.130449 ,val acc : 0.979065\n",
      "[ ecpho : 0  iter :234 ]train loss : 0.235058 ,train acc: 0.902191 ,val loss : 0.144361 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :235 ]train loss : 0.090079 ,train acc: 0.992686 ,val loss : 0.151806 ,val acc : 0.979004\n",
      "[ ecpho : 0  iter :236 ]train loss : 0.078790 ,train acc: 0.987711 ,val loss : 0.159359 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :237 ]train loss : 0.138849 ,train acc: 0.988372 ,val loss : 0.158686 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :238 ]train loss : 0.097292 ,train acc: 0.984761 ,val loss : 0.158765 ,val acc : 0.979614\n",
      "[ ecpho : 0  iter :239 ]train loss : 0.072924 ,train acc: 0.993164 ,val loss : 0.154710 ,val acc : 0.979614\n",
      "[ ecpho : 0  iter :240 ]train loss : 0.095568 ,train acc: 0.992950 ,val loss : 0.154879 ,val acc : 0.979248\n",
      "[ ecpho : 0  iter :241 ]train loss : 0.137199 ,train acc: 0.985158 ,val loss : 0.148292 ,val acc : 0.979065\n",
      "[ ecpho : 0  iter :242 ]train loss : 0.064828 ,train acc: 0.994262 ,val loss : 0.143066 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :243 ]train loss : 0.156906 ,train acc: 0.949544 ,val loss : 0.141297 ,val acc : 0.979095\n",
      "[ ecpho : 0  iter :244 ]train loss : 0.102645 ,train acc: 0.984466 ,val loss : 0.136083 ,val acc : 0.979553\n",
      "[ ecpho : 0  iter :245 ]train loss : 0.090512 ,train acc: 0.989685 ,val loss : 0.129958 ,val acc : 0.979736\n",
      "[ ecpho : 0  iter :246 ]train loss : 0.111660 ,train acc: 0.962565 ,val loss : 0.130625 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :247 ]train loss : 0.155262 ,train acc: 0.957265 ,val loss : 0.131676 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :248 ]train loss : 0.072786 ,train acc: 0.991455 ,val loss : 0.128760 ,val acc : 0.979187\n",
      "[ ecpho : 0  iter :249 ]train loss : 0.110231 ,train acc: 0.974528 ,val loss : 0.130068 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :250 ]train loss : 0.084408 ,train acc: 0.990498 ,val loss : 0.127647 ,val acc : 0.979248\n",
      "[ ecpho : 0  iter :251 ]train loss : 0.090422 ,train acc: 0.990254 ,val loss : 0.122270 ,val acc : 0.979492\n",
      "[ ecpho : 0  iter :252 ]train loss : 0.099616 ,train acc: 0.987691 ,val loss : 0.117812 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :253 ]train loss : 0.100824 ,train acc: 0.981506 ,val loss : 0.116322 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :254 ]train loss : 0.071987 ,train acc: 0.995300 ,val loss : 0.117046 ,val acc : 0.979156\n",
      "[ ecpho : 0  iter :255 ]train loss : 0.083225 ,train acc: 0.989298 ,val loss : 0.117796 ,val acc : 0.979462\n",
      "[ ecpho : 0  iter :256 ]train loss : 0.109642 ,train acc: 0.982086 ,val loss : 0.128796 ,val acc : 0.979340\n",
      "[ ecpho : 0  iter :257 ]train loss : 0.254876 ,train acc: 0.897278 ,val loss : 0.145163 ,val acc : 0.978882\n",
      "[ ecpho : 0  iter :258 ]train loss : 0.118991 ,train acc: 0.989359 ,val loss : 0.156543 ,val acc : 0.979004\n",
      "[ ecpho : 0  iter :259 ]train loss : 0.125177 ,train acc: 0.990977 ,val loss : 0.153180 ,val acc : 0.979553\n",
      "[ ecpho : 0  iter :260 ]train loss : 0.138439 ,train acc: 0.974863 ,val loss : 0.154816 ,val acc : 0.979797\n",
      "[ ecpho : 0  iter :261 ]train loss : 0.103761 ,train acc: 0.985270 ,val loss : 0.148799 ,val acc : 0.979462\n",
      "[ ecpho : 0  iter :262 ]train loss : 0.085574 ,train acc: 0.985717 ,val loss : 0.145181 ,val acc : 0.979553\n",
      "[ ecpho : 0  iter :263 ]train loss : 0.170927 ,train acc: 0.931752 ,val loss : 0.145640 ,val acc : 0.979248\n",
      "[ ecpho : 0  iter :264 ]train loss : 0.058571 ,train acc: 0.994934 ,val loss : 0.147392 ,val acc : 0.979156\n",
      "[ ecpho : 0  iter :265 ]train loss : 0.077196 ,train acc: 0.991546 ,val loss : 0.143166 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :266 ]train loss : 0.105729 ,train acc: 0.984537 ,val loss : 0.138296 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :267 ]train loss : 0.127688 ,train acc: 0.968160 ,val loss : 0.146813 ,val acc : 0.979401\n",
      "[ ecpho : 0  iter :268 ]train loss : 0.052043 ,train acc: 0.996846 ,val loss : 0.148933 ,val acc : 0.979584\n",
      "[ ecpho : 0  iter :269 ]train loss : 0.112804 ,train acc: 0.963724 ,val loss : 0.153785 ,val acc : 0.979462\n",
      "[ ecpho : 0  iter :270 ]train loss : 0.131556 ,train acc: 0.967915 ,val loss : 0.152546 ,val acc : 0.979492\n",
      "[ ecpho : 0  iter :271 ]train loss : 0.220971 ,train acc: 0.888204 ,val loss : 0.157651 ,val acc : 0.979614\n",
      "[ ecpho : 0  iter :272 ]train loss : 0.125794 ,train acc: 0.977773 ,val loss : 0.160926 ,val acc : 0.979340\n",
      "[ ecpho : 0  iter :273 ]train loss : 0.107358 ,train acc: 0.990275 ,val loss : 0.155775 ,val acc : 0.979370\n",
      "[ ecpho : 0  iter :274 ]train loss : 0.163042 ,train acc: 0.932597 ,val loss : 0.156306 ,val acc : 0.979248\n",
      "[ ecpho : 0  iter :275 ]train loss : 0.107570 ,train acc: 0.982706 ,val loss : 0.153608 ,val acc : 0.979523\n",
      "[ ecpho : 0  iter :276 ]train loss : 0.059360 ,train acc: 0.996531 ,val loss : 0.149505 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :277 ]train loss : 0.067284 ,train acc: 0.989939 ,val loss : 0.154612 ,val acc : 0.979340\n",
      "[ ecpho : 0  iter :278 ]train loss : 0.092148 ,train acc: 0.992777 ,val loss : 0.149362 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :279 ]train loss : 0.171703 ,train acc: 0.911641 ,val loss : 0.149923 ,val acc : 0.979431\n",
      "[ ecpho : 0  iter :280 ]train loss : 0.153457 ,train acc: 0.931691 ,val loss : 0.157137 ,val acc : 0.979248\n",
      "[ ecpho : 0  iter :281 ]train loss : 0.063203 ,train acc: 0.994527 ,val loss : 0.153394 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :282 ]train loss : 0.107373 ,train acc: 0.988189 ,val loss : 0.156491 ,val acc : 0.979370\n",
      "[ ecpho : 0  iter :283 ]train loss : 0.098336 ,train acc: 0.994323 ,val loss : 0.152520 ,val acc : 0.979187\n",
      "[ ecpho : 0  iter :284 ]train loss : 0.069297 ,train acc: 0.989888 ,val loss : 0.151977 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :285 ]train loss : 0.087820 ,train acc: 0.993103 ,val loss : 0.145723 ,val acc : 0.979309\n",
      "[ ecpho : 0  iter :286 ]train loss : 0.149506 ,train acc: 0.947642 ,val loss : 0.146459 ,val acc : 0.979187\n",
      "[ ecpho : 0  iter :287 ]train loss : 0.094058 ,train acc: 0.990438 ,val loss : 0.139584 ,val acc : 0.979614\n",
      "[ ecpho : 0  iter :288 ]train loss : 0.124095 ,train acc: 0.971527 ,val loss : 0.135960 ,val acc : 0.979004\n",
      "[ ecpho : 0  iter :289 ]train loss : 0.126491 ,train acc: 0.976755 ,val loss : 0.128186 ,val acc : 0.979279\n",
      "[ ecpho : 0  iter :290 ]train loss : 0.138136 ,train acc: 0.964213 ,val loss : 0.125899 ,val acc : 0.979523\n",
      "[ ecpho : 0  iter :291 ]train loss : 0.053052 ,train acc: 0.995900 ,val loss : 0.122879 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :292 ]train loss : 0.255514 ,train acc: 0.903666 ,val loss : 0.130981 ,val acc : 0.978699\n",
      "[ ecpho : 0  iter :293 ]train loss : 0.056589 ,train acc: 0.995859 ,val loss : 0.141646 ,val acc : 0.979095\n",
      "[ ecpho : 0  iter :294 ]train loss : 0.194075 ,train acc: 0.932586 ,val loss : 0.149067 ,val acc : 0.978485\n",
      "[ ecpho : 0  iter :295 ]train loss : 0.080711 ,train acc: 0.983032 ,val loss : 0.151473 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :296 ]train loss : 0.109939 ,train acc: 0.967946 ,val loss : 0.155898 ,val acc : 0.978088\n",
      "[ ecpho : 0  iter :297 ]train loss : 0.091702 ,train acc: 0.984944 ,val loss : 0.157611 ,val acc : 0.978424\n",
      "[ ecpho : 0  iter :298 ]train loss : 0.120347 ,train acc: 0.987762 ,val loss : 0.157904 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :299 ]train loss : 0.300952 ,train acc: 0.918457 ,val loss : 0.145769 ,val acc : 0.979492\n",
      "[ ecpho : 0  iter :300 ]train loss : 0.097637 ,train acc: 0.987080 ,val loss : 0.135664 ,val acc : 0.979034\n",
      "[ ecpho : 0  iter :301 ]train loss : 0.147518 ,train acc: 0.961131 ,val loss : 0.127383 ,val acc : 0.978394\n",
      "[ ecpho : 0  iter :302 ]train loss : 0.068529 ,train acc: 0.993530 ,val loss : 0.122416 ,val acc : 0.978058\n",
      "[ ecpho : 0  iter :303 ]train loss : 0.078239 ,train acc: 0.987660 ,val loss : 0.118258 ,val acc : 0.978210\n",
      "[ ecpho : 0  iter :304 ]train loss : 0.179313 ,train acc: 0.946777 ,val loss : 0.118832 ,val acc : 0.976929\n",
      "[ ecpho : 0  iter :305 ]train loss : 0.076687 ,train acc: 0.988708 ,val loss : 0.118472 ,val acc : 0.977692\n",
      "[ ecpho : 0  iter :306 ]train loss : 0.253113 ,train acc: 0.906046 ,val loss : 0.129847 ,val acc : 0.975128\n",
      "[ ecpho : 0  iter :307 ]train loss : 0.296495 ,train acc: 0.880310 ,val loss : 0.124185 ,val acc : 0.977173\n",
      "[ ecpho : 0  iter :308 ]train loss : 0.125307 ,train acc: 0.963735 ,val loss : 0.120802 ,val acc : 0.977875\n",
      "[ ecpho : 0  iter :309 ]train loss : 0.081378 ,train acc: 0.988088 ,val loss : 0.119139 ,val acc : 0.977539\n",
      "[ ecpho : 0  iter :310 ]train loss : 0.235968 ,train acc: 0.925862 ,val loss : 0.145346 ,val acc : 0.977356\n",
      "[ ecpho : 0  iter :311 ]train loss : 0.200102 ,train acc: 0.922404 ,val loss : 0.163745 ,val acc : 0.977661\n",
      "[ ecpho : 0  iter :312 ]train loss : 0.191624 ,train acc: 0.921041 ,val loss : 0.174465 ,val acc : 0.977570\n",
      "[ ecpho : 0  iter :313 ]train loss : 0.068120 ,train acc: 0.992889 ,val loss : 0.177709 ,val acc : 0.977234\n",
      "[ ecpho : 0  iter :314 ]train loss : 0.113458 ,train acc: 0.984914 ,val loss : 0.174791 ,val acc : 0.977966\n",
      "[ ecpho : 0  iter :315 ]train loss : 0.087765 ,train acc: 0.988393 ,val loss : 0.178085 ,val acc : 0.977997\n",
      "[ ecpho : 0  iter :316 ]train loss : 0.137873 ,train acc: 0.983347 ,val loss : 0.177795 ,val acc : 0.977386\n",
      "[ ecpho : 0  iter :317 ]train loss : 0.110706 ,train acc: 0.981313 ,val loss : 0.176119 ,val acc : 0.978333\n",
      "[ ecpho : 0  iter :318 ]train loss : 0.072426 ,train acc: 0.990010 ,val loss : 0.174897 ,val acc : 0.977692\n",
      "[ ecpho : 0  iter :319 ]train loss : 0.124012 ,train acc: 0.983836 ,val loss : 0.172747 ,val acc : 0.978149\n",
      "[ ecpho : 0  iter :320 ]train loss : 0.082145 ,train acc: 0.987620 ,val loss : 0.170148 ,val acc : 0.977478\n",
      "[ ecpho : 0  iter :321 ]train loss : 0.071948 ,train acc: 0.988851 ,val loss : 0.176456 ,val acc : 0.977692\n",
      "[ ecpho : 0  iter :322 ]train loss : 0.113890 ,train acc: 0.975870 ,val loss : 0.167305 ,val acc : 0.977600\n",
      "[ ecpho : 0  iter :323 ]train loss : 0.128455 ,train acc: 0.986226 ,val loss : 0.166815 ,val acc : 0.977753\n",
      "[ ecpho : 0  iter :324 ]train loss : 0.203835 ,train acc: 0.932352 ,val loss : 0.164128 ,val acc : 0.977203\n",
      "[ ecpho : 0  iter :325 ]train loss : 0.175694 ,train acc: 0.930104 ,val loss : 0.161313 ,val acc : 0.977203\n",
      "[ ecpho : 0  iter :326 ]train loss : 0.111887 ,train acc: 0.970927 ,val loss : 0.157972 ,val acc : 0.977356\n",
      "[ ecpho : 0  iter :327 ]train loss : 0.128614 ,train acc: 0.979980 ,val loss : 0.151830 ,val acc : 0.976776\n",
      "[ ecpho : 0  iter :328 ]train loss : 0.078156 ,train acc: 0.984405 ,val loss : 0.152798 ,val acc : 0.977753\n",
      "[ ecpho : 0  iter :329 ]train loss : 0.090053 ,train acc: 0.980285 ,val loss : 0.150103 ,val acc : 0.977814\n",
      "[ ecpho : 0  iter :330 ]train loss : 0.065173 ,train acc: 0.993693 ,val loss : 0.150464 ,val acc : 0.976990\n",
      "[ ecpho : 0  iter :331 ]train loss : 0.068734 ,train acc: 0.993286 ,val loss : 0.147793 ,val acc : 0.977875\n",
      "[ ecpho : 0  iter :332 ]train loss : 0.072152 ,train acc: 0.991078 ,val loss : 0.142804 ,val acc : 0.978180\n",
      "[ ecpho : 0  iter :333 ]train loss : 0.137515 ,train acc: 0.964823 ,val loss : 0.148321 ,val acc : 0.978119\n",
      "[ ecpho : 0  iter :334 ]train loss : 0.092354 ,train acc: 0.994018 ,val loss : 0.143383 ,val acc : 0.978333\n",
      "[ ecpho : 0  iter :335 ]train loss : 0.095501 ,train acc: 0.985585 ,val loss : 0.136494 ,val acc : 0.978485\n",
      "[ ecpho : 0  iter :336 ]train loss : 0.111257 ,train acc: 0.965311 ,val loss : 0.138748 ,val acc : 0.977936\n",
      "[ ecpho : 0  iter :337 ]train loss : 0.119261 ,train acc: 0.971476 ,val loss : 0.138353 ,val acc : 0.977875\n",
      "[ ecpho : 0  iter :338 ]train loss : 0.126422 ,train acc: 0.962372 ,val loss : 0.138316 ,val acc : 0.978424\n",
      "[ ecpho : 0  iter :339 ]train loss : 0.080438 ,train acc: 0.989909 ,val loss : 0.135200 ,val acc : 0.978516\n",
      "[ ecpho : 0  iter :340 ]train loss : 0.060382 ,train acc: 0.992340 ,val loss : 0.135684 ,val acc : 0.978241\n",
      "[ ecpho : 0  iter :341 ]train loss : 0.067566 ,train acc: 0.990417 ,val loss : 0.134772 ,val acc : 0.978363\n",
      "[ ecpho : 0  iter :342 ]train loss : 0.167771 ,train acc: 0.936696 ,val loss : 0.138068 ,val acc : 0.978119\n",
      "[ ecpho : 0  iter :343 ]train loss : 0.243330 ,train acc: 0.886719 ,val loss : 0.152969 ,val acc : 0.978119\n",
      "[ ecpho : 0  iter :344 ]train loss : 0.077167 ,train acc: 0.989298 ,val loss : 0.167967 ,val acc : 0.977478\n",
      "[ ecpho : 0  iter :345 ]train loss : 0.204322 ,train acc: 0.895569 ,val loss : 0.176131 ,val acc : 0.976898\n",
      "[ ecpho : 0  iter :346 ]train loss : 0.341205 ,train acc: 0.853119 ,val loss : 0.176086 ,val acc : 0.975983\n",
      "[ ecpho : 0  iter :347 ]train loss : 0.134554 ,train acc: 0.981252 ,val loss : 0.178407 ,val acc : 0.978210\n",
      "[ ecpho : 0  iter :348 ]train loss : 0.109508 ,train acc: 0.991444 ,val loss : 0.173362 ,val acc : 0.979004\n",
      "[ ecpho : 0  iter :349 ]train loss : 0.077748 ,train acc: 0.994964 ,val loss : 0.170323 ,val acc : 0.979065\n",
      "[ ecpho : 0  iter :350 ]train loss : 0.124462 ,train acc: 0.960978 ,val loss : 0.169757 ,val acc : 0.979218\n",
      "[ ecpho : 0  iter :351 ]train loss : 0.118989 ,train acc: 0.968831 ,val loss : 0.167085 ,val acc : 0.978516\n",
      "[ ecpho : 0  iter :352 ]train loss : 0.087115 ,train acc: 0.985148 ,val loss : 0.162478 ,val acc : 0.978699\n",
      "[ ecpho : 0  iter :353 ]train loss : 0.226878 ,train acc: 0.934479 ,val loss : 0.163493 ,val acc : 0.978577\n",
      "[ ecpho : 0  iter :354 ]train loss : 0.131243 ,train acc: 0.969157 ,val loss : 0.153956 ,val acc : 0.978271\n",
      "[ ecpho : 0  iter :355 ]train loss : 0.133696 ,train acc: 0.977101 ,val loss : 0.151267 ,val acc : 0.978241\n",
      "[ ecpho : 0  iter :356 ]train loss : 0.100120 ,train acc: 0.990356 ,val loss : 0.139438 ,val acc : 0.977661\n",
      "[ ecpho : 0  iter :357 ]train loss : 0.088351 ,train acc: 0.981130 ,val loss : 0.135845 ,val acc : 0.978333\n",
      "[ ecpho : 0  iter :358 ]train loss : 0.204487 ,train acc: 0.921926 ,val loss : 0.138722 ,val acc : 0.977295\n",
      "[ ecpho : 0  iter :359 ]train loss : 0.056322 ,train acc: 0.995086 ,val loss : 0.142659 ,val acc : 0.976196\n",
      "[ ecpho : 0  iter :360 ]train loss : 0.075704 ,train acc: 0.985443 ,val loss : 0.146535 ,val acc : 0.976746\n",
      "[ ecpho : 0  iter :361 ]train loss : 0.075285 ,train acc: 0.987986 ,val loss : 0.146105 ,val acc : 0.976624\n",
      "[ ecpho : 0  iter :362 ]train loss : 0.086440 ,train acc: 0.983256 ,val loss : 0.147416 ,val acc : 0.977478\n",
      "[ ecpho : 0  iter :363 ]train loss : 0.104425 ,train acc: 0.973571 ,val loss : 0.144956 ,val acc : 0.977905\n",
      "[ ecpho : 0  iter :364 ]train loss : 0.114791 ,train acc: 0.960632 ,val loss : 0.147755 ,val acc : 0.977905\n",
      "[ ecpho : 0  iter :365 ]train loss : 0.142193 ,train acc: 0.968516 ,val loss : 0.145943 ,val acc : 0.978363\n",
      "[ ecpho : 0  iter :366 ]train loss : 0.110275 ,train acc: 0.986470 ,val loss : 0.141270 ,val acc : 0.978851\n",
      "[ ecpho : 0  iter :367 ]train loss : 0.136160 ,train acc: 0.956126 ,val loss : 0.138350 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :368 ]train loss : 0.117086 ,train acc: 0.960601 ,val loss : 0.138753 ,val acc : 0.978882\n",
      "[ ecpho : 0  iter :369 ]train loss : 0.163254 ,train acc: 0.942118 ,val loss : 0.142390 ,val acc : 0.978607\n",
      "[ ecpho : 0  iter :370 ]train loss : 0.097599 ,train acc: 0.991465 ,val loss : 0.140511 ,val acc : 0.978912\n",
      "[ ecpho : 0  iter :371 ]train loss : 0.071553 ,train acc: 0.990814 ,val loss : 0.141220 ,val acc : 0.978394\n",
      "[ ecpho : 0  iter :372 ]train loss : 0.076339 ,train acc: 0.992329 ,val loss : 0.138062 ,val acc : 0.978577\n",
      "[ ecpho : 0  iter :373 ]train loss : 0.101963 ,train acc: 0.971639 ,val loss : 0.136666 ,val acc : 0.979126\n",
      "[ ecpho : 0  iter :374 ]train loss : 0.070317 ,train acc: 0.989369 ,val loss : 0.138337 ,val acc : 0.978973\n",
      "[ ecpho : 0  iter :375 ]train loss : 0.075408 ,train acc: 0.990153 ,val loss : 0.133017 ,val acc : 0.978943\n",
      "[ ecpho : 0  iter :376 ]train loss : 0.104407 ,train acc: 0.983154 ,val loss : 0.129702 ,val acc : 0.978973\n",
      "[ ecpho : 0  iter :377 ]train loss : 0.068297 ,train acc: 0.994649 ,val loss : 0.123131 ,val acc : 0.978302\n",
      "[ ecpho : 0  iter :378 ]train loss : 0.166963 ,train acc: 0.936889 ,val loss : 0.119299 ,val acc : 0.978394\n",
      "[ ecpho : 0  iter :379 ]train loss : 0.155412 ,train acc: 0.958394 ,val loss : 0.115930 ,val acc : 0.976898\n",
      "[ ecpho : 0  iter :380 ]train loss : 0.092566 ,train acc: 0.988484 ,val loss : 0.115148 ,val acc : 0.977570\n",
      "[ ecpho : 0  iter :381 ]train loss : 0.124377 ,train acc: 0.964752 ,val loss : 0.115664 ,val acc : 0.977844\n",
      "[ ecpho : 0  iter :382 ]train loss : 0.111063 ,train acc: 0.974843 ,val loss : 0.118158 ,val acc : 0.976501\n",
      "[ ecpho : 0  iter :383 ]train loss : 0.180994 ,train acc: 0.944041 ,val loss : 0.137159 ,val acc : 0.970520\n",
      "[ ecpho : 0  iter :384 ]train loss : 0.129029 ,train acc: 0.961619 ,val loss : 0.137115 ,val acc : 0.972717\n",
      "[ ecpho : 0  iter :385 ]train loss : 0.107852 ,train acc: 0.972717 ,val loss : 0.142033 ,val acc : 0.976868\n",
      "[ ecpho : 0  iter :386 ]train loss : 0.160649 ,train acc: 0.932474 ,val loss : 0.145679 ,val acc : 0.977539\n",
      "[ ecpho : 0  iter :387 ]train loss : 0.079402 ,train acc: 0.990356 ,val loss : 0.146964 ,val acc : 0.977753\n",
      "[ ecpho : 0  iter :388 ]train loss : 0.067527 ,train acc: 0.991760 ,val loss : 0.145492 ,val acc : 0.978088\n",
      "[ ecpho : 0  iter :389 ]train loss : 0.156065 ,train acc: 0.975850 ,val loss : 0.138540 ,val acc : 0.977844\n",
      "[ ecpho : 0  iter :390 ]train loss : 0.072246 ,train acc: 0.985921 ,val loss : 0.131488 ,val acc : 0.977875\n",
      "[ ecpho : 0  iter :391 ]train loss : 0.063422 ,train acc: 0.989685 ,val loss : 0.128348 ,val acc : 0.977814\n",
      "[ ecpho : 0  iter :392 ]train loss : 0.330896 ,train acc: 0.843760 ,val loss : 0.136312 ,val acc : 0.977478\n",
      "[ ecpho : 0  iter :393 ]train loss : 0.116729 ,train acc: 0.964081 ,val loss : 0.139699 ,val acc : 0.976135\n",
      "[ ecpho : 0  iter :394 ]train loss : 0.075493 ,train acc: 0.989257 ,val loss : 0.142581 ,val acc : 0.976135\n",
      "[ ecpho : 0  iter :395 ]train loss : 0.165468 ,train acc: 0.944539 ,val loss : 0.145860 ,val acc : 0.973450\n",
      "[ ecpho : 0  iter :396 ]train loss : 0.078854 ,train acc: 0.987854 ,val loss : 0.145074 ,val acc : 0.974884\n",
      "[ ecpho : 0  iter :397 ]train loss : 0.053835 ,train acc: 0.991638 ,val loss : 0.147253 ,val acc : 0.975311\n",
      "[ ecpho : 0  iter :398 ]train loss : 0.135547 ,train acc: 0.967753 ,val loss : 0.143155 ,val acc : 0.976990\n",
      "[ ecpho : 0  iter :399 ]train loss : 0.117957 ,train acc: 0.974701 ,val loss : 0.136067 ,val acc : 0.977417\n",
      "[ ecpho : 0  iter :400 ]train loss : 0.089163 ,train acc: 0.982635 ,val loss : 0.133498 ,val acc : 0.977051\n",
      "=============================================\n",
      "[ 0 ] average train loss : 0.147151 train acc : 0.957201\n",
      "[ ecpho : 1  iter :1 ]train loss : 0.492652 ,train acc: 0.749878 ,val loss : 0.145659 ,val acc : 0.977631\n",
      "[ ecpho : 1  iter :2 ]train loss : 0.095918 ,train acc: 0.991129 ,val loss : 0.150367 ,val acc : 0.977234\n",
      "[ ecpho : 1  iter :3 ]train loss : 0.076273 ,train acc: 0.992675 ,val loss : 0.149404 ,val acc : 0.976471\n",
      "[ ecpho : 1  iter :4 ]train loss : 0.077021 ,train acc: 0.990610 ,val loss : 0.148616 ,val acc : 0.975403\n",
      "[ ecpho : 1  iter :5 ]train loss : 0.127057 ,train acc: 0.956777 ,val loss : 0.153154 ,val acc : 0.972107\n",
      "[ ecpho : 1  iter :6 ]train loss : 0.065911 ,train acc: 0.990600 ,val loss : 0.154062 ,val acc : 0.973450\n",
      "[ ecpho : 1  iter :7 ]train loss : 0.072805 ,train acc: 0.988383 ,val loss : 0.153281 ,val acc : 0.973480\n",
      "[ ecpho : 1  iter :8 ]train loss : 0.112403 ,train acc: 0.971588 ,val loss : 0.148866 ,val acc : 0.976593\n",
      "[ ecpho : 1  iter :9 ]train loss : 0.100831 ,train acc: 0.972229 ,val loss : 0.147919 ,val acc : 0.975372\n",
      "[ ecpho : 1  iter :10 ]train loss : 0.225476 ,train acc: 0.894541 ,val loss : 0.152202 ,val acc : 0.974487\n",
      "[ ecpho : 1  iter :11 ]train loss : 0.236860 ,train acc: 0.916982 ,val loss : 0.149525 ,val acc : 0.975952\n",
      "[ ecpho : 1  iter :12 ]train loss : 0.144407 ,train acc: 0.937489 ,val loss : 0.155313 ,val acc : 0.976288\n",
      "[ ecpho : 1  iter :13 ]train loss : 0.247240 ,train acc: 0.865214 ,val loss : 0.158683 ,val acc : 0.977509\n",
      "[ ecpho : 1  iter :14 ]train loss : 0.104473 ,train acc: 0.982676 ,val loss : 0.161760 ,val acc : 0.976837\n",
      "[ ecpho : 1  iter :15 ]train loss : 0.147927 ,train acc: 0.948863 ,val loss : 0.169502 ,val acc : 0.976074\n",
      "[ ecpho : 1  iter :16 ]train loss : 0.111227 ,train acc: 0.971812 ,val loss : 0.164792 ,val acc : 0.975800\n",
      "[ ecpho : 1  iter :17 ]train loss : 0.221384 ,train acc: 0.912557 ,val loss : 0.170006 ,val acc : 0.975403\n",
      "[ ecpho : 1  iter :18 ]train loss : 0.071985 ,train acc: 0.986623 ,val loss : 0.168117 ,val acc : 0.975586\n",
      "[ ecpho : 1  iter :19 ]train loss : 0.086534 ,train acc: 0.992635 ,val loss : 0.166095 ,val acc : 0.975281\n",
      "[ ecpho : 1  iter :20 ]train loss : 0.077084 ,train acc: 0.993092 ,val loss : 0.164660 ,val acc : 0.976166\n",
      "[ ecpho : 1  iter :21 ]train loss : 0.094813 ,train acc: 0.989430 ,val loss : 0.161554 ,val acc : 0.977234\n",
      "[ ecpho : 1  iter :22 ]train loss : 0.086798 ,train acc: 0.991577 ,val loss : 0.159176 ,val acc : 0.977081\n",
      "[ ecpho : 1  iter :23 ]train loss : 0.182150 ,train acc: 0.946564 ,val loss : 0.151211 ,val acc : 0.977234\n",
      "[ ecpho : 1  iter :24 ]train loss : 0.276631 ,train acc: 0.881449 ,val loss : 0.142886 ,val acc : 0.975952\n",
      "[ ecpho : 1  iter :25 ]train loss : 0.350630 ,train acc: 0.842204 ,val loss : 0.154590 ,val acc : 0.974792\n",
      "[ ecpho : 1  iter :26 ]train loss : 0.104799 ,train acc: 0.986918 ,val loss : 0.150502 ,val acc : 0.974945\n",
      "[ ecpho : 1  iter :27 ]train loss : 0.094664 ,train acc: 0.979522 ,val loss : 0.151670 ,val acc : 0.972473\n",
      "[ ecpho : 1  iter :28 ]train loss : 0.164631 ,train acc: 0.923207 ,val loss : 0.153086 ,val acc : 0.969635\n",
      "[ ecpho : 1  iter :29 ]train loss : 0.060062 ,train acc: 0.984456 ,val loss : 0.158190 ,val acc : 0.969147\n",
      "[ ecpho : 1  iter :30 ]train loss : 0.092855 ,train acc: 0.984883 ,val loss : 0.153648 ,val acc : 0.970673\n",
      "[ ecpho : 1  iter :31 ]train loss : 0.264202 ,train acc: 0.869130 ,val loss : 0.156029 ,val acc : 0.972473\n",
      "[ ecpho : 1  iter :32 ]train loss : 0.100197 ,train acc: 0.987009 ,val loss : 0.147091 ,val acc : 0.972839\n",
      "[ ecpho : 1  iter :33 ]train loss : 0.142595 ,train acc: 0.936920 ,val loss : 0.152167 ,val acc : 0.973022\n",
      "[ ecpho : 1  iter :34 ]train loss : 0.137115 ,train acc: 0.945862 ,val loss : 0.154228 ,val acc : 0.973755\n",
      "[ ecpho : 1  iter :35 ]train loss : 0.125112 ,train acc: 0.976318 ,val loss : 0.151140 ,val acc : 0.973633\n",
      "[ ecpho : 1  iter :36 ]train loss : 0.079399 ,train acc: 0.993886 ,val loss : 0.145040 ,val acc : 0.974396\n",
      "[ ecpho : 1  iter :37 ]train loss : 0.148098 ,train acc: 0.946340 ,val loss : 0.142795 ,val acc : 0.974701\n",
      "[ ecpho : 1  iter :38 ]train loss : 0.095975 ,train acc: 0.977854 ,val loss : 0.139692 ,val acc : 0.973633\n",
      "[ ecpho : 1  iter :39 ]train loss : 0.074435 ,train acc: 0.992086 ,val loss : 0.137799 ,val acc : 0.973083\n",
      "[ ecpho : 1  iter :40 ]train loss : 0.075510 ,train acc: 0.985951 ,val loss : 0.131662 ,val acc : 0.975006\n",
      "[ ecpho : 1  iter :41 ]train loss : 0.176591 ,train acc: 0.929708 ,val loss : 0.137701 ,val acc : 0.974121\n",
      "[ ecpho : 1  iter :42 ]train loss : 0.160007 ,train acc: 0.933288 ,val loss : 0.145769 ,val acc : 0.973572\n",
      "[ ecpho : 1  iter :43 ]train loss : 0.067948 ,train acc: 0.987009 ,val loss : 0.154759 ,val acc : 0.973083\n",
      "[ ecpho : 1  iter :44 ]train loss : 0.070557 ,train acc: 0.988810 ,val loss : 0.154140 ,val acc : 0.975922\n",
      "[ ecpho : 1  iter :45 ]train loss : 0.379226 ,train acc: 0.820323 ,val loss : 0.160532 ,val acc : 0.976654\n",
      "[ ecpho : 1  iter :46 ]train loss : 0.084501 ,train acc: 0.982818 ,val loss : 0.159626 ,val acc : 0.976349\n",
      "[ ecpho : 1  iter :47 ]train loss : 0.104816 ,train acc: 0.985361 ,val loss : 0.159959 ,val acc : 0.976715\n",
      "[ ecpho : 1  iter :48 ]train loss : 0.129384 ,train acc: 0.949646 ,val loss : 0.157301 ,val acc : 0.977722\n",
      "[ ecpho : 1  iter :49 ]train loss : 0.107987 ,train acc: 0.977610 ,val loss : 0.157355 ,val acc : 0.977325\n",
      "[ ecpho : 1  iter :50 ]train loss : 0.170707 ,train acc: 0.935313 ,val loss : 0.156585 ,val acc : 0.977020\n",
      "[ ecpho : 1  iter :51 ]train loss : 0.132650 ,train acc: 0.976979 ,val loss : 0.151055 ,val acc : 0.976898\n",
      "[ ecpho : 1  iter :52 ]train loss : 0.124174 ,train acc: 0.966064 ,val loss : 0.147216 ,val acc : 0.976196\n",
      "[ ecpho : 1  iter :53 ]train loss : 0.076039 ,train acc: 0.986094 ,val loss : 0.144055 ,val acc : 0.975708\n",
      "[ ecpho : 1  iter :54 ]train loss : 0.174693 ,train acc: 0.919840 ,val loss : 0.145107 ,val acc : 0.974243\n",
      "[ ecpho : 1  iter :55 ]train loss : 0.187253 ,train acc: 0.924174 ,val loss : 0.152619 ,val acc : 0.973114\n",
      "[ ecpho : 1  iter :56 ]train loss : 0.070817 ,train acc: 0.981964 ,val loss : 0.154981 ,val acc : 0.973389\n",
      "[ ecpho : 1  iter :57 ]train loss : 0.127737 ,train acc: 0.975718 ,val loss : 0.146032 ,val acc : 0.974365\n",
      "[ ecpho : 1  iter :58 ]train loss : 0.129677 ,train acc: 0.969034 ,val loss : 0.147403 ,val acc : 0.975281\n",
      "[ ecpho : 1  iter :59 ]train loss : 0.078504 ,train acc: 0.991302 ,val loss : 0.142909 ,val acc : 0.976074\n",
      "[ ecpho : 1  iter :60 ]train loss : 0.070816 ,train acc: 0.990671 ,val loss : 0.134651 ,val acc : 0.976074\n",
      "[ ecpho : 1  iter :61 ]train loss : 0.083489 ,train acc: 0.978953 ,val loss : 0.132700 ,val acc : 0.974487\n",
      "[ ecpho : 1  iter :62 ]train loss : 0.067862 ,train acc: 0.993591 ,val loss : 0.128041 ,val acc : 0.975464\n",
      "[ ecpho : 1  iter :63 ]train loss : 0.258581 ,train acc: 0.903544 ,val loss : 0.144622 ,val acc : 0.973541\n",
      "[ ecpho : 1  iter :64 ]train loss : 0.062239 ,train acc: 0.988667 ,val loss : 0.157757 ,val acc : 0.971680\n",
      "[ ecpho : 1  iter :65 ]train loss : 0.100204 ,train acc: 0.965047 ,val loss : 0.160687 ,val acc : 0.971954\n",
      "[ ecpho : 1  iter :66 ]train loss : 0.099368 ,train acc: 0.974212 ,val loss : 0.165525 ,val acc : 0.975525\n",
      "[ ecpho : 1  iter :67 ]train loss : 0.103525 ,train acc: 0.985941 ,val loss : 0.163322 ,val acc : 0.977692\n",
      "[ ecpho : 1  iter :68 ]train loss : 0.180490 ,train acc: 0.934346 ,val loss : 0.164747 ,val acc : 0.977570\n",
      "[ ecpho : 1  iter :69 ]train loss : 0.063364 ,train acc: 0.996368 ,val loss : 0.163642 ,val acc : 0.978271\n",
      "[ ecpho : 1  iter :70 ]train loss : 0.161406 ,train acc: 0.959605 ,val loss : 0.163928 ,val acc : 0.978210\n",
      "[ ecpho : 1  iter :71 ]train loss : 0.193575 ,train acc: 0.906707 ,val loss : 0.162926 ,val acc : 0.977722\n",
      "[ ecpho : 1  iter :72 ]train loss : 0.153601 ,train acc: 0.958099 ,val loss : 0.156376 ,val acc : 0.977386\n",
      "[ ecpho : 1  iter :73 ]train loss : 0.122451 ,train acc: 0.984598 ,val loss : 0.153947 ,val acc : 0.977234\n",
      "[ ecpho : 1  iter :74 ]train loss : 0.087024 ,train acc: 0.975647 ,val loss : 0.151624 ,val acc : 0.975861\n",
      "[ ecpho : 1  iter :75 ]train loss : 0.134857 ,train acc: 0.951711 ,val loss : 0.153497 ,val acc : 0.976898\n",
      "[ ecpho : 1  iter :76 ]train loss : 0.087086 ,train acc: 0.990397 ,val loss : 0.148163 ,val acc : 0.977753\n",
      "[ ecpho : 1  iter :77 ]train loss : 0.194120 ,train acc: 0.910929 ,val loss : 0.155599 ,val acc : 0.977600\n",
      "[ ecpho : 1  iter :78 ]train loss : 0.079004 ,train acc: 0.989105 ,val loss : 0.156776 ,val acc : 0.977051\n",
      "[ ecpho : 1  iter :79 ]train loss : 0.153800 ,train acc: 0.940623 ,val loss : 0.161248 ,val acc : 0.976868\n",
      "[ ecpho : 1  iter :80 ]train loss : 0.212150 ,train acc: 0.899912 ,val loss : 0.161801 ,val acc : 0.977295\n",
      "[ ecpho : 1  iter :81 ]train loss : 0.176797 ,train acc: 0.949045 ,val loss : 0.163174 ,val acc : 0.977631\n",
      "[ ecpho : 1  iter :82 ]train loss : 0.107454 ,train acc: 0.969146 ,val loss : 0.162816 ,val acc : 0.977539\n",
      "[ ecpho : 1  iter :83 ]train loss : 0.142833 ,train acc: 0.984842 ,val loss : 0.160383 ,val acc : 0.977570\n",
      "[ ecpho : 1  iter :84 ]train loss : 0.080829 ,train acc: 0.986175 ,val loss : 0.153836 ,val acc : 0.977844\n",
      "[ ecpho : 1  iter :85 ]train loss : 0.204749 ,train acc: 0.923675 ,val loss : 0.150735 ,val acc : 0.977386\n",
      "[ ecpho : 1  iter :86 ]train loss : 0.160671 ,train acc: 0.937134 ,val loss : 0.150762 ,val acc : 0.977844\n",
      "[ ecpho : 1  iter :87 ]train loss : 0.121549 ,train acc: 0.956014 ,val loss : 0.152681 ,val acc : 0.977203\n",
      "[ ecpho : 1  iter :88 ]train loss : 0.168380 ,train acc: 0.915334 ,val loss : 0.157200 ,val acc : 0.977020\n",
      "[ ecpho : 1  iter :89 ]train loss : 0.280629 ,train acc: 0.862356 ,val loss : 0.159528 ,val acc : 0.976135\n",
      "[ ecpho : 1  iter :90 ]train loss : 0.057998 ,train acc: 0.989532 ,val loss : 0.165346 ,val acc : 0.975952\n",
      "[ ecpho : 1  iter :91 ]train loss : 0.091933 ,train acc: 0.989268 ,val loss : 0.162519 ,val acc : 0.976593\n",
      "[ ecpho : 1  iter :92 ]train loss : 0.074584 ,train acc: 0.984985 ,val loss : 0.162039 ,val acc : 0.976593\n",
      "[ ecpho : 1  iter :93 ]train loss : 0.154939 ,train acc: 0.971110 ,val loss : 0.157824 ,val acc : 0.977386\n",
      "[ ecpho : 1  iter :94 ]train loss : 0.189916 ,train acc: 0.917582 ,val loss : 0.161391 ,val acc : 0.977142\n",
      "[ ecpho : 1  iter :95 ]train loss : 0.133257 ,train acc: 0.976542 ,val loss : 0.157174 ,val acc : 0.978058\n",
      "[ ecpho : 1  iter :96 ]train loss : 0.056599 ,train acc: 0.993662 ,val loss : 0.148731 ,val acc : 0.977478\n",
      "[ ecpho : 1  iter :97 ]train loss : 0.120993 ,train acc: 0.976054 ,val loss : 0.148511 ,val acc : 0.977173\n",
      "[ ecpho : 1  iter :98 ]train loss : 0.072806 ,train acc: 0.994374 ,val loss : 0.143449 ,val acc : 0.976654\n",
      "[ ecpho : 1  iter :99 ]train loss : 0.062158 ,train acc: 0.990509 ,val loss : 0.135981 ,val acc : 0.974854\n",
      "[ ecpho : 1  iter :100 ]train loss : 0.225667 ,train acc: 0.914774 ,val loss : 0.136894 ,val acc : 0.973480\n",
      "[ ecpho : 1  iter :101 ]train loss : 0.075783 ,train acc: 0.983469 ,val loss : 0.136112 ,val acc : 0.973389\n",
      "[ ecpho : 1  iter :102 ]train loss : 0.099160 ,train acc: 0.977752 ,val loss : 0.142214 ,val acc : 0.973328\n",
      "[ ecpho : 1  iter :103 ]train loss : 0.076608 ,train acc: 0.987325 ,val loss : 0.143139 ,val acc : 0.974976\n",
      "[ ecpho : 1  iter :104 ]train loss : 0.106299 ,train acc: 0.973449 ,val loss : 0.139304 ,val acc : 0.974854\n",
      "[ ecpho : 1  iter :105 ]train loss : 0.076173 ,train acc: 0.985758 ,val loss : 0.138520 ,val acc : 0.975830\n",
      "[ ecpho : 1  iter :106 ]train loss : 0.085123 ,train acc: 0.989797 ,val loss : 0.136393 ,val acc : 0.975433\n",
      "[ ecpho : 1  iter :107 ]train loss : 0.239951 ,train acc: 0.903574 ,val loss : 0.137893 ,val acc : 0.974396\n",
      "[ ecpho : 1  iter :108 ]train loss : 0.073683 ,train acc: 0.988820 ,val loss : 0.135595 ,val acc : 0.973938\n",
      "[ ecpho : 1  iter :109 ]train loss : 0.082231 ,train acc: 0.990488 ,val loss : 0.132015 ,val acc : 0.973663\n",
      "[ ecpho : 1  iter :110 ]train loss : 0.162980 ,train acc: 0.945231 ,val loss : 0.125906 ,val acc : 0.974579\n",
      "[ ecpho : 1  iter :111 ]train loss : 0.066111 ,train acc: 0.986785 ,val loss : 0.122628 ,val acc : 0.974304\n",
      "[ ecpho : 1  iter :112 ]train loss : 0.060448 ,train acc: 0.990875 ,val loss : 0.122188 ,val acc : 0.973907\n",
      "[ ecpho : 1  iter :113 ]train loss : 0.114388 ,train acc: 0.961761 ,val loss : 0.123586 ,val acc : 0.973389\n",
      "[ ecpho : 1  iter :114 ]train loss : 0.322212 ,train acc: 0.887207 ,val loss : 0.156256 ,val acc : 0.966064\n",
      "[ ecpho : 1  iter :115 ]train loss : 0.177648 ,train acc: 0.932088 ,val loss : 0.170300 ,val acc : 0.963837\n",
      "[ ecpho : 1  iter :116 ]train loss : 0.087593 ,train acc: 0.975687 ,val loss : 0.179297 ,val acc : 0.973999\n",
      "[ ecpho : 1  iter :117 ]train loss : 0.095588 ,train acc: 0.989166 ,val loss : 0.187157 ,val acc : 0.977570\n",
      "[ ecpho : 1  iter :118 ]train loss : 0.128431 ,train acc: 0.975107 ,val loss : 0.185211 ,val acc : 0.977661\n",
      "[ ecpho : 1  iter :119 ]train loss : 0.082401 ,train acc: 0.995493 ,val loss : 0.184412 ,val acc : 0.978058\n",
      "[ ecpho : 1  iter :120 ]train loss : 0.131851 ,train acc: 0.974263 ,val loss : 0.186557 ,val acc : 0.977478\n",
      "[ ecpho : 1  iter :121 ]train loss : 0.206648 ,train acc: 0.948659 ,val loss : 0.187044 ,val acc : 0.976593\n",
      "[ ecpho : 1  iter :122 ]train loss : 0.105228 ,train acc: 0.964772 ,val loss : 0.186094 ,val acc : 0.975433\n",
      "[ ecpho : 1  iter :123 ]train loss : 0.084153 ,train acc: 0.979299 ,val loss : 0.180499 ,val acc : 0.974426\n",
      "[ ecpho : 1  iter :124 ]train loss : 0.139798 ,train acc: 0.942149 ,val loss : 0.183268 ,val acc : 0.972656\n",
      "[ ecpho : 1  iter :125 ]train loss : 0.069010 ,train acc: 0.991872 ,val loss : 0.174120 ,val acc : 0.973419\n",
      "[ ecpho : 1  iter :126 ]train loss : 0.155328 ,train acc: 0.961161 ,val loss : 0.174284 ,val acc : 0.975342\n",
      "[ ecpho : 1  iter :127 ]train loss : 0.096401 ,train acc: 0.977763 ,val loss : 0.180345 ,val acc : 0.975128\n",
      "[ ecpho : 1  iter :128 ]train loss : 0.100775 ,train acc: 0.983052 ,val loss : 0.175148 ,val acc : 0.976074\n",
      "[ ecpho : 1  iter :129 ]train loss : 0.287229 ,train acc: 0.816701 ,val loss : 0.174956 ,val acc : 0.974579\n",
      "[ ecpho : 1  iter :130 ]train loss : 0.220568 ,train acc: 0.888234 ,val loss : 0.172094 ,val acc : 0.975464\n",
      "[ ecpho : 1  iter :131 ]train loss : 0.176160 ,train acc: 0.918325 ,val loss : 0.165615 ,val acc : 0.975677\n",
      "[ ecpho : 1  iter :132 ]train loss : 0.057904 ,train acc: 0.989919 ,val loss : 0.172210 ,val acc : 0.973877\n",
      "[ ecpho : 1  iter :133 ]train loss : 0.100312 ,train acc: 0.981130 ,val loss : 0.170715 ,val acc : 0.973816\n",
      "[ ecpho : 1  iter :134 ]train loss : 0.109592 ,train acc: 0.978820 ,val loss : 0.166773 ,val acc : 0.974304\n",
      "[ ecpho : 1  iter :135 ]train loss : 0.214027 ,train acc: 0.915720 ,val loss : 0.165418 ,val acc : 0.974060\n",
      "[ ecpho : 1  iter :136 ]train loss : 0.221790 ,train acc: 0.890238 ,val loss : 0.166705 ,val acc : 0.973358\n",
      "[ ecpho : 1  iter :137 ]train loss : 0.096951 ,train acc: 0.985727 ,val loss : 0.165308 ,val acc : 0.973633\n",
      "[ ecpho : 1  iter :138 ]train loss : 0.106287 ,train acc: 0.968129 ,val loss : 0.159042 ,val acc : 0.973755\n",
      "[ ecpho : 1  iter :139 ]train loss : 0.096334 ,train acc: 0.988617 ,val loss : 0.157952 ,val acc : 0.972504\n",
      "[ ecpho : 1  iter :140 ]train loss : 0.162547 ,train acc: 0.933309 ,val loss : 0.156670 ,val acc : 0.972992\n",
      "[ ecpho : 1  iter :141 ]train loss : 0.084820 ,train acc: 0.989715 ,val loss : 0.151333 ,val acc : 0.972992\n",
      "[ ecpho : 1  iter :142 ]train loss : 0.366090 ,train acc: 0.797953 ,val loss : 0.161869 ,val acc : 0.973816\n",
      "[ ecpho : 1  iter :143 ]train loss : 0.104049 ,train acc: 0.983734 ,val loss : 0.164532 ,val acc : 0.972961\n",
      "[ ecpho : 1  iter :144 ]train loss : 0.153869 ,train acc: 0.965230 ,val loss : 0.161175 ,val acc : 0.974670\n",
      "[ ecpho : 1  iter :145 ]train loss : 0.201916 ,train acc: 0.900533 ,val loss : 0.159387 ,val acc : 0.974701\n",
      "[ ecpho : 1  iter :146 ]train loss : 0.090040 ,train acc: 0.986846 ,val loss : 0.158179 ,val acc : 0.974213\n",
      "[ ecpho : 1  iter :147 ]train loss : 0.068305 ,train acc: 0.982818 ,val loss : 0.162846 ,val acc : 0.975494\n",
      "[ ecpho : 1  iter :148 ]train loss : 0.090828 ,train acc: 0.989552 ,val loss : 0.156738 ,val acc : 0.975494\n",
      "[ ecpho : 1  iter :149 ]train loss : 0.114126 ,train acc: 0.981943 ,val loss : 0.152836 ,val acc : 0.974640\n",
      "[ ecpho : 1  iter :150 ]train loss : 0.120411 ,train acc: 0.959706 ,val loss : 0.144832 ,val acc : 0.974609\n",
      "[ ecpho : 1  iter :151 ]train loss : 0.086278 ,train acc: 0.984344 ,val loss : 0.139809 ,val acc : 0.974243\n",
      "[ ecpho : 1  iter :152 ]train loss : 0.095446 ,train acc: 0.973256 ,val loss : 0.136875 ,val acc : 0.974518\n",
      "[ ecpho : 1  iter :153 ]train loss : 0.239891 ,train acc: 0.899546 ,val loss : 0.144105 ,val acc : 0.973907\n",
      "[ ecpho : 1  iter :154 ]train loss : 0.188501 ,train acc: 0.928355 ,val loss : 0.154057 ,val acc : 0.974548\n",
      "[ ecpho : 1  iter :155 ]train loss : 0.071024 ,train acc: 0.986826 ,val loss : 0.162757 ,val acc : 0.973999\n",
      "[ ecpho : 1  iter :156 ]train loss : 0.169160 ,train acc: 0.942016 ,val loss : 0.166986 ,val acc : 0.972626\n",
      "[ ecpho : 1  iter :157 ]train loss : 0.231412 ,train acc: 0.928934 ,val loss : 0.165784 ,val acc : 0.973145\n",
      "[ ecpho : 1  iter :158 ]train loss : 0.198810 ,train acc: 0.902201 ,val loss : 0.166024 ,val acc : 0.973022\n",
      "[ ecpho : 1  iter :159 ]train loss : 0.157488 ,train acc: 0.955648 ,val loss : 0.165921 ,val acc : 0.974915\n",
      "[ ecpho : 1  iter :160 ]train loss : 0.148378 ,train acc: 0.970448 ,val loss : 0.159233 ,val acc : 0.975098\n",
      "[ ecpho : 1  iter :161 ]train loss : 0.066233 ,train acc: 0.993377 ,val loss : 0.151637 ,val acc : 0.975250\n",
      "[ ecpho : 1  iter :162 ]train loss : 0.088688 ,train acc: 0.991251 ,val loss : 0.147790 ,val acc : 0.975342\n",
      "[ ecpho : 1  iter :163 ]train loss : 0.062975 ,train acc: 0.984232 ,val loss : 0.145856 ,val acc : 0.974243\n",
      "[ ecpho : 1  iter :164 ]train loss : 0.209919 ,train acc: 0.915792 ,val loss : 0.146096 ,val acc : 0.974335\n",
      "[ ecpho : 1  iter :165 ]train loss : 0.092999 ,train acc: 0.976877 ,val loss : 0.146662 ,val acc : 0.971832\n",
      "[ ecpho : 1  iter :166 ]train loss : 0.157127 ,train acc: 0.941101 ,val loss : 0.140182 ,val acc : 0.972168\n",
      "[ ecpho : 1  iter :167 ]train loss : 0.186927 ,train acc: 0.922333 ,val loss : 0.143981 ,val acc : 0.967651\n",
      "[ ecpho : 1  iter :168 ]train loss : 0.067944 ,train acc: 0.980733 ,val loss : 0.145513 ,val acc : 0.971802\n",
      "[ ecpho : 1  iter :169 ]train loss : 0.078526 ,train acc: 0.986602 ,val loss : 0.143177 ,val acc : 0.976105\n",
      "[ ecpho : 1  iter :170 ]train loss : 0.138548 ,train acc: 0.945058 ,val loss : 0.143510 ,val acc : 0.975952\n",
      "[ ecpho : 1  iter :171 ]train loss : 0.122888 ,train acc: 0.966227 ,val loss : 0.139697 ,val acc : 0.976868\n",
      "[ ecpho : 1  iter :172 ]train loss : 0.054622 ,train acc: 0.993459 ,val loss : 0.139931 ,val acc : 0.976501\n",
      "[ ecpho : 1  iter :173 ]train loss : 0.084841 ,train acc: 0.983520 ,val loss : 0.134677 ,val acc : 0.976685\n",
      "[ ecpho : 1  iter :174 ]train loss : 0.088840 ,train acc: 0.988362 ,val loss : 0.126945 ,val acc : 0.976807\n",
      "[ ecpho : 1  iter :175 ]train loss : 0.094442 ,train acc: 0.984598 ,val loss : 0.121603 ,val acc : 0.976288\n",
      "[ ecpho : 1  iter :176 ]train loss : 0.228003 ,train acc: 0.925394 ,val loss : 0.126890 ,val acc : 0.976624\n",
      "[ ecpho : 1  iter :177 ]train loss : 0.089641 ,train acc: 0.981231 ,val loss : 0.131701 ,val acc : 0.976410\n",
      "[ ecpho : 1  iter :178 ]train loss : 0.085125 ,train acc: 0.989644 ,val loss : 0.127415 ,val acc : 0.976074\n",
      "[ ecpho : 1  iter :179 ]train loss : 0.118458 ,train acc: 0.960795 ,val loss : 0.125831 ,val acc : 0.975555\n",
      "[ ecpho : 1  iter :180 ]train loss : 0.062699 ,train acc: 0.989685 ,val loss : 0.125316 ,val acc : 0.974884\n",
      "[ ecpho : 1  iter :181 ]train loss : 0.082293 ,train acc: 0.983306 ,val loss : 0.119213 ,val acc : 0.976471\n",
      "[ ecpho : 1  iter :182 ]train loss : 0.236247 ,train acc: 0.909922 ,val loss : 0.135889 ,val acc : 0.975006\n",
      "[ ecpho : 1  iter :183 ]train loss : 0.080206 ,train acc: 0.975321 ,val loss : 0.144357 ,val acc : 0.971161\n",
      "[ ecpho : 1  iter :184 ]train loss : 0.065008 ,train acc: 0.988016 ,val loss : 0.152602 ,val acc : 0.974274\n",
      "[ ecpho : 1  iter :185 ]train loss : 0.111975 ,train acc: 0.973215 ,val loss : 0.155418 ,val acc : 0.975647\n",
      "[ ecpho : 1  iter :186 ]train loss : 0.109913 ,train acc: 0.981801 ,val loss : 0.149009 ,val acc : 0.977783\n",
      "[ ecpho : 1  iter :187 ]train loss : 0.229172 ,train acc: 0.940450 ,val loss : 0.143571 ,val acc : 0.977448\n",
      "[ ecpho : 1  iter :188 ]train loss : 0.120323 ,train acc: 0.972636 ,val loss : 0.135601 ,val acc : 0.977112\n",
      "[ ecpho : 1  iter :189 ]train loss : 0.072263 ,train acc: 0.993235 ,val loss : 0.126117 ,val acc : 0.975769\n",
      "[ ecpho : 1  iter :190 ]train loss : 0.064900 ,train acc: 0.994140 ,val loss : 0.123879 ,val acc : 0.975403\n",
      "[ ecpho : 1  iter :191 ]train loss : 0.061971 ,train acc: 0.986582 ,val loss : 0.120742 ,val acc : 0.974121\n",
      "[ ecpho : 1  iter :192 ]train loss : 0.070839 ,train acc: 0.989786 ,val loss : 0.120023 ,val acc : 0.973572\n",
      "[ ecpho : 1  iter :193 ]train loss : 0.056647 ,train acc: 0.989420 ,val loss : 0.119012 ,val acc : 0.974487\n",
      "[ ecpho : 1  iter :194 ]train loss : 0.079691 ,train acc: 0.985850 ,val loss : 0.118644 ,val acc : 0.975281\n",
      "[ ecpho : 1  iter :195 ]train loss : 0.064833 ,train acc: 0.993865 ,val loss : 0.117197 ,val acc : 0.975922\n",
      "[ ecpho : 1  iter :196 ]train loss : 0.189440 ,train acc: 0.932800 ,val loss : 0.118780 ,val acc : 0.976074\n",
      "[ ecpho : 1  iter :197 ]train loss : 0.067627 ,train acc: 0.982991 ,val loss : 0.123113 ,val acc : 0.976196\n",
      "[ ecpho : 1  iter :198 ]train loss : 0.060138 ,train acc: 0.991566 ,val loss : 0.123355 ,val acc : 0.975800\n",
      "[ ecpho : 1  iter :199 ]train loss : 0.196740 ,train acc: 0.924031 ,val loss : 0.131593 ,val acc : 0.976532\n",
      "[ ecpho : 1  iter :200 ]train loss : 0.070043 ,train acc: 0.984609 ,val loss : 0.137141 ,val acc : 0.976013\n",
      "[ ecpho : 1  iter :201 ]train loss : 0.126174 ,train acc: 0.954610 ,val loss : 0.142340 ,val acc : 0.975922\n",
      "[ ecpho : 1  iter :202 ]train loss : 0.106204 ,train acc: 0.977854 ,val loss : 0.141125 ,val acc : 0.975006\n",
      "[ ecpho : 1  iter :203 ]train loss : 0.195435 ,train acc: 0.946380 ,val loss : 0.135162 ,val acc : 0.975769\n",
      "[ ecpho : 1  iter :204 ]train loss : 0.160186 ,train acc: 0.937490 ,val loss : 0.135894 ,val acc : 0.975098\n",
      "[ ecpho : 1  iter :205 ]train loss : 0.210243 ,train acc: 0.910604 ,val loss : 0.138641 ,val acc : 0.975372\n",
      "[ ecpho : 1  iter :206 ]train loss : 0.167994 ,train acc: 0.942698 ,val loss : 0.134190 ,val acc : 0.973877\n",
      "[ ecpho : 1  iter :207 ]train loss : 0.061100 ,train acc: 0.984853 ,val loss : 0.135610 ,val acc : 0.974731\n",
      "[ ecpho : 1  iter :208 ]train loss : 0.194316 ,train acc: 0.913849 ,val loss : 0.146189 ,val acc : 0.974884\n",
      "[ ecpho : 1  iter :209 ]train loss : 0.148276 ,train acc: 0.960622 ,val loss : 0.148203 ,val acc : 0.974823\n",
      "[ ecpho : 1  iter :210 ]train loss : 0.068003 ,train acc: 0.982533 ,val loss : 0.148562 ,val acc : 0.975372\n",
      "[ ecpho : 1  iter :211 ]train loss : 0.064881 ,train acc: 0.984924 ,val loss : 0.149711 ,val acc : 0.974854\n",
      "[ ecpho : 1  iter :212 ]train loss : 0.204832 ,train acc: 0.928294 ,val loss : 0.146913 ,val acc : 0.975037\n",
      "[ ecpho : 1  iter :213 ]train loss : 0.228491 ,train acc: 0.880066 ,val loss : 0.151877 ,val acc : 0.975861\n",
      "[ ecpho : 1  iter :214 ]train loss : 0.098440 ,train acc: 0.991485 ,val loss : 0.152131 ,val acc : 0.974915\n",
      "[ ecpho : 1  iter :215 ]train loss : 0.104424 ,train acc: 0.961710 ,val loss : 0.151478 ,val acc : 0.975372\n",
      "[ ecpho : 1  iter :216 ]train loss : 0.076053 ,train acc: 0.988322 ,val loss : 0.151123 ,val acc : 0.975372\n",
      "[ ecpho : 1  iter :217 ]train loss : 0.117833 ,train acc: 0.973093 ,val loss : 0.149845 ,val acc : 0.974487\n",
      "[ ecpho : 1  iter :218 ]train loss : 0.320955 ,train acc: 0.873535 ,val loss : 0.140312 ,val acc : 0.973602\n",
      "[ ecpho : 1  iter :219 ]train loss : 0.231923 ,train acc: 0.894277 ,val loss : 0.135598 ,val acc : 0.971039\n",
      "[ ecpho : 1  iter :220 ]train loss : 0.079443 ,train acc: 0.990509 ,val loss : 0.131163 ,val acc : 0.968536\n",
      "[ ecpho : 1  iter :221 ]train loss : 0.073883 ,train acc: 0.988474 ,val loss : 0.129042 ,val acc : 0.967499\n",
      "[ ecpho : 1  iter :222 ]train loss : 0.101908 ,train acc: 0.968546 ,val loss : 0.130527 ,val acc : 0.961090\n",
      "[ ecpho : 1  iter :223 ]train loss : 0.125440 ,train acc: 0.951039 ,val loss : 0.146098 ,val acc : 0.945404\n",
      "[ ecpho : 1  iter :224 ]train loss : 0.106249 ,train acc: 0.956685 ,val loss : 0.127994 ,val acc : 0.965942\n",
      "[ ecpho : 1  iter :225 ]train loss : 0.079275 ,train acc: 0.974172 ,val loss : 0.124569 ,val acc : 0.970123\n",
      "[ ecpho : 1  iter :226 ]train loss : 0.081457 ,train acc: 0.983256 ,val loss : 0.123414 ,val acc : 0.971375\n",
      "[ ecpho : 1  iter :227 ]train loss : 0.073719 ,train acc: 0.975718 ,val loss : 0.124412 ,val acc : 0.973816\n",
      "[ ecpho : 1  iter :228 ]train loss : 0.080899 ,train acc: 0.976318 ,val loss : 0.124421 ,val acc : 0.974640\n",
      "[ ecpho : 1  iter :229 ]train loss : 0.069687 ,train acc: 0.987203 ,val loss : 0.124672 ,val acc : 0.975189\n",
      "[ ecpho : 1  iter :230 ]train loss : 0.076256 ,train acc: 0.976410 ,val loss : 0.124839 ,val acc : 0.975647\n",
      "[ ecpho : 1  iter :231 ]train loss : 0.070794 ,train acc: 0.984202 ,val loss : 0.127731 ,val acc : 0.975616\n",
      "[ ecpho : 1  iter :232 ]train loss : 0.057782 ,train acc: 0.991984 ,val loss : 0.125103 ,val acc : 0.975616\n",
      "[ ecpho : 1  iter :233 ]train loss : 0.340518 ,train acc: 0.862600 ,val loss : 0.155329 ,val acc : 0.967072\n",
      "[ ecpho : 1  iter :234 ]train loss : 0.208149 ,train acc: 0.916870 ,val loss : 0.173902 ,val acc : 0.962250\n",
      "[ ecpho : 1  iter :235 ]train loss : 0.177152 ,train acc: 0.923014 ,val loss : 0.183655 ,val acc : 0.951965\n",
      "[ ecpho : 1  iter :236 ]train loss : 0.119117 ,train acc: 0.951182 ,val loss : 0.179361 ,val acc : 0.976349\n",
      "[ ecpho : 1  iter :237 ]train loss : 0.158526 ,train acc: 0.958557 ,val loss : 0.181496 ,val acc : 0.978088\n",
      "[ ecpho : 1  iter :238 ]train loss : 0.125527 ,train acc: 0.969391 ,val loss : 0.176934 ,val acc : 0.978363\n",
      "[ ecpho : 1  iter :239 ]train loss : 0.089205 ,train acc: 0.996073 ,val loss : 0.179619 ,val acc : 0.977997\n",
      "[ ecpho : 1  iter :240 ]train loss : 0.208733 ,train acc: 0.892608 ,val loss : 0.181820 ,val acc : 0.977936\n",
      "[ ecpho : 1  iter :241 ]train loss : 0.151600 ,train acc: 0.962005 ,val loss : 0.180311 ,val acc : 0.977112\n",
      "[ ecpho : 1  iter :242 ]train loss : 0.089469 ,train acc: 0.989115 ,val loss : 0.176515 ,val acc : 0.976501\n",
      "[ ecpho : 1  iter :243 ]train loss : 0.197571 ,train acc: 0.940908 ,val loss : 0.178222 ,val acc : 0.974854\n",
      "[ ecpho : 1  iter :244 ]train loss : 0.162565 ,train acc: 0.960276 ,val loss : 0.169541 ,val acc : 0.974976\n",
      "[ ecpho : 1  iter :245 ]train loss : 0.281515 ,train acc: 0.899536 ,val loss : 0.164988 ,val acc : 0.974213\n",
      "[ ecpho : 1  iter :246 ]train loss : 0.111182 ,train acc: 0.977132 ,val loss : 0.162282 ,val acc : 0.973572\n",
      "[ ecpho : 1  iter :247 ]train loss : 0.167143 ,train acc: 0.964528 ,val loss : 0.158701 ,val acc : 0.972534\n",
      "[ ecpho : 1  iter :248 ]train loss : 0.181807 ,train acc: 0.939016 ,val loss : 0.151343 ,val acc : 0.972260\n",
      "[ ecpho : 1  iter :249 ]train loss : 0.087441 ,train acc: 0.984049 ,val loss : 0.147293 ,val acc : 0.970978\n",
      "[ ecpho : 1  iter :250 ]train loss : 0.193582 ,train acc: 0.913116 ,val loss : 0.152538 ,val acc : 0.968506\n",
      "[ ecpho : 1  iter :251 ]train loss : 0.062826 ,train acc: 0.983378 ,val loss : 0.151433 ,val acc : 0.968475\n",
      "[ ecpho : 1  iter :252 ]train loss : 0.122078 ,train acc: 0.958760 ,val loss : 0.156455 ,val acc : 0.967072\n",
      "[ ecpho : 1  iter :253 ]train loss : 0.094708 ,train acc: 0.976023 ,val loss : 0.151528 ,val acc : 0.970947\n",
      "[ ecpho : 1  iter :254 ]train loss : 0.086653 ,train acc: 0.985545 ,val loss : 0.146476 ,val acc : 0.972961\n",
      "[ ecpho : 1  iter :255 ]train loss : 0.090224 ,train acc: 0.984110 ,val loss : 0.138960 ,val acc : 0.974487\n",
      "[ ecpho : 1  iter :256 ]train loss : 0.154438 ,train acc: 0.943990 ,val loss : 0.143875 ,val acc : 0.975647\n",
      "[ ecpho : 1  iter :257 ]train loss : 0.228291 ,train acc: 0.906128 ,val loss : 0.158569 ,val acc : 0.976257\n",
      "[ ecpho : 1  iter :258 ]train loss : 0.061538 ,train acc: 0.995046 ,val loss : 0.169301 ,val acc : 0.977142\n",
      "[ ecpho : 1  iter :259 ]train loss : 0.123307 ,train acc: 0.958394 ,val loss : 0.172846 ,val acc : 0.976440\n",
      "[ ecpho : 1  iter :260 ]train loss : 0.143724 ,train acc: 0.936910 ,val loss : 0.174173 ,val acc : 0.977570\n",
      "[ ecpho : 1  iter :261 ]train loss : 0.102791 ,train acc: 0.982767 ,val loss : 0.176821 ,val acc : 0.977234\n",
      "[ ecpho : 1  iter :262 ]train loss : 0.359272 ,train acc: 0.929148 ,val loss : 0.168097 ,val acc : 0.977570\n",
      "[ ecpho : 1  iter :263 ]train loss : 0.125354 ,train acc: 0.977559 ,val loss : 0.156963 ,val acc : 0.975433\n",
      "[ ecpho : 1  iter :264 ]train loss : 0.087581 ,train acc: 0.987528 ,val loss : 0.150215 ,val acc : 0.974365\n",
      "[ ecpho : 1  iter :265 ]train loss : 0.085254 ,train acc: 0.990112 ,val loss : 0.149152 ,val acc : 0.973206\n",
      "[ ecpho : 1  iter :266 ]train loss : 0.091513 ,train acc: 0.971944 ,val loss : 0.144051 ,val acc : 0.973267\n",
      "[ ecpho : 1  iter :267 ]train loss : 0.059853 ,train acc: 0.995147 ,val loss : 0.137994 ,val acc : 0.972443\n",
      "[ ecpho : 1  iter :268 ]train loss : 0.072648 ,train acc: 0.986694 ,val loss : 0.136119 ,val acc : 0.970703\n",
      "[ ecpho : 1  iter :269 ]train loss : 0.234734 ,train acc: 0.906301 ,val loss : 0.143764 ,val acc : 0.963257\n",
      "[ ecpho : 1  iter :270 ]train loss : 0.126144 ,train acc: 0.952708 ,val loss : 0.155450 ,val acc : 0.956726\n",
      "[ ecpho : 1  iter :271 ]train loss : 0.197589 ,train acc: 0.902720 ,val loss : 0.200793 ,val acc : 0.919647\n",
      "[ ecpho : 1  iter :272 ]train loss : 0.138178 ,train acc: 0.930145 ,val loss : 0.166352 ,val acc : 0.974884\n",
      "[ ecpho : 1  iter :273 ]train loss : 0.099440 ,train acc: 0.984690 ,val loss : 0.166925 ,val acc : 0.976898\n",
      "[ ecpho : 1  iter :274 ]train loss : 0.138795 ,train acc: 0.964315 ,val loss : 0.165799 ,val acc : 0.975983\n",
      "[ ecpho : 1  iter :275 ]train loss : 0.201493 ,train acc: 0.941925 ,val loss : 0.163415 ,val acc : 0.977020\n",
      "[ ecpho : 1  iter :276 ]train loss : 0.145959 ,train acc: 0.963063 ,val loss : 0.161943 ,val acc : 0.976990\n",
      "[ ecpho : 1  iter :277 ]train loss : 0.063067 ,train acc: 0.995646 ,val loss : 0.161199 ,val acc : 0.976624\n",
      "[ ecpho : 1  iter :278 ]train loss : 0.095444 ,train acc: 0.979950 ,val loss : 0.160190 ,val acc : 0.975861\n",
      "[ ecpho : 1  iter :279 ]train loss : 0.181980 ,train acc: 0.907979 ,val loss : 0.159444 ,val acc : 0.972900\n",
      "[ ecpho : 1  iter :280 ]train loss : 0.054587 ,train acc: 0.990549 ,val loss : 0.162220 ,val acc : 0.970795\n",
      "[ ecpho : 1  iter :281 ]train loss : 0.145757 ,train acc: 0.966909 ,val loss : 0.159001 ,val acc : 0.969788\n",
      "[ ecpho : 1  iter :282 ]train loss : 0.095437 ,train acc: 0.977020 ,val loss : 0.152479 ,val acc : 0.972168\n",
      "[ ecpho : 1  iter :283 ]train loss : 0.111143 ,train acc: 0.973826 ,val loss : 0.150110 ,val acc : 0.972717\n",
      "[ ecpho : 1  iter :284 ]train loss : 0.211228 ,train acc: 0.917958 ,val loss : 0.144545 ,val acc : 0.973450\n",
      "[ ecpho : 1  iter :285 ]train loss : 0.075376 ,train acc: 0.973856 ,val loss : 0.145938 ,val acc : 0.972412\n",
      "[ ecpho : 1  iter :286 ]train loss : 0.194132 ,train acc: 0.929087 ,val loss : 0.144063 ,val acc : 0.972473\n",
      "[ ecpho : 1  iter :287 ]train loss : 0.086284 ,train acc: 0.987203 ,val loss : 0.140767 ,val acc : 0.973724\n",
      "[ ecpho : 1  iter :288 ]train loss : 0.083076 ,train acc: 0.987030 ,val loss : 0.135886 ,val acc : 0.973999\n",
      "[ ecpho : 1  iter :289 ]train loss : 0.102534 ,train acc: 0.981587 ,val loss : 0.129113 ,val acc : 0.974335\n",
      "[ ecpho : 1  iter :290 ]train loss : 0.199947 ,train acc: 0.925516 ,val loss : 0.129526 ,val acc : 0.974792\n",
      "[ ecpho : 1  iter :291 ]train loss : 0.115595 ,train acc: 0.962280 ,val loss : 0.133455 ,val acc : 0.972931\n",
      "[ ecpho : 1  iter :292 ]train loss : 0.063389 ,train acc: 0.987426 ,val loss : 0.134756 ,val acc : 0.973907\n",
      "[ ecpho : 1  iter :293 ]train loss : 0.066534 ,train acc: 0.984415 ,val loss : 0.133340 ,val acc : 0.973877\n",
      "[ ecpho : 1  iter :294 ]train loss : 0.071287 ,train acc: 0.979014 ,val loss : 0.133681 ,val acc : 0.973877\n",
      "[ ecpho : 1  iter :295 ]train loss : 0.280145 ,train acc: 0.904765 ,val loss : 0.134552 ,val acc : 0.974731\n",
      "[ ecpho : 1  iter :296 ]train loss : 0.069245 ,train acc: 0.980875 ,val loss : 0.132026 ,val acc : 0.975983\n",
      "[ ecpho : 1  iter :297 ]train loss : 0.211417 ,train acc: 0.909973 ,val loss : 0.138151 ,val acc : 0.971741\n",
      "[ ecpho : 1  iter :298 ]train loss : 0.082238 ,train acc: 0.980234 ,val loss : 0.141267 ,val acc : 0.973724\n",
      "[ ecpho : 1  iter :299 ]train loss : 0.068488 ,train acc: 0.988372 ,val loss : 0.141383 ,val acc : 0.975433\n",
      "[ ecpho : 1  iter :300 ]train loss : 0.119643 ,train acc: 0.964518 ,val loss : 0.139363 ,val acc : 0.975739\n",
      "[ ecpho : 1  iter :301 ]train loss : 0.091222 ,train acc: 0.986999 ,val loss : 0.136617 ,val acc : 0.976715\n",
      "[ ecpho : 1  iter :302 ]train loss : 0.096818 ,train acc: 0.978607 ,val loss : 0.131108 ,val acc : 0.976501\n",
      "[ ecpho : 1  iter :303 ]train loss : 0.317348 ,train acc: 0.870860 ,val loss : 0.139806 ,val acc : 0.976898\n",
      "[ ecpho : 1  iter :304 ]train loss : 0.341634 ,train acc: 0.783874 ,val loss : 0.165633 ,val acc : 0.977448\n",
      "[ ecpho : 1  iter :305 ]train loss : 0.108827 ,train acc: 0.956512 ,val loss : 0.176580 ,val acc : 0.977356\n",
      "[ ecpho : 1  iter :306 ]train loss : 0.180634 ,train acc: 0.957774 ,val loss : 0.183859 ,val acc : 0.978546\n",
      "[ ecpho : 1  iter :307 ]train loss : 0.072769 ,train acc: 0.986277 ,val loss : 0.178972 ,val acc : 0.977722\n",
      "[ ecpho : 1  iter :308 ]train loss : 0.156031 ,train acc: 0.983469 ,val loss : 0.185686 ,val acc : 0.978516\n",
      "[ ecpho : 1  iter :309 ]train loss : 0.071537 ,train acc: 0.992574 ,val loss : 0.189734 ,val acc : 0.977966\n",
      "[ ecpho : 1  iter :310 ]train loss : 0.186155 ,train acc: 0.954823 ,val loss : 0.184076 ,val acc : 0.978241\n",
      "[ ecpho : 1  iter :311 ]train loss : 0.094550 ,train acc: 0.973999 ,val loss : 0.182687 ,val acc : 0.977844\n",
      "[ ecpho : 1  iter :312 ]train loss : 0.156082 ,train acc: 0.962656 ,val loss : 0.185365 ,val acc : 0.977386\n",
      "[ ecpho : 1  iter :313 ]train loss : 0.123351 ,train acc: 0.966074 ,val loss : 0.181711 ,val acc : 0.976196\n",
      "[ ecpho : 1  iter :314 ]train loss : 0.097602 ,train acc: 0.986063 ,val loss : 0.177193 ,val acc : 0.975739\n",
      "[ ecpho : 1  iter :315 ]train loss : 0.212836 ,train acc: 0.920654 ,val loss : 0.181230 ,val acc : 0.975464\n",
      "[ ecpho : 1  iter :316 ]train loss : 0.063012 ,train acc: 0.990672 ,val loss : 0.178767 ,val acc : 0.975159\n",
      "[ ecpho : 1  iter :317 ]train loss : 0.106289 ,train acc: 0.975331 ,val loss : 0.177864 ,val acc : 0.975281\n",
      "[ ecpho : 1  iter :318 ]train loss : 0.165831 ,train acc: 0.962606 ,val loss : 0.179624 ,val acc : 0.974304\n",
      "[ ecpho : 1  iter :319 ]train loss : 0.129965 ,train acc: 0.973470 ,val loss : 0.172853 ,val acc : 0.974121\n",
      "[ ecpho : 1  iter :320 ]train loss : 0.124299 ,train acc: 0.945078 ,val loss : 0.167860 ,val acc : 0.974792\n",
      "[ ecpho : 1  iter :321 ]train loss : 0.314659 ,train acc: 0.853607 ,val loss : 0.172530 ,val acc : 0.973755\n",
      "[ ecpho : 1  iter :322 ]train loss : 0.131281 ,train acc: 0.943084 ,val loss : 0.168279 ,val acc : 0.973602\n",
      "[ ecpho : 1  iter :323 ]train loss : 0.083403 ,train acc: 0.987864 ,val loss : 0.169966 ,val acc : 0.973785\n",
      "[ ecpho : 1  iter :324 ]train loss : 0.146352 ,train acc: 0.967132 ,val loss : 0.168063 ,val acc : 0.973389\n",
      "[ ecpho : 1  iter :325 ]train loss : 0.108292 ,train acc: 0.987772 ,val loss : 0.158800 ,val acc : 0.973877\n",
      "[ ecpho : 1  iter :326 ]train loss : 0.214874 ,train acc: 0.917887 ,val loss : 0.155787 ,val acc : 0.973114\n",
      "[ ecpho : 1  iter :327 ]train loss : 0.092921 ,train acc: 0.990509 ,val loss : 0.155110 ,val acc : 0.972595\n",
      "[ ecpho : 1  iter :328 ]train loss : 0.078826 ,train acc: 0.987711 ,val loss : 0.149824 ,val acc : 0.970490\n",
      "[ ecpho : 1  iter :329 ]train loss : 0.119619 ,train acc: 0.975270 ,val loss : 0.139279 ,val acc : 0.970703\n",
      "[ ecpho : 1  iter :330 ]train loss : 0.110163 ,train acc: 0.966471 ,val loss : 0.136211 ,val acc : 0.969513\n",
      "[ ecpho : 1  iter :331 ]train loss : 0.135184 ,train acc: 0.946574 ,val loss : 0.138890 ,val acc : 0.968903\n",
      "[ ecpho : 1  iter :332 ]train loss : 0.132311 ,train acc: 0.958231 ,val loss : 0.139564 ,val acc : 0.968292\n",
      "[ ecpho : 1  iter :333 ]train loss : 0.187604 ,train acc: 0.928507 ,val loss : 0.144213 ,val acc : 0.968262\n",
      "[ ecpho : 1  iter :334 ]train loss : 0.088569 ,train acc: 0.975006 ,val loss : 0.149704 ,val acc : 0.964813\n",
      "[ ecpho : 1  iter :335 ]train loss : 0.135089 ,train acc: 0.958933 ,val loss : 0.157108 ,val acc : 0.959290\n",
      "[ ecpho : 1  iter :336 ]train loss : 0.146090 ,train acc: 0.933675 ,val loss : 0.162777 ,val acc : 0.951599\n",
      "[ ecpho : 1  iter :337 ]train loss : 0.071654 ,train acc: 0.974375 ,val loss : 0.162955 ,val acc : 0.964417\n",
      "[ ecpho : 1  iter :338 ]train loss : 0.074365 ,train acc: 0.980041 ,val loss : 0.158944 ,val acc : 0.974060\n",
      "[ ecpho : 1  iter :339 ]train loss : 0.057866 ,train acc: 0.983825 ,val loss : 0.156738 ,val acc : 0.976318\n",
      "[ ecpho : 1  iter :340 ]train loss : 0.178322 ,train acc: 0.912984 ,val loss : 0.158511 ,val acc : 0.976685\n",
      "[ ecpho : 1  iter :341 ]train loss : 0.173867 ,train acc: 0.957062 ,val loss : 0.157707 ,val acc : 0.976837\n",
      "[ ecpho : 1  iter :342 ]train loss : 0.054391 ,train acc: 0.989278 ,val loss : 0.153872 ,val acc : 0.976837\n",
      "[ ecpho : 1  iter :343 ]train loss : 0.074817 ,train acc: 0.994995 ,val loss : 0.155780 ,val acc : 0.976532\n",
      "[ ecpho : 1  iter :344 ]train loss : 0.080264 ,train acc: 0.986226 ,val loss : 0.151363 ,val acc : 0.976349\n",
      "[ ecpho : 1  iter :345 ]train loss : 0.120150 ,train acc: 0.951060 ,val loss : 0.151874 ,val acc : 0.976105\n",
      "[ ecpho : 1  iter :346 ]train loss : 0.142261 ,train acc: 0.963877 ,val loss : 0.146279 ,val acc : 0.975220\n",
      "[ ecpho : 1  iter :347 ]train loss : 0.104691 ,train acc: 0.981547 ,val loss : 0.142502 ,val acc : 0.975006\n",
      "[ ecpho : 1  iter :348 ]train loss : 0.079260 ,train acc: 0.980723 ,val loss : 0.138448 ,val acc : 0.974945\n",
      "[ ecpho : 1  iter :349 ]train loss : 0.056245 ,train acc: 0.988667 ,val loss : 0.139700 ,val acc : 0.975098\n",
      "[ ecpho : 1  iter :350 ]train loss : 0.121635 ,train acc: 0.965210 ,val loss : 0.142115 ,val acc : 0.975983\n",
      "[ ecpho : 1  iter :351 ]train loss : 0.086742 ,train acc: 0.983663 ,val loss : 0.142055 ,val acc : 0.976318\n",
      "[ ecpho : 1  iter :352 ]train loss : 0.179911 ,train acc: 0.922394 ,val loss : 0.143745 ,val acc : 0.976532\n",
      "[ ecpho : 1  iter :353 ]train loss : 0.082939 ,train acc: 0.990305 ,val loss : 0.147369 ,val acc : 0.976135\n",
      "[ ecpho : 1  iter :354 ]train loss : 0.052820 ,train acc: 0.989512 ,val loss : 0.146813 ,val acc : 0.975250\n",
      "[ ecpho : 1  iter :355 ]train loss : 0.203803 ,train acc: 0.921295 ,val loss : 0.147738 ,val acc : 0.976440\n",
      "[ ecpho : 1  iter :356 ]train loss : 0.374366 ,train acc: 0.795440 ,val loss : 0.156779 ,val acc : 0.974884\n",
      "[ ecpho : 1  iter :357 ]train loss : 0.100481 ,train acc: 0.984314 ,val loss : 0.157874 ,val acc : 0.974060\n",
      "[ ecpho : 1  iter :358 ]train loss : 0.185465 ,train acc: 0.926137 ,val loss : 0.157530 ,val acc : 0.974060\n",
      "[ ecpho : 1  iter :359 ]train loss : 0.076474 ,train acc: 0.990732 ,val loss : 0.156450 ,val acc : 0.975372\n",
      "[ ecpho : 1  iter :360 ]train loss : 0.115636 ,train acc: 0.959269 ,val loss : 0.154645 ,val acc : 0.975067\n",
      "[ ecpho : 1  iter :361 ]train loss : 0.165520 ,train acc: 0.928863 ,val loss : 0.157578 ,val acc : 0.976349\n",
      "[ ecpho : 1  iter :362 ]train loss : 0.102805 ,train acc: 0.988932 ,val loss : 0.160340 ,val acc : 0.975891\n",
      "[ ecpho : 1  iter :363 ]train loss : 0.074461 ,train acc: 0.995290 ,val loss : 0.151769 ,val acc : 0.975769\n",
      "[ ecpho : 1  iter :364 ]train loss : 0.089201 ,train acc: 0.991689 ,val loss : 0.147498 ,val acc : 0.975220\n",
      "[ ecpho : 1  iter :365 ]train loss : 0.120619 ,train acc: 0.972056 ,val loss : 0.143528 ,val acc : 0.974792\n",
      "[ ecpho : 1  iter :366 ]train loss : 0.255435 ,train acc: 0.879099 ,val loss : 0.145150 ,val acc : 0.974792\n",
      "[ ecpho : 1  iter :367 ]train loss : 0.118141 ,train acc: 0.961934 ,val loss : 0.148792 ,val acc : 0.974213\n",
      "[ ecpho : 1  iter :368 ]train loss : 0.066399 ,train acc: 0.993326 ,val loss : 0.149856 ,val acc : 0.973541\n",
      "[ ecpho : 1  iter :369 ]train loss : 0.070035 ,train acc: 0.981160 ,val loss : 0.149926 ,val acc : 0.975098\n",
      "[ ecpho : 1  iter :370 ]train loss : 0.102652 ,train acc: 0.966624 ,val loss : 0.151816 ,val acc : 0.974213\n",
      "[ ecpho : 1  iter :371 ]train loss : 0.130436 ,train acc: 0.950561 ,val loss : 0.151269 ,val acc : 0.975281\n",
      "[ ecpho : 1  iter :372 ]train loss : 0.188251 ,train acc: 0.932607 ,val loss : 0.147014 ,val acc : 0.975952\n",
      "[ ecpho : 1  iter :373 ]train loss : 0.256804 ,train acc: 0.878133 ,val loss : 0.151867 ,val acc : 0.974792\n",
      "[ ecpho : 1  iter :374 ]train loss : 0.092247 ,train acc: 0.981954 ,val loss : 0.151549 ,val acc : 0.974640\n",
      "[ ecpho : 1  iter :375 ]train loss : 0.120154 ,train acc: 0.950541 ,val loss : 0.150725 ,val acc : 0.975128\n",
      "[ ecpho : 1  iter :376 ]train loss : 0.150604 ,train acc: 0.944356 ,val loss : 0.147669 ,val acc : 0.974457\n",
      "[ ecpho : 1  iter :377 ]train loss : 0.093946 ,train acc: 0.988545 ,val loss : 0.146871 ,val acc : 0.974609\n",
      "[ ecpho : 1  iter :378 ]train loss : 0.075136 ,train acc: 0.983062 ,val loss : 0.139776 ,val acc : 0.974640\n",
      "[ ecpho : 1  iter :379 ]train loss : 0.091138 ,train acc: 0.984324 ,val loss : 0.135342 ,val acc : 0.975433\n",
      "[ ecpho : 1  iter :380 ]train loss : 0.139765 ,train acc: 0.953328 ,val loss : 0.135647 ,val acc : 0.974335\n",
      "[ ecpho : 1  iter :381 ]train loss : 0.076726 ,train acc: 0.987579 ,val loss : 0.135914 ,val acc : 0.973938\n",
      "[ ecpho : 1  iter :382 ]train loss : 0.056741 ,train acc: 0.992126 ,val loss : 0.133460 ,val acc : 0.974823\n",
      "[ ecpho : 1  iter :383 ]train loss : 0.231899 ,train acc: 0.908162 ,val loss : 0.130524 ,val acc : 0.973419\n",
      "[ ecpho : 1  iter :384 ]train loss : 0.105515 ,train acc: 0.964294 ,val loss : 0.132605 ,val acc : 0.972504\n",
      "[ ecpho : 1  iter :385 ]train loss : 0.088084 ,train acc: 0.979777 ,val loss : 0.131036 ,val acc : 0.971954\n",
      "[ ecpho : 1  iter :386 ]train loss : 0.168079 ,train acc: 0.941447 ,val loss : 0.138058 ,val acc : 0.972534\n",
      "[ ecpho : 1  iter :387 ]train loss : 0.191867 ,train acc: 0.913493 ,val loss : 0.152219 ,val acc : 0.967651\n",
      "[ ecpho : 1  iter :388 ]train loss : 0.185069 ,train acc: 0.929616 ,val loss : 0.162621 ,val acc : 0.961975\n",
      "[ ecpho : 1  iter :389 ]train loss : 0.112570 ,train acc: 0.980021 ,val loss : 0.161812 ,val acc : 0.964294\n",
      "[ ecpho : 1  iter :390 ]train loss : 0.115522 ,train acc: 0.954854 ,val loss : 0.154786 ,val acc : 0.968384\n",
      "[ ecpho : 1  iter :391 ]train loss : 0.154112 ,train acc: 0.929901 ,val loss : 0.159367 ,val acc : 0.966522\n",
      "[ ecpho : 1  iter :392 ]train loss : 0.130720 ,train acc: 0.943634 ,val loss : 0.164905 ,val acc : 0.966339\n",
      "[ ecpho : 1  iter :393 ]train loss : 0.086325 ,train acc: 0.972849 ,val loss : 0.160816 ,val acc : 0.970337\n",
      "[ ecpho : 1  iter :394 ]train loss : 0.088602 ,train acc: 0.977579 ,val loss : 0.160611 ,val acc : 0.975311\n",
      "[ ecpho : 1  iter :395 ]train loss : 0.078716 ,train acc: 0.988026 ,val loss : 0.155953 ,val acc : 0.976715\n",
      "[ ecpho : 1  iter :396 ]train loss : 0.136434 ,train acc: 0.964721 ,val loss : 0.156514 ,val acc : 0.976593\n",
      "[ ecpho : 1  iter :397 ]train loss : 0.078959 ,train acc: 0.995249 ,val loss : 0.148172 ,val acc : 0.976898\n",
      "[ ecpho : 1  iter :398 ]train loss : 0.112758 ,train acc: 0.973307 ,val loss : 0.149098 ,val acc : 0.976807\n",
      "[ ecpho : 1  iter :399 ]train loss : 0.213070 ,train acc: 0.916148 ,val loss : 0.145113 ,val acc : 0.977234\n",
      "[ ecpho : 1  iter :400 ]train loss : 0.051228 ,train acc: 0.992279 ,val loss : 0.143906 ,val acc : 0.976929\n",
      "=============================================\n",
      "[ 1 ] average train loss : 0.130471 train acc : 0.959111\n",
      "[ ecpho : 2  iter :1 ]train loss : 0.115030 ,train acc: 0.983612 ,val loss : 0.138475 ,val acc : 0.976044\n",
      "[ ecpho : 2  iter :2 ]train loss : 0.086866 ,train acc: 0.988535 ,val loss : 0.130526 ,val acc : 0.976562\n",
      "[ ecpho : 2  iter :3 ]train loss : 0.093346 ,train acc: 0.977793 ,val loss : 0.129592 ,val acc : 0.975372\n",
      "[ ecpho : 2  iter :4 ]train loss : 0.142265 ,train acc: 0.955251 ,val loss : 0.127706 ,val acc : 0.975250\n",
      "[ ecpho : 2  iter :5 ]train loss : 0.063287 ,train acc: 0.991851 ,val loss : 0.123247 ,val acc : 0.975525\n",
      "[ ecpho : 2  iter :6 ]train loss : 0.057754 ,train acc: 0.993418 ,val loss : 0.122340 ,val acc : 0.975403\n",
      "[ ecpho : 2  iter :7 ]train loss : 0.339256 ,train acc: 0.898061 ,val loss : 0.144042 ,val acc : 0.975464\n",
      "[ ecpho : 2  iter :8 ]train loss : 0.086189 ,train acc: 0.984792 ,val loss : 0.160197 ,val acc : 0.974152\n",
      "[ ecpho : 2  iter :9 ]train loss : 0.132442 ,train acc: 0.935953 ,val loss : 0.172671 ,val acc : 0.973175\n",
      "[ ecpho : 2  iter :10 ]train loss : 0.056057 ,train acc: 0.991628 ,val loss : 0.174517 ,val acc : 0.973114\n",
      "[ ecpho : 2  iter :11 ]train loss : 0.087492 ,train acc: 0.979726 ,val loss : 0.176966 ,val acc : 0.974609\n",
      "[ ecpho : 2  iter :12 ]train loss : 0.248399 ,train acc: 0.937846 ,val loss : 0.170622 ,val acc : 0.976471\n",
      "[ ecpho : 2  iter :13 ]train loss : 0.150157 ,train acc: 0.938212 ,val loss : 0.174072 ,val acc : 0.975861\n",
      "[ ecpho : 2  iter :14 ]train loss : 0.141145 ,train acc: 0.976521 ,val loss : 0.176251 ,val acc : 0.976746\n",
      "[ ecpho : 2  iter :15 ]train loss : 0.184207 ,train acc: 0.925405 ,val loss : 0.176187 ,val acc : 0.975311\n",
      "[ ecpho : 2  iter :16 ]train loss : 0.103677 ,train acc: 0.983083 ,val loss : 0.175049 ,val acc : 0.976532\n",
      "[ ecpho : 2  iter :17 ]train loss : 0.119358 ,train acc: 0.987731 ,val loss : 0.171766 ,val acc : 0.976501\n",
      "[ ecpho : 2  iter :18 ]train loss : 0.084132 ,train acc: 0.978587 ,val loss : 0.164201 ,val acc : 0.976837\n",
      "[ ecpho : 2  iter :19 ]train loss : 0.138397 ,train acc: 0.938924 ,val loss : 0.161088 ,val acc : 0.976593\n",
      "[ ecpho : 2  iter :20 ]train loss : 0.136874 ,train acc: 0.950215 ,val loss : 0.164788 ,val acc : 0.976166\n",
      "[ ecpho : 2  iter :21 ]train loss : 0.077567 ,train acc: 0.992584 ,val loss : 0.162036 ,val acc : 0.975189\n",
      "[ ecpho : 2  iter :22 ]train loss : 0.112175 ,train acc: 0.980855 ,val loss : 0.159663 ,val acc : 0.975677\n",
      "[ ecpho : 2  iter :23 ]train loss : 0.099223 ,train acc: 0.964742 ,val loss : 0.161695 ,val acc : 0.975342\n",
      "[ ecpho : 2  iter :24 ]train loss : 0.246950 ,train acc: 0.866953 ,val loss : 0.161414 ,val acc : 0.974396\n",
      "[ ecpho : 2  iter :25 ]train loss : 0.225959 ,train acc: 0.886932 ,val loss : 0.161519 ,val acc : 0.973846\n",
      "[ ecpho : 2  iter :26 ]train loss : 0.063554 ,train acc: 0.991607 ,val loss : 0.160214 ,val acc : 0.972412\n",
      "[ ecpho : 2  iter :27 ]train loss : 0.113841 ,train acc: 0.960602 ,val loss : 0.167221 ,val acc : 0.970032\n",
      "[ ecpho : 2  iter :28 ]train loss : 0.131264 ,train acc: 0.959137 ,val loss : 0.164148 ,val acc : 0.966919\n",
      "[ ecpho : 2  iter :29 ]train loss : 0.191031 ,train acc: 0.944966 ,val loss : 0.162782 ,val acc : 0.972992\n",
      "[ ecpho : 2  iter :30 ]train loss : 0.172252 ,train acc: 0.928802 ,val loss : 0.156584 ,val acc : 0.974060\n",
      "[ ecpho : 2  iter :31 ]train loss : 0.058244 ,train acc: 0.992696 ,val loss : 0.156383 ,val acc : 0.974121\n",
      "[ ecpho : 2  iter :32 ]train loss : 0.126634 ,train acc: 0.949290 ,val loss : 0.156795 ,val acc : 0.973541\n",
      "[ ecpho : 2  iter :33 ]train loss : 0.075477 ,train acc: 0.995015 ,val loss : 0.147335 ,val acc : 0.973450\n",
      "[ ecpho : 2  iter :34 ]train loss : 0.121484 ,train acc: 0.961934 ,val loss : 0.146358 ,val acc : 0.974121\n",
      "[ ecpho : 2  iter :35 ]train loss : 0.146287 ,train acc: 0.932800 ,val loss : 0.148903 ,val acc : 0.973724\n",
      "[ ecpho : 2  iter :36 ]train loss : 0.068072 ,train acc: 0.979624 ,val loss : 0.152023 ,val acc : 0.973358\n",
      "[ ecpho : 2  iter :37 ]train loss : 0.230329 ,train acc: 0.902567 ,val loss : 0.149596 ,val acc : 0.973236\n",
      "[ ecpho : 2  iter :38 ]train loss : 0.244173 ,train acc: 0.916911 ,val loss : 0.153544 ,val acc : 0.972534\n",
      "[ ecpho : 2  iter :39 ]train loss : 0.076616 ,train acc: 0.979146 ,val loss : 0.157984 ,val acc : 0.971283\n",
      "[ ecpho : 2  iter :40 ]train loss : 0.073431 ,train acc: 0.988444 ,val loss : 0.154670 ,val acc : 0.972717\n",
      "[ ecpho : 2  iter :41 ]train loss : 0.076528 ,train acc: 0.983602 ,val loss : 0.151533 ,val acc : 0.974304\n",
      "[ ecpho : 2  iter :42 ]train loss : 0.215366 ,train acc: 0.919495 ,val loss : 0.153633 ,val acc : 0.973663\n",
      "[ ecpho : 2  iter :43 ]train loss : 0.082768 ,train acc: 0.992146 ,val loss : 0.149680 ,val acc : 0.974670\n",
      "[ ecpho : 2  iter :44 ]train loss : 0.111592 ,train acc: 0.978556 ,val loss : 0.142799 ,val acc : 0.973480\n",
      "[ ecpho : 2  iter :45 ]train loss : 0.156247 ,train acc: 0.943227 ,val loss : 0.143806 ,val acc : 0.974060\n",
      "[ ecpho : 2  iter :46 ]train loss : 0.063001 ,train acc: 0.988189 ,val loss : 0.139037 ,val acc : 0.974030\n",
      "[ ecpho : 2  iter :47 ]train loss : 0.081211 ,train acc: 0.978932 ,val loss : 0.131728 ,val acc : 0.974060\n",
      "[ ecpho : 2  iter :48 ]train loss : 0.121039 ,train acc: 0.959472 ,val loss : 0.133704 ,val acc : 0.974121\n",
      "[ ecpho : 2  iter :49 ]train loss : 0.104128 ,train acc: 0.966715 ,val loss : 0.132675 ,val acc : 0.973358\n",
      "[ ecpho : 2  iter :50 ]train loss : 0.069478 ,train acc: 0.988840 ,val loss : 0.128967 ,val acc : 0.973145\n",
      "[ ecpho : 2  iter :51 ]train loss : 0.079478 ,train acc: 0.975575 ,val loss : 0.127487 ,val acc : 0.973724\n",
      "[ ecpho : 2  iter :52 ]train loss : 0.138051 ,train acc: 0.951497 ,val loss : 0.133077 ,val acc : 0.970703\n",
      "[ ecpho : 2  iter :53 ]train loss : 0.179454 ,train acc: 0.938212 ,val loss : 0.135297 ,val acc : 0.966949\n",
      "[ ecpho : 2  iter :54 ]train loss : 0.089193 ,train acc: 0.965586 ,val loss : 0.135435 ,val acc : 0.969604\n",
      "[ ecpho : 2  iter :55 ]train loss : 0.151881 ,train acc: 0.935099 ,val loss : 0.142870 ,val acc : 0.968201\n",
      "[ ecpho : 2  iter :56 ]train loss : 0.057270 ,train acc: 0.984893 ,val loss : 0.142420 ,val acc : 0.972870\n",
      "[ ecpho : 2  iter :57 ]train loss : 0.065244 ,train acc: 0.986755 ,val loss : 0.144365 ,val acc : 0.976471\n",
      "[ ecpho : 2  iter :58 ]train loss : 0.062298 ,train acc: 0.991465 ,val loss : 0.143138 ,val acc : 0.977203\n",
      "[ ecpho : 2  iter :59 ]train loss : 0.084921 ,train acc: 0.986216 ,val loss : 0.144237 ,val acc : 0.978394\n",
      "[ ecpho : 2  iter :60 ]train loss : 0.117113 ,train acc: 0.981120 ,val loss : 0.137181 ,val acc : 0.977783\n",
      "[ ecpho : 2  iter :61 ]train loss : 0.110774 ,train acc: 0.979299 ,val loss : 0.134835 ,val acc : 0.977386\n",
      "[ ecpho : 2  iter :62 ]train loss : 0.066727 ,train acc: 0.993296 ,val loss : 0.126772 ,val acc : 0.977325\n",
      "[ ecpho : 2  iter :63 ]train loss : 0.061556 ,train acc: 0.994354 ,val loss : 0.123757 ,val acc : 0.976562\n",
      "[ ecpho : 2  iter :64 ]train loss : 0.084890 ,train acc: 0.976420 ,val loss : 0.122956 ,val acc : 0.976471\n",
      "[ ecpho : 2  iter :65 ]train loss : 0.076797 ,train acc: 0.977905 ,val loss : 0.123628 ,val acc : 0.977112\n",
      "[ ecpho : 2  iter :66 ]train loss : 0.118110 ,train acc: 0.969442 ,val loss : 0.124695 ,val acc : 0.976624\n",
      "[ ecpho : 2  iter :67 ]train loss : 0.056597 ,train acc: 0.994140 ,val loss : 0.124431 ,val acc : 0.976959\n",
      "[ ecpho : 2  iter :68 ]train loss : 0.057895 ,train acc: 0.992980 ,val loss : 0.123860 ,val acc : 0.976654\n",
      "[ ecpho : 2  iter :69 ]train loss : 0.226540 ,train acc: 0.888041 ,val loss : 0.131550 ,val acc : 0.974731\n",
      "[ ecpho : 2  iter :70 ]train loss : 0.240587 ,train acc: 0.897878 ,val loss : 0.141089 ,val acc : 0.969482\n",
      "[ ecpho : 2  iter :71 ]train loss : 0.078371 ,train acc: 0.983479 ,val loss : 0.145658 ,val acc : 0.967438\n",
      "[ ecpho : 2  iter :72 ]train loss : 0.116298 ,train acc: 0.967651 ,val loss : 0.144434 ,val acc : 0.971069\n",
      "[ ecpho : 2  iter :73 ]train loss : 0.161792 ,train acc: 0.932108 ,val loss : 0.147648 ,val acc : 0.971802\n",
      "[ ecpho : 2  iter :74 ]train loss : 0.346254 ,train acc: 0.774739 ,val loss : 0.161891 ,val acc : 0.970764\n",
      "[ ecpho : 2  iter :75 ]train loss : 0.243353 ,train acc: 0.886576 ,val loss : 0.168167 ,val acc : 0.963562\n",
      "[ ecpho : 2  iter :76 ]train loss : 0.061944 ,train acc: 0.981333 ,val loss : 0.175162 ,val acc : 0.970917\n",
      "[ ecpho : 2  iter :77 ]train loss : 0.122500 ,train acc: 0.968709 ,val loss : 0.173895 ,val acc : 0.972931\n",
      "[ ecpho : 2  iter :78 ]train loss : 0.093661 ,train acc: 0.975046 ,val loss : 0.170093 ,val acc : 0.975250\n",
      "[ ecpho : 2  iter :79 ]train loss : 0.052232 ,train acc: 0.989522 ,val loss : 0.176027 ,val acc : 0.974976\n",
      "[ ecpho : 2  iter :80 ]train loss : 0.090702 ,train acc: 0.988759 ,val loss : 0.178001 ,val acc : 0.976227\n",
      "[ ecpho : 2  iter :81 ]train loss : 0.125900 ,train acc: 0.983205 ,val loss : 0.173254 ,val acc : 0.976410\n",
      "[ ecpho : 2  iter :82 ]train loss : 0.100943 ,train acc: 0.981659 ,val loss : 0.172480 ,val acc : 0.976318\n",
      "[ ecpho : 2  iter :83 ]train loss : 0.122882 ,train acc: 0.982737 ,val loss : 0.168316 ,val acc : 0.975983\n",
      "[ ecpho : 2  iter :84 ]train loss : 0.078095 ,train acc: 0.979573 ,val loss : 0.169346 ,val acc : 0.975861\n",
      "[ ecpho : 2  iter :85 ]train loss : 0.224026 ,train acc: 0.937886 ,val loss : 0.168900 ,val acc : 0.974823\n",
      "[ ecpho : 2  iter :86 ]train loss : 0.080391 ,train acc: 0.986663 ,val loss : 0.162705 ,val acc : 0.974518\n",
      "[ ecpho : 2  iter :87 ]train loss : 0.120702 ,train acc: 0.947001 ,val loss : 0.162482 ,val acc : 0.974762\n",
      "[ ecpho : 2  iter :88 ]train loss : 0.084271 ,train acc: 0.986236 ,val loss : 0.160448 ,val acc : 0.975311\n",
      "[ ecpho : 2  iter :89 ]train loss : 0.135178 ,train acc: 0.965810 ,val loss : 0.154334 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :90 ]train loss : 0.107674 ,train acc: 0.964904 ,val loss : 0.153443 ,val acc : 0.973206\n",
      "[ ecpho : 2  iter :91 ]train loss : 0.060411 ,train acc: 0.990315 ,val loss : 0.152695 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :92 ]train loss : 0.070386 ,train acc: 0.990295 ,val loss : 0.148153 ,val acc : 0.973663\n",
      "[ ecpho : 2  iter :93 ]train loss : 0.082935 ,train acc: 0.985321 ,val loss : 0.143402 ,val acc : 0.973969\n",
      "[ ecpho : 2  iter :94 ]train loss : 0.211376 ,train acc: 0.923543 ,val loss : 0.142628 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :95 ]train loss : 0.080396 ,train acc: 0.985626 ,val loss : 0.139161 ,val acc : 0.971832\n",
      "[ ecpho : 2  iter :96 ]train loss : 0.079767 ,train acc: 0.981516 ,val loss : 0.134359 ,val acc : 0.972473\n",
      "[ ecpho : 2  iter :97 ]train loss : 0.075412 ,train acc: 0.986002 ,val loss : 0.129512 ,val acc : 0.971985\n",
      "[ ecpho : 2  iter :98 ]train loss : 0.070424 ,train acc: 0.982940 ,val loss : 0.130133 ,val acc : 0.970367\n",
      "[ ecpho : 2  iter :99 ]train loss : 0.137363 ,train acc: 0.963175 ,val loss : 0.130390 ,val acc : 0.971344\n",
      "[ ecpho : 2  iter :100 ]train loss : 0.067985 ,train acc: 0.980509 ,val loss : 0.128456 ,val acc : 0.972992\n",
      "[ ecpho : 2  iter :101 ]train loss : 0.079569 ,train acc: 0.982432 ,val loss : 0.128118 ,val acc : 0.972534\n",
      "[ ecpho : 2  iter :102 ]train loss : 0.069937 ,train acc: 0.984751 ,val loss : 0.124803 ,val acc : 0.972992\n",
      "[ ecpho : 2  iter :103 ]train loss : 0.063086 ,train acc: 0.978088 ,val loss : 0.125241 ,val acc : 0.972015\n",
      "[ ecpho : 2  iter :104 ]train loss : 0.094116 ,train acc: 0.972198 ,val loss : 0.123150 ,val acc : 0.974487\n",
      "[ ecpho : 2  iter :105 ]train loss : 0.186423 ,train acc: 0.931691 ,val loss : 0.132656 ,val acc : 0.975037\n",
      "[ ecpho : 2  iter :106 ]train loss : 0.086659 ,train acc: 0.974070 ,val loss : 0.134105 ,val acc : 0.972931\n",
      "[ ecpho : 2  iter :107 ]train loss : 0.067907 ,train acc: 0.979187 ,val loss : 0.140895 ,val acc : 0.972778\n",
      "[ ecpho : 2  iter :108 ]train loss : 0.071409 ,train acc: 0.987345 ,val loss : 0.139638 ,val acc : 0.974304\n",
      "[ ecpho : 2  iter :109 ]train loss : 0.045005 ,train acc: 0.990844 ,val loss : 0.141567 ,val acc : 0.977478\n",
      "[ ecpho : 2  iter :110 ]train loss : 0.096593 ,train acc: 0.983581 ,val loss : 0.139769 ,val acc : 0.977936\n",
      "[ ecpho : 2  iter :111 ]train loss : 0.150152 ,train acc: 0.959483 ,val loss : 0.135214 ,val acc : 0.978058\n",
      "[ ecpho : 2  iter :112 ]train loss : 0.182054 ,train acc: 0.930064 ,val loss : 0.132124 ,val acc : 0.977783\n",
      "[ ecpho : 2  iter :113 ]train loss : 0.082107 ,train acc: 0.990559 ,val loss : 0.131145 ,val acc : 0.976410\n",
      "[ ecpho : 2  iter :114 ]train loss : 0.083144 ,train acc: 0.975077 ,val loss : 0.130802 ,val acc : 0.976349\n",
      "[ ecpho : 2  iter :115 ]train loss : 0.092399 ,train acc: 0.973256 ,val loss : 0.132289 ,val acc : 0.976868\n",
      "[ ecpho : 2  iter :116 ]train loss : 0.190933 ,train acc: 0.923350 ,val loss : 0.133668 ,val acc : 0.977142\n",
      "[ ecpho : 2  iter :117 ]train loss : 0.083197 ,train acc: 0.984293 ,val loss : 0.140117 ,val acc : 0.975586\n",
      "[ ecpho : 2  iter :118 ]train loss : 0.128898 ,train acc: 0.948517 ,val loss : 0.138402 ,val acc : 0.976898\n",
      "[ ecpho : 2  iter :119 ]train loss : 0.093388 ,train acc: 0.966766 ,val loss : 0.142745 ,val acc : 0.973969\n",
      "[ ecpho : 2  iter :120 ]train loss : 0.057734 ,train acc: 0.985789 ,val loss : 0.141293 ,val acc : 0.973694\n",
      "[ ecpho : 2  iter :121 ]train loss : 0.130516 ,train acc: 0.973765 ,val loss : 0.137514 ,val acc : 0.974091\n",
      "[ ecpho : 2  iter :122 ]train loss : 0.135264 ,train acc: 0.957031 ,val loss : 0.135867 ,val acc : 0.974792\n",
      "[ ecpho : 2  iter :123 ]train loss : 0.110938 ,train acc: 0.962321 ,val loss : 0.133986 ,val acc : 0.973450\n",
      "[ ecpho : 2  iter :124 ]train loss : 0.054513 ,train acc: 0.989084 ,val loss : 0.131044 ,val acc : 0.973419\n",
      "[ ecpho : 2  iter :125 ]train loss : 0.128673 ,train acc: 0.965393 ,val loss : 0.126147 ,val acc : 0.974091\n",
      "[ ecpho : 2  iter :126 ]train loss : 0.053609 ,train acc: 0.993520 ,val loss : 0.124448 ,val acc : 0.973236\n",
      "[ ecpho : 2  iter :127 ]train loss : 0.056123 ,train acc: 0.985005 ,val loss : 0.123336 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :128 ]train loss : 0.158017 ,train acc: 0.943247 ,val loss : 0.131884 ,val acc : 0.972382\n",
      "[ ecpho : 2  iter :129 ]train loss : 0.070225 ,train acc: 0.988352 ,val loss : 0.131651 ,val acc : 0.971802\n",
      "[ ecpho : 2  iter :130 ]train loss : 0.104648 ,train acc: 0.963501 ,val loss : 0.132353 ,val acc : 0.973389\n",
      "[ ecpho : 2  iter :131 ]train loss : 0.049886 ,train acc: 0.991973 ,val loss : 0.132164 ,val acc : 0.974213\n",
      "[ ecpho : 2  iter :132 ]train loss : 0.083625 ,train acc: 0.982198 ,val loss : 0.128847 ,val acc : 0.974487\n",
      "[ ecpho : 2  iter :133 ]train loss : 0.089346 ,train acc: 0.982360 ,val loss : 0.126859 ,val acc : 0.975372\n",
      "[ ecpho : 2  iter :134 ]train loss : 0.107628 ,train acc: 0.969340 ,val loss : 0.125066 ,val acc : 0.975128\n",
      "[ ecpho : 2  iter :135 ]train loss : 0.084587 ,train acc: 0.985127 ,val loss : 0.122496 ,val acc : 0.975342\n",
      "[ ecpho : 2  iter :136 ]train loss : 0.104980 ,train acc: 0.967336 ,val loss : 0.121496 ,val acc : 0.975555\n",
      "[ ecpho : 2  iter :137 ]train loss : 0.093071 ,train acc: 0.974202 ,val loss : 0.122379 ,val acc : 0.974152\n",
      "[ ecpho : 2  iter :138 ]train loss : 0.103216 ,train acc: 0.966044 ,val loss : 0.118945 ,val acc : 0.974457\n",
      "[ ecpho : 2  iter :139 ]train loss : 0.061627 ,train acc: 0.986959 ,val loss : 0.120056 ,val acc : 0.974579\n",
      "[ ecpho : 2  iter :140 ]train loss : 0.064377 ,train acc: 0.985575 ,val loss : 0.118149 ,val acc : 0.975769\n",
      "[ ecpho : 2  iter :141 ]train loss : 0.082398 ,train acc: 0.984039 ,val loss : 0.119268 ,val acc : 0.974548\n",
      "[ ecpho : 2  iter :142 ]train loss : 0.051580 ,train acc: 0.996348 ,val loss : 0.118958 ,val acc : 0.975830\n",
      "[ ecpho : 2  iter :143 ]train loss : 0.488038 ,train acc: 0.833384 ,val loss : 0.142545 ,val acc : 0.975677\n",
      "[ ecpho : 2  iter :144 ]train loss : 0.058162 ,train acc: 0.987742 ,val loss : 0.153760 ,val acc : 0.973999\n",
      "[ ecpho : 2  iter :145 ]train loss : 0.094991 ,train acc: 0.988749 ,val loss : 0.162760 ,val acc : 0.976257\n",
      "[ ecpho : 2  iter :146 ]train loss : 0.126603 ,train acc: 0.960011 ,val loss : 0.170281 ,val acc : 0.975250\n",
      "[ ecpho : 2  iter :147 ]train loss : 0.065475 ,train acc: 0.992614 ,val loss : 0.177734 ,val acc : 0.975983\n",
      "[ ecpho : 2  iter :148 ]train loss : 0.068624 ,train acc: 0.981832 ,val loss : 0.174080 ,val acc : 0.976227\n",
      "[ ecpho : 2  iter :149 ]train loss : 0.166054 ,train acc: 0.933360 ,val loss : 0.176082 ,val acc : 0.976044\n",
      "[ ecpho : 2  iter :150 ]train loss : 0.362431 ,train acc: 0.795939 ,val loss : 0.178508 ,val acc : 0.972504\n",
      "[ ecpho : 2  iter :151 ]train loss : 0.126501 ,train acc: 0.978902 ,val loss : 0.177085 ,val acc : 0.971893\n",
      "[ ecpho : 2  iter :152 ]train loss : 0.169713 ,train acc: 0.923919 ,val loss : 0.174006 ,val acc : 0.974457\n",
      "[ ecpho : 2  iter :153 ]train loss : 0.123306 ,train acc: 0.976755 ,val loss : 0.175258 ,val acc : 0.972107\n",
      "[ ecpho : 2  iter :154 ]train loss : 0.168451 ,train acc: 0.926768 ,val loss : 0.171985 ,val acc : 0.969879\n",
      "[ ecpho : 2  iter :155 ]train loss : 0.066388 ,train acc: 0.983581 ,val loss : 0.172440 ,val acc : 0.971985\n",
      "[ ecpho : 2  iter :156 ]train loss : 0.206274 ,train acc: 0.951792 ,val loss : 0.171199 ,val acc : 0.972717\n",
      "[ ecpho : 2  iter :157 ]train loss : 0.075423 ,train acc: 0.984893 ,val loss : 0.172735 ,val acc : 0.972931\n",
      "[ ecpho : 2  iter :158 ]train loss : 0.159772 ,train acc: 0.926717 ,val loss : 0.168546 ,val acc : 0.974457\n",
      "[ ecpho : 2  iter :159 ]train loss : 0.156572 ,train acc: 0.926686 ,val loss : 0.168378 ,val acc : 0.974335\n",
      "[ ecpho : 2  iter :160 ]train loss : 0.186424 ,train acc: 0.937988 ,val loss : 0.164058 ,val acc : 0.974274\n",
      "[ ecpho : 2  iter :161 ]train loss : 0.074820 ,train acc: 0.993978 ,val loss : 0.165389 ,val acc : 0.973175\n",
      "[ ecpho : 2  iter :162 ]train loss : 0.064218 ,train acc: 0.992574 ,val loss : 0.162448 ,val acc : 0.971985\n",
      "[ ecpho : 2  iter :163 ]train loss : 0.138949 ,train acc: 0.957987 ,val loss : 0.158630 ,val acc : 0.971985\n",
      "[ ecpho : 2  iter :164 ]train loss : 0.252121 ,train acc: 0.893839 ,val loss : 0.163122 ,val acc : 0.970367\n",
      "[ ecpho : 2  iter :165 ]train loss : 0.073629 ,train acc: 0.989237 ,val loss : 0.158058 ,val acc : 0.970154\n",
      "[ ecpho : 2  iter :166 ]train loss : 0.063908 ,train acc: 0.987538 ,val loss : 0.153729 ,val acc : 0.970337\n",
      "[ ecpho : 2  iter :167 ]train loss : 0.111368 ,train acc: 0.959483 ,val loss : 0.154379 ,val acc : 0.969818\n",
      "[ ecpho : 2  iter :168 ]train loss : 0.056317 ,train acc: 0.993184 ,val loss : 0.153024 ,val acc : 0.968933\n",
      "[ ecpho : 2  iter :169 ]train loss : 0.107538 ,train acc: 0.970052 ,val loss : 0.150010 ,val acc : 0.968811\n",
      "[ ecpho : 2  iter :170 ]train loss : 0.205204 ,train acc: 0.907928 ,val loss : 0.151925 ,val acc : 0.966095\n",
      "[ ecpho : 2  iter :171 ]train loss : 0.055417 ,train acc: 0.985361 ,val loss : 0.149674 ,val acc : 0.968658\n",
      "[ ecpho : 2  iter :172 ]train loss : 0.060557 ,train acc: 0.980774 ,val loss : 0.147752 ,val acc : 0.969971\n",
      "[ ecpho : 2  iter :173 ]train loss : 0.137101 ,train acc: 0.942515 ,val loss : 0.148962 ,val acc : 0.970581\n",
      "[ ecpho : 2  iter :174 ]train loss : 0.128520 ,train acc: 0.949717 ,val loss : 0.154363 ,val acc : 0.961761\n",
      "[ ecpho : 2  iter :175 ]train loss : 0.148513 ,train acc: 0.950938 ,val loss : 0.151153 ,val acc : 0.962494\n",
      "[ ecpho : 2  iter :176 ]train loss : 0.185374 ,train acc: 0.910441 ,val loss : 0.155555 ,val acc : 0.959045\n",
      "[ ecpho : 2  iter :177 ]train loss : 0.356084 ,train acc: 0.774312 ,val loss : 0.200740 ,val acc : 0.925354\n",
      "[ ecpho : 2  iter :178 ]train loss : 0.105179 ,train acc: 0.950053 ,val loss : 0.162119 ,val acc : 0.974640\n",
      "[ ecpho : 2  iter :179 ]train loss : 0.097805 ,train acc: 0.973429 ,val loss : 0.170169 ,val acc : 0.976349\n",
      "[ ecpho : 2  iter :180 ]train loss : 0.073695 ,train acc: 0.985972 ,val loss : 0.166276 ,val acc : 0.977295\n",
      "[ ecpho : 2  iter :181 ]train loss : 0.111149 ,train acc: 0.957590 ,val loss : 0.166453 ,val acc : 0.976562\n",
      "[ ecpho : 2  iter :182 ]train loss : 0.072245 ,train acc: 0.981272 ,val loss : 0.169367 ,val acc : 0.976776\n",
      "[ ecpho : 2  iter :183 ]train loss : 0.193273 ,train acc: 0.929860 ,val loss : 0.165090 ,val acc : 0.977173\n",
      "[ ecpho : 2  iter :184 ]train loss : 0.095744 ,train acc: 0.977152 ,val loss : 0.169818 ,val acc : 0.977234\n",
      "[ ecpho : 2  iter :185 ]train loss : 0.089151 ,train acc: 0.995534 ,val loss : 0.171367 ,val acc : 0.977112\n",
      "[ ecpho : 2  iter :186 ]train loss : 0.183352 ,train acc: 0.951467 ,val loss : 0.167680 ,val acc : 0.974609\n",
      "[ ecpho : 2  iter :187 ]train loss : 0.073607 ,train acc: 0.987335 ,val loss : 0.170994 ,val acc : 0.973572\n",
      "[ ecpho : 2  iter :188 ]train loss : 0.200792 ,train acc: 0.904348 ,val loss : 0.168789 ,val acc : 0.971985\n",
      "[ ecpho : 2  iter :189 ]train loss : 0.177132 ,train acc: 0.956522 ,val loss : 0.168341 ,val acc : 0.969727\n",
      "[ ecpho : 2  iter :190 ]train loss : 0.073058 ,train acc: 0.981781 ,val loss : 0.167766 ,val acc : 0.968872\n",
      "[ ecpho : 2  iter :191 ]train loss : 0.092814 ,train acc: 0.982584 ,val loss : 0.162937 ,val acc : 0.971863\n",
      "[ ecpho : 2  iter :192 ]train loss : 0.183425 ,train acc: 0.908254 ,val loss : 0.162801 ,val acc : 0.969360\n",
      "[ ecpho : 2  iter :193 ]train loss : 0.076189 ,train acc: 0.982594 ,val loss : 0.159674 ,val acc : 0.969971\n",
      "[ ecpho : 2  iter :194 ]train loss : 0.148530 ,train acc: 0.951457 ,val loss : 0.157650 ,val acc : 0.968872\n",
      "[ ecpho : 2  iter :195 ]train loss : 0.096819 ,train acc: 0.965667 ,val loss : 0.158664 ,val acc : 0.971832\n",
      "[ ecpho : 2  iter :196 ]train loss : 0.095887 ,train acc: 0.984202 ,val loss : 0.154476 ,val acc : 0.972168\n",
      "[ ecpho : 2  iter :197 ]train loss : 0.057483 ,train acc: 0.989644 ,val loss : 0.148742 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :198 ]train loss : 0.082146 ,train acc: 0.984029 ,val loss : 0.146074 ,val acc : 0.973816\n",
      "[ ecpho : 2  iter :199 ]train loss : 0.060364 ,train acc: 0.984741 ,val loss : 0.143627 ,val acc : 0.973846\n",
      "[ ecpho : 2  iter :200 ]train loss : 0.211780 ,train acc: 0.906952 ,val loss : 0.147892 ,val acc : 0.974396\n",
      "[ ecpho : 2  iter :201 ]train loss : 0.129582 ,train acc: 0.953552 ,val loss : 0.151246 ,val acc : 0.974274\n",
      "[ ecpho : 2  iter :202 ]train loss : 0.050442 ,train acc: 0.995107 ,val loss : 0.152932 ,val acc : 0.975830\n",
      "[ ecpho : 2  iter :203 ]train loss : 0.127631 ,train acc: 0.969208 ,val loss : 0.153450 ,val acc : 0.975250\n",
      "[ ecpho : 2  iter :204 ]train loss : 0.070944 ,train acc: 0.989939 ,val loss : 0.151666 ,val acc : 0.975098\n",
      "[ ecpho : 2  iter :205 ]train loss : 0.081685 ,train acc: 0.983632 ,val loss : 0.150251 ,val acc : 0.976196\n",
      "[ ecpho : 2  iter :206 ]train loss : 0.212168 ,train acc: 0.927459 ,val loss : 0.146958 ,val acc : 0.975616\n",
      "[ ecpho : 2  iter :207 ]train loss : 0.055343 ,train acc: 0.994700 ,val loss : 0.142261 ,val acc : 0.975403\n",
      "[ ecpho : 2  iter :208 ]train loss : 0.062255 ,train acc: 0.990153 ,val loss : 0.141604 ,val acc : 0.975861\n",
      "[ ecpho : 2  iter :209 ]train loss : 0.070683 ,train acc: 0.984731 ,val loss : 0.139598 ,val acc : 0.975128\n",
      "[ ecpho : 2  iter :210 ]train loss : 0.072851 ,train acc: 0.991821 ,val loss : 0.132970 ,val acc : 0.975281\n",
      "[ ecpho : 2  iter :211 ]train loss : 0.081538 ,train acc: 0.984049 ,val loss : 0.131039 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :212 ]train loss : 0.069818 ,train acc: 0.983886 ,val loss : 0.125478 ,val acc : 0.974884\n",
      "[ ecpho : 2  iter :213 ]train loss : 0.154852 ,train acc: 0.944265 ,val loss : 0.126789 ,val acc : 0.974426\n",
      "[ ecpho : 2  iter :214 ]train loss : 0.184382 ,train acc: 0.931050 ,val loss : 0.128543 ,val acc : 0.974091\n",
      "[ ecpho : 2  iter :215 ]train loss : 0.076683 ,train acc: 0.983205 ,val loss : 0.129181 ,val acc : 0.974213\n",
      "[ ecpho : 2  iter :216 ]train loss : 0.089219 ,train acc: 0.970184 ,val loss : 0.132150 ,val acc : 0.971924\n",
      "[ ecpho : 2  iter :217 ]train loss : 0.063792 ,train acc: 0.982086 ,val loss : 0.134010 ,val acc : 0.969757\n",
      "[ ecpho : 2  iter :218 ]train loss : 0.098819 ,train acc: 0.964121 ,val loss : 0.134036 ,val acc : 0.968689\n",
      "[ ecpho : 2  iter :219 ]train loss : 0.084997 ,train acc: 0.975982 ,val loss : 0.135602 ,val acc : 0.970154\n",
      "[ ecpho : 2  iter :220 ]train loss : 0.198121 ,train acc: 0.923380 ,val loss : 0.138208 ,val acc : 0.966248\n",
      "[ ecpho : 2  iter :221 ]train loss : 0.076555 ,train acc: 0.985656 ,val loss : 0.135710 ,val acc : 0.969238\n",
      "[ ecpho : 2  iter :222 ]train loss : 0.081140 ,train acc: 0.987681 ,val loss : 0.132566 ,val acc : 0.970917\n",
      "[ ecpho : 2  iter :223 ]train loss : 0.145096 ,train acc: 0.942210 ,val loss : 0.130121 ,val acc : 0.971802\n",
      "[ ecpho : 2  iter :224 ]train loss : 0.066215 ,train acc: 0.984008 ,val loss : 0.127010 ,val acc : 0.972443\n",
      "[ ecpho : 2  iter :225 ]train loss : 0.141393 ,train acc: 0.955973 ,val loss : 0.124193 ,val acc : 0.972473\n",
      "[ ecpho : 2  iter :226 ]train loss : 0.108376 ,train acc: 0.972117 ,val loss : 0.121706 ,val acc : 0.973206\n",
      "[ ecpho : 2  iter :227 ]train loss : 0.143573 ,train acc: 0.948171 ,val loss : 0.123376 ,val acc : 0.972046\n",
      "[ ecpho : 2  iter :228 ]train loss : 0.109185 ,train acc: 0.968546 ,val loss : 0.122349 ,val acc : 0.973022\n",
      "[ ecpho : 2  iter :229 ]train loss : 0.067841 ,train acc: 0.986826 ,val loss : 0.121405 ,val acc : 0.972656\n",
      "[ ecpho : 2  iter :230 ]train loss : 0.101500 ,train acc: 0.971628 ,val loss : 0.121271 ,val acc : 0.973175\n",
      "[ ecpho : 2  iter :231 ]train loss : 0.053645 ,train acc: 0.993510 ,val loss : 0.119204 ,val acc : 0.974731\n",
      "[ ecpho : 2  iter :232 ]train loss : 0.051757 ,train acc: 0.992706 ,val loss : 0.119268 ,val acc : 0.972809\n",
      "[ ecpho : 2  iter :233 ]train loss : 0.119127 ,train acc: 0.955719 ,val loss : 0.117431 ,val acc : 0.974609\n",
      "[ ecpho : 2  iter :234 ]train loss : 0.112694 ,train acc: 0.962697 ,val loss : 0.121554 ,val acc : 0.973969\n",
      "[ ecpho : 2  iter :235 ]train loss : 0.172874 ,train acc: 0.935313 ,val loss : 0.124679 ,val acc : 0.971252\n",
      "[ ecpho : 2  iter :236 ]train loss : 0.216415 ,train acc: 0.924835 ,val loss : 0.138375 ,val acc : 0.969788\n",
      "[ ecpho : 2  iter :237 ]train loss : 0.153000 ,train acc: 0.938049 ,val loss : 0.145960 ,val acc : 0.966400\n",
      "[ ecpho : 2  iter :238 ]train loss : 0.190365 ,train acc: 0.910583 ,val loss : 0.156722 ,val acc : 0.957916\n",
      "[ ecpho : 2  iter :239 ]train loss : 0.106541 ,train acc: 0.959940 ,val loss : 0.159803 ,val acc : 0.958771\n",
      "[ ecpho : 2  iter :240 ]train loss : 0.094734 ,train acc: 0.971639 ,val loss : 0.154444 ,val acc : 0.968567\n",
      "[ ecpho : 2  iter :241 ]train loss : 0.086008 ,train acc: 0.980194 ,val loss : 0.151685 ,val acc : 0.974091\n",
      "[ ecpho : 2  iter :242 ]train loss : 0.064147 ,train acc: 0.989756 ,val loss : 0.150846 ,val acc : 0.975952\n",
      "[ ecpho : 2  iter :243 ]train loss : 0.067877 ,train acc: 0.983205 ,val loss : 0.148221 ,val acc : 0.977264\n",
      "[ ecpho : 2  iter :244 ]train loss : 0.186517 ,train acc: 0.937235 ,val loss : 0.144141 ,val acc : 0.976501\n",
      "[ ecpho : 2  iter :245 ]train loss : 0.092989 ,train acc: 0.981333 ,val loss : 0.145535 ,val acc : 0.974945\n",
      "[ ecpho : 2  iter :246 ]train loss : 0.099721 ,train acc: 0.977508 ,val loss : 0.144671 ,val acc : 0.975525\n",
      "[ ecpho : 2  iter :247 ]train loss : 0.119235 ,train acc: 0.974355 ,val loss : 0.139114 ,val acc : 0.972992\n",
      "[ ecpho : 2  iter :248 ]train loss : 0.207052 ,train acc: 0.916432 ,val loss : 0.141504 ,val acc : 0.972504\n",
      "[ ecpho : 2  iter :249 ]train loss : 0.258390 ,train acc: 0.889689 ,val loss : 0.148297 ,val acc : 0.972290\n",
      "[ ecpho : 2  iter :250 ]train loss : 0.247058 ,train acc: 0.892863 ,val loss : 0.154688 ,val acc : 0.970825\n",
      "[ ecpho : 2  iter :251 ]train loss : 0.075892 ,train acc: 0.992594 ,val loss : 0.157739 ,val acc : 0.969574\n",
      "[ ecpho : 2  iter :252 ]train loss : 0.087917 ,train acc: 0.975240 ,val loss : 0.161157 ,val acc : 0.970093\n",
      "[ ecpho : 2  iter :253 ]train loss : 0.088473 ,train acc: 0.977823 ,val loss : 0.156798 ,val acc : 0.969666\n",
      "[ ecpho : 2  iter :254 ]train loss : 0.098984 ,train acc: 0.986480 ,val loss : 0.160693 ,val acc : 0.970642\n",
      "[ ecpho : 2  iter :255 ]train loss : 0.152764 ,train acc: 0.932800 ,val loss : 0.160653 ,val acc : 0.968658\n",
      "[ ecpho : 2  iter :256 ]train loss : 0.233285 ,train acc: 0.871785 ,val loss : 0.159765 ,val acc : 0.969147\n",
      "[ ecpho : 2  iter :257 ]train loss : 0.130399 ,train acc: 0.967234 ,val loss : 0.158308 ,val acc : 0.969757\n",
      "[ ecpho : 2  iter :258 ]train loss : 0.204991 ,train acc: 0.914917 ,val loss : 0.159073 ,val acc : 0.968811\n",
      "[ ecpho : 2  iter :259 ]train loss : 0.062719 ,train acc: 0.979543 ,val loss : 0.160076 ,val acc : 0.970123\n",
      "[ ecpho : 2  iter :260 ]train loss : 0.086134 ,train acc: 0.987070 ,val loss : 0.157725 ,val acc : 0.972321\n",
      "[ ecpho : 2  iter :261 ]train loss : 0.061048 ,train acc: 0.988891 ,val loss : 0.158699 ,val acc : 0.972748\n",
      "[ ecpho : 2  iter :262 ]train loss : 0.235505 ,train acc: 0.917358 ,val loss : 0.150750 ,val acc : 0.973480\n",
      "[ ecpho : 2  iter :263 ]train loss : 0.058985 ,train acc: 0.980489 ,val loss : 0.150042 ,val acc : 0.971710\n",
      "[ ecpho : 2  iter :264 ]train loss : 0.108460 ,train acc: 0.952230 ,val loss : 0.149931 ,val acc : 0.972198\n",
      "[ ecpho : 2  iter :265 ]train loss : 0.246405 ,train acc: 0.877604 ,val loss : 0.154136 ,val acc : 0.972412\n",
      "[ ecpho : 2  iter :266 ]train loss : 0.065166 ,train acc: 0.991343 ,val loss : 0.156183 ,val acc : 0.972351\n",
      "[ ecpho : 2  iter :267 ]train loss : 0.116332 ,train acc: 0.967621 ,val loss : 0.156998 ,val acc : 0.970398\n",
      "[ ecpho : 2  iter :268 ]train loss : 0.108372 ,train acc: 0.964630 ,val loss : 0.155497 ,val acc : 0.972229\n",
      "[ ecpho : 2  iter :269 ]train loss : 0.081413 ,train acc: 0.990875 ,val loss : 0.154338 ,val acc : 0.971588\n",
      "[ ecpho : 2  iter :270 ]train loss : 0.146519 ,train acc: 0.953511 ,val loss : 0.152315 ,val acc : 0.971313\n",
      "[ ecpho : 2  iter :271 ]train loss : 0.072994 ,train acc: 0.987823 ,val loss : 0.151432 ,val acc : 0.970062\n",
      "[ ecpho : 2  iter :272 ]train loss : 0.064530 ,train acc: 0.991658 ,val loss : 0.150596 ,val acc : 0.970612\n",
      "[ ecpho : 2  iter :273 ]train loss : 0.081261 ,train acc: 0.983795 ,val loss : 0.147043 ,val acc : 0.972443\n",
      "[ ecpho : 2  iter :274 ]train loss : 0.072164 ,train acc: 0.984273 ,val loss : 0.142765 ,val acc : 0.971893\n",
      "[ ecpho : 2  iter :275 ]train loss : 0.281549 ,train acc: 0.865214 ,val loss : 0.149442 ,val acc : 0.972473\n",
      "[ ecpho : 2  iter :276 ]train loss : 0.098305 ,train acc: 0.967529 ,val loss : 0.153327 ,val acc : 0.973083\n",
      "[ ecpho : 2  iter :277 ]train loss : 0.198851 ,train acc: 0.911153 ,val loss : 0.156870 ,val acc : 0.969543\n",
      "[ ecpho : 2  iter :278 ]train loss : 0.118791 ,train acc: 0.958923 ,val loss : 0.158452 ,val acc : 0.966827\n",
      "[ ecpho : 2  iter :279 ]train loss : 0.057839 ,train acc: 0.987589 ,val loss : 0.157204 ,val acc : 0.968597\n",
      "[ ecpho : 2  iter :280 ]train loss : 0.399543 ,train acc: 0.814311 ,val loss : 0.163260 ,val acc : 0.965393\n",
      "[ ecpho : 2  iter :281 ]train loss : 0.124581 ,train acc: 0.952799 ,val loss : 0.160611 ,val acc : 0.962799\n",
      "[ ecpho : 2  iter :282 ]train loss : 0.117653 ,train acc: 0.956746 ,val loss : 0.158162 ,val acc : 0.966034\n",
      "[ ecpho : 2  iter :283 ]train loss : 0.341471 ,train acc: 0.819783 ,val loss : 0.162650 ,val acc : 0.963776\n",
      "[ ecpho : 2  iter :284 ]train loss : 0.077380 ,train acc: 0.967529 ,val loss : 0.162325 ,val acc : 0.964752\n",
      "[ ecpho : 2  iter :285 ]train loss : 0.236150 ,train acc: 0.921122 ,val loss : 0.158805 ,val acc : 0.968536\n",
      "[ ecpho : 2  iter :286 ]train loss : 0.130230 ,train acc: 0.940795 ,val loss : 0.153361 ,val acc : 0.969604\n",
      "[ ecpho : 2  iter :287 ]train loss : 0.153614 ,train acc: 0.949808 ,val loss : 0.152516 ,val acc : 0.971497\n",
      "[ ecpho : 2  iter :288 ]train loss : 0.064519 ,train acc: 0.980295 ,val loss : 0.151244 ,val acc : 0.973694\n",
      "[ ecpho : 2  iter :289 ]train loss : 0.069489 ,train acc: 0.985544 ,val loss : 0.145821 ,val acc : 0.974640\n",
      "[ ecpho : 2  iter :290 ]train loss : 0.089372 ,train acc: 0.985382 ,val loss : 0.144203 ,val acc : 0.975922\n",
      "[ ecpho : 2  iter :291 ]train loss : 0.063129 ,train acc: 0.988820 ,val loss : 0.144090 ,val acc : 0.975006\n",
      "[ ecpho : 2  iter :292 ]train loss : 0.129850 ,train acc: 0.944081 ,val loss : 0.142978 ,val acc : 0.976044\n",
      "[ ecpho : 2  iter :293 ]train loss : 0.215838 ,train acc: 0.907745 ,val loss : 0.141548 ,val acc : 0.975769\n",
      "[ ecpho : 2  iter :294 ]train loss : 0.142266 ,train acc: 0.949412 ,val loss : 0.143297 ,val acc : 0.975616\n",
      "[ ecpho : 2  iter :295 ]train loss : 0.077566 ,train acc: 0.983886 ,val loss : 0.141181 ,val acc : 0.974518\n",
      "[ ecpho : 2  iter :296 ]train loss : 0.111774 ,train acc: 0.973043 ,val loss : 0.140585 ,val acc : 0.974976\n",
      "[ ecpho : 2  iter :297 ]train loss : 0.339473 ,train acc: 0.847605 ,val loss : 0.140179 ,val acc : 0.974731\n",
      "[ ecpho : 2  iter :298 ]train loss : 0.122822 ,train acc: 0.955902 ,val loss : 0.138852 ,val acc : 0.972992\n",
      "[ ecpho : 2  iter :299 ]train loss : 0.175007 ,train acc: 0.932637 ,val loss : 0.142194 ,val acc : 0.968567\n",
      "[ ecpho : 2  iter :300 ]train loss : 0.084726 ,train acc: 0.977305 ,val loss : 0.140014 ,val acc : 0.969391\n",
      "[ ecpho : 2  iter :301 ]train loss : 0.103800 ,train acc: 0.967051 ,val loss : 0.137414 ,val acc : 0.970032\n",
      "[ ecpho : 2  iter :302 ]train loss : 0.228211 ,train acc: 0.896749 ,val loss : 0.140137 ,val acc : 0.968475\n",
      "[ ecpho : 2  iter :303 ]train loss : 0.058934 ,train acc: 0.987335 ,val loss : 0.141607 ,val acc : 0.967682\n",
      "[ ecpho : 2  iter :304 ]train loss : 0.108433 ,train acc: 0.961090 ,val loss : 0.137661 ,val acc : 0.968567\n",
      "[ ecpho : 2  iter :305 ]train loss : 0.174003 ,train acc: 0.928334 ,val loss : 0.145105 ,val acc : 0.968262\n",
      "[ ecpho : 2  iter :306 ]train loss : 0.060960 ,train acc: 0.982737 ,val loss : 0.146203 ,val acc : 0.970825\n",
      "[ ecpho : 2  iter :307 ]train loss : 0.073253 ,train acc: 0.984120 ,val loss : 0.145122 ,val acc : 0.971313\n",
      "[ ecpho : 2  iter :308 ]train loss : 0.112968 ,train acc: 0.971974 ,val loss : 0.142819 ,val acc : 0.974182\n",
      "[ ecpho : 2  iter :309 ]train loss : 0.088915 ,train acc: 0.964671 ,val loss : 0.142687 ,val acc : 0.975220\n",
      "[ ecpho : 2  iter :310 ]train loss : 0.124377 ,train acc: 0.961487 ,val loss : 0.138373 ,val acc : 0.976135\n",
      "[ ecpho : 2  iter :311 ]train loss : 0.112506 ,train acc: 0.973795 ,val loss : 0.133606 ,val acc : 0.976318\n",
      "[ ecpho : 2  iter :312 ]train loss : 0.094223 ,train acc: 0.980204 ,val loss : 0.130547 ,val acc : 0.975494\n",
      "[ ecpho : 2  iter :313 ]train loss : 0.173451 ,train acc: 0.933319 ,val loss : 0.129240 ,val acc : 0.975159\n",
      "[ ecpho : 2  iter :314 ]train loss : 0.058425 ,train acc: 0.987406 ,val loss : 0.129791 ,val acc : 0.975861\n",
      "[ ecpho : 2  iter :315 ]train loss : 0.127830 ,train acc: 0.951080 ,val loss : 0.132332 ,val acc : 0.975952\n",
      "[ ecpho : 2  iter :316 ]train loss : 0.058771 ,train acc: 0.995096 ,val loss : 0.130428 ,val acc : 0.976044\n",
      "[ ecpho : 2  iter :317 ]train loss : 0.146696 ,train acc: 0.944793 ,val loss : 0.132934 ,val acc : 0.975677\n",
      "[ ecpho : 2  iter :318 ]train loss : 0.126875 ,train acc: 0.950958 ,val loss : 0.136010 ,val acc : 0.976837\n",
      "[ ecpho : 2  iter :319 ]train loss : 0.079436 ,train acc: 0.987467 ,val loss : 0.140581 ,val acc : 0.977020\n",
      "[ ecpho : 2  iter :320 ]train loss : 0.062987 ,train acc: 0.984090 ,val loss : 0.138858 ,val acc : 0.976990\n",
      "[ ecpho : 2  iter :321 ]train loss : 0.064893 ,train acc: 0.983510 ,val loss : 0.140526 ,val acc : 0.976746\n",
      "[ ecpho : 2  iter :322 ]train loss : 0.182526 ,train acc: 0.942962 ,val loss : 0.137197 ,val acc : 0.975616\n",
      "[ ecpho : 2  iter :323 ]train loss : 0.095174 ,train acc: 0.978709 ,val loss : 0.136464 ,val acc : 0.975403\n",
      "[ ecpho : 2  iter :324 ]train loss : 0.304878 ,train acc: 0.858032 ,val loss : 0.139249 ,val acc : 0.975555\n",
      "[ ecpho : 2  iter :325 ]train loss : 0.117730 ,train acc: 0.951263 ,val loss : 0.141994 ,val acc : 0.976105\n",
      "[ ecpho : 2  iter :326 ]train loss : 0.070621 ,train acc: 0.989278 ,val loss : 0.143581 ,val acc : 0.976288\n",
      "[ ecpho : 2  iter :327 ]train loss : 0.089716 ,train acc: 0.986684 ,val loss : 0.143440 ,val acc : 0.975220\n",
      "[ ecpho : 2  iter :328 ]train loss : 0.159147 ,train acc: 0.939880 ,val loss : 0.142435 ,val acc : 0.975800\n",
      "[ ecpho : 2  iter :329 ]train loss : 0.250413 ,train acc: 0.889007 ,val loss : 0.146487 ,val acc : 0.975220\n",
      "[ ecpho : 2  iter :330 ]train loss : 0.087131 ,train acc: 0.982615 ,val loss : 0.148680 ,val acc : 0.974762\n",
      "[ ecpho : 2  iter :331 ]train loss : 0.084471 ,train acc: 0.987681 ,val loss : 0.148758 ,val acc : 0.975677\n",
      "[ ecpho : 2  iter :332 ]train loss : 0.050149 ,train acc: 0.987111 ,val loss : 0.146336 ,val acc : 0.975830\n",
      "[ ecpho : 2  iter :333 ]train loss : 0.067615 ,train acc: 0.984324 ,val loss : 0.147873 ,val acc : 0.975922\n",
      "[ ecpho : 2  iter :334 ]train loss : 0.099817 ,train acc: 0.979431 ,val loss : 0.150553 ,val acc : 0.975830\n",
      "[ ecpho : 2  iter :335 ]train loss : 0.070245 ,train acc: 0.995198 ,val loss : 0.145528 ,val acc : 0.976990\n",
      "[ ecpho : 2  iter :336 ]train loss : 0.192556 ,train acc: 0.906412 ,val loss : 0.145774 ,val acc : 0.975250\n",
      "[ ecpho : 2  iter :337 ]train loss : 0.100146 ,train acc: 0.970571 ,val loss : 0.145586 ,val acc : 0.976074\n",
      "[ ecpho : 2  iter :338 ]train loss : 0.050610 ,train acc: 0.993927 ,val loss : 0.144361 ,val acc : 0.975739\n",
      "[ ecpho : 2  iter :339 ]train loss : 0.097026 ,train acc: 0.962667 ,val loss : 0.143957 ,val acc : 0.975647\n",
      "[ ecpho : 2  iter :340 ]train loss : 0.083339 ,train acc: 0.991353 ,val loss : 0.143941 ,val acc : 0.977020\n",
      "[ ecpho : 2  iter :341 ]train loss : 0.099264 ,train acc: 0.975565 ,val loss : 0.145380 ,val acc : 0.975494\n",
      "[ ecpho : 2  iter :342 ]train loss : 0.138312 ,train acc: 0.935150 ,val loss : 0.141051 ,val acc : 0.975708\n",
      "[ ecpho : 2  iter :343 ]train loss : 0.072306 ,train acc: 0.990844 ,val loss : 0.139305 ,val acc : 0.972534\n",
      "[ ecpho : 2  iter :344 ]train loss : 0.088940 ,train acc: 0.983866 ,val loss : 0.136826 ,val acc : 0.973785\n",
      "[ ecpho : 2  iter :345 ]train loss : 0.234532 ,train acc: 0.896423 ,val loss : 0.136082 ,val acc : 0.972351\n",
      "[ ecpho : 2  iter :346 ]train loss : 0.075229 ,train acc: 0.973805 ,val loss : 0.137759 ,val acc : 0.972900\n",
      "[ ecpho : 2  iter :347 ]train loss : 0.092459 ,train acc: 0.973785 ,val loss : 0.132711 ,val acc : 0.972961\n",
      "[ ecpho : 2  iter :348 ]train loss : 0.185915 ,train acc: 0.921122 ,val loss : 0.132453 ,val acc : 0.974335\n",
      "[ ecpho : 2  iter :349 ]train loss : 0.081510 ,train acc: 0.973378 ,val loss : 0.133991 ,val acc : 0.973480\n",
      "[ ecpho : 2  iter :350 ]train loss : 0.175869 ,train acc: 0.923106 ,val loss : 0.134745 ,val acc : 0.972656\n",
      "[ ecpho : 2  iter :351 ]train loss : 0.085205 ,train acc: 0.979136 ,val loss : 0.136604 ,val acc : 0.972321\n",
      "[ ecpho : 2  iter :352 ]train loss : 0.060765 ,train acc: 0.986084 ,val loss : 0.133541 ,val acc : 0.974609\n",
      "[ ecpho : 2  iter :353 ]train loss : 0.108735 ,train acc: 0.978281 ,val loss : 0.127474 ,val acc : 0.975189\n",
      "[ ecpho : 2  iter :354 ]train loss : 0.340761 ,train acc: 0.852498 ,val loss : 0.135360 ,val acc : 0.974731\n",
      "[ ecpho : 2  iter :355 ]train loss : 0.074725 ,train acc: 0.991444 ,val loss : 0.138742 ,val acc : 0.974426\n",
      "[ ecpho : 2  iter :356 ]train loss : 0.054915 ,train acc: 0.993662 ,val loss : 0.139779 ,val acc : 0.975616\n",
      "[ ecpho : 2  iter :357 ]train loss : 0.093815 ,train acc: 0.964589 ,val loss : 0.140644 ,val acc : 0.976379\n",
      "[ ecpho : 2  iter :358 ]train loss : 0.174964 ,train acc: 0.933919 ,val loss : 0.144137 ,val acc : 0.976532\n",
      "[ ecpho : 2  iter :359 ]train loss : 0.077138 ,train acc: 0.990519 ,val loss : 0.143546 ,val acc : 0.976532\n",
      "[ ecpho : 2  iter :360 ]train loss : 0.076542 ,train acc: 0.991821 ,val loss : 0.142076 ,val acc : 0.977112\n",
      "[ ecpho : 2  iter :361 ]train loss : 0.050975 ,train acc: 0.993398 ,val loss : 0.145977 ,val acc : 0.975800\n",
      "[ ecpho : 2  iter :362 ]train loss : 0.080019 ,train acc: 0.984761 ,val loss : 0.144439 ,val acc : 0.976013\n",
      "[ ecpho : 2  iter :363 ]train loss : 0.045916 ,train acc: 0.993733 ,val loss : 0.141420 ,val acc : 0.976196\n",
      "[ ecpho : 2  iter :364 ]train loss : 0.081827 ,train acc: 0.990315 ,val loss : 0.139148 ,val acc : 0.975677\n",
      "[ ecpho : 2  iter :365 ]train loss : 0.063038 ,train acc: 0.980051 ,val loss : 0.135319 ,val acc : 0.975830\n",
      "[ ecpho : 2  iter :366 ]train loss : 0.102765 ,train acc: 0.973775 ,val loss : 0.134080 ,val acc : 0.975800\n",
      "[ ecpho : 2  iter :367 ]train loss : 0.063570 ,train acc: 0.994059 ,val loss : 0.130729 ,val acc : 0.975372\n",
      "[ ecpho : 2  iter :368 ]train loss : 0.116192 ,train acc: 0.964965 ,val loss : 0.127674 ,val acc : 0.974609\n",
      "[ ecpho : 2  iter :369 ]train loss : 0.079549 ,train acc: 0.973765 ,val loss : 0.123703 ,val acc : 0.974945\n",
      "[ ecpho : 2  iter :370 ]train loss : 0.214564 ,train acc: 0.922923 ,val loss : 0.127612 ,val acc : 0.975006\n",
      "[ ecpho : 2  iter :371 ]train loss : 0.147675 ,train acc: 0.941314 ,val loss : 0.134020 ,val acc : 0.975403\n",
      "[ ecpho : 2  iter :372 ]train loss : 0.071488 ,train acc: 0.987040 ,val loss : 0.135489 ,val acc : 0.975861\n",
      "[ ecpho : 2  iter :373 ]train loss : 0.159845 ,train acc: 0.934713 ,val loss : 0.135300 ,val acc : 0.974243\n",
      "[ ecpho : 2  iter :374 ]train loss : 0.124584 ,train acc: 0.960103 ,val loss : 0.135740 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :375 ]train loss : 0.131587 ,train acc: 0.964243 ,val loss : 0.135385 ,val acc : 0.973938\n",
      "[ ecpho : 2  iter :376 ]train loss : 0.058104 ,train acc: 0.984436 ,val loss : 0.131710 ,val acc : 0.974365\n",
      "[ ecpho : 2  iter :377 ]train loss : 0.220363 ,train acc: 0.916076 ,val loss : 0.132654 ,val acc : 0.973694\n",
      "[ ecpho : 2  iter :378 ]train loss : 0.083321 ,train acc: 0.978403 ,val loss : 0.133088 ,val acc : 0.974609\n",
      "[ ecpho : 2  iter :379 ]train loss : 0.048803 ,train acc: 0.990580 ,val loss : 0.131716 ,val acc : 0.974457\n",
      "[ ecpho : 2  iter :380 ]train loss : 0.088128 ,train acc: 0.971659 ,val loss : 0.130850 ,val acc : 0.975739\n",
      "[ ecpho : 2  iter :381 ]train loss : 0.122924 ,train acc: 0.948791 ,val loss : 0.131484 ,val acc : 0.975464\n",
      "[ ecpho : 2  iter :382 ]train loss : 0.075446 ,train acc: 0.989888 ,val loss : 0.134624 ,val acc : 0.974762\n",
      "[ ecpho : 2  iter :383 ]train loss : 0.125066 ,train acc: 0.962077 ,val loss : 0.129269 ,val acc : 0.975525\n",
      "[ ecpho : 2  iter :384 ]train loss : 0.079468 ,train acc: 0.977600 ,val loss : 0.126585 ,val acc : 0.975189\n",
      "[ ecpho : 2  iter :385 ]train loss : 0.118410 ,train acc: 0.960805 ,val loss : 0.128250 ,val acc : 0.975525\n",
      "[ ecpho : 2  iter :386 ]train loss : 0.114118 ,train acc: 0.954732 ,val loss : 0.127115 ,val acc : 0.974854\n",
      "[ ecpho : 2  iter :387 ]train loss : 0.054517 ,train acc: 0.990366 ,val loss : 0.130235 ,val acc : 0.974243\n",
      "[ ecpho : 2  iter :388 ]train loss : 0.079527 ,train acc: 0.986755 ,val loss : 0.124830 ,val acc : 0.974152\n",
      "[ ecpho : 2  iter :389 ]train loss : 0.094525 ,train acc: 0.981872 ,val loss : 0.122874 ,val acc : 0.974335\n",
      "[ ecpho : 2  iter :390 ]train loss : 0.078115 ,train acc: 0.972188 ,val loss : 0.120814 ,val acc : 0.974518\n",
      "[ ecpho : 2  iter :391 ]train loss : 0.075401 ,train acc: 0.986236 ,val loss : 0.118902 ,val acc : 0.974121\n",
      "[ ecpho : 2  iter :392 ]train loss : 0.081408 ,train acc: 0.981404 ,val loss : 0.118847 ,val acc : 0.974396\n",
      "[ ecpho : 2  iter :393 ]train loss : 0.105081 ,train acc: 0.973856 ,val loss : 0.121271 ,val acc : 0.973724\n",
      "[ ecpho : 2  iter :394 ]train loss : 0.052905 ,train acc: 0.991465 ,val loss : 0.121784 ,val acc : 0.974243\n",
      "[ ecpho : 2  iter :395 ]train loss : 0.069373 ,train acc: 0.978393 ,val loss : 0.121012 ,val acc : 0.974548\n",
      "[ ecpho : 2  iter :396 ]train loss : 0.202442 ,train acc: 0.924031 ,val loss : 0.125213 ,val acc : 0.974792\n",
      "[ ecpho : 2  iter :397 ]train loss : 0.062569 ,train acc: 0.983734 ,val loss : 0.125520 ,val acc : 0.975006\n",
      "[ ecpho : 2  iter :398 ]train loss : 0.081098 ,train acc: 0.986582 ,val loss : 0.123927 ,val acc : 0.975006\n",
      "[ ecpho : 2  iter :399 ]train loss : 0.103881 ,train acc: 0.971069 ,val loss : 0.125367 ,val acc : 0.974457\n",
      "[ ecpho : 2  iter :400 ]train loss : 0.258453 ,train acc: 0.884867 ,val loss : 0.137893 ,val acc : 0.973907\n",
      "=============================================\n",
      "[ 2 ] average train loss : 0.117817 train acc : 0.962122\n",
      "[ ecpho : 3  iter :1 ]train loss : 0.059794 ,train acc: 0.992350 ,val loss : 0.146068 ,val acc : 0.973083\n",
      "[ ecpho : 3  iter :2 ]train loss : 0.062055 ,train acc: 0.990336 ,val loss : 0.145167 ,val acc : 0.973907\n",
      "[ ecpho : 3  iter :3 ]train loss : 0.246743 ,train acc: 0.866424 ,val loss : 0.153731 ,val acc : 0.973602\n",
      "[ ecpho : 3  iter :4 ]train loss : 0.090801 ,train acc: 0.974833 ,val loss : 0.157744 ,val acc : 0.971161\n",
      "[ ecpho : 3  iter :5 ]train loss : 0.071165 ,train acc: 0.981811 ,val loss : 0.156854 ,val acc : 0.972656\n",
      "[ ecpho : 3  iter :6 ]train loss : 0.051811 ,train acc: 0.981384 ,val loss : 0.156910 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :7 ]train loss : 0.070984 ,train acc: 0.983378 ,val loss : 0.159234 ,val acc : 0.977234\n",
      "[ ecpho : 3  iter :8 ]train loss : 0.078816 ,train acc: 0.991882 ,val loss : 0.156861 ,val acc : 0.977783\n",
      "[ ecpho : 3  iter :9 ]train loss : 0.193477 ,train acc: 0.925282 ,val loss : 0.156926 ,val acc : 0.977081\n",
      "[ ecpho : 3  iter :10 ]train loss : 0.409779 ,train acc: 0.794617 ,val loss : 0.158891 ,val acc : 0.977112\n",
      "[ ecpho : 3  iter :11 ]train loss : 0.038714 ,train acc: 0.993804 ,val loss : 0.157098 ,val acc : 0.977905\n",
      "[ ecpho : 3  iter :12 ]train loss : 0.104765 ,train acc: 0.984059 ,val loss : 0.156341 ,val acc : 0.977844\n",
      "[ ecpho : 3  iter :13 ]train loss : 0.132175 ,train acc: 0.978912 ,val loss : 0.156933 ,val acc : 0.976868\n",
      "[ ecpho : 3  iter :14 ]train loss : 0.092713 ,train acc: 0.992879 ,val loss : 0.155814 ,val acc : 0.977295\n",
      "[ ecpho : 3  iter :15 ]train loss : 0.094793 ,train acc: 0.986684 ,val loss : 0.152493 ,val acc : 0.976410\n",
      "[ ecpho : 3  iter :16 ]train loss : 0.120094 ,train acc: 0.948445 ,val loss : 0.149802 ,val acc : 0.977203\n",
      "[ ecpho : 3  iter :17 ]train loss : 0.065104 ,train acc: 0.991160 ,val loss : 0.148694 ,val acc : 0.976318\n",
      "[ ecpho : 3  iter :18 ]train loss : 0.079492 ,train acc: 0.991801 ,val loss : 0.150987 ,val acc : 0.975830\n",
      "[ ecpho : 3  iter :19 ]train loss : 0.151315 ,train acc: 0.942189 ,val loss : 0.145054 ,val acc : 0.975494\n",
      "[ ecpho : 3  iter :20 ]train loss : 0.133313 ,train acc: 0.944834 ,val loss : 0.146185 ,val acc : 0.975769\n",
      "[ ecpho : 3  iter :21 ]train loss : 0.068081 ,train acc: 0.985809 ,val loss : 0.146152 ,val acc : 0.975647\n",
      "[ ecpho : 3  iter :22 ]train loss : 0.066892 ,train acc: 0.994049 ,val loss : 0.142524 ,val acc : 0.975677\n",
      "[ ecpho : 3  iter :23 ]train loss : 0.071537 ,train acc: 0.994120 ,val loss : 0.139845 ,val acc : 0.976013\n",
      "[ ecpho : 3  iter :24 ]train loss : 0.047059 ,train acc: 0.996521 ,val loss : 0.139490 ,val acc : 0.975739\n",
      "[ ecpho : 3  iter :25 ]train loss : 0.087900 ,train acc: 0.974324 ,val loss : 0.137904 ,val acc : 0.976044\n",
      "[ ecpho : 3  iter :26 ]train loss : 0.353617 ,train acc: 0.827789 ,val loss : 0.141485 ,val acc : 0.976501\n",
      "[ ecpho : 3  iter :27 ]train loss : 0.102356 ,train acc: 0.960113 ,val loss : 0.146558 ,val acc : 0.975891\n",
      "[ ecpho : 3  iter :28 ]train loss : 0.086992 ,train acc: 0.968851 ,val loss : 0.147450 ,val acc : 0.977203\n",
      "[ ecpho : 3  iter :29 ]train loss : 0.134553 ,train acc: 0.945567 ,val loss : 0.152351 ,val acc : 0.976746\n",
      "[ ecpho : 3  iter :30 ]train loss : 0.056843 ,train acc: 0.987111 ,val loss : 0.150163 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :31 ]train loss : 0.095942 ,train acc: 0.989125 ,val loss : 0.151034 ,val acc : 0.976166\n",
      "[ ecpho : 3  iter :32 ]train loss : 0.205938 ,train acc: 0.928863 ,val loss : 0.148231 ,val acc : 0.976776\n",
      "[ ecpho : 3  iter :33 ]train loss : 0.098735 ,train acc: 0.983835 ,val loss : 0.145445 ,val acc : 0.975952\n",
      "[ ecpho : 3  iter :34 ]train loss : 0.175114 ,train acc: 0.934184 ,val loss : 0.148425 ,val acc : 0.976074\n",
      "[ ecpho : 3  iter :35 ]train loss : 0.067182 ,train acc: 0.992777 ,val loss : 0.146838 ,val acc : 0.974518\n",
      "[ ecpho : 3  iter :36 ]train loss : 0.061903 ,train acc: 0.988555 ,val loss : 0.142793 ,val acc : 0.976074\n",
      "[ ecpho : 3  iter :37 ]train loss : 0.167833 ,train acc: 0.920044 ,val loss : 0.146033 ,val acc : 0.975616\n",
      "[ ecpho : 3  iter :38 ]train loss : 0.077727 ,train acc: 0.974924 ,val loss : 0.147360 ,val acc : 0.975006\n",
      "[ ecpho : 3  iter :39 ]train loss : 0.137796 ,train acc: 0.957591 ,val loss : 0.143766 ,val acc : 0.976318\n",
      "[ ecpho : 3  iter :40 ]train loss : 0.091772 ,train acc: 0.980346 ,val loss : 0.144594 ,val acc : 0.975311\n",
      "[ ecpho : 3  iter :41 ]train loss : 0.075837 ,train acc: 0.985575 ,val loss : 0.143165 ,val acc : 0.975037\n",
      "[ ecpho : 3  iter :42 ]train loss : 0.077302 ,train acc: 0.989786 ,val loss : 0.140080 ,val acc : 0.974792\n",
      "[ ecpho : 3  iter :43 ]train loss : 0.058158 ,train acc: 0.994700 ,val loss : 0.138998 ,val acc : 0.974396\n",
      "[ ecpho : 3  iter :44 ]train loss : 0.057188 ,train acc: 0.989115 ,val loss : 0.136451 ,val acc : 0.974823\n",
      "[ ecpho : 3  iter :45 ]train loss : 0.288828 ,train acc: 0.900279 ,val loss : 0.134639 ,val acc : 0.974152\n",
      "[ ecpho : 3  iter :46 ]train loss : 0.083248 ,train acc: 0.986226 ,val loss : 0.130311 ,val acc : 0.972961\n",
      "[ ecpho : 3  iter :47 ]train loss : 0.047628 ,train acc: 0.985738 ,val loss : 0.131385 ,val acc : 0.973480\n",
      "[ ecpho : 3  iter :48 ]train loss : 0.161797 ,train acc: 0.936310 ,val loss : 0.131992 ,val acc : 0.974274\n",
      "[ ecpho : 3  iter :49 ]train loss : 0.066578 ,train acc: 0.981638 ,val loss : 0.129947 ,val acc : 0.974609\n",
      "[ ecpho : 3  iter :50 ]train loss : 0.070036 ,train acc: 0.982788 ,val loss : 0.128332 ,val acc : 0.976044\n",
      "[ ecpho : 3  iter :51 ]train loss : 0.062090 ,train acc: 0.988911 ,val loss : 0.127858 ,val acc : 0.977142\n",
      "[ ecpho : 3  iter :52 ]train loss : 0.059976 ,train acc: 0.989135 ,val loss : 0.128145 ,val acc : 0.976959\n",
      "[ ecpho : 3  iter :53 ]train loss : 0.065888 ,train acc: 0.987111 ,val loss : 0.127482 ,val acc : 0.977051\n",
      "[ ecpho : 3  iter :54 ]train loss : 0.056153 ,train acc: 0.992757 ,val loss : 0.124207 ,val acc : 0.976837\n",
      "[ ecpho : 3  iter :55 ]train loss : 0.061668 ,train acc: 0.991373 ,val loss : 0.123686 ,val acc : 0.976074\n",
      "[ ecpho : 3  iter :56 ]train loss : 0.069906 ,train acc: 0.988759 ,val loss : 0.122160 ,val acc : 0.976349\n",
      "[ ecpho : 3  iter :57 ]train loss : 0.062463 ,train acc: 0.987233 ,val loss : 0.120382 ,val acc : 0.977295\n",
      "[ ecpho : 3  iter :58 ]train loss : 0.048239 ,train acc: 0.990580 ,val loss : 0.119158 ,val acc : 0.977112\n",
      "[ ecpho : 3  iter :59 ]train loss : 0.086294 ,train acc: 0.973694 ,val loss : 0.120837 ,val acc : 0.976379\n",
      "[ ecpho : 3  iter :60 ]train loss : 0.061407 ,train acc: 0.985819 ,val loss : 0.119352 ,val acc : 0.976654\n",
      "[ ecpho : 3  iter :61 ]train loss : 0.057351 ,train acc: 0.989919 ,val loss : 0.118195 ,val acc : 0.976562\n",
      "[ ecpho : 3  iter :62 ]train loss : 0.117092 ,train acc: 0.949646 ,val loss : 0.119922 ,val acc : 0.976990\n",
      "[ ecpho : 3  iter :63 ]train loss : 0.084867 ,train acc: 0.980652 ,val loss : 0.121038 ,val acc : 0.977509\n",
      "[ ecpho : 3  iter :64 ]train loss : 0.084529 ,train acc: 0.985656 ,val loss : 0.119353 ,val acc : 0.976471\n",
      "[ ecpho : 3  iter :65 ]train loss : 0.061787 ,train acc: 0.981882 ,val loss : 0.119644 ,val acc : 0.976715\n",
      "[ ecpho : 3  iter :66 ]train loss : 0.058829 ,train acc: 0.984782 ,val loss : 0.117464 ,val acc : 0.976715\n",
      "[ ecpho : 3  iter :67 ]train loss : 0.065617 ,train acc: 0.990600 ,val loss : 0.119139 ,val acc : 0.975586\n",
      "[ ecpho : 3  iter :68 ]train loss : 0.049865 ,train acc: 0.991862 ,val loss : 0.118271 ,val acc : 0.976807\n",
      "[ ecpho : 3  iter :69 ]train loss : 0.402833 ,train acc: 0.846049 ,val loss : 0.127758 ,val acc : 0.976074\n",
      "[ ecpho : 3  iter :70 ]train loss : 0.222708 ,train acc: 0.906941 ,val loss : 0.135539 ,val acc : 0.976685\n",
      "[ ecpho : 3  iter :71 ]train loss : 0.193512 ,train acc: 0.912089 ,val loss : 0.142205 ,val acc : 0.976990\n",
      "[ ecpho : 3  iter :72 ]train loss : 0.102273 ,train acc: 0.971730 ,val loss : 0.147477 ,val acc : 0.975769\n",
      "[ ecpho : 3  iter :73 ]train loss : 0.243892 ,train acc: 0.894826 ,val loss : 0.151529 ,val acc : 0.973999\n",
      "[ ecpho : 3  iter :74 ]train loss : 0.120261 ,train acc: 0.978190 ,val loss : 0.154190 ,val acc : 0.973022\n",
      "[ ecpho : 3  iter :75 ]train loss : 0.174931 ,train acc: 0.897349 ,val loss : 0.156904 ,val acc : 0.968689\n",
      "[ ecpho : 3  iter :76 ]train loss : 0.099986 ,train acc: 0.974935 ,val loss : 0.157348 ,val acc : 0.968536\n",
      "[ ecpho : 3  iter :77 ]train loss : 0.255207 ,train acc: 0.869120 ,val loss : 0.158534 ,val acc : 0.963379\n",
      "[ ecpho : 3  iter :78 ]train loss : 0.175225 ,train acc: 0.934316 ,val loss : 0.158216 ,val acc : 0.960175\n",
      "[ ecpho : 3  iter :79 ]train loss : 0.073975 ,train acc: 0.976583 ,val loss : 0.153965 ,val acc : 0.970581\n",
      "[ ecpho : 3  iter :80 ]train loss : 0.163435 ,train acc: 0.939941 ,val loss : 0.151907 ,val acc : 0.973114\n",
      "[ ecpho : 3  iter :81 ]train loss : 0.119515 ,train acc: 0.952291 ,val loss : 0.152983 ,val acc : 0.973999\n",
      "[ ecpho : 3  iter :82 ]train loss : 0.058855 ,train acc: 0.984446 ,val loss : 0.148933 ,val acc : 0.975800\n",
      "[ ecpho : 3  iter :83 ]train loss : 0.108010 ,train acc: 0.954803 ,val loss : 0.150392 ,val acc : 0.976257\n",
      "[ ecpho : 3  iter :84 ]train loss : 0.165232 ,train acc: 0.968617 ,val loss : 0.149832 ,val acc : 0.975800\n",
      "[ ecpho : 3  iter :85 ]train loss : 0.040831 ,train acc: 0.994079 ,val loss : 0.145639 ,val acc : 0.975922\n",
      "[ ecpho : 3  iter :86 ]train loss : 0.062096 ,train acc: 0.995554 ,val loss : 0.144410 ,val acc : 0.975586\n",
      "[ ecpho : 3  iter :87 ]train loss : 0.049734 ,train acc: 0.996765 ,val loss : 0.143311 ,val acc : 0.975433\n",
      "[ ecpho : 3  iter :88 ]train loss : 0.165650 ,train acc: 0.937276 ,val loss : 0.142677 ,val acc : 0.975769\n",
      "[ ecpho : 3  iter :89 ]train loss : 0.401276 ,train acc: 0.792836 ,val loss : 0.145642 ,val acc : 0.975677\n",
      "[ ecpho : 3  iter :90 ]train loss : 0.107553 ,train acc: 0.982717 ,val loss : 0.147429 ,val acc : 0.976654\n",
      "[ ecpho : 3  iter :91 ]train loss : 0.074048 ,train acc: 0.991434 ,val loss : 0.151402 ,val acc : 0.975708\n",
      "[ ecpho : 3  iter :92 ]train loss : 0.093597 ,train acc: 0.984069 ,val loss : 0.146872 ,val acc : 0.976257\n",
      "[ ecpho : 3  iter :93 ]train loss : 0.107173 ,train acc: 0.978068 ,val loss : 0.146060 ,val acc : 0.975586\n",
      "[ ecpho : 3  iter :94 ]train loss : 0.136711 ,train acc: 0.947754 ,val loss : 0.147388 ,val acc : 0.975708\n",
      "[ ecpho : 3  iter :95 ]train loss : 0.126735 ,train acc: 0.954091 ,val loss : 0.144653 ,val acc : 0.976501\n",
      "[ ecpho : 3  iter :96 ]train loss : 0.134871 ,train acc: 0.959055 ,val loss : 0.147023 ,val acc : 0.976105\n",
      "[ ecpho : 3  iter :97 ]train loss : 0.124219 ,train acc: 0.966675 ,val loss : 0.145928 ,val acc : 0.975800\n",
      "[ ecpho : 3  iter :98 ]train loss : 0.071495 ,train acc: 0.989715 ,val loss : 0.142181 ,val acc : 0.975433\n",
      "[ ecpho : 3  iter :99 ]train loss : 0.112925 ,train acc: 0.958903 ,val loss : 0.140620 ,val acc : 0.975037\n",
      "[ ecpho : 3  iter :100 ]train loss : 0.188818 ,train acc: 0.931244 ,val loss : 0.134931 ,val acc : 0.975006\n",
      "[ ecpho : 3  iter :101 ]train loss : 0.170391 ,train acc: 0.926890 ,val loss : 0.139017 ,val acc : 0.974396\n",
      "[ ecpho : 3  iter :102 ]train loss : 0.127187 ,train acc: 0.961639 ,val loss : 0.138992 ,val acc : 0.972168\n",
      "[ ecpho : 3  iter :103 ]train loss : 0.107000 ,train acc: 0.974823 ,val loss : 0.136798 ,val acc : 0.973022\n",
      "[ ecpho : 3  iter :104 ]train loss : 0.214450 ,train acc: 0.902140 ,val loss : 0.136597 ,val acc : 0.971863\n",
      "[ ecpho : 3  iter :105 ]train loss : 0.054064 ,train acc: 0.989959 ,val loss : 0.136724 ,val acc : 0.971344\n",
      "[ ecpho : 3  iter :106 ]train loss : 0.143514 ,train acc: 0.938639 ,val loss : 0.136546 ,val acc : 0.969147\n",
      "[ ecpho : 3  iter :107 ]train loss : 0.086393 ,train acc: 0.983866 ,val loss : 0.139069 ,val acc : 0.967407\n",
      "[ ecpho : 3  iter :108 ]train loss : 0.068370 ,train acc: 0.981384 ,val loss : 0.136401 ,val acc : 0.969025\n",
      "[ ecpho : 3  iter :109 ]train loss : 0.173981 ,train acc: 0.935608 ,val loss : 0.134959 ,val acc : 0.968903\n",
      "[ ecpho : 3  iter :110 ]train loss : 0.064053 ,train acc: 0.981658 ,val loss : 0.132813 ,val acc : 0.968903\n",
      "[ ecpho : 3  iter :111 ]train loss : 0.095513 ,train acc: 0.967590 ,val loss : 0.132700 ,val acc : 0.969147\n",
      "[ ecpho : 3  iter :112 ]train loss : 0.067567 ,train acc: 0.976705 ,val loss : 0.130009 ,val acc : 0.972809\n",
      "[ ecpho : 3  iter :113 ]train loss : 0.181975 ,train acc: 0.935821 ,val loss : 0.128439 ,val acc : 0.972015\n",
      "[ ecpho : 3  iter :114 ]train loss : 0.090926 ,train acc: 0.968648 ,val loss : 0.124805 ,val acc : 0.974030\n",
      "[ ecpho : 3  iter :115 ]train loss : 0.051597 ,train acc: 0.985595 ,val loss : 0.126311 ,val acc : 0.974365\n",
      "[ ecpho : 3  iter :116 ]train loss : 0.075103 ,train acc: 0.984904 ,val loss : 0.125894 ,val acc : 0.975128\n",
      "[ ecpho : 3  iter :117 ]train loss : 0.059145 ,train acc: 0.991668 ,val loss : 0.127080 ,val acc : 0.975494\n",
      "[ ecpho : 3  iter :118 ]train loss : 0.140038 ,train acc: 0.951162 ,val loss : 0.126314 ,val acc : 0.975311\n",
      "[ ecpho : 3  iter :119 ]train loss : 0.061565 ,train acc: 0.983245 ,val loss : 0.129273 ,val acc : 0.975952\n",
      "[ ecpho : 3  iter :120 ]train loss : 0.107612 ,train acc: 0.961863 ,val loss : 0.127761 ,val acc : 0.975372\n",
      "[ ecpho : 3  iter :121 ]train loss : 0.097695 ,train acc: 0.973897 ,val loss : 0.124701 ,val acc : 0.975677\n",
      "[ ecpho : 3  iter :122 ]train loss : 0.058466 ,train acc: 0.987131 ,val loss : 0.126038 ,val acc : 0.975739\n",
      "[ ecpho : 3  iter :123 ]train loss : 0.174189 ,train acc: 0.937632 ,val loss : 0.125960 ,val acc : 0.976074\n",
      "[ ecpho : 3  iter :124 ]train loss : 0.113832 ,train acc: 0.955698 ,val loss : 0.130857 ,val acc : 0.974396\n",
      "[ ecpho : 3  iter :125 ]train loss : 0.128178 ,train acc: 0.950429 ,val loss : 0.136566 ,val acc : 0.970184\n",
      "[ ecpho : 3  iter :126 ]train loss : 0.086222 ,train acc: 0.976359 ,val loss : 0.140758 ,val acc : 0.967865\n",
      "[ ecpho : 3  iter :127 ]train loss : 0.107763 ,train acc: 0.972941 ,val loss : 0.137392 ,val acc : 0.970703\n",
      "[ ecpho : 3  iter :128 ]train loss : 0.063869 ,train acc: 0.973999 ,val loss : 0.134371 ,val acc : 0.973450\n",
      "[ ecpho : 3  iter :129 ]train loss : 0.151950 ,train acc: 0.951762 ,val loss : 0.133611 ,val acc : 0.974945\n",
      "[ ecpho : 3  iter :130 ]train loss : 0.129341 ,train acc: 0.944743 ,val loss : 0.133115 ,val acc : 0.974457\n",
      "[ ecpho : 3  iter :131 ]train loss : 0.116844 ,train acc: 0.974100 ,val loss : 0.131692 ,val acc : 0.974487\n",
      "[ ecpho : 3  iter :132 ]train loss : 0.109541 ,train acc: 0.971700 ,val loss : 0.129451 ,val acc : 0.973328\n",
      "[ ecpho : 3  iter :133 ]train loss : 0.042079 ,train acc: 0.995931 ,val loss : 0.130650 ,val acc : 0.972809\n",
      "[ ecpho : 3  iter :134 ]train loss : 0.078446 ,train acc: 0.980682 ,val loss : 0.125239 ,val acc : 0.971954\n",
      "[ ecpho : 3  iter :135 ]train loss : 0.059434 ,train acc: 0.988128 ,val loss : 0.124256 ,val acc : 0.973145\n",
      "[ ecpho : 3  iter :136 ]train loss : 0.072361 ,train acc: 0.984995 ,val loss : 0.124613 ,val acc : 0.972412\n",
      "[ ecpho : 3  iter :137 ]train loss : 0.068702 ,train acc: 0.987976 ,val loss : 0.124824 ,val acc : 0.972687\n",
      "[ ecpho : 3  iter :138 ]train loss : 0.059501 ,train acc: 0.981974 ,val loss : 0.123984 ,val acc : 0.972565\n",
      "[ ecpho : 3  iter :139 ]train loss : 0.087198 ,train acc: 0.972870 ,val loss : 0.123503 ,val acc : 0.972748\n",
      "[ ecpho : 3  iter :140 ]train loss : 0.058086 ,train acc: 0.993611 ,val loss : 0.124145 ,val acc : 0.973053\n",
      "[ ecpho : 3  iter :141 ]train loss : 0.084843 ,train acc: 0.971303 ,val loss : 0.123325 ,val acc : 0.972717\n",
      "[ ecpho : 3  iter :142 ]train loss : 0.063366 ,train acc: 0.987559 ,val loss : 0.122767 ,val acc : 0.973480\n",
      "[ ecpho : 3  iter :143 ]train loss : 0.121772 ,train acc: 0.951385 ,val loss : 0.122171 ,val acc : 0.972382\n",
      "[ ecpho : 3  iter :144 ]train loss : 0.056039 ,train acc: 0.993479 ,val loss : 0.121675 ,val acc : 0.972992\n",
      "[ ecpho : 3  iter :145 ]train loss : 0.066396 ,train acc: 0.982472 ,val loss : 0.119147 ,val acc : 0.974182\n",
      "[ ecpho : 3  iter :146 ]train loss : 0.063269 ,train acc: 0.990417 ,val loss : 0.117491 ,val acc : 0.974152\n",
      "[ ecpho : 3  iter :147 ]train loss : 0.053411 ,train acc: 0.994354 ,val loss : 0.117092 ,val acc : 0.974823\n",
      "[ ecpho : 3  iter :148 ]train loss : 0.434791 ,train acc: 0.806874 ,val loss : 0.126053 ,val acc : 0.975037\n",
      "[ ecpho : 3  iter :149 ]train loss : 0.059813 ,train acc: 0.991373 ,val loss : 0.132647 ,val acc : 0.975525\n",
      "[ ecpho : 3  iter :150 ]train loss : 0.076933 ,train acc: 0.988383 ,val loss : 0.135535 ,val acc : 0.975037\n",
      "[ ecpho : 3  iter :151 ]train loss : 0.053382 ,train acc: 0.982513 ,val loss : 0.135579 ,val acc : 0.975250\n",
      "[ ecpho : 3  iter :152 ]train loss : 0.083736 ,train acc: 0.988932 ,val loss : 0.138678 ,val acc : 0.975098\n",
      "[ ecpho : 3  iter :153 ]train loss : 0.079171 ,train acc: 0.970977 ,val loss : 0.132866 ,val acc : 0.976379\n",
      "[ ecpho : 3  iter :154 ]train loss : 0.097103 ,train acc: 0.980774 ,val loss : 0.131322 ,val acc : 0.976288\n",
      "[ ecpho : 3  iter :155 ]train loss : 0.047199 ,train acc: 0.993570 ,val loss : 0.127898 ,val acc : 0.976624\n",
      "[ ecpho : 3  iter :156 ]train loss : 0.076544 ,train acc: 0.980906 ,val loss : 0.130407 ,val acc : 0.975281\n",
      "[ ecpho : 3  iter :157 ]train loss : 0.080021 ,train acc: 0.983001 ,val loss : 0.129366 ,val acc : 0.975342\n",
      "[ ecpho : 3  iter :158 ]train loss : 0.043339 ,train acc: 0.991567 ,val loss : 0.125494 ,val acc : 0.976685\n",
      "[ ecpho : 3  iter :159 ]train loss : 0.071411 ,train acc: 0.986938 ,val loss : 0.125919 ,val acc : 0.975006\n",
      "[ ecpho : 3  iter :160 ]train loss : 0.260693 ,train acc: 0.904927 ,val loss : 0.133568 ,val acc : 0.976410\n",
      "[ ecpho : 3  iter :161 ]train loss : 0.053201 ,train acc: 0.994679 ,val loss : 0.135984 ,val acc : 0.976288\n",
      "[ ecpho : 3  iter :162 ]train loss : 0.076061 ,train acc: 0.987549 ,val loss : 0.137473 ,val acc : 0.976959\n",
      "[ ecpho : 3  iter :163 ]train loss : 0.080444 ,train acc: 0.975555 ,val loss : 0.138232 ,val acc : 0.976959\n",
      "[ ecpho : 3  iter :164 ]train loss : 0.118535 ,train acc: 0.961141 ,val loss : 0.139855 ,val acc : 0.976013\n",
      "[ ecpho : 3  iter :165 ]train loss : 0.079179 ,train acc: 0.973846 ,val loss : 0.139630 ,val acc : 0.976318\n",
      "[ ecpho : 3  iter :166 ]train loss : 0.114653 ,train acc: 0.952128 ,val loss : 0.139232 ,val acc : 0.976868\n",
      "[ ecpho : 3  iter :167 ]train loss : 0.072088 ,train acc: 0.977122 ,val loss : 0.142052 ,val acc : 0.977356\n",
      "[ ecpho : 3  iter :168 ]train loss : 0.157002 ,train acc: 0.941894 ,val loss : 0.145121 ,val acc : 0.977325\n",
      "[ ecpho : 3  iter :169 ]train loss : 0.054937 ,train acc: 0.991831 ,val loss : 0.140723 ,val acc : 0.977386\n",
      "[ ecpho : 3  iter :170 ]train loss : 0.099793 ,train acc: 0.963145 ,val loss : 0.143138 ,val acc : 0.977356\n",
      "[ ecpho : 3  iter :171 ]train loss : 0.079202 ,train acc: 0.991648 ,val loss : 0.142563 ,val acc : 0.977692\n",
      "[ ecpho : 3  iter :172 ]train loss : 0.114964 ,train acc: 0.981709 ,val loss : 0.142197 ,val acc : 0.977783\n",
      "[ ecpho : 3  iter :173 ]train loss : 0.071766 ,train acc: 0.987162 ,val loss : 0.141017 ,val acc : 0.977173\n",
      "[ ecpho : 3  iter :174 ]train loss : 0.080141 ,train acc: 0.986480 ,val loss : 0.137181 ,val acc : 0.977509\n",
      "[ ecpho : 3  iter :175 ]train loss : 0.123084 ,train acc: 0.956797 ,val loss : 0.137917 ,val acc : 0.976562\n",
      "[ ecpho : 3  iter :176 ]train loss : 0.101073 ,train acc: 0.964955 ,val loss : 0.137230 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :177 ]train loss : 0.089202 ,train acc: 0.978576 ,val loss : 0.136776 ,val acc : 0.975952\n",
      "[ ecpho : 3  iter :178 ]train loss : 0.223245 ,train acc: 0.925822 ,val loss : 0.136718 ,val acc : 0.976410\n",
      "[ ecpho : 3  iter :179 ]train loss : 0.106002 ,train acc: 0.963745 ,val loss : 0.138448 ,val acc : 0.976196\n",
      "[ ecpho : 3  iter :180 ]train loss : 0.126284 ,train acc: 0.964966 ,val loss : 0.135045 ,val acc : 0.975677\n",
      "[ ecpho : 3  iter :181 ]train loss : 0.154155 ,train acc: 0.940104 ,val loss : 0.136197 ,val acc : 0.974213\n",
      "[ ecpho : 3  iter :182 ]train loss : 0.117792 ,train acc: 0.951050 ,val loss : 0.137920 ,val acc : 0.975128\n",
      "[ ecpho : 3  iter :183 ]train loss : 0.190805 ,train acc: 0.925181 ,val loss : 0.135125 ,val acc : 0.973267\n",
      "[ ecpho : 3  iter :184 ]train loss : 0.084678 ,train acc: 0.977925 ,val loss : 0.135286 ,val acc : 0.971344\n",
      "[ ecpho : 3  iter :185 ]train loss : 0.153333 ,train acc: 0.943237 ,val loss : 0.134067 ,val acc : 0.971527\n",
      "[ ecpho : 3  iter :186 ]train loss : 0.114452 ,train acc: 0.953186 ,val loss : 0.136860 ,val acc : 0.970032\n",
      "[ ecpho : 3  iter :187 ]train loss : 0.090932 ,train acc: 0.967865 ,val loss : 0.134061 ,val acc : 0.971619\n",
      "[ ecpho : 3  iter :188 ]train loss : 0.095255 ,train acc: 0.962524 ,val loss : 0.131277 ,val acc : 0.970886\n",
      "[ ecpho : 3  iter :189 ]train loss : 0.083412 ,train acc: 0.982737 ,val loss : 0.126206 ,val acc : 0.972229\n",
      "[ ecpho : 3  iter :190 ]train loss : 0.229108 ,train acc: 0.909220 ,val loss : 0.132793 ,val acc : 0.969177\n",
      "[ ecpho : 3  iter :191 ]train loss : 0.072624 ,train acc: 0.986562 ,val loss : 0.136363 ,val acc : 0.967621\n",
      "[ ecpho : 3  iter :192 ]train loss : 0.117084 ,train acc: 0.947103 ,val loss : 0.139739 ,val acc : 0.966217\n",
      "[ ecpho : 3  iter :193 ]train loss : 0.068146 ,train acc: 0.983846 ,val loss : 0.135183 ,val acc : 0.969604\n",
      "[ ecpho : 3  iter :194 ]train loss : 0.080623 ,train acc: 0.979258 ,val loss : 0.133156 ,val acc : 0.972656\n",
      "[ ecpho : 3  iter :195 ]train loss : 0.088454 ,train acc: 0.977467 ,val loss : 0.132211 ,val acc : 0.974854\n",
      "[ ecpho : 3  iter :196 ]train loss : 0.096174 ,train acc: 0.967132 ,val loss : 0.130916 ,val acc : 0.975800\n",
      "[ ecpho : 3  iter :197 ]train loss : 0.214543 ,train acc: 0.906341 ,val loss : 0.136456 ,val acc : 0.974091\n",
      "[ ecpho : 3  iter :198 ]train loss : 0.078488 ,train acc: 0.987152 ,val loss : 0.139796 ,val acc : 0.975067\n",
      "[ ecpho : 3  iter :199 ]train loss : 0.145235 ,train acc: 0.964152 ,val loss : 0.140534 ,val acc : 0.974823\n",
      "[ ecpho : 3  iter :200 ]train loss : 0.125732 ,train acc: 0.950683 ,val loss : 0.141665 ,val acc : 0.974548\n",
      "[ ecpho : 3  iter :201 ]train loss : 0.071075 ,train acc: 0.982198 ,val loss : 0.144906 ,val acc : 0.973114\n",
      "[ ecpho : 3  iter :202 ]train loss : 0.079616 ,train acc: 0.981201 ,val loss : 0.139327 ,val acc : 0.974335\n",
      "[ ecpho : 3  iter :203 ]train loss : 0.075405 ,train acc: 0.978617 ,val loss : 0.136722 ,val acc : 0.974548\n",
      "[ ecpho : 3  iter :204 ]train loss : 0.050379 ,train acc: 0.986745 ,val loss : 0.137064 ,val acc : 0.975891\n",
      "[ ecpho : 3  iter :205 ]train loss : 0.119697 ,train acc: 0.958445 ,val loss : 0.137102 ,val acc : 0.975922\n",
      "[ ecpho : 3  iter :206 ]train loss : 0.186147 ,train acc: 0.912486 ,val loss : 0.137748 ,val acc : 0.975586\n",
      "[ ecpho : 3  iter :207 ]train loss : 0.050398 ,train acc: 0.989807 ,val loss : 0.138507 ,val acc : 0.975586\n",
      "[ ecpho : 3  iter :208 ]train loss : 0.128119 ,train acc: 0.957936 ,val loss : 0.138683 ,val acc : 0.975037\n",
      "[ ecpho : 3  iter :209 ]train loss : 0.077609 ,train acc: 0.980011 ,val loss : 0.139035 ,val acc : 0.974701\n",
      "[ ecpho : 3  iter :210 ]train loss : 0.048016 ,train acc: 0.992014 ,val loss : 0.139781 ,val acc : 0.974335\n",
      "[ ecpho : 3  iter :211 ]train loss : 0.103638 ,train acc: 0.972361 ,val loss : 0.136552 ,val acc : 0.975372\n",
      "[ ecpho : 3  iter :212 ]train loss : 0.077760 ,train acc: 0.983622 ,val loss : 0.135991 ,val acc : 0.974365\n",
      "[ ecpho : 3  iter :213 ]train loss : 0.160679 ,train acc: 0.934529 ,val loss : 0.135523 ,val acc : 0.973694\n",
      "[ ecpho : 3  iter :214 ]train loss : 0.064402 ,train acc: 0.989685 ,val loss : 0.132223 ,val acc : 0.974426\n",
      "[ ecpho : 3  iter :215 ]train loss : 0.123766 ,train acc: 0.956889 ,val loss : 0.134140 ,val acc : 0.973419\n",
      "[ ecpho : 3  iter :216 ]train loss : 0.100569 ,train acc: 0.963358 ,val loss : 0.131417 ,val acc : 0.972687\n",
      "[ ecpho : 3  iter :217 ]train loss : 0.052529 ,train acc: 0.988993 ,val loss : 0.129443 ,val acc : 0.973175\n",
      "[ ecpho : 3  iter :218 ]train loss : 0.086539 ,train acc: 0.974935 ,val loss : 0.131699 ,val acc : 0.972412\n",
      "[ ecpho : 3  iter :219 ]train loss : 0.139468 ,train acc: 0.950388 ,val loss : 0.129087 ,val acc : 0.972473\n",
      "[ ecpho : 3  iter :220 ]train loss : 0.067836 ,train acc: 0.986440 ,val loss : 0.129315 ,val acc : 0.972748\n",
      "[ ecpho : 3  iter :221 ]train loss : 0.173421 ,train acc: 0.936727 ,val loss : 0.129555 ,val acc : 0.973206\n",
      "[ ecpho : 3  iter :222 ]train loss : 0.049687 ,train acc: 0.993682 ,val loss : 0.126911 ,val acc : 0.972931\n",
      "[ ecpho : 3  iter :223 ]train loss : 0.197247 ,train acc: 0.919647 ,val loss : 0.127648 ,val acc : 0.973114\n",
      "[ ecpho : 3  iter :224 ]train loss : 0.063031 ,train acc: 0.986918 ,val loss : 0.127209 ,val acc : 0.972473\n",
      "[ ecpho : 3  iter :225 ]train loss : 0.196731 ,train acc: 0.912577 ,val loss : 0.130481 ,val acc : 0.969788\n",
      "[ ecpho : 3  iter :226 ]train loss : 0.214845 ,train acc: 0.918854 ,val loss : 0.131781 ,val acc : 0.967743\n",
      "[ ecpho : 3  iter :227 ]train loss : 0.063166 ,train acc: 0.986562 ,val loss : 0.131444 ,val acc : 0.968658\n",
      "[ ecpho : 3  iter :228 ]train loss : 0.155317 ,train acc: 0.942739 ,val loss : 0.135576 ,val acc : 0.966797\n",
      "[ ecpho : 3  iter :229 ]train loss : 0.076403 ,train acc: 0.973561 ,val loss : 0.133171 ,val acc : 0.967621\n",
      "[ ecpho : 3  iter :230 ]train loss : 0.148951 ,train acc: 0.948049 ,val loss : 0.130780 ,val acc : 0.969025\n",
      "[ ecpho : 3  iter :231 ]train loss : 0.096782 ,train acc: 0.976847 ,val loss : 0.125283 ,val acc : 0.971710\n",
      "[ ecpho : 3  iter :232 ]train loss : 0.080312 ,train acc: 0.979604 ,val loss : 0.125010 ,val acc : 0.970551\n",
      "[ ecpho : 3  iter :233 ]train loss : 0.052967 ,train acc: 0.989990 ,val loss : 0.122205 ,val acc : 0.971558\n",
      "[ ecpho : 3  iter :234 ]train loss : 0.134261 ,train acc: 0.954030 ,val loss : 0.125842 ,val acc : 0.969330\n",
      "[ ecpho : 3  iter :235 ]train loss : 0.096477 ,train acc: 0.972513 ,val loss : 0.124512 ,val acc : 0.971039\n",
      "[ ecpho : 3  iter :236 ]train loss : 0.072101 ,train acc: 0.983215 ,val loss : 0.121243 ,val acc : 0.971069\n",
      "[ ecpho : 3  iter :237 ]train loss : 0.112648 ,train acc: 0.962697 ,val loss : 0.123000 ,val acc : 0.971069\n",
      "[ ecpho : 3  iter :238 ]train loss : 0.131094 ,train acc: 0.949900 ,val loss : 0.125589 ,val acc : 0.972565\n",
      "[ ecpho : 3  iter :239 ]train loss : 0.117304 ,train acc: 0.952697 ,val loss : 0.126637 ,val acc : 0.972687\n",
      "[ ecpho : 3  iter :240 ]train loss : 0.110175 ,train acc: 0.963877 ,val loss : 0.127940 ,val acc : 0.973389\n",
      "[ ecpho : 3  iter :241 ]train loss : 0.058381 ,train acc: 0.980245 ,val loss : 0.125429 ,val acc : 0.973328\n",
      "[ ecpho : 3  iter :242 ]train loss : 0.074965 ,train acc: 0.977295 ,val loss : 0.125561 ,val acc : 0.974487\n",
      "[ ecpho : 3  iter :243 ]train loss : 0.041151 ,train acc: 0.994435 ,val loss : 0.125226 ,val acc : 0.975067\n",
      "[ ecpho : 3  iter :244 ]train loss : 0.061364 ,train acc: 0.987518 ,val loss : 0.123956 ,val acc : 0.975189\n",
      "[ ecpho : 3  iter :245 ]train loss : 0.054896 ,train acc: 0.994211 ,val loss : 0.122035 ,val acc : 0.976593\n",
      "[ ecpho : 3  iter :246 ]train loss : 0.162006 ,train acc: 0.938364 ,val loss : 0.122176 ,val acc : 0.975494\n",
      "[ ecpho : 3  iter :247 ]train loss : 0.182959 ,train acc: 0.942800 ,val loss : 0.123544 ,val acc : 0.974762\n",
      "[ ecpho : 3  iter :248 ]train loss : 0.101667 ,train acc: 0.974660 ,val loss : 0.124188 ,val acc : 0.974518\n",
      "[ ecpho : 3  iter :249 ]train loss : 0.056911 ,train acc: 0.981476 ,val loss : 0.119896 ,val acc : 0.976166\n",
      "[ ecpho : 3  iter :250 ]train loss : 0.141730 ,train acc: 0.946248 ,val loss : 0.118753 ,val acc : 0.974945\n",
      "[ ecpho : 3  iter :251 ]train loss : 0.055716 ,train acc: 0.991007 ,val loss : 0.117283 ,val acc : 0.976196\n",
      "[ ecpho : 3  iter :252 ]train loss : 0.055942 ,train acc: 0.992034 ,val loss : 0.120000 ,val acc : 0.973572\n",
      "[ ecpho : 3  iter :253 ]train loss : 0.071410 ,train acc: 0.981872 ,val loss : 0.118715 ,val acc : 0.975433\n",
      "[ ecpho : 3  iter :254 ]train loss : 0.159356 ,train acc: 0.943451 ,val loss : 0.119254 ,val acc : 0.974854\n",
      "[ ecpho : 3  iter :255 ]train loss : 0.096989 ,train acc: 0.965200 ,val loss : 0.122265 ,val acc : 0.975922\n",
      "[ ecpho : 3  iter :256 ]train loss : 0.423238 ,train acc: 0.813547 ,val loss : 0.139198 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :257 ]train loss : 0.094584 ,train acc: 0.965759 ,val loss : 0.150520 ,val acc : 0.975281\n",
      "[ ecpho : 3  iter :258 ]train loss : 0.078723 ,train acc: 0.970428 ,val loss : 0.154912 ,val acc : 0.974121\n",
      "[ ecpho : 3  iter :259 ]train loss : 0.044206 ,train acc: 0.991872 ,val loss : 0.160127 ,val acc : 0.974518\n",
      "[ ecpho : 3  iter :260 ]train loss : 0.307019 ,train acc: 0.849386 ,val loss : 0.162962 ,val acc : 0.973236\n",
      "[ ecpho : 3  iter :261 ]train loss : 0.205911 ,train acc: 0.917226 ,val loss : 0.171326 ,val acc : 0.966705\n",
      "[ ecpho : 3  iter :262 ]train loss : 0.218961 ,train acc: 0.917999 ,val loss : 0.167540 ,val acc : 0.964508\n",
      "[ ecpho : 3  iter :263 ]train loss : 0.302538 ,train acc: 0.826050 ,val loss : 0.177978 ,val acc : 0.953674\n",
      "[ ecpho : 3  iter :264 ]train loss : 0.073808 ,train acc: 0.973287 ,val loss : 0.175247 ,val acc : 0.958710\n",
      "[ ecpho : 3  iter :265 ]train loss : 0.073477 ,train acc: 0.973317 ,val loss : 0.170724 ,val acc : 0.964111\n",
      "[ ecpho : 3  iter :266 ]train loss : 0.143557 ,train acc: 0.940836 ,val loss : 0.169831 ,val acc : 0.968597\n",
      "[ ecpho : 3  iter :267 ]train loss : 0.060353 ,train acc: 0.977722 ,val loss : 0.168689 ,val acc : 0.967651\n",
      "[ ecpho : 3  iter :268 ]train loss : 0.172507 ,train acc: 0.926188 ,val loss : 0.165208 ,val acc : 0.970886\n",
      "[ ecpho : 3  iter :269 ]train loss : 0.202873 ,train acc: 0.919993 ,val loss : 0.169875 ,val acc : 0.967560\n",
      "[ ecpho : 3  iter :270 ]train loss : 0.113572 ,train acc: 0.967142 ,val loss : 0.166023 ,val acc : 0.970367\n",
      "[ ecpho : 3  iter :271 ]train loss : 0.185220 ,train acc: 0.923706 ,val loss : 0.168348 ,val acc : 0.966736\n",
      "[ ecpho : 3  iter :272 ]train loss : 0.117859 ,train acc: 0.972076 ,val loss : 0.165449 ,val acc : 0.968933\n",
      "[ ecpho : 3  iter :273 ]train loss : 0.055485 ,train acc: 0.978810 ,val loss : 0.162093 ,val acc : 0.967865\n",
      "[ ecpho : 3  iter :274 ]train loss : 0.119128 ,train acc: 0.968577 ,val loss : 0.166642 ,val acc : 0.968811\n",
      "[ ecpho : 3  iter :275 ]train loss : 0.105894 ,train acc: 0.963745 ,val loss : 0.163207 ,val acc : 0.969635\n",
      "[ ecpho : 3  iter :276 ]train loss : 0.124405 ,train acc: 0.975026 ,val loss : 0.161384 ,val acc : 0.970337\n",
      "[ ecpho : 3  iter :277 ]train loss : 0.091519 ,train acc: 0.977539 ,val loss : 0.159288 ,val acc : 0.972107\n",
      "[ ecpho : 3  iter :278 ]train loss : 0.215146 ,train acc: 0.917684 ,val loss : 0.155554 ,val acc : 0.971710\n",
      "[ ecpho : 3  iter :279 ]train loss : 0.097541 ,train acc: 0.982879 ,val loss : 0.153829 ,val acc : 0.971558\n",
      "[ ecpho : 3  iter :280 ]train loss : 0.089261 ,train acc: 0.985605 ,val loss : 0.150364 ,val acc : 0.972351\n",
      "[ ecpho : 3  iter :281 ]train loss : 0.124808 ,train acc: 0.968160 ,val loss : 0.143993 ,val acc : 0.973419\n",
      "[ ecpho : 3  iter :282 ]train loss : 0.079283 ,train acc: 0.963725 ,val loss : 0.142512 ,val acc : 0.973114\n",
      "[ ecpho : 3  iter :283 ]train loss : 0.125815 ,train acc: 0.960083 ,val loss : 0.140645 ,val acc : 0.972168\n",
      "[ ecpho : 3  iter :284 ]train loss : 0.059178 ,train acc: 0.983530 ,val loss : 0.138002 ,val acc : 0.973267\n",
      "[ ecpho : 3  iter :285 ]train loss : 0.100959 ,train acc: 0.967499 ,val loss : 0.134827 ,val acc : 0.971954\n",
      "[ ecpho : 3  iter :286 ]train loss : 0.085101 ,train acc: 0.963206 ,val loss : 0.133274 ,val acc : 0.974243\n",
      "[ ecpho : 3  iter :287 ]train loss : 0.066258 ,train acc: 0.990305 ,val loss : 0.129909 ,val acc : 0.973969\n",
      "[ ecpho : 3  iter :288 ]train loss : 0.064901 ,train acc: 0.980092 ,val loss : 0.127097 ,val acc : 0.975464\n",
      "[ ecpho : 3  iter :289 ]train loss : 0.060510 ,train acc: 0.985677 ,val loss : 0.124916 ,val acc : 0.975616\n",
      "[ ecpho : 3  iter :290 ]train loss : 0.054415 ,train acc: 0.992655 ,val loss : 0.123296 ,val acc : 0.975464\n",
      "[ ecpho : 3  iter :291 ]train loss : 0.174130 ,train acc: 0.931834 ,val loss : 0.121983 ,val acc : 0.976196\n",
      "[ ecpho : 3  iter :292 ]train loss : 0.123723 ,train acc: 0.964589 ,val loss : 0.122017 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :293 ]train loss : 0.085292 ,train acc: 0.974680 ,val loss : 0.121454 ,val acc : 0.976135\n",
      "[ ecpho : 3  iter :294 ]train loss : 0.169892 ,train acc: 0.934224 ,val loss : 0.124139 ,val acc : 0.976288\n",
      "[ ecpho : 3  iter :295 ]train loss : 0.087481 ,train acc: 0.968607 ,val loss : 0.124024 ,val acc : 0.976532\n",
      "[ ecpho : 3  iter :296 ]train loss : 0.084236 ,train acc: 0.982259 ,val loss : 0.124613 ,val acc : 0.976807\n",
      "[ ecpho : 3  iter :297 ]train loss : 0.112016 ,train acc: 0.957153 ,val loss : 0.126647 ,val acc : 0.975159\n",
      "[ ecpho : 3  iter :298 ]train loss : 0.109952 ,train acc: 0.954122 ,val loss : 0.127326 ,val acc : 0.973541\n",
      "[ ecpho : 3  iter :299 ]train loss : 0.174413 ,train acc: 0.946838 ,val loss : 0.127311 ,val acc : 0.971283\n",
      "[ ecpho : 3  iter :300 ]train loss : 0.074151 ,train acc: 0.982777 ,val loss : 0.124928 ,val acc : 0.970612\n",
      "[ ecpho : 3  iter :301 ]train loss : 0.058029 ,train acc: 0.985199 ,val loss : 0.122256 ,val acc : 0.971954\n",
      "[ ecpho : 3  iter :302 ]train loss : 0.050102 ,train acc: 0.983703 ,val loss : 0.121180 ,val acc : 0.973480\n",
      "[ ecpho : 3  iter :303 ]train loss : 0.067898 ,train acc: 0.983947 ,val loss : 0.120738 ,val acc : 0.974457\n",
      "[ ecpho : 3  iter :304 ]train loss : 0.082793 ,train acc: 0.977946 ,val loss : 0.117856 ,val acc : 0.975433\n",
      "[ ecpho : 3  iter :305 ]train loss : 0.110138 ,train acc: 0.965393 ,val loss : 0.117898 ,val acc : 0.976196\n",
      "[ ecpho : 3  iter :306 ]train loss : 0.072632 ,train acc: 0.982666 ,val loss : 0.115897 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :307 ]train loss : 0.121525 ,train acc: 0.953989 ,val loss : 0.117917 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :308 ]train loss : 0.077346 ,train acc: 0.974772 ,val loss : 0.118404 ,val acc : 0.976105\n",
      "[ ecpho : 3  iter :309 ]train loss : 0.246205 ,train acc: 0.871765 ,val loss : 0.121158 ,val acc : 0.974823\n",
      "[ ecpho : 3  iter :310 ]train loss : 0.081648 ,train acc: 0.985097 ,val loss : 0.119280 ,val acc : 0.974854\n",
      "[ ecpho : 3  iter :311 ]train loss : 0.111473 ,train acc: 0.965820 ,val loss : 0.120887 ,val acc : 0.973572\n",
      "[ ecpho : 3  iter :312 ]train loss : 0.209231 ,train acc: 0.927419 ,val loss : 0.124912 ,val acc : 0.974670\n",
      "[ ecpho : 3  iter :313 ]train loss : 0.052682 ,train acc: 0.985951 ,val loss : 0.129099 ,val acc : 0.973938\n",
      "[ ecpho : 3  iter :314 ]train loss : 0.108519 ,train acc: 0.965210 ,val loss : 0.132954 ,val acc : 0.972473\n",
      "[ ecpho : 3  iter :315 ]train loss : 0.058615 ,train acc: 0.989573 ,val loss : 0.133535 ,val acc : 0.972290\n",
      "[ ecpho : 3  iter :316 ]train loss : 0.060118 ,train acc: 0.989145 ,val loss : 0.131480 ,val acc : 0.973938\n",
      "[ ecpho : 3  iter :317 ]train loss : 0.137574 ,train acc: 0.951456 ,val loss : 0.132852 ,val acc : 0.972015\n",
      "[ ecpho : 3  iter :318 ]train loss : 0.065940 ,train acc: 0.985463 ,val loss : 0.132282 ,val acc : 0.971954\n",
      "[ ecpho : 3  iter :319 ]train loss : 0.054403 ,train acc: 0.992848 ,val loss : 0.129130 ,val acc : 0.973236\n",
      "[ ecpho : 3  iter :320 ]train loss : 0.049501 ,train acc: 0.991597 ,val loss : 0.125391 ,val acc : 0.973938\n",
      "[ ecpho : 3  iter :321 ]train loss : 0.050678 ,train acc: 0.989471 ,val loss : 0.125199 ,val acc : 0.974426\n",
      "[ ecpho : 3  iter :322 ]train loss : 0.155708 ,train acc: 0.947031 ,val loss : 0.125270 ,val acc : 0.973969\n",
      "[ ecpho : 3  iter :323 ]train loss : 0.149476 ,train acc: 0.940999 ,val loss : 0.124628 ,val acc : 0.975098\n",
      "[ ecpho : 3  iter :324 ]train loss : 0.101666 ,train acc: 0.964538 ,val loss : 0.124751 ,val acc : 0.975616\n",
      "[ ecpho : 3  iter :325 ]train loss : 0.095395 ,train acc: 0.969299 ,val loss : 0.128190 ,val acc : 0.974487\n",
      "[ ecpho : 3  iter :326 ]train loss : 0.069762 ,train acc: 0.986124 ,val loss : 0.127980 ,val acc : 0.974701\n",
      "[ ecpho : 3  iter :327 ]train loss : 0.059874 ,train acc: 0.986236 ,val loss : 0.125710 ,val acc : 0.975128\n",
      "[ ecpho : 3  iter :328 ]train loss : 0.291286 ,train acc: 0.880625 ,val loss : 0.132671 ,val acc : 0.973267\n",
      "[ ecpho : 3  iter :329 ]train loss : 0.204826 ,train acc: 0.923045 ,val loss : 0.133876 ,val acc : 0.972809\n",
      "[ ecpho : 3  iter :330 ]train loss : 0.079064 ,train acc: 0.982655 ,val loss : 0.138186 ,val acc : 0.973114\n",
      "[ ecpho : 3  iter :331 ]train loss : 0.086982 ,train acc: 0.981414 ,val loss : 0.132978 ,val acc : 0.973999\n",
      "[ ecpho : 3  iter :332 ]train loss : 0.097460 ,train acc: 0.958384 ,val loss : 0.133049 ,val acc : 0.972260\n",
      "[ ecpho : 3  iter :333 ]train loss : 0.084286 ,train acc: 0.980489 ,val loss : 0.132294 ,val acc : 0.973511\n",
      "[ ecpho : 3  iter :334 ]train loss : 0.070718 ,train acc: 0.984934 ,val loss : 0.128575 ,val acc : 0.974335\n",
      "[ ecpho : 3  iter :335 ]train loss : 0.179491 ,train acc: 0.928914 ,val loss : 0.129966 ,val acc : 0.973694\n",
      "[ ecpho : 3  iter :336 ]train loss : 0.058423 ,train acc: 0.989105 ,val loss : 0.127013 ,val acc : 0.971008\n",
      "[ ecpho : 3  iter :337 ]train loss : 0.107582 ,train acc: 0.962656 ,val loss : 0.126222 ,val acc : 0.971771\n",
      "[ ecpho : 3  iter :338 ]train loss : 0.076059 ,train acc: 0.977580 ,val loss : 0.129151 ,val acc : 0.970612\n",
      "[ ecpho : 3  iter :339 ]train loss : 0.165179 ,train acc: 0.930776 ,val loss : 0.126883 ,val acc : 0.970032\n",
      "[ ecpho : 3  iter :340 ]train loss : 0.136136 ,train acc: 0.950704 ,val loss : 0.126342 ,val acc : 0.971100\n",
      "[ ecpho : 3  iter :341 ]train loss : 0.080232 ,train acc: 0.967346 ,val loss : 0.122964 ,val acc : 0.971863\n",
      "[ ecpho : 3  iter :342 ]train loss : 0.134818 ,train acc: 0.954803 ,val loss : 0.122007 ,val acc : 0.971893\n",
      "[ ecpho : 3  iter :343 ]train loss : 0.056129 ,train acc: 0.990092 ,val loss : 0.120733 ,val acc : 0.972717\n",
      "[ ecpho : 3  iter :344 ]train loss : 0.096990 ,train acc: 0.963053 ,val loss : 0.120326 ,val acc : 0.971863\n",
      "[ ecpho : 3  iter :345 ]train loss : 0.060621 ,train acc: 0.979655 ,val loss : 0.120608 ,val acc : 0.972504\n",
      "[ ecpho : 3  iter :346 ]train loss : 0.067314 ,train acc: 0.973785 ,val loss : 0.119949 ,val acc : 0.973450\n",
      "[ ecpho : 3  iter :347 ]train loss : 0.082688 ,train acc: 0.977061 ,val loss : 0.119733 ,val acc : 0.974213\n",
      "[ ecpho : 3  iter :348 ]train loss : 0.053678 ,train acc: 0.991709 ,val loss : 0.120380 ,val acc : 0.974182\n",
      "[ ecpho : 3  iter :349 ]train loss : 0.158214 ,train acc: 0.945129 ,val loss : 0.118957 ,val acc : 0.973816\n",
      "[ ecpho : 3  iter :350 ]train loss : 0.072287 ,train acc: 0.983195 ,val loss : 0.118909 ,val acc : 0.973145\n",
      "[ ecpho : 3  iter :351 ]train loss : 0.054163 ,train acc: 0.991994 ,val loss : 0.117369 ,val acc : 0.974274\n",
      "[ ecpho : 3  iter :352 ]train loss : 0.205775 ,train acc: 0.920919 ,val loss : 0.118057 ,val acc : 0.974365\n",
      "[ ecpho : 3  iter :353 ]train loss : 0.088214 ,train acc: 0.974487 ,val loss : 0.123557 ,val acc : 0.973022\n",
      "[ ecpho : 3  iter :354 ]train loss : 0.065202 ,train acc: 0.983541 ,val loss : 0.123087 ,val acc : 0.973999\n",
      "[ ecpho : 3  iter :355 ]train loss : 0.123280 ,train acc: 0.948232 ,val loss : 0.126481 ,val acc : 0.972748\n",
      "[ ecpho : 3  iter :356 ]train loss : 0.192978 ,train acc: 0.930349 ,val loss : 0.136273 ,val acc : 0.970123\n",
      "[ ecpho : 3  iter :357 ]train loss : 0.102216 ,train acc: 0.957194 ,val loss : 0.141597 ,val acc : 0.968628\n",
      "[ ecpho : 3  iter :358 ]train loss : 0.113419 ,train acc: 0.966909 ,val loss : 0.146651 ,val acc : 0.967194\n",
      "[ ecpho : 3  iter :359 ]train loss : 0.116155 ,train acc: 0.957763 ,val loss : 0.145475 ,val acc : 0.969055\n",
      "[ ecpho : 3  iter :360 ]train loss : 0.094615 ,train acc: 0.973399 ,val loss : 0.145872 ,val acc : 0.972748\n",
      "[ ecpho : 3  iter :361 ]train loss : 0.085122 ,train acc: 0.978739 ,val loss : 0.140949 ,val acc : 0.975647\n",
      "[ ecpho : 3  iter :362 ]train loss : 0.057960 ,train acc: 0.987060 ,val loss : 0.141154 ,val acc : 0.976227\n",
      "[ ecpho : 3  iter :363 ]train loss : 0.394578 ,train acc: 0.797302 ,val loss : 0.143286 ,val acc : 0.975616\n",
      "[ ecpho : 3  iter :364 ]train loss : 0.057328 ,train acc: 0.987498 ,val loss : 0.141135 ,val acc : 0.975281\n",
      "[ ecpho : 3  iter :365 ]train loss : 0.137359 ,train acc: 0.949432 ,val loss : 0.142308 ,val acc : 0.975616\n",
      "[ ecpho : 3  iter :366 ]train loss : 0.088972 ,train acc: 0.984985 ,val loss : 0.143783 ,val acc : 0.974182\n",
      "[ ecpho : 3  iter :367 ]train loss : 0.089685 ,train acc: 0.979644 ,val loss : 0.142787 ,val acc : 0.974396\n",
      "[ ecpho : 3  iter :368 ]train loss : 0.094020 ,train acc: 0.979675 ,val loss : 0.139811 ,val acc : 0.973206\n",
      "[ ecpho : 3  iter :369 ]train loss : 0.103026 ,train acc: 0.960663 ,val loss : 0.139674 ,val acc : 0.973724\n",
      "[ ecpho : 3  iter :370 ]train loss : 0.064304 ,train acc: 0.990814 ,val loss : 0.136231 ,val acc : 0.973663\n",
      "[ ecpho : 3  iter :371 ]train loss : 0.052144 ,train acc: 0.983266 ,val loss : 0.135348 ,val acc : 0.973694\n",
      "[ ecpho : 3  iter :372 ]train loss : 0.065641 ,train acc: 0.979522 ,val loss : 0.133915 ,val acc : 0.973907\n",
      "[ ecpho : 3  iter :373 ]train loss : 0.193620 ,train acc: 0.924957 ,val loss : 0.132338 ,val acc : 0.973175\n",
      "[ ecpho : 3  iter :374 ]train loss : 0.071679 ,train acc: 0.985148 ,val loss : 0.132806 ,val acc : 0.973114\n",
      "[ ecpho : 3  iter :375 ]train loss : 0.087454 ,train acc: 0.973592 ,val loss : 0.132953 ,val acc : 0.972412\n",
      "[ ecpho : 3  iter :376 ]train loss : 0.211841 ,train acc: 0.916575 ,val loss : 0.134541 ,val acc : 0.972626\n",
      "[ ecpho : 3  iter :377 ]train loss : 0.077083 ,train acc: 0.967214 ,val loss : 0.134052 ,val acc : 0.972656\n",
      "[ ecpho : 3  iter :378 ]train loss : 0.282207 ,train acc: 0.867696 ,val loss : 0.136347 ,val acc : 0.972595\n",
      "[ ecpho : 3  iter :379 ]train loss : 0.180446 ,train acc: 0.921783 ,val loss : 0.137979 ,val acc : 0.972809\n",
      "[ ecpho : 3  iter :380 ]train loss : 0.093154 ,train acc: 0.972910 ,val loss : 0.136522 ,val acc : 0.972626\n",
      "[ ecpho : 3  iter :381 ]train loss : 0.094674 ,train acc: 0.968424 ,val loss : 0.136217 ,val acc : 0.972900\n",
      "[ ecpho : 3  iter :382 ]train loss : 0.073885 ,train acc: 0.974355 ,val loss : 0.132921 ,val acc : 0.972076\n",
      "[ ecpho : 3  iter :383 ]train loss : 0.053701 ,train acc: 0.986155 ,val loss : 0.132077 ,val acc : 0.973969\n",
      "[ ecpho : 3  iter :384 ]train loss : 0.138873 ,train acc: 0.947540 ,val loss : 0.128117 ,val acc : 0.975311\n",
      "[ ecpho : 3  iter :385 ]train loss : 0.271369 ,train acc: 0.883250 ,val loss : 0.132073 ,val acc : 0.973480\n",
      "[ ecpho : 3  iter :386 ]train loss : 0.055331 ,train acc: 0.985595 ,val loss : 0.132341 ,val acc : 0.973907\n",
      "[ ecpho : 3  iter :387 ]train loss : 0.083449 ,train acc: 0.979594 ,val loss : 0.128751 ,val acc : 0.971954\n",
      "[ ecpho : 3  iter :388 ]train loss : 0.085260 ,train acc: 0.972381 ,val loss : 0.128899 ,val acc : 0.973999\n",
      "[ ecpho : 3  iter :389 ]train loss : 0.070038 ,train acc: 0.982299 ,val loss : 0.128447 ,val acc : 0.972900\n",
      "[ ecpho : 3  iter :390 ]train loss : 0.056762 ,train acc: 0.992380 ,val loss : 0.128216 ,val acc : 0.973816\n",
      "[ ecpho : 3  iter :391 ]train loss : 0.070336 ,train acc: 0.988627 ,val loss : 0.123635 ,val acc : 0.974609\n",
      "[ ecpho : 3  iter :392 ]train loss : 0.049288 ,train acc: 0.992462 ,val loss : 0.120774 ,val acc : 0.974854\n",
      "[ ecpho : 3  iter :393 ]train loss : 0.238505 ,train acc: 0.919138 ,val loss : 0.123071 ,val acc : 0.975403\n",
      "[ ecpho : 3  iter :394 ]train loss : 0.125543 ,train acc: 0.951161 ,val loss : 0.127893 ,val acc : 0.974457\n",
      "[ ecpho : 3  iter :395 ]train loss : 0.283267 ,train acc: 0.887085 ,val loss : 0.136654 ,val acc : 0.972473\n",
      "[ ecpho : 3  iter :396 ]train loss : 0.073553 ,train acc: 0.987589 ,val loss : 0.138497 ,val acc : 0.971954\n",
      "[ ecpho : 3  iter :397 ]train loss : 0.158881 ,train acc: 0.943298 ,val loss : 0.140673 ,val acc : 0.974121\n",
      "[ ecpho : 3  iter :398 ]train loss : 0.104172 ,train acc: 0.972320 ,val loss : 0.147315 ,val acc : 0.971893\n",
      "[ ecpho : 3  iter :399 ]train loss : 0.059143 ,train acc: 0.990855 ,val loss : 0.145820 ,val acc : 0.972015\n",
      "[ ecpho : 3  iter :400 ]train loss : 0.065229 ,train acc: 0.980509 ,val loss : 0.141809 ,val acc : 0.974487\n",
      "=============================================\n",
      "[ 3 ] average train loss : 0.110277 train acc : 0.963812\n",
      "[ ecpho : 4  iter :1 ]train loss : 0.236862 ,train acc: 0.905568 ,val loss : 0.141834 ,val acc : 0.973907\n",
      "[ ecpho : 4  iter :2 ]train loss : 0.079783 ,train acc: 0.977010 ,val loss : 0.140588 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :3 ]train loss : 0.190787 ,train acc: 0.911845 ,val loss : 0.143277 ,val acc : 0.972748\n",
      "[ ecpho : 4  iter :4 ]train loss : 0.099776 ,train acc: 0.978119 ,val loss : 0.142344 ,val acc : 0.972626\n",
      "[ ecpho : 4  iter :5 ]train loss : 0.098782 ,train acc: 0.976949 ,val loss : 0.142787 ,val acc : 0.970947\n",
      "[ ecpho : 4  iter :6 ]train loss : 0.160755 ,train acc: 0.924754 ,val loss : 0.139656 ,val acc : 0.972687\n",
      "[ ecpho : 4  iter :7 ]train loss : 0.060654 ,train acc: 0.990112 ,val loss : 0.140999 ,val acc : 0.972351\n",
      "[ ecpho : 4  iter :8 ]train loss : 0.201553 ,train acc: 0.904693 ,val loss : 0.140364 ,val acc : 0.972046\n",
      "[ ecpho : 4  iter :9 ]train loss : 0.106194 ,train acc: 0.958242 ,val loss : 0.141201 ,val acc : 0.973358\n",
      "[ ecpho : 4  iter :10 ]train loss : 0.088427 ,train acc: 0.979461 ,val loss : 0.139830 ,val acc : 0.973022\n",
      "[ ecpho : 4  iter :11 ]train loss : 0.177334 ,train acc: 0.927815 ,val loss : 0.140115 ,val acc : 0.971985\n",
      "[ ecpho : 4  iter :12 ]train loss : 0.064017 ,train acc: 0.983195 ,val loss : 0.138571 ,val acc : 0.972595\n",
      "[ ecpho : 4  iter :13 ]train loss : 0.104790 ,train acc: 0.968536 ,val loss : 0.133511 ,val acc : 0.973053\n",
      "[ ecpho : 4  iter :14 ]train loss : 0.067709 ,train acc: 0.976633 ,val loss : 0.133499 ,val acc : 0.972778\n",
      "[ ecpho : 4  iter :15 ]train loss : 0.065906 ,train acc: 0.983968 ,val loss : 0.129495 ,val acc : 0.973938\n",
      "[ ecpho : 4  iter :16 ]train loss : 0.061272 ,train acc: 0.989257 ,val loss : 0.127342 ,val acc : 0.974060\n",
      "[ ecpho : 4  iter :17 ]train loss : 0.348015 ,train acc: 0.841370 ,val loss : 0.129803 ,val acc : 0.974823\n",
      "[ ecpho : 4  iter :18 ]train loss : 0.062723 ,train acc: 0.991709 ,val loss : 0.129332 ,val acc : 0.974823\n",
      "[ ecpho : 4  iter :19 ]train loss : 0.566170 ,train acc: 0.750671 ,val loss : 0.141789 ,val acc : 0.974915\n",
      "[ ecpho : 4  iter :20 ]train loss : 0.087913 ,train acc: 0.968027 ,val loss : 0.152589 ,val acc : 0.975861\n",
      "[ ecpho : 4  iter :21 ]train loss : 0.086899 ,train acc: 0.983439 ,val loss : 0.149918 ,val acc : 0.976501\n",
      "[ ecpho : 4  iter :22 ]train loss : 0.083697 ,train acc: 0.964732 ,val loss : 0.151932 ,val acc : 0.976501\n",
      "[ ecpho : 4  iter :23 ]train loss : 0.135711 ,train acc: 0.973602 ,val loss : 0.156635 ,val acc : 0.976471\n",
      "[ ecpho : 4  iter :24 ]train loss : 0.061936 ,train acc: 0.978200 ,val loss : 0.155484 ,val acc : 0.977325\n",
      "[ ecpho : 4  iter :25 ]train loss : 0.149946 ,train acc: 0.924967 ,val loss : 0.155495 ,val acc : 0.976959\n",
      "[ ecpho : 4  iter :26 ]train loss : 0.114217 ,train acc: 0.971679 ,val loss : 0.156707 ,val acc : 0.976837\n",
      "[ ecpho : 4  iter :27 ]train loss : 0.076363 ,train acc: 0.982879 ,val loss : 0.154650 ,val acc : 0.975159\n",
      "[ ecpho : 4  iter :28 ]train loss : 0.095238 ,train acc: 0.985473 ,val loss : 0.153156 ,val acc : 0.976379\n",
      "[ ecpho : 4  iter :29 ]train loss : 0.062506 ,train acc: 0.993011 ,val loss : 0.154757 ,val acc : 0.976074\n",
      "[ ecpho : 4  iter :30 ]train loss : 0.073665 ,train acc: 0.992645 ,val loss : 0.150625 ,val acc : 0.975586\n",
      "[ ecpho : 4  iter :31 ]train loss : 0.088356 ,train acc: 0.986236 ,val loss : 0.155301 ,val acc : 0.975250\n",
      "[ ecpho : 4  iter :32 ]train loss : 0.063691 ,train acc: 0.991862 ,val loss : 0.152318 ,val acc : 0.975372\n",
      "[ ecpho : 4  iter :33 ]train loss : 0.146060 ,train acc: 0.958669 ,val loss : 0.153219 ,val acc : 0.974823\n",
      "[ ecpho : 4  iter :34 ]train loss : 0.055572 ,train acc: 0.982381 ,val loss : 0.150340 ,val acc : 0.975281\n",
      "[ ecpho : 4  iter :35 ]train loss : 0.078430 ,train acc: 0.988851 ,val loss : 0.150278 ,val acc : 0.974304\n",
      "[ ecpho : 4  iter :36 ]train loss : 0.056746 ,train acc: 0.997731 ,val loss : 0.146804 ,val acc : 0.974884\n",
      "[ ecpho : 4  iter :37 ]train loss : 0.116101 ,train acc: 0.958089 ,val loss : 0.145061 ,val acc : 0.973633\n",
      "[ ecpho : 4  iter :38 ]train loss : 0.071614 ,train acc: 0.981435 ,val loss : 0.145117 ,val acc : 0.974762\n",
      "[ ecpho : 4  iter :39 ]train loss : 0.067370 ,train acc: 0.988647 ,val loss : 0.143851 ,val acc : 0.974152\n",
      "[ ecpho : 4  iter :40 ]train loss : 0.080744 ,train acc: 0.978352 ,val loss : 0.139798 ,val acc : 0.974457\n",
      "[ ecpho : 4  iter :41 ]train loss : 0.075528 ,train acc: 0.987559 ,val loss : 0.142030 ,val acc : 0.973053\n",
      "[ ecpho : 4  iter :42 ]train loss : 0.050757 ,train acc: 0.993347 ,val loss : 0.137623 ,val acc : 0.974731\n",
      "[ ecpho : 4  iter :43 ]train loss : 0.191432 ,train acc: 0.916921 ,val loss : 0.137642 ,val acc : 0.973572\n",
      "[ ecpho : 4  iter :44 ]train loss : 0.104264 ,train acc: 0.972849 ,val loss : 0.137965 ,val acc : 0.973236\n",
      "[ ecpho : 4  iter :45 ]train loss : 0.076134 ,train acc: 0.971120 ,val loss : 0.136565 ,val acc : 0.973938\n",
      "[ ecpho : 4  iter :46 ]train loss : 0.057402 ,train acc: 0.992004 ,val loss : 0.132745 ,val acc : 0.973145\n",
      "[ ecpho : 4  iter :47 ]train loss : 0.158752 ,train acc: 0.938191 ,val loss : 0.137953 ,val acc : 0.971893\n",
      "[ ecpho : 4  iter :48 ]train loss : 0.090072 ,train acc: 0.978607 ,val loss : 0.136766 ,val acc : 0.972504\n",
      "[ ecpho : 4  iter :49 ]train loss : 0.074888 ,train acc: 0.978943 ,val loss : 0.137035 ,val acc : 0.971191\n",
      "[ ecpho : 4  iter :50 ]train loss : 0.160854 ,train acc: 0.945790 ,val loss : 0.132150 ,val acc : 0.971100\n",
      "[ ecpho : 4  iter :51 ]train loss : 0.133607 ,train acc: 0.948354 ,val loss : 0.130597 ,val acc : 0.971588\n",
      "[ ecpho : 4  iter :52 ]train loss : 0.111698 ,train acc: 0.957356 ,val loss : 0.129390 ,val acc : 0.971649\n",
      "[ ecpho : 4  iter :53 ]train loss : 0.148719 ,train acc: 0.931681 ,val loss : 0.129255 ,val acc : 0.971191\n",
      "[ ecpho : 4  iter :54 ]train loss : 0.095481 ,train acc: 0.968638 ,val loss : 0.128863 ,val acc : 0.970734\n",
      "[ ecpho : 4  iter :55 ]train loss : 0.095320 ,train acc: 0.967061 ,val loss : 0.125944 ,val acc : 0.970337\n",
      "[ ecpho : 4  iter :56 ]train loss : 0.098062 ,train acc: 0.965749 ,val loss : 0.128157 ,val acc : 0.969940\n",
      "[ ecpho : 4  iter :57 ]train loss : 0.065469 ,train acc: 0.986663 ,val loss : 0.123870 ,val acc : 0.970673\n",
      "[ ecpho : 4  iter :58 ]train loss : 0.082343 ,train acc: 0.973368 ,val loss : 0.125694 ,val acc : 0.970154\n",
      "[ ecpho : 4  iter :59 ]train loss : 0.068348 ,train acc: 0.977203 ,val loss : 0.124631 ,val acc : 0.970154\n",
      "[ ecpho : 4  iter :60 ]train loss : 0.141419 ,train acc: 0.946655 ,val loss : 0.121543 ,val acc : 0.971497\n",
      "[ ecpho : 4  iter :61 ]train loss : 0.153297 ,train acc: 0.943817 ,val loss : 0.122411 ,val acc : 0.971130\n",
      "[ ecpho : 4  iter :62 ]train loss : 0.062985 ,train acc: 0.978851 ,val loss : 0.122449 ,val acc : 0.971100\n",
      "[ ecpho : 4  iter :63 ]train loss : 0.087164 ,train acc: 0.968312 ,val loss : 0.120717 ,val acc : 0.972290\n",
      "[ ecpho : 4  iter :64 ]train loss : 0.052280 ,train acc: 0.983550 ,val loss : 0.120712 ,val acc : 0.972748\n",
      "[ ecpho : 4  iter :65 ]train loss : 0.069507 ,train acc: 0.985839 ,val loss : 0.116915 ,val acc : 0.973267\n",
      "[ ecpho : 4  iter :66 ]train loss : 0.063000 ,train acc: 0.979400 ,val loss : 0.119350 ,val acc : 0.973328\n",
      "[ ecpho : 4  iter :67 ]train loss : 0.082026 ,train acc: 0.971486 ,val loss : 0.118687 ,val acc : 0.974304\n",
      "[ ecpho : 4  iter :68 ]train loss : 0.130733 ,train acc: 0.951965 ,val loss : 0.121763 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :69 ]train loss : 0.070324 ,train acc: 0.982757 ,val loss : 0.120783 ,val acc : 0.975525\n",
      "[ ecpho : 4  iter :70 ]train loss : 0.112932 ,train acc: 0.959910 ,val loss : 0.120389 ,val acc : 0.975372\n",
      "[ ecpho : 4  iter :71 ]train loss : 0.092618 ,train acc: 0.977824 ,val loss : 0.119663 ,val acc : 0.975891\n",
      "[ ecpho : 4  iter :72 ]train loss : 0.074401 ,train acc: 0.986277 ,val loss : 0.119437 ,val acc : 0.975891\n",
      "[ ecpho : 4  iter :73 ]train loss : 0.122664 ,train acc: 0.953115 ,val loss : 0.119327 ,val acc : 0.976166\n",
      "[ ecpho : 4  iter :74 ]train loss : 0.132130 ,train acc: 0.949839 ,val loss : 0.120864 ,val acc : 0.974670\n",
      "[ ecpho : 4  iter :75 ]train loss : 0.070644 ,train acc: 0.982839 ,val loss : 0.120578 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :76 ]train loss : 0.082361 ,train acc: 0.976867 ,val loss : 0.119947 ,val acc : 0.974487\n",
      "[ ecpho : 4  iter :77 ]train loss : 0.128009 ,train acc: 0.957672 ,val loss : 0.118927 ,val acc : 0.974396\n",
      "[ ecpho : 4  iter :78 ]train loss : 0.058211 ,train acc: 0.985168 ,val loss : 0.118983 ,val acc : 0.973633\n",
      "[ ecpho : 4  iter :79 ]train loss : 0.224061 ,train acc: 0.918752 ,val loss : 0.124695 ,val acc : 0.974243\n",
      "[ ecpho : 4  iter :80 ]train loss : 0.098269 ,train acc: 0.965027 ,val loss : 0.131726 ,val acc : 0.973694\n",
      "[ ecpho : 4  iter :81 ]train loss : 0.226178 ,train acc: 0.900289 ,val loss : 0.139229 ,val acc : 0.972443\n",
      "[ ecpho : 4  iter :82 ]train loss : 0.064654 ,train acc: 0.983083 ,val loss : 0.143193 ,val acc : 0.969971\n",
      "[ ecpho : 4  iter :83 ]train loss : 0.122198 ,train acc: 0.959137 ,val loss : 0.144944 ,val acc : 0.970184\n",
      "[ ecpho : 4  iter :84 ]train loss : 0.161251 ,train acc: 0.925018 ,val loss : 0.143019 ,val acc : 0.970520\n",
      "[ ecpho : 4  iter :85 ]train loss : 0.083337 ,train acc: 0.978973 ,val loss : 0.144262 ,val acc : 0.969635\n",
      "[ ecpho : 4  iter :86 ]train loss : 0.103479 ,train acc: 0.974813 ,val loss : 0.144007 ,val acc : 0.972595\n",
      "[ ecpho : 4  iter :87 ]train loss : 0.083311 ,train acc: 0.978322 ,val loss : 0.141095 ,val acc : 0.972534\n",
      "[ ecpho : 4  iter :88 ]train loss : 0.085797 ,train acc: 0.975952 ,val loss : 0.143015 ,val acc : 0.973907\n",
      "[ ecpho : 4  iter :89 ]train loss : 0.075316 ,train acc: 0.985321 ,val loss : 0.139464 ,val acc : 0.974976\n",
      "[ ecpho : 4  iter :90 ]train loss : 0.058449 ,train acc: 0.993408 ,val loss : 0.137590 ,val acc : 0.974457\n",
      "[ ecpho : 4  iter :91 ]train loss : 0.086659 ,train acc: 0.982859 ,val loss : 0.134457 ,val acc : 0.975739\n",
      "[ ecpho : 4  iter :92 ]train loss : 0.057840 ,train acc: 0.993143 ,val loss : 0.132364 ,val acc : 0.975403\n",
      "[ ecpho : 4  iter :93 ]train loss : 0.071254 ,train acc: 0.987447 ,val loss : 0.129959 ,val acc : 0.974670\n",
      "[ ecpho : 4  iter :94 ]train loss : 0.061432 ,train acc: 0.980621 ,val loss : 0.128940 ,val acc : 0.975555\n",
      "[ ecpho : 4  iter :95 ]train loss : 0.044361 ,train acc: 0.993072 ,val loss : 0.128308 ,val acc : 0.974731\n",
      "[ ecpho : 4  iter :96 ]train loss : 0.098722 ,train acc: 0.968841 ,val loss : 0.123576 ,val acc : 0.976837\n",
      "[ ecpho : 4  iter :97 ]train loss : 0.188483 ,train acc: 0.920034 ,val loss : 0.124721 ,val acc : 0.976440\n",
      "[ ecpho : 4  iter :98 ]train loss : 0.051356 ,train acc: 0.995076 ,val loss : 0.124763 ,val acc : 0.975891\n",
      "[ ecpho : 4  iter :99 ]train loss : 0.067544 ,train acc: 0.985646 ,val loss : 0.122241 ,val acc : 0.975311\n",
      "[ ecpho : 4  iter :100 ]train loss : 0.261437 ,train acc: 0.898376 ,val loss : 0.125978 ,val acc : 0.976135\n",
      "[ ecpho : 4  iter :101 ]train loss : 0.137030 ,train acc: 0.958659 ,val loss : 0.124938 ,val acc : 0.976898\n",
      "[ ecpho : 4  iter :102 ]train loss : 0.143240 ,train acc: 0.947794 ,val loss : 0.125701 ,val acc : 0.976349\n",
      "[ ecpho : 4  iter :103 ]train loss : 0.076172 ,train acc: 0.983907 ,val loss : 0.126108 ,val acc : 0.974762\n",
      "[ ecpho : 4  iter :104 ]train loss : 0.072628 ,train acc: 0.985646 ,val loss : 0.124750 ,val acc : 0.974396\n",
      "[ ecpho : 4  iter :105 ]train loss : 0.076884 ,train acc: 0.984985 ,val loss : 0.124219 ,val acc : 0.974121\n",
      "[ ecpho : 4  iter :106 ]train loss : 0.310971 ,train acc: 0.868500 ,val loss : 0.127600 ,val acc : 0.974152\n",
      "[ ecpho : 4  iter :107 ]train loss : 0.308920 ,train acc: 0.872640 ,val loss : 0.137983 ,val acc : 0.974304\n",
      "[ ecpho : 4  iter :108 ]train loss : 0.063939 ,train acc: 0.990224 ,val loss : 0.146198 ,val acc : 0.974640\n",
      "[ ecpho : 4  iter :109 ]train loss : 0.041514 ,train acc: 0.996521 ,val loss : 0.145891 ,val acc : 0.975189\n",
      "[ ecpho : 4  iter :110 ]train loss : 0.072531 ,train acc: 0.973755 ,val loss : 0.146987 ,val acc : 0.975494\n",
      "[ ecpho : 4  iter :111 ]train loss : 0.068204 ,train acc: 0.984537 ,val loss : 0.149439 ,val acc : 0.975677\n",
      "[ ecpho : 4  iter :112 ]train loss : 0.055880 ,train acc: 0.984059 ,val loss : 0.148751 ,val acc : 0.975769\n",
      "[ ecpho : 4  iter :113 ]train loss : 0.098784 ,train acc: 0.981516 ,val loss : 0.150827 ,val acc : 0.976837\n",
      "[ ecpho : 4  iter :114 ]train loss : 0.153605 ,train acc: 0.930938 ,val loss : 0.150529 ,val acc : 0.976868\n",
      "[ ecpho : 4  iter :115 ]train loss : 0.131453 ,train acc: 0.980112 ,val loss : 0.144142 ,val acc : 0.977356\n",
      "[ ecpho : 4  iter :116 ]train loss : 0.175064 ,train acc: 0.931966 ,val loss : 0.144641 ,val acc : 0.976715\n",
      "[ ecpho : 4  iter :117 ]train loss : 0.182371 ,train acc: 0.929290 ,val loss : 0.143420 ,val acc : 0.976593\n",
      "[ ecpho : 4  iter :118 ]train loss : 0.101821 ,train acc: 0.974985 ,val loss : 0.147655 ,val acc : 0.975952\n",
      "[ ecpho : 4  iter :119 ]train loss : 0.085702 ,train acc: 0.971964 ,val loss : 0.144942 ,val acc : 0.976501\n",
      "[ ecpho : 4  iter :120 ]train loss : 0.086231 ,train acc: 0.972463 ,val loss : 0.144242 ,val acc : 0.975983\n",
      "[ ecpho : 4  iter :121 ]train loss : 0.107549 ,train acc: 0.959371 ,val loss : 0.147438 ,val acc : 0.974915\n",
      "[ ecpho : 4  iter :122 ]train loss : 0.099739 ,train acc: 0.981903 ,val loss : 0.145108 ,val acc : 0.974823\n",
      "[ ecpho : 4  iter :123 ]train loss : 0.078538 ,train acc: 0.987437 ,val loss : 0.146486 ,val acc : 0.973694\n",
      "[ ecpho : 4  iter :124 ]train loss : 0.092634 ,train acc: 0.979370 ,val loss : 0.140743 ,val acc : 0.974823\n",
      "[ ecpho : 4  iter :125 ]train loss : 0.069195 ,train acc: 0.981648 ,val loss : 0.143307 ,val acc : 0.973419\n",
      "[ ecpho : 4  iter :126 ]train loss : 0.191074 ,train acc: 0.916351 ,val loss : 0.139009 ,val acc : 0.973602\n",
      "[ ecpho : 4  iter :127 ]train loss : 0.154819 ,train acc: 0.922455 ,val loss : 0.140896 ,val acc : 0.973541\n",
      "[ ecpho : 4  iter :128 ]train loss : 0.082021 ,train acc: 0.984059 ,val loss : 0.137077 ,val acc : 0.973633\n",
      "[ ecpho : 4  iter :129 ]train loss : 0.080421 ,train acc: 0.987945 ,val loss : 0.136601 ,val acc : 0.972992\n",
      "[ ecpho : 4  iter :130 ]train loss : 0.070667 ,train acc: 0.984049 ,val loss : 0.133880 ,val acc : 0.974121\n",
      "[ ecpho : 4  iter :131 ]train loss : 0.134364 ,train acc: 0.950897 ,val loss : 0.130902 ,val acc : 0.972778\n",
      "[ ecpho : 4  iter :132 ]train loss : 0.226523 ,train acc: 0.898214 ,val loss : 0.129957 ,val acc : 0.973053\n",
      "[ ecpho : 4  iter :133 ]train loss : 0.059163 ,train acc: 0.978373 ,val loss : 0.129943 ,val acc : 0.974487\n",
      "[ ecpho : 4  iter :134 ]train loss : 0.082421 ,train acc: 0.981648 ,val loss : 0.127692 ,val acc : 0.974731\n",
      "[ ecpho : 4  iter :135 ]train loss : 0.306820 ,train acc: 0.882365 ,val loss : 0.135298 ,val acc : 0.972504\n",
      "[ ecpho : 4  iter :136 ]train loss : 0.201492 ,train acc: 0.917928 ,val loss : 0.137731 ,val acc : 0.973633\n",
      "[ ecpho : 4  iter :137 ]train loss : 0.384837 ,train acc: 0.827626 ,val loss : 0.139679 ,val acc : 0.973206\n",
      "[ ecpho : 4  iter :138 ]train loss : 0.317508 ,train acc: 0.840617 ,val loss : 0.145671 ,val acc : 0.971588\n",
      "[ ecpho : 4  iter :139 ]train loss : 0.071107 ,train acc: 0.986613 ,val loss : 0.149583 ,val acc : 0.969788\n",
      "[ ecpho : 4  iter :140 ]train loss : 0.062868 ,train acc: 0.980550 ,val loss : 0.154409 ,val acc : 0.967560\n",
      "[ ecpho : 4  iter :141 ]train loss : 0.148069 ,train acc: 0.945729 ,val loss : 0.154982 ,val acc : 0.965424\n",
      "[ ecpho : 4  iter :142 ]train loss : 0.151384 ,train acc: 0.950093 ,val loss : 0.157785 ,val acc : 0.967255\n",
      "[ ecpho : 4  iter :143 ]train loss : 0.055944 ,train acc: 0.987131 ,val loss : 0.155130 ,val acc : 0.969086\n",
      "[ ecpho : 4  iter :144 ]train loss : 0.064002 ,train acc: 0.985260 ,val loss : 0.151541 ,val acc : 0.969727\n",
      "[ ecpho : 4  iter :145 ]train loss : 0.107029 ,train acc: 0.974019 ,val loss : 0.154469 ,val acc : 0.970184\n",
      "[ ecpho : 4  iter :146 ]train loss : 0.061016 ,train acc: 0.977854 ,val loss : 0.150042 ,val acc : 0.970581\n",
      "[ ecpho : 4  iter :147 ]train loss : 0.074206 ,train acc: 0.988698 ,val loss : 0.149748 ,val acc : 0.971985\n",
      "[ ecpho : 4  iter :148 ]train loss : 0.103825 ,train acc: 0.982015 ,val loss : 0.149714 ,val acc : 0.974030\n",
      "[ ecpho : 4  iter :149 ]train loss : 0.068296 ,train acc: 0.986674 ,val loss : 0.148801 ,val acc : 0.972992\n",
      "[ ecpho : 4  iter :150 ]train loss : 0.052090 ,train acc: 0.982055 ,val loss : 0.146713 ,val acc : 0.973480\n",
      "[ ecpho : 4  iter :151 ]train loss : 0.075602 ,train acc: 0.986684 ,val loss : 0.141035 ,val acc : 0.974915\n",
      "[ ecpho : 4  iter :152 ]train loss : 0.052824 ,train acc: 0.995280 ,val loss : 0.143105 ,val acc : 0.973511\n",
      "[ ecpho : 4  iter :153 ]train loss : 0.150603 ,train acc: 0.924245 ,val loss : 0.141742 ,val acc : 0.974579\n",
      "[ ecpho : 4  iter :154 ]train loss : 0.131352 ,train acc: 0.966298 ,val loss : 0.141048 ,val acc : 0.975159\n",
      "[ ecpho : 4  iter :155 ]train loss : 0.069115 ,train acc: 0.993347 ,val loss : 0.141439 ,val acc : 0.973511\n",
      "[ ecpho : 4  iter :156 ]train loss : 0.091528 ,train acc: 0.976867 ,val loss : 0.138263 ,val acc : 0.974548\n",
      "[ ecpho : 4  iter :157 ]train loss : 0.138612 ,train acc: 0.958893 ,val loss : 0.138108 ,val acc : 0.972900\n",
      "[ ecpho : 4  iter :158 ]train loss : 0.092167 ,train acc: 0.969950 ,val loss : 0.135137 ,val acc : 0.971924\n",
      "[ ecpho : 4  iter :159 ]train loss : 0.133225 ,train acc: 0.952891 ,val loss : 0.132519 ,val acc : 0.971283\n",
      "[ ecpho : 4  iter :160 ]train loss : 0.055852 ,train acc: 0.981374 ,val loss : 0.130669 ,val acc : 0.972321\n",
      "[ ecpho : 4  iter :161 ]train loss : 0.094439 ,train acc: 0.975647 ,val loss : 0.129270 ,val acc : 0.972870\n",
      "[ ecpho : 4  iter :162 ]train loss : 0.062251 ,train acc: 0.986735 ,val loss : 0.126197 ,val acc : 0.972229\n",
      "[ ecpho : 4  iter :163 ]train loss : 0.056308 ,train acc: 0.984670 ,val loss : 0.126526 ,val acc : 0.971619\n",
      "[ ecpho : 4  iter :164 ]train loss : 0.338579 ,train acc: 0.857188 ,val loss : 0.129966 ,val acc : 0.970947\n",
      "[ ecpho : 4  iter :165 ]train loss : 0.057642 ,train acc: 0.984832 ,val loss : 0.131018 ,val acc : 0.972931\n",
      "[ ecpho : 4  iter :166 ]train loss : 0.062538 ,train acc: 0.990438 ,val loss : 0.129112 ,val acc : 0.974701\n",
      "[ ecpho : 4  iter :167 ]train loss : 0.290613 ,train acc: 0.863200 ,val loss : 0.129557 ,val acc : 0.974030\n",
      "[ ecpho : 4  iter :168 ]train loss : 0.289058 ,train acc: 0.873820 ,val loss : 0.134175 ,val acc : 0.972839\n",
      "[ ecpho : 4  iter :169 ]train loss : 0.063400 ,train acc: 0.987752 ,val loss : 0.138557 ,val acc : 0.971893\n",
      "[ ecpho : 4  iter :170 ]train loss : 0.220112 ,train acc: 0.909871 ,val loss : 0.140873 ,val acc : 0.970612\n",
      "[ ecpho : 4  iter :171 ]train loss : 0.065520 ,train acc: 0.976552 ,val loss : 0.141649 ,val acc : 0.969666\n",
      "[ ecpho : 4  iter :172 ]train loss : 0.075676 ,train acc: 0.978485 ,val loss : 0.140883 ,val acc : 0.972290\n",
      "[ ecpho : 4  iter :173 ]train loss : 0.098505 ,train acc: 0.981577 ,val loss : 0.139906 ,val acc : 0.972382\n",
      "[ ecpho : 4  iter :174 ]train loss : 0.066773 ,train acc: 0.982676 ,val loss : 0.138984 ,val acc : 0.973724\n",
      "[ ecpho : 4  iter :175 ]train loss : 0.340878 ,train acc: 0.825745 ,val loss : 0.134546 ,val acc : 0.973450\n",
      "[ ecpho : 4  iter :176 ]train loss : 0.073864 ,train acc: 0.986765 ,val loss : 0.139026 ,val acc : 0.971344\n",
      "[ ecpho : 4  iter :177 ]train loss : 0.164013 ,train acc: 0.936788 ,val loss : 0.135161 ,val acc : 0.972412\n",
      "[ ecpho : 4  iter :178 ]train loss : 0.062726 ,train acc: 0.990570 ,val loss : 0.131724 ,val acc : 0.970764\n",
      "[ ecpho : 4  iter :179 ]train loss : 0.208911 ,train acc: 0.910746 ,val loss : 0.133773 ,val acc : 0.972015\n",
      "[ ecpho : 4  iter :180 ]train loss : 0.179360 ,train acc: 0.917206 ,val loss : 0.138189 ,val acc : 0.971710\n",
      "[ ecpho : 4  iter :181 ]train loss : 0.094002 ,train acc: 0.966522 ,val loss : 0.138996 ,val acc : 0.973175\n",
      "[ ecpho : 4  iter :182 ]train loss : 0.059421 ,train acc: 0.977722 ,val loss : 0.140438 ,val acc : 0.972626\n",
      "[ ecpho : 4  iter :183 ]train loss : 0.135073 ,train acc: 0.950490 ,val loss : 0.143589 ,val acc : 0.974152\n",
      "[ ecpho : 4  iter :184 ]train loss : 0.414898 ,train acc: 0.763906 ,val loss : 0.148567 ,val acc : 0.973053\n",
      "[ ecpho : 4  iter :185 ]train loss : 0.167349 ,train acc: 0.948496 ,val loss : 0.150883 ,val acc : 0.973694\n",
      "[ ecpho : 4  iter :186 ]train loss : 0.088058 ,train acc: 0.986613 ,val loss : 0.150156 ,val acc : 0.974182\n",
      "[ ecpho : 4  iter :187 ]train loss : 0.116261 ,train acc: 0.969258 ,val loss : 0.150741 ,val acc : 0.973022\n",
      "[ ecpho : 4  iter :188 ]train loss : 0.066642 ,train acc: 0.976674 ,val loss : 0.147571 ,val acc : 0.974945\n",
      "[ ecpho : 4  iter :189 ]train loss : 0.087469 ,train acc: 0.983276 ,val loss : 0.147664 ,val acc : 0.973999\n",
      "[ ecpho : 4  iter :190 ]train loss : 0.096021 ,train acc: 0.980662 ,val loss : 0.147949 ,val acc : 0.973602\n",
      "[ ecpho : 4  iter :191 ]train loss : 0.071192 ,train acc: 0.974517 ,val loss : 0.146784 ,val acc : 0.973419\n",
      "[ ecpho : 4  iter :192 ]train loss : 0.072831 ,train acc: 0.976725 ,val loss : 0.147080 ,val acc : 0.973999\n",
      "[ ecpho : 4  iter :193 ]train loss : 0.135183 ,train acc: 0.959381 ,val loss : 0.146150 ,val acc : 0.973541\n",
      "[ ecpho : 4  iter :194 ]train loss : 0.125259 ,train acc: 0.951446 ,val loss : 0.140860 ,val acc : 0.974792\n",
      "[ ecpho : 4  iter :195 ]train loss : 0.061790 ,train acc: 0.980265 ,val loss : 0.144098 ,val acc : 0.973755\n",
      "[ ecpho : 4  iter :196 ]train loss : 0.063991 ,train acc: 0.990824 ,val loss : 0.140893 ,val acc : 0.975494\n",
      "[ ecpho : 4  iter :197 ]train loss : 0.119535 ,train acc: 0.957021 ,val loss : 0.141180 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :198 ]train loss : 0.057092 ,train acc: 0.985982 ,val loss : 0.137827 ,val acc : 0.974335\n",
      "[ ecpho : 4  iter :199 ]train loss : 0.078571 ,train acc: 0.983947 ,val loss : 0.135777 ,val acc : 0.974030\n",
      "[ ecpho : 4  iter :200 ]train loss : 0.080866 ,train acc: 0.983368 ,val loss : 0.132910 ,val acc : 0.973358\n",
      "[ ecpho : 4  iter :201 ]train loss : 0.159874 ,train acc: 0.951609 ,val loss : 0.129619 ,val acc : 0.975006\n",
      "[ ecpho : 4  iter :202 ]train loss : 0.061442 ,train acc: 0.981018 ,val loss : 0.128358 ,val acc : 0.973511\n",
      "[ ecpho : 4  iter :203 ]train loss : 0.098328 ,train acc: 0.967875 ,val loss : 0.127910 ,val acc : 0.973907\n",
      "[ ecpho : 4  iter :204 ]train loss : 0.151034 ,train acc: 0.940389 ,val loss : 0.127081 ,val acc : 0.974243\n",
      "[ ecpho : 4  iter :205 ]train loss : 0.141345 ,train acc: 0.940958 ,val loss : 0.129869 ,val acc : 0.973907\n",
      "[ ecpho : 4  iter :206 ]train loss : 0.196796 ,train acc: 0.915792 ,val loss : 0.127559 ,val acc : 0.974884\n",
      "[ ecpho : 4  iter :207 ]train loss : 0.076803 ,train acc: 0.985941 ,val loss : 0.129132 ,val acc : 0.974792\n",
      "[ ecpho : 4  iter :208 ]train loss : 0.088363 ,train acc: 0.976115 ,val loss : 0.128424 ,val acc : 0.974213\n",
      "[ ecpho : 4  iter :209 ]train loss : 0.062821 ,train acc: 0.988342 ,val loss : 0.130063 ,val acc : 0.974243\n",
      "[ ecpho : 4  iter :210 ]train loss : 0.092796 ,train acc: 0.971628 ,val loss : 0.131205 ,val acc : 0.974579\n",
      "[ ecpho : 4  iter :211 ]train loss : 0.057705 ,train acc: 0.978139 ,val loss : 0.127123 ,val acc : 0.975494\n",
      "[ ecpho : 4  iter :212 ]train loss : 0.197990 ,train acc: 0.927104 ,val loss : 0.125928 ,val acc : 0.975647\n",
      "[ ecpho : 4  iter :213 ]train loss : 0.192244 ,train acc: 0.912811 ,val loss : 0.131872 ,val acc : 0.974304\n",
      "[ ecpho : 4  iter :214 ]train loss : 0.295087 ,train acc: 0.890208 ,val loss : 0.130181 ,val acc : 0.973816\n",
      "[ ecpho : 4  iter :215 ]train loss : 0.076211 ,train acc: 0.977223 ,val loss : 0.129915 ,val acc : 0.972717\n",
      "[ ecpho : 4  iter :216 ]train loss : 0.087391 ,train acc: 0.973134 ,val loss : 0.129037 ,val acc : 0.974243\n",
      "[ ecpho : 4  iter :217 ]train loss : 0.227764 ,train acc: 0.906179 ,val loss : 0.133439 ,val acc : 0.974335\n",
      "[ ecpho : 4  iter :218 ]train loss : 0.099611 ,train acc: 0.963745 ,val loss : 0.137728 ,val acc : 0.974670\n",
      "[ ecpho : 4  iter :219 ]train loss : 0.075818 ,train acc: 0.981008 ,val loss : 0.138864 ,val acc : 0.974976\n",
      "[ ecpho : 4  iter :220 ]train loss : 0.097852 ,train acc: 0.979299 ,val loss : 0.136354 ,val acc : 0.975037\n",
      "[ ecpho : 4  iter :221 ]train loss : 0.073642 ,train acc: 0.981954 ,val loss : 0.141208 ,val acc : 0.974091\n",
      "[ ecpho : 4  iter :222 ]train loss : 0.048465 ,train acc: 0.990173 ,val loss : 0.138122 ,val acc : 0.975616\n",
      "[ ecpho : 4  iter :223 ]train loss : 0.073869 ,train acc: 0.974395 ,val loss : 0.137861 ,val acc : 0.975555\n",
      "[ ecpho : 4  iter :224 ]train loss : 0.050523 ,train acc: 0.992553 ,val loss : 0.135042 ,val acc : 0.974762\n",
      "[ ecpho : 4  iter :225 ]train loss : 0.070564 ,train acc: 0.991861 ,val loss : 0.133916 ,val acc : 0.975098\n",
      "[ ecpho : 4  iter :226 ]train loss : 0.372306 ,train acc: 0.846151 ,val loss : 0.131409 ,val acc : 0.976166\n",
      "[ ecpho : 4  iter :227 ]train loss : 0.064959 ,train acc: 0.977834 ,val loss : 0.137322 ,val acc : 0.975494\n",
      "[ ecpho : 4  iter :228 ]train loss : 0.108622 ,train acc: 0.965118 ,val loss : 0.137235 ,val acc : 0.975586\n",
      "[ ecpho : 4  iter :229 ]train loss : 0.082750 ,train acc: 0.984263 ,val loss : 0.137692 ,val acc : 0.975067\n",
      "[ ecpho : 4  iter :230 ]train loss : 0.063109 ,train acc: 0.978709 ,val loss : 0.136489 ,val acc : 0.976044\n",
      "[ ecpho : 4  iter :231 ]train loss : 0.064803 ,train acc: 0.980031 ,val loss : 0.134769 ,val acc : 0.976105\n",
      "[ ecpho : 4  iter :232 ]train loss : 0.105646 ,train acc: 0.972534 ,val loss : 0.134991 ,val acc : 0.975189\n",
      "[ ecpho : 4  iter :233 ]train loss : 0.067525 ,train acc: 0.985138 ,val loss : 0.132876 ,val acc : 0.974487\n",
      "[ ecpho : 4  iter :234 ]train loss : 0.130024 ,train acc: 0.953532 ,val loss : 0.130406 ,val acc : 0.975800\n",
      "[ ecpho : 4  iter :235 ]train loss : 0.081796 ,train acc: 0.975789 ,val loss : 0.131909 ,val acc : 0.974762\n",
      "[ ecpho : 4  iter :236 ]train loss : 0.088348 ,train acc: 0.979197 ,val loss : 0.128342 ,val acc : 0.974152\n",
      "[ ecpho : 4  iter :237 ]train loss : 0.040665 ,train acc: 0.994822 ,val loss : 0.127559 ,val acc : 0.975494\n",
      "[ ecpho : 4  iter :238 ]train loss : 0.100996 ,train acc: 0.961161 ,val loss : 0.127363 ,val acc : 0.974030\n",
      "[ ecpho : 4  iter :239 ]train loss : 0.093698 ,train acc: 0.968892 ,val loss : 0.127758 ,val acc : 0.973755\n",
      "[ ecpho : 4  iter :240 ]train loss : 0.070536 ,train acc: 0.982340 ,val loss : 0.130601 ,val acc : 0.972198\n",
      "[ ecpho : 4  iter :241 ]train loss : 0.059971 ,train acc: 0.987732 ,val loss : 0.125885 ,val acc : 0.972992\n",
      "[ ecpho : 4  iter :242 ]train loss : 0.078443 ,train acc: 0.976816 ,val loss : 0.124264 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :243 ]train loss : 0.070638 ,train acc: 0.984761 ,val loss : 0.122801 ,val acc : 0.973694\n",
      "[ ecpho : 4  iter :244 ]train loss : 0.110836 ,train acc: 0.957082 ,val loss : 0.122213 ,val acc : 0.973907\n",
      "[ ecpho : 4  iter :245 ]train loss : 0.162088 ,train acc: 0.931976 ,val loss : 0.122565 ,val acc : 0.974030\n",
      "[ ecpho : 4  iter :246 ]train loss : 0.194007 ,train acc: 0.928701 ,val loss : 0.124390 ,val acc : 0.974670\n",
      "[ ecpho : 4  iter :247 ]train loss : 0.393612 ,train acc: 0.839437 ,val loss : 0.133310 ,val acc : 0.974884\n",
      "[ ecpho : 4  iter :248 ]train loss : 0.076168 ,train acc: 0.981079 ,val loss : 0.134599 ,val acc : 0.975342\n",
      "[ ecpho : 4  iter :249 ]train loss : 0.078278 ,train acc: 0.982330 ,val loss : 0.137291 ,val acc : 0.975677\n",
      "[ ecpho : 4  iter :250 ]train loss : 0.075789 ,train acc: 0.987152 ,val loss : 0.136280 ,val acc : 0.975250\n",
      "[ ecpho : 4  iter :251 ]train loss : 0.079579 ,train acc: 0.983266 ,val loss : 0.136765 ,val acc : 0.976074\n",
      "[ ecpho : 4  iter :252 ]train loss : 0.058375 ,train acc: 0.982635 ,val loss : 0.137203 ,val acc : 0.975891\n",
      "[ ecpho : 4  iter :253 ]train loss : 0.082925 ,train acc: 0.972778 ,val loss : 0.132726 ,val acc : 0.976837\n",
      "[ ecpho : 4  iter :254 ]train loss : 0.098019 ,train acc: 0.980051 ,val loss : 0.132729 ,val acc : 0.976105\n",
      "[ ecpho : 4  iter :255 ]train loss : 0.055414 ,train acc: 0.990254 ,val loss : 0.133737 ,val acc : 0.977081\n",
      "[ ecpho : 4  iter :256 ]train loss : 0.104365 ,train acc: 0.974436 ,val loss : 0.133658 ,val acc : 0.977020\n",
      "[ ecpho : 4  iter :257 ]train loss : 0.067886 ,train acc: 0.990102 ,val loss : 0.130623 ,val acc : 0.976562\n",
      "[ ecpho : 4  iter :258 ]train loss : 0.197109 ,train acc: 0.925069 ,val loss : 0.129778 ,val acc : 0.975922\n",
      "[ ecpho : 4  iter :259 ]train loss : 0.196857 ,train acc: 0.923472 ,val loss : 0.125566 ,val acc : 0.976562\n",
      "[ ecpho : 4  iter :260 ]train loss : 0.063409 ,train acc: 0.990336 ,val loss : 0.126234 ,val acc : 0.975861\n",
      "[ ecpho : 4  iter :261 ]train loss : 0.076411 ,train acc: 0.971333 ,val loss : 0.128342 ,val acc : 0.975311\n",
      "[ ecpho : 4  iter :262 ]train loss : 0.182570 ,train acc: 0.926381 ,val loss : 0.128318 ,val acc : 0.975189\n",
      "[ ecpho : 4  iter :263 ]train loss : 0.068522 ,train acc: 0.980540 ,val loss : 0.125555 ,val acc : 0.976959\n",
      "[ ecpho : 4  iter :264 ]train loss : 0.111592 ,train acc: 0.967305 ,val loss : 0.125250 ,val acc : 0.976776\n",
      "[ ecpho : 4  iter :265 ]train loss : 0.066528 ,train acc: 0.991668 ,val loss : 0.124799 ,val acc : 0.976227\n",
      "[ ecpho : 4  iter :266 ]train loss : 0.058523 ,train acc: 0.991943 ,val loss : 0.122019 ,val acc : 0.976685\n",
      "[ ecpho : 4  iter :267 ]train loss : 0.121189 ,train acc: 0.962748 ,val loss : 0.120245 ,val acc : 0.976532\n",
      "[ ecpho : 4  iter :268 ]train loss : 0.103622 ,train acc: 0.970621 ,val loss : 0.119929 ,val acc : 0.975159\n",
      "[ ecpho : 4  iter :269 ]train loss : 0.050926 ,train acc: 0.986897 ,val loss : 0.119092 ,val acc : 0.976013\n",
      "[ ecpho : 4  iter :270 ]train loss : 0.070099 ,train acc: 0.985229 ,val loss : 0.117643 ,val acc : 0.976410\n",
      "[ ecpho : 4  iter :271 ]train loss : 0.093716 ,train acc: 0.969930 ,val loss : 0.115083 ,val acc : 0.975586\n",
      "[ ecpho : 4  iter :272 ]train loss : 0.131139 ,train acc: 0.954346 ,val loss : 0.116581 ,val acc : 0.975189\n",
      "[ ecpho : 4  iter :273 ]train loss : 0.042156 ,train acc: 0.993825 ,val loss : 0.116645 ,val acc : 0.975647\n",
      "[ ecpho : 4  iter :274 ]train loss : 0.047228 ,train acc: 0.990325 ,val loss : 0.118188 ,val acc : 0.974152\n",
      "[ ecpho : 4  iter :275 ]train loss : 0.052460 ,train acc: 0.993184 ,val loss : 0.115671 ,val acc : 0.975555\n",
      "[ ecpho : 4  iter :276 ]train loss : 0.260634 ,train acc: 0.903117 ,val loss : 0.119708 ,val acc : 0.975067\n",
      "[ ecpho : 4  iter :277 ]train loss : 0.053694 ,train acc: 0.993693 ,val loss : 0.119211 ,val acc : 0.975708\n",
      "[ ecpho : 4  iter :278 ]train loss : 0.057671 ,train acc: 0.992228 ,val loss : 0.120261 ,val acc : 0.976196\n",
      "[ ecpho : 4  iter :279 ]train loss : 0.074419 ,train acc: 0.977803 ,val loss : 0.122533 ,val acc : 0.975555\n",
      "[ ecpho : 4  iter :280 ]train loss : 0.142134 ,train acc: 0.940012 ,val loss : 0.121032 ,val acc : 0.976257\n",
      "[ ecpho : 4  iter :281 ]train loss : 0.091304 ,train acc: 0.967936 ,val loss : 0.124312 ,val acc : 0.975739\n",
      "[ ecpho : 4  iter :282 ]train loss : 0.073411 ,train acc: 0.982635 ,val loss : 0.125801 ,val acc : 0.975037\n",
      "[ ecpho : 4  iter :283 ]train loss : 0.053927 ,train acc: 0.992065 ,val loss : 0.123035 ,val acc : 0.975800\n",
      "[ ecpho : 4  iter :284 ]train loss : 0.151493 ,train acc: 0.949005 ,val loss : 0.126900 ,val acc : 0.973877\n",
      "[ ecpho : 4  iter :285 ]train loss : 0.357098 ,train acc: 0.846456 ,val loss : 0.129060 ,val acc : 0.973602\n",
      "[ ecpho : 4  iter :286 ]train loss : 0.198431 ,train acc: 0.912486 ,val loss : 0.137674 ,val acc : 0.970703\n",
      "[ ecpho : 4  iter :287 ]train loss : 0.124022 ,train acc: 0.942688 ,val loss : 0.140629 ,val acc : 0.968750\n",
      "[ ecpho : 4  iter :288 ]train loss : 0.164375 ,train acc: 0.938130 ,val loss : 0.146501 ,val acc : 0.967316\n",
      "[ ecpho : 4  iter :289 ]train loss : 0.162355 ,train acc: 0.924825 ,val loss : 0.149994 ,val acc : 0.959015\n",
      "[ ecpho : 4  iter :290 ]train loss : 0.115179 ,train acc: 0.955800 ,val loss : 0.152898 ,val acc : 0.959564\n",
      "[ ecpho : 4  iter :291 ]train loss : 0.053628 ,train acc: 0.981119 ,val loss : 0.146720 ,val acc : 0.964539\n",
      "[ ecpho : 4  iter :292 ]train loss : 0.086447 ,train acc: 0.975474 ,val loss : 0.148457 ,val acc : 0.968079\n",
      "[ ecpho : 4  iter :293 ]train loss : 0.079146 ,train acc: 0.978993 ,val loss : 0.143813 ,val acc : 0.973083\n",
      "[ ecpho : 4  iter :294 ]train loss : 0.092749 ,train acc: 0.980021 ,val loss : 0.142852 ,val acc : 0.974213\n",
      "[ ecpho : 4  iter :295 ]train loss : 0.068934 ,train acc: 0.984008 ,val loss : 0.138164 ,val acc : 0.974762\n",
      "[ ecpho : 4  iter :296 ]train loss : 0.109467 ,train acc: 0.963531 ,val loss : 0.140312 ,val acc : 0.975952\n",
      "[ ecpho : 4  iter :297 ]train loss : 0.055372 ,train acc: 0.983195 ,val loss : 0.138839 ,val acc : 0.976135\n",
      "[ ecpho : 4  iter :298 ]train loss : 0.064606 ,train acc: 0.983154 ,val loss : 0.138370 ,val acc : 0.975861\n",
      "[ ecpho : 4  iter :299 ]train loss : 0.095444 ,train acc: 0.973592 ,val loss : 0.138545 ,val acc : 0.976532\n",
      "[ ecpho : 4  iter :300 ]train loss : 0.090119 ,train acc: 0.983276 ,val loss : 0.137859 ,val acc : 0.975739\n",
      "[ ecpho : 4  iter :301 ]train loss : 0.077117 ,train acc: 0.991404 ,val loss : 0.132409 ,val acc : 0.976257\n",
      "[ ecpho : 4  iter :302 ]train loss : 0.077026 ,train acc: 0.971903 ,val loss : 0.130901 ,val acc : 0.976562\n",
      "[ ecpho : 4  iter :303 ]train loss : 0.087992 ,train acc: 0.980112 ,val loss : 0.129042 ,val acc : 0.976013\n",
      "[ ecpho : 4  iter :304 ]train loss : 0.061476 ,train acc: 0.990865 ,val loss : 0.129817 ,val acc : 0.975647\n",
      "[ ecpho : 4  iter :305 ]train loss : 0.053638 ,train acc: 0.989909 ,val loss : 0.127121 ,val acc : 0.976288\n",
      "[ ecpho : 4  iter :306 ]train loss : 0.054285 ,train acc: 0.990855 ,val loss : 0.125378 ,val acc : 0.975922\n",
      "[ ecpho : 4  iter :307 ]train loss : 0.048875 ,train acc: 0.986165 ,val loss : 0.124622 ,val acc : 0.975525\n",
      "[ ecpho : 4  iter :308 ]train loss : 0.106762 ,train acc: 0.972005 ,val loss : 0.123875 ,val acc : 0.976349\n",
      "[ ecpho : 4  iter :309 ]train loss : 0.076727 ,train acc: 0.974324 ,val loss : 0.125940 ,val acc : 0.975677\n",
      "[ ecpho : 4  iter :310 ]train loss : 0.077941 ,train acc: 0.981516 ,val loss : 0.125462 ,val acc : 0.975281\n",
      "[ ecpho : 4  iter :311 ]train loss : 0.070107 ,train acc: 0.977284 ,val loss : 0.123407 ,val acc : 0.976990\n",
      "[ ecpho : 4  iter :312 ]train loss : 0.078918 ,train acc: 0.970520 ,val loss : 0.122968 ,val acc : 0.976501\n",
      "[ ecpho : 4  iter :313 ]train loss : 0.108660 ,train acc: 0.963185 ,val loss : 0.121757 ,val acc : 0.977112\n",
      "[ ecpho : 4  iter :314 ]train loss : 0.153566 ,train acc: 0.942037 ,val loss : 0.120084 ,val acc : 0.977051\n",
      "[ ecpho : 4  iter :315 ]train loss : 0.041814 ,train acc: 0.994629 ,val loss : 0.120191 ,val acc : 0.976624\n",
      "[ ecpho : 4  iter :316 ]train loss : 0.103720 ,train acc: 0.970011 ,val loss : 0.118143 ,val acc : 0.976990\n",
      "[ ecpho : 4  iter :317 ]train loss : 0.064586 ,train acc: 0.985829 ,val loss : 0.117918 ,val acc : 0.976105\n",
      "[ ecpho : 4  iter :318 ]train loss : 0.062049 ,train acc: 0.988413 ,val loss : 0.116026 ,val acc : 0.976501\n",
      "[ ecpho : 4  iter :319 ]train loss : 0.050880 ,train acc: 0.995015 ,val loss : 0.116261 ,val acc : 0.976532\n",
      "[ ecpho : 4  iter :320 ]train loss : 0.192847 ,train acc: 0.918915 ,val loss : 0.117626 ,val acc : 0.975342\n",
      "[ ecpho : 4  iter :321 ]train loss : 0.122952 ,train acc: 0.958608 ,val loss : 0.117054 ,val acc : 0.975647\n",
      "[ ecpho : 4  iter :322 ]train loss : 0.054993 ,train acc: 0.990610 ,val loss : 0.117973 ,val acc : 0.975677\n",
      "[ ecpho : 4  iter :323 ]train loss : 0.099652 ,train acc: 0.968922 ,val loss : 0.119640 ,val acc : 0.975800\n",
      "[ ecpho : 4  iter :324 ]train loss : 0.049980 ,train acc: 0.987152 ,val loss : 0.119063 ,val acc : 0.976624\n",
      "[ ecpho : 4  iter :325 ]train loss : 0.048710 ,train acc: 0.985789 ,val loss : 0.120244 ,val acc : 0.976135\n",
      "[ ecpho : 4  iter :326 ]train loss : 0.104505 ,train acc: 0.960815 ,val loss : 0.121395 ,val acc : 0.975677\n",
      "[ ecpho : 4  iter :327 ]train loss : 0.062527 ,train acc: 0.988179 ,val loss : 0.121752 ,val acc : 0.975922\n",
      "[ ecpho : 4  iter :328 ]train loss : 0.242067 ,train acc: 0.900411 ,val loss : 0.123221 ,val acc : 0.977386\n",
      "[ ecpho : 4  iter :329 ]train loss : 0.075312 ,train acc: 0.984619 ,val loss : 0.128155 ,val acc : 0.976593\n",
      "[ ecpho : 4  iter :330 ]train loss : 0.058240 ,train acc: 0.993052 ,val loss : 0.127510 ,val acc : 0.977173\n",
      "[ ecpho : 4  iter :331 ]train loss : 0.064407 ,train acc: 0.984334 ,val loss : 0.128506 ,val acc : 0.978027\n",
      "[ ecpho : 4  iter :332 ]train loss : 0.048723 ,train acc: 0.992594 ,val loss : 0.126901 ,val acc : 0.977417\n",
      "[ ecpho : 4  iter :333 ]train loss : 0.217645 ,train acc: 0.908274 ,val loss : 0.130067 ,val acc : 0.977631\n",
      "[ ecpho : 4  iter :334 ]train loss : 0.284228 ,train acc: 0.887838 ,val loss : 0.130460 ,val acc : 0.977448\n",
      "[ ecpho : 4  iter :335 ]train loss : 0.049472 ,train acc: 0.992482 ,val loss : 0.131902 ,val acc : 0.977051\n",
      "[ ecpho : 4  iter :336 ]train loss : 0.052173 ,train acc: 0.987528 ,val loss : 0.132794 ,val acc : 0.976929\n",
      "[ ecpho : 4  iter :337 ]train loss : 0.070347 ,train acc: 0.985148 ,val loss : 0.131675 ,val acc : 0.976532\n",
      "[ ecpho : 4  iter :338 ]train loss : 0.049878 ,train acc: 0.992991 ,val loss : 0.133223 ,val acc : 0.977295\n",
      "[ ecpho : 4  iter :339 ]train loss : 0.072663 ,train acc: 0.974263 ,val loss : 0.131616 ,val acc : 0.977112\n",
      "[ ecpho : 4  iter :340 ]train loss : 0.063443 ,train acc: 0.996205 ,val loss : 0.130067 ,val acc : 0.976837\n",
      "[ ecpho : 4  iter :341 ]train loss : 0.110827 ,train acc: 0.964721 ,val loss : 0.128559 ,val acc : 0.976868\n",
      "[ ecpho : 4  iter :342 ]train loss : 0.055734 ,train acc: 0.991912 ,val loss : 0.128324 ,val acc : 0.976562\n",
      "[ ecpho : 4  iter :343 ]train loss : 0.055083 ,train acc: 0.988566 ,val loss : 0.127964 ,val acc : 0.975800\n",
      "[ ecpho : 4  iter :344 ]train loss : 0.139117 ,train acc: 0.955230 ,val loss : 0.126058 ,val acc : 0.975708\n",
      "[ ecpho : 4  iter :345 ]train loss : 0.098858 ,train acc: 0.970011 ,val loss : 0.124770 ,val acc : 0.976318\n",
      "[ ecpho : 4  iter :346 ]train loss : 0.047092 ,train acc: 0.992655 ,val loss : 0.124451 ,val acc : 0.975555\n",
      "[ ecpho : 4  iter :347 ]train loss : 0.049098 ,train acc: 0.988728 ,val loss : 0.122665 ,val acc : 0.975800\n",
      "[ ecpho : 4  iter :348 ]train loss : 0.067015 ,train acc: 0.985341 ,val loss : 0.121638 ,val acc : 0.975342\n",
      "[ ecpho : 4  iter :349 ]train loss : 0.326215 ,train acc: 0.853760 ,val loss : 0.125806 ,val acc : 0.975250\n",
      "[ ecpho : 4  iter :350 ]train loss : 0.086382 ,train acc: 0.967020 ,val loss : 0.127948 ,val acc : 0.976318\n",
      "[ ecpho : 4  iter :351 ]train loss : 0.126564 ,train acc: 0.957692 ,val loss : 0.129155 ,val acc : 0.976135\n",
      "[ ecpho : 4  iter :352 ]train loss : 0.042907 ,train acc: 0.996571 ,val loss : 0.131821 ,val acc : 0.975006\n",
      "[ ecpho : 4  iter :353 ]train loss : 0.070849 ,train acc: 0.988301 ,val loss : 0.130922 ,val acc : 0.973907\n",
      "[ ecpho : 4  iter :354 ]train loss : 0.097905 ,train acc: 0.975250 ,val loss : 0.128393 ,val acc : 0.975647\n",
      "[ ecpho : 4  iter :355 ]train loss : 0.058936 ,train acc: 0.989542 ,val loss : 0.129940 ,val acc : 0.974579\n",
      "[ ecpho : 4  iter :356 ]train loss : 0.104188 ,train acc: 0.973673 ,val loss : 0.127812 ,val acc : 0.974243\n",
      "[ ecpho : 4  iter :357 ]train loss : 0.076295 ,train acc: 0.979899 ,val loss : 0.127925 ,val acc : 0.974304\n",
      "[ ecpho : 4  iter :358 ]train loss : 0.205268 ,train acc: 0.892700 ,val loss : 0.129960 ,val acc : 0.973785\n",
      "[ ecpho : 4  iter :359 ]train loss : 0.110971 ,train acc: 0.965861 ,val loss : 0.129850 ,val acc : 0.974213\n",
      "[ ecpho : 4  iter :360 ]train loss : 0.237237 ,train acc: 0.900879 ,val loss : 0.131468 ,val acc : 0.974243\n",
      "[ ecpho : 4  iter :361 ]train loss : 0.061652 ,train acc: 0.990081 ,val loss : 0.132190 ,val acc : 0.974457\n",
      "[ ecpho : 4  iter :362 ]train loss : 0.082529 ,train acc: 0.982411 ,val loss : 0.130265 ,val acc : 0.973114\n",
      "[ ecpho : 4  iter :363 ]train loss : 0.100252 ,train acc: 0.971201 ,val loss : 0.131254 ,val acc : 0.972595\n",
      "[ ecpho : 4  iter :364 ]train loss : 0.064697 ,train acc: 0.985880 ,val loss : 0.127892 ,val acc : 0.973541\n",
      "[ ecpho : 4  iter :365 ]train loss : 0.147009 ,train acc: 0.945261 ,val loss : 0.129447 ,val acc : 0.972900\n",
      "[ ecpho : 4  iter :366 ]train loss : 0.055725 ,train acc: 0.985127 ,val loss : 0.131721 ,val acc : 0.972839\n",
      "[ ecpho : 4  iter :367 ]train loss : 0.209307 ,train acc: 0.902293 ,val loss : 0.132319 ,val acc : 0.972504\n",
      "[ ecpho : 4  iter :368 ]train loss : 0.186852 ,train acc: 0.925883 ,val loss : 0.136080 ,val acc : 0.972321\n",
      "[ ecpho : 4  iter :369 ]train loss : 0.047163 ,train acc: 0.987294 ,val loss : 0.135109 ,val acc : 0.970642\n",
      "[ ecpho : 4  iter :370 ]train loss : 0.187616 ,train acc: 0.932810 ,val loss : 0.139362 ,val acc : 0.971893\n",
      "[ ecpho : 4  iter :371 ]train loss : 0.080564 ,train acc: 0.983276 ,val loss : 0.134807 ,val acc : 0.974121\n",
      "[ ecpho : 4  iter :372 ]train loss : 0.053541 ,train acc: 0.987243 ,val loss : 0.138431 ,val acc : 0.972687\n",
      "[ ecpho : 4  iter :373 ]train loss : 0.143528 ,train acc: 0.934245 ,val loss : 0.137778 ,val acc : 0.973297\n",
      "[ ecpho : 4  iter :374 ]train loss : 0.056430 ,train acc: 0.979014 ,val loss : 0.140554 ,val acc : 0.972809\n",
      "[ ecpho : 4  iter :375 ]train loss : 0.148160 ,train acc: 0.945404 ,val loss : 0.137160 ,val acc : 0.972412\n",
      "[ ecpho : 4  iter :376 ]train loss : 0.116119 ,train acc: 0.967855 ,val loss : 0.138385 ,val acc : 0.973267\n",
      "[ ecpho : 4  iter :377 ]train loss : 0.090307 ,train acc: 0.968831 ,val loss : 0.136880 ,val acc : 0.972137\n",
      "[ ecpho : 4  iter :378 ]train loss : 0.078417 ,train acc: 0.987477 ,val loss : 0.134218 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :379 ]train loss : 0.075450 ,train acc: 0.986663 ,val loss : 0.133706 ,val acc : 0.972961\n",
      "[ ecpho : 4  iter :380 ]train loss : 0.058947 ,train acc: 0.991088 ,val loss : 0.129951 ,val acc : 0.974213\n",
      "[ ecpho : 4  iter :381 ]train loss : 0.184639 ,train acc: 0.915130 ,val loss : 0.129544 ,val acc : 0.973389\n",
      "[ ecpho : 4  iter :382 ]train loss : 0.169381 ,train acc: 0.922872 ,val loss : 0.135485 ,val acc : 0.972748\n",
      "[ ecpho : 4  iter :383 ]train loss : 0.210165 ,train acc: 0.917826 ,val loss : 0.131997 ,val acc : 0.971924\n",
      "[ ecpho : 4  iter :384 ]train loss : 0.080228 ,train acc: 0.969553 ,val loss : 0.129815 ,val acc : 0.973083\n",
      "[ ecpho : 4  iter :385 ]train loss : 0.065204 ,train acc: 0.978922 ,val loss : 0.131522 ,val acc : 0.972473\n",
      "[ ecpho : 4  iter :386 ]train loss : 0.191068 ,train acc: 0.923431 ,val loss : 0.127711 ,val acc : 0.974030\n",
      "[ ecpho : 4  iter :387 ]train loss : 0.070920 ,train acc: 0.974131 ,val loss : 0.126949 ,val acc : 0.972992\n",
      "[ ecpho : 4  iter :388 ]train loss : 0.094994 ,train acc: 0.971374 ,val loss : 0.124670 ,val acc : 0.973969\n",
      "[ ecpho : 4  iter :389 ]train loss : 0.083728 ,train acc: 0.977722 ,val loss : 0.124437 ,val acc : 0.973755\n",
      "[ ecpho : 4  iter :390 ]train loss : 0.082162 ,train acc: 0.978556 ,val loss : 0.121609 ,val acc : 0.973694\n",
      "[ ecpho : 4  iter :391 ]train loss : 0.084085 ,train acc: 0.981241 ,val loss : 0.121978 ,val acc : 0.972260\n",
      "[ ecpho : 4  iter :392 ]train loss : 0.304484 ,train acc: 0.880656 ,val loss : 0.124850 ,val acc : 0.972412\n",
      "[ ecpho : 4  iter :393 ]train loss : 0.056119 ,train acc: 0.991231 ,val loss : 0.125189 ,val acc : 0.972260\n",
      "[ ecpho : 4  iter :394 ]train loss : 0.065790 ,train acc: 0.984436 ,val loss : 0.127016 ,val acc : 0.972076\n",
      "[ ecpho : 4  iter :395 ]train loss : 0.091949 ,train acc: 0.967783 ,val loss : 0.125530 ,val acc : 0.973724\n",
      "[ ecpho : 4  iter :396 ]train loss : 0.087647 ,train acc: 0.976053 ,val loss : 0.125806 ,val acc : 0.972168\n",
      "[ ecpho : 4  iter :397 ]train loss : 0.079265 ,train acc: 0.982065 ,val loss : 0.127294 ,val acc : 0.971741\n",
      "[ ecpho : 4  iter :398 ]train loss : 0.202021 ,train acc: 0.923909 ,val loss : 0.128498 ,val acc : 0.971405\n",
      "[ ecpho : 4  iter :399 ]train loss : 0.104383 ,train acc: 0.965342 ,val loss : 0.126155 ,val acc : 0.972351\n",
      "[ ecpho : 4  iter :400 ]train loss : 0.047277 ,train acc: 0.992777 ,val loss : 0.127213 ,val acc : 0.972717\n",
      "=============================================\n",
      "[ 4 ] average train loss : 0.110014 train acc : 0.963546\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "data_files = glob.glob('../unet_3d_traindata/*_data_*.npy')\n",
    "valdata_files = glob.glob('../unet_3d_valdata/*_data_*.npy')\n",
    "\n",
    "print(len(data_files))\n",
    "print(len(valdata_files))\n",
    "\n",
    "np.random.shuffle(data_files)\n",
    "np.random.shuffle(data_files)\n",
    "np.random.shuffle(valdata_files)\n",
    "train_datafiles = data_files[:]\n",
    "val_datafiles = valdata_files[:10]\n",
    "\n",
    "\n",
    "evaled_weights = []\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "val_costs = []\n",
    "val_accs = []\n",
    "for val_datafile in val_datafiles[:2]:\n",
    "    val_data = np.load(val_datafile)\n",
    "    val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "    val_norm[val_norm > 1] = 1\n",
    "    val_norm[val_norm < 0] = 0\n",
    "    val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "    val_label = np.load(val_datafiles[0].replace('_data_','_label_'))\n",
    "    val_label = np.reshape(val_label,[1,32,32,32,2])\n",
    "    \n",
    "    val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                       feed_dict={input_x:val_norm,input_y:val_label,keep_prob:0.5})\n",
    "    print('val loss: %f ,val acc : %f' % (val_cost,val_acc))\n",
    "    val_costs.append(val_cost)\n",
    "    val_accs.append(val_acc)\n",
    "print(np.mean(val_cost),np.mean(val_acc))\n",
    "\n",
    "for ecpho in range(5):\n",
    "    iteration = 0\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    #tmp_tranfiles = train_datafiles[ecpho*5000:(ecpho + 1)*2000]\n",
    "    tmp_tranfiles = np.random.choice(train_datafiles,2000)\n",
    "    for idx in np.arange(0,len(tmp_tranfiles),5):\n",
    "        iteration += 1\n",
    "        tmp_files = tmp_tranfiles[idx:idx+3]\n",
    "        train_datas = []\n",
    "        train_labels = []\n",
    "        for train_datafile in tmp_files:\n",
    "            train_data = np.load(train_datafile)\n",
    "            train_label = np.load(train_datafile.replace('_data_','_label_'))\n",
    "            train_norm = (train_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            train_norm[train_norm > 1] = 1\n",
    "            train_norm[train_norm < 0] = 0\n",
    "            train_datas.append(train_norm)\n",
    "            train_labels.append(train_label)\n",
    "        \n",
    "        train_datas = np.array(train_datas)\n",
    "        train_labels = np.array(train_labels)\n",
    "        _,train_cost,train_output_shape,train_acc,ws = sess.run([optimizer,cost,logits_shape,accuracy,weights],\n",
    "                                       feed_dict={input_x:train_datas,input_y:train_labels,keep_prob:0.5})\n",
    "        train_loss.append(train_cost)\n",
    "        train_accs.append(train_acc)\n",
    "        val_costs = []\n",
    "        val_accs = []\n",
    "        for val_datafile in val_datafiles[:10]:\n",
    "            val_data = np.load(val_datafile)\n",
    "            val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            val_norm[val_norm > 1] = 1\n",
    "            val_norm[val_norm < 0] = 0\n",
    "            val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "            val_label = np.load(val_datafiles[0].replace('_data_','_label_'))\n",
    "            val_label = np.reshape(val_label,[1,32,32,32,2])\n",
    "            val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                           feed_dict={input_x:val_norm,input_y:val_label,keep_prob:0.5})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accs.append(val_acc)\n",
    "        print('[ ecpho : %d  iter :%d ]train loss : %f ,train acc: %f ,val loss : %f ,val acc : %f' % (ecpho,iteration,train_cost,train_acc,np.mean(val_cost),np.mean(val_acc)))\n",
    "    print(\"=============================================\")\n",
    "    print(\"[ %d ] average train loss : %f train acc : %f\" % (ecpho,np.mean(train_loss),np.mean(train_accs)))\n",
    "    \n",
    "    modelpath = './unet3d_models_7/ecpho_'+str(ecpho)\n",
    "    if not os.path.exists(modelpath):\n",
    "        os.mkdir(modelpath)\n",
    "    saver.save(sess,modelpath+'/unet3d_model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ecpho : 0  iter :1 ]train loss : 0.595357 ,train acc: 0.650402 ,val loss : 0.595931 ,val acc : 0.646362\n",
      "[ ecpho : 0  iter :2 ]train loss : 0.584650 ,train acc: 0.654950 ,val loss : 0.599817 ,val acc : 0.648010\n",
      "[ ecpho : 0  iter :3 ]train loss : 0.611157 ,train acc: 0.642547 ,val loss : 0.594924 ,val acc : 0.650848\n",
      "[ ecpho : 0  iter :4 ]train loss : 0.619635 ,train acc: 0.636895 ,val loss : 0.596105 ,val acc : 0.648224\n",
      "[ ecpho : 0  iter :5 ]train loss : 0.592014 ,train acc: 0.650073 ,val loss : 0.596040 ,val acc : 0.647400\n",
      "[ ecpho : 0  iter :6 ]train loss : 0.604625 ,train acc: 0.645257 ,val loss : 0.595920 ,val acc : 0.649536\n",
      "[ ecpho : 0  iter :7 ]train loss : 0.604288 ,train acc: 0.647937 ,val loss : 0.589215 ,val acc : 0.653809\n",
      "[ ecpho : 0  iter :8 ]train loss : 0.596475 ,train acc: 0.650842 ,val loss : 0.593178 ,val acc : 0.651093\n",
      "[ ecpho : 0  iter :9 ]train loss : 0.587452 ,train acc: 0.651068 ,val loss : 0.598628 ,val acc : 0.650238\n",
      "[ ecpho : 0  iter :10 ]train loss : 0.584547 ,train acc: 0.654956 ,val loss : 0.592523 ,val acc : 0.649231\n",
      "[ ecpho : 0  iter :11 ]train loss : 0.600373 ,train acc: 0.648651 ,val loss : 0.594915 ,val acc : 0.652344\n",
      "[ ecpho : 0  iter :12 ]train loss : 0.598177 ,train acc: 0.648492 ,val loss : 0.590975 ,val acc : 0.651886\n",
      "[ ecpho : 0  iter :13 ]train loss : 0.592198 ,train acc: 0.653003 ,val loss : 0.583238 ,val acc : 0.655945\n",
      "[ ecpho : 0  iter :14 ]train loss : 0.626938 ,train acc: 0.629412 ,val loss : 0.593740 ,val acc : 0.648682\n",
      "[ ecpho : 0  iter :15 ]train loss : 0.610875 ,train acc: 0.630511 ,val loss : 0.586408 ,val acc : 0.653717\n",
      "[ ecpho : 0  iter :16 ]train loss : 0.576109 ,train acc: 0.656976 ,val loss : 0.586554 ,val acc : 0.653076\n",
      "[ ecpho : 0  iter :17 ]train loss : 0.605370 ,train acc: 0.640722 ,val loss : 0.590618 ,val acc : 0.648895\n",
      "[ ecpho : 0  iter :18 ]train loss : 0.587623 ,train acc: 0.654980 ,val loss : 0.591924 ,val acc : 0.648285\n",
      "[ ecpho : 0  iter :19 ]train loss : 0.565540 ,train acc: 0.659179 ,val loss : 0.590156 ,val acc : 0.653900\n",
      "[ ecpho : 0  iter :20 ]train loss : 0.591915 ,train acc: 0.648480 ,val loss : 0.581399 ,val acc : 0.651459\n",
      "[ ecpho : 0  iter :21 ]train loss : 0.577701 ,train acc: 0.657623 ,val loss : 0.590169 ,val acc : 0.651459\n",
      "[ ecpho : 0  iter :22 ]train loss : 0.577082 ,train acc: 0.658093 ,val loss : 0.576401 ,val acc : 0.652222\n",
      "[ ecpho : 0  iter :23 ]train loss : 0.608394 ,train acc: 0.644317 ,val loss : 0.585364 ,val acc : 0.654175\n",
      "[ ecpho : 0  iter :24 ]train loss : 0.586904 ,train acc: 0.654828 ,val loss : 0.588828 ,val acc : 0.649323\n",
      "[ ecpho : 0  iter :25 ]train loss : 0.599224 ,train acc: 0.646777 ,val loss : 0.584453 ,val acc : 0.653503\n",
      "[ ecpho : 0  iter :26 ]train loss : 0.596033 ,train acc: 0.646338 ,val loss : 0.577569 ,val acc : 0.653839\n",
      "[ ecpho : 0  iter :27 ]train loss : 0.601730 ,train acc: 0.646338 ,val loss : 0.582050 ,val acc : 0.651062\n",
      "[ ecpho : 0  iter :28 ]train loss : 0.588224 ,train acc: 0.649542 ,val loss : 0.578452 ,val acc : 0.657074\n",
      "[ ecpho : 0  iter :29 ]train loss : 0.562983 ,train acc: 0.662329 ,val loss : 0.574681 ,val acc : 0.656158\n",
      "[ ecpho : 0  iter :30 ]train loss : 0.578369 ,train acc: 0.658105 ,val loss : 0.581849 ,val acc : 0.653351\n",
      "[ ecpho : 0  iter :31 ]train loss : 0.575545 ,train acc: 0.660974 ,val loss : 0.578933 ,val acc : 0.658142\n",
      "[ ecpho : 0  iter :32 ]train loss : 0.563283 ,train acc: 0.661432 ,val loss : 0.575770 ,val acc : 0.654968\n",
      "[ ecpho : 0  iter :33 ]train loss : 0.569123 ,train acc: 0.662543 ,val loss : 0.581364 ,val acc : 0.656677\n",
      "[ ecpho : 0  iter :34 ]train loss : 0.580608 ,train acc: 0.660943 ,val loss : 0.575449 ,val acc : 0.657593\n",
      "[ ecpho : 0  iter :35 ]train loss : 0.557349 ,train acc: 0.667663 ,val loss : 0.578622 ,val acc : 0.659271\n",
      "[ ecpho : 0  iter :36 ]train loss : 0.563069 ,train acc: 0.666259 ,val loss : 0.571380 ,val acc : 0.660614\n",
      "[ ecpho : 0  iter :37 ]train loss : 0.586091 ,train acc: 0.654217 ,val loss : 0.570847 ,val acc : 0.658997\n",
      "[ ecpho : 0  iter :38 ]train loss : 0.588354 ,train acc: 0.649829 ,val loss : 0.565929 ,val acc : 0.658569\n",
      "[ ecpho : 0  iter :39 ]train loss : 0.559297 ,train acc: 0.667254 ,val loss : 0.568619 ,val acc : 0.662201\n",
      "[ ecpho : 0  iter :40 ]train loss : 0.554364 ,train acc: 0.667517 ,val loss : 0.562780 ,val acc : 0.664276\n",
      "[ ecpho : 0  iter :41 ]train loss : 0.569743 ,train acc: 0.657611 ,val loss : 0.558692 ,val acc : 0.662048\n",
      "[ ecpho : 0  iter :42 ]train loss : 0.579704 ,train acc: 0.657299 ,val loss : 0.561768 ,val acc : 0.660889\n",
      "[ ecpho : 0  iter :43 ]train loss : 0.547404 ,train acc: 0.672259 ,val loss : 0.558821 ,val acc : 0.665863\n",
      "[ ecpho : 0  iter :44 ]train loss : 0.575853 ,train acc: 0.653784 ,val loss : 0.558840 ,val acc : 0.660553\n",
      "[ ecpho : 0  iter :45 ]train loss : 0.607681 ,train acc: 0.633075 ,val loss : 0.551442 ,val acc : 0.667328\n",
      "[ ecpho : 0  iter :46 ]train loss : 0.533600 ,train acc: 0.680298 ,val loss : 0.554546 ,val acc : 0.664917\n",
      "[ ecpho : 0  iter :47 ]train loss : 0.527728 ,train acc: 0.680530 ,val loss : 0.555493 ,val acc : 0.663666\n",
      "[ ecpho : 0  iter :48 ]train loss : 0.543173 ,train acc: 0.676306 ,val loss : 0.554777 ,val acc : 0.668396\n",
      "[ ecpho : 0  iter :49 ]train loss : 0.545887 ,train acc: 0.672516 ,val loss : 0.547559 ,val acc : 0.667816\n",
      "[ ecpho : 0  iter :50 ]train loss : 0.536971 ,train acc: 0.673553 ,val loss : 0.547719 ,val acc : 0.666992\n",
      "[ ecpho : 0  iter :51 ]train loss : 0.534713 ,train acc: 0.678906 ,val loss : 0.534320 ,val acc : 0.673737\n",
      "[ ecpho : 0  iter :52 ]train loss : 0.516049 ,train acc: 0.683758 ,val loss : 0.541218 ,val acc : 0.673401\n",
      "[ ecpho : 0  iter :53 ]train loss : 0.506590 ,train acc: 0.689349 ,val loss : 0.525146 ,val acc : 0.672577\n",
      "[ ecpho : 0  iter :54 ]train loss : 0.503091 ,train acc: 0.696783 ,val loss : 0.528548 ,val acc : 0.677643\n",
      "[ ecpho : 0  iter :55 ]train loss : 0.523393 ,train acc: 0.682251 ,val loss : 0.524648 ,val acc : 0.678986\n",
      "[ ecpho : 0  iter :56 ]train loss : 0.506085 ,train acc: 0.693030 ,val loss : 0.525490 ,val acc : 0.681702\n",
      "[ ecpho : 0  iter :57 ]train loss : 0.503056 ,train acc: 0.686719 ,val loss : 0.523492 ,val acc : 0.679779\n",
      "[ ecpho : 0  iter :58 ]train loss : 0.497211 ,train acc: 0.696887 ,val loss : 0.517813 ,val acc : 0.684692\n",
      "[ ecpho : 0  iter :59 ]train loss : 0.474520 ,train acc: 0.709900 ,val loss : 0.509403 ,val acc : 0.783508\n",
      "[ ecpho : 0  iter :60 ]train loss : 0.476902 ,train acc: 0.797614 ,val loss : 0.506276 ,val acc : 0.787354\n",
      "[ ecpho : 0  iter :61 ]train loss : 0.469308 ,train acc: 0.797126 ,val loss : 0.498296 ,val acc : 0.788422\n",
      "[ ecpho : 0  iter :62 ]train loss : 0.456994 ,train acc: 0.776721 ,val loss : 0.502271 ,val acc : 0.789612\n",
      "[ ecpho : 0  iter :63 ]train loss : 0.453624 ,train acc: 0.805902 ,val loss : 0.496151 ,val acc : 0.790924\n",
      "[ ecpho : 0  iter :64 ]train loss : 0.449886 ,train acc: 0.802240 ,val loss : 0.491652 ,val acc : 0.790405\n",
      "[ ecpho : 0  iter :65 ]train loss : 0.465471 ,train acc: 0.786249 ,val loss : 0.479498 ,val acc : 0.794495\n",
      "[ ecpho : 0  iter :66 ]train loss : 0.435618 ,train acc: 0.783283 ,val loss : 0.482726 ,val acc : 0.794525\n",
      "[ ecpho : 0  iter :67 ]train loss : 0.407638 ,train acc: 0.814856 ,val loss : 0.472238 ,val acc : 0.796936\n",
      "[ ecpho : 0  iter :68 ]train loss : 0.409946 ,train acc: 0.785706 ,val loss : 0.468998 ,val acc : 0.798401\n",
      "[ ecpho : 0  iter :69 ]train loss : 0.396814 ,train acc: 0.795947 ,val loss : 0.463087 ,val acc : 0.806000\n",
      "[ ecpho : 0  iter :70 ]train loss : 0.438891 ,train acc: 0.809693 ,val loss : 0.464775 ,val acc : 0.800476\n",
      "[ ecpho : 0  iter :71 ]train loss : 0.422844 ,train acc: 0.810895 ,val loss : 0.452017 ,val acc : 0.803619\n",
      "[ ecpho : 0  iter :72 ]train loss : 0.424756 ,train acc: 0.760712 ,val loss : 0.449264 ,val acc : 0.802277\n",
      "[ ecpho : 0  iter :73 ]train loss : 0.418335 ,train acc: 0.785999 ,val loss : 0.445982 ,val acc : 0.811890\n",
      "[ ecpho : 0  iter :74 ]train loss : 0.382548 ,train acc: 0.820142 ,val loss : 0.452201 ,val acc : 0.810089\n",
      "[ ecpho : 0  iter :75 ]train loss : 0.395663 ,train acc: 0.794306 ,val loss : 0.435799 ,val acc : 0.809021\n",
      "[ ecpho : 0  iter :76 ]train loss : 0.362074 ,train acc: 0.824372 ,val loss : 0.439449 ,val acc : 0.809875\n",
      "[ ecpho : 0  iter :77 ]train loss : 0.359250 ,train acc: 0.801850 ,val loss : 0.430481 ,val acc : 0.814667\n",
      "[ ecpho : 0  iter :78 ]train loss : 0.379485 ,train acc: 0.801654 ,val loss : 0.433865 ,val acc : 0.813202\n",
      "[ ecpho : 0  iter :79 ]train loss : 0.384294 ,train acc: 0.811560 ,val loss : 0.426401 ,val acc : 0.816986\n",
      "[ ecpho : 0  iter :80 ]train loss : 0.318679 ,train acc: 0.836811 ,val loss : 0.418039 ,val acc : 0.814117\n",
      "[ ecpho : 0  iter :81 ]train loss : 0.401847 ,train acc: 0.783356 ,val loss : 0.411054 ,val acc : 0.817322\n",
      "[ ecpho : 0  iter :82 ]train loss : 0.381560 ,train acc: 0.819580 ,val loss : 0.408021 ,val acc : 0.818451\n",
      "[ ecpho : 0  iter :83 ]train loss : 0.352634 ,train acc: 0.824134 ,val loss : 0.413090 ,val acc : 0.816254\n",
      "[ ecpho : 0  iter :84 ]train loss : 0.335663 ,train acc: 0.806061 ,val loss : 0.402696 ,val acc : 0.817352\n",
      "[ ecpho : 0  iter :85 ]train loss : 0.343395 ,train acc: 0.799622 ,val loss : 0.405821 ,val acc : 0.826355\n",
      "[ ecpho : 0  iter :86 ]train loss : 0.355233 ,train acc: 0.801551 ,val loss : 0.394219 ,val acc : 0.824463\n",
      "[ ecpho : 0  iter :87 ]train loss : 0.363842 ,train acc: 0.792176 ,val loss : 0.393626 ,val acc : 0.821869\n",
      "[ ecpho : 0  iter :88 ]train loss : 0.339204 ,train acc: 0.822809 ,val loss : 0.388128 ,val acc : 0.821106\n",
      "[ ecpho : 0  iter :89 ]train loss : 0.317422 ,train acc: 0.829273 ,val loss : 0.389160 ,val acc : 0.822021\n",
      "[ ecpho : 0  iter :90 ]train loss : 0.311510 ,train acc: 0.831080 ,val loss : 0.379339 ,val acc : 0.822693\n",
      "[ ecpho : 0  iter :91 ]train loss : 0.313611 ,train acc: 0.831379 ,val loss : 0.372045 ,val acc : 0.818359\n",
      "[ ecpho : 0  iter :92 ]train loss : 0.294147 ,train acc: 0.789283 ,val loss : 0.372325 ,val acc : 0.832611\n",
      "[ ecpho : 0  iter :93 ]train loss : 0.378358 ,train acc: 0.821173 ,val loss : 0.367764 ,val acc : 0.814392\n",
      "[ ecpho : 0  iter :94 ]train loss : 0.322022 ,train acc: 0.807269 ,val loss : 0.363116 ,val acc : 0.824677\n",
      "[ ecpho : 0  iter :95 ]train loss : 0.288598 ,train acc: 0.830518 ,val loss : 0.359988 ,val acc : 0.834991\n",
      "[ ecpho : 0  iter :96 ]train loss : 0.317158 ,train acc: 0.853675 ,val loss : 0.352059 ,val acc : 0.815735\n",
      "[ ecpho : 0  iter :97 ]train loss : 0.315851 ,train acc: 0.788800 ,val loss : 0.347049 ,val acc : 0.827484\n",
      "[ ecpho : 0  iter :98 ]train loss : 0.253675 ,train acc: 0.844025 ,val loss : 0.349567 ,val acc : 0.839264\n",
      "[ ecpho : 0  iter :99 ]train loss : 0.289053 ,train acc: 0.855433 ,val loss : 0.336651 ,val acc : 0.813782\n",
      "[ ecpho : 0  iter :100 ]train loss : 0.294596 ,train acc: 0.780432 ,val loss : 0.333269 ,val acc : 0.844116\n",
      "[ ecpho : 0  iter :101 ]train loss : 0.353523 ,train acc: 0.837702 ,val loss : 0.323618 ,val acc : 0.829102\n",
      "[ ecpho : 0  iter :102 ]train loss : 0.269594 ,train acc: 0.785498 ,val loss : 0.328182 ,val acc : 0.849243\n",
      "[ ecpho : 0  iter :103 ]train loss : 0.340601 ,train acc: 0.835437 ,val loss : 0.319149 ,val acc : 0.817566\n",
      "[ ecpho : 0  iter :104 ]train loss : 0.270375 ,train acc: 0.773126 ,val loss : 0.316680 ,val acc : 0.847595\n",
      "[ ecpho : 0  iter :105 ]train loss : 0.257508 ,train acc: 0.884992 ,val loss : 0.301410 ,val acc : 0.833313\n",
      "[ ecpho : 0  iter :106 ]train loss : 0.314254 ,train acc: 0.749372 ,val loss : 0.305121 ,val acc : 0.843201\n",
      "[ ecpho : 0  iter :107 ]train loss : 0.243063 ,train acc: 0.858960 ,val loss : 0.309290 ,val acc : 0.844727\n",
      "[ ecpho : 0  iter :108 ]train loss : 0.260947 ,train acc: 0.854969 ,val loss : 0.300867 ,val acc : 0.838806\n",
      "[ ecpho : 0  iter :109 ]train loss : 0.249079 ,train acc: 0.843891 ,val loss : 0.296991 ,val acc : 0.837067\n",
      "[ ecpho : 0  iter :110 ]train loss : 0.238830 ,train acc: 0.840162 ,val loss : 0.292887 ,val acc : 0.861328\n",
      "[ ecpho : 0  iter :111 ]train loss : 0.226064 ,train acc: 0.904237 ,val loss : 0.289130 ,val acc : 0.840698\n",
      "[ ecpho : 0  iter :112 ]train loss : 0.231968 ,train acc: 0.805249 ,val loss : 0.290845 ,val acc : 0.890320\n",
      "[ ecpho : 0  iter :113 ]train loss : 0.293782 ,train acc: 0.903266 ,val loss : 0.311594 ,val acc : 0.797638\n",
      "[ ecpho : 0  iter :114 ]train loss : 0.383076 ,train acc: 0.788404 ,val loss : 0.283685 ,val acc : 0.807617\n",
      "[ ecpho : 0  iter :115 ]train loss : 0.235804 ,train acc: 0.776160 ,val loss : 0.292693 ,val acc : 0.904022\n",
      "[ ecpho : 0  iter :116 ]train loss : 0.287920 ,train acc: 0.910444 ,val loss : 0.268629 ,val acc : 0.879059\n",
      "[ ecpho : 0  iter :117 ]train loss : 0.316607 ,train acc: 0.852997 ,val loss : 0.279597 ,val acc : 0.808746\n",
      "[ ecpho : 0  iter :118 ]train loss : 0.267952 ,train acc: 0.759461 ,val loss : 0.267682 ,val acc : 0.870697\n",
      "[ ecpho : 0  iter :119 ]train loss : 0.265766 ,train acc: 0.826135 ,val loss : 0.273620 ,val acc : 0.899017\n",
      "[ ecpho : 0  iter :120 ]train loss : 0.236647 ,train acc: 0.906556 ,val loss : 0.264416 ,val acc : 0.891388\n",
      "[ ecpho : 0  iter :121 ]train loss : 0.241875 ,train acc: 0.928516 ,val loss : 0.267557 ,val acc : 0.835144\n",
      "[ ecpho : 0  iter :122 ]train loss : 0.229133 ,train acc: 0.788367 ,val loss : 0.257589 ,val acc : 0.878723\n",
      "[ ecpho : 0  iter :123 ]train loss : 0.344265 ,train acc: 0.708685 ,val loss : 0.280823 ,val acc : 0.911438\n",
      "[ ecpho : 0  iter :124 ]train loss : 0.267029 ,train acc: 0.924573 ,val loss : 0.270431 ,val acc : 0.836853\n",
      "[ ecpho : 0  iter :125 ]train loss : 0.279810 ,train acc: 0.764752 ,val loss : 0.268559 ,val acc : 0.846832\n",
      "[ ecpho : 0  iter :126 ]train loss : 0.231199 ,train acc: 0.799872 ,val loss : 0.266953 ,val acc : 0.906189\n",
      "[ ecpho : 0  iter :127 ]train loss : 0.220191 ,train acc: 0.947035 ,val loss : 0.255264 ,val acc : 0.879730\n",
      "[ ecpho : 0  iter :128 ]train loss : 0.312986 ,train acc: 0.796851 ,val loss : 0.256989 ,val acc : 0.854553\n",
      "[ ecpho : 0  iter :129 ]train loss : 0.222107 ,train acc: 0.774353 ,val loss : 0.254920 ,val acc : 0.920624\n",
      "[ ecpho : 0  iter :130 ]train loss : 0.301136 ,train acc: 0.891639 ,val loss : 0.258683 ,val acc : 0.842865\n",
      "[ ecpho : 0  iter :131 ]train loss : 0.230964 ,train acc: 0.754511 ,val loss : 0.249216 ,val acc : 0.905396\n",
      "[ ecpho : 0  iter :132 ]train loss : 0.270489 ,train acc: 0.868775 ,val loss : 0.265015 ,val acc : 0.914764\n",
      "[ ecpho : 0  iter :133 ]train loss : 0.215491 ,train acc: 0.939698 ,val loss : 0.256597 ,val acc : 0.866089\n",
      "[ ecpho : 0  iter :134 ]train loss : 0.230635 ,train acc: 0.796076 ,val loss : 0.257107 ,val acc : 0.901093\n",
      "[ ecpho : 0  iter :135 ]train loss : 0.248767 ,train acc: 0.897993 ,val loss : 0.261825 ,val acc : 0.914307\n",
      "[ ecpho : 0  iter :136 ]train loss : 0.232385 ,train acc: 0.920753 ,val loss : 0.250125 ,val acc : 0.869232\n",
      "[ ecpho : 0  iter :137 ]train loss : 0.224196 ,train acc: 0.798902 ,val loss : 0.247499 ,val acc : 0.924194\n",
      "[ ecpho : 0  iter :138 ]train loss : 0.212471 ,train acc: 0.939887 ,val loss : 0.240834 ,val acc : 0.929749\n",
      "[ ecpho : 0  iter :139 ]train loss : 0.255875 ,train acc: 0.925068 ,val loss : 0.239737 ,val acc : 0.914673\n",
      "[ ecpho : 0  iter :140 ]train loss : 0.220372 ,train acc: 0.881275 ,val loss : 0.243882 ,val acc : 0.933258\n",
      "[ ecpho : 0  iter :141 ]train loss : 0.212892 ,train acc: 0.949104 ,val loss : 0.248160 ,val acc : 0.806549\n",
      "[ ecpho : 0  iter :142 ]train loss : 0.253229 ,train acc: 0.793604 ,val loss : 0.231196 ,val acc : 0.937469\n",
      "[ ecpho : 0  iter :143 ]train loss : 0.297653 ,train acc: 0.819849 ,val loss : 0.281891 ,val acc : 0.917816\n",
      "[ ecpho : 0  iter :144 ]train loss : 0.340584 ,train acc: 0.855780 ,val loss : 0.280838 ,val acc : 0.839294\n",
      "[ ecpho : 0  iter :145 ]train loss : 0.319939 ,train acc: 0.751563 ,val loss : 0.260281 ,val acc : 0.897705\n",
      "[ ecpho : 0  iter :146 ]train loss : 0.256328 ,train acc: 0.835852 ,val loss : 0.273720 ,val acc : 0.914825\n",
      "[ ecpho : 0  iter :147 ]train loss : 0.218383 ,train acc: 0.911134 ,val loss : 0.269363 ,val acc : 0.924164\n",
      "[ ecpho : 0  iter :148 ]train loss : 0.228948 ,train acc: 0.921076 ,val loss : 0.245325 ,val acc : 0.883148\n",
      "[ ecpho : 0  iter :149 ]train loss : 0.276625 ,train acc: 0.793183 ,val loss : 0.245659 ,val acc : 0.914520\n",
      "[ ecpho : 0  iter :150 ]train loss : 0.219041 ,train acc: 0.867402 ,val loss : 0.270027 ,val acc : 0.923645\n",
      "[ ecpho : 0  iter :151 ]train loss : 0.254346 ,train acc: 0.917621 ,val loss : 0.254982 ,val acc : 0.838257\n",
      "[ ecpho : 0  iter :152 ]train loss : 0.314373 ,train acc: 0.765503 ,val loss : 0.269727 ,val acc : 0.836426\n",
      "[ ecpho : 0  iter :153 ]train loss : 0.256521 ,train acc: 0.773712 ,val loss : 0.262877 ,val acc : 0.916687\n",
      "[ ecpho : 0  iter :154 ]train loss : 0.253945 ,train acc: 0.909284 ,val loss : 0.253494 ,val acc : 0.905273\n",
      "[ ecpho : 0  iter :155 ]train loss : 0.284163 ,train acc: 0.801654 ,val loss : 0.271389 ,val acc : 0.885132\n",
      "[ ecpho : 0  iter :156 ]train loss : 0.235750 ,train acc: 0.848389 ,val loss : 0.281881 ,val acc : 0.898254\n",
      "[ ecpho : 0  iter :157 ]train loss : 0.237445 ,train acc: 0.923164 ,val loss : 0.259868 ,val acc : 0.886658\n",
      "[ ecpho : 0  iter :158 ]train loss : 0.228248 ,train acc: 0.839808 ,val loss : 0.245717 ,val acc : 0.923309\n",
      "[ ecpho : 0  iter :159 ]train loss : 0.193615 ,train acc: 0.953461 ,val loss : 0.234523 ,val acc : 0.939270\n",
      "[ ecpho : 0  iter :160 ]train loss : 0.229044 ,train acc: 0.920899 ,val loss : 0.238226 ,val acc : 0.919525\n",
      "[ ecpho : 0  iter :161 ]train loss : 0.263646 ,train acc: 0.795850 ,val loss : 0.264659 ,val acc : 0.916473\n",
      "[ ecpho : 0  iter :162 ]train loss : 0.227312 ,train acc: 0.929279 ,val loss : 0.275090 ,val acc : 0.898651\n",
      "[ ecpho : 0  iter :163 ]train loss : 0.254509 ,train acc: 0.860407 ,val loss : 0.273318 ,val acc : 0.910126\n",
      "[ ecpho : 0  iter :164 ]train loss : 0.244350 ,train acc: 0.918659 ,val loss : 0.269843 ,val acc : 0.844696\n",
      "[ ecpho : 0  iter :165 ]train loss : 0.246299 ,train acc: 0.815259 ,val loss : 0.250439 ,val acc : 0.930389\n",
      "[ ecpho : 0  iter :166 ]train loss : 0.241153 ,train acc: 0.926850 ,val loss : 0.252719 ,val acc : 0.863098\n",
      "[ ecpho : 0  iter :167 ]train loss : 0.263760 ,train acc: 0.761701 ,val loss : 0.242288 ,val acc : 0.927094\n",
      "[ ecpho : 0  iter :168 ]train loss : 0.222732 ,train acc: 0.880939 ,val loss : 0.262840 ,val acc : 0.927521\n",
      "[ ecpho : 0  iter :169 ]train loss : 0.331616 ,train acc: 0.858478 ,val loss : 0.243564 ,val acc : 0.908112\n",
      "[ ecpho : 0  iter :170 ]train loss : 0.270882 ,train acc: 0.814630 ,val loss : 0.262096 ,val acc : 0.884857\n",
      "[ ecpho : 0  iter :171 ]train loss : 0.219512 ,train acc: 0.877833 ,val loss : 0.259098 ,val acc : 0.910309\n",
      "[ ecpho : 0  iter :172 ]train loss : 0.216106 ,train acc: 0.921693 ,val loss : 0.233877 ,val acc : 0.936646\n",
      "[ ecpho : 0  iter :173 ]train loss : 0.205154 ,train acc: 0.912537 ,val loss : 0.215971 ,val acc : 0.958069\n",
      "[ ecpho : 0  iter :174 ]train loss : 0.193214 ,train acc: 0.965730 ,val loss : 0.214632 ,val acc : 0.963226\n",
      "[ ecpho : 0  iter :175 ]train loss : 0.194346 ,train acc: 0.934010 ,val loss : 0.227655 ,val acc : 0.956390\n",
      "[ ecpho : 0  iter :176 ]train loss : 0.228362 ,train acc: 0.929926 ,val loss : 0.231812 ,val acc : 0.863037\n",
      "[ ecpho : 0  iter :177 ]train loss : 0.282608 ,train acc: 0.774774 ,val loss : 0.227119 ,val acc : 0.958038\n",
      "[ ecpho : 0  iter :178 ]train loss : 0.196241 ,train acc: 0.959229 ,val loss : 0.256092 ,val acc : 0.933044\n",
      "[ ecpho : 0  iter :179 ]train loss : 0.264448 ,train acc: 0.888941 ,val loss : 0.238929 ,val acc : 0.861145\n",
      "[ ecpho : 0  iter :180 ]train loss : 0.318216 ,train acc: 0.715772 ,val loss : 0.229945 ,val acc : 0.925262\n",
      "[ ecpho : 0  iter :181 ]train loss : 0.214735 ,train acc: 0.856562 ,val loss : 0.243721 ,val acc : 0.932098\n",
      "[ ecpho : 0  iter :182 ]train loss : 0.349496 ,train acc: 0.814960 ,val loss : 0.244592 ,val acc : 0.929840\n",
      "[ ecpho : 0  iter :183 ]train loss : 0.238786 ,train acc: 0.893671 ,val loss : 0.241295 ,val acc : 0.921722\n",
      "[ ecpho : 0  iter :184 ]train loss : 0.270578 ,train acc: 0.803821 ,val loss : 0.224832 ,val acc : 0.949463\n",
      "[ ecpho : 0  iter :185 ]train loss : 0.216383 ,train acc: 0.932874 ,val loss : 0.223940 ,val acc : 0.960449\n",
      "[ ecpho : 0  iter :186 ]train loss : 0.182681 ,train acc: 0.961512 ,val loss : 0.208616 ,val acc : 0.968842\n",
      "[ ecpho : 0  iter :187 ]train loss : 0.273646 ,train acc: 0.947511 ,val loss : 0.210451 ,val acc : 0.968170\n",
      "[ ecpho : 0  iter :188 ]train loss : 0.183558 ,train acc: 0.973915 ,val loss : 0.200658 ,val acc : 0.970947\n",
      "[ ecpho : 0  iter :189 ]train loss : 0.208553 ,train acc: 0.942481 ,val loss : 0.211708 ,val acc : 0.955566\n",
      "[ ecpho : 0  iter :190 ]train loss : 0.224227 ,train acc: 0.927729 ,val loss : 0.206779 ,val acc : 0.970123\n",
      "[ ecpho : 0  iter :191 ]train loss : 0.200849 ,train acc: 0.943238 ,val loss : 0.205366 ,val acc : 0.963104\n",
      "[ ecpho : 0  iter :192 ]train loss : 0.166299 ,train acc: 0.970985 ,val loss : 0.213757 ,val acc : 0.960175\n",
      "[ ecpho : 0  iter :193 ]train loss : 0.203208 ,train acc: 0.936427 ,val loss : 0.203758 ,val acc : 0.976074\n",
      "[ ecpho : 0  iter :194 ]train loss : 0.178274 ,train acc: 0.981117 ,val loss : 0.212021 ,val acc : 0.964722\n",
      "[ ecpho : 0  iter :195 ]train loss : 0.157076 ,train acc: 0.978626 ,val loss : 0.213559 ,val acc : 0.977448\n",
      "[ ecpho : 0  iter :196 ]train loss : 0.196377 ,train acc: 0.945564 ,val loss : 0.202776 ,val acc : 0.974915\n",
      "[ ecpho : 0  iter :197 ]train loss : 0.147277 ,train acc: 0.989918 ,val loss : 0.200048 ,val acc : 0.964050\n",
      "[ ecpho : 0  iter :198 ]train loss : 0.187276 ,train acc: 0.951807 ,val loss : 0.195872 ,val acc : 0.979523\n",
      "[ ecpho : 0  iter :199 ]train loss : 0.174156 ,train acc: 0.979334 ,val loss : 0.190115 ,val acc : 0.974030\n",
      "[ ecpho : 0  iter :200 ]train loss : 0.188942 ,train acc: 0.962452 ,val loss : 0.192878 ,val acc : 0.971985\n",
      "=============================================\n",
      "[ 0 ] average train loss : 0.368063 train acc : 0.795610\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "data_files = glob.glob('../unet_3d_traindata/*_data_*.npy')\n",
    "valdata_files = glob.glob('../unet_3d_valdata/*_data_*.npy')\n",
    "\n",
    "np.random.shuffle(data_files)\n",
    "np.random.shuffle(data_files)\n",
    "np.random.shuffle(valdata_files)\n",
    "train_datafiles = data_files[:]\n",
    "val_datafiles = valdata_files[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ecpho in range(1):\n",
    "    iteration = 0\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    #tmp_tranfiles = train_datafiles[ecpho*5000:(ecpho + 1)*5000]\n",
    "    tmp_tranfiles = np.random.choice(train_datafiles,1000)\n",
    "    for idx in np.arange(0,len(tmp_tranfiles),5):\n",
    "        iteration += 1\n",
    "        tmp_files = tmp_tranfiles[idx:idx+5]\n",
    "        train_datas = []\n",
    "        train_labels = []\n",
    "        for train_datafile in tmp_files:\n",
    "            train_data = np.load(train_datafile)\n",
    "            train_label = np.load(train_datafile.replace('_data_','_label_'))\n",
    "            train_norm = (train_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            train_norm[train_norm > 1] = 1\n",
    "            train_norm[train_norm < 0] = 0\n",
    "            train_datas.append(train_norm)\n",
    "            train_labels.append(train_label)\n",
    "        \n",
    "        train_datas = np.array(train_datas)\n",
    "        train_labels = np.array(train_labels)\n",
    "        _,train_cost,train_output_shape,train_acc,ws = sess.run([optimizer,cost,logits_shape,accuracy,weights],\n",
    "                                       feed_dict={input_x:train_datas,input_y:train_labels,keep_prob:0.5})\n",
    "        train_loss.append(train_cost)\n",
    "        train_accs.append(train_acc)\n",
    "        val_costs = []\n",
    "        val_accs = []\n",
    "        for val_datafile in val_datafiles[:10]:\n",
    "            val_data = np.load(val_datafile)\n",
    "            val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            val_norm[val_norm > 1] = 1\n",
    "            val_norm[val_norm < 0] = 0\n",
    "            val_norm = np.reshape(val_norm,[1,64,64,64])\n",
    "            val_label = np.load(val_datafiles[0].replace('_data_','_label_'))\n",
    "            val_label = np.reshape(val_label,[1,32,32,32,2])\n",
    "            val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                           feed_dict={input_x:val_norm,input_y:val_label,keep_prob:0.5})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accs.append(val_acc)\n",
    "        print('[ ecpho : %d  iter :%d ]train loss : %f ,train acc: %f ,val loss : %f ,val acc : %f' % (ecpho,iteration,train_cost,train_acc,np.mean(val_cost),np.mean(val_acc)))\n",
    "    print(\"=============================================\")\n",
    "    print(\"[ %d ] average train loss : %f train acc : %f\" % (ecpho,np.mean(train_loss),np.mean(train_accs)))\n",
    "    \n",
    "    modelpath = './unet3d_models_7/ecpho_'+str(ecpho+9)\n",
    "    if not os.path.exists(modelpath):\n",
    "        os.mkdir(modelpath)\n",
    "    saver.save(sess,modelpath+'/unet3d_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.598791 ,val acc : 0.652466\n",
      "val loss: 0.597984 ,val acc : 0.654236\n",
      "val loss: 0.598413 ,val acc : 0.653625\n",
      "val loss: 0.597399 ,val acc : 0.651672\n",
      "val loss: 0.599315 ,val acc : 0.651276\n",
      "val loss: 0.592774 ,val acc : 0.655731\n",
      "val loss: 0.597739 ,val acc : 0.651093\n",
      "val loss: 0.607238 ,val acc : 0.649933\n",
      "val loss: 0.603403 ,val acc : 0.650604\n",
      "val loss: 0.589720 ,val acc : 0.655182\n",
      "val loss: 0.599727 ,val acc : 0.650299\n",
      "val loss: 0.593633 ,val acc : 0.656891\n",
      "val loss: 0.595074 ,val acc : 0.649384\n",
      "val loss: 0.604537 ,val acc : 0.647888\n",
      "val loss: 0.586376 ,val acc : 0.650024\n",
      "val loss: 0.593210 ,val acc : 0.656433\n",
      "val loss: 0.599938 ,val acc : 0.649475\n",
      "val loss: 0.606407 ,val acc : 0.650726\n",
      "val loss: 0.595188 ,val acc : 0.651794\n",
      "val loss: 0.597037 ,val acc : 0.649902\n",
      "0.597037 0.649902\n",
      "train loss : 0.600011 ,train acc: 0.649750 ,val loss : 0.588701 ,val acc : 0.649506\n",
      "train loss : 0.596491 ,train acc: 0.649780 ,val loss : 0.587578 ,val acc : 0.650696\n",
      "train loss : 0.611604 ,train acc: 0.644684 ,val loss : 0.585364 ,val acc : 0.654663\n",
      "train loss : 0.668416 ,train acc: 0.535431 ,val loss : 0.587483 ,val acc : 0.652802\n",
      "train loss : 0.589159 ,train acc: 0.654694 ,val loss : 0.590169 ,val acc : 0.656708\n",
      "train loss : 0.602397 ,train acc: 0.641418 ,val loss : 0.586088 ,val acc : 0.653656\n",
      "train loss : 0.590177 ,train acc: 0.654053 ,val loss : 0.579827 ,val acc : 0.657227\n",
      "train loss : 0.583559 ,train acc: 0.659271 ,val loss : 0.573700 ,val acc : 0.658203\n",
      "train loss : 0.604942 ,train acc: 0.649475 ,val loss : 0.578421 ,val acc : 0.657532\n",
      "train loss : 0.569582 ,train acc: 0.657959 ,val loss : 0.577293 ,val acc : 0.660919\n",
      "train loss : 0.569979 ,train acc: 0.660522 ,val loss : 0.564893 ,val acc : 0.665497\n",
      "train loss : 0.553357 ,train acc: 0.662354 ,val loss : 0.571787 ,val acc : 0.664246\n",
      "train loss : 0.559224 ,train acc: 0.663696 ,val loss : 0.556118 ,val acc : 0.668396\n",
      "train loss : 0.564056 ,train acc: 0.659943 ,val loss : 0.553382 ,val acc : 0.668213\n",
      "train loss : 0.550268 ,train acc: 0.661926 ,val loss : 0.551729 ,val acc : 0.670013\n",
      "train loss : 0.547557 ,train acc: 0.666626 ,val loss : 0.555281 ,val acc : 0.664886\n",
      "train loss : 0.563422 ,train acc: 0.658264 ,val loss : 0.546649 ,val acc : 0.670380\n",
      "train loss : 0.594729 ,train acc: 0.582031 ,val loss : 0.543764 ,val acc : 0.674286\n",
      "train loss : 0.554332 ,train acc: 0.668701 ,val loss : 0.534696 ,val acc : 0.673584\n",
      "train loss : 0.544333 ,train acc: 0.669189 ,val loss : 0.542513 ,val acc : 0.670593\n",
      "train loss : 0.544954 ,train acc: 0.667938 ,val loss : 0.533465 ,val acc : 0.789795\n",
      "train loss : 0.579426 ,train acc: 0.617065 ,val loss : 0.533818 ,val acc : 0.791809\n",
      "train loss : 0.547353 ,train acc: 0.786804 ,val loss : 0.528723 ,val acc : 0.791565\n",
      "train loss : 0.522138 ,train acc: 0.791321 ,val loss : 0.536657 ,val acc : 0.790161\n",
      "train loss : 0.523753 ,train acc: 0.794159 ,val loss : 0.534433 ,val acc : 0.789368\n",
      "train loss : 0.540238 ,train acc: 0.777405 ,val loss : 0.520901 ,val acc : 0.794952\n",
      "train loss : 0.539118 ,train acc: 0.785980 ,val loss : 0.526357 ,val acc : 0.790283\n",
      "train loss : 0.525863 ,train acc: 0.795258 ,val loss : 0.520703 ,val acc : 0.791748\n",
      "train loss : 0.513087 ,train acc: 0.797150 ,val loss : 0.517699 ,val acc : 0.792999\n",
      "train loss : 0.510195 ,train acc: 0.792267 ,val loss : 0.512324 ,val acc : 0.796021\n",
      "train loss : 0.533252 ,train acc: 0.781128 ,val loss : 0.512784 ,val acc : 0.794403\n",
      "train loss : 0.492834 ,train acc: 0.796661 ,val loss : 0.513074 ,val acc : 0.795593\n",
      "train loss : 0.507226 ,train acc: 0.800659 ,val loss : 0.506812 ,val acc : 0.792938\n",
      "train loss : 0.509325 ,train acc: 0.795898 ,val loss : 0.499800 ,val acc : 0.796295\n",
      "train loss : 0.515824 ,train acc: 0.794739 ,val loss : 0.503382 ,val acc : 0.797546\n",
      "train loss : 0.545883 ,train acc: 0.755371 ,val loss : 0.500348 ,val acc : 0.797211\n",
      "train loss : 0.503080 ,train acc: 0.793182 ,val loss : 0.497397 ,val acc : 0.796783\n",
      "train loss : 0.526533 ,train acc: 0.784302 ,val loss : 0.498045 ,val acc : 0.797119\n",
      "train loss : 0.544211 ,train acc: 0.755798 ,val loss : 0.491194 ,val acc : 0.799469\n",
      "train loss : 0.491681 ,train acc: 0.801727 ,val loss : 0.492436 ,val acc : 0.798126\n",
      "train loss : 0.498191 ,train acc: 0.790924 ,val loss : 0.488142 ,val acc : 0.798767\n",
      "train loss : 0.554058 ,train acc: 0.454956 ,val loss : 0.490479 ,val acc : 0.797791\n",
      "train loss : 0.483316 ,train acc: 0.800201 ,val loss : 0.486006 ,val acc : 0.798889\n",
      "train loss : 0.483707 ,train acc: 0.799988 ,val loss : 0.476844 ,val acc : 0.802032\n",
      "train loss : 0.498403 ,train acc: 0.799072 ,val loss : 0.480134 ,val acc : 0.801483\n",
      "train loss : 0.483301 ,train acc: 0.799164 ,val loss : 0.473098 ,val acc : 0.803497\n",
      "train loss : 0.494568 ,train acc: 0.788422 ,val loss : 0.476968 ,val acc : 0.799835\n",
      "train loss : 0.501109 ,train acc: 0.793518 ,val loss : 0.472189 ,val acc : 0.801544\n",
      "train loss : 0.487555 ,train acc: 0.789703 ,val loss : 0.470773 ,val acc : 0.804413\n",
      "train loss : 0.466482 ,train acc: 0.806976 ,val loss : 0.463987 ,val acc : 0.804077\n",
      "train loss : 0.513963 ,train acc: 0.754669 ,val loss : 0.467759 ,val acc : 0.804077\n",
      "train loss : 0.512923 ,train acc: 0.747986 ,val loss : 0.466006 ,val acc : 0.803986\n",
      "train loss : 0.462459 ,train acc: 0.804138 ,val loss : 0.454382 ,val acc : 0.806793\n",
      "train loss : 0.476163 ,train acc: 0.804718 ,val loss : 0.461296 ,val acc : 0.801971\n",
      "train loss : 0.470233 ,train acc: 0.802399 ,val loss : 0.458921 ,val acc : 0.804199\n",
      "train loss : 0.450504 ,train acc: 0.805511 ,val loss : 0.452026 ,val acc : 0.803894\n",
      "train loss : 0.477235 ,train acc: 0.804932 ,val loss : 0.443952 ,val acc : 0.810150\n",
      "train loss : 0.471041 ,train acc: 0.796967 ,val loss : 0.448543 ,val acc : 0.807526\n",
      "train loss : 0.466432 ,train acc: 0.776672 ,val loss : 0.445652 ,val acc : 0.810150\n",
      "train loss : 0.443591 ,train acc: 0.810181 ,val loss : 0.440981 ,val acc : 0.811615\n",
      "train loss : 0.448075 ,train acc: 0.812683 ,val loss : 0.441678 ,val acc : 0.806458\n",
      "train loss : 0.432664 ,train acc: 0.814789 ,val loss : 0.436163 ,val acc : 0.808868\n",
      "train loss : 0.433082 ,train acc: 0.812927 ,val loss : 0.440642 ,val acc : 0.808136\n",
      "train loss : 0.441967 ,train acc: 0.771790 ,val loss : 0.429171 ,val acc : 0.812042\n",
      "train loss : 0.442992 ,train acc: 0.808014 ,val loss : 0.423466 ,val acc : 0.815186\n",
      "train loss : 0.456644 ,train acc: 0.805420 ,val loss : 0.428860 ,val acc : 0.811157\n",
      "train loss : 0.449556 ,train acc: 0.807617 ,val loss : 0.423107 ,val acc : 0.816101\n",
      "train loss : 0.416818 ,train acc: 0.819550 ,val loss : 0.421337 ,val acc : 0.813782\n",
      "train loss : 0.436838 ,train acc: 0.801147 ,val loss : 0.414836 ,val acc : 0.816956\n",
      "train loss : 0.416332 ,train acc: 0.821899 ,val loss : 0.419700 ,val acc : 0.815796\n",
      "train loss : 0.424015 ,train acc: 0.819366 ,val loss : 0.416586 ,val acc : 0.813385\n",
      "train loss : 0.414769 ,train acc: 0.816650 ,val loss : 0.413979 ,val acc : 0.815826\n",
      "train loss : 0.432215 ,train acc: 0.813141 ,val loss : 0.409700 ,val acc : 0.815277\n",
      "train loss : 0.425708 ,train acc: 0.813324 ,val loss : 0.403909 ,val acc : 0.819763\n",
      "train loss : 0.410077 ,train acc: 0.817535 ,val loss : 0.403331 ,val acc : 0.819305\n",
      "train loss : 0.469684 ,train acc: 0.616455 ,val loss : 0.394036 ,val acc : 0.826569\n",
      "train loss : 0.446692 ,train acc: 0.498993 ,val loss : 0.403363 ,val acc : 0.820374\n",
      "train loss : 0.440310 ,train acc: 0.805481 ,val loss : 0.397369 ,val acc : 0.824005\n",
      "train loss : 0.399182 ,train acc: 0.823639 ,val loss : 0.394885 ,val acc : 0.825500\n",
      "train loss : 0.404931 ,train acc: 0.827820 ,val loss : 0.391712 ,val acc : 0.827087\n",
      "train loss : 0.411757 ,train acc: 0.807098 ,val loss : 0.390895 ,val acc : 0.824951\n",
      "train loss : 0.429141 ,train acc: 0.745819 ,val loss : 0.387707 ,val acc : 0.829346\n",
      "train loss : 0.394920 ,train acc: 0.824249 ,val loss : 0.385863 ,val acc : 0.829681\n",
      "train loss : 0.403056 ,train acc: 0.827271 ,val loss : 0.379559 ,val acc : 0.830963\n",
      "train loss : 0.403793 ,train acc: 0.819611 ,val loss : 0.378768 ,val acc : 0.828979\n",
      "train loss : 0.425436 ,train acc: 0.807312 ,val loss : 0.379169 ,val acc : 0.830383\n",
      "train loss : 0.388027 ,train acc: 0.816803 ,val loss : 0.375972 ,val acc : 0.831116\n",
      "train loss : 0.351202 ,train acc: 0.840088 ,val loss : 0.370292 ,val acc : 0.837433\n",
      "train loss : 0.371725 ,train acc: 0.827728 ,val loss : 0.376693 ,val acc : 0.829529\n",
      "train loss : 0.372286 ,train acc: 0.838928 ,val loss : 0.361415 ,val acc : 0.835358\n",
      "train loss : 0.373131 ,train acc: 0.827911 ,val loss : 0.362771 ,val acc : 0.835266\n",
      "train loss : 0.392380 ,train acc: 0.820190 ,val loss : 0.358148 ,val acc : 0.834351\n",
      "train loss : 0.376550 ,train acc: 0.830994 ,val loss : 0.351638 ,val acc : 0.838013\n",
      "train loss : 0.397225 ,train acc: 0.821350 ,val loss : 0.359044 ,val acc : 0.837006\n",
      "train loss : 0.374641 ,train acc: 0.834137 ,val loss : 0.349689 ,val acc : 0.840942\n",
      "train loss : 0.359558 ,train acc: 0.735992 ,val loss : 0.356616 ,val acc : 0.833374\n",
      "train loss : 0.397714 ,train acc: 0.822418 ,val loss : 0.351758 ,val acc : 0.836639\n",
      "train loss : 0.346262 ,train acc: 0.839355 ,val loss : 0.346336 ,val acc : 0.840210\n",
      "train loss : 0.331842 ,train acc: 0.844757 ,val loss : 0.344339 ,val acc : 0.840027\n",
      "train loss : 0.558262 ,train acc: 0.198212 ,val loss : 0.341811 ,val acc : 0.841217\n",
      "train loss : 0.361264 ,train acc: 0.841431 ,val loss : 0.338392 ,val acc : 0.842682\n",
      "train loss : 0.346277 ,train acc: 0.836182 ,val loss : 0.335769 ,val acc : 0.844208\n",
      "train loss : 0.368192 ,train acc: 0.842255 ,val loss : 0.337239 ,val acc : 0.841644\n",
      "train loss : 0.341510 ,train acc: 0.851227 ,val loss : 0.333330 ,val acc : 0.841827\n",
      "train loss : 0.394520 ,train acc: 0.824127 ,val loss : 0.334068 ,val acc : 0.842285\n",
      "train loss : 0.380088 ,train acc: 0.824493 ,val loss : 0.328093 ,val acc : 0.844879\n",
      "train loss : 0.356435 ,train acc: 0.829407 ,val loss : 0.327950 ,val acc : 0.845337\n",
      "train loss : 0.374294 ,train acc: 0.833435 ,val loss : 0.326248 ,val acc : 0.846069\n",
      "train loss : 0.359390 ,train acc: 0.832581 ,val loss : 0.327992 ,val acc : 0.844666\n",
      "train loss : 0.409916 ,train acc: 0.745605 ,val loss : 0.323050 ,val acc : 0.845306\n",
      "train loss : 0.314462 ,train acc: 0.853424 ,val loss : 0.320228 ,val acc : 0.844604\n",
      "train loss : 0.364451 ,train acc: 0.833618 ,val loss : 0.322043 ,val acc : 0.844971\n",
      "train loss : 0.324190 ,train acc: 0.841156 ,val loss : 0.321597 ,val acc : 0.848389\n",
      "train loss : 0.351404 ,train acc: 0.837006 ,val loss : 0.319452 ,val acc : 0.844666\n",
      "train loss : 0.361736 ,train acc: 0.807098 ,val loss : 0.316797 ,val acc : 0.848053\n",
      "train loss : 0.371861 ,train acc: 0.796906 ,val loss : 0.310765 ,val acc : 0.849457\n",
      "train loss : 0.290947 ,train acc: 0.806122 ,val loss : 0.308829 ,val acc : 0.852875\n",
      "train loss : 0.296197 ,train acc: 0.855377 ,val loss : 0.311180 ,val acc : 0.851379\n",
      "train loss : 0.415858 ,train acc: 0.544159 ,val loss : 0.306639 ,val acc : 0.854187\n",
      "train loss : 0.338447 ,train acc: 0.827911 ,val loss : 0.306146 ,val acc : 0.856964\n",
      "train loss : 0.344939 ,train acc: 0.845886 ,val loss : 0.312079 ,val acc : 0.851715\n",
      "train loss : 0.329863 ,train acc: 0.817505 ,val loss : 0.304208 ,val acc : 0.856903\n",
      "train loss : 0.322409 ,train acc: 0.845367 ,val loss : 0.302290 ,val acc : 0.856598\n",
      "train loss : 0.317530 ,train acc: 0.851624 ,val loss : 0.308437 ,val acc : 0.850891\n",
      "train loss : 0.334506 ,train acc: 0.841156 ,val loss : 0.295670 ,val acc : 0.860260\n",
      "train loss : 0.321997 ,train acc: 0.762787 ,val loss : 0.298984 ,val acc : 0.854065\n",
      "train loss : 0.338385 ,train acc: 0.623657 ,val loss : 0.298626 ,val acc : 0.858734\n",
      "train loss : 0.339589 ,train acc: 0.833588 ,val loss : 0.300751 ,val acc : 0.861206\n",
      "train loss : 0.316462 ,train acc: 0.847229 ,val loss : 0.296899 ,val acc : 0.865662\n",
      "train loss : 0.333319 ,train acc: 0.849854 ,val loss : 0.293757 ,val acc : 0.864349\n",
      "train loss : 0.318895 ,train acc: 0.848389 ,val loss : 0.294640 ,val acc : 0.864929\n",
      "train loss : 0.353897 ,train acc: 0.819183 ,val loss : 0.294331 ,val acc : 0.862457\n",
      "train loss : 0.310211 ,train acc: 0.842377 ,val loss : 0.293026 ,val acc : 0.863617\n",
      "train loss : 0.321574 ,train acc: 0.858398 ,val loss : 0.285367 ,val acc : 0.866486\n",
      "train loss : 0.335052 ,train acc: 0.688080 ,val loss : 0.291028 ,val acc : 0.864136\n",
      "train loss : 0.311162 ,train acc: 0.826996 ,val loss : 0.288995 ,val acc : 0.864777\n",
      "train loss : 0.301330 ,train acc: 0.847412 ,val loss : 0.284674 ,val acc : 0.864929\n",
      "train loss : 0.297852 ,train acc: 0.863281 ,val loss : 0.288382 ,val acc : 0.861694\n",
      "train loss : 0.310048 ,train acc: 0.858917 ,val loss : 0.278090 ,val acc : 0.864929\n",
      "train loss : 0.293709 ,train acc: 0.854431 ,val loss : 0.284247 ,val acc : 0.863251\n",
      "train loss : 0.364627 ,train acc: 0.794617 ,val loss : 0.281916 ,val acc : 0.863190\n",
      "train loss : 0.289569 ,train acc: 0.853699 ,val loss : 0.277797 ,val acc : 0.866302\n",
      "train loss : 0.319305 ,train acc: 0.851471 ,val loss : 0.278969 ,val acc : 0.861938\n",
      "train loss : 0.365325 ,train acc: 0.832733 ,val loss : 0.278888 ,val acc : 0.861664\n",
      "train loss : 0.283072 ,train acc: 0.853027 ,val loss : 0.274044 ,val acc : 0.863678\n",
      "train loss : 0.332565 ,train acc: 0.829956 ,val loss : 0.276847 ,val acc : 0.860229\n",
      "train loss : 0.280200 ,train acc: 0.859985 ,val loss : 0.269198 ,val acc : 0.865479\n",
      "train loss : 0.371302 ,train acc: 0.822754 ,val loss : 0.271043 ,val acc : 0.864410\n",
      "train loss : 0.392211 ,train acc: 0.500092 ,val loss : 0.272045 ,val acc : 0.864532\n",
      "train loss : 0.356904 ,train acc: 0.635315 ,val loss : 0.270585 ,val acc : 0.867157\n",
      "train loss : 0.284392 ,train acc: 0.870239 ,val loss : 0.274749 ,val acc : 0.867950\n",
      "train loss : 0.289884 ,train acc: 0.868256 ,val loss : 0.272602 ,val acc : 0.868622\n",
      "train loss : 0.268690 ,train acc: 0.874420 ,val loss : 0.268063 ,val acc : 0.870422\n",
      "train loss : 0.295574 ,train acc: 0.862579 ,val loss : 0.266341 ,val acc : 0.871155\n",
      "train loss : 0.299335 ,train acc: 0.858612 ,val loss : 0.266289 ,val acc : 0.870209\n",
      "train loss : 0.311067 ,train acc: 0.853333 ,val loss : 0.267256 ,val acc : 0.867462\n",
      "train loss : 0.303345 ,train acc: 0.846649 ,val loss : 0.267446 ,val acc : 0.867340\n",
      "train loss : 0.366577 ,train acc: 0.827728 ,val loss : 0.262162 ,val acc : 0.869019\n",
      "train loss : 0.331110 ,train acc: 0.715790 ,val loss : 0.262145 ,val acc : 0.868988\n",
      "train loss : 0.272071 ,train acc: 0.868225 ,val loss : 0.261120 ,val acc : 0.871735\n",
      "train loss : 0.286026 ,train acc: 0.855743 ,val loss : 0.262670 ,val acc : 0.865326\n",
      "train loss : 0.233964 ,train acc: 0.880463 ,val loss : 0.260367 ,val acc : 0.869049\n",
      "train loss : 0.321586 ,train acc: 0.801544 ,val loss : 0.261092 ,val acc : 0.864838\n",
      "train loss : 0.274540 ,train acc: 0.859711 ,val loss : 0.259780 ,val acc : 0.871979\n",
      "train loss : 0.275763 ,train acc: 0.867462 ,val loss : 0.260739 ,val acc : 0.868591\n",
      "train loss : 0.245300 ,train acc: 0.877655 ,val loss : 0.256499 ,val acc : 0.872986\n",
      "train loss : 0.260544 ,train acc: 0.862854 ,val loss : 0.254716 ,val acc : 0.872375\n",
      "train loss : 0.293454 ,train acc: 0.829498 ,val loss : 0.252613 ,val acc : 0.874603\n",
      "train loss : 0.233725 ,train acc: 0.880707 ,val loss : 0.250465 ,val acc : 0.873901\n",
      "train loss : 0.264173 ,train acc: 0.861206 ,val loss : 0.249352 ,val acc : 0.873108\n",
      "train loss : 0.286535 ,train acc: 0.857635 ,val loss : 0.252640 ,val acc : 0.870972\n",
      "train loss : 0.245079 ,train acc: 0.876068 ,val loss : 0.249782 ,val acc : 0.873657\n",
      "train loss : 0.323871 ,train acc: 0.797546 ,val loss : 0.249629 ,val acc : 0.874115\n",
      "train loss : 0.369971 ,train acc: 0.765869 ,val loss : 0.247578 ,val acc : 0.878235\n",
      "train loss : 0.542090 ,train acc: 0.266174 ,val loss : 0.250722 ,val acc : 0.875092\n",
      "train loss : 0.526185 ,train acc: 0.344116 ,val loss : 0.250232 ,val acc : 0.876343\n",
      "train loss : 0.223858 ,train acc: 0.890900 ,val loss : 0.247402 ,val acc : 0.880402\n",
      "train loss : 0.347498 ,train acc: 0.829773 ,val loss : 0.248686 ,val acc : 0.878418\n",
      "train loss : 0.310074 ,train acc: 0.734741 ,val loss : 0.249661 ,val acc : 0.877228\n",
      "train loss : 0.248843 ,train acc: 0.873840 ,val loss : 0.250054 ,val acc : 0.881897\n",
      "train loss : 0.575108 ,train acc: 0.341644 ,val loss : 0.251550 ,val acc : 0.882355\n",
      "train loss : 0.261679 ,train acc: 0.840759 ,val loss : 0.245588 ,val acc : 0.884369\n",
      "train loss : 0.269187 ,train acc: 0.836456 ,val loss : 0.249270 ,val acc : 0.881287\n",
      "train loss : 0.266288 ,train acc: 0.831787 ,val loss : 0.246582 ,val acc : 0.884216\n",
      "train loss : 0.355750 ,train acc: 0.832092 ,val loss : 0.247659 ,val acc : 0.882507\n",
      "train loss : 0.268915 ,train acc: 0.876465 ,val loss : 0.248559 ,val acc : 0.879364\n",
      "train loss : 0.293716 ,train acc: 0.708405 ,val loss : 0.242785 ,val acc : 0.885284\n",
      "train loss : 0.255001 ,train acc: 0.883179 ,val loss : 0.248118 ,val acc : 0.881531\n",
      "train loss : 0.240782 ,train acc: 0.890930 ,val loss : 0.248070 ,val acc : 0.881744\n",
      "train loss : 0.241692 ,train acc: 0.889374 ,val loss : 0.241535 ,val acc : 0.882202\n",
      "train loss : 0.231281 ,train acc: 0.887726 ,val loss : 0.243744 ,val acc : 0.880035\n",
      "train loss : 0.279862 ,train acc: 0.833221 ,val loss : 0.241122 ,val acc : 0.882172\n",
      "train loss : 0.297628 ,train acc: 0.801453 ,val loss : 0.239664 ,val acc : 0.882294\n",
      "train loss : 0.283991 ,train acc: 0.861145 ,val loss : 0.237876 ,val acc : 0.883423\n",
      "train loss : 0.305756 ,train acc: 0.740479 ,val loss : 0.237873 ,val acc : 0.881836\n",
      "train loss : 0.254839 ,train acc: 0.864441 ,val loss : 0.235252 ,val acc : 0.885651\n",
      "train loss : 0.283729 ,train acc: 0.867554 ,val loss : 0.237363 ,val acc : 0.884888\n",
      "train loss : 0.254734 ,train acc: 0.868683 ,val loss : 0.235196 ,val acc : 0.885437\n",
      "train loss : 0.494568 ,train acc: 0.703918 ,val loss : 0.234900 ,val acc : 0.885895\n",
      "train loss : 0.219568 ,train acc: 0.891693 ,val loss : 0.235316 ,val acc : 0.882080\n",
      "train loss : 0.217678 ,train acc: 0.893982 ,val loss : 0.239571 ,val acc : 0.880432\n",
      "train loss : 0.337463 ,train acc: 0.658600 ,val loss : 0.237386 ,val acc : 0.883545\n",
      "train loss : 0.248749 ,train acc: 0.842224 ,val loss : 0.236045 ,val acc : 0.889160\n",
      "train loss : 0.228803 ,train acc: 0.885681 ,val loss : 0.236178 ,val acc : 0.884491\n",
      "train loss : 0.236899 ,train acc: 0.882904 ,val loss : 0.232331 ,val acc : 0.886993\n",
      "train loss : 0.284260 ,train acc: 0.866028 ,val loss : 0.232983 ,val acc : 0.888458\n",
      "train loss : 0.235449 ,train acc: 0.883331 ,val loss : 0.232840 ,val acc : 0.886841\n",
      "train loss : 0.253583 ,train acc: 0.876892 ,val loss : 0.228939 ,val acc : 0.890747\n",
      "train loss : 0.286756 ,train acc: 0.817841 ,val loss : 0.227666 ,val acc : 0.887085\n",
      "train loss : 0.314774 ,train acc: 0.859894 ,val loss : 0.230616 ,val acc : 0.885651\n",
      "train loss : 0.204937 ,train acc: 0.898438 ,val loss : 0.227473 ,val acc : 0.886993\n",
      "train loss : 0.295493 ,train acc: 0.854431 ,val loss : 0.228077 ,val acc : 0.887482\n",
      "train loss : 0.236330 ,train acc: 0.879089 ,val loss : 0.225194 ,val acc : 0.888855\n",
      "train loss : 0.219650 ,train acc: 0.885773 ,val loss : 0.225656 ,val acc : 0.889526\n",
      "train loss : 0.374275 ,train acc: 0.660797 ,val loss : 0.225931 ,val acc : 0.888428\n",
      "train loss : 0.647015 ,train acc: 0.312073 ,val loss : 0.227061 ,val acc : 0.889648\n",
      "train loss : 0.294097 ,train acc: 0.807373 ,val loss : 0.222699 ,val acc : 0.893372\n",
      "train loss : 0.255311 ,train acc: 0.872345 ,val loss : 0.226444 ,val acc : 0.888245\n",
      "train loss : 0.268800 ,train acc: 0.860504 ,val loss : 0.224261 ,val acc : 0.890747\n",
      "train loss : 0.270906 ,train acc: 0.765747 ,val loss : 0.224673 ,val acc : 0.894104\n",
      "train loss : 0.227402 ,train acc: 0.889954 ,val loss : 0.226592 ,val acc : 0.891083\n",
      "train loss : 0.263026 ,train acc: 0.876099 ,val loss : 0.224978 ,val acc : 0.891754\n",
      "train loss : 0.261823 ,train acc: 0.861542 ,val loss : 0.223237 ,val acc : 0.892273\n",
      "train loss : 0.231922 ,train acc: 0.882141 ,val loss : 0.220950 ,val acc : 0.893158\n",
      "train loss : 0.218331 ,train acc: 0.890350 ,val loss : 0.223092 ,val acc : 0.890656\n",
      "train loss : 0.268893 ,train acc: 0.870758 ,val loss : 0.221866 ,val acc : 0.890503\n",
      "train loss : 0.325986 ,train acc: 0.735382 ,val loss : 0.220040 ,val acc : 0.894257\n",
      "train loss : 0.352241 ,train acc: 0.829926 ,val loss : 0.222272 ,val acc : 0.890198\n",
      "train loss : 0.292647 ,train acc: 0.859406 ,val loss : 0.220502 ,val acc : 0.892151\n",
      "train loss : 0.202717 ,train acc: 0.901306 ,val loss : 0.217113 ,val acc : 0.892273\n",
      "train loss : 0.228474 ,train acc: 0.876251 ,val loss : 0.218099 ,val acc : 0.894196\n",
      "train loss : 0.388269 ,train acc: 0.492340 ,val loss : 0.220904 ,val acc : 0.892242\n",
      "train loss : 0.223567 ,train acc: 0.885071 ,val loss : 0.220538 ,val acc : 0.896515\n",
      "train loss : 0.246770 ,train acc: 0.876312 ,val loss : 0.219547 ,val acc : 0.898010\n",
      "train loss : 0.253783 ,train acc: 0.865845 ,val loss : 0.218262 ,val acc : 0.896118\n",
      "train loss : 0.254228 ,train acc: 0.879120 ,val loss : 0.220108 ,val acc : 0.896759\n",
      "train loss : 0.299117 ,train acc: 0.869141 ,val loss : 0.215831 ,val acc : 0.897308\n",
      "train loss : 0.330225 ,train acc: 0.837067 ,val loss : 0.216624 ,val acc : 0.896576\n",
      "train loss : 0.406104 ,train acc: 0.553894 ,val loss : 0.216401 ,val acc : 0.898071\n",
      "train loss : 0.252612 ,train acc: 0.841797 ,val loss : 0.215570 ,val acc : 0.900970\n",
      "train loss : 0.235185 ,train acc: 0.891724 ,val loss : 0.216380 ,val acc : 0.901459\n",
      "train loss : 0.239564 ,train acc: 0.884613 ,val loss : 0.213393 ,val acc : 0.901917\n",
      "train loss : 0.254955 ,train acc: 0.884552 ,val loss : 0.217731 ,val acc : 0.899780\n",
      "train loss : 0.214312 ,train acc: 0.903809 ,val loss : 0.215022 ,val acc : 0.901062\n",
      "train loss : 0.233131 ,train acc: 0.888672 ,val loss : 0.216959 ,val acc : 0.897919\n",
      "train loss : 0.246065 ,train acc: 0.874390 ,val loss : 0.208835 ,val acc : 0.901245\n",
      "train loss : 0.243030 ,train acc: 0.892517 ,val loss : 0.213447 ,val acc : 0.898773\n",
      "train loss : 0.277024 ,train acc: 0.856384 ,val loss : 0.209732 ,val acc : 0.897217\n",
      "train loss : 0.213776 ,train acc: 0.895538 ,val loss : 0.210071 ,val acc : 0.895905\n",
      "train loss : 0.264659 ,train acc: 0.873566 ,val loss : 0.208452 ,val acc : 0.898682\n",
      "train loss : 0.242647 ,train acc: 0.881256 ,val loss : 0.207779 ,val acc : 0.897766\n",
      "train loss : 0.237804 ,train acc: 0.877380 ,val loss : 0.206733 ,val acc : 0.899811\n",
      "train loss : 0.212359 ,train acc: 0.894836 ,val loss : 0.207891 ,val acc : 0.898224\n",
      "train loss : 0.236482 ,train acc: 0.884308 ,val loss : 0.206705 ,val acc : 0.897766\n",
      "train loss : 0.238396 ,train acc: 0.874573 ,val loss : 0.205563 ,val acc : 0.897125\n",
      "train loss : 0.242579 ,train acc: 0.878540 ,val loss : 0.207314 ,val acc : 0.899902\n",
      "train loss : 0.204483 ,train acc: 0.895905 ,val loss : 0.203950 ,val acc : 0.898285\n",
      "train loss : 0.269477 ,train acc: 0.858124 ,val loss : 0.205612 ,val acc : 0.901398\n",
      "train loss : 0.225756 ,train acc: 0.886261 ,val loss : 0.205379 ,val acc : 0.899384\n",
      "train loss : 0.202716 ,train acc: 0.896973 ,val loss : 0.198558 ,val acc : 0.905060\n",
      "train loss : 0.181376 ,train acc: 0.912445 ,val loss : 0.202501 ,val acc : 0.904327\n",
      "train loss : 0.188320 ,train acc: 0.908997 ,val loss : 0.200459 ,val acc : 0.903137\n",
      "train loss : 0.209095 ,train acc: 0.897491 ,val loss : 0.200593 ,val acc : 0.905731\n",
      "train loss : 0.248330 ,train acc: 0.866394 ,val loss : 0.200008 ,val acc : 0.905731\n",
      "train loss : 0.188290 ,train acc: 0.908661 ,val loss : 0.200189 ,val acc : 0.903778\n",
      "train loss : 0.215611 ,train acc: 0.898254 ,val loss : 0.199680 ,val acc : 0.905212\n",
      "train loss : 0.213211 ,train acc: 0.894348 ,val loss : 0.200267 ,val acc : 0.906189\n",
      "train loss : 0.226902 ,train acc: 0.869781 ,val loss : 0.199666 ,val acc : 0.907135\n",
      "train loss : 0.212566 ,train acc: 0.895111 ,val loss : 0.199121 ,val acc : 0.909180\n",
      "train loss : 0.217109 ,train acc: 0.892181 ,val loss : 0.198717 ,val acc : 0.906219\n",
      "train loss : 0.288068 ,train acc: 0.829315 ,val loss : 0.198964 ,val acc : 0.907379\n",
      "train loss : 0.198633 ,train acc: 0.910919 ,val loss : 0.197586 ,val acc : 0.906647\n",
      "train loss : 0.184298 ,train acc: 0.914154 ,val loss : 0.197088 ,val acc : 0.908447\n",
      "train loss : 0.250724 ,train acc: 0.869904 ,val loss : 0.196629 ,val acc : 0.909851\n",
      "train loss : 0.195821 ,train acc: 0.909027 ,val loss : 0.195951 ,val acc : 0.908661\n",
      "train loss : 0.246680 ,train acc: 0.807770 ,val loss : 0.196109 ,val acc : 0.911133\n",
      "train loss : 0.275700 ,train acc: 0.869080 ,val loss : 0.192794 ,val acc : 0.910278\n",
      "train loss : 0.360382 ,train acc: 0.580017 ,val loss : 0.197154 ,val acc : 0.913208\n",
      "train loss : 0.227346 ,train acc: 0.894440 ,val loss : 0.196637 ,val acc : 0.916443\n",
      "train loss : 0.190813 ,train acc: 0.921783 ,val loss : 0.194727 ,val acc : 0.917633\n",
      "train loss : 0.436905 ,train acc: 0.648376 ,val loss : 0.193758 ,val acc : 0.917908\n",
      "train loss : 0.184802 ,train acc: 0.914490 ,val loss : 0.192827 ,val acc : 0.918060\n",
      "train loss : 0.216400 ,train acc: 0.901123 ,val loss : 0.188298 ,val acc : 0.918823\n",
      "train loss : 0.220431 ,train acc: 0.883667 ,val loss : 0.192066 ,val acc : 0.917053\n",
      "train loss : 0.233610 ,train acc: 0.897491 ,val loss : 0.192774 ,val acc : 0.912170\n",
      "train loss : 0.182772 ,train acc: 0.914185 ,val loss : 0.191174 ,val acc : 0.915558\n",
      "train loss : 0.203982 ,train acc: 0.910736 ,val loss : 0.192252 ,val acc : 0.913696\n",
      "train loss : 0.168377 ,train acc: 0.922974 ,val loss : 0.192092 ,val acc : 0.915161\n",
      "train loss : 0.221950 ,train acc: 0.889984 ,val loss : 0.191610 ,val acc : 0.913239\n",
      "train loss : 0.197572 ,train acc: 0.907501 ,val loss : 0.190571 ,val acc : 0.914581\n",
      "train loss : 0.203416 ,train acc: 0.908417 ,val loss : 0.188147 ,val acc : 0.914032\n",
      "train loss : 0.161208 ,train acc: 0.929810 ,val loss : 0.187321 ,val acc : 0.915344\n",
      "train loss : 0.192838 ,train acc: 0.910706 ,val loss : 0.186270 ,val acc : 0.915771\n",
      "train loss : 0.209130 ,train acc: 0.889313 ,val loss : 0.186945 ,val acc : 0.916199\n",
      "train loss : 0.190241 ,train acc: 0.906952 ,val loss : 0.186721 ,val acc : 0.914276\n",
      "train loss : 0.182621 ,train acc: 0.912842 ,val loss : 0.185714 ,val acc : 0.918610\n",
      "train loss : 0.202896 ,train acc: 0.904358 ,val loss : 0.186738 ,val acc : 0.916351\n",
      "train loss : 0.208434 ,train acc: 0.901825 ,val loss : 0.185098 ,val acc : 0.914398\n",
      "train loss : 0.233502 ,train acc: 0.887756 ,val loss : 0.183219 ,val acc : 0.919342\n",
      "train loss : 0.222629 ,train acc: 0.889801 ,val loss : 0.183159 ,val acc : 0.920959\n",
      "train loss : 0.227507 ,train acc: 0.874481 ,val loss : 0.184243 ,val acc : 0.918243\n",
      "train loss : 0.164157 ,train acc: 0.930817 ,val loss : 0.182961 ,val acc : 0.919281\n",
      "train loss : 0.216211 ,train acc: 0.899109 ,val loss : 0.182231 ,val acc : 0.920166\n",
      "train loss : 0.200346 ,train acc: 0.906891 ,val loss : 0.182100 ,val acc : 0.920715\n",
      "train loss : 0.300293 ,train acc: 0.852661 ,val loss : 0.181719 ,val acc : 0.922943\n",
      "train loss : 0.253531 ,train acc: 0.882172 ,val loss : 0.180497 ,val acc : 0.920441\n",
      "train loss : 0.202650 ,train acc: 0.907440 ,val loss : 0.182209 ,val acc : 0.920135\n",
      "train loss : 0.299992 ,train acc: 0.648071 ,val loss : 0.179517 ,val acc : 0.924225\n",
      "train loss : 0.212288 ,train acc: 0.887848 ,val loss : 0.179705 ,val acc : 0.928284\n",
      "train loss : 0.195769 ,train acc: 0.933929 ,val loss : 0.184269 ,val acc : 0.924011\n",
      "train loss : 0.189751 ,train acc: 0.915344 ,val loss : 0.180409 ,val acc : 0.927338\n",
      "train loss : 0.259342 ,train acc: 0.898743 ,val loss : 0.181005 ,val acc : 0.927032\n",
      "train loss : 0.283081 ,train acc: 0.746613 ,val loss : 0.181741 ,val acc : 0.928833\n",
      "train loss : 0.246565 ,train acc: 0.873932 ,val loss : 0.179296 ,val acc : 0.932587\n",
      "train loss : 0.199232 ,train acc: 0.907898 ,val loss : 0.181236 ,val acc : 0.928650\n",
      "train loss : 0.260461 ,train acc: 0.881165 ,val loss : 0.180244 ,val acc : 0.932465\n",
      "train loss : 0.179582 ,train acc: 0.921539 ,val loss : 0.177588 ,val acc : 0.933258\n",
      "train loss : 0.230147 ,train acc: 0.828094 ,val loss : 0.181502 ,val acc : 0.930634\n",
      "train loss : 0.254842 ,train acc: 0.772797 ,val loss : 0.180167 ,val acc : 0.933136\n",
      "train loss : 0.194176 ,train acc: 0.917572 ,val loss : 0.179859 ,val acc : 0.932159\n",
      "train loss : 0.221005 ,train acc: 0.901123 ,val loss : 0.177726 ,val acc : 0.934357\n",
      "train loss : 0.173125 ,train acc: 0.925537 ,val loss : 0.177302 ,val acc : 0.936859\n",
      "train loss : 0.215678 ,train acc: 0.901703 ,val loss : 0.183622 ,val acc : 0.931641\n",
      "train loss : 0.364427 ,train acc: 0.798157 ,val loss : 0.178186 ,val acc : 0.934662\n",
      "train loss : 0.191838 ,train acc: 0.916718 ,val loss : 0.177224 ,val acc : 0.934662\n",
      "train loss : 0.236059 ,train acc: 0.906036 ,val loss : 0.174516 ,val acc : 0.933289\n",
      "train loss : 0.197582 ,train acc: 0.927887 ,val loss : 0.175045 ,val acc : 0.932404\n",
      "train loss : 0.170020 ,train acc: 0.931549 ,val loss : 0.176454 ,val acc : 0.930359\n",
      "train loss : 0.166407 ,train acc: 0.938843 ,val loss : 0.174237 ,val acc : 0.929169\n",
      "train loss : 0.215721 ,train acc: 0.855438 ,val loss : 0.175455 ,val acc : 0.929108\n",
      "train loss : 0.174002 ,train acc: 0.930267 ,val loss : 0.172942 ,val acc : 0.931946\n",
      "train loss : 0.205689 ,train acc: 0.912292 ,val loss : 0.173707 ,val acc : 0.932434\n",
      "train loss : 0.151644 ,train acc: 0.945770 ,val loss : 0.171903 ,val acc : 0.931946\n",
      "train loss : 0.217616 ,train acc: 0.896301 ,val loss : 0.172846 ,val acc : 0.934113\n",
      "train loss : 0.179095 ,train acc: 0.918152 ,val loss : 0.172435 ,val acc : 0.932159\n",
      "train loss : 0.161788 ,train acc: 0.933472 ,val loss : 0.172787 ,val acc : 0.933594\n",
      "train loss : 0.238735 ,train acc: 0.900513 ,val loss : 0.173109 ,val acc : 0.933167\n",
      "train loss : 0.151539 ,train acc: 0.942719 ,val loss : 0.170772 ,val acc : 0.936920\n",
      "train loss : 0.178300 ,train acc: 0.920441 ,val loss : 0.172892 ,val acc : 0.934448\n",
      "train loss : 0.199375 ,train acc: 0.918976 ,val loss : 0.170064 ,val acc : 0.936554\n",
      "train loss : 0.176548 ,train acc: 0.925476 ,val loss : 0.168883 ,val acc : 0.935059\n",
      "train loss : 0.284974 ,train acc: 0.730591 ,val loss : 0.172798 ,val acc : 0.936646\n",
      "train loss : 0.205937 ,train acc: 0.922089 ,val loss : 0.170913 ,val acc : 0.939392\n",
      "train loss : 0.192354 ,train acc: 0.920166 ,val loss : 0.170423 ,val acc : 0.941254\n",
      "train loss : 0.319588 ,train acc: 0.839417 ,val loss : 0.168760 ,val acc : 0.939941\n",
      "train loss : 0.157156 ,train acc: 0.944427 ,val loss : 0.169770 ,val acc : 0.940338\n",
      "train loss : 0.178084 ,train acc: 0.931000 ,val loss : 0.168078 ,val acc : 0.939270\n",
      "train loss : 0.191290 ,train acc: 0.924255 ,val loss : 0.166533 ,val acc : 0.940826\n",
      "train loss : 0.242510 ,train acc: 0.824463 ,val loss : 0.169781 ,val acc : 0.937500\n",
      "train loss : 0.169929 ,train acc: 0.928131 ,val loss : 0.169588 ,val acc : 0.939117\n",
      "train loss : 0.158266 ,train acc: 0.937225 ,val loss : 0.168439 ,val acc : 0.940094\n",
      "train loss : 0.155598 ,train acc: 0.951416 ,val loss : 0.166326 ,val acc : 0.941650\n",
      "train loss : 0.148149 ,train acc: 0.956360 ,val loss : 0.167395 ,val acc : 0.939575\n",
      "train loss : 0.588082 ,train acc: 0.514771 ,val loss : 0.169168 ,val acc : 0.940613\n",
      "train loss : 0.453915 ,train acc: 0.484131 ,val loss : 0.168980 ,val acc : 0.940613\n",
      "train loss : 0.181598 ,train acc: 0.915863 ,val loss : 0.167594 ,val acc : 0.942810\n",
      "train loss : 0.211736 ,train acc: 0.935730 ,val loss : 0.169669 ,val acc : 0.941620\n",
      "train loss : 0.160846 ,train acc: 0.941223 ,val loss : 0.167748 ,val acc : 0.943085\n",
      "train loss : 0.166103 ,train acc: 0.935455 ,val loss : 0.169248 ,val acc : 0.941498\n",
      "train loss : 0.290447 ,train acc: 0.784180 ,val loss : 0.168291 ,val acc : 0.942566\n",
      "train loss : 0.236545 ,train acc: 0.894653 ,val loss : 0.166851 ,val acc : 0.943146\n",
      "train loss : 0.232618 ,train acc: 0.888428 ,val loss : 0.168346 ,val acc : 0.941925\n",
      "train loss : 0.146735 ,train acc: 0.951202 ,val loss : 0.163664 ,val acc : 0.944824\n",
      "train loss : 0.342631 ,train acc: 0.847839 ,val loss : 0.165303 ,val acc : 0.941681\n",
      "train loss : 0.159090 ,train acc: 0.941132 ,val loss : 0.164855 ,val acc : 0.942993\n",
      "train loss : 0.184620 ,train acc: 0.915192 ,val loss : 0.168899 ,val acc : 0.938873\n",
      "train loss : 0.316368 ,train acc: 0.692444 ,val loss : 0.166581 ,val acc : 0.942108\n",
      "train loss : 0.193756 ,train acc: 0.924622 ,val loss : 0.166136 ,val acc : 0.942566\n",
      "train loss : 0.182363 ,train acc: 0.937744 ,val loss : 0.166527 ,val acc : 0.944763\n",
      "train loss : 0.184296 ,train acc: 0.928345 ,val loss : 0.165783 ,val acc : 0.943695\n",
      "train loss : 0.241274 ,train acc: 0.861481 ,val loss : 0.163934 ,val acc : 0.945831\n",
      "train loss : 0.186919 ,train acc: 0.928528 ,val loss : 0.165995 ,val acc : 0.942749\n",
      "train loss : 0.189688 ,train acc: 0.919830 ,val loss : 0.162977 ,val acc : 0.943878\n",
      "train loss : 0.234280 ,train acc: 0.916107 ,val loss : 0.162824 ,val acc : 0.944305\n",
      "train loss : 0.183946 ,train acc: 0.922485 ,val loss : 0.164317 ,val acc : 0.941528\n",
      "train loss : 0.237471 ,train acc: 0.901215 ,val loss : 0.162839 ,val acc : 0.945160\n",
      "train loss : 0.208807 ,train acc: 0.927490 ,val loss : 0.161745 ,val acc : 0.944489\n",
      "train loss : 0.225644 ,train acc: 0.906311 ,val loss : 0.161040 ,val acc : 0.944519\n",
      "train loss : 0.179464 ,train acc: 0.922089 ,val loss : 0.163498 ,val acc : 0.943115\n",
      "train loss : 0.220372 ,train acc: 0.913940 ,val loss : 0.161575 ,val acc : 0.944458\n",
      "train loss : 0.192166 ,train acc: 0.932434 ,val loss : 0.162186 ,val acc : 0.943604\n",
      "train loss : 0.146520 ,train acc: 0.945435 ,val loss : 0.161814 ,val acc : 0.944672\n",
      "train loss : 0.175740 ,train acc: 0.928162 ,val loss : 0.158584 ,val acc : 0.947388\n",
      "train loss : 0.155316 ,train acc: 0.949310 ,val loss : 0.158625 ,val acc : 0.947906\n",
      "train loss : 0.143128 ,train acc: 0.952393 ,val loss : 0.160680 ,val acc : 0.946259\n",
      "train loss : 0.176315 ,train acc: 0.928284 ,val loss : 0.160910 ,val acc : 0.945648\n",
      "train loss : 0.169983 ,train acc: 0.940765 ,val loss : 0.159925 ,val acc : 0.945465\n",
      "train loss : 0.220549 ,train acc: 0.904663 ,val loss : 0.158975 ,val acc : 0.946686\n",
      "train loss : 0.266572 ,train acc: 0.897095 ,val loss : 0.159674 ,val acc : 0.947876\n",
      "train loss : 0.145289 ,train acc: 0.948883 ,val loss : 0.159446 ,val acc : 0.948303\n",
      "train loss : 0.180223 ,train acc: 0.926666 ,val loss : 0.158921 ,val acc : 0.947723\n",
      "train loss : 0.190536 ,train acc: 0.913818 ,val loss : 0.161718 ,val acc : 0.947266\n",
      "train loss : 0.217729 ,train acc: 0.872620 ,val loss : 0.161081 ,val acc : 0.950195\n",
      "train loss : 0.156067 ,train acc: 0.941711 ,val loss : 0.158850 ,val acc : 0.949097\n",
      "train loss : 0.204741 ,train acc: 0.883789 ,val loss : 0.156711 ,val acc : 0.950287\n",
      "train loss : 0.329878 ,train acc: 0.821503 ,val loss : 0.156901 ,val acc : 0.951141\n",
      "train loss : 0.223627 ,train acc: 0.860931 ,val loss : 0.158242 ,val acc : 0.952057\n",
      "train loss : 0.157833 ,train acc: 0.948730 ,val loss : 0.156253 ,val acc : 0.950989\n",
      "train loss : 0.147571 ,train acc: 0.960449 ,val loss : 0.157819 ,val acc : 0.951630\n",
      "train loss : 0.213135 ,train acc: 0.859497 ,val loss : 0.156124 ,val acc : 0.952087\n",
      "train loss : 0.209813 ,train acc: 0.856903 ,val loss : 0.156280 ,val acc : 0.955017\n",
      "train loss : 0.184686 ,train acc: 0.883881 ,val loss : 0.156263 ,val acc : 0.954315\n",
      "train loss : 0.211666 ,train acc: 0.903107 ,val loss : 0.158238 ,val acc : 0.955750\n",
      "train loss : 0.205176 ,train acc: 0.933014 ,val loss : 0.162527 ,val acc : 0.951904\n",
      "train loss : 0.195976 ,train acc: 0.948517 ,val loss : 0.159068 ,val acc : 0.954041\n",
      "train loss : 0.191792 ,train acc: 0.906525 ,val loss : 0.159362 ,val acc : 0.953644\n",
      "train loss : 0.169125 ,train acc: 0.932404 ,val loss : 0.157806 ,val acc : 0.954407\n",
      "train loss : 0.192321 ,train acc: 0.927795 ,val loss : 0.156018 ,val acc : 0.956787\n",
      "train loss : 0.307705 ,train acc: 0.748840 ,val loss : 0.154954 ,val acc : 0.956726\n",
      "train loss : 0.200301 ,train acc: 0.929871 ,val loss : 0.155523 ,val acc : 0.954895\n",
      "train loss : 0.225986 ,train acc: 0.921814 ,val loss : 0.153144 ,val acc : 0.958069\n",
      "train loss : 0.165950 ,train acc: 0.941803 ,val loss : 0.154064 ,val acc : 0.955658\n",
      "train loss : 0.300940 ,train acc: 0.711395 ,val loss : 0.154366 ,val acc : 0.956757\n",
      "train loss : 0.162009 ,train acc: 0.953003 ,val loss : 0.153668 ,val acc : 0.957123\n",
      "train loss : 0.202744 ,train acc: 0.901398 ,val loss : 0.154014 ,val acc : 0.956421\n",
      "train loss : 0.176339 ,train acc: 0.948456 ,val loss : 0.154810 ,val acc : 0.955872\n",
      "train loss : 0.158135 ,train acc: 0.941101 ,val loss : 0.152003 ,val acc : 0.956390\n",
      "train loss : 0.203698 ,train acc: 0.842072 ,val loss : 0.154368 ,val acc : 0.957458\n",
      "train loss : 0.255456 ,train acc: 0.768738 ,val loss : 0.154661 ,val acc : 0.956726\n",
      "train loss : 0.169439 ,train acc: 0.946136 ,val loss : 0.154479 ,val acc : 0.956787\n",
      "train loss : 0.282124 ,train acc: 0.822144 ,val loss : 0.154494 ,val acc : 0.957153\n",
      "train loss : 0.176469 ,train acc: 0.933716 ,val loss : 0.153804 ,val acc : 0.958069\n",
      "train loss : 0.150923 ,train acc: 0.966370 ,val loss : 0.152326 ,val acc : 0.958710\n",
      "train loss : 0.140729 ,train acc: 0.965942 ,val loss : 0.152544 ,val acc : 0.958984\n",
      "train loss : 0.183820 ,train acc: 0.945496 ,val loss : 0.154166 ,val acc : 0.956451\n",
      "train loss : 0.175139 ,train acc: 0.940002 ,val loss : 0.152327 ,val acc : 0.956360\n",
      "train loss : 0.571805 ,train acc: 0.374084 ,val loss : 0.152195 ,val acc : 0.956116\n",
      "train loss : 0.163357 ,train acc: 0.953735 ,val loss : 0.152063 ,val acc : 0.957916\n",
      "train loss : 0.141067 ,train acc: 0.955994 ,val loss : 0.152162 ,val acc : 0.957275\n",
      "train loss : 0.185430 ,train acc: 0.920715 ,val loss : 0.151815 ,val acc : 0.957245\n",
      "train loss : 0.177808 ,train acc: 0.930969 ,val loss : 0.150504 ,val acc : 0.957397\n",
      "train loss : 0.159784 ,train acc: 0.939819 ,val loss : 0.151287 ,val acc : 0.958069\n",
      "train loss : 0.183096 ,train acc: 0.925903 ,val loss : 0.149510 ,val acc : 0.958832\n",
      "train loss : 0.201258 ,train acc: 0.941315 ,val loss : 0.150712 ,val acc : 0.959198\n",
      "train loss : 0.158831 ,train acc: 0.950409 ,val loss : 0.148916 ,val acc : 0.958832\n",
      "train loss : 0.131957 ,train acc: 0.963745 ,val loss : 0.150265 ,val acc : 0.959991\n",
      "train loss : 0.168964 ,train acc: 0.952850 ,val loss : 0.147897 ,val acc : 0.959656\n",
      "train loss : 0.169917 ,train acc: 0.929565 ,val loss : 0.150323 ,val acc : 0.958588\n",
      "train loss : 0.169574 ,train acc: 0.949127 ,val loss : 0.148020 ,val acc : 0.960785\n",
      "train loss : 0.204116 ,train acc: 0.866119 ,val loss : 0.149423 ,val acc : 0.958801\n",
      "train loss : 0.174153 ,train acc: 0.933380 ,val loss : 0.148014 ,val acc : 0.960876\n",
      "train loss : 0.146591 ,train acc: 0.948578 ,val loss : 0.148272 ,val acc : 0.960358\n",
      "train loss : 0.247453 ,train acc: 0.853638 ,val loss : 0.146106 ,val acc : 0.962738\n",
      "train loss : 0.170918 ,train acc: 0.936615 ,val loss : 0.149228 ,val acc : 0.961060\n",
      "train loss : 0.142887 ,train acc: 0.955444 ,val loss : 0.149105 ,val acc : 0.962830\n",
      "train loss : 0.174243 ,train acc: 0.949921 ,val loss : 0.145599 ,val acc : 0.963226\n",
      "train loss : 0.147868 ,train acc: 0.967621 ,val loss : 0.145572 ,val acc : 0.963776\n",
      "train loss : 0.169097 ,train acc: 0.960205 ,val loss : 0.147580 ,val acc : 0.963806\n",
      "train loss : 0.153495 ,train acc: 0.963043 ,val loss : 0.144449 ,val acc : 0.962646\n",
      "train loss : 0.253805 ,train acc: 0.789124 ,val loss : 0.147331 ,val acc : 0.963257\n",
      "train loss : 0.167599 ,train acc: 0.938141 ,val loss : 0.144568 ,val acc : 0.964355\n",
      "train loss : 0.222464 ,train acc: 0.825775 ,val loss : 0.146084 ,val acc : 0.963013\n",
      "train loss : 0.163335 ,train acc: 0.965332 ,val loss : 0.147653 ,val acc : 0.962402\n",
      "train loss : 0.365759 ,train acc: 0.860168 ,val loss : 0.148469 ,val acc : 0.961304\n",
      "train loss : 0.163534 ,train acc: 0.941467 ,val loss : 0.147422 ,val acc : 0.962677\n",
      "train loss : 0.135704 ,train acc: 0.962921 ,val loss : 0.145748 ,val acc : 0.964569\n",
      "train loss : 0.151249 ,train acc: 0.963593 ,val loss : 0.144439 ,val acc : 0.964020\n",
      "train loss : 0.309664 ,train acc: 0.719177 ,val loss : 0.145020 ,val acc : 0.963806\n",
      "train loss : 0.136976 ,train acc: 0.972321 ,val loss : 0.144226 ,val acc : 0.964600\n",
      "train loss : 0.197845 ,train acc: 0.932526 ,val loss : 0.147969 ,val acc : 0.963623\n",
      "train loss : 0.183192 ,train acc: 0.917603 ,val loss : 0.144324 ,val acc : 0.963470\n",
      "train loss : 0.185464 ,train acc: 0.955444 ,val loss : 0.145228 ,val acc : 0.964050\n",
      "train loss : 0.168078 ,train acc: 0.929626 ,val loss : 0.145545 ,val acc : 0.963898\n",
      "train loss : 0.152364 ,train acc: 0.953644 ,val loss : 0.144011 ,val acc : 0.965851\n",
      "train loss : 0.151435 ,train acc: 0.951019 ,val loss : 0.143398 ,val acc : 0.965759\n",
      "train loss : 0.160939 ,train acc: 0.963470 ,val loss : 0.143396 ,val acc : 0.964630\n",
      "train loss : 0.176906 ,train acc: 0.947540 ,val loss : 0.143832 ,val acc : 0.964478\n",
      "train loss : 0.157624 ,train acc: 0.940155 ,val loss : 0.143714 ,val acc : 0.963593\n",
      "train loss : 0.156734 ,train acc: 0.943848 ,val loss : 0.142469 ,val acc : 0.964417\n",
      "train loss : 0.141550 ,train acc: 0.958282 ,val loss : 0.141906 ,val acc : 0.967560\n",
      "train loss : 0.150830 ,train acc: 0.956238 ,val loss : 0.143466 ,val acc : 0.965973\n",
      "train loss : 0.169179 ,train acc: 0.949860 ,val loss : 0.142801 ,val acc : 0.965790\n",
      "train loss : 0.174709 ,train acc: 0.928558 ,val loss : 0.143280 ,val acc : 0.965607\n",
      "train loss : 0.184090 ,train acc: 0.916779 ,val loss : 0.142347 ,val acc : 0.965942\n",
      "train loss : 0.193470 ,train acc: 0.900757 ,val loss : 0.142366 ,val acc : 0.966431\n",
      "train loss : 0.130812 ,train acc: 0.966248 ,val loss : 0.144169 ,val acc : 0.964600\n",
      "train loss : 0.155788 ,train acc: 0.941437 ,val loss : 0.141737 ,val acc : 0.966156\n",
      "train loss : 0.182513 ,train acc: 0.949493 ,val loss : 0.143166 ,val acc : 0.966003\n",
      "train loss : 0.227926 ,train acc: 0.892822 ,val loss : 0.139171 ,val acc : 0.969421\n",
      "train loss : 0.174869 ,train acc: 0.956512 ,val loss : 0.142299 ,val acc : 0.968079\n",
      "train loss : 0.162273 ,train acc: 0.967346 ,val loss : 0.141178 ,val acc : 0.966736\n",
      "train loss : 0.212353 ,train acc: 0.932831 ,val loss : 0.140359 ,val acc : 0.967712\n",
      "train loss : 0.113492 ,train acc: 0.979767 ,val loss : 0.141064 ,val acc : 0.967621\n",
      "train loss : 0.286043 ,train acc: 0.728302 ,val loss : 0.139706 ,val acc : 0.968445\n",
      "train loss : 0.121158 ,train acc: 0.975922 ,val loss : 0.141631 ,val acc : 0.967377\n",
      "train loss : 0.273352 ,train acc: 0.876312 ,val loss : 0.139265 ,val acc : 0.968140\n",
      "train loss : 0.130718 ,train acc: 0.965271 ,val loss : 0.139799 ,val acc : 0.967560\n",
      "train loss : 0.191468 ,train acc: 0.941864 ,val loss : 0.139975 ,val acc : 0.967529\n",
      "train loss : 0.138063 ,train acc: 0.962616 ,val loss : 0.141931 ,val acc : 0.966827\n",
      "train loss : 0.156293 ,train acc: 0.958527 ,val loss : 0.139398 ,val acc : 0.967834\n",
      "train loss : 0.158794 ,train acc: 0.950104 ,val loss : 0.139539 ,val acc : 0.968872\n",
      "train loss : 0.182277 ,train acc: 0.950745 ,val loss : 0.139777 ,val acc : 0.968506\n",
      "train loss : 0.122619 ,train acc: 0.979767 ,val loss : 0.138743 ,val acc : 0.969482\n",
      "train loss : 0.344336 ,train acc: 0.615387 ,val loss : 0.140076 ,val acc : 0.969635\n",
      "train loss : 0.193495 ,train acc: 0.904327 ,val loss : 0.138732 ,val acc : 0.967438\n",
      "train loss : 0.261592 ,train acc: 0.735291 ,val loss : 0.139214 ,val acc : 0.970154\n",
      "train loss : 0.179728 ,train acc: 0.939209 ,val loss : 0.141528 ,val acc : 0.967651\n",
      "train loss : 0.414258 ,train acc: 0.636017 ,val loss : 0.139812 ,val acc : 0.968353\n",
      "train loss : 0.361844 ,train acc: 0.768982 ,val loss : 0.142750 ,val acc : 0.965515\n",
      "train loss : 0.164112 ,train acc: 0.943542 ,val loss : 0.143300 ,val acc : 0.966675\n",
      "train loss : 0.169095 ,train acc: 0.961578 ,val loss : 0.141622 ,val acc : 0.967041\n",
      "train loss : 0.219824 ,train acc: 0.845062 ,val loss : 0.138782 ,val acc : 0.966644\n",
      "train loss : 0.186342 ,train acc: 0.907379 ,val loss : 0.140803 ,val acc : 0.966949\n",
      "train loss : 0.164733 ,train acc: 0.962006 ,val loss : 0.138838 ,val acc : 0.966827\n",
      "train loss : 0.160869 ,train acc: 0.943573 ,val loss : 0.139791 ,val acc : 0.968079\n",
      "train loss : 0.140756 ,train acc: 0.960022 ,val loss : 0.136087 ,val acc : 0.969940\n",
      "train loss : 0.150595 ,train acc: 0.957245 ,val loss : 0.137099 ,val acc : 0.970551\n",
      "train loss : 0.152781 ,train acc: 0.955322 ,val loss : 0.135598 ,val acc : 0.971436\n",
      "train loss : 0.149245 ,train acc: 0.973999 ,val loss : 0.135723 ,val acc : 0.970062\n",
      "train loss : 0.178735 ,train acc: 0.956268 ,val loss : 0.137421 ,val acc : 0.969208\n",
      "train loss : 0.136232 ,train acc: 0.966522 ,val loss : 0.136148 ,val acc : 0.970642\n",
      "train loss : 0.232795 ,train acc: 0.810150 ,val loss : 0.138075 ,val acc : 0.969452\n",
      "train loss : 0.259055 ,train acc: 0.749817 ,val loss : 0.137591 ,val acc : 0.969940\n",
      "train loss : 0.221752 ,train acc: 0.890137 ,val loss : 0.136415 ,val acc : 0.971069\n",
      "train loss : 0.146995 ,train acc: 0.956818 ,val loss : 0.136278 ,val acc : 0.971649\n",
      "train loss : 0.143121 ,train acc: 0.954926 ,val loss : 0.136646 ,val acc : 0.970490\n",
      "train loss : 0.128183 ,train acc: 0.970154 ,val loss : 0.135976 ,val acc : 0.970337\n",
      "train loss : 0.125974 ,train acc: 0.970795 ,val loss : 0.136318 ,val acc : 0.969452\n",
      "train loss : 0.569155 ,train acc: 0.453522 ,val loss : 0.136337 ,val acc : 0.970184\n",
      "train loss : 0.206293 ,train acc: 0.870697 ,val loss : 0.140035 ,val acc : 0.967926\n",
      "train loss : 0.191199 ,train acc: 0.948792 ,val loss : 0.135708 ,val acc : 0.971100\n",
      "train loss : 0.143078 ,train acc: 0.967743 ,val loss : 0.135678 ,val acc : 0.969025\n",
      "train loss : 0.129019 ,train acc: 0.979156 ,val loss : 0.136027 ,val acc : 0.970886\n",
      "train loss : 0.121909 ,train acc: 0.980103 ,val loss : 0.135492 ,val acc : 0.970154\n",
      "train loss : 0.356636 ,train acc: 0.672089 ,val loss : 0.136324 ,val acc : 0.969910\n",
      "train loss : 0.147724 ,train acc: 0.950867 ,val loss : 0.136739 ,val acc : 0.969788\n",
      "train loss : 0.163006 ,train acc: 0.969208 ,val loss : 0.136219 ,val acc : 0.969727\n",
      "train loss : 0.243258 ,train acc: 0.797119 ,val loss : 0.136990 ,val acc : 0.970612\n",
      "train loss : 0.143698 ,train acc: 0.969666 ,val loss : 0.135936 ,val acc : 0.971313\n",
      "train loss : 0.202140 ,train acc: 0.939514 ,val loss : 0.136793 ,val acc : 0.969238\n",
      "train loss : 0.114587 ,train acc: 0.983887 ,val loss : 0.136500 ,val acc : 0.970917\n",
      "train loss : 0.131968 ,train acc: 0.978149 ,val loss : 0.135144 ,val acc : 0.970947\n",
      "train loss : 0.179856 ,train acc: 0.919464 ,val loss : 0.132878 ,val acc : 0.972778\n",
      "train loss : 0.400658 ,train acc: 0.593628 ,val loss : 0.135357 ,val acc : 0.971283\n",
      "train loss : 0.161398 ,train acc: 0.953003 ,val loss : 0.132779 ,val acc : 0.971802\n",
      "train loss : 0.250315 ,train acc: 0.854675 ,val loss : 0.134766 ,val acc : 0.971405\n",
      "train loss : 0.149457 ,train acc: 0.952484 ,val loss : 0.137048 ,val acc : 0.970337\n",
      "train loss : 0.137120 ,train acc: 0.968292 ,val loss : 0.134817 ,val acc : 0.971405\n",
      "train loss : 0.120868 ,train acc: 0.977570 ,val loss : 0.134739 ,val acc : 0.971130\n",
      "train loss : 0.181062 ,train acc: 0.910797 ,val loss : 0.134810 ,val acc : 0.971375\n",
      "train loss : 0.148375 ,train acc: 0.958252 ,val loss : 0.135733 ,val acc : 0.971680\n",
      "train loss : 0.169677 ,train acc: 0.963470 ,val loss : 0.132964 ,val acc : 0.971802\n",
      "train loss : 0.146819 ,train acc: 0.975464 ,val loss : 0.133731 ,val acc : 0.971466\n",
      "train loss : 0.151330 ,train acc: 0.960999 ,val loss : 0.133291 ,val acc : 0.971130\n",
      "train loss : 0.158291 ,train acc: 0.965881 ,val loss : 0.130927 ,val acc : 0.974396\n",
      "train loss : 0.164068 ,train acc: 0.965210 ,val loss : 0.130537 ,val acc : 0.974152\n",
      "train loss : 0.149014 ,train acc: 0.958191 ,val loss : 0.132876 ,val acc : 0.973114\n",
      "train loss : 0.160969 ,train acc: 0.967041 ,val loss : 0.131647 ,val acc : 0.973694\n",
      "train loss : 0.564024 ,train acc: 0.405609 ,val loss : 0.133833 ,val acc : 0.973083\n",
      "train loss : 0.156894 ,train acc: 0.970917 ,val loss : 0.132087 ,val acc : 0.972534\n",
      "train loss : 0.304163 ,train acc: 0.705292 ,val loss : 0.132954 ,val acc : 0.973358\n",
      "train loss : 0.230613 ,train acc: 0.932892 ,val loss : 0.135720 ,val acc : 0.970612\n",
      "train loss : 0.137741 ,train acc: 0.965027 ,val loss : 0.132631 ,val acc : 0.971924\n",
      "train loss : 0.164925 ,train acc: 0.938538 ,val loss : 0.134417 ,val acc : 0.970795\n",
      "train loss : 0.147959 ,train acc: 0.948425 ,val loss : 0.130490 ,val acc : 0.972961\n",
      "train loss : 0.165076 ,train acc: 0.959290 ,val loss : 0.132784 ,val acc : 0.971954\n",
      "train loss : 0.147900 ,train acc: 0.955231 ,val loss : 0.131597 ,val acc : 0.971771\n",
      "train loss : 0.126512 ,train acc: 0.972443 ,val loss : 0.131689 ,val acc : 0.970551\n",
      "train loss : 0.214399 ,train acc: 0.933685 ,val loss : 0.130841 ,val acc : 0.973724\n",
      "train loss : 0.191085 ,train acc: 0.932922 ,val loss : 0.130998 ,val acc : 0.973846\n",
      "train loss : 0.112816 ,train acc: 0.981842 ,val loss : 0.131820 ,val acc : 0.971863\n",
      "train loss : 0.275483 ,train acc: 0.888367 ,val loss : 0.131928 ,val acc : 0.973785\n",
      "train loss : 0.163682 ,train acc: 0.962158 ,val loss : 0.131302 ,val acc : 0.972870\n",
      "train loss : 0.164386 ,train acc: 0.935181 ,val loss : 0.130919 ,val acc : 0.973480\n",
      "train loss : 0.138867 ,train acc: 0.965546 ,val loss : 0.132741 ,val acc : 0.973969\n",
      "train loss : 0.123985 ,train acc: 0.973877 ,val loss : 0.131747 ,val acc : 0.973083\n",
      "train loss : 0.138636 ,train acc: 0.975464 ,val loss : 0.130496 ,val acc : 0.975250\n",
      "train loss : 0.285108 ,train acc: 0.727905 ,val loss : 0.130481 ,val acc : 0.974304\n",
      "train loss : 0.127819 ,train acc: 0.970459 ,val loss : 0.131657 ,val acc : 0.972717\n",
      "train loss : 0.144255 ,train acc: 0.965271 ,val loss : 0.130173 ,val acc : 0.974091\n",
      "train loss : 0.133010 ,train acc: 0.966034 ,val loss : 0.130332 ,val acc : 0.974335\n",
      "train loss : 0.157413 ,train acc: 0.950714 ,val loss : 0.127029 ,val acc : 0.975616\n",
      "train loss : 0.166721 ,train acc: 0.937775 ,val loss : 0.129631 ,val acc : 0.974030\n",
      "train loss : 0.147844 ,train acc: 0.959442 ,val loss : 0.128833 ,val acc : 0.973969\n",
      "train loss : 0.166117 ,train acc: 0.966400 ,val loss : 0.129747 ,val acc : 0.974945\n",
      "train loss : 0.119282 ,train acc: 0.978027 ,val loss : 0.128694 ,val acc : 0.974335\n",
      "train loss : 0.169554 ,train acc: 0.922180 ,val loss : 0.128384 ,val acc : 0.975189\n",
      "train loss : 0.165011 ,train acc: 0.963715 ,val loss : 0.128642 ,val acc : 0.974426\n",
      "train loss : 0.252348 ,train acc: 0.774750 ,val loss : 0.128068 ,val acc : 0.975342\n",
      "train loss : 0.132128 ,train acc: 0.979828 ,val loss : 0.128166 ,val acc : 0.974274\n",
      "train loss : 0.177620 ,train acc: 0.957581 ,val loss : 0.128493 ,val acc : 0.974182\n",
      "train loss : 0.135623 ,train acc: 0.964386 ,val loss : 0.129394 ,val acc : 0.973724\n",
      "train loss : 0.153620 ,train acc: 0.947601 ,val loss : 0.130399 ,val acc : 0.973358\n",
      "train loss : 0.134060 ,train acc: 0.967560 ,val loss : 0.126870 ,val acc : 0.975952\n",
      "train loss : 0.161965 ,train acc: 0.939453 ,val loss : 0.130677 ,val acc : 0.973846\n",
      "train loss : 0.685704 ,train acc: 0.349976 ,val loss : 0.127399 ,val acc : 0.975922\n",
      "train loss : 0.132781 ,train acc: 0.971008 ,val loss : 0.128097 ,val acc : 0.974152\n",
      "train loss : 0.149786 ,train acc: 0.950256 ,val loss : 0.128541 ,val acc : 0.974396\n",
      "train loss : 0.137999 ,train acc: 0.965515 ,val loss : 0.128645 ,val acc : 0.975403\n",
      "train loss : 0.192944 ,train acc: 0.952393 ,val loss : 0.127014 ,val acc : 0.975494\n",
      "train loss : 0.128064 ,train acc: 0.976288 ,val loss : 0.126099 ,val acc : 0.975037\n",
      "train loss : 0.201238 ,train acc: 0.906158 ,val loss : 0.129040 ,val acc : 0.975769\n",
      "train loss : 0.274725 ,train acc: 0.932526 ,val loss : 0.128034 ,val acc : 0.975281\n",
      "train loss : 0.150241 ,train acc: 0.975372 ,val loss : 0.128698 ,val acc : 0.975311\n",
      "train loss : 0.161540 ,train acc: 0.960602 ,val loss : 0.127576 ,val acc : 0.976746\n",
      "train loss : 0.139549 ,train acc: 0.979248 ,val loss : 0.125394 ,val acc : 0.976135\n",
      "train loss : 0.138375 ,train acc: 0.968567 ,val loss : 0.125896 ,val acc : 0.976227\n",
      "train loss : 0.240054 ,train acc: 0.921600 ,val loss : 0.126959 ,val acc : 0.976013\n",
      "train loss : 0.156132 ,train acc: 0.969971 ,val loss : 0.127536 ,val acc : 0.975067\n",
      "train loss : 0.113105 ,train acc: 0.985870 ,val loss : 0.126247 ,val acc : 0.975677\n",
      "train loss : 0.119205 ,train acc: 0.983643 ,val loss : 0.126543 ,val acc : 0.976440\n",
      "train loss : 0.124793 ,train acc: 0.975037 ,val loss : 0.126232 ,val acc : 0.976471\n",
      "train loss : 0.169409 ,train acc: 0.962708 ,val loss : 0.126275 ,val acc : 0.976013\n",
      "train loss : 0.130218 ,train acc: 0.971039 ,val loss : 0.127055 ,val acc : 0.975525\n",
      "train loss : 0.142480 ,train acc: 0.968475 ,val loss : 0.126372 ,val acc : 0.976501\n",
      "train loss : 0.133838 ,train acc: 0.966980 ,val loss : 0.126726 ,val acc : 0.976898\n",
      "train loss : 0.113153 ,train acc: 0.977814 ,val loss : 0.126296 ,val acc : 0.976135\n",
      "train loss : 0.430961 ,train acc: 0.529083 ,val loss : 0.126129 ,val acc : 0.975433\n",
      "train loss : 0.183137 ,train acc: 0.954620 ,val loss : 0.125655 ,val acc : 0.975159\n",
      "train loss : 0.302146 ,train acc: 0.733002 ,val loss : 0.126707 ,val acc : 0.974976\n",
      "train loss : 0.147047 ,train acc: 0.967621 ,val loss : 0.126813 ,val acc : 0.975189\n",
      "train loss : 0.173271 ,train acc: 0.933685 ,val loss : 0.125817 ,val acc : 0.975342\n",
      "train loss : 0.140036 ,train acc: 0.963593 ,val loss : 0.126885 ,val acc : 0.974091\n",
      "train loss : 0.168603 ,train acc: 0.924774 ,val loss : 0.124381 ,val acc : 0.975800\n",
      "train loss : 0.508648 ,train acc: 0.453979 ,val loss : 0.126794 ,val acc : 0.973022\n",
      "train loss : 0.150294 ,train acc: 0.972015 ,val loss : 0.128543 ,val acc : 0.972595\n",
      "train loss : 0.126025 ,train acc: 0.974701 ,val loss : 0.124804 ,val acc : 0.974670\n",
      "train loss : 0.140694 ,train acc: 0.963470 ,val loss : 0.127073 ,val acc : 0.975616\n",
      "train loss : 0.148945 ,train acc: 0.949860 ,val loss : 0.127517 ,val acc : 0.975494\n",
      "train loss : 0.145200 ,train acc: 0.969543 ,val loss : 0.127347 ,val acc : 0.974945\n",
      "train loss : 0.171340 ,train acc: 0.961975 ,val loss : 0.123927 ,val acc : 0.976837\n",
      "train loss : 0.118498 ,train acc: 0.981995 ,val loss : 0.125838 ,val acc : 0.975800\n",
      "train loss : 0.136657 ,train acc: 0.977905 ,val loss : 0.124017 ,val acc : 0.976135\n",
      "train loss : 0.105264 ,train acc: 0.986206 ,val loss : 0.126362 ,val acc : 0.976288\n",
      "train loss : 0.187733 ,train acc: 0.952423 ,val loss : 0.123788 ,val acc : 0.976318\n",
      "train loss : 0.131500 ,train acc: 0.977875 ,val loss : 0.124345 ,val acc : 0.975830\n",
      "train loss : 0.229992 ,train acc: 0.916748 ,val loss : 0.123782 ,val acc : 0.975983\n",
      "train loss : 0.135012 ,train acc: 0.960541 ,val loss : 0.123600 ,val acc : 0.976562\n",
      "train loss : 0.136179 ,train acc: 0.976227 ,val loss : 0.124218 ,val acc : 0.977936\n",
      "train loss : 0.112317 ,train acc: 0.978912 ,val loss : 0.123967 ,val acc : 0.977509\n",
      "train loss : 0.113147 ,train acc: 0.977661 ,val loss : 0.123606 ,val acc : 0.978973\n",
      "train loss : 0.135124 ,train acc: 0.968475 ,val loss : 0.124419 ,val acc : 0.977325\n",
      "train loss : 0.206578 ,train acc: 0.946777 ,val loss : 0.124071 ,val acc : 0.976318\n",
      "train loss : 0.127342 ,train acc: 0.966461 ,val loss : 0.123500 ,val acc : 0.977905\n",
      "train loss : 0.192585 ,train acc: 0.886597 ,val loss : 0.125010 ,val acc : 0.976349\n",
      "train loss : 0.163690 ,train acc: 0.966492 ,val loss : 0.123478 ,val acc : 0.977020\n",
      "train loss : 0.147035 ,train acc: 0.974762 ,val loss : 0.123147 ,val acc : 0.976898\n",
      "train loss : 0.117424 ,train acc: 0.983032 ,val loss : 0.122957 ,val acc : 0.977844\n",
      "train loss : 0.145938 ,train acc: 0.948700 ,val loss : 0.123376 ,val acc : 0.978638\n",
      "train loss : 0.125241 ,train acc: 0.976227 ,val loss : 0.124135 ,val acc : 0.977478\n",
      "train loss : 0.094866 ,train acc: 0.991791 ,val loss : 0.123377 ,val acc : 0.977081\n",
      "train loss : 0.431337 ,train acc: 0.491547 ,val loss : 0.123966 ,val acc : 0.976379\n",
      "train loss : 0.174389 ,train acc: 0.969543 ,val loss : 0.123248 ,val acc : 0.976593\n",
      "train loss : 0.121716 ,train acc: 0.971558 ,val loss : 0.122672 ,val acc : 0.976227\n",
      "train loss : 0.337298 ,train acc: 0.793823 ,val loss : 0.122119 ,val acc : 0.977051\n",
      "train loss : 0.176928 ,train acc: 0.950989 ,val loss : 0.122804 ,val acc : 0.975739\n",
      "train loss : 0.149956 ,train acc: 0.973999 ,val loss : 0.123208 ,val acc : 0.976135\n",
      "train loss : 0.180609 ,train acc: 0.951416 ,val loss : 0.121865 ,val acc : 0.978027\n",
      "train loss : 0.141528 ,train acc: 0.976288 ,val loss : 0.122100 ,val acc : 0.977295\n",
      "train loss : 0.111296 ,train acc: 0.985168 ,val loss : 0.124161 ,val acc : 0.976501\n",
      "train loss : 0.239913 ,train acc: 0.807343 ,val loss : 0.123557 ,val acc : 0.976410\n",
      "train loss : 0.117840 ,train acc: 0.983521 ,val loss : 0.123785 ,val acc : 0.975983\n",
      "train loss : 0.112781 ,train acc: 0.982391 ,val loss : 0.122781 ,val acc : 0.976471\n",
      "train loss : 0.135079 ,train acc: 0.972717 ,val loss : 0.124092 ,val acc : 0.977051\n",
      "train loss : 0.130942 ,train acc: 0.974274 ,val loss : 0.122076 ,val acc : 0.976746\n",
      "train loss : 0.127599 ,train acc: 0.977478 ,val loss : 0.124338 ,val acc : 0.977020\n",
      "train loss : 0.294644 ,train acc: 0.919708 ,val loss : 0.123058 ,val acc : 0.977234\n",
      "train loss : 0.319413 ,train acc: 0.701599 ,val loss : 0.122422 ,val acc : 0.977478\n",
      "train loss : 0.182798 ,train acc: 0.883942 ,val loss : 0.120573 ,val acc : 0.977600\n",
      "train loss : 0.159675 ,train acc: 0.971283 ,val loss : 0.123021 ,val acc : 0.976227\n",
      "train loss : 0.189040 ,train acc: 0.959198 ,val loss : 0.122237 ,val acc : 0.977325\n",
      "train loss : 0.113307 ,train acc: 0.979858 ,val loss : 0.122536 ,val acc : 0.978546\n",
      "train loss : 0.171286 ,train acc: 0.967072 ,val loss : 0.122277 ,val acc : 0.977570\n",
      "train loss : 0.117545 ,train acc: 0.983551 ,val loss : 0.122453 ,val acc : 0.976776\n",
      "train loss : 0.209702 ,train acc: 0.870605 ,val loss : 0.121289 ,val acc : 0.977264\n",
      "train loss : 0.215343 ,train acc: 0.859253 ,val loss : 0.123202 ,val acc : 0.976532\n",
      "train loss : 0.102331 ,train acc: 0.988708 ,val loss : 0.122870 ,val acc : 0.976746\n",
      "train loss : 0.161770 ,train acc: 0.969482 ,val loss : 0.122874 ,val acc : 0.977692\n",
      "train loss : 0.136915 ,train acc: 0.974030 ,val loss : 0.121392 ,val acc : 0.976715\n",
      "train loss : 0.154406 ,train acc: 0.937347 ,val loss : 0.122318 ,val acc : 0.977386\n",
      "train loss : 0.103566 ,train acc: 0.988007 ,val loss : 0.123394 ,val acc : 0.977722\n",
      "train loss : 0.145128 ,train acc: 0.973480 ,val loss : 0.121437 ,val acc : 0.977631\n",
      "train loss : 0.131034 ,train acc: 0.971985 ,val loss : 0.121062 ,val acc : 0.977722\n",
      "train loss : 0.177571 ,train acc: 0.932312 ,val loss : 0.119308 ,val acc : 0.979370\n",
      "train loss : 0.170346 ,train acc: 0.959351 ,val loss : 0.122428 ,val acc : 0.976166\n",
      "train loss : 0.129197 ,train acc: 0.970398 ,val loss : 0.120218 ,val acc : 0.978058\n",
      "train loss : 0.124109 ,train acc: 0.971893 ,val loss : 0.121260 ,val acc : 0.978271\n",
      "train loss : 0.196482 ,train acc: 0.931793 ,val loss : 0.120351 ,val acc : 0.979187\n",
      "train loss : 0.394500 ,train acc: 0.640686 ,val loss : 0.121793 ,val acc : 0.978607\n",
      "train loss : 0.125248 ,train acc: 0.977570 ,val loss : 0.121023 ,val acc : 0.977325\n",
      "train loss : 0.119218 ,train acc: 0.978516 ,val loss : 0.120472 ,val acc : 0.977386\n",
      "train loss : 0.120554 ,train acc: 0.980072 ,val loss : 0.120675 ,val acc : 0.978027\n",
      "train loss : 0.101433 ,train acc: 0.989044 ,val loss : 0.119982 ,val acc : 0.978119\n",
      "train loss : 0.133370 ,train acc: 0.976257 ,val loss : 0.120345 ,val acc : 0.978241\n",
      "train loss : 0.127497 ,train acc: 0.976196 ,val loss : 0.118920 ,val acc : 0.978424\n",
      "train loss : 0.140890 ,train acc: 0.973663 ,val loss : 0.120625 ,val acc : 0.978546\n",
      "train loss : 0.113666 ,train acc: 0.978973 ,val loss : 0.119544 ,val acc : 0.979279\n",
      "train loss : 0.150471 ,train acc: 0.973541 ,val loss : 0.117687 ,val acc : 0.980103\n",
      "train loss : 0.237293 ,train acc: 0.944366 ,val loss : 0.118178 ,val acc : 0.980316\n",
      "train loss : 0.196517 ,train acc: 0.923126 ,val loss : 0.119552 ,val acc : 0.978729\n",
      "train loss : 0.143431 ,train acc: 0.961853 ,val loss : 0.119750 ,val acc : 0.979431\n",
      "train loss : 0.120448 ,train acc: 0.983490 ,val loss : 0.119122 ,val acc : 0.979340\n",
      "train loss : 0.146397 ,train acc: 0.976440 ,val loss : 0.119375 ,val acc : 0.977600\n",
      "train loss : 0.160256 ,train acc: 0.935120 ,val loss : 0.118292 ,val acc : 0.979034\n",
      "train loss : 0.134716 ,train acc: 0.969910 ,val loss : 0.119497 ,val acc : 0.978119\n",
      "train loss : 0.257108 ,train acc: 0.863098 ,val loss : 0.119296 ,val acc : 0.977661\n",
      "train loss : 0.485847 ,train acc: 0.581299 ,val loss : 0.120628 ,val acc : 0.977997\n",
      "train loss : 0.107526 ,train acc: 0.985931 ,val loss : 0.119853 ,val acc : 0.979187\n",
      "train loss : 0.163426 ,train acc: 0.929199 ,val loss : 0.120145 ,val acc : 0.977692\n",
      "train loss : 0.115392 ,train acc: 0.981537 ,val loss : 0.119505 ,val acc : 0.978088\n",
      "train loss : 0.146190 ,train acc: 0.961151 ,val loss : 0.119543 ,val acc : 0.977905\n",
      "train loss : 0.122830 ,train acc: 0.975128 ,val loss : 0.118427 ,val acc : 0.978455\n",
      "train loss : 0.121511 ,train acc: 0.976257 ,val loss : 0.118790 ,val acc : 0.978821\n",
      "train loss : 0.143166 ,train acc: 0.960938 ,val loss : 0.119265 ,val acc : 0.979248\n",
      "train loss : 0.167277 ,train acc: 0.965271 ,val loss : 0.117678 ,val acc : 0.980469\n",
      "train loss : 0.143148 ,train acc: 0.973602 ,val loss : 0.119538 ,val acc : 0.978241\n",
      "train loss : 0.146101 ,train acc: 0.974457 ,val loss : 0.118775 ,val acc : 0.980286\n",
      "train loss : 0.198034 ,train acc: 0.905518 ,val loss : 0.119554 ,val acc : 0.979065\n",
      "train loss : 0.112366 ,train acc: 0.984894 ,val loss : 0.118232 ,val acc : 0.979950\n",
      "train loss : 0.097987 ,train acc: 0.989410 ,val loss : 0.116656 ,val acc : 0.980164\n",
      "train loss : 0.131045 ,train acc: 0.970306 ,val loss : 0.117985 ,val acc : 0.979401\n",
      "train loss : 0.194208 ,train acc: 0.955292 ,val loss : 0.117221 ,val acc : 0.979462\n",
      "train loss : 0.193584 ,train acc: 0.962067 ,val loss : 0.118093 ,val acc : 0.980011\n",
      "train loss : 0.130217 ,train acc: 0.980469 ,val loss : 0.119259 ,val acc : 0.980133\n",
      "train loss : 0.175651 ,train acc: 0.900299 ,val loss : 0.118029 ,val acc : 0.980011\n",
      "train loss : 0.171702 ,train acc: 0.917816 ,val loss : 0.118875 ,val acc : 0.978577\n",
      "train loss : 0.124432 ,train acc: 0.976013 ,val loss : 0.119216 ,val acc : 0.978546\n",
      "train loss : 0.114785 ,train acc: 0.980652 ,val loss : 0.119623 ,val acc : 0.979523\n",
      "train loss : 0.130437 ,train acc: 0.980652 ,val loss : 0.118313 ,val acc : 0.978821\n",
      "train loss : 0.117344 ,train acc: 0.978638 ,val loss : 0.117649 ,val acc : 0.979614\n",
      "train loss : 0.365948 ,train acc: 0.793091 ,val loss : 0.118138 ,val acc : 0.980286\n",
      "train loss : 0.113845 ,train acc: 0.984375 ,val loss : 0.117768 ,val acc : 0.978363\n",
      "train loss : 0.149338 ,train acc: 0.954285 ,val loss : 0.117317 ,val acc : 0.981140\n",
      "train loss : 0.126210 ,train acc: 0.972626 ,val loss : 0.117629 ,val acc : 0.979370\n",
      "train loss : 0.133753 ,train acc: 0.957733 ,val loss : 0.117303 ,val acc : 0.979095\n",
      "train loss : 0.165539 ,train acc: 0.963562 ,val loss : 0.116546 ,val acc : 0.980072\n",
      "train loss : 0.132694 ,train acc: 0.968781 ,val loss : 0.116486 ,val acc : 0.978912\n",
      "train loss : 0.094423 ,train acc: 0.991364 ,val loss : 0.116233 ,val acc : 0.980255\n",
      "train loss : 0.282722 ,train acc: 0.804688 ,val loss : 0.116987 ,val acc : 0.978790\n",
      "train loss : 0.119123 ,train acc: 0.976715 ,val loss : 0.117119 ,val acc : 0.979309\n",
      "train loss : 0.153933 ,train acc: 0.954132 ,val loss : 0.116577 ,val acc : 0.978424\n",
      "train loss : 0.194294 ,train acc: 0.951904 ,val loss : 0.117499 ,val acc : 0.978210\n",
      "train loss : 0.162537 ,train acc: 0.924683 ,val loss : 0.115885 ,val acc : 0.979126\n",
      "train loss : 0.153205 ,train acc: 0.970123 ,val loss : 0.116489 ,val acc : 0.978180\n",
      "train loss : 0.126826 ,train acc: 0.974670 ,val loss : 0.116853 ,val acc : 0.979095\n",
      "train loss : 0.158673 ,train acc: 0.968719 ,val loss : 0.117589 ,val acc : 0.978271\n",
      "train loss : 0.113678 ,train acc: 0.981354 ,val loss : 0.117128 ,val acc : 0.979248\n",
      "train loss : 0.124790 ,train acc: 0.966919 ,val loss : 0.115878 ,val acc : 0.979401\n",
      "train loss : 0.179522 ,train acc: 0.896332 ,val loss : 0.116277 ,val acc : 0.979675\n",
      "train loss : 0.138969 ,train acc: 0.955505 ,val loss : 0.116740 ,val acc : 0.978363\n",
      "train loss : 0.111168 ,train acc: 0.981720 ,val loss : 0.116631 ,val acc : 0.979614\n",
      "train loss : 0.094656 ,train acc: 0.989349 ,val loss : 0.116720 ,val acc : 0.979218\n",
      "train loss : 0.153812 ,train acc: 0.968719 ,val loss : 0.115236 ,val acc : 0.979767\n",
      "train loss : 0.097731 ,train acc: 0.989288 ,val loss : 0.115606 ,val acc : 0.979858\n",
      "train loss : 0.163483 ,train acc: 0.960663 ,val loss : 0.116544 ,val acc : 0.980530\n",
      "train loss : 0.110625 ,train acc: 0.983704 ,val loss : 0.116023 ,val acc : 0.979828\n",
      "train loss : 0.533232 ,train acc: 0.498413 ,val loss : 0.114950 ,val acc : 0.980225\n",
      "train loss : 0.318991 ,train acc: 0.840576 ,val loss : 0.115521 ,val acc : 0.979065\n",
      "train loss : 0.152026 ,train acc: 0.941650 ,val loss : 0.113911 ,val acc : 0.979645\n",
      "train loss : 0.133368 ,train acc: 0.978210 ,val loss : 0.116012 ,val acc : 0.979095\n",
      "train loss : 0.143788 ,train acc: 0.975159 ,val loss : 0.113447 ,val acc : 0.980499\n",
      "train loss : 0.107209 ,train acc: 0.985199 ,val loss : 0.116317 ,val acc : 0.979004\n",
      "train loss : 0.137936 ,train acc: 0.978546 ,val loss : 0.115760 ,val acc : 0.979218\n",
      "train loss : 0.139461 ,train acc: 0.964264 ,val loss : 0.116267 ,val acc : 0.979553\n",
      "train loss : 0.118558 ,train acc: 0.974915 ,val loss : 0.115194 ,val acc : 0.980865\n",
      "train loss : 0.126657 ,train acc: 0.976654 ,val loss : 0.114156 ,val acc : 0.981445\n",
      "train loss : 0.143700 ,train acc: 0.970703 ,val loss : 0.114670 ,val acc : 0.980621\n",
      "train loss : 0.132864 ,train acc: 0.978607 ,val loss : 0.115221 ,val acc : 0.979797\n",
      "train loss : 0.270822 ,train acc: 0.848785 ,val loss : 0.114202 ,val acc : 0.979279\n",
      "train loss : 0.108866 ,train acc: 0.978882 ,val loss : 0.114479 ,val acc : 0.980865\n",
      "train loss : 0.141353 ,train acc: 0.977753 ,val loss : 0.116160 ,val acc : 0.980804\n",
      "train loss : 0.287167 ,train acc: 0.857330 ,val loss : 0.114876 ,val acc : 0.980286\n",
      "train loss : 0.108298 ,train acc: 0.984894 ,val loss : 0.112948 ,val acc : 0.980804\n",
      "train loss : 0.653326 ,train acc: 0.333496 ,val loss : 0.114932 ,val acc : 0.980774\n",
      "train loss : 0.304558 ,train acc: 0.764893 ,val loss : 0.116460 ,val acc : 0.979645\n",
      "train loss : 0.133648 ,train acc: 0.972412 ,val loss : 0.116260 ,val acc : 0.978729\n",
      "train loss : 0.124927 ,train acc: 0.974518 ,val loss : 0.114826 ,val acc : 0.979431\n",
      "train loss : 0.130450 ,train acc: 0.971008 ,val loss : 0.114848 ,val acc : 0.979431\n",
      "train loss : 0.156062 ,train acc: 0.931213 ,val loss : 0.114496 ,val acc : 0.980042\n",
      "train loss : 0.125493 ,train acc: 0.975922 ,val loss : 0.114849 ,val acc : 0.980774\n",
      "train loss : 0.108306 ,train acc: 0.986664 ,val loss : 0.114764 ,val acc : 0.979706\n",
      "train loss : 0.142228 ,train acc: 0.960754 ,val loss : 0.114920 ,val acc : 0.980774\n",
      "train loss : 0.101696 ,train acc: 0.987091 ,val loss : 0.113863 ,val acc : 0.981506\n",
      "train loss : 0.138540 ,train acc: 0.976685 ,val loss : 0.114323 ,val acc : 0.980469\n",
      "train loss : 0.128497 ,train acc: 0.971222 ,val loss : 0.114629 ,val acc : 0.981384\n",
      "train loss : 0.168778 ,train acc: 0.966736 ,val loss : 0.114930 ,val acc : 0.980286\n",
      "train loss : 0.124933 ,train acc: 0.976593 ,val loss : 0.112394 ,val acc : 0.982208\n",
      "train loss : 0.120709 ,train acc: 0.977386 ,val loss : 0.113241 ,val acc : 0.981445\n",
      "train loss : 0.116203 ,train acc: 0.975800 ,val loss : 0.112333 ,val acc : 0.981873\n",
      "train loss : 0.152577 ,train acc: 0.972839 ,val loss : 0.113785 ,val acc : 0.981232\n",
      "train loss : 0.125006 ,train acc: 0.971436 ,val loss : 0.113249 ,val acc : 0.982300\n",
      "train loss : 0.186179 ,train acc: 0.884552 ,val loss : 0.114641 ,val acc : 0.980621\n",
      "train loss : 0.128684 ,train acc: 0.974182 ,val loss : 0.113827 ,val acc : 0.981598\n",
      "train loss : 0.132406 ,train acc: 0.967255 ,val loss : 0.112748 ,val acc : 0.981506\n",
      "train loss : 0.218389 ,train acc: 0.943115 ,val loss : 0.113582 ,val acc : 0.980255\n",
      "train loss : 0.127404 ,train acc: 0.978912 ,val loss : 0.112235 ,val acc : 0.981689\n",
      "train loss : 0.107491 ,train acc: 0.983246 ,val loss : 0.114658 ,val acc : 0.980835\n",
      "train loss : 0.367678 ,train acc: 0.628357 ,val loss : 0.113955 ,val acc : 0.980133\n",
      "train loss : 0.205387 ,train acc: 0.955780 ,val loss : 0.114738 ,val acc : 0.980469\n",
      "train loss : 0.238217 ,train acc: 0.809570 ,val loss : 0.113015 ,val acc : 0.980469\n",
      "train loss : 0.219001 ,train acc: 0.818024 ,val loss : 0.114032 ,val acc : 0.979645\n",
      "train loss : 0.306019 ,train acc: 0.800079 ,val loss : 0.114890 ,val acc : 0.978516\n",
      "train loss : 0.120732 ,train acc: 0.979218 ,val loss : 0.115048 ,val acc : 0.977844\n",
      "train loss : 0.118374 ,train acc: 0.976471 ,val loss : 0.114505 ,val acc : 0.978210\n",
      "train loss : 0.185425 ,train acc: 0.943085 ,val loss : 0.114561 ,val acc : 0.978485\n",
      "train loss : 0.154702 ,train acc: 0.969879 ,val loss : 0.114997 ,val acc : 0.978241\n",
      "train loss : 0.108513 ,train acc: 0.985260 ,val loss : 0.114471 ,val acc : 0.979767\n",
      "train loss : 0.143654 ,train acc: 0.956360 ,val loss : 0.113019 ,val acc : 0.979858\n",
      "train loss : 0.114672 ,train acc: 0.983002 ,val loss : 0.113855 ,val acc : 0.981567\n",
      "train loss : 0.419755 ,train acc: 0.510406 ,val loss : 0.112904 ,val acc : 0.980164\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "data_files = glob.glob('../unet_3d_traindata/*_data_*.npy')\n",
    "\n",
    "np.random.shuffle(data_files)\n",
    "train_datafiles = data_files[:800]\n",
    "val_datafiles = data_files[800:]\n",
    "\n",
    "val_data = np.load(val_datafiles[2])\n",
    "val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "val_norm[val_norm > 1] = 1\n",
    "val_norm[val_norm < 0] = 0\n",
    "val_label = np.load(val_datafiles[0].replace('_data_','_label_weighted'))\n",
    "evaled_weights = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    val_costs = []\n",
    "    val_accs = []\n",
    "    for val_datafile in val_datafiles[:20]:\n",
    "        val_data = np.load(val_datafile)\n",
    "        val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "        val_norm[val_norm > 1] = 1\n",
    "        val_norm[val_norm < 0] = 0\n",
    "        val_label = np.load(val_datafiles[0].replace('_data_','_label_weighted'))\n",
    "        val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                           feed_dict={x:val_norm,y:crop_to_shape(val_label,[32,32,32,2]),keep_prob:0.5})\n",
    "        print('val loss: %f ,val acc : %f' % (val_cost,val_acc))\n",
    "        val_costs.append(val_cost)\n",
    "        val_accs.append(val_acc)\n",
    "    print(np.mean(val_cost),np.mean(val_acc))\n",
    "    for train_datafile in train_datafiles:\n",
    "        train_data = np.load(train_datafile)\n",
    "        train_norm = (train_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "        train_norm[train_norm > 1] = 1\n",
    "        train_norm[train_norm < 0] = 0\n",
    "        train_label = np.load(train_datafile.replace('_data_','_label_weighted'))\n",
    "        _,train_cost,train_output_shape,train_acc,ws = sess.run([optimizer,cost,logits_shape,accuracy,weights],\n",
    "                                       feed_dict={x:train_norm,y:crop_to_shape(train_label,[32,32,32,2]),keep_prob:0.5})\n",
    "        evaled_weights.extend(ws)\n",
    "        val_costs = []\n",
    "        val_accs = []\n",
    "        for val_datafile in val_datafiles[:10]:\n",
    "            val_data = np.load(val_datafile)\n",
    "            val_norm = (val_data.astype('float32')-(-1000))/(400 - (-1000))\n",
    "            val_norm[val_norm > 1] = 1\n",
    "            val_norm[val_norm < 0] = 0\n",
    "            val_label = np.load(val_datafiles[0].replace('_data_','_label_weighted'))\n",
    "            val_cost,val_output_shape,val_acc = sess.run([cost,logits_shape,accuracy],\n",
    "                                           feed_dict={x:val_norm,y:crop_to_shape(val_label,[32,32,32,2]),keep_prob:0.5})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accs.append(val_acc)\n",
    "        print('train loss : %f ,train acc: %f ,val loss : %f ,val acc : %f' % (train_cost,train_acc,np.mean(val_cost),np.mean(val_acc)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 训练数据及其对应的Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64) (32, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "data0 = np.load('../unet_3d_traindata/LKDS-00001_data_0_0_0_0.npy')\n",
    "label0 = np.load('../unet_3d_traindata/LKDS-00001_label_0_0_0_0.npy')\n",
    "print(data0.shape,label0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f433db1ffd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f434346c450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data0[32,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f433e00d690>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f433e0e8b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(label0[16,:,:,1],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64) (32, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load('../unet_3d_traindata/LKDS-00011_data_0_0_-8_0.npy')\n",
    "label1 = np.load('../unet_3d_traindata/LKDS-00011_label_0_0_-8_0.npy')\n",
    "print(data1.shape,label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1dcd82d2d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1dcd8aa390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data1[32,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1dccfa7810>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1dcd085150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(label1[19,:,:,1],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('../nodule_cubes/val_data/pkl/origion.pkl','rb')\n",
    "origins = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('../nodule_cubes/val_data/pkl/new_spacing.pkl','rb')\n",
    "new_spacings = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 350, 350)\n",
      "171.25 170.749940447 285.39990046\n"
     ]
    }
   ],
   "source": [
    "ct_id = \"LKDS-00851\"\n",
    "train_data = np.load('../nodule_cubes/val_data/npy/'+ct_id+'.npy')\n",
    "\n",
    "origin = origins[ct_id]\n",
    "spacing = new_spacings[ct_id]\n",
    "print(train_data.shape)\n",
    "# print(val_meta[ct_id])\n",
    "# cz,cy,cx= val_meta[ct_id]['grounds'][0]\n",
    "\n",
    "cz,cy,cx = world_2_voxel(np.array([166.50,-4.25,105.40]),origin,spacing)\n",
    "print(cz,cy,cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1909ca9710>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1909d8f7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[171,:,:]>-600,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbovKyqJMZSrTbdH/D/bJH7eTu+XFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1909ee9310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f190a70aed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[171,:,:],cmap='gray')\n",
    "plt.show()\n",
    "mask = train_data[int(cz),:,:]  > -700\n",
    "mask = mask.astype('uint8')\n",
    "mask *= 255\n",
    "rgb = cv2.cvtColor(mask,cv2.COLOR_GRAY2RGB)\n",
    "cv2.circle(rgb,(int(cx),int(cy)),10,[255,0,0],2)\n",
    "plt.imshow(rgb,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "data_mask = np.load('../valdata_masks/LKDS-00002.npy')\n",
    "print(data_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe8ed7449d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8f40cf810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_mask[211,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证集、训练集数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./unet3d_models_7/ecpho_7/unet3d_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./unet3d_models_7/ecpho_7/unet3d_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n",
      "[ 1 ] LKDS-00644 num : 1296 ,time : 87.305805 \n",
      "1848\n",
      "[ 2 ] LKDS-00276 num : 1848 ,time : 118.239371 \n",
      "900\n",
      "[ 3 ] LKDS-00172 num : 900 ,time : 56.998324 \n",
      "936\n",
      "[ 4 ] LKDS-00353 num : 936 ,time : 59.509210 \n",
      "1452\n",
      "[ 5 ] LKDS-00588 num : 1452 ,time : 93.831174 \n",
      "2028\n",
      "[ 6 ] LKDS-00853 num : 2028 ,time : 126.355228 \n",
      "7956\n",
      "[ 7 ] LKDS-00748 num : 7956 ,time : 496.964527 \n",
      "1248\n",
      "[ 8 ] LKDS-00376 num : 1248 ,time : 78.831475 \n",
      "2028\n",
      "[ 9 ] LKDS-00685 num : 2028 ,time : 127.308609 \n",
      "1848\n",
      "[ 10 ] LKDS-00828 num : 1848 ,time : 116.333400 \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "val_datafiles = glob.glob('../nodule_cubes/val_data/npy/*.npy')\n",
    "# val_datamasks = glob.glob('../valdata_mask/*.npy')\n",
    "\n",
    "np.random.shuffle(val_datafiles)\n",
    "\n",
    "ind = 0\n",
    "for val_datafile in val_datafiles[:10]:\n",
    "    ind += 1\n",
    "    t1 = time.time()\n",
    "    ct_id = os.path.basename(val_datafile)[:-4]\n",
    "    maskfile = '../valdata_masks/'+ct_id+'.npy'\n",
    "    origin = np.load(val_datafile)\n",
    "    normed_data = (origin.astype('float32')-(-1000))/(400 - (-1000))\n",
    "    normed_data[normed_data > 1] = 1\n",
    "    normed_data[normed_data < 0] = 0\n",
    "    data_mask = np.load(maskfile)\n",
    "    result3d = np.zeros_like(origin,dtype=np.float32)\n",
    "    \n",
    "    coords = []\n",
    "    for az in range(0,origin.shape[0]-63,24):\n",
    "        for ay in range(30,origin.shape[1]-63,24):\n",
    "            for ax in range(20,origin.shape[2]-63,24):\n",
    "#                 if np.sum(data_mask[az+30:az+34,ay+30:ay+34,ax+30:ax+34]) < 2:\n",
    "#                     continue\n",
    "#                 if np.sum(data_mask[az+20:az+40,ay+20:ay+40,ax+20:ax+40]) > 6000:\n",
    "#                     continue\n",
    "                coords.append([az,ay,ax])\n",
    "    coords = np.array(coords)\n",
    "    print(coords.shape[0])\n",
    "    \n",
    "#     inds = np.random.choice(np.arange(coords.shape[0]),int(coords.shape[0]*0.6))\n",
    "#     coords = coords[inds]\n",
    "    \n",
    "    for i in range(0,coords.shape[0],30):\n",
    "        tmp_data = []\n",
    "        for tz,ty,tx in coords[i:i+30]:\n",
    "            tmp_data.append(normed_data[tz:tz+64,ty:ty+64,tx:tx+64])\n",
    "        tmp_data = np.array(tmp_data)\n",
    "        prediction,val_output_shape = sess.run([predictor,logits_shape],feed_dict={input_x:tmp_data,keep_prob:0.5})\n",
    "        for j in range(prediction.shape[0]):\n",
    "            tz,ty,tx = coords[i+j,:]\n",
    "            result3d[tz+16:tz+48,ty+16:ty+48,tx+16:tx+48] = np.maximum(result3d[tz+16:tz+48,ty+16:ty+48,tx+16:tx+48],prediction[j,:,:,:,1])\n",
    "    np.save('../unet3d_prediction/'+ct_id+'.npy',result3d)\n",
    "    t2 = time.time()\n",
    "    print('[ %d ] %s num : %d ,time : %f ' % (ind,ct_id,coords.shape[0],t2-t1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 366, 366)\n"
     ]
    }
   ],
   "source": [
    "tt = np.load('../unet3d_prediction/LKDS-00644.npy')\n",
    "print(tt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tt>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff74870a050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+A0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7f8549890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tt[171]>0.4,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7347ce4d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKVAoiEiBQkFECv4fnn5RhjYAMWYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7486db2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tt[171]>0.5,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f190267ff90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1906171610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = tt[167]>0.5\n",
    "disk = skimage.morphology.disk(2)\n",
    "tmp = np.zeros_like(mask)\n",
    "skimage.morphology.binary_closing(mask,selem=disk,out=tmp)\n",
    "plt.imshow(tmp,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ LKDS-00172 ] before : 4585 ,after : 4252\n",
      "[ LKDS-00276 ] before : 6131 ,after : 5839\n",
      "[ LKDS-00353 ] before : 2911 ,after : 2682\n",
      "[ LKDS-00376 ] before : 3541 ,after : 3354\n",
      "[ LKDS-00588 ] before : 4912 ,after : 4630\n",
      "[ LKDS-00644 ] before : 4457 ,after : 4251\n",
      "[ LKDS-00685 ] before : 6620 ,after : 6270\n",
      "[ LKDS-00748 ] before : 6695 ,after : 6369\n",
      "[ LKDS-00828 ] before : 4964 ,after : 4590\n",
      "[ LKDS-00853 ] before : 5038 ,after : 4763\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "prediction_files = glob.glob('../unet3d_prediction/*.npy')\n",
    "\n",
    "f = open('../nodule_cubes/val_data/pkl/origion.pkl','rb')\n",
    "origins = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('../nodule_cubes/val_data/pkl/new_spacing.pkl','rb')\n",
    "new_spacings = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "ct_ids = []\n",
    "probs = []\n",
    "coordZs = []\n",
    "coordYs = []\n",
    "coordXs = []\n",
    "\n",
    "# np.random.shuffle(prediction_files)\n",
    "disk = skimage.morphology.disk(2)\n",
    "for prediction_file in prediction_files[:]:\n",
    "    prediction = np.load(prediction_file)\n",
    "    mask_3d = prediction > 0.50\n",
    "    ct_id = os.path.basename(prediction_file)[:-4]\n",
    "    origin = origins[ct_id]\n",
    "    spacing = new_spacings[ct_id]\n",
    "    prediction_mask = np.load('../resized_valdata_masks/'+ct_id+'.npy')\n",
    "    coords = np.argwhere(mask_3d)\n",
    "    count = 0\n",
    "    for idx in range(coords.shape[0]):\n",
    "        coord = coords[idx]\n",
    "        if prediction_mask[coord[0],coord[1],coord[2]] == 0:\n",
    "            prediction[coord[0],coord[1],coord[2]] = 0\n",
    "            mask_3d[coord[0],coord[1],coord[2]] = 0\n",
    "    \n",
    "    for idx in range(mask_3d.shape[0]):\n",
    "        mask_tmp = np.zeros_like(mask_3d[idx])\n",
    "        skimage.morphology.binary_closing(mask_3d[idx,:,:],selem=disk,out = mask_tmp)\n",
    "        mask_3d[idx,:,:] = mask_tmp[:,:]\n",
    "    \n",
    "    measured = skimage.measure.label(mask_3d)\n",
    "    regions = regionprops(measured)\n",
    "    for region in regions:\n",
    "        coords = region.coords\n",
    "        area = region.area\n",
    "        center = coords.mean(axis=0)\n",
    "        if area < 30:\n",
    "            count += 1\n",
    "            prob = prediction[int(center[0]),int(center[1]),int(center[2])]\n",
    "            coordz,coordy,coordx = voxel_2_world(center,origin,spacing)\n",
    "            coordZs.append(coordz)\n",
    "            coordYs.append(coordy)\n",
    "            coordXs.append(coordx)\n",
    "            probs.append(prob)\n",
    "            ct_ids.append(ct_id)\n",
    "            continue\n",
    "            \n",
    "        tmp_probs = []\n",
    "        for coord in coords:\n",
    "            tmp_prob = prediction[coord[0],coord[1],coord[2]]\n",
    "            tmp_probs.append(tmp_prob)\n",
    "        core_coord = coords[np.argmax(tmp_probs)]\n",
    "        coordz,coordy,coordx = voxel_2_world(core_coord,origin,spacing)\n",
    "        core_prob = tmp_probs[np.argmax(tmp_probs)]\n",
    "        coordZs.append(coordz)\n",
    "        coordYs.append(coordy)\n",
    "        coordXs.append(coordx)\n",
    "        probs.append(core_prob)\n",
    "        ct_ids.append(ct_id)\n",
    "        \n",
    "        if area < 200:\n",
    "            inds = []\n",
    "            for _ in range(20):\n",
    "                ind = np.random.choice(np.arange(int(area)),1)\n",
    "                coord = coords[ind][0]\n",
    "                prob = prediction[coord[0],coord[1],coord[2]]\n",
    "                if (np.linalg.norm(coord-core_coord) > 3) and (ind not in inds) and ((core_prob - prob) < 0.1):\n",
    "                    count += 1\n",
    "                    inds.append(ind)\n",
    "                    coordz,coordy,coordx = voxel_2_world(coord,origin,spacing)\n",
    "                    coordZs.append(coordz)\n",
    "                    coordYs.append(coordy)\n",
    "                    coordXs.append(coordx)\n",
    "                    probs.append(prob)\n",
    "                    ct_ids.append(ct_id)\n",
    "                    continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        inds = []\n",
    "        for _ in range(120):\n",
    "            ind = np.random.choice(np.arange(int(area)),1)\n",
    "            coord = coords[ind][0]\n",
    "            prob = prediction[coord[0],coord[1],coord[2]]\n",
    "            if (np.linalg.norm(coord-core_coord) > 6) and (ind not in inds) and ((core_prob - prob) < 0.1):\n",
    "                count += 1\n",
    "                inds.append(ind)\n",
    "                coordz,coordy,coordx = voxel_2_world(coord,origin,spacing)\n",
    "                coordZs.append(coordz)\n",
    "                coordYs.append(coordy)\n",
    "                coordXs.append(coordx)\n",
    "                probs.append(prob)\n",
    "                ct_ids.append(ct_id)\n",
    "                continue\n",
    "\n",
    "\n",
    "    #np.save(prediction_file,prediction)\n",
    "    print(\"[ %s ] before : %d ,after : %d\" % (ct_id,count,len(regions)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'seriesuid':ct_ids,'coordZ':coordZs,'coordY':coordYs,'coordX':coordXs,'probability':probs})\n",
    "df.to_csv('unet3d_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>probability</th>\n",
       "      <th>seriesuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41.053965</td>\n",
       "      <td>-124.089142</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.703482</td>\n",
       "      <td>LKDS-00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-63.968018</td>\n",
       "      <td>-124.907501</td>\n",
       "      <td>20.499999</td>\n",
       "      <td>0.522195</td>\n",
       "      <td>LKDS-00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-85.245352</td>\n",
       "      <td>-139.637964</td>\n",
       "      <td>26.099999</td>\n",
       "      <td>0.507359</td>\n",
       "      <td>LKDS-00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.781936</td>\n",
       "      <td>-119.997347</td>\n",
       "      <td>27.499999</td>\n",
       "      <td>0.543271</td>\n",
       "      <td>LKDS-00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.053423</td>\n",
       "      <td>-111.813757</td>\n",
       "      <td>32.399999</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>LKDS-00002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coordX      coordY     coordZ  probability   seriesuid\n",
       "0 -41.053965 -124.089142  12.800000     0.703482  LKDS-00002\n",
       "1 -63.968018 -124.907501  20.499999     0.522195  LKDS-00002\n",
       "2 -85.245352 -139.637964  26.099999     0.507359  LKDS-00002\n",
       "3  40.781936 -119.997347  27.499999     0.543271  LKDS-00002\n",
       "4  35.053423 -111.813757  32.399999     0.528025  LKDS-00002"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 LKDS-00002 15.111971 ]\n",
      "[ 2 LKDS-00006 14.850761 ]\n",
      "[ 3 LKDS-00008 8.783515 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-64aea2b42a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_opening\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmeasured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mregions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregionprops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasured\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/misc.pyc\u001b[0m in \u001b[0;36mfunc_out\u001b[0;34m(image, selem, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mselem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_selem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/binary.pyc\u001b[0m in \u001b[0;36mbinary_opening\u001b[0;34m(image, selem, out)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m    110\u001b[0m     \u001b[0meroded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_erosion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meroded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/misc.pyc\u001b[0m in \u001b[0;36mfunc_out\u001b[0;34m(image, selem, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mselem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_selem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/binary.pyc\u001b[0m in \u001b[0;36mbinary_dilation\u001b[0;34m(image, selem, out)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mndi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/morphology.pyc\u001b[0m in \u001b[0;36mbinary_dilation\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     return _binary_erosion(input, structure, iterations, mask,\n\u001b[0;32m--> 502\u001b[0;31m                            output, border_value, origin, 1, brute_force)\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/morphology.pyc\u001b[0m in \u001b[0;36m_binary_erosion\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, invert, brute_force)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         _nd_image.binary_erosion(input, structure, mask, output,\n\u001b[0;32m--> 248\u001b[0;31m                                      border_value, origin, invert, cit, 0)\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbrute_force\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "train_datafiles = glob.glob('../valdata_pkl/*.npy')\n",
    "count = 0\n",
    "for train_datafile in train_datafiles[:]:\n",
    "    count += 1\n",
    "    t1 = time.time()\n",
    "    train_data = np.load(train_datafile)\n",
    "    ct_id = os.path.basename(train_datafile)[:-4]\n",
    "    save_path = '../valdata_masks/'+ct_id+'.npy'\n",
    "    #if os.path.exists(save_path):\n",
    "        #continue\n",
    "    result3d = np.zeros_like(train_data)\n",
    "    disk = skimage.morphology.disk(5)\n",
    "    for i in range(train_data.shape[0]):\n",
    "        mask = train_data[i,:,:] > -600\n",
    "        tmp = np.zeros_like(mask)\n",
    "        skimage.morphology.binary_opening(mask,selem=disk,out=tmp)\n",
    "        measured = skimage.measure.label(tmp)\n",
    "        regions = skimage.measure.regionprops(measured)\n",
    "        regions = sorted(regions,key=lambda r:r.area,reverse=True)\n",
    "        for region in regions[1:]:\n",
    "            coords = region.coords\n",
    "            for coord in coords:\n",
    "                tmp[coord[0],coord[1]] = 0\n",
    "        mask = train_data[i,:,:] > -700\n",
    "        tmp_result = np.bitwise_xor(mask,tmp)\n",
    "        tmp_result = skimage.segmentation.clear_border(tmp_result)\n",
    "        tmp_disk = skimage.morphology.disk(2)\n",
    "        tmp = np.zeros_like(mask)\n",
    "        skimage.morphology.binary_dilation(tmp_result,selem=tmp_disk,out=tmp)\n",
    "        #meauserd = skimage.measure.label(tmp)\n",
    "        #regions = skimage.measure.regionprops(meauserd)\n",
    "        #regions = sorted(regions,key=lambda arg:arg.area,reverse=True)\n",
    "        #tmp_out = np.zeros_like(mask)\n",
    "        #for region in regions[:2]:\n",
    "         #   for tx,ty in region.coords:\n",
    "          #      tmp_out[tx,ty] = 1\n",
    "        \n",
    "        result3d[i,:,:] = np.bitwise_and(tmp_result,tmp)\n",
    "    np.save(save_path,result3d)\n",
    "    t2 = time.time()\n",
    "    print(\"[ %d %s %f ]\" % (count,ct_id,t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 LKDS-00002 33.154730 ]\n",
      "[ 2 LKDS-00006 24.575217 ]\n",
      "[ 3 LKDS-00008 17.127676 ]\n",
      "[ 4 LKDS-00009 16.582665 ]\n",
      "[ 5 LKDS-00010 17.047099 ]\n",
      "[ 6 LKDS-00014 13.263974 ]\n",
      "[ 7 LKDS-00017 12.387539 ]\n",
      "[ 8 LKDS-00018 25.132138 ]\n",
      "[ 9 LKDS-00024 14.631619 ]\n",
      "[ 10 LKDS-00032 18.442744 ]\n",
      "[ 11 LKDS-00045 13.903500 ]\n",
      "[ 12 LKDS-00048 29.206207 ]\n",
      "[ 13 LKDS-00055 21.279819 ]\n",
      "[ 14 LKDS-00059 16.913303 ]\n",
      "[ 15 LKDS-00060 26.071715 ]\n",
      "[ 16 LKDS-00067 19.088675 ]\n",
      "[ 17 LKDS-00069 15.352309 ]\n",
      "[ 18 LKDS-00071 15.361076 ]\n",
      "[ 19 LKDS-00072 11.439435 ]\n",
      "[ 20 LKDS-00080 11.111553 ]\n",
      "[ 21 LKDS-00086 14.807965 ]\n",
      "[ 22 LKDS-00113 11.599208 ]\n",
      "[ 23 LKDS-00115 19.180905 ]\n",
      "[ 24 LKDS-00121 22.281838 ]\n",
      "[ 25 LKDS-00123 27.315559 ]\n",
      "[ 26 LKDS-00125 20.865943 ]\n",
      "[ 27 LKDS-00128 18.795923 ]\n",
      "[ 28 LKDS-00130 12.240114 ]\n",
      "[ 29 LKDS-00138 12.249719 ]\n",
      "[ 30 LKDS-00141 16.310938 ]\n",
      "[ 31 LKDS-00145 14.862299 ]\n",
      "[ 32 LKDS-00146 22.854043 ]\n",
      "[ 33 LKDS-00148 30.915375 ]\n",
      "[ 34 LKDS-00153 11.119447 ]\n",
      "[ 35 LKDS-00161 28.200116 ]\n",
      "[ 36 LKDS-00163 18.597680 ]\n",
      "[ 37 LKDS-00166 15.014563 ]\n",
      "[ 38 LKDS-00170 11.280591 ]\n",
      "[ 39 LKDS-00172 23.431848 ]\n",
      "[ 40 LKDS-00177 18.638926 ]\n",
      "[ 41 LKDS-00190 16.745353 ]\n",
      "[ 42 LKDS-00197 18.260379 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-9154d02d77be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdisk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmeasuered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mregions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregionprops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasuered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/misc.pyc\u001b[0m in \u001b[0;36mfunc_out\u001b[0;34m(image, selem, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mselem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_selem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/binary.pyc\u001b[0m in \u001b[0;36mbinary_dilation\u001b[0;34m(image, selem, out)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mndi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/morphology.pyc\u001b[0m in \u001b[0;36mbinary_dilation\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     return _binary_erosion(input, structure, iterations, mask,\n\u001b[0;32m--> 502\u001b[0;31m                            output, border_value, origin, 1, brute_force)\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/ndimage/morphology.pyc\u001b[0m in \u001b[0;36m_binary_erosion\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, invert, brute_force)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         _nd_image.binary_erosion(input, structure, mask, output,\n\u001b[0;32m--> 248\u001b[0;31m                                      border_value, origin, invert, cit, 0)\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbrute_force\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "train_datafiles = glob.glob('../valdata_pkl/*.npy')\n",
    "count = 0\n",
    "for train_datafile in train_datafiles[:]:\n",
    "    count += 1\n",
    "    t1 = time.time()\n",
    "    train_data = np.load(train_datafile)\n",
    "    ct_id = os.path.basename(train_datafile)[:-4]\n",
    "    save_path = '../valdata_masks/'+ct_id+'.npy'\n",
    "    #if os.path.exists(save_path):\n",
    "        #continue\n",
    "    result_mask3d = np.zeros_like(train_data)\n",
    "    for i in range(train_data.shape[0]):\n",
    "        mask = train_data[i] > -600\n",
    "        disk = skimage.morphology.disk(5)\n",
    "        tmp1 = np.zeros_like(mask)\n",
    "        skimage.morphology.binary_opening(mask,selem=disk,out=tmp1)\n",
    "        meausred = label(tmp1)\n",
    "        regions = regionprops(meausred)\n",
    "        regions = sorted(regions,key=lambda r:r.area,reverse=True)\n",
    "        for r in regions[1:]:\n",
    "            coords = r.coords\n",
    "            for coord in coords:\n",
    "                tmp1[coord[0],coord[1]] = 0\n",
    "        mask = train_data[i] > -700\n",
    "        disk = skimage.morphology.disk(5)\n",
    "        tmp2 = np.zeros_like(mask)\n",
    "        skimage.morphology.binary_dilation(mask,selem=disk,out=tmp2)\n",
    "        measuered = label(tmp2)\n",
    "        regions = regionprops(measuered)\n",
    "        regions = sorted(regions,key=lambda r:r.area,reverse=True)\n",
    "        for region in regions[1:]:\n",
    "            coords = region.coords\n",
    "            for cx,cy in coords:\n",
    "                tmp2[cx,cy] = 0\n",
    "        tmp3 = np.bitwise_and(mask,tmp2)\n",
    "        tmp2 = np.bitwise_xor(tmp1,tmp3)\n",
    "        disk = skimage.morphology.disk(1)\n",
    "        tmp3 = skimage.morphology.binary_dilation(tmp2,selem=disk)\n",
    "        tmp1 = clear_border(tmp3)\n",
    "        result_mask3d[i,:,:] = np.bitwise_and(tmp2,tmp1)\n",
    "    np.save(save_path,result_mask3d)\n",
    "    t2 = time.time()\n",
    "    print(\"[ %d %s %f ]\" % (count,ct_id,t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 LKDS-00002 3.420715 ]\n",
      "[ 2 LKDS-00006 2.316464 ]\n",
      "[ 3 LKDS-00008 2.102210 ]\n",
      "[ 4 LKDS-00009 2.788738 ]\n",
      "[ 5 LKDS-00010 4.340834 ]\n",
      "[ 6 LKDS-00014 2.549039 ]\n",
      "[ 7 LKDS-00017 2.489507 ]\n",
      "[ 8 LKDS-00018 2.992262 ]\n",
      "[ 9 LKDS-00024 2.436633 ]\n",
      "[ 10 LKDS-00032 2.997989 ]\n",
      "[ 11 LKDS-00045 2.076540 ]\n",
      "[ 12 LKDS-00048 2.986247 ]\n",
      "[ 13 LKDS-00055 6.589551 ]\n",
      "[ 14 LKDS-00059 2.722981 ]\n",
      "[ 15 LKDS-00060 2.614075 ]\n",
      "[ 16 LKDS-00067 3.785329 ]\n",
      "[ 17 LKDS-00069 2.509820 ]\n",
      "[ 18 LKDS-00071 2.589662 ]\n",
      "[ 19 LKDS-00072 2.458911 ]\n",
      "[ 20 LKDS-00080 2.109376 ]\n",
      "[ 21 LKDS-00086 2.677634 ]\n",
      "[ 22 LKDS-00113 2.362517 ]\n",
      "[ 23 LKDS-00115 3.008454 ]\n",
      "[ 24 LKDS-00121 2.571785 ]\n",
      "[ 25 LKDS-00123 2.851527 ]\n",
      "[ 26 LKDS-00125 8.195948 ]\n",
      "[ 27 LKDS-00128 2.708191 ]\n",
      "[ 28 LKDS-00130 2.318049 ]\n",
      "[ 29 LKDS-00138 3.350427 ]\n",
      "[ 30 LKDS-00141 2.176796 ]\n",
      "[ 31 LKDS-00145 3.529581 ]\n",
      "[ 32 LKDS-00146 2.780962 ]\n",
      "[ 33 LKDS-00148 2.940868 ]\n",
      "[ 34 LKDS-00153 2.447239 ]\n",
      "[ 35 LKDS-00161 4.089303 ]\n",
      "[ 36 LKDS-00163 2.829546 ]\n",
      "[ 37 LKDS-00166 3.517176 ]\n",
      "[ 38 LKDS-00170 7.058749 ]\n",
      "[ 39 LKDS-00172 1.601382 ]\n",
      "[ 40 LKDS-00177 3.748620 ]\n",
      "[ 41 LKDS-00190 2.603958 ]\n",
      "[ 42 LKDS-00197 2.381582 ]\n",
      "[ 43 LKDS-00201 3.578962 ]\n",
      "[ 44 LKDS-00202 2.193631 ]\n",
      "[ 45 LKDS-00208 1.719026 ]\n",
      "[ 46 LKDS-00210 2.482122 ]\n",
      "[ 47 LKDS-00226 2.305349 ]\n",
      "[ 48 LKDS-00228 6.888286 ]\n",
      "[ 49 LKDS-00233 2.483092 ]\n",
      "[ 50 LKDS-00234 4.093106 ]\n",
      "[ 51 LKDS-00241 2.725020 ]\n",
      "[ 52 LKDS-00250 8.222981 ]\n",
      "[ 53 LKDS-00255 2.714464 ]\n",
      "[ 54 LKDS-00268 3.107992 ]\n",
      "[ 55 LKDS-00276 2.963410 ]\n",
      "[ 56 LKDS-00282 2.780257 ]\n",
      "[ 57 LKDS-00288 1.824340 ]\n",
      "[ 58 LKDS-00310 3.686601 ]\n",
      "[ 59 LKDS-00311 2.472447 ]\n",
      "[ 60 LKDS-00317 2.645232 ]\n",
      "[ 61 LKDS-00318 2.675397 ]\n",
      "[ 62 LKDS-00324 2.555292 ]\n",
      "[ 63 LKDS-00327 2.525781 ]\n",
      "[ 64 LKDS-00329 2.567023 ]\n",
      "[ 65 LKDS-00338 8.171804 ]\n",
      "[ 66 LKDS-00340 2.067601 ]\n",
      "[ 67 LKDS-00343 2.522910 ]\n",
      "[ 68 LKDS-00344 1.623473 ]\n",
      "[ 69 LKDS-00353 1.988307 ]\n",
      "[ 70 LKDS-00354 2.469057 ]\n",
      "[ 71 LKDS-00365 2.313649 ]\n",
      "[ 72 LKDS-00367 2.200690 ]\n",
      "[ 73 LKDS-00370 2.902921 ]\n",
      "[ 74 LKDS-00372 2.649383 ]\n",
      "[ 75 LKDS-00376 1.959605 ]\n",
      "[ 76 LKDS-00380 2.440991 ]\n",
      "[ 77 LKDS-00387 2.385403 ]\n",
      "[ 78 LKDS-00391 8.226294 ]\n",
      "[ 79 LKDS-00401 2.762429 ]\n",
      "[ 80 LKDS-00404 4.496340 ]\n",
      "[ 81 LKDS-00409 2.381803 ]\n",
      "[ 82 LKDS-00411 2.242193 ]\n",
      "[ 83 LKDS-00415 2.389610 ]\n",
      "[ 84 LKDS-00419 2.519277 ]\n",
      "[ 85 LKDS-00425 2.935851 ]\n",
      "[ 86 LKDS-00070 2.120513 ]\n",
      "[ 87 LKDS-00157 2.726456 ]\n",
      "[ 88 LKDS-00243 2.574790 ]\n",
      "[ 89 LKDS-00351 2.886187 ]\n",
      "[ 90 LKDS-00430 2.494767 ]\n",
      "[ 91 LKDS-00539 2.142473 ]\n",
      "[ 92 LKDS-00618 8.701557 ]\n",
      "[ 93 LKDS-00687 3.015250 ]\n",
      "[ 94 LKDS-00774 3.507756 ]\n",
      "[ 95 LKDS-00902 3.188262 ]\n",
      "[ 96 LKDS-00432 3.150172 ]\n",
      "[ 97 LKDS-00433 2.792381 ]\n",
      "[ 98 LKDS-00437 3.454105 ]\n",
      "[ 99 LKDS-00464 2.530503 ]\n",
      "[ 100 LKDS-00468 1.671227 ]\n",
      "[ 101 LKDS-00479 2.770506 ]\n",
      "[ 102 LKDS-00483 2.531129 ]\n",
      "[ 103 LKDS-00484 2.013163 ]\n",
      "[ 104 LKDS-00501 1.924661 ]\n",
      "[ 105 LKDS-00504 9.485608 ]\n",
      "[ 106 LKDS-00505 3.503110 ]\n",
      "[ 107 LKDS-00508 2.440138 ]\n",
      "[ 108 LKDS-00520 2.386376 ]\n",
      "[ 109 LKDS-00522 2.561463 ]\n",
      "[ 110 LKDS-00524 2.224793 ]\n",
      "[ 111 LKDS-00532 3.025813 ]\n",
      "[ 112 LKDS-00538 5.801324 ]\n",
      "[ 113 LKDS-00542 1.545297 ]\n",
      "[ 114 LKDS-00552 2.168831 ]\n",
      "[ 115 LKDS-00554 2.706935 ]\n",
      "[ 116 LKDS-00557 6.864456 ]\n",
      "[ 117 LKDS-00560 3.828100 ]\n",
      "[ 118 LKDS-00570 2.370100 ]\n",
      "[ 119 LKDS-00577 2.631712 ]\n",
      "[ 120 LKDS-00584 1.943067 ]\n",
      "[ 121 LKDS-00588 2.335851 ]\n",
      "[ 122 LKDS-00590 3.165315 ]\n",
      "[ 123 LKDS-00591 2.226421 ]\n",
      "[ 124 LKDS-00594 2.305890 ]\n",
      "[ 125 LKDS-00597 2.064309 ]\n",
      "[ 126 LKDS-00602 2.200701 ]\n",
      "[ 127 LKDS-00607 2.874861 ]\n",
      "[ 128 LKDS-00616 5.008683 ]\n",
      "[ 129 LKDS-00617 4.215787 ]\n",
      "[ 130 LKDS-00621 5.863456 ]\n",
      "[ 131 LKDS-00627 3.126541 ]\n",
      "[ 132 LKDS-00636 3.264160 ]\n",
      "[ 133 LKDS-00637 4.255209 ]\n",
      "[ 134 LKDS-00644 2.032941 ]\n",
      "[ 135 LKDS-00645 2.203495 ]\n",
      "[ 136 LKDS-00652 6.659653 ]\n",
      "[ 137 LKDS-00654 4.059442 ]\n",
      "[ 138 LKDS-00656 2.410076 ]\n",
      "[ 139 LKDS-00657 2.777598 ]\n",
      "[ 140 LKDS-00662 2.384784 ]\n",
      "[ 141 LKDS-00664 8.168553 ]\n",
      "[ 142 LKDS-00672 2.543398 ]\n",
      "[ 143 LKDS-00679 2.556918 ]\n",
      "[ 144 LKDS-00680 2.179826 ]\n",
      "[ 145 LKDS-00685 3.221701 ]\n",
      "[ 146 LKDS-00686 1.931467 ]\n",
      "[ 147 LKDS-00688 3.142024 ]\n",
      "[ 148 LKDS-00690 2.882635 ]\n",
      "[ 149 LKDS-00693 2.625747 ]\n",
      "[ 150 LKDS-00695 2.517680 ]\n",
      "[ 151 LKDS-00704 2.774653 ]\n",
      "[ 152 LKDS-00715 8.811851 ]\n",
      "[ 153 LKDS-00720 2.535738 ]\n",
      "[ 154 LKDS-00724 2.969915 ]\n",
      "[ 155 LKDS-00729 4.003965 ]\n",
      "[ 156 LKDS-00735 1.759375 ]\n",
      "[ 157 LKDS-00737 1.923320 ]\n",
      "[ 158 LKDS-00747 2.369036 ]\n",
      "[ 159 LKDS-00748 9.430538 ]\n",
      "[ 160 LKDS-00758 2.951066 ]\n",
      "[ 161 LKDS-00761 2.279568 ]\n",
      "[ 162 LKDS-00766 2.529968 ]\n",
      "[ 163 LKDS-00769 2.251669 ]\n",
      "[ 164 LKDS-00785 9.301295 ]\n",
      "[ 165 LKDS-00791 2.318283 ]\n",
      "[ 166 LKDS-00793 2.534077 ]\n",
      "[ 167 LKDS-00799 4.168415 ]\n",
      "[ 168 LKDS-00806 2.250548 ]\n",
      "[ 169 LKDS-00828 3.025418 ]\n",
      "[ 170 LKDS-00850 3.350871 ]\n",
      "[ 171 LKDS-00851 2.244360 ]\n",
      "[ 172 LKDS-00853 2.991696 ]\n",
      "[ 173 LKDS-00858 2.184738 ]\n",
      "[ 174 LKDS-00860 2.673868 ]\n",
      "[ 175 LKDS-00861 2.372586 ]\n",
      "[ 176 LKDS-00864 2.048577 ]\n",
      "[ 177 LKDS-00869 9.029130 ]\n",
      "[ 178 LKDS-00877 2.368773 ]\n",
      "[ 179 LKDS-00881 2.520623 ]\n",
      "[ 180 LKDS-00889 2.264727 ]\n",
      "[ 181 LKDS-00905 2.264478 ]\n",
      "[ 182 LKDS-00908 2.365909 ]\n",
      "[ 183 LKDS-00913 2.771639 ]\n",
      "[ 184 LKDS-00926 3.074414 ]\n",
      "[ 185 LKDS-00928 2.128573 ]\n",
      "[ 186 LKDS-00929 2.280299 ]\n",
      "[ 187 LKDS-00932 1.532119 ]\n",
      "[ 188 LKDS-00943 2.599307 ]\n",
      "[ 189 LKDS-00947 8.116280 ]\n",
      "[ 190 LKDS-00955 1.562223 ]\n",
      "[ 191 LKDS-00958 2.415241 ]\n",
      "[ 192 LKDS-00959 4.952168 ]\n",
      "[ 193 LKDS-00960 7.228317 ]\n",
      "[ 194 LKDS-00971 2.500280 ]\n",
      "[ 195 LKDS-00972 3.025060 ]\n",
      "[ 196 LKDS-00978 2.671052 ]\n",
      "[ 197 LKDS-00987 8.075100 ]\n",
      "[ 198 LKDS-00988 2.192725 ]\n",
      "[ 199 LKDS-00993 8.477487 ]\n",
      "[ 200 LKDS-00999 2.414254 ]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "train_datafiles = glob.glob('../nodule_cubes/val_data/npy/*.npy')\n",
    "count = 0\n",
    "for train_datafile in train_datafiles[:]:\n",
    "    count += 1\n",
    "    t1 = time.time()\n",
    "    train_data = np.load(train_datafile)\n",
    "    ct_id = os.path.basename(train_datafile)[:-4]\n",
    "    save_path = '../resized_valdata_masks/'+ct_id+'.npy'\n",
    "    result_mask3d = np.zeros_like(train_data)\n",
    "    disk = skimage.morphology.disk(5)\n",
    "    for i in range(train_data.shape[0]):\n",
    "        mask = train_data[i] < -600\n",
    "        tmp = np.zeros_like(mask)\n",
    "        skimage.morphology.binary_dilation(mask,selem=disk,out=tmp)\n",
    "        cleared = clear_border(tmp)\n",
    "        result_mask3d[i,:,:] = cleared[:,:]\n",
    "        \n",
    "    np.save(save_path,result_mask3d)\n",
    "    t2 = time.time()\n",
    "    print(\"[ %d %s %f ]\" % (count,ct_id,t2-t1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
